{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.6936681866645813
[5/24] Train loss=0.6848737597465515
[10/24] Train loss=0.6783919334411621
[15/24] Train loss=0.6698368191719055
[20/24] Train loss=0.6600858569145203
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.29%
Best model saved!! Metric=50.2860274591607!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.674660 Test loss=0.652327 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6482620239257812
[5/24] Train loss=0.63491290807724
[10/24] Train loss=0.631125271320343
[15/24] Train loss=0.6196712255477905
[20/24] Train loss=0.6076463460922241
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.59%
Best model saved!! Metric=50.588549860673915!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.624658 Test loss=0.598528 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.5880071520805359
[5/24] Train loss=0.573585569858551
[10/24] Train loss=0.5845217704772949
[15/24] Train loss=0.5849995017051697
[20/24] Train loss=0.5838290452957153
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.41%
Best model saved!! Metric=54.40796622213533!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.580928 Test loss=0.579599 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.564896285533905
[5/24] Train loss=0.5504528880119324
[10/24] Train loss=0.569345235824585
[15/24] Train loss=0.5712447762489319
[20/24] Train loss=0.5710066556930542
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.32%
Best model saved!! Metric=62.317966529038316!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.565539 Test loss=0.567257 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5591427087783813
[5/24] Train loss=0.5362209677696228
[10/24] Train loss=0.5564179420471191
[15/24] Train loss=0.5567070841789246
[20/24] Train loss=0.5602942705154419
Test set avg_accuracy=73.68% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=66.45%
Best model saved!! Metric=66.44558430874126!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.553605 Test loss=0.556596 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5522677898406982
[5/24] Train loss=0.5190097093582153
[10/24] Train loss=0.5426009297370911
[15/24] Train loss=0.5419937372207642
[20/24] Train loss=0.5480376482009888
Test set avg_accuracy=73.59% avg_sensitivity=0.59%, avg_specificity=99.66% avg_auc=68.47%
Best model saved!! Metric=68.4707330408341!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.541032 Test loss=0.545061 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5407400131225586
[5/24] Train loss=0.5048893690109253
[10/24] Train loss=0.530443012714386
[15/24] Train loss=0.5264812707901001
[20/24] Train loss=0.5313533544540405
Test set avg_accuracy=73.36% avg_sensitivity=1.53%, avg_specificity=99.01% avg_auc=71.14%
Best model saved!! Metric=71.14071903958778!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.527286 Test loss=0.531297 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.5200484395027161
[5/24] Train loss=0.49235326051712036
[10/24] Train loss=0.5169126987457275
[15/24] Train loss=0.5091246962547302
[20/24] Train loss=0.5124646425247192
Test set avg_accuracy=74.02% avg_sensitivity=7.22%, avg_specificity=97.88% avg_auc=72.90%
Best model saved!! Metric=72.90351381181462!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.511327 Test loss=0.517064 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.4945545196533203
[5/24] Train loss=0.4787675440311432
[10/24] Train loss=0.5006622672080994
[15/24] Train loss=0.4915428161621094
[20/24] Train loss=0.5033868551254272
Test set avg_accuracy=74.99% avg_sensitivity=10.44%, avg_specificity=98.04% avg_auc=74.30%
Best model saved!! Metric=74.295839086307!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.495597 Test loss=0.504942 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.4767351448535919
[5/24] Train loss=0.46146446466445923
[10/24] Train loss=0.4872148036956787
[15/24] Train loss=0.47683948278427124
[20/24] Train loss=0.49009159207344055
Test set avg_accuracy=75.83% avg_sensitivity=24.10%, avg_specificity=94.31% avg_auc=75.84%
Best model saved!! Metric=75.84260825915273!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.480104 Test loss=0.493427 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.4638233482837677
[5/24] Train loss=0.44375738501548767
[10/24] Train loss=0.471495658159256
[15/24] Train loss=0.4617263972759247
[20/24] Train loss=0.47164037823677063
Test set avg_accuracy=76.88% avg_sensitivity=29.99%, avg_specificity=93.62% avg_auc=77.48%
Best model saved!! Metric=77.4834375127603!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.465152 Test loss=0.480265 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.44759124517440796
[5/24] Train loss=0.4293948709964752
[10/24] Train loss=0.4606539309024811
[15/24] Train loss=0.45139747858047485
[20/24] Train loss=0.4496123790740967
Test set avg_accuracy=77.49% avg_sensitivity=32.95%, avg_specificity=93.39% avg_auc=79.20%
Best model saved!! Metric=79.19699228082166!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.451253 Test loss=0.466999 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.4344453513622284
[5/24] Train loss=0.41959065198898315
[10/24] Train loss=0.45618191361427307
[15/24] Train loss=0.44452276825904846
[20/24] Train loss=0.4312748908996582
Test set avg_accuracy=78.20% avg_sensitivity=41.32%, avg_specificity=91.38% avg_auc=80.58%
Best model saved!! Metric=80.57906122487168!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.440323 Test loss=0.457638 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.422711580991745
[5/24] Train loss=0.4076090157032013
[10/24] Train loss=0.448588490486145
[15/24] Train loss=0.4291808605194092
[20/24] Train loss=0.4216676354408264
Test set avg_accuracy=78.31% avg_sensitivity=51.31%, avg_specificity=87.95% avg_auc=81.67%
Best model saved!! Metric=81.67157463701291!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.429081 Test loss=0.451373 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.4160586893558502
[5/24] Train loss=0.3958736062049866
[10/24] Train loss=0.43234527111053467
[15/24] Train loss=0.4163099527359009
[20/24] Train loss=0.41032499074935913
Test set avg_accuracy=79.36% avg_sensitivity=52.94%, avg_specificity=88.80% avg_auc=82.70%
Best model saved!! Metric=82.69720768124829!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.416383 Test loss=0.440482 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.40349605679512024
[5/24] Train loss=0.38291284441947937
[10/24] Train loss=0.4237285852432251
[15/24] Train loss=0.4086567163467407
[20/24] Train loss=0.3955021798610687
Test set avg_accuracy=80.52% avg_sensitivity=51.26%, avg_specificity=90.97% avg_auc=83.48%
Best model saved!! Metric=83.48322906355506!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.404705 Test loss=0.427914 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.3824445307254791
[5/24] Train loss=0.37184587121009827
[10/24] Train loss=0.41619327664375305
[15/24] Train loss=0.40220028162002563
[20/24] Train loss=0.38315048813819885
Test set avg_accuracy=81.26% avg_sensitivity=48.59%, avg_specificity=92.93% avg_auc=84.06%
Best model saved!! Metric=84.05831803700306!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.394303 Test loss=0.419069 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.3724645674228668
[5/24] Train loss=0.3561614453792572
[10/24] Train loss=0.4020397961139679
[15/24] Train loss=0.38963866233825684
[20/24] Train loss=0.37117478251457214
Test set avg_accuracy=81.24% avg_sensitivity=43.74%, avg_specificity=94.63% avg_auc=84.42%
Best model saved!! Metric=84.41529167281276!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.384011 Test loss=0.413892 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.3603331446647644
[5/24] Train loss=0.3460921347141266
[10/24] Train loss=0.38994100689888
[15/24] Train loss=0.37179407477378845
[20/24] Train loss=0.3713153898715973
Test set avg_accuracy=81.51% avg_sensitivity=47.11%, avg_specificity=93.80% avg_auc=84.97%
Best model saved!! Metric=84.96872256398818!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.374618 Test loss=0.407953 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.3542787432670593
[5/24] Train loss=0.33716803789138794
[10/24] Train loss=0.3818698227405548
[15/24] Train loss=0.36345770955085754
[20/24] Train loss=0.3701015114784241
Test set avg_accuracy=82.23% avg_sensitivity=49.43%, avg_specificity=93.94% avg_auc=85.41%
Best model saved!! Metric=85.41142355855494!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.366419 Test loss=0.402830 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.34569621086120605
[5/24] Train loss=0.3310563564300537
[10/24] Train loss=0.3802015483379364
[15/24] Train loss=0.35386091470718384
[20/24] Train loss=0.35560980439186096
Test set avg_accuracy=82.64% avg_sensitivity=47.50%, avg_specificity=95.19% avg_auc=85.57%
Best model saved!! Metric=85.57042728327295!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.359769 Test loss=0.400327 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.3393792510032654
[5/24] Train loss=0.33149123191833496
[10/24] Train loss=0.3712470531463623
[15/24] Train loss=0.34817689657211304
[20/24] Train loss=0.34870222210884094
Test set avg_accuracy=82.33% avg_sensitivity=45.03%, avg_specificity=95.65% avg_auc=85.87%
Best model saved!! Metric=85.87092115225194!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.353671 Test loss=0.398255 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.33192673325538635
[5/24] Train loss=0.32397037744522095
[10/24] Train loss=0.3639746606349945
[15/24] Train loss=0.34367913007736206
[20/24] Train loss=0.34002354741096497
Test set avg_accuracy=82.43% avg_sensitivity=44.73%, avg_specificity=95.90% avg_auc=86.16%
Best model saved!! Metric=86.15746886005826!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.348269 Test loss=0.396162 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.323999285697937
[5/24] Train loss=0.31855934858322144
[10/24] Train loss=0.35899755358695984
[15/24] Train loss=0.3349987268447876
[20/24] Train loss=0.33390504121780396
Test set avg_accuracy=82.63% avg_sensitivity=43.69%, avg_specificity=96.54% avg_auc=86.62%
Best model saved!! Metric=86.62261049578473!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.341565 Test loss=0.393170 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.3226238489151001
[5/24] Train loss=0.3078726530075073
[10/24] Train loss=0.3511500358581543
[15/24] Train loss=0.3289320170879364
[20/24] Train loss=0.3312236964702606
Test set avg_accuracy=83.27% avg_sensitivity=46.41%, avg_specificity=96.43% avg_auc=86.96%
Best model saved!! Metric=86.96453626740745!!
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.336207 Test loss=0.387912 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.311899870634079
[5/24] Train loss=0.30197182297706604
[10/24] Train loss=0.3463103771209717
[15/24] Train loss=0.3226746916770935
[20/24] Train loss=0.32607564330101013
Test set avg_accuracy=83.26% avg_sensitivity=45.57%, avg_specificity=96.71% avg_auc=87.19%
Best model saved!! Metric=87.19261502238513!!
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.330272 Test loss=0.385373 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.30946841835975647
[5/24] Train loss=0.29628226161003113
[10/24] Train loss=0.3424778878688812
[15/24] Train loss=0.3131764233112335
[20/24] Train loss=0.32115498185157776
Test set avg_accuracy=83.14% avg_sensitivity=44.14%, avg_specificity=97.07% avg_auc=87.30%
Best model saved!! Metric=87.30065623901848!!
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.325936 Test loss=0.388295 Current lr=[0.000669125424222739]

[0/24] Train loss=0.31230512261390686
[5/24] Train loss=0.29733872413635254
[10/24] Train loss=0.3338826298713684
[15/24] Train loss=0.31272509694099426
[20/24] Train loss=0.3203456401824951
Test set avg_accuracy=83.18% avg_sensitivity=44.38%, avg_specificity=97.03% avg_auc=87.58%
Best model saved!! Metric=87.57729299153377!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.321601 Test loss=0.383878 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.3025195896625519
[5/24] Train loss=0.2894606292247772
[10/24] Train loss=0.33373990654945374
[15/24] Train loss=0.30667707324028015
[20/24] Train loss=0.3096522390842438
Test set avg_accuracy=83.79% avg_sensitivity=46.81%, avg_specificity=97.00% avg_auc=87.71%
Best model saved!! Metric=87.71048538848889!!
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.316704 Test loss=0.378543 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.30321890115737915
[5/24] Train loss=0.28498098254203796
[10/24] Train loss=0.33100762963294983
[15/24] Train loss=0.3023926019668579
[20/24] Train loss=0.3035561740398407
Test set avg_accuracy=83.55% avg_sensitivity=45.13%, avg_specificity=97.28% avg_auc=87.72%
Best model saved!! Metric=87.71669339753755!!
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.313528 Test loss=0.382408 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.3029877543449402
[5/24] Train loss=0.28398558497428894
[10/24] Train loss=0.32587695121765137
[15/24] Train loss=0.2970122694969177
[20/24] Train loss=0.29937806725502014
Test set avg_accuracy=83.15% avg_sensitivity=43.39%, avg_specificity=97.35% avg_auc=87.62%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.311646 Test loss=0.390604 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.3078891336917877
[5/24] Train loss=0.28268682956695557
[10/24] Train loss=0.3235264718532562
[15/24] Train loss=0.29329046607017517
[20/24] Train loss=0.3056891858577728
Test set avg_accuracy=83.91% avg_sensitivity=46.26%, avg_specificity=97.35% avg_auc=87.63%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.311164 Test loss=0.385334 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.3041515052318573
[5/24] Train loss=0.28305965662002563
[10/24] Train loss=0.32009264826774597
[15/24] Train loss=0.29880592226982117
[20/24] Train loss=0.30246931314468384
Test set avg_accuracy=84.58% avg_sensitivity=50.92%, avg_specificity=96.61% avg_auc=87.71%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.309179 Test loss=0.377346 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.2921077609062195
[5/24] Train loss=0.28032663464546204
[10/24] Train loss=0.32158488035202026
[15/24] Train loss=0.2990235388278961
[20/24] Train loss=0.30155158042907715
Test set avg_accuracy=83.91% avg_sensitivity=48.44%, avg_specificity=96.57% avg_auc=87.74%
Best model saved!! Metric=87.7420762852393!!
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.308694 Test loss=0.381572 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.29401519894599915
[5/24] Train loss=0.28054437041282654
[10/24] Train loss=0.32210466265678406
[15/24] Train loss=0.29752466082572937
[20/24] Train loss=0.2966943681240082
Test set avg_accuracy=83.70% avg_sensitivity=48.24%, avg_specificity=96.36% avg_auc=87.85%
Best model saved!! Metric=87.84783103093436!!
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.306825 Test loss=0.379202 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.294487327337265
[5/24] Train loss=0.282438188791275
[10/24] Train loss=0.31991833448410034
[15/24] Train loss=0.29498594999313354
[20/24] Train loss=0.29606279730796814
Test set avg_accuracy=83.54% avg_sensitivity=47.55%, avg_specificity=96.40% avg_auc=87.78%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.307583 Test loss=0.383175 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.296223908662796
[5/24] Train loss=0.27682217955589294
[10/24] Train loss=0.320529580116272
[15/24] Train loss=0.29127559065818787
[20/24] Train loss=0.2900626063346863
Test set avg_accuracy=83.83% avg_sensitivity=48.84%, avg_specificity=96.32% avg_auc=87.82%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.306040 Test loss=0.379387 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.2949451506137848
[5/24] Train loss=0.2843095362186432
[10/24] Train loss=0.32072463631629944
[15/24] Train loss=0.2932925820350647
[20/24] Train loss=0.29285305738449097
Test set avg_accuracy=83.63% avg_sensitivity=47.80%, avg_specificity=96.43% avg_auc=87.78%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.306129 Test loss=0.383985 Current lr=[0.000944367614404117]

[0/24] Train loss=0.29442518949508667
[5/24] Train loss=0.2824527621269226
[10/24] Train loss=0.322853684425354
[15/24] Train loss=0.29050830006599426
[20/24] Train loss=0.2951492667198181
Test set avg_accuracy=84.02% avg_sensitivity=48.64%, avg_specificity=96.66% avg_auc=87.76%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.306574 Test loss=0.382243 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.29751870036125183
[5/24] Train loss=0.28108248114585876
[10/24] Train loss=0.31988561153411865
[15/24] Train loss=0.2881314754486084
[20/24] Train loss=0.29211634397506714
Test set avg_accuracy=83.40% avg_sensitivity=45.13%, avg_specificity=97.07% avg_auc=87.59%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.306582 Test loss=0.389044 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.30323031544685364
[5/24] Train loss=0.2790757715702057
[10/24] Train loss=0.3225967586040497
[15/24] Train loss=0.28941473364830017
[20/24] Train loss=0.29635459184646606
Test set avg_accuracy=83.75% avg_sensitivity=46.41%, avg_specificity=97.08% avg_auc=87.63%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.307747 Test loss=0.387112 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.298021525144577
[5/24] Train loss=0.2780979573726654
[10/24] Train loss=0.32368242740631104
[15/24] Train loss=0.29233965277671814
[20/24] Train loss=0.2985541522502899
Test set avg_accuracy=84.13% avg_sensitivity=48.14%, avg_specificity=96.98% avg_auc=87.73%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.306911 Test loss=0.381615 Current lr=[0.000989780311725182]

[0/24] Train loss=0.2957035005092621
[5/24] Train loss=0.2817689776420593
[10/24] Train loss=0.324296236038208
[15/24] Train loss=0.29237455129623413
[20/24] Train loss=0.3035639524459839
Test set avg_accuracy=84.47% avg_sensitivity=51.61%, avg_specificity=96.20% avg_auc=87.83%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.307248 Test loss=0.376164 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.2900950014591217
[5/24] Train loss=0.282554566860199
[10/24] Train loss=0.32231128215789795
[15/24] Train loss=0.29338398575782776
[20/24] Train loss=0.2981899380683899
Test set avg_accuracy=84.24% avg_sensitivity=50.62%, avg_specificity=96.25% avg_auc=87.86%
Best model saved!! Metric=87.86462763006455!!
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.306697 Test loss=0.378568 Current lr=[0.000998924125869967]

[0/24] Train loss=0.2951163053512573
[5/24] Train loss=0.2778671085834503
[10/24] Train loss=0.3235684335231781
[15/24] Train loss=0.2923637926578522
[20/24] Train loss=0.3000810742378235
Test set avg_accuracy=84.41% avg_sensitivity=50.77%, avg_specificity=96.43% avg_auc=87.86%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.305663 Test loss=0.377564 Current lr=[0.000999999611458977]

[0/24] Train loss=0.29420173168182373
[5/24] Train loss=0.2801940441131592
[10/24] Train loss=0.3215981423854828
[15/24] Train loss=0.29345056414604187
[20/24] Train loss=0.2995195686817169
Test set avg_accuracy=84.53% avg_sensitivity=51.26%, avg_specificity=96.41% avg_auc=87.86%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.305505 Test loss=0.376782 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.2889131009578705
[5/24] Train loss=0.2803800404071808
[10/24] Train loss=0.3242644667625427
[15/24] Train loss=0.2894161641597748
[20/24] Train loss=0.3001996874809265
Test set avg_accuracy=84.74% avg_sensitivity=52.20%, avg_specificity=96.36% avg_auc=87.84%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.305650 Test loss=0.376588 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.2976788282394409
[5/24] Train loss=0.2800915837287903
[10/24] Train loss=0.3192225992679596
[15/24] Train loss=0.29030224680900574
[20/24] Train loss=0.29818809032440186
Test set avg_accuracy=84.60% avg_sensitivity=51.41%, avg_specificity=96.45% avg_auc=87.85%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.305468 Test loss=0.377188 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.2980184257030487
[5/24] Train loss=0.2824949622154236
[10/24] Train loss=0.3193950355052948
[15/24] Train loss=0.290583997964859
[20/24] Train loss=0.29611045122146606
Test set avg_accuracy=84.45% avg_sensitivity=51.46%, avg_specificity=96.24% avg_auc=87.87%
Best model saved!! Metric=87.86651189196594!!
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.305662 Test loss=0.376472 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.2985072731971741
[5/24] Train loss=0.27941712737083435
[10/24] Train loss=0.3221197724342346
[15/24] Train loss=0.28995299339294434
[20/24] Train loss=0.29793766140937805
Test set avg_accuracy=84.32% avg_sensitivity=50.57%, avg_specificity=96.38% avg_auc=87.96%
Best model saved!! Metric=87.9602659441127!!
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.306198 Test loss=0.376816 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.3002958595752716
[5/24] Train loss=0.27786749601364136
[10/24] Train loss=0.3236485421657562
[15/24] Train loss=0.287607878446579
[20/24] Train loss=0.29861217737197876
Test set avg_accuracy=84.26% avg_sensitivity=50.47%, avg_specificity=96.32% avg_auc=87.95%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.306630 Test loss=0.378163 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.2984378933906555
[5/24] Train loss=0.2806422710418701
[10/24] Train loss=0.32451173663139343
[15/24] Train loss=0.29126065969467163
[20/24] Train loss=0.3010672926902771
Test set avg_accuracy=84.21% avg_sensitivity=48.89%, avg_specificity=96.82% avg_auc=87.89%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.306874 Test loss=0.381022 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.3008289635181427
[5/24] Train loss=0.2818843722343445
[10/24] Train loss=0.3235014081001282
[15/24] Train loss=0.2925940454006195
[20/24] Train loss=0.3054243326187134
Test set avg_accuracy=84.60% avg_sensitivity=53.74%, avg_specificity=95.62% avg_auc=87.92%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.307705 Test loss=0.373528 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.2941783368587494
[5/24] Train loss=0.2830689549446106
[10/24] Train loss=0.32319769263267517
[15/24] Train loss=0.29577726125717163
[20/24] Train loss=0.30271515250205994
Test set avg_accuracy=84.56% avg_sensitivity=54.43%, avg_specificity=95.32% avg_auc=87.99%
Best model saved!! Metric=87.98914630170103!!
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.307127 Test loss=0.371643 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.29393646121025085
[5/24] Train loss=0.28134986758232117
[10/24] Train loss=0.32609686255455017
[15/24] Train loss=0.29730069637298584
[20/24] Train loss=0.3023527264595032
Test set avg_accuracy=84.43% avg_sensitivity=52.65%, avg_specificity=95.78% avg_auc=87.93%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.306665 Test loss=0.375767 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.29734256863594055
[5/24] Train loss=0.28447362780570984
[10/24] Train loss=0.3252818286418915
[15/24] Train loss=0.2935822904109955
[20/24] Train loss=0.3011561930179596
Test set avg_accuracy=84.49% avg_sensitivity=52.99%, avg_specificity=95.74% avg_auc=87.89%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.307492 Test loss=0.375566 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.3023316264152527
[5/24] Train loss=0.28059762716293335
[10/24] Train loss=0.3285621106624603
[15/24] Train loss=0.2965751886367798
[20/24] Train loss=0.3060324490070343
Test set avg_accuracy=84.39% avg_sensitivity=52.60%, avg_specificity=95.74% avg_auc=88.06%
Best model saved!! Metric=88.06437687896106!!
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.308126 Test loss=0.373268 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.297768771648407
[5/24] Train loss=0.28379642963409424
[10/24] Train loss=0.3291890025138855
[15/24] Train loss=0.2952705919742584
[20/24] Train loss=0.3040689527988434
Test set avg_accuracy=84.43% avg_sensitivity=52.60%, avg_specificity=95.79% avg_auc=88.12%
Best model saved!! Metric=88.12243487907804!!
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.308397 Test loss=0.372809 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.29491937160491943
[5/24] Train loss=0.2789252698421478
[10/24] Train loss=0.3295688033103943
[15/24] Train loss=0.29445499181747437
[20/24] Train loss=0.30416807532310486
Test set avg_accuracy=84.39% avg_sensitivity=52.89%, avg_specificity=95.64% avg_auc=88.12%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.308122 Test loss=0.372795 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.29511797428131104
[5/24] Train loss=0.2842428386211395
[10/24] Train loss=0.32561415433883667
[15/24] Train loss=0.29856497049331665
[20/24] Train loss=0.301324725151062
Test set avg_accuracy=84.88% avg_sensitivity=56.51%, avg_specificity=95.02% avg_auc=88.18%
Best model saved!! Metric=88.18161206955872!!
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.307656 Test loss=0.368749 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.29391899704933167
[5/24] Train loss=0.28059250116348267
[10/24] Train loss=0.3302464783191681
[15/24] Train loss=0.29607880115509033
[20/24] Train loss=0.3030269145965576
Test set avg_accuracy=84.58% avg_sensitivity=55.37%, avg_specificity=95.02% avg_auc=88.38%
Best model saved!! Metric=88.38189468261291!!
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.308469 Test loss=0.367872 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.2942206859588623
[5/24] Train loss=0.28010138869285583
[10/24] Train loss=0.3314104974269867
[15/24] Train loss=0.29846692085266113
[20/24] Train loss=0.29952484369277954
Test set avg_accuracy=84.83% avg_sensitivity=55.71%, avg_specificity=95.23% avg_auc=88.32%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.307906 Test loss=0.367619 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.29164987802505493
[5/24] Train loss=0.280905157327652
[10/24] Train loss=0.3272112309932709
[15/24] Train loss=0.29750558733940125
[20/24] Train loss=0.29884642362594604
Test set avg_accuracy=84.40% avg_sensitivity=53.24%, avg_specificity=95.53% avg_auc=88.40%
Best model saved!! Metric=88.40099086819356!!
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.307575 Test loss=0.369639 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.29721200466156006
[5/24] Train loss=0.2774454355239868
[10/24] Train loss=0.3287959694862366
[15/24] Train loss=0.2960938811302185
[20/24] Train loss=0.29848504066467285
Test set avg_accuracy=84.41% avg_sensitivity=53.98%, avg_specificity=95.28% avg_auc=88.46%
Best model saved!! Metric=88.45745751951218!!
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.307430 Test loss=0.368132 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.29316800832748413
[5/24] Train loss=0.27732589840888977
[10/24] Train loss=0.33274587988853455
[15/24] Train loss=0.2954851984977722
[20/24] Train loss=0.30217164754867554
Test set avg_accuracy=84.22% avg_sensitivity=55.76%, avg_specificity=94.38% avg_auc=88.55%
Best model saved!! Metric=88.54848791698477!!
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.306698 Test loss=0.365223 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.29171550273895264
[5/24] Train loss=0.27324244379997253
[10/24] Train loss=0.3311169743537903
[15/24] Train loss=0.29507097601890564
[20/24] Train loss=0.2984176576137543
Test set avg_accuracy=84.51% avg_sensitivity=54.28%, avg_specificity=95.30% avg_auc=88.54%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.306213 Test loss=0.368483 Current lr=[0.000904142181093812]

[0/24] Train loss=0.29697737097740173
[5/24] Train loss=0.27241501212120056
[10/24] Train loss=0.3330494165420532
[15/24] Train loss=0.29159966111183167
[20/24] Train loss=0.29489752650260925
Test set avg_accuracy=84.60% avg_sensitivity=55.57%, avg_specificity=94.96% avg_auc=88.69%
Best model saved!! Metric=88.69242629016637!!
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.305148 Test loss=0.364455 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.2933848798274994
[5/24] Train loss=0.2716751992702484
[10/24] Train loss=0.324325829744339
[15/24] Train loss=0.292711079120636
[20/24] Train loss=0.30380499362945557
Test set avg_accuracy=84.53% avg_sensitivity=54.58%, avg_specificity=95.23% avg_auc=88.57%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.305715 Test loss=0.366476 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.2943304777145386
[5/24] Train loss=0.2690599858760834
[10/24] Train loss=0.32882577180862427
[15/24] Train loss=0.2901673913002014
[20/24] Train loss=0.2974565029144287
Test set avg_accuracy=84.31% avg_sensitivity=56.06%, avg_specificity=94.40% avg_auc=88.56%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.305676 Test loss=0.365396 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.29283300042152405
[5/24] Train loss=0.2752206325531006
[10/24] Train loss=0.3298226296901703
[15/24] Train loss=0.29465505480766296
[20/24] Train loss=0.2953966557979584
Test set avg_accuracy=84.14% avg_sensitivity=53.24%, avg_specificity=95.18% avg_auc=88.33%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.306449 Test loss=0.371558 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.2923964262008667
[5/24] Train loss=0.27549782395362854
[10/24] Train loss=0.3265071213245392
[15/24] Train loss=0.29516318440437317
[20/24] Train loss=0.30174270272254944
Test set avg_accuracy=84.45% avg_sensitivity=54.82%, avg_specificity=95.03% avg_auc=88.35%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.305903 Test loss=0.370306 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.2869967520236969
[5/24] Train loss=0.2714478373527527
[10/24] Train loss=0.33402907848358154
[15/24] Train loss=0.2913866341114044
[20/24] Train loss=0.30209457874298096
Test set avg_accuracy=84.67% avg_sensitivity=59.67%, avg_specificity=93.60% avg_auc=88.57%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.306223 Test loss=0.364601 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.283047616481781
[5/24] Train loss=0.27347978949546814
[10/24] Train loss=0.3329961597919464
[15/24] Train loss=0.3052038252353668
[20/24] Train loss=0.29794713854789734
Test set avg_accuracy=84.92% avg_sensitivity=62.15%, avg_specificity=93.06% avg_auc=88.81%
Best model saved!! Metric=88.81158508920166!!
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.305475 Test loss=0.360728 Current lr=[0.000834102481048427]

[0/24] Train loss=0.28504154086112976
[5/24] Train loss=0.2680225968360901
[10/24] Train loss=0.33065900206565857
[15/24] Train loss=0.2986697852611542
[20/24] Train loss=0.29716622829437256
Test set avg_accuracy=84.73% avg_sensitivity=60.17%, avg_specificity=93.50% avg_auc=88.66%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.304234 Test loss=0.362997 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.2858005166053772
[5/24] Train loss=0.2677595019340515
[10/24] Train loss=0.3310869336128235
[15/24] Train loss=0.29843074083328247
[20/24] Train loss=0.28104695677757263
Test set avg_accuracy=84.84% avg_sensitivity=59.82%, avg_specificity=93.78% avg_auc=88.61%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.302982 Test loss=0.365496 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.28440842032432556
[5/24] Train loss=0.2666710615158081
[10/24] Train loss=0.33235710859298706
[15/24] Train loss=0.3015731871128082
[20/24] Train loss=0.2880830466747284
Test set avg_accuracy=84.92% avg_sensitivity=57.89%, avg_specificity=94.58% avg_auc=88.56%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.303142 Test loss=0.367952 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.2822812497615814
[5/24] Train loss=0.26841798424720764
[10/24] Train loss=0.3322466313838959
[15/24] Train loss=0.2963531017303467
[20/24] Train loss=0.2872101664543152
Test set avg_accuracy=84.74% avg_sensitivity=57.60%, avg_specificity=94.43% avg_auc=88.39%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.300760 Test loss=0.370305 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.2866709232330322
[5/24] Train loss=0.2673618197441101
[10/24] Train loss=0.3313255310058594
[15/24] Train loss=0.29400375485420227
[20/24] Train loss=0.28982365131378174
Test set avg_accuracy=84.17% avg_sensitivity=55.17%, avg_specificity=94.52% avg_auc=88.33%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.301461 Test loss=0.372490 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.28618648648262024
[5/24] Train loss=0.2647840976715088
[10/24] Train loss=0.32132136821746826
[15/24] Train loss=0.2940036356449127
[20/24] Train loss=0.29222241044044495
Test set avg_accuracy=84.84% avg_sensitivity=59.57%, avg_specificity=93.87% avg_auc=88.46%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.299851 Test loss=0.366801 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.2838287353515625
[5/24] Train loss=0.26094546914100647
[10/24] Train loss=0.3299682140350342
[15/24] Train loss=0.29296836256980896
[20/24] Train loss=0.29446324706077576
Test set avg_accuracy=84.58% avg_sensitivity=60.37%, avg_specificity=93.23% avg_auc=88.62%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.299991 Test loss=0.364658 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.28436821699142456
[5/24] Train loss=0.26567116379737854
[10/24] Train loss=0.3253411650657654
[15/24] Train loss=0.2956896424293518
[20/24] Train loss=0.2945556938648224
Test set avg_accuracy=84.32% avg_sensitivity=61.50%, avg_specificity=92.47% avg_auc=88.46%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.299226 Test loss=0.366657 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.284894734621048
[5/24] Train loss=0.2629334330558777
[10/24] Train loss=0.31850895285606384
[15/24] Train loss=0.29903870820999146
[20/24] Train loss=0.2961302697658539
Test set avg_accuracy=84.21% avg_sensitivity=63.48%, avg_specificity=91.61% avg_auc=88.58%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.299307 Test loss=0.366458 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.28173041343688965
[5/24] Train loss=0.2561083734035492
[10/24] Train loss=0.31765902042388916
[15/24] Train loss=0.30394574999809265
[20/24] Train loss=0.28183713555336
Test set avg_accuracy=84.45% avg_sensitivity=61.06%, avg_specificity=92.81% avg_auc=88.39%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.298578 Test loss=0.368340 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.2858930230140686
[5/24] Train loss=0.26579904556274414
[10/24] Train loss=0.3145531415939331
[15/24] Train loss=0.2979252338409424
[20/24] Train loss=0.28450319170951843
Test set avg_accuracy=84.53% avg_sensitivity=60.91%, avg_specificity=92.97% avg_auc=88.43%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.298281 Test loss=0.368186 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.28578028082847595
[5/24] Train loss=0.26337599754333496
[10/24] Train loss=0.31610286235809326
[15/24] Train loss=0.28936344385147095
[20/24] Train loss=0.2820224165916443
Test set avg_accuracy=84.48% avg_sensitivity=60.91%, avg_specificity=92.90% avg_auc=88.28%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.295060 Test loss=0.370875 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.2865217626094818
[5/24] Train loss=0.25973397493362427
[10/24] Train loss=0.32323208451271057
[15/24] Train loss=0.286456823348999
[20/24] Train loss=0.28338268399238586
Test set avg_accuracy=84.04% avg_sensitivity=56.70%, avg_specificity=93.80% avg_auc=88.41%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.295444 Test loss=0.369785 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.2892009913921356
[5/24] Train loss=0.26250287890434265
[10/24] Train loss=0.3190639913082123
[15/24] Train loss=0.29078343510627747
[20/24] Train loss=0.29401853680610657
Test set avg_accuracy=84.84% avg_sensitivity=62.49%, avg_specificity=92.83% avg_auc=88.47%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.296308 Test loss=0.367428 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.2791716158390045
[5/24] Train loss=0.25978389382362366
[10/24] Train loss=0.3205440044403076
[15/24] Train loss=0.28791865706443787
[20/24] Train loss=0.2820277214050293
Test set avg_accuracy=84.61% avg_sensitivity=62.05%, avg_specificity=92.67% avg_auc=88.33%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.292903 Test loss=0.369388 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.2776409685611725
[5/24] Train loss=0.25839346647262573
[10/24] Train loss=0.32005539536476135
[15/24] Train loss=0.2837598919868469
[20/24] Train loss=0.2825703024864197
Test set avg_accuracy=84.51% avg_sensitivity=61.55%, avg_specificity=92.70% avg_auc=88.41%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.291755 Test loss=0.369967 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.281561940908432
[5/24] Train loss=0.2617207169532776
[10/24] Train loss=0.31003496050834656
[15/24] Train loss=0.282915323972702
[20/24] Train loss=0.28129270672798157
Test set avg_accuracy=84.23% avg_sensitivity=58.19%, avg_specificity=93.53% avg_auc=88.20%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.291241 Test loss=0.372126 Current lr=[0.00061065423442182]

[0/24] Train loss=0.284964919090271
[5/24] Train loss=0.25888553261756897
[10/24] Train loss=0.3137153089046478
[15/24] Train loss=0.2847963869571686
[20/24] Train loss=0.2871965765953064
Test set avg_accuracy=84.73% avg_sensitivity=60.42%, avg_specificity=93.41% avg_auc=88.30%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.290275 Test loss=0.370344 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.279342383146286
[5/24] Train loss=0.2569125294685364
[10/24] Train loss=0.3154682219028473
[15/24] Train loss=0.2851361334323883
[20/24] Train loss=0.2880299389362335
Test set avg_accuracy=84.61% avg_sensitivity=62.84%, avg_specificity=92.38% avg_auc=88.26%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.289875 Test loss=0.371460 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.27778953313827515
[5/24] Train loss=0.26381915807724
[10/24] Train loss=0.30869898200035095
[15/24] Train loss=0.2811090350151062
[20/24] Train loss=0.28143244981765747
Test set avg_accuracy=84.54% avg_sensitivity=59.92%, avg_specificity=93.34% avg_auc=88.14%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.288035 Test loss=0.372845 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.27690061926841736
[5/24] Train loss=0.2537219226360321
[10/24] Train loss=0.30989769101142883
[15/24] Train loss=0.2842843532562256
[20/24] Train loss=0.2845001220703125
Test set avg_accuracy=83.83% avg_sensitivity=57.60%, avg_specificity=93.20% avg_auc=88.08%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.287286 Test loss=0.374315 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.27212321758270264
[5/24] Train loss=0.2605759799480438
[10/24] Train loss=0.30263790488243103
[15/24] Train loss=0.2852325439453125
[20/24] Train loss=0.28262728452682495
Test set avg_accuracy=84.57% avg_sensitivity=60.32%, avg_specificity=93.23% avg_auc=88.09%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.286619 Test loss=0.375061 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.2748493254184723
[5/24] Train loss=0.2540254294872284
[10/24] Train loss=0.30880382657051086
[15/24] Train loss=0.2854726016521454
[20/24] Train loss=0.28877803683280945
Test set avg_accuracy=84.14% avg_sensitivity=58.83%, avg_specificity=93.18% avg_auc=88.17%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.286961 Test loss=0.374148 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.27716052532196045
[5/24] Train loss=0.261344313621521
[10/24] Train loss=0.3068508207798004
[15/24] Train loss=0.28952106833457947
[20/24] Train loss=0.2842651605606079
Test set avg_accuracy=84.17% avg_sensitivity=61.70%, avg_specificity=92.19% avg_auc=88.22%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.287334 Test loss=0.372511 Current lr=[0.000506858408304961]

[0/24] Train loss=0.2769111096858978
[5/24] Train loss=0.2608417868614197
[10/24] Train loss=0.3103218972682953
[15/24] Train loss=0.2875808775424957
[20/24] Train loss=0.2805120050907135
Test set avg_accuracy=83.79% avg_sensitivity=54.73%, avg_specificity=94.17% avg_auc=87.90%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.287499 Test loss=0.380310 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.2748596966266632
[5/24] Train loss=0.2604290544986725
[10/24] Train loss=0.31264084577560425
[15/24] Train loss=0.2857144773006439
[20/24] Train loss=0.27759596705436707
Test set avg_accuracy=83.89% avg_sensitivity=55.02%, avg_specificity=94.20% avg_auc=88.08%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.287255 Test loss=0.378333 Current lr=[0.000476946990416354]

[0/24] Train loss=0.2823276221752167
[5/24] Train loss=0.2586047053337097
[10/24] Train loss=0.30481866002082825
[15/24] Train loss=0.28091490268707275
[20/24] Train loss=0.27484190464019775
Test set avg_accuracy=84.02% avg_sensitivity=56.41%, avg_specificity=93.89% avg_auc=88.22%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.287381 Test loss=0.377670 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.26925432682037354
[5/24] Train loss=0.2655380368232727
[10/24] Train loss=0.3034161329269409
[15/24] Train loss=0.2788616418838501
[20/24] Train loss=0.28558534383773804
Test set avg_accuracy=83.74% avg_sensitivity=61.45%, avg_specificity=91.69% avg_auc=88.43%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.291201 Test loss=0.372866 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.26648035645484924
[5/24] Train loss=0.26376888155937195
[10/24] Train loss=0.30160772800445557
[15/24] Train loss=0.27774202823638916
[20/24] Train loss=0.2963082194328308
Test set avg_accuracy=83.95% avg_sensitivity=66.85%, avg_specificity=90.05% avg_auc=88.59%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.289497 Test loss=0.373898 Current lr=[0.000432267999769856]

[0/24] Train loss=0.2697403132915497
[5/24] Train loss=0.25870808959007263
[10/24] Train loss=0.30143415927886963
[15/24] Train loss=0.2720976769924164
[20/24] Train loss=0.2899254560470581
Test set avg_accuracy=83.74% avg_sensitivity=62.00%, avg_specificity=91.50% avg_auc=88.65%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.287154 Test loss=0.372268 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.26935145258903503
[5/24] Train loss=0.2484164983034134
[10/24] Train loss=0.30027028918266296
[15/24] Train loss=0.2710080146789551
[20/24] Train loss=0.2826709449291229
Test set avg_accuracy=83.95% avg_sensitivity=61.65%, avg_specificity=91.91% avg_auc=88.67%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.284015 Test loss=0.374332 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.26914623379707336
[5/24] Train loss=0.2473861277103424
[10/24] Train loss=0.2931942045688629
[15/24] Train loss=0.27230557799339294
[20/24] Train loss=0.2794063091278076
Test set avg_accuracy=83.54% avg_sensitivity=60.37%, avg_specificity=91.82% avg_auc=88.44%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.283209 Test loss=0.379638 Current lr=[0.000388134363466264]

[0/24] Train loss=0.2609252631664276
[5/24] Train loss=0.25149136781692505
[10/24] Train loss=0.29743334650993347
[15/24] Train loss=0.2681428790092468
[20/24] Train loss=0.28348588943481445
Test set avg_accuracy=83.40% avg_sensitivity=60.81%, avg_specificity=91.46% avg_auc=88.44%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.283588 Test loss=0.380805 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.26814475655555725
[5/24] Train loss=0.2519693374633789
[10/24] Train loss=0.29808974266052246
[15/24] Train loss=0.27070221304893494
[20/24] Train loss=0.2766042947769165
Test set avg_accuracy=83.48% avg_sensitivity=59.28%, avg_specificity=92.12% avg_auc=88.39%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.284118 Test loss=0.381228 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.2700854539871216
[5/24] Train loss=0.24674823880195618
[10/24] Train loss=0.2994735836982727
[15/24] Train loss=0.2749449610710144
[20/24] Train loss=0.27173036336898804
Test set avg_accuracy=83.58% avg_sensitivity=60.07%, avg_specificity=91.98% avg_auc=88.38%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.282496 Test loss=0.379872 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.27448713779449463
[5/24] Train loss=0.25058409571647644
[10/24] Train loss=0.3032156229019165
[15/24] Train loss=0.2767789661884308
[20/24] Train loss=0.26641401648521423
Test set avg_accuracy=83.80% avg_sensitivity=59.43%, avg_specificity=92.51% avg_auc=88.34%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.283034 Test loss=0.380040 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.2752527892589569
[5/24] Train loss=0.2507997751235962
[10/24] Train loss=0.3019633889198303
[15/24] Train loss=0.2730925977230072
[20/24] Train loss=0.26738402247428894
Test set avg_accuracy=83.95% avg_sensitivity=57.94%, avg_specificity=93.23% avg_auc=88.36%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.282882 Test loss=0.379382 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.27589932084083557
[5/24] Train loss=0.24728013575077057
[10/24] Train loss=0.3035355806350708
[15/24] Train loss=0.2836158871650696
[20/24] Train loss=0.26708170771598816
Test set avg_accuracy=84.01% avg_sensitivity=59.23%, avg_specificity=92.86% avg_auc=88.43%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.284459 Test loss=0.376409 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.26675769686698914
[5/24] Train loss=0.250887930393219
[10/24] Train loss=0.30978959798812866
[15/24] Train loss=0.28898781538009644
[20/24] Train loss=0.2658635377883911
Test set avg_accuracy=84.41% avg_sensitivity=68.78%, avg_specificity=90.00% avg_auc=88.69%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.289007 Test loss=0.372600 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2633577287197113
[5/24] Train loss=0.26679524779319763
[10/24] Train loss=0.3178195655345917
[15/24] Train loss=0.2733723521232605
[20/24] Train loss=0.2761443555355072
Test set avg_accuracy=84.08% avg_sensitivity=73.92%, avg_specificity=87.70% avg_auc=88.88%
Best model saved!! Metric=88.87558878812581!!
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.287838 Test loss=0.380813 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.2728598415851593
[5/24] Train loss=0.25891005992889404
[10/24] Train loss=0.2979235351085663
[15/24] Train loss=0.2675866484642029
[20/24] Train loss=0.28266534209251404
Test set avg_accuracy=84.58% avg_sensitivity=66.25%, avg_specificity=91.13% avg_auc=88.76%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.283013 Test loss=0.369595 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.2637541890144348
[5/24] Train loss=0.24577754735946655
[10/24] Train loss=0.2952263653278351
[15/24] Train loss=0.27224549651145935
[20/24] Train loss=0.27084219455718994
Test set avg_accuracy=84.30% avg_sensitivity=65.26%, avg_specificity=91.09% avg_auc=88.62%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.277578 Test loss=0.372796 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.26554468274116516
[5/24] Train loss=0.2485913187265396
[10/24] Train loss=0.2983788847923279
[15/24] Train loss=0.26654595136642456
[20/24] Train loss=0.2690674662590027
Test set avg_accuracy=84.17% avg_sensitivity=67.10%, avg_specificity=90.26% avg_auc=88.52%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.276387 Test loss=0.377004 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.2654217481613159
[5/24] Train loss=0.24866582453250885
[10/24] Train loss=0.2987893223762512
[15/24] Train loss=0.25828322768211365
[20/24] Train loss=0.2726409435272217
Test set avg_accuracy=84.15% avg_sensitivity=64.97%, avg_specificity=91.01% avg_auc=88.41%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.275926 Test loss=0.377423 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.26101818680763245
[5/24] Train loss=0.24443362653255463
[10/24] Train loss=0.30300211906433105
[15/24] Train loss=0.2661186754703522
[20/24] Train loss=0.2720806300640106
Test set avg_accuracy=84.27% avg_sensitivity=64.92%, avg_specificity=91.18% avg_auc=88.33%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.275246 Test loss=0.378685 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.259694367647171
[5/24] Train loss=0.24843211472034454
[10/24] Train loss=0.3040555417537689
[15/24] Train loss=0.25857895612716675
[20/24] Train loss=0.26665231585502625
Test set avg_accuracy=84.11% avg_sensitivity=64.42%, avg_specificity=91.15% avg_auc=88.33%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.274304 Test loss=0.379332 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.2628796398639679
[5/24] Train loss=0.24580612778663635
[10/24] Train loss=0.295285165309906
[15/24] Train loss=0.2642935514450073
[20/24] Train loss=0.26942598819732666
Test set avg_accuracy=84.00% avg_sensitivity=62.54%, avg_specificity=91.66% avg_auc=88.30%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.275329 Test loss=0.379845 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.260893851518631
[5/24] Train loss=0.2399672269821167
[10/24] Train loss=0.2984084486961365
[15/24] Train loss=0.26415184140205383
[20/24] Train loss=0.26441454887390137
Test set avg_accuracy=84.21% avg_sensitivity=63.19%, avg_specificity=91.71% avg_auc=88.30%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.272981 Test loss=0.379580 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.261695921421051
[5/24] Train loss=0.2413681149482727
[10/24] Train loss=0.2955027222633362
[15/24] Train loss=0.26132383942604065
[20/24] Train loss=0.26452696323394775
Test set avg_accuracy=84.34% avg_sensitivity=63.93%, avg_specificity=91.62% avg_auc=88.26%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.271993 Test loss=0.381417 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.2617975175380707
[5/24] Train loss=0.2417374551296234
[10/24] Train loss=0.2907107472419739
[15/24] Train loss=0.2618746757507324
[20/24] Train loss=0.26617541909217834
Test set avg_accuracy=84.05% avg_sensitivity=60.86%, avg_specificity=92.33% avg_auc=88.21%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.273100 Test loss=0.381121 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.2609430253505707
[5/24] Train loss=0.240462988615036
[10/24] Train loss=0.29627725481987
[15/24] Train loss=0.25565844774246216
[20/24] Train loss=0.26571837067604065
Test set avg_accuracy=84.28% avg_sensitivity=62.94%, avg_specificity=91.91% avg_auc=88.22%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.272017 Test loss=0.381022 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.2555657923221588
[5/24] Train loss=0.2411486655473709
[10/24] Train loss=0.2899349331855774
[15/24] Train loss=0.261237233877182
[20/24] Train loss=0.2689390182495117
Test set avg_accuracy=84.23% avg_sensitivity=62.15%, avg_specificity=92.12% avg_auc=88.21%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.271824 Test loss=0.381670 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.2600955069065094
[5/24] Train loss=0.23875194787979126
[10/24] Train loss=0.2966916561126709
[15/24] Train loss=0.2609671950340271
[20/24] Train loss=0.26339074969291687
Test set avg_accuracy=84.35% avg_sensitivity=62.05%, avg_specificity=92.31% avg_auc=88.20%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.272019 Test loss=0.381956 Current lr=[0.000123057953306828]

[0/24] Train loss=0.25808367133140564
[5/24] Train loss=0.24181468784809113
[10/24] Train loss=0.29123160243034363
[15/24] Train loss=0.25829705595970154
[20/24] Train loss=0.26292020082473755
Test set avg_accuracy=84.08% avg_sensitivity=60.42%, avg_specificity=92.53% avg_auc=88.14%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.270265 Test loss=0.382815 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.2603985071182251
[5/24] Train loss=0.24097131192684174
[10/24] Train loss=0.293077677488327
[15/24] Train loss=0.2579039931297302
[20/24] Train loss=0.2646063268184662
Test set avg_accuracy=84.05% avg_sensitivity=60.32%, avg_specificity=92.53% avg_auc=88.19%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.271547 Test loss=0.382514 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.2603813409805298
[5/24] Train loss=0.24299396574497223
[10/24] Train loss=0.2939651310443878
[15/24] Train loss=0.25626641511917114
[20/24] Train loss=0.25959521532058716
Test set avg_accuracy=84.01% avg_sensitivity=60.42%, avg_specificity=92.44% avg_auc=88.17%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.271418 Test loss=0.382527 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.26068392395973206
[5/24] Train loss=0.24489599466323853
[10/24] Train loss=0.29788699746131897
[15/24] Train loss=0.25913673639297485
[20/24] Train loss=0.2577698826789856
Test set avg_accuracy=84.24% avg_sensitivity=62.20%, avg_specificity=92.12% avg_auc=88.24%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.272416 Test loss=0.380965 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.2623763084411621
[5/24] Train loss=0.24600662291049957
[10/24] Train loss=0.29107820987701416
[15/24] Train loss=0.2619999945163727
[20/24] Train loss=0.25698360800743103
Test set avg_accuracy=84.26% avg_sensitivity=64.47%, avg_specificity=91.32% avg_auc=88.29%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.274856 Test loss=0.380206 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.25994524359703064
[5/24] Train loss=0.24916504323482513
[10/24] Train loss=0.29789265990257263
[15/24] Train loss=0.2541617155075073
[20/24] Train loss=0.2620972990989685
Test set avg_accuracy=83.80% avg_sensitivity=69.37%, avg_specificity=88.96% avg_auc=88.37%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.276604 Test loss=0.385392 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.2630073130130768
[5/24] Train loss=0.2429094910621643
[10/24] Train loss=0.2934403121471405
[15/24] Train loss=0.26085296273231506
[20/24] Train loss=0.2578791379928589
Test set avg_accuracy=83.66% avg_sensitivity=72.34%, avg_specificity=87.70% avg_auc=88.40%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.275110 Test loss=0.391614 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.2656436264514923
[5/24] Train loss=0.24445194005966187
[10/24] Train loss=0.29763248562812805
[15/24] Train loss=0.2675960063934326
[20/24] Train loss=0.2644144594669342
Test set avg_accuracy=84.15% avg_sensitivity=71.94%, avg_specificity=88.51% avg_auc=88.39%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.274408 Test loss=0.388310 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.26980701088905334
[5/24] Train loss=0.2399744838476181
[10/24] Train loss=0.2903745174407959
[15/24] Train loss=0.2645510733127594
[20/24] Train loss=0.26158347725868225
Test set avg_accuracy=84.17% avg_sensitivity=67.44%, avg_specificity=90.14% avg_auc=88.33%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.272332 Test loss=0.381803 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.2593531906604767
[5/24] Train loss=0.24245145916938782
[10/24] Train loss=0.28897514939308167
[15/24] Train loss=0.25822991132736206
[20/24] Train loss=0.26100513339042664
Test set avg_accuracy=84.24% avg_sensitivity=67.39%, avg_specificity=90.26% avg_auc=88.32%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.269751 Test loss=0.382025 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.25576940178871155
[5/24] Train loss=0.23885302245616913
[10/24] Train loss=0.29296061396598816
[15/24] Train loss=0.2562662363052368
[20/24] Train loss=0.2643011510372162
Test set avg_accuracy=84.10% avg_sensitivity=67.74%, avg_specificity=89.95% avg_auc=88.28%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.269379 Test loss=0.383727 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.26166489720344543
[5/24] Train loss=0.23991693556308746
[10/24] Train loss=0.2857772409915924
[15/24] Train loss=0.26088863611221313
[20/24] Train loss=0.26210924983024597
Test set avg_accuracy=84.35% avg_sensitivity=67.19%, avg_specificity=90.48% avg_auc=88.25%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.269784 Test loss=0.382721 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.26102113723754883
[5/24] Train loss=0.2388433963060379
[10/24] Train loss=0.2908817529678345
[15/24] Train loss=0.2639451026916504
[20/24] Train loss=0.2596941590309143
Test set avg_accuracy=84.24% avg_sensitivity=67.24%, avg_specificity=90.32% avg_auc=88.27%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.269493 Test loss=0.383025 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.2604932188987732
[5/24] Train loss=0.23649868369102478
[10/24] Train loss=0.2886964678764343
[15/24] Train loss=0.2572265565395355
[20/24] Train loss=0.2632702589035034
Test set avg_accuracy=84.31% avg_sensitivity=66.90%, avg_specificity=90.53% avg_auc=88.25%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.268891 Test loss=0.382961 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.2570624053478241
[5/24] Train loss=0.24261927604675293
[10/24] Train loss=0.2917018234729767
[15/24] Train loss=0.2571485936641693
[20/24] Train loss=0.2562418580055237
Test set avg_accuracy=84.27% avg_sensitivity=66.90%, avg_specificity=90.48% avg_auc=88.26%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.269321 Test loss=0.383231 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.25660499930381775
[5/24] Train loss=0.2403283566236496
[10/24] Train loss=0.28865036368370056
[15/24] Train loss=0.2572287321090698
[20/24] Train loss=0.2621603012084961
Test set avg_accuracy=84.30% avg_sensitivity=66.80%, avg_specificity=90.55% avg_auc=88.24%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.268402 Test loss=0.383132 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.2581011652946472
[5/24] Train loss=0.24221745133399963
[10/24] Train loss=0.29679206013679504
[15/24] Train loss=0.2564454972743988
[20/24] Train loss=0.26281219720840454
Test set avg_accuracy=84.36% avg_sensitivity=66.16%, avg_specificity=90.86% avg_auc=88.23%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.269179 Test loss=0.382990 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.2558113932609558
[5/24] Train loss=0.24296417832374573
[10/24] Train loss=0.29463568329811096
[15/24] Train loss=0.25726133584976196
[20/24] Train loss=0.2652140259742737
Test set avg_accuracy=84.36% avg_sensitivity=66.16%, avg_specificity=90.86% avg_auc=88.22%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.268943 Test loss=0.382977 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.2594313621520996
[5/24] Train loss=0.2352312207221985
[10/24] Train loss=0.2944306433200836
[15/24] Train loss=0.2609401345252991
[20/24] Train loss=0.25768211483955383
Test set avg_accuracy=84.36% avg_sensitivity=66.25%, avg_specificity=90.83% avg_auc=88.22%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.268681 Test loss=0.383165 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.2554398477077484
[5/24] Train loss=0.23971612751483917
[10/24] Train loss=0.2920897901058197
[15/24] Train loss=0.259941428899765
[20/24] Train loss=0.2634080946445465
Test set avg_accuracy=84.35% avg_sensitivity=66.25%, avg_specificity=90.81% avg_auc=88.22%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.269140 Test loss=0.383223 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.25448763370513916
[5/24] Train loss=0.23585301637649536
[10/24] Train loss=0.28702032566070557
[15/24] Train loss=0.2616971731185913
[20/24] Train loss=0.2598652243614197
Test set avg_accuracy=84.36% avg_sensitivity=66.25%, avg_specificity=90.83% avg_auc=88.22%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.267816 Test loss=0.383231 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.25871506333351135
[5/24] Train loss=0.23877812922000885
[10/24] Train loss=0.2903284728527069
[15/24] Train loss=0.25994759798049927
[20/24] Train loss=0.2603115439414978
Test set avg_accuracy=84.34% avg_sensitivity=66.16%, avg_specificity=90.83% avg_auc=88.22%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.268394 Test loss=0.383214 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.2579314112663269
[5/24] Train loss=0.23890578746795654
[10/24] Train loss=0.2938569486141205
[15/24] Train loss=0.2553415298461914
[20/24] Train loss=0.25963449478149414
Test set avg_accuracy=84.34% avg_sensitivity=66.16%, avg_specificity=90.83% avg_auc=88.22%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.269429 Test loss=0.383209 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.25189608335494995
[5/24] Train loss=0.23697741329669952
[10/24] Train loss=0.29276520013809204
[15/24] Train loss=0.25408393144607544
[20/24] Train loss=0.2566656172275543
Test set avg_accuracy=84.34% avg_sensitivity=66.16%, avg_specificity=90.83% avg_auc=88.22%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.269235 Test loss=0.383207 Current lr=[4.388541022775342e-09]

Fold[1] Result: acc=84.08% sen=73.92%, spe=87.70%, auc=88.88%!
Fold[1] Avg_jsc=0.60%(±0.2676115629340962)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.69137042760849
[5/24] Train loss=0.6807793378829956
[10/24] Train loss=0.6663147211074829
[15/24] Train loss=0.6508362293243408
[20/24] Train loss=0.6356480717658997
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.26%
Best model saved!! Metric=59.25619073920648!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.662909 Test loss=0.625921 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6238867044448853
[5/24] Train loss=0.62418532371521
[10/24] Train loss=0.597537636756897
[15/24] Train loss=0.5777351260185242
[20/24] Train loss=0.5603897571563721
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.66%
Best model saved!! Metric=62.657518494169494!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.596769 Test loss=0.557941 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.5524468421936035
[5/24] Train loss=0.5793646574020386
[10/24] Train loss=0.5456203818321228
[15/24] Train loss=0.5329229831695557
[20/24] Train loss=0.52174973487854
Test set avg_accuracy=74.79% avg_sensitivity=0.00%, avg_specificity=99.67% avg_auc=71.69%
Best model saved!! Metric=71.68971179536395!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.550434 Test loss=0.528555 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.5202245712280273
[5/24] Train loss=0.5586185455322266
[10/24] Train loss=0.5198825001716614
[15/24] Train loss=0.5119313597679138
[20/24] Train loss=0.5002833604812622
Test set avg_accuracy=73.63% avg_sensitivity=2.97%, avg_specificity=97.14% avg_auc=75.87%
Best model saved!! Metric=75.87318177740809!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.528696 Test loss=0.510907 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5024622678756714
[5/24] Train loss=0.5288958549499512
[10/24] Train loss=0.49802255630493164
[15/24] Train loss=0.4940345287322998
[20/24] Train loss=0.4819311499595642
Test set avg_accuracy=72.99% avg_sensitivity=12.36%, avg_specificity=93.16% avg_auc=76.73%
Best model saved!! Metric=76.73473440691707!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.511684 Test loss=0.494720 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.4835069477558136
[5/24] Train loss=0.5101850628852844
[10/24] Train loss=0.4787465035915375
[15/24] Train loss=0.4753526747226715
[20/24] Train loss=0.46520450711250305
Test set avg_accuracy=73.45% avg_sensitivity=19.87%, avg_specificity=91.27% avg_auc=78.68%
Best model saved!! Metric=78.67895414336651!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.494587 Test loss=0.477493 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.4642249643802643
[5/24] Train loss=0.4893991947174072
[10/24] Train loss=0.45832282304763794
[15/24] Train loss=0.4550190269947052
[20/24] Train loss=0.445915549993515
Test set avg_accuracy=75.40% avg_sensitivity=27.39%, avg_specificity=91.38% avg_auc=81.00%
Best model saved!! Metric=81.00429493238893!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.474732 Test loss=0.455520 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.43967318534851074
[5/24] Train loss=0.46547645330429077
[10/24] Train loss=0.4345419108867645
[15/24] Train loss=0.42754295468330383
[20/24] Train loss=0.4193618595600128
Test set avg_accuracy=77.16% avg_sensitivity=39.02%, avg_specificity=89.85% avg_auc=82.94%
Best model saved!! Metric=82.94241383545906!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.450309 Test loss=0.431755 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.40981149673461914
[5/24] Train loss=0.43579399585723877
[10/24] Train loss=0.4083211421966553
[15/24] Train loss=0.40016937255859375
[20/24] Train loss=0.3936435282230377
Test set avg_accuracy=78.89% avg_sensitivity=44.76%, avg_specificity=90.25% avg_auc=84.47%
Best model saved!! Metric=84.46747735337159!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.424128 Test loss=0.411704 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.37977686524391174
[5/24] Train loss=0.40749406814575195
[10/24] Train loss=0.38520509004592896
[15/24] Train loss=0.3789757490158081
[20/24] Train loss=0.3726966977119446
Test set avg_accuracy=79.67% avg_sensitivity=49.35%, avg_specificity=89.76% avg_auc=85.47%
Best model saved!! Metric=85.4725670234025!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.401292 Test loss=0.398408 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.3583223521709442
[5/24] Train loss=0.3813158869743347
[10/24] Train loss=0.37000730633735657
[15/24] Train loss=0.36050504446029663
[20/24] Train loss=0.354341596364975
Test set avg_accuracy=81.81% avg_sensitivity=60.82%, avg_specificity=88.79% avg_auc=86.25%
Best model saved!! Metric=86.24696553689914!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.383539 Test loss=0.390292 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.3434840440750122
[5/24] Train loss=0.3686777949333191
[10/24] Train loss=0.3587407171726227
[15/24] Train loss=0.34562748670578003
[20/24] Train loss=0.343718558549881
Test set avg_accuracy=81.95% avg_sensitivity=60.51%, avg_specificity=89.09% avg_auc=86.71%
Best model saved!! Metric=86.71174223055701!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.371538 Test loss=0.384269 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.3314058482646942
[5/24] Train loss=0.3553168773651123
[10/24] Train loss=0.35073351860046387
[15/24] Train loss=0.33571672439575195
[20/24] Train loss=0.33444347977638245
Test set avg_accuracy=82.10% avg_sensitivity=61.50%, avg_specificity=88.95% avg_auc=87.12%
Best model saved!! Metric=87.12390149923908!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.362002 Test loss=0.378863 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.3217575252056122
[5/24] Train loss=0.3479636013507843
[10/24] Train loss=0.34232816100120544
[15/24] Train loss=0.3289329707622528
[20/24] Train loss=0.3259614408016205
Test set avg_accuracy=82.51% avg_sensitivity=63.28%, avg_specificity=88.91% avg_auc=87.41%
Best model saved!! Metric=87.4117268698534!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.354153 Test loss=0.375934 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.314813494682312
[5/24] Train loss=0.3428457975387573
[10/24] Train loss=0.3371615409851074
[15/24] Train loss=0.3250803053379059
[20/24] Train loss=0.3224028944969177
Test set avg_accuracy=82.28% avg_sensitivity=63.59%, avg_specificity=88.50% avg_auc=87.61%
Best model saved!! Metric=87.60612983496702!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.349334 Test loss=0.374531 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.30962345004081726
[5/24] Train loss=0.33698344230651855
[10/24] Train loss=0.33348238468170166
[15/24] Train loss=0.316641241312027
[20/24] Train loss=0.31518518924713135
Test set avg_accuracy=82.63% avg_sensitivity=63.95%, avg_specificity=88.84% avg_auc=87.74%
Best model saved!! Metric=87.74331712086646!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.344900 Test loss=0.373317 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.3049067258834839
[5/24] Train loss=0.33744433522224426
[10/24] Train loss=0.3332516849040985
[15/24] Train loss=0.3143729567527771
[20/24] Train loss=0.3118496835231781
Test set avg_accuracy=82.99% avg_sensitivity=65.05%, avg_specificity=88.96% avg_auc=87.81%
Best model saved!! Metric=87.81265300170507!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.342064 Test loss=0.373407 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.304106205701828
[5/24] Train loss=0.3349649906158447
[10/24] Train loss=0.3296850323677063
[15/24] Train loss=0.3127008080482483
[20/24] Train loss=0.3093754053115845
Test set avg_accuracy=83.19% avg_sensitivity=65.41%, avg_specificity=89.10% avg_auc=87.89%
Best model saved!! Metric=87.89263818591266!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.339344 Test loss=0.371986 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.29985320568084717
[5/24] Train loss=0.3325514793395996
[10/24] Train loss=0.3270987570285797
[15/24] Train loss=0.3119780719280243
[20/24] Train loss=0.3045184016227722
Test set avg_accuracy=83.27% avg_sensitivity=65.36%, avg_specificity=89.22% avg_auc=87.96%
Best model saved!! Metric=87.96305574269907!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.336211 Test loss=0.370714 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.29632067680358887
[5/24] Train loss=0.3295767605304718
[10/24] Train loss=0.3254391551017761
[15/24] Train loss=0.31027674674987793
[20/24] Train loss=0.30319732427597046
Test set avg_accuracy=83.37% avg_sensitivity=65.05%, avg_specificity=89.47% avg_auc=88.01%
Best model saved!! Metric=88.00932793889318!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.333555 Test loss=0.369427 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.29207098484039307
[5/24] Train loss=0.3258894085884094
[10/24] Train loss=0.3221481144428253
[15/24] Train loss=0.308155357837677
[20/24] Train loss=0.3015083968639374
Test set avg_accuracy=83.41% avg_sensitivity=64.53%, avg_specificity=89.69% avg_auc=88.06%
Best model saved!! Metric=88.06330311610473!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.331494 Test loss=0.368229 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.28944775462150574
[5/24] Train loss=0.32054460048675537
[10/24] Train loss=0.31877556443214417
[15/24] Train loss=0.30432626605033875
[20/24] Train loss=0.29961174726486206
Test set avg_accuracy=83.49% avg_sensitivity=62.28%, avg_specificity=90.54% avg_auc=88.04%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.328661 Test loss=0.367993 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.28720253705978394
[5/24] Train loss=0.3142823576927185
[10/24] Train loss=0.3160816431045532
[15/24] Train loss=0.3045075833797455
[20/24] Train loss=0.29618752002716064
Test set avg_accuracy=83.48% avg_sensitivity=59.89%, avg_specificity=91.32% avg_auc=88.12%
Best model saved!! Metric=88.1229808527064!!
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.325141 Test loss=0.367653 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.28859686851501465
[5/24] Train loss=0.30944162607192993
[10/24] Train loss=0.315358430147171
[15/24] Train loss=0.29846274852752686
[20/24] Train loss=0.29362165927886963
Test set avg_accuracy=83.71% avg_sensitivity=58.48%, avg_specificity=92.10% avg_auc=88.15%
Best model saved!! Metric=88.15015400078441!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.322574 Test loss=0.368310 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.28398045897483826
[5/24] Train loss=0.3070605397224426
[10/24] Train loss=0.31840938329696655
[15/24] Train loss=0.29400599002838135
[20/24] Train loss=0.29237425327301025
Test set avg_accuracy=83.82% avg_sensitivity=58.84%, avg_specificity=92.12% avg_auc=88.21%
Best model saved!! Metric=88.21491878242936!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.320879 Test loss=0.368270 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.28596651554107666
[5/24] Train loss=0.3050879240036011
[10/24] Train loss=0.3159289062023163
[15/24] Train loss=0.2926223576068878
[20/24] Train loss=0.2901409864425659
Test set avg_accuracy=83.53% avg_sensitivity=54.15%, avg_specificity=93.30% avg_auc=88.26%
Best model saved!! Metric=88.26092847985788!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.318450 Test loss=0.369009 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.28730228543281555
[5/24] Train loss=0.30329573154449463
[10/24] Train loss=0.31659406423568726
[15/24] Train loss=0.28875625133514404
[20/24] Train loss=0.2879513204097748
Test set avg_accuracy=83.49% avg_sensitivity=53.16%, avg_specificity=93.58% avg_auc=88.23%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.317012 Test loss=0.372150 Current lr=[0.000669125424222739]

[0/24] Train loss=0.2881966829299927
[5/24] Train loss=0.2974654734134674
[10/24] Train loss=0.3151026964187622
[15/24] Train loss=0.28908276557922363
[20/24] Train loss=0.2874186336994171
Test set avg_accuracy=83.02% avg_sensitivity=49.61%, avg_specificity=94.13% avg_auc=88.16%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.315611 Test loss=0.375184 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.2913661301136017
[5/24] Train loss=0.3006119430065155
[10/24] Train loss=0.3124561905860901
[15/24] Train loss=0.2871547043323517
[20/24] Train loss=0.28409144282341003
Test set avg_accuracy=83.63% avg_sensitivity=50.08%, avg_specificity=94.79% avg_auc=88.18%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.314461 Test loss=0.375786 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.28921109437942505
[5/24] Train loss=0.29833510518074036
[10/24] Train loss=0.3087213635444641
[15/24] Train loss=0.28452491760253906
[20/24] Train loss=0.2799779176712036
Test set avg_accuracy=84.06% avg_sensitivity=52.69%, avg_specificity=94.50% avg_auc=88.35%
Best model saved!! Metric=88.35432373031384!!
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.311915 Test loss=0.371898 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.2829645276069641
[5/24] Train loss=0.2986886203289032
[10/24] Train loss=0.3110119104385376
[15/24] Train loss=0.2826962172985077
[20/24] Train loss=0.27827197313308716
Test set avg_accuracy=83.91% avg_sensitivity=51.43%, avg_specificity=94.71% avg_auc=88.37%
Best model saved!! Metric=88.36957581376201!!
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.310218 Test loss=0.372788 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.28326424956321716
[5/24] Train loss=0.299412339925766
[10/24] Train loss=0.3109704256057739
[15/24] Train loss=0.2829603850841522
[20/24] Train loss=0.28065410256385803
Test set avg_accuracy=84.09% avg_sensitivity=53.94%, avg_specificity=94.12% avg_auc=88.30%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.308491 Test loss=0.372550 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.2830974757671356
[5/24] Train loss=0.29794248938560486
[10/24] Train loss=0.30946066975593567
[15/24] Train loss=0.28134942054748535
[20/24] Train loss=0.2780028283596039
Test set avg_accuracy=84.06% avg_sensitivity=52.90%, avg_specificity=94.43% avg_auc=88.26%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.308275 Test loss=0.375508 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.28515180945396423
[5/24] Train loss=0.30294594168663025
[10/24] Train loss=0.3133537769317627
[15/24] Train loss=0.2817082107067108
[20/24] Train loss=0.27862855792045593
Test set avg_accuracy=84.00% avg_sensitivity=53.42%, avg_specificity=94.17% avg_auc=88.24%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.308581 Test loss=0.374213 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.2785644233226776
[5/24] Train loss=0.3051305413246155
[10/24] Train loss=0.3142852187156677
[15/24] Train loss=0.2747404873371124
[20/24] Train loss=0.277083158493042
Test set avg_accuracy=83.63% avg_sensitivity=51.28%, avg_specificity=94.40% avg_auc=88.24%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.307485 Test loss=0.376269 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.2805882394313812
[5/24] Train loss=0.3095916211605072
[10/24] Train loss=0.31126469373703003
[15/24] Train loss=0.27769017219543457
[20/24] Train loss=0.27725356817245483
Test set avg_accuracy=83.19% avg_sensitivity=46.53%, avg_specificity=95.38% avg_auc=88.14%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.308194 Test loss=0.379398 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.28148385882377625
[5/24] Train loss=0.3036978840827942
[10/24] Train loss=0.309914231300354
[15/24] Train loss=0.27336859703063965
[20/24] Train loss=0.2763884961605072
Test set avg_accuracy=83.15% avg_sensitivity=47.37%, avg_specificity=95.05% avg_auc=88.17%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.305883 Test loss=0.377376 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.28304821252822876
[5/24] Train loss=0.3053370416164398
[10/24] Train loss=0.30816447734832764
[15/24] Train loss=0.2767147719860077
[20/24] Train loss=0.2765014171600342
Test set avg_accuracy=83.59% avg_sensitivity=51.07%, avg_specificity=94.41% avg_auc=88.28%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.305146 Test loss=0.373218 Current lr=[0.000944367614404117]

[0/24] Train loss=0.27892568707466125
[5/24] Train loss=0.30023258924484253
[10/24] Train loss=0.3042420744895935
[15/24] Train loss=0.2769949436187744
[20/24] Train loss=0.27471694350242615
Test set avg_accuracy=83.80% avg_sensitivity=50.81%, avg_specificity=94.78% avg_auc=88.35%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.304634 Test loss=0.372288 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.2792294919490814
[5/24] Train loss=0.30185529589653015
[10/24] Train loss=0.3160102963447571
[15/24] Train loss=0.2762940227985382
[20/24] Train loss=0.27535516023635864
Test set avg_accuracy=83.57% avg_sensitivity=51.12%, avg_specificity=94.36% avg_auc=88.41%
Best model saved!! Metric=88.412132294671!!
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.304826 Test loss=0.370048 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.2749035954475403
[5/24] Train loss=0.29840052127838135
[10/24] Train loss=0.3113898038864136
[15/24] Train loss=0.27232587337493896
[20/24] Train loss=0.2693660259246826
Test set avg_accuracy=83.84% avg_sensitivity=52.53%, avg_specificity=94.26% avg_auc=88.27%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.303399 Test loss=0.372683 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.2732493281364441
[5/24] Train loss=0.30215170979499817
[10/24] Train loss=0.31243857741355896
[15/24] Train loss=0.2771245241165161
[20/24] Train loss=0.27509042620658875
Test set avg_accuracy=83.31% avg_sensitivity=49.71%, avg_specificity=94.48% avg_auc=88.32%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.303972 Test loss=0.373848 Current lr=[0.000989780311725182]

[0/24] Train loss=0.2791101038455963
[5/24] Train loss=0.30092915892601013
[10/24] Train loss=0.30663830041885376
[15/24] Train loss=0.2696342170238495
[20/24] Train loss=0.27547991275787354
Test set avg_accuracy=83.36% avg_sensitivity=50.50%, avg_specificity=94.29% avg_auc=88.27%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.302977 Test loss=0.373823 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.2756706774234772
[5/24] Train loss=0.29736149311065674
[10/24] Train loss=0.304747611284256
[15/24] Train loss=0.2727055549621582
[20/24] Train loss=0.27363842725753784
Test set avg_accuracy=83.53% avg_sensitivity=51.70%, avg_specificity=94.12% avg_auc=88.37%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.302257 Test loss=0.371646 Current lr=[0.000998924125869967]

[0/24] Train loss=0.27191290259361267
[5/24] Train loss=0.3036027252674103
[10/24] Train loss=0.3037587106227875
[15/24] Train loss=0.2712644636631012
[20/24] Train loss=0.2739149034023285
Test set avg_accuracy=83.58% avg_sensitivity=53.00%, avg_specificity=93.75% avg_auc=88.26%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.302812 Test loss=0.373058 Current lr=[0.000999999611458977]

[0/24] Train loss=0.27346575260162354
[5/24] Train loss=0.29933932423591614
[10/24] Train loss=0.30963948369026184
[15/24] Train loss=0.27145832777023315
[20/24] Train loss=0.2728116512298584
Test set avg_accuracy=83.46% avg_sensitivity=52.69%, avg_specificity=93.70% avg_auc=88.37%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.302327 Test loss=0.370151 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.26676979660987854
[5/24] Train loss=0.30115002393722534
[10/24] Train loss=0.310751348733902
[15/24] Train loss=0.26802802085876465
[20/24] Train loss=0.2714666426181793
Test set avg_accuracy=83.50% avg_sensitivity=50.13%, avg_specificity=94.60% avg_auc=88.36%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.301169 Test loss=0.373435 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.2759247422218323
[5/24] Train loss=0.30020615458488464
[10/24] Train loss=0.31031766533851624
[15/24] Train loss=0.2695281505584717
[20/24] Train loss=0.2672186493873596
Test set avg_accuracy=83.36% avg_sensitivity=52.06%, avg_specificity=93.77% avg_auc=88.40%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.301167 Test loss=0.370769 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.26766249537467957
[5/24] Train loss=0.3027653396129608
[10/24] Train loss=0.3136189877986908
[15/24] Train loss=0.2663115859031677
[20/24] Train loss=0.2757633924484253
Test set avg_accuracy=83.11% avg_sensitivity=52.27%, avg_specificity=93.37% avg_auc=88.24%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.300817 Test loss=0.372384 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.2740784287452698
[5/24] Train loss=0.29925867915153503
[10/24] Train loss=0.3083234429359436
[15/24] Train loss=0.26941362023353577
[20/24] Train loss=0.27248549461364746
Test set avg_accuracy=83.31% avg_sensitivity=51.28%, avg_specificity=93.96% avg_auc=88.35%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.301478 Test loss=0.369785 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.27084410190582275
[5/24] Train loss=0.30058789253234863
[10/24] Train loss=0.3081858158111572
[15/24] Train loss=0.2675100564956665
[20/24] Train loss=0.27312707901000977
Test set avg_accuracy=83.44% avg_sensitivity=50.65%, avg_specificity=94.34% avg_auc=88.28%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.299808 Test loss=0.372853 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.27547281980514526
[5/24] Train loss=0.30182692408561707
[10/24] Train loss=0.3128582239151001
[15/24] Train loss=0.26606443524360657
[20/24] Train loss=0.27137547731399536
Test set avg_accuracy=82.99% avg_sensitivity=51.85%, avg_specificity=93.35% avg_auc=88.35%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.300683 Test loss=0.369761 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.2690202295780182
[5/24] Train loss=0.3009611964225769
[10/24] Train loss=0.31284940242767334
[15/24] Train loss=0.2710982859134674
[20/24] Train loss=0.27004778385162354
Test set avg_accuracy=83.24% avg_sensitivity=49.61%, avg_specificity=94.43% avg_auc=88.37%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.300862 Test loss=0.371870 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.2770909368991852
[5/24] Train loss=0.29897114634513855
[10/24] Train loss=0.30871742963790894
[15/24] Train loss=0.265004962682724
[20/24] Train loss=0.2714472711086273
Test set avg_accuracy=83.15% avg_sensitivity=48.20%, avg_specificity=94.78% avg_auc=88.31%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.299538 Test loss=0.372896 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.2716299891471863
[5/24] Train loss=0.3022788465023041
[10/24] Train loss=0.3046547770500183
[15/24] Train loss=0.27091333270072937
[20/24] Train loss=0.27357015013694763
Test set avg_accuracy=83.31% avg_sensitivity=49.61%, avg_specificity=94.52% avg_auc=88.23%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.299617 Test loss=0.373615 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.2697092294692993
[5/24] Train loss=0.3039810359477997
[10/24] Train loss=0.30496102571487427
[15/24] Train loss=0.27179235219955444
[20/24] Train loss=0.2710159420967102
Test set avg_accuracy=83.02% avg_sensitivity=48.25%, avg_specificity=94.59% avg_auc=88.25%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.299842 Test loss=0.373814 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.27144208550453186
[5/24] Train loss=0.2920759320259094
[10/24] Train loss=0.29973119497299194
[15/24] Train loss=0.26546335220336914
[20/24] Train loss=0.2712898254394531
Test set avg_accuracy=82.94% avg_sensitivity=47.84%, avg_specificity=94.62% avg_auc=88.07%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.299291 Test loss=0.376812 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.2743756175041199
[5/24] Train loss=0.292165607213974
[10/24] Train loss=0.2994988262653351
[15/24] Train loss=0.2681044340133667
[20/24] Train loss=0.2703510522842407
Test set avg_accuracy=82.90% avg_sensitivity=49.92%, avg_specificity=93.87% avg_auc=88.18%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.298895 Test loss=0.374206 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.26971399784088135
[5/24] Train loss=0.2913605570793152
[10/24] Train loss=0.3008083403110504
[15/24] Train loss=0.26682695746421814
[20/24] Train loss=0.27223795652389526
Test set avg_accuracy=82.80% avg_sensitivity=51.12%, avg_specificity=93.34% avg_auc=88.16%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.298528 Test loss=0.371856 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.26665613055229187
[5/24] Train loss=0.29073473811149597
[10/24] Train loss=0.29969853162765503
[15/24] Train loss=0.2698354125022888
[20/24] Train loss=0.27078568935394287
Test set avg_accuracy=83.02% avg_sensitivity=51.75%, avg_specificity=93.42% avg_auc=88.09%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.298275 Test loss=0.371992 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.2717861831188202
[5/24] Train loss=0.2894708216190338
[10/24] Train loss=0.30103665590286255
[15/24] Train loss=0.262174129486084
[20/24] Train loss=0.27214667201042175
Test set avg_accuracy=82.99% avg_sensitivity=52.01%, avg_specificity=93.30% avg_auc=88.17%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.298059 Test loss=0.372958 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.26744067668914795
[5/24] Train loss=0.290288507938385
[10/24] Train loss=0.3030007779598236
[15/24] Train loss=0.2634564936161041
[20/24] Train loss=0.27313125133514404
Test set avg_accuracy=83.18% avg_sensitivity=52.90%, avg_specificity=93.25% avg_auc=88.22%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.298291 Test loss=0.372234 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.26371628046035767
[5/24] Train loss=0.2912139296531677
[10/24] Train loss=0.30597472190856934
[15/24] Train loss=0.266728937625885
[20/24] Train loss=0.2737080752849579
Test set avg_accuracy=83.07% avg_sensitivity=52.84%, avg_specificity=93.13% avg_auc=88.12%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.297884 Test loss=0.374436 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.2700018584728241
[5/24] Train loss=0.293039470911026
[10/24] Train loss=0.3056968152523041
[15/24] Train loss=0.26455944776535034
[20/24] Train loss=0.27410775423049927
Test set avg_accuracy=83.28% avg_sensitivity=52.74%, avg_specificity=93.44% avg_auc=88.16%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.298403 Test loss=0.372703 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.2672451138496399
[5/24] Train loss=0.29356250166893005
[10/24] Train loss=0.30796438455581665
[15/24] Train loss=0.2686067223548889
[20/24] Train loss=0.273097425699234
Test set avg_accuracy=83.31% avg_sensitivity=51.64%, avg_specificity=93.84% avg_auc=88.03%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.298552 Test loss=0.374608 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.26975977420806885
[5/24] Train loss=0.3005293309688568
[10/24] Train loss=0.30784696340560913
[15/24] Train loss=0.2625349462032318
[20/24] Train loss=0.2730088233947754
Test set avg_accuracy=83.29% avg_sensitivity=51.33%, avg_specificity=93.93% avg_auc=88.18%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.298739 Test loss=0.375630 Current lr=[0.000904142181093812]

[0/24] Train loss=0.2743799090385437
[5/24] Train loss=0.28160834312438965
[10/24] Train loss=0.29819437861442566
[15/24] Train loss=0.2694130539894104
[20/24] Train loss=0.26908963918685913
Test set avg_accuracy=83.14% avg_sensitivity=51.96%, avg_specificity=93.51% avg_auc=87.83%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.297755 Test loss=0.378679 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.2695290148258209
[5/24] Train loss=0.2851063013076782
[10/24] Train loss=0.2997523248195648
[15/24] Train loss=0.2610603868961334
[20/24] Train loss=0.27124324440956116
Test set avg_accuracy=83.19% avg_sensitivity=53.73%, avg_specificity=92.99% avg_auc=88.06%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.297802 Test loss=0.373729 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.2694755494594574
[5/24] Train loss=0.28376269340515137
[10/24] Train loss=0.30847984552383423
[15/24] Train loss=0.25984475016593933
[20/24] Train loss=0.26954492926597595
Test set avg_accuracy=83.23% avg_sensitivity=55.92%, avg_specificity=92.31% avg_auc=88.11%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.296133 Test loss=0.372814 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.26708364486694336
[5/24] Train loss=0.27944251894950867
[10/24] Train loss=0.3020382821559906
[15/24] Train loss=0.25836434960365295
[20/24] Train loss=0.2705025374889374
Test set avg_accuracy=83.35% avg_sensitivity=55.66%, avg_specificity=92.56% avg_auc=88.08%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.294856 Test loss=0.374012 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.2659382224082947
[5/24] Train loss=0.2773706018924713
[10/24] Train loss=0.30277737975120544
[15/24] Train loss=0.2591732144355774
[20/24] Train loss=0.2675229012966156
Test set avg_accuracy=83.31% avg_sensitivity=57.02%, avg_specificity=92.05% avg_auc=88.05%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.294639 Test loss=0.375381 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.2668868601322174
[5/24] Train loss=0.279760479927063
[10/24] Train loss=0.2993963062763214
[15/24] Train loss=0.25814688205718994
[20/24] Train loss=0.26437652111053467
Test set avg_accuracy=83.54% avg_sensitivity=55.19%, avg_specificity=92.97% avg_auc=88.04%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.294063 Test loss=0.375656 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.27163922786712646
[5/24] Train loss=0.28016772866249084
[10/24] Train loss=0.30873560905456543
[15/24] Train loss=0.2620772421360016
[20/24] Train loss=0.265461802482605
Test set avg_accuracy=83.57% avg_sensitivity=58.84%, avg_specificity=91.79% avg_auc=88.18%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.294487 Test loss=0.372181 Current lr=[0.000834102481048427]

[0/24] Train loss=0.2663152515888214
[5/24] Train loss=0.27793338894844055
[10/24] Train loss=0.2989530861377716
[15/24] Train loss=0.2577977776527405
[20/24] Train loss=0.26467445492744446
Test set avg_accuracy=83.53% avg_sensitivity=57.12%, avg_specificity=92.31% avg_auc=88.00%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.291991 Test loss=0.377448 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.26764458417892456
[5/24] Train loss=0.27897876501083374
[10/24] Train loss=0.2997439503669739
[15/24] Train loss=0.2601965069770813
[20/24] Train loss=0.2721593976020813
Test set avg_accuracy=83.59% avg_sensitivity=57.80%, avg_specificity=92.17% avg_auc=88.17%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.292807 Test loss=0.376583 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.26425763964653015
[5/24] Train loss=0.2779199182987213
[10/24] Train loss=0.30555376410484314
[15/24] Train loss=0.258065402507782
[20/24] Train loss=0.2720791697502136
Test set avg_accuracy=83.63% avg_sensitivity=58.22%, avg_specificity=92.09% avg_auc=88.05%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.293708 Test loss=0.376717 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.2653599977493286
[5/24] Train loss=0.2819139063358307
[10/24] Train loss=0.3059598505496979
[15/24] Train loss=0.2573656141757965
[20/24] Train loss=0.2624371647834778
Test set avg_accuracy=83.55% avg_sensitivity=53.83%, avg_specificity=93.44% avg_auc=87.87%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.293230 Test loss=0.381013 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.27010345458984375
[5/24] Train loss=0.2742520868778229
[10/24] Train loss=0.2969389259815216
[15/24] Train loss=0.25514379143714905
[20/24] Train loss=0.2623465061187744
Test set avg_accuracy=83.61% avg_sensitivity=52.48%, avg_specificity=93.96% avg_auc=87.66%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.290525 Test loss=0.385765 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.27148208022117615
[5/24] Train loss=0.276360422372818
[10/24] Train loss=0.2955853044986725
[15/24] Train loss=0.25444477796554565
[20/24] Train loss=0.26225340366363525
Test set avg_accuracy=83.76% avg_sensitivity=54.46%, avg_specificity=93.51% avg_auc=87.73%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.290474 Test loss=0.383561 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.26718127727508545
[5/24] Train loss=0.2712346017360687
[10/24] Train loss=0.2954871654510498
[15/24] Train loss=0.25129935145378113
[20/24] Train loss=0.26480787992477417
Test set avg_accuracy=83.65% avg_sensitivity=57.07%, avg_specificity=92.49% avg_auc=87.88%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.290962 Test loss=0.378700 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.26598218083381653
[5/24] Train loss=0.26625001430511475
[10/24] Train loss=0.29651910066604614
[15/24] Train loss=0.2536454200744629
[20/24] Train loss=0.2614067792892456
Test set avg_accuracy=83.52% avg_sensitivity=58.84%, avg_specificity=91.72% avg_auc=87.79%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.289970 Test loss=0.379788 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.26437684893608093
[5/24] Train loss=0.2666097581386566
[10/24] Train loss=0.29855644702911377
[15/24] Train loss=0.2520069181919098
[20/24] Train loss=0.2626856565475464
Test set avg_accuracy=83.53% avg_sensitivity=57.22%, avg_specificity=92.28% avg_auc=87.83%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.288240 Test loss=0.379347 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.25532007217407227
[5/24] Train loss=0.26766276359558105
[10/24] Train loss=0.2964992821216583
[15/24] Train loss=0.2510816156864166
[20/24] Train loss=0.26219049096107483
Test set avg_accuracy=83.50% avg_sensitivity=55.87%, avg_specificity=92.69% avg_auc=87.61%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.285580 Test loss=0.385627 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.2636909484863281
[5/24] Train loss=0.26990339159965515
[10/24] Train loss=0.29539936780929565
[15/24] Train loss=0.2497960329055786
[20/24] Train loss=0.26016056537628174
Test set avg_accuracy=83.53% avg_sensitivity=56.44%, avg_specificity=92.54% avg_auc=87.62%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.286515 Test loss=0.384142 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.2661568820476532
[5/24] Train loss=0.26548129320144653
[10/24] Train loss=0.2892328202724457
[15/24] Train loss=0.24758481979370117
[20/24] Train loss=0.2543739676475525
Test set avg_accuracy=83.89% avg_sensitivity=56.39%, avg_specificity=93.04% avg_auc=87.68%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.285629 Test loss=0.384894 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.2618611752986908
[5/24] Train loss=0.2692384123802185
[10/24] Train loss=0.29798561334609985
[15/24] Train loss=0.25464773178100586
[20/24] Train loss=0.25732550024986267
Test set avg_accuracy=83.78% avg_sensitivity=56.03%, avg_specificity=93.01% avg_auc=87.68%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.286766 Test loss=0.385508 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.26899072527885437
[5/24] Train loss=0.2660951018333435
[10/24] Train loss=0.29806187748908997
[15/24] Train loss=0.24954482913017273
[20/24] Train loss=0.2585986256599426
Test set avg_accuracy=83.46% avg_sensitivity=53.31%, avg_specificity=93.49% avg_auc=87.56%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.286564 Test loss=0.391702 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.26396867632865906
[5/24] Train loss=0.2634316384792328
[10/24] Train loss=0.29819223284721375
[15/24] Train loss=0.24946488440036774
[20/24] Train loss=0.2522905766963959
Test set avg_accuracy=83.02% avg_sensitivity=51.28%, avg_specificity=93.58% avg_auc=87.46%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.284356 Test loss=0.395180 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.2632516324520111
[5/24] Train loss=0.2685346007347107
[10/24] Train loss=0.2970641255378723
[15/24] Train loss=0.24822606146335602
[20/24] Train loss=0.25309884548187256
Test set avg_accuracy=82.94% avg_sensitivity=52.32%, avg_specificity=93.13% avg_auc=87.43%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.285450 Test loss=0.396484 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.26452264189720154
[5/24] Train loss=0.26402127742767334
[10/24] Train loss=0.3115784525871277
[15/24] Train loss=0.24829119443893433
[20/24] Train loss=0.2540251612663269
Test set avg_accuracy=82.70% avg_sensitivity=57.85%, avg_specificity=90.96% avg_auc=87.52%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.289112 Test loss=0.389996 Current lr=[0.00061065423442182]

[0/24] Train loss=0.25852301716804504
[5/24] Train loss=0.2593364119529724
[10/24] Train loss=0.30777430534362793
[15/24] Train loss=0.2536141574382782
[20/24] Train loss=0.26279962062835693
Test set avg_accuracy=83.03% avg_sensitivity=66.51%, avg_specificity=88.53% avg_auc=87.88%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.290491 Test loss=0.388346 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.25421133637428284
[5/24] Train loss=0.26273077726364136
[10/24] Train loss=0.2899433374404907
[15/24] Train loss=0.24661192297935486
[20/24] Train loss=0.2530669569969177
Test set avg_accuracy=82.97% avg_sensitivity=65.94%, avg_specificity=88.63% avg_auc=87.74%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.285583 Test loss=0.389837 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.25652042031288147
[5/24] Train loss=0.27036014199256897
[10/24] Train loss=0.290620893239975
[15/24] Train loss=0.24531972408294678
[20/24] Train loss=0.2536050081253052
Test set avg_accuracy=82.83% avg_sensitivity=62.65%, avg_specificity=89.54% avg_auc=87.60%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.281157 Test loss=0.391903 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.25728702545166016
[5/24] Train loss=0.2583179473876953
[10/24] Train loss=0.2931174039840698
[15/24] Train loss=0.24047592282295227
[20/24] Train loss=0.251238614320755
Test set avg_accuracy=83.32% avg_sensitivity=61.61%, avg_specificity=90.54% avg_auc=87.53%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.280700 Test loss=0.392781 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.2539199888706207
[5/24] Train loss=0.25814366340637207
[10/24] Train loss=0.29169151186943054
[15/24] Train loss=0.24789559841156006
[20/24] Train loss=0.250720351934433
Test set avg_accuracy=83.05% avg_sensitivity=62.65%, avg_specificity=89.83% avg_auc=87.57%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.279455 Test loss=0.393975 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.25306764245033264
[5/24] Train loss=0.25312185287475586
[10/24] Train loss=0.2903440296649933
[15/24] Train loss=0.24578715860843658
[20/24] Train loss=0.25243014097213745
Test set avg_accuracy=83.11% avg_sensitivity=62.44%, avg_specificity=89.99% avg_auc=87.53%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.279458 Test loss=0.394589 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.2505841553211212
[5/24] Train loss=0.2576783299446106
[10/24] Train loss=0.291170209646225
[15/24] Train loss=0.23787643015384674
[20/24] Train loss=0.25519242882728577
Test set avg_accuracy=82.94% avg_sensitivity=62.55%, avg_specificity=89.73% avg_auc=87.55%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.277524 Test loss=0.394515 Current lr=[0.000506858408304961]

[0/24] Train loss=0.2513374388217926
[5/24] Train loss=0.25522106885910034
[10/24] Train loss=0.2804497480392456
[15/24] Train loss=0.23634061217308044
[20/24] Train loss=0.24479182064533234
Test set avg_accuracy=83.10% avg_sensitivity=60.35%, avg_specificity=90.66% avg_auc=87.48%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.277042 Test loss=0.395008 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.2478782832622528
[5/24] Train loss=0.2551145851612091
[10/24] Train loss=0.2818776071071625
[15/24] Train loss=0.23942503333091736
[20/24] Train loss=0.24976840615272522
Test set avg_accuracy=83.06% avg_sensitivity=57.90%, avg_specificity=91.43% avg_auc=87.41%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.275055 Test loss=0.395344 Current lr=[0.000476946990416354]

[0/24] Train loss=0.24761511385440826
[5/24] Train loss=0.2506848871707916
[10/24] Train loss=0.283740758895874
[15/24] Train loss=0.23191450536251068
[20/24] Train loss=0.24718768894672394
Test set avg_accuracy=83.12% avg_sensitivity=61.29%, avg_specificity=90.39% avg_auc=87.52%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.273837 Test loss=0.395078 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.2465537041425705
[5/24] Train loss=0.248750701546669
[10/24] Train loss=0.2836262583732605
[15/24] Train loss=0.23393848538398743
[20/24] Train loss=0.24784572422504425
Test set avg_accuracy=83.11% avg_sensitivity=61.29%, avg_specificity=90.37% avg_auc=87.53%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.273158 Test loss=0.394896 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.2479039430618286
[5/24] Train loss=0.24864065647125244
[10/24] Train loss=0.2834770083427429
[15/24] Train loss=0.22994275391101837
[20/24] Train loss=0.24969962239265442
Test set avg_accuracy=82.99% avg_sensitivity=61.19%, avg_specificity=90.25% avg_auc=87.50%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.272354 Test loss=0.395282 Current lr=[0.000432267999769856]

[0/24] Train loss=0.2517489194869995
[5/24] Train loss=0.2498890459537506
[10/24] Train loss=0.2824142277240753
[15/24] Train loss=0.2316933125257492
[20/24] Train loss=0.24651770293712616
Test set avg_accuracy=83.03% avg_sensitivity=61.97%, avg_specificity=90.04% avg_auc=87.44%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.273851 Test loss=0.395155 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.24960146844387054
[5/24] Train loss=0.24834886193275452
[10/24] Train loss=0.2828492820262909
[15/24] Train loss=0.2323722094297409
[20/24] Train loss=0.24664168059825897
Test set avg_accuracy=82.85% avg_sensitivity=59.99%, avg_specificity=90.46% avg_auc=87.37%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.272836 Test loss=0.396822 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.2482215166091919
[5/24] Train loss=0.2439366728067398
[10/24] Train loss=0.2805759310722351
[15/24] Train loss=0.2341793030500412
[20/24] Train loss=0.24442225694656372
Test set avg_accuracy=83.12% avg_sensitivity=61.14%, avg_specificity=90.44% avg_auc=87.42%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.270655 Test loss=0.399770 Current lr=[0.000388134363466264]

[0/24] Train loss=0.24560974538326263
[5/24] Train loss=0.2476818710565567
[10/24] Train loss=0.2859307527542114
[15/24] Train loss=0.23516950011253357
[20/24] Train loss=0.24434909224510193
Test set avg_accuracy=83.06% avg_sensitivity=61.24%, avg_specificity=90.32% avg_auc=87.44%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.272047 Test loss=0.401326 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.2442280352115631
[5/24] Train loss=0.2445012927055359
[10/24] Train loss=0.2817758023738861
[15/24] Train loss=0.2303774356842041
[20/24] Train loss=0.2438577115535736
Test set avg_accuracy=82.79% avg_sensitivity=61.50%, avg_specificity=89.87% avg_auc=87.42%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.272136 Test loss=0.401479 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.2438361495733261
[5/24] Train loss=0.25010865926742554
[10/24] Train loss=0.28290247917175293
[15/24] Train loss=0.23733638226985931
[20/24] Train loss=0.24273595213890076
Test set avg_accuracy=82.55% avg_sensitivity=62.55%, avg_specificity=89.21% avg_auc=87.47%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.273317 Test loss=0.402798 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.24339284002780914
[5/24] Train loss=0.2521173357963562
[10/24] Train loss=0.2893611788749695
[15/24] Train loss=0.23838365077972412
[20/24] Train loss=0.24060571193695068
Test set avg_accuracy=82.45% avg_sensitivity=67.76%, avg_specificity=87.33% avg_auc=87.63%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.276148 Test loss=0.405211 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.24421103298664093
[5/24] Train loss=0.2699512839317322
[10/24] Train loss=0.2916078269481659
[15/24] Train loss=0.23104003071784973
[20/24] Train loss=0.24978914856910706
Test set avg_accuracy=82.04% avg_sensitivity=72.87%, avg_specificity=85.09% avg_auc=87.80%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.279789 Test loss=0.416526 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.25845661759376526
[5/24] Train loss=0.2721489667892456
[10/24] Train loss=0.28314313292503357
[15/24] Train loss=0.24050696194171906
[20/24] Train loss=0.2715471386909485
Test set avg_accuracy=82.83% avg_sensitivity=66.09%, avg_specificity=88.39% avg_auc=87.80%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.281670 Test loss=0.393983 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.24887615442276
[5/24] Train loss=0.25059229135513306
[10/24] Train loss=0.283839613199234
[15/24] Train loss=0.2347271740436554
[20/24] Train loss=0.2524678111076355
Test set avg_accuracy=82.94% avg_sensitivity=63.07%, avg_specificity=89.55% avg_auc=87.74%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.273199 Test loss=0.393811 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2485489547252655
[5/24] Train loss=0.24651500582695007
[10/24] Train loss=0.2766530513763428
[15/24] Train loss=0.23687872290611267
[20/24] Train loss=0.2531778812408447
Test set avg_accuracy=83.18% avg_sensitivity=65.05%, avg_specificity=89.21% avg_auc=87.61%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.269049 Test loss=0.398994 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.2419813722372055
[5/24] Train loss=0.24575667083263397
[10/24] Train loss=0.2746354043483734
[15/24] Train loss=0.23357778787612915
[20/24] Train loss=0.2527313232421875
Test set avg_accuracy=82.89% avg_sensitivity=65.36%, avg_specificity=88.72% avg_auc=87.59%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.268900 Test loss=0.402403 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.2417658120393753
[5/24] Train loss=0.24217531085014343
[10/24] Train loss=0.27731746435165405
[15/24] Train loss=0.23157741129398346
[20/24] Train loss=0.24624891579151154
Test set avg_accuracy=82.88% avg_sensitivity=64.37%, avg_specificity=89.03% avg_auc=87.47%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.266539 Test loss=0.404772 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.2468489408493042
[5/24] Train loss=0.24313631653785706
[10/24] Train loss=0.27904364466667175
[15/24] Train loss=0.22722835838794708
[20/24] Train loss=0.247493177652359
Test set avg_accuracy=83.10% avg_sensitivity=64.79%, avg_specificity=89.19% avg_auc=87.44%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.266382 Test loss=0.405047 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.2404969036579132
[5/24] Train loss=0.2430497258901596
[10/24] Train loss=0.27496498823165894
[15/24] Train loss=0.2259170114994049
[20/24] Train loss=0.24212312698364258
Test set avg_accuracy=83.24% avg_sensitivity=63.75%, avg_specificity=89.73% avg_auc=87.43%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.264713 Test loss=0.404971 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.24400629103183746
[5/24] Train loss=0.2449643611907959
[10/24] Train loss=0.2735660672187805
[15/24] Train loss=0.23002365231513977
[20/24] Train loss=0.24153955280780792
Test set avg_accuracy=83.41% avg_sensitivity=63.28%, avg_specificity=90.11% avg_auc=87.46%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.264084 Test loss=0.403518 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.2373366355895996
[5/24] Train loss=0.24236588180065155
[10/24] Train loss=0.27511534094810486
[15/24] Train loss=0.22648440301418304
[20/24] Train loss=0.24663738906383514
Test set avg_accuracy=82.76% avg_sensitivity=61.66%, avg_specificity=89.78% avg_auc=87.42%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.263699 Test loss=0.403619 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.23898224532604218
[5/24] Train loss=0.24157340824604034
[10/24] Train loss=0.2699342370033264
[15/24] Train loss=0.2295181304216385
[20/24] Train loss=0.25128722190856934
Test set avg_accuracy=83.26% avg_sensitivity=63.07%, avg_specificity=89.97% avg_auc=87.36%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.263186 Test loss=0.406464 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2410736232995987
[5/24] Train loss=0.24290773272514343
[10/24] Train loss=0.2722761929035187
[15/24] Train loss=0.2334667593240738
[20/24] Train loss=0.24157167971134186
Test set avg_accuracy=82.97% avg_sensitivity=62.96%, avg_specificity=89.62% avg_auc=87.41%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.262432 Test loss=0.404411 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.23905713856220245
[5/24] Train loss=0.23776192963123322
[10/24] Train loss=0.2721666991710663
[15/24] Train loss=0.22898878157138824
[20/24] Train loss=0.23613935708999634
Test set avg_accuracy=82.80% avg_sensitivity=61.76%, avg_specificity=89.80% avg_auc=87.35%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.261111 Test loss=0.406233 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.23798829317092896
[5/24] Train loss=0.24127082526683807
[10/24] Train loss=0.2712499797344208
[15/24] Train loss=0.227956622838974
[20/24] Train loss=0.242035910487175
Test set avg_accuracy=82.83% avg_sensitivity=61.66%, avg_specificity=89.87% avg_auc=87.40%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.261801 Test loss=0.405034 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.23753201961517334
[5/24] Train loss=0.23907247185707092
[10/24] Train loss=0.27034223079681396
[15/24] Train loss=0.22610506415367126
[20/24] Train loss=0.24128326773643494
Test set avg_accuracy=82.76% avg_sensitivity=61.45%, avg_specificity=89.85% avg_auc=87.38%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.260736 Test loss=0.405123 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.24386774003505707
[5/24] Train loss=0.23800647258758545
[10/24] Train loss=0.26638147234916687
[15/24] Train loss=0.22497805953025818
[20/24] Train loss=0.24329149723052979
Test set avg_accuracy=82.76% avg_sensitivity=60.04%, avg_specificity=90.32% avg_auc=87.38%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.260896 Test loss=0.405204 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.2398076206445694
[5/24] Train loss=0.23941078782081604
[10/24] Train loss=0.26891544461250305
[15/24] Train loss=0.22415651381015778
[20/24] Train loss=0.24351225793361664
Test set avg_accuracy=82.88% avg_sensitivity=60.04%, avg_specificity=90.47% avg_auc=87.31%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.261544 Test loss=0.405591 Current lr=[0.000123057953306828]

[0/24] Train loss=0.23568809032440186
[5/24] Train loss=0.23324203491210938
[10/24] Train loss=0.2697291076183319
[15/24] Train loss=0.22640986740589142
[20/24] Train loss=0.23825332522392273
Test set avg_accuracy=82.76% avg_sensitivity=60.25%, avg_specificity=90.25% avg_auc=87.33%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.260156 Test loss=0.406211 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.2396228313446045
[5/24] Train loss=0.23489943146705627
[10/24] Train loss=0.26587116718292236
[15/24] Train loss=0.22880809009075165
[20/24] Train loss=0.24070264399051666
Test set avg_accuracy=82.73% avg_sensitivity=58.69%, avg_specificity=90.73% avg_auc=87.30%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.259092 Test loss=0.405414 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.23711802065372467
[5/24] Train loss=0.23916326463222504
[10/24] Train loss=0.26252976059913635
[15/24] Train loss=0.2280026227235794
[20/24] Train loss=0.24188238382339478
Test set avg_accuracy=82.92% avg_sensitivity=58.58%, avg_specificity=91.01% avg_auc=87.29%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.259614 Test loss=0.406364 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.23797796666622162
[5/24] Train loss=0.2444680631160736
[10/24] Train loss=0.2647549510002136
[15/24] Train loss=0.23027317225933075
[20/24] Train loss=0.24106916785240173
Test set avg_accuracy=82.92% avg_sensitivity=58.53%, avg_specificity=91.03% avg_auc=87.28%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.259845 Test loss=0.406306 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.24143634736537933
[5/24] Train loss=0.24730703234672546
[10/24] Train loss=0.2653394341468811
[15/24] Train loss=0.23176175355911255
[20/24] Train loss=0.23248806595802307
Test set avg_accuracy=83.02% avg_sensitivity=59.94%, avg_specificity=90.70% avg_auc=87.32%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.260295 Test loss=0.405190 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.23756489157676697
[5/24] Train loss=0.24167965352535248
[10/24] Train loss=0.26688557863235474
[15/24] Train loss=0.23002269864082336
[20/24] Train loss=0.23593221604824066
Test set avg_accuracy=82.72% avg_sensitivity=60.46%, avg_specificity=90.13% avg_auc=87.34%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.260327 Test loss=0.405771 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.23856161534786224
[5/24] Train loss=0.2465246021747589
[10/24] Train loss=0.27308279275894165
[15/24] Train loss=0.23037230968475342
[20/24] Train loss=0.24015124142169952
Test set avg_accuracy=82.98% avg_sensitivity=65.00%, avg_specificity=88.96% avg_auc=87.42%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.261966 Test loss=0.406979 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.23558484017848969
[5/24] Train loss=0.23832228779792786
[10/24] Train loss=0.27556362748146057
[15/24] Train loss=0.22813694179058075
[20/24] Train loss=0.2401331216096878
Test set avg_accuracy=82.70% avg_sensitivity=65.57%, avg_specificity=88.39% avg_auc=87.43%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.260548 Test loss=0.408184 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.2381860613822937
[5/24] Train loss=0.23693212866783142
[10/24] Train loss=0.26756027340888977
[15/24] Train loss=0.22932137548923492
[20/24] Train loss=0.23707599937915802
Test set avg_accuracy=82.80% avg_sensitivity=64.06%, avg_specificity=89.03% avg_auc=87.41%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.259315 Test loss=0.406291 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.239420548081398
[5/24] Train loss=0.23681022226810455
[10/24] Train loss=0.2713305354118347
[15/24] Train loss=0.22273004055023193
[20/24] Train loss=0.24101445078849792
Test set avg_accuracy=82.94% avg_sensitivity=63.69%, avg_specificity=89.35% avg_auc=87.39%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.257670 Test loss=0.406330 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.23476074635982513
[5/24] Train loss=0.2393530011177063
[10/24] Train loss=0.26615580916404724
[15/24] Train loss=0.21923844516277313
[20/24] Train loss=0.23560869693756104
Test set avg_accuracy=82.89% avg_sensitivity=63.80%, avg_specificity=89.24% avg_auc=87.38%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.256891 Test loss=0.407253 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.24115696549415588
[5/24] Train loss=0.2339998483657837
[10/24] Train loss=0.26498672366142273
[15/24] Train loss=0.21947801113128662
[20/24] Train loss=0.2415015697479248
Test set avg_accuracy=82.79% avg_sensitivity=62.96%, avg_specificity=89.38% avg_auc=87.36%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.257189 Test loss=0.407129 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.23522071540355682
[5/24] Train loss=0.23430323600769043
[10/24] Train loss=0.26796889305114746
[15/24] Train loss=0.22368460893630981
[20/24] Train loss=0.2330581694841385
Test set avg_accuracy=82.71% avg_sensitivity=62.75%, avg_specificity=89.35% avg_auc=87.34%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.256683 Test loss=0.407457 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.2332039326429367
[5/24] Train loss=0.23147666454315186
[10/24] Train loss=0.26423582434654236
[15/24] Train loss=0.22889216244220734
[20/24] Train loss=0.24120503664016724
Test set avg_accuracy=82.98% avg_sensitivity=63.54%, avg_specificity=89.45% avg_auc=87.34%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.257584 Test loss=0.407720 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.23438219726085663
[5/24] Train loss=0.2371349185705185
[10/24] Train loss=0.2650887370109558
[15/24] Train loss=0.2255970686674118
[20/24] Train loss=0.2430519014596939
Test set avg_accuracy=82.99% avg_sensitivity=63.54%, avg_specificity=89.47% avg_auc=87.35%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.257930 Test loss=0.407760 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.2362966388463974
[5/24] Train loss=0.236700177192688
[10/24] Train loss=0.26346704363822937
[15/24] Train loss=0.22342783212661743
[20/24] Train loss=0.23502187430858612
Test set avg_accuracy=82.77% avg_sensitivity=62.60%, avg_specificity=89.48% avg_auc=87.34%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.257740 Test loss=0.407682 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.2360285222530365
[5/24] Train loss=0.2384525090456009
[10/24] Train loss=0.2669003903865814
[15/24] Train loss=0.22559624910354614
[20/24] Train loss=0.2392898052930832
Test set avg_accuracy=82.68% avg_sensitivity=62.18%, avg_specificity=89.50% avg_auc=87.33%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.257749 Test loss=0.407710 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.24356253445148468
[5/24] Train loss=0.23456791043281555
[10/24] Train loss=0.2670239508152008
[15/24] Train loss=0.22063980996608734
[20/24] Train loss=0.23811271786689758
Test set avg_accuracy=82.64% avg_sensitivity=62.08%, avg_specificity=89.48% avg_auc=87.33%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.257357 Test loss=0.407892 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.2353564351797104
[5/24] Train loss=0.23306937515735626
[10/24] Train loss=0.2716370224952698
[15/24] Train loss=0.22329601645469666
[20/24] Train loss=0.23815403878688812
Test set avg_accuracy=82.67% avg_sensitivity=62.13%, avg_specificity=89.50% avg_auc=87.32%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.257704 Test loss=0.407903 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.23713715374469757
[5/24] Train loss=0.23447541892528534
[10/24] Train loss=0.27040454745292664
[15/24] Train loss=0.2238498479127884
[20/24] Train loss=0.2345021665096283
Test set avg_accuracy=82.64% avg_sensitivity=62.02%, avg_specificity=89.50% avg_auc=87.32%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.257265 Test loss=0.407876 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.24155308306217194
[5/24] Train loss=0.23665212094783783
[10/24] Train loss=0.2692987024784088
[15/24] Train loss=0.22085662186145782
[20/24] Train loss=0.23114870488643646
Test set avg_accuracy=82.64% avg_sensitivity=62.02%, avg_specificity=89.50% avg_auc=87.32%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.257317 Test loss=0.407879 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.2364354133605957
[5/24] Train loss=0.2303042858839035
[10/24] Train loss=0.26576125621795654
[15/24] Train loss=0.21892285346984863
[20/24] Train loss=0.2314789742231369
Test set avg_accuracy=82.64% avg_sensitivity=62.02%, avg_specificity=89.50% avg_auc=87.32%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.255780 Test loss=0.407906 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.23756860196590424
[5/24] Train loss=0.2299143522977829
[10/24] Train loss=0.26135221123695374
[15/24] Train loss=0.22534331679344177
[20/24] Train loss=0.23329666256904602
Test set avg_accuracy=82.64% avg_sensitivity=62.02%, avg_specificity=89.50% avg_auc=87.32%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.256267 Test loss=0.407913 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.23689086735248566
[5/24] Train loss=0.23794963955879211
[10/24] Train loss=0.2686266005039215
[15/24] Train loss=0.225629061460495
[20/24] Train loss=0.2372356653213501
Test set avg_accuracy=82.64% avg_sensitivity=62.02%, avg_specificity=89.50% avg_auc=87.32%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.257672 Test loss=0.407913 Current lr=[4.388541022775342e-09]

Fold[2] Result: acc=83.57% sen=51.12%, spe=94.36%, auc=88.41%!
Fold[2] Avg_jsc=0.51%(±0.2986230644644288)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.6948080658912659
[5/24] Train loss=0.6859408617019653
[10/24] Train loss=0.6806246638298035
[15/24] Train loss=0.6714165210723877
[20/24] Train loss=0.6622331142425537
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.58%
Best model saved!! Metric=50.582223659244264!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.674974 Test loss=0.655453 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6518942713737488
[5/24] Train loss=0.6363680362701416
[10/24] Train loss=0.640082836151123
[15/24] Train loss=0.6211988925933838
[20/24] Train loss=0.6084839105606079
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.52%
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.622360 Test loss=0.602303 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.5901057124137878
[5/24] Train loss=0.566389262676239
[10/24] Train loss=0.6088138818740845
[15/24] Train loss=0.589215099811554
[20/24] Train loss=0.5904290676116943
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.49%
Best model saved!! Metric=51.48952581109022!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.574076 Test loss=0.594500 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.5714359879493713
[5/24] Train loss=0.549730122089386
[10/24] Train loss=0.6124875545501709
[15/24] Train loss=0.5859895944595337
[20/24] Train loss=0.5841080546379089
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.51%
Best model saved!! Metric=53.51494550188467!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.566797 Test loss=0.587480 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5683422088623047
[5/24] Train loss=0.5519360899925232
[10/24] Train loss=0.604993462562561
[15/24] Train loss=0.5840118527412415
[20/24] Train loss=0.5830951929092407
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.55%
Best model saved!! Metric=54.550941485786254!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.565939 Test loss=0.586773 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5672492980957031
[5/24] Train loss=0.5485128164291382
[10/24] Train loss=0.6068255305290222
[15/24] Train loss=0.5838617086410522
[20/24] Train loss=0.5828494429588318
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.16%
Best model saved!! Metric=56.16339224178274!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.564483 Test loss=0.586118 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5661439895629883
[5/24] Train loss=0.5479658842086792
[10/24] Train loss=0.6040235161781311
[15/24] Train loss=0.5818066596984863
[20/24] Train loss=0.5807763338088989
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.38%
Best model saved!! Metric=58.37687510104062!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.563418 Test loss=0.584637 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.5648945569992065
[5/24] Train loss=0.5463624596595764
[10/24] Train loss=0.6034775376319885
[15/24] Train loss=0.5802711844444275
[20/24] Train loss=0.5791289210319519
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.77%
Best model saved!! Metric=60.766581296212784!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.561964 Test loss=0.582918 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.5632337927818298
[5/24] Train loss=0.5444431304931641
[10/24] Train loss=0.6008468866348267
[15/24] Train loss=0.5775901079177856
[20/24] Train loss=0.5762205719947815
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.11%
Best model saved!! Metric=63.107575280573826!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.559970 Test loss=0.580335 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.5605416297912598
[5/24] Train loss=0.5415207147598267
[10/24] Train loss=0.5979369878768921
[15/24] Train loss=0.5734454393386841
[20/24] Train loss=0.5717068314552307
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.29%
Best model saved!! Metric=65.29299224858968!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.556965 Test loss=0.576193 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.5564824938774109
[5/24] Train loss=0.5372905731201172
[10/24] Train loss=0.5930158495903015
[15/24] Train loss=0.5665109753608704
[20/24] Train loss=0.5638166069984436
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=68.03%
Best model saved!! Metric=68.0344048601598!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.552085 Test loss=0.569377 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.5490425825119019
[5/24] Train loss=0.5312126874923706
[10/24] Train loss=0.5830481648445129
[15/24] Train loss=0.5546430349349976
[20/24] Train loss=0.5532711148262024
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=71.00%
Best model saved!! Metric=70.99693261973844!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.543794 Test loss=0.556992 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.5348490476608276
[5/24] Train loss=0.521309494972229
[10/24] Train loss=0.5707917809486389
[15/24] Train loss=0.541510283946991
[20/24] Train loss=0.5244407057762146
Test set avg_accuracy=72.45% avg_sensitivity=1.42%, avg_specificity=99.35% avg_auc=73.00%
Best model saved!! Metric=72.99678797212556!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.529946 Test loss=0.538794 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.5131847858428955
[5/24] Train loss=0.5136186480522156
[10/24] Train loss=0.5742539763450623
[15/24] Train loss=0.540534257888794
[20/24] Train loss=0.5202329754829407
Test set avg_accuracy=72.77% avg_sensitivity=10.09%, avg_specificity=96.52% avg_auc=74.49%
Best model saved!! Metric=74.49180188382243!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.522732 Test loss=0.534298 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.517345666885376
[5/24] Train loss=0.512677788734436
[10/24] Train loss=0.5613517761230469
[15/24] Train loss=0.5127338767051697
[20/24] Train loss=0.5253552794456482
Test set avg_accuracy=73.22% avg_sensitivity=11.61%, avg_specificity=96.55% avg_auc=76.08%
Best model saved!! Metric=76.08257251525183!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.515937 Test loss=0.522205 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.5030019879341125
[5/24] Train loss=0.4952287971973419
[10/24] Train loss=0.5542728900909424
[15/24] Train loss=0.49672943353652954
[20/24] Train loss=0.4971604347229004
Test set avg_accuracy=73.18% avg_sensitivity=17.73%, avg_specificity=94.18% avg_auc=77.81%
Best model saved!! Metric=77.8136087877679!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.502471 Test loss=0.506576 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.48893555998802185
[5/24] Train loss=0.4909801483154297
[10/24] Train loss=0.5552337765693665
[15/24] Train loss=0.5028057098388672
[20/24] Train loss=0.47461581230163574
Test set avg_accuracy=73.72% avg_sensitivity=14.22%, avg_specificity=96.27% avg_auc=79.53%
Best model saved!! Metric=79.53276268431935!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.491420 Test loss=0.490663 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.471648246049881
[5/24] Train loss=0.4759068489074707
[10/24] Train loss=0.5449573993682861
[15/24] Train loss=0.49470627307891846
[20/24] Train loss=0.45428627729415894
Test set avg_accuracy=73.79% avg_sensitivity=9.95%, avg_specificity=97.97% avg_auc=80.77%
Best model saved!! Metric=80.77074204225411!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.478013 Test loss=0.484524 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.45371103286743164
[5/24] Train loss=0.44931140542030334
[10/24] Train loss=0.526228666305542
[15/24] Train loss=0.46207118034362793
[20/24] Train loss=0.4352576732635498
Test set avg_accuracy=74.41% avg_sensitivity=14.93%, avg_specificity=96.95% avg_auc=82.28%
Best model saved!! Metric=82.27973572030257!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.460447 Test loss=0.467197 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.43852293491363525
[5/24] Train loss=0.4308178126811981
[10/24] Train loss=0.5130816102027893
[15/24] Train loss=0.43015819787979126
[20/24] Train loss=0.41586828231811523
Test set avg_accuracy=73.75% avg_sensitivity=11.18%, avg_specificity=97.45% avg_auc=83.47%
Best model saved!! Metric=83.47319339385844!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.442100 Test loss=0.461995 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.4303896725177765
[5/24] Train loss=0.4169556796550751
[10/24] Train loss=0.49744510650634766
[15/24] Train loss=0.4284481704235077
[20/24] Train loss=0.4027911126613617
Test set avg_accuracy=74.83% avg_sensitivity=15.92%, avg_specificity=97.15% avg_auc=83.96%
Best model saved!! Metric=83.9613748330171!!
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.430297 Test loss=0.452486 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.41871631145477295
[5/24] Train loss=0.4076533317565918
[10/24] Train loss=0.4859418570995331
[15/24] Train loss=0.42391595244407654
[20/24] Train loss=0.39500024914741516
Test set avg_accuracy=74.83% avg_sensitivity=15.64%, avg_specificity=97.25% avg_auc=84.12%
Best model saved!! Metric=84.11702417316872!!
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.422009 Test loss=0.451361 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.41344428062438965
[5/24] Train loss=0.39940428733825684
[10/24] Train loss=0.4780007600784302
[15/24] Train loss=0.42396554350852966
[20/24] Train loss=0.38536128401756287
Test set avg_accuracy=76.32% avg_sensitivity=22.37%, avg_specificity=96.75% avg_auc=84.62%
Best model saved!! Metric=84.6156372578216!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.416133 Test loss=0.441080 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.40807703137397766
[5/24] Train loss=0.39658674597740173
[10/24] Train loss=0.47334715723991394
[15/24] Train loss=0.42533329129219055
[20/24] Train loss=0.38122087717056274
Test set avg_accuracy=76.41% avg_sensitivity=22.04%, avg_specificity=97.00% avg_auc=84.71%
Best model saved!! Metric=84.71217677640031!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.410387 Test loss=0.441263 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.4001166522502899
[5/24] Train loss=0.39153096079826355
[10/24] Train loss=0.4596693813800812
[15/24] Train loss=0.42140650749206543
[20/24] Train loss=0.3768712878227234
Test set avg_accuracy=76.28% avg_sensitivity=21.37%, avg_specificity=97.07% avg_auc=84.54%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.405977 Test loss=0.445449 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.39868980646133423
[5/24] Train loss=0.3852517902851105
[10/24] Train loss=0.4550440013408661
[15/24] Train loss=0.421243816614151
[20/24] Train loss=0.38167864084243774
Test set avg_accuracy=77.01% avg_sensitivity=25.50%, avg_specificity=96.52% avg_auc=84.86%
Best model saved!! Metric=84.86476299063195!!
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.403457 Test loss=0.437224 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.38975363969802856
[5/24] Train loss=0.3746801018714905
[10/24] Train loss=0.4488055109977722
[15/24] Train loss=0.4094789922237396
[20/24] Train loss=0.36173033714294434
Test set avg_accuracy=76.48% avg_sensitivity=22.32%, avg_specificity=97.00% avg_auc=84.78%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.397132 Test loss=0.450005 Current lr=[0.000669125424222739]

[0/24] Train loss=0.3891621530056
[5/24] Train loss=0.37716028094291687
[10/24] Train loss=0.44173333048820496
[15/24] Train loss=0.42107725143432617
[20/24] Train loss=0.36942070722579956
Test set avg_accuracy=77.57% avg_sensitivity=27.77%, avg_specificity=96.43% avg_auc=85.02%
Best model saved!! Metric=85.01648131918623!!
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.395297 Test loss=0.436394 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.37639766931533813
[5/24] Train loss=0.3780340850353241
[10/24] Train loss=0.442274272441864
[15/24] Train loss=0.39829421043395996
[20/24] Train loss=0.3540545105934143
Test set avg_accuracy=77.57% avg_sensitivity=25.83%, avg_specificity=97.16% avg_auc=84.83%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.389401 Test loss=0.446421 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.3812822997570038
[5/24] Train loss=0.36821919679641724
[10/24] Train loss=0.4301155209541321
[15/24] Train loss=0.386279433965683
[20/24] Train loss=0.34691864252090454
Test set avg_accuracy=77.50% avg_sensitivity=25.92%, avg_specificity=97.04% avg_auc=84.76%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.386247 Test loss=0.448196 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.37877708673477173
[5/24] Train loss=0.3636852204799652
[10/24] Train loss=0.42675265669822693
[15/24] Train loss=0.3941137194633484
[20/24] Train loss=0.3471428155899048
Test set avg_accuracy=77.23% avg_sensitivity=23.22%, avg_specificity=97.68% avg_auc=84.57%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.385186 Test loss=0.458068 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.37741363048553467
[5/24] Train loss=0.37333962321281433
[10/24] Train loss=0.4242238700389862
[15/24] Train loss=0.39582639932632446
[20/24] Train loss=0.35161563754081726
Test set avg_accuracy=78.22% avg_sensitivity=27.06%, avg_specificity=97.59% avg_auc=85.05%
Best model saved!! Metric=85.04829103099713!!
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.382624 Test loss=0.451178 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.3708864450454712
[5/24] Train loss=0.370166540145874
[10/24] Train loss=0.42298245429992676
[15/24] Train loss=0.3959161043167114
[20/24] Train loss=0.3416610360145569
Test set avg_accuracy=79.19% avg_sensitivity=37.01%, avg_specificity=95.17% avg_auc=85.06%
Best model saved!! Metric=85.06210062368646!!
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.379518 Test loss=0.430826 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.3547540009021759
[5/24] Train loss=0.34731167554855347
[10/24] Train loss=0.4127254784107208
[15/24] Train loss=0.3793714940547943
[20/24] Train loss=0.33353108167648315
Test set avg_accuracy=79.67% avg_sensitivity=39.95%, avg_specificity=94.72% avg_auc=85.47%
Best model saved!! Metric=85.46576531350242!!
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.370549 Test loss=0.424435 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.3537152409553528
[5/24] Train loss=0.34896567463874817
[10/24] Train loss=0.40372544527053833
[15/24] Train loss=0.3672180473804474
[20/24] Train loss=0.31506890058517456
Test set avg_accuracy=79.78% avg_sensitivity=41.33%, avg_specificity=94.34% avg_auc=85.47%
Best model saved!! Metric=85.46744152407533!!
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.364979 Test loss=0.422650 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.3360288143157959
[5/24] Train loss=0.33745160698890686
[10/24] Train loss=0.4009990394115448
[15/24] Train loss=0.3541906177997589
[20/24] Train loss=0.3167317509651184
Test set avg_accuracy=79.31% avg_sensitivity=38.86%, avg_specificity=94.63% avg_auc=85.44%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.360860 Test loss=0.423929 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.3383711576461792
[5/24] Train loss=0.33012041449546814
[10/24] Train loss=0.40317657589912415
[15/24] Train loss=0.34923577308654785
[20/24] Train loss=0.3156145513057709
Test set avg_accuracy=79.26% avg_sensitivity=39.05%, avg_specificity=94.49% avg_auc=85.16%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.359702 Test loss=0.427624 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.3274742364883423
[5/24] Train loss=0.3263283967971802
[10/24] Train loss=0.39753952622413635
[15/24] Train loss=0.3567028045654297
[20/24] Train loss=0.31053048372268677
Test set avg_accuracy=79.65% avg_sensitivity=45.17%, avg_specificity=92.71% avg_auc=85.17%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.357011 Test loss=0.423083 Current lr=[0.000944367614404117]

[0/24] Train loss=0.3279136121273041
[5/24] Train loss=0.3166981041431427
[10/24] Train loss=0.391353964805603
[15/24] Train loss=0.3399389684200287
[20/24] Train loss=0.30751833319664
Test set avg_accuracy=79.15% avg_sensitivity=39.95%, avg_specificity=94.00% avg_auc=85.46%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.354155 Test loss=0.424356 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.3274623155593872
[5/24] Train loss=0.3159734010696411
[10/24] Train loss=0.386918842792511
[15/24] Train loss=0.3403077721595764
[20/24] Train loss=0.30967533588409424
Test set avg_accuracy=79.74% avg_sensitivity=45.92%, avg_specificity=92.55% avg_auc=85.45%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.352651 Test loss=0.419034 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.3200294077396393
[5/24] Train loss=0.3173251748085022
[10/24] Train loss=0.37999504804611206
[15/24] Train loss=0.3328407406806946
[20/24] Train loss=0.3164866268634796
Test set avg_accuracy=79.31% avg_sensitivity=39.57%, avg_specificity=94.36% avg_auc=85.56%
Best model saved!! Metric=85.55923745181958!!
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.351232 Test loss=0.422295 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.32002440094947815
[5/24] Train loss=0.3057802617549896
[10/24] Train loss=0.3792160749435425
[15/24] Train loss=0.33483824133872986
[20/24] Train loss=0.31285738945007324
Test set avg_accuracy=79.11% avg_sensitivity=36.07%, avg_specificity=95.42% avg_auc=85.36%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.346890 Test loss=0.427854 Current lr=[0.000989780311725182]

[0/24] Train loss=0.32950690388679504
[5/24] Train loss=0.3034690320491791
[10/24] Train loss=0.3770906925201416
[15/24] Train loss=0.34137338399887085
[20/24] Train loss=0.3077656030654907
Test set avg_accuracy=78.52% avg_sensitivity=33.03%, avg_specificity=95.75% avg_auc=85.18%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.348011 Test loss=0.435691 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.33156755566596985
[5/24] Train loss=0.31173810362815857
[10/24] Train loss=0.3801991045475006
[15/24] Train loss=0.3551099896430969
[20/24] Train loss=0.31061065196990967
Test set avg_accuracy=78.14% avg_sensitivity=28.25%, avg_specificity=97.04% avg_auc=84.93%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.350892 Test loss=0.455565 Current lr=[0.000998924125869967]

[0/24] Train loss=0.3503950834274292
[5/24] Train loss=0.32708674669265747
[10/24] Train loss=0.3805232644081116
[15/24] Train loss=0.34107497334480286
[20/24] Train loss=0.3073083460330963
Test set avg_accuracy=80.34% avg_sensitivity=47.49%, avg_specificity=92.78% avg_auc=85.60%
Best model saved!! Metric=85.59969624001295!!
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.349342 Test loss=0.417434 Current lr=[0.000999999611458977]

[0/24] Train loss=0.320233553647995
[5/24] Train loss=0.3026084303855896
[10/24] Train loss=0.3759758770465851
[15/24] Train loss=0.3354625999927521
[20/24] Train loss=0.29742223024368286
Test set avg_accuracy=80.78% avg_sensitivity=51.23%, avg_specificity=91.97% avg_auc=85.61%
Best model saved!! Metric=85.6138759604176!!
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.341772 Test loss=0.416183 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.31308335065841675
[5/24] Train loss=0.29945218563079834
[10/24] Train loss=0.3707607388496399
[15/24] Train loss=0.3272683322429657
[20/24] Train loss=0.2969042658805847
Test set avg_accuracy=79.96% avg_sensitivity=45.73%, avg_specificity=92.93% avg_auc=85.26%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.337008 Test loss=0.425068 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.3144635558128357
[5/24] Train loss=0.2986733913421631
[10/24] Train loss=0.3744097352027893
[15/24] Train loss=0.33956313133239746
[20/24] Train loss=0.3006959557533264
Test set avg_accuracy=78.91% avg_sensitivity=36.87%, avg_specificity=94.83% avg_auc=85.14%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.338193 Test loss=0.433316 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3224532902240753
[5/24] Train loss=0.3077947795391083
[10/24] Train loss=0.3706558048725128
[15/24] Train loss=0.3363097012042999
[20/24] Train loss=0.305448979139328
Test set avg_accuracy=78.85% avg_sensitivity=33.93%, avg_specificity=95.87% avg_auc=84.99%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.338652 Test loss=0.443324 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.33070045709609985
[5/24] Train loss=0.3110629618167877
[10/24] Train loss=0.37341609597206116
[15/24] Train loss=0.32863539457321167
[20/24] Train loss=0.30053961277008057
Test set avg_accuracy=79.92% avg_sensitivity=42.65%, avg_specificity=94.04% avg_auc=85.34%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.336916 Test loss=0.428260 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.3144387900829315
[5/24] Train loss=0.2980717420578003
[10/24] Train loss=0.36679238080978394
[15/24] Train loss=0.33241337537765503
[20/24] Train loss=0.2969460189342499
Test set avg_accuracy=80.73% avg_sensitivity=47.39%, avg_specificity=93.36% avg_auc=85.38%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.334933 Test loss=0.422685 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.3079345226287842
[5/24] Train loss=0.29262280464172363
[10/24] Train loss=0.35880783200263977
[15/24] Train loss=0.33023080229759216
[20/24] Train loss=0.2909524142742157
Test set avg_accuracy=80.47% avg_sensitivity=45.36%, avg_specificity=93.77% avg_auc=85.22%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.331336 Test loss=0.425720 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.3126780390739441
[5/24] Train loss=0.2987000644207001
[10/24] Train loss=0.3674185574054718
[15/24] Train loss=0.3306611180305481
[20/24] Train loss=0.29649651050567627
Test set avg_accuracy=80.01% avg_sensitivity=43.03%, avg_specificity=94.02% avg_auc=85.10%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.332454 Test loss=0.427030 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.31327494978904724
[5/24] Train loss=0.29123613238334656
[10/24] Train loss=0.3655727505683899
[15/24] Train loss=0.33336737751960754
[20/24] Train loss=0.29429924488067627
Test set avg_accuracy=79.67% avg_sensitivity=41.33%, avg_specificity=94.20% avg_auc=85.20%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.331730 Test loss=0.428363 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.31353405117988586
[5/24] Train loss=0.29387837648391724
[10/24] Train loss=0.37002500891685486
[15/24] Train loss=0.3329352140426636
[20/24] Train loss=0.2896408140659332
Test set avg_accuracy=80.51% avg_sensitivity=44.83%, avg_specificity=94.02% avg_auc=85.11%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.331770 Test loss=0.426524 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.31207507848739624
[5/24] Train loss=0.2946917712688446
[10/24] Train loss=0.3725263774394989
[15/24] Train loss=0.33707353472709656
[20/24] Train loss=0.2961335778236389
Test set avg_accuracy=80.00% avg_sensitivity=43.41%, avg_specificity=93.86% avg_auc=84.97%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.331159 Test loss=0.431601 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.3129066526889801
[5/24] Train loss=0.2955256998538971
[10/24] Train loss=0.3652149438858032
[15/24] Train loss=0.3328666687011719
[20/24] Train loss=0.29487937688827515
Test set avg_accuracy=80.35% avg_sensitivity=47.54%, avg_specificity=92.78% avg_auc=84.92%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.328106 Test loss=0.428632 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.3074490427970886
[5/24] Train loss=0.2969549596309662
[10/24] Train loss=0.3622496426105499
[15/24] Train loss=0.33102595806121826
[20/24] Train loss=0.29236987233161926
Test set avg_accuracy=80.29% avg_sensitivity=45.88%, avg_specificity=93.32% avg_auc=84.82%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.327667 Test loss=0.431201 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.30183321237564087
[5/24] Train loss=0.2881366014480591
[10/24] Train loss=0.3644135892391205
[15/24] Train loss=0.3311263620853424
[20/24] Train loss=0.28902754187583923
Test set avg_accuracy=80.22% avg_sensitivity=48.58%, avg_specificity=92.21% avg_auc=84.93%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.325687 Test loss=0.428219 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.3035173714160919
[5/24] Train loss=0.28689831495285034
[10/24] Train loss=0.36443865299224854
[15/24] Train loss=0.33246591687202454
[20/24] Train loss=0.29426270723342896
Test set avg_accuracy=80.20% avg_sensitivity=46.78%, avg_specificity=92.85% avg_auc=85.12%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.325429 Test loss=0.426348 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.30652549862861633
[5/24] Train loss=0.2858321964740753
[10/24] Train loss=0.35600385069847107
[15/24] Train loss=0.3280235528945923
[20/24] Train loss=0.29271531105041504
Test set avg_accuracy=80.49% avg_sensitivity=46.97%, avg_specificity=93.20% avg_auc=84.77%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.324509 Test loss=0.432100 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.2994975745677948
[5/24] Train loss=0.2853497862815857
[10/24] Train loss=0.3537415862083435
[15/24] Train loss=0.3254099190235138
[20/24] Train loss=0.29444006085395813
Test set avg_accuracy=80.29% avg_sensitivity=51.09%, avg_specificity=91.35% avg_auc=84.63%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.324190 Test loss=0.432069 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.3006031811237335
[5/24] Train loss=0.2852100729942322
[10/24] Train loss=0.3466539978981018
[15/24] Train loss=0.32872968912124634
[20/24] Train loss=0.2931708097457886
Test set avg_accuracy=80.08% avg_sensitivity=47.63%, avg_specificity=92.37% avg_auc=84.50%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.323109 Test loss=0.436472 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.30097490549087524
[5/24] Train loss=0.2884381115436554
[10/24] Train loss=0.3498643934726715
[15/24] Train loss=0.32479289174079895
[20/24] Train loss=0.2926461696624756
Test set avg_accuracy=79.99% avg_sensitivity=45.83%, avg_specificity=92.93% avg_auc=84.38%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.322754 Test loss=0.438851 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.30251002311706543
[5/24] Train loss=0.29595574736595154
[10/24] Train loss=0.3527567386627197
[15/24] Train loss=0.3261973261833191
[20/24] Train loss=0.288826584815979
Test set avg_accuracy=80.12% avg_sensitivity=47.39%, avg_specificity=92.51% avg_auc=84.36%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.323679 Test loss=0.437892 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.30865970253944397
[5/24] Train loss=0.2938373386859894
[10/24] Train loss=0.3533565104007721
[15/24] Train loss=0.3229674696922302
[20/24] Train loss=0.2861059308052063
Test set avg_accuracy=80.35% avg_sensitivity=49.24%, avg_specificity=92.14% avg_auc=84.64%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.322302 Test loss=0.435217 Current lr=[0.000904142181093812]

[0/24] Train loss=0.2977401912212372
[5/24] Train loss=0.2926025092601776
[10/24] Train loss=0.35077059268951416
[15/24] Train loss=0.3242977261543274
[20/24] Train loss=0.2881830334663391
Test set avg_accuracy=80.27% avg_sensitivity=50.85%, avg_specificity=91.42% avg_auc=84.76%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.320514 Test loss=0.433177 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.29711204767227173
[5/24] Train loss=0.2889799177646637
[10/24] Train loss=0.35058218240737915
[15/24] Train loss=0.32686010003089905
[20/24] Train loss=0.28201526403427124
Test set avg_accuracy=80.51% avg_sensitivity=49.86%, avg_specificity=92.12% avg_auc=84.45%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.318175 Test loss=0.441359 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.2919600307941437
[5/24] Train loss=0.28942281007766724
[10/24] Train loss=0.3505321741104126
[15/24] Train loss=0.3213514983654022
[20/24] Train loss=0.280816912651062
Test set avg_accuracy=80.43% avg_sensitivity=51.80%, avg_specificity=91.27% avg_auc=84.46%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.317439 Test loss=0.439726 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.28971928358078003
[5/24] Train loss=0.2946259677410126
[10/24] Train loss=0.349197119474411
[15/24] Train loss=0.31786444783210754
[20/24] Train loss=0.28321027755737305
Test set avg_accuracy=80.56% avg_sensitivity=54.45%, avg_specificity=90.45% avg_auc=84.62%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.317090 Test loss=0.436723 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.2906109094619751
[5/24] Train loss=0.2874828577041626
[10/24] Train loss=0.3479103147983551
[15/24] Train loss=0.3162962794303894
[20/24] Train loss=0.2876138389110565
Test set avg_accuracy=80.52% avg_sensitivity=53.79%, avg_specificity=90.65% avg_auc=84.33%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.316924 Test loss=0.444251 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.2984970211982727
[5/24] Train loss=0.29178836941719055
[10/24] Train loss=0.3420473337173462
[15/24] Train loss=0.31807631254196167
[20/24] Train loss=0.2838401198387146
Test set avg_accuracy=80.43% avg_sensitivity=49.05%, avg_specificity=92.32% avg_auc=84.08%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.317309 Test loss=0.452135 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.2990530729293823
[5/24] Train loss=0.2938850522041321
[10/24] Train loss=0.34527429938316345
[15/24] Train loss=0.3123871386051178
[20/24] Train loss=0.28131017088890076
Test set avg_accuracy=80.78% avg_sensitivity=50.71%, avg_specificity=92.17% avg_auc=84.07%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.317709 Test loss=0.449373 Current lr=[0.000834102481048427]

[0/24] Train loss=0.2984701693058014
[5/24] Train loss=0.304081529378891
[10/24] Train loss=0.35350820422172546
[15/24] Train loss=0.3136056959629059
[20/24] Train loss=0.2875608503818512
Test set avg_accuracy=80.66% avg_sensitivity=53.84%, avg_specificity=90.83% avg_auc=84.07%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.319879 Test loss=0.448493 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.28933945298194885
[5/24] Train loss=0.3005993366241455
[10/24] Train loss=0.3541322946548462
[15/24] Train loss=0.31174877285957336
[20/24] Train loss=0.2827059030532837
Test set avg_accuracy=81.41% avg_sensitivity=54.31%, avg_specificity=91.67% avg_auc=84.35%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.318368 Test loss=0.441234 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.29576075077056885
[5/24] Train loss=0.2939770221710205
[10/24] Train loss=0.3498612642288208
[15/24] Train loss=0.315988689661026
[20/24] Train loss=0.28957095742225647
Test set avg_accuracy=81.15% avg_sensitivity=53.60%, avg_specificity=91.58% avg_auc=84.25%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.318395 Test loss=0.443278 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.2879554331302643
[5/24] Train loss=0.2956021726131439
[10/24] Train loss=0.35262396931648254
[15/24] Train loss=0.3137218654155731
[20/24] Train loss=0.28576576709747314
Test set avg_accuracy=81.25% avg_sensitivity=53.89%, avg_specificity=91.62% avg_auc=84.41%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.317577 Test loss=0.442627 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.2873319983482361
[5/24] Train loss=0.29734963178634644
[10/24] Train loss=0.3491275906562805
[15/24] Train loss=0.31100228428840637
[20/24] Train loss=0.28804799914360046
Test set avg_accuracy=81.55% avg_sensitivity=53.41%, avg_specificity=92.21% avg_auc=84.43%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.317770 Test loss=0.445137 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.2919687330722809
[5/24] Train loss=0.3037818372249603
[10/24] Train loss=0.35171422362327576
[15/24] Train loss=0.3158969283103943
[20/24] Train loss=0.2887997329235077
Test set avg_accuracy=80.13% avg_sensitivity=42.70%, avg_specificity=94.31% avg_auc=84.20%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.320934 Test loss=0.457112 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.30440205335617065
[5/24] Train loss=0.306277871131897
[10/24] Train loss=0.3613542318344116
[15/24] Train loss=0.3171766698360443
[20/24] Train loss=0.3126707971096039
Test set avg_accuracy=81.32% avg_sensitivity=49.34%, avg_specificity=93.43% avg_auc=84.87%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.333109 Test loss=0.430864 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.2972392439842224
[5/24] Train loss=0.29723674058914185
[10/24] Train loss=0.36846399307250977
[15/24] Train loss=0.3301140069961548
[20/24] Train loss=0.3011114001274109
Test set avg_accuracy=82.15% avg_sensitivity=65.73%, avg_specificity=88.37% avg_auc=84.93%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.325198 Test loss=0.429191 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.296324223279953
[5/24] Train loss=0.2824171781539917
[10/24] Train loss=0.36274585127830505
[15/24] Train loss=0.3192881643772125
[20/24] Train loss=0.2987729012966156
Test set avg_accuracy=81.69% avg_sensitivity=59.81%, avg_specificity=89.98% avg_auc=84.85%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.318616 Test loss=0.430653 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.2911653220653534
[5/24] Train loss=0.28099218010902405
[10/24] Train loss=0.3601950407028198
[15/24] Train loss=0.3166492283344269
[20/24] Train loss=0.2970721423625946
Test set avg_accuracy=81.48% avg_sensitivity=55.88%, avg_specificity=91.18% avg_auc=84.85%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.316542 Test loss=0.431467 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.2913338243961334
[5/24] Train loss=0.27802351117134094
[10/24] Train loss=0.36753684282302856
[15/24] Train loss=0.31023433804512024
[20/24] Train loss=0.294109046459198
Test set avg_accuracy=81.43% avg_sensitivity=55.64%, avg_specificity=91.20% avg_auc=84.54%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.315360 Test loss=0.434662 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.2908950448036194
[5/24] Train loss=0.2788189649581909
[10/24] Train loss=0.35531455278396606
[15/24] Train loss=0.3164011240005493
[20/24] Train loss=0.28860145807266235
Test set avg_accuracy=81.48% avg_sensitivity=59.00%, avg_specificity=90.00% avg_auc=84.31%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.312738 Test loss=0.441464 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.2850911021232605
[5/24] Train loss=0.27655941247940063
[10/24] Train loss=0.3544110655784607
[15/24] Train loss=0.30953580141067505
[20/24] Train loss=0.28472819924354553
Test set avg_accuracy=80.92% avg_sensitivity=53.84%, avg_specificity=91.18% avg_auc=84.20%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.311887 Test loss=0.442398 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.2872803509235382
[5/24] Train loss=0.27829763293266296
[10/24] Train loss=0.34694987535476685
[15/24] Train loss=0.3124209940433502
[20/24] Train loss=0.2841463088989258
Test set avg_accuracy=81.28% avg_sensitivity=54.08%, avg_specificity=91.58% avg_auc=83.95%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.310459 Test loss=0.447355 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.28681549429893494
[5/24] Train loss=0.27927064895629883
[10/24] Train loss=0.3524816334247589
[15/24] Train loss=0.3097890615463257
[20/24] Train loss=0.2826673090457916
Test set avg_accuracy=81.09% avg_sensitivity=54.79%, avg_specificity=91.06% avg_auc=83.95%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.310302 Test loss=0.447029 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.2803229093551636
[5/24] Train loss=0.2816784679889679
[10/24] Train loss=0.3468785285949707
[15/24] Train loss=0.31200334429740906
[20/24] Train loss=0.28913912177085876
Test set avg_accuracy=81.24% avg_sensitivity=56.87%, avg_specificity=90.47% avg_auc=83.90%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.308954 Test loss=0.449570 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.2857566177845001
[5/24] Train loss=0.2776833474636078
[10/24] Train loss=0.347514808177948
[15/24] Train loss=0.30842599272727966
[20/24] Train loss=0.2898140847682953
Test set avg_accuracy=81.52% avg_sensitivity=60.62%, avg_specificity=89.44% avg_auc=83.66%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.308836 Test loss=0.455097 Current lr=[0.00061065423442182]

[0/24] Train loss=0.28218138217926025
[5/24] Train loss=0.2847043573856354
[10/24] Train loss=0.35107505321502686
[15/24] Train loss=0.31212928891181946
[20/24] Train loss=0.28352493047714233
Test set avg_accuracy=81.29% avg_sensitivity=62.32%, avg_specificity=88.47% avg_auc=83.91%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.307106 Test loss=0.452969 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.2863789498806
[5/24] Train loss=0.28825923800468445
[10/24] Train loss=0.35355743765830994
[15/24] Train loss=0.3183816969394684
[20/24] Train loss=0.2872561514377594
Test set avg_accuracy=80.59% avg_sensitivity=55.26%, avg_specificity=90.18% avg_auc=83.93%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.310939 Test loss=0.448046 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.28910988569259644
[5/24] Train loss=0.2865086793899536
[10/24] Train loss=0.36766454577445984
[15/24] Train loss=0.3142293393611908
[20/24] Train loss=0.2859971523284912
Test set avg_accuracy=80.53% avg_sensitivity=55.64%, avg_specificity=89.96% avg_auc=84.09%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.311685 Test loss=0.444787 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.2872704863548279
[5/24] Train loss=0.27464157342910767
[10/24] Train loss=0.35629013180732727
[15/24] Train loss=0.3137439787387848
[20/24] Train loss=0.2896210551261902
Test set avg_accuracy=81.02% avg_sensitivity=60.24%, avg_specificity=88.89% avg_auc=84.37%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.309327 Test loss=0.440459 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.2916797697544098
[5/24] Train loss=0.28185051679611206
[10/24] Train loss=0.3526807427406311
[15/24] Train loss=0.3131025731563568
[20/24] Train loss=0.28627631068229675
Test set avg_accuracy=81.73% avg_sensitivity=63.32%, avg_specificity=88.71% avg_auc=84.42%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.307203 Test loss=0.442604 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.2932390868663788
[5/24] Train loss=0.2792418897151947
[10/24] Train loss=0.35124850273132324
[15/24] Train loss=0.31318530440330505
[20/24] Train loss=0.2838079333305359
Test set avg_accuracy=81.16% avg_sensitivity=59.57%, avg_specificity=89.34% avg_auc=84.14%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.307037 Test loss=0.443925 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.2927996814250946
[5/24] Train loss=0.2806813418865204
[10/24] Train loss=0.3471538722515106
[15/24] Train loss=0.31298932433128357
[20/24] Train loss=0.28776660561561584
Test set avg_accuracy=80.94% avg_sensitivity=60.95%, avg_specificity=88.51% avg_auc=84.14%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.306310 Test loss=0.446333 Current lr=[0.000506858408304961]

[0/24] Train loss=0.29096531867980957
[5/24] Train loss=0.28382349014282227
[10/24] Train loss=0.36024904251098633
[15/24] Train loss=0.31224414706230164
[20/24] Train loss=0.2892138361930847
Test set avg_accuracy=81.32% avg_sensitivity=62.65%, avg_specificity=88.38% avg_auc=84.13%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.308290 Test loss=0.443836 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.2943267524242401
[5/24] Train loss=0.28418299555778503
[10/24] Train loss=0.3612552285194397
[15/24] Train loss=0.3066377341747284
[20/24] Train loss=0.2909771203994751
Test set avg_accuracy=81.25% avg_sensitivity=61.66%, avg_specificity=88.67% avg_auc=84.12%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.309468 Test loss=0.441575 Current lr=[0.000476946990416354]

[0/24] Train loss=0.2902068495750427
[5/24] Train loss=0.28255540132522583
[10/24] Train loss=0.382739782333374
[15/24] Train loss=0.31700995564460754
[20/24] Train loss=0.2878875136375427
Test set avg_accuracy=81.90% avg_sensitivity=55.97%, avg_specificity=91.72% avg_auc=84.00%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.314073 Test loss=0.437317 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.2958146035671234
[5/24] Train loss=0.2871580421924591
[10/24] Train loss=0.38724640011787415
[15/24] Train loss=0.34303775429725647
[20/24] Train loss=0.28506579995155334
Test set avg_accuracy=81.16% avg_sensitivity=46.68%, avg_specificity=94.22% avg_auc=83.63%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.314346 Test loss=0.450885 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.302272230386734
[5/24] Train loss=0.2838258147239685
[10/24] Train loss=0.35603684186935425
[15/24] Train loss=0.3251252770423889
[20/24] Train loss=0.2783099114894867
Test set avg_accuracy=81.55% avg_sensitivity=52.75%, avg_specificity=92.46% avg_auc=83.98%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.308024 Test loss=0.444520 Current lr=[0.000432267999769856]

[0/24] Train loss=0.2866145670413971
[5/24] Train loss=0.279207706451416
[10/24] Train loss=0.3587959408760071
[15/24] Train loss=0.32020577788352966
[20/24] Train loss=0.2760579586029053
Test set avg_accuracy=81.32% avg_sensitivity=52.27%, avg_specificity=92.32% avg_auc=83.79%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.305536 Test loss=0.448353 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.28415459394454956
[5/24] Train loss=0.28282541036605835
[10/24] Train loss=0.3621044456958771
[15/24] Train loss=0.31961655616760254
[20/24] Train loss=0.27903100848197937
Test set avg_accuracy=81.25% avg_sensitivity=50.81%, avg_specificity=92.78% avg_auc=83.66%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.304099 Test loss=0.452571 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.29403650760650635
[5/24] Train loss=0.2802090346813202
[10/24] Train loss=0.3575228750705719
[15/24] Train loss=0.31691768765449524
[20/24] Train loss=0.27623650431632996
Test set avg_accuracy=81.41% avg_sensitivity=52.61%, avg_specificity=92.32% avg_auc=83.72%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.304312 Test loss=0.452940 Current lr=[0.000388134363466264]

[0/24] Train loss=0.28991764783859253
[5/24] Train loss=0.28103333711624146
[10/24] Train loss=0.3478517532348633
[15/24] Train loss=0.31096282601356506
[20/24] Train loss=0.2760767340660095
Test set avg_accuracy=81.73% avg_sensitivity=54.64%, avg_specificity=91.99% avg_auc=83.84%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.302440 Test loss=0.450941 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.2820061445236206
[5/24] Train loss=0.2874585688114166
[10/24] Train loss=0.34958386421203613
[15/24] Train loss=0.3053945004940033
[20/24] Train loss=0.2849677503108978
Test set avg_accuracy=81.78% avg_sensitivity=58.10%, avg_specificity=90.75% avg_auc=83.95%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.301273 Test loss=0.450426 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.2832348346710205
[5/24] Train loss=0.27201876044273376
[10/24] Train loss=0.3526598811149597
[15/24] Train loss=0.31641891598701477
[20/24] Train loss=0.2768959105014801
Test set avg_accuracy=81.60% avg_sensitivity=56.92%, avg_specificity=90.95% avg_auc=83.86%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.302704 Test loss=0.454063 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.28738686442375183
[5/24] Train loss=0.27903690934181213
[10/24] Train loss=0.3607933223247528
[15/24] Train loss=0.3099557161331177
[20/24] Train loss=0.27921876311302185
Test set avg_accuracy=81.56% avg_sensitivity=57.91%, avg_specificity=90.52% avg_auc=83.79%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.301008 Test loss=0.456190 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.2836047112941742
[5/24] Train loss=0.2748417854309082
[10/24] Train loss=0.3576337993144989
[15/24] Train loss=0.3163550794124603
[20/24] Train loss=0.2772296369075775
Test set avg_accuracy=81.58% avg_sensitivity=60.19%, avg_specificity=89.68% avg_auc=83.86%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.301889 Test loss=0.454926 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.28973639011383057
[5/24] Train loss=0.2785263657569885
[10/24] Train loss=0.3636329174041748
[15/24] Train loss=0.3195556700229645
[20/24] Train loss=0.27881190180778503
Test set avg_accuracy=81.65% avg_sensitivity=64.12%, avg_specificity=88.29% avg_auc=83.93%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.303279 Test loss=0.455708 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.2917490303516388
[5/24] Train loss=0.2850412428379059
[10/24] Train loss=0.36366018652915955
[15/24] Train loss=0.32804492115974426
[20/24] Train loss=0.274007111787796
Test set avg_accuracy=80.87% avg_sensitivity=67.58%, avg_specificity=85.91% avg_auc=84.27%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.304844 Test loss=0.454426 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2982674539089203
[5/24] Train loss=0.2948134243488312
[10/24] Train loss=0.3587089776992798
[15/24] Train loss=0.311590313911438
[20/24] Train loss=0.29818961024284363
Test set avg_accuracy=80.38% avg_sensitivity=72.65%, avg_specificity=83.30% avg_auc=84.74%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.309753 Test loss=0.456134 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.30958712100982666
[5/24] Train loss=0.2794727385044098
[10/24] Train loss=0.3386381268501282
[15/24] Train loss=0.30475914478302
[20/24] Train loss=0.3153216540813446
Test set avg_accuracy=82.30% avg_sensitivity=62.46%, avg_specificity=89.82% avg_auc=84.70%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.311255 Test loss=0.437181 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.286311537027359
[5/24] Train loss=0.27254626154899597
[10/24] Train loss=0.34612056612968445
[15/24] Train loss=0.2917234003543854
[20/24] Train loss=0.2862243056297302
Test set avg_accuracy=81.65% avg_sensitivity=57.68%, avg_specificity=90.74% avg_auc=84.46%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.301764 Test loss=0.444995 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.284704327583313
[5/24] Train loss=0.27350014448165894
[10/24] Train loss=0.33997607231140137
[15/24] Train loss=0.3002879321575165
[20/24] Train loss=0.2826336622238159
Test set avg_accuracy=81.84% avg_sensitivity=60.19%, avg_specificity=90.04% avg_auc=84.31%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.296460 Test loss=0.449418 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.27497538924217224
[5/24] Train loss=0.2716042697429657
[10/24] Train loss=0.3370239734649658
[15/24] Train loss=0.2910735309123993
[20/24] Train loss=0.28041180968284607
Test set avg_accuracy=81.43% avg_sensitivity=59.67%, avg_specificity=89.68% avg_auc=84.23%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.294666 Test loss=0.452291 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.28329071402549744
[5/24] Train loss=0.26773956418037415
[10/24] Train loss=0.33542415499687195
[15/24] Train loss=0.2966698408126831
[20/24] Train loss=0.27923476696014404
Test set avg_accuracy=81.41% avg_sensitivity=60.81%, avg_specificity=89.21% avg_auc=84.14%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.293680 Test loss=0.454867 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.2769355773925781
[5/24] Train loss=0.27240321040153503
[10/24] Train loss=0.33768075704574585
[15/24] Train loss=0.2984914183616638
[20/24] Train loss=0.2783319354057312
Test set avg_accuracy=81.39% avg_sensitivity=59.86%, avg_specificity=89.55% avg_auc=84.11%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.292518 Test loss=0.455951 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.28040429949760437
[5/24] Train loss=0.2662791311740875
[10/24] Train loss=0.34349966049194336
[15/24] Train loss=0.29469045996665955
[20/24] Train loss=0.2752284109592438
Test set avg_accuracy=81.46% avg_sensitivity=58.29%, avg_specificity=90.23% avg_auc=84.05%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.292442 Test loss=0.457609 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2754019498825073
[5/24] Train loss=0.2674902081489563
[10/24] Train loss=0.337758332490921
[15/24] Train loss=0.29619669914245605
[20/24] Train loss=0.2743937373161316
Test set avg_accuracy=81.38% avg_sensitivity=59.24%, avg_specificity=89.77% avg_auc=84.01%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.290610 Test loss=0.459162 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.27639275789260864
[5/24] Train loss=0.2670535445213318
[10/24] Train loss=0.3351667523384094
[15/24] Train loss=0.2957153916358948
[20/24] Train loss=0.27712923288345337
Test set avg_accuracy=81.03% avg_sensitivity=58.44%, avg_specificity=89.59% avg_auc=83.91%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.290854 Test loss=0.460978 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.2784770727157593
[5/24] Train loss=0.26503729820251465
[10/24] Train loss=0.33372899889945984
[15/24] Train loss=0.2901497185230255
[20/24] Train loss=0.2746301293373108
Test set avg_accuracy=81.21% avg_sensitivity=58.86%, avg_specificity=89.68% avg_auc=83.95%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.290271 Test loss=0.461179 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.28053754568099976
[5/24] Train loss=0.26896053552627563
[10/24] Train loss=0.34037327766418457
[15/24] Train loss=0.29542276263237
[20/24] Train loss=0.27496716380119324
Test set avg_accuracy=81.25% avg_sensitivity=59.10%, avg_specificity=89.64% avg_auc=83.94%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.290048 Test loss=0.461499 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.27973052859306335
[5/24] Train loss=0.26668858528137207
[10/24] Train loss=0.33840513229370117
[15/24] Train loss=0.2933308482170105
[20/24] Train loss=0.27464237809181213
Test set avg_accuracy=81.26% avg_sensitivity=58.67%, avg_specificity=89.82% avg_auc=83.95%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.290395 Test loss=0.461776 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.2768632173538208
[5/24] Train loss=0.2663261294364929
[10/24] Train loss=0.33576667308807373
[15/24] Train loss=0.2954949140548706
[20/24] Train loss=0.27136436104774475
Test set avg_accuracy=81.08% avg_sensitivity=58.67%, avg_specificity=89.57% avg_auc=83.92%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.290702 Test loss=0.461666 Current lr=[0.000123057953306828]

[0/24] Train loss=0.27760741114616394
[5/24] Train loss=0.2666475772857666
[10/24] Train loss=0.3339816927909851
[15/24] Train loss=0.2931097149848938
[20/24] Train loss=0.27408042550086975
Test set avg_accuracy=81.28% avg_sensitivity=57.82%, avg_specificity=90.16% avg_auc=83.88%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.288894 Test loss=0.463469 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.27474433183670044
[5/24] Train loss=0.26245322823524475
[10/24] Train loss=0.33443745970726013
[15/24] Train loss=0.29021456837654114
[20/24] Train loss=0.27135220170021057
Test set avg_accuracy=81.15% avg_sensitivity=58.01%, avg_specificity=89.91% avg_auc=83.90%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.288372 Test loss=0.463097 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.2747671604156494
[5/24] Train loss=0.2639135718345642
[10/24] Train loss=0.3343784809112549
[15/24] Train loss=0.2913855314254761
[20/24] Train loss=0.2729369103908539
Test set avg_accuracy=81.24% avg_sensitivity=58.48%, avg_specificity=89.86% avg_auc=83.91%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.288496 Test loss=0.463128 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.2781178951263428
[5/24] Train loss=0.2608010470867157
[10/24] Train loss=0.33623942732810974
[15/24] Train loss=0.2926550507545471
[20/24] Train loss=0.27651479840278625
Test set avg_accuracy=81.13% avg_sensitivity=58.15%, avg_specificity=89.84% avg_auc=83.87%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.289075 Test loss=0.463659 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.27808451652526855
[5/24] Train loss=0.26841577887535095
[10/24] Train loss=0.3369036614894867
[15/24] Train loss=0.29383140802383423
[20/24] Train loss=0.28085964918136597
Test set avg_accuracy=81.33% avg_sensitivity=58.67%, avg_specificity=89.91% avg_auc=83.87%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.288733 Test loss=0.464258 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.2738053798675537
[5/24] Train loss=0.2627984881401062
[10/24] Train loss=0.3320622742176056
[15/24] Train loss=0.2943408191204071
[20/24] Train loss=0.27989649772644043
Test set avg_accuracy=81.15% avg_sensitivity=57.39%, avg_specificity=90.14% avg_auc=83.82%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.287673 Test loss=0.465147 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.2747541666030884
[5/24] Train loss=0.2654995024204254
[10/24] Train loss=0.3383314907550812
[15/24] Train loss=0.29031336307525635
[20/24] Train loss=0.2709950804710388
Test set avg_accuracy=81.03% avg_sensitivity=55.50%, avg_specificity=90.70% avg_auc=83.79%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.288912 Test loss=0.466482 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.27535387873649597
[5/24] Train loss=0.263232946395874
[10/24] Train loss=0.33757272362709045
[15/24] Train loss=0.2929518520832062
[20/24] Train loss=0.27446556091308594
Test set avg_accuracy=81.03% avg_sensitivity=54.74%, avg_specificity=90.99% avg_auc=83.77%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.287741 Test loss=0.466992 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.27664437890052795
[5/24] Train loss=0.2693597078323364
[10/24] Train loss=0.33551886677742004
[15/24] Train loss=0.29302459955215454
[20/24] Train loss=0.2715017795562744
Test set avg_accuracy=81.04% avg_sensitivity=54.98%, avg_specificity=90.92% avg_auc=83.78%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.289435 Test loss=0.466385 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.27648043632507324
[5/24] Train loss=0.26702162623405457
[10/24] Train loss=0.3392869532108307
[15/24] Train loss=0.2884153127670288
[20/24] Train loss=0.2690409719944
Test set avg_accuracy=80.96% avg_sensitivity=56.26%, avg_specificity=90.32% avg_auc=83.82%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.287790 Test loss=0.465759 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.2765020430088043
[5/24] Train loss=0.2621013820171356
[10/24] Train loss=0.33588096499443054
[15/24] Train loss=0.28570812940597534
[20/24] Train loss=0.2722175121307373
Test set avg_accuracy=81.05% avg_sensitivity=57.06%, avg_specificity=90.14% avg_auc=83.83%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.287070 Test loss=0.465242 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.27561530470848083
[5/24] Train loss=0.2620163857936859
[10/24] Train loss=0.3312833905220032
[15/24] Train loss=0.28922146558761597
[20/24] Train loss=0.27113234996795654
Test set avg_accuracy=81.17% avg_sensitivity=57.77%, avg_specificity=90.04% avg_auc=83.85%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.286739 Test loss=0.464937 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.2732268273830414
[5/24] Train loss=0.2629266381263733
[10/24] Train loss=0.33048704266548157
[15/24] Train loss=0.2942255735397339
[20/24] Train loss=0.2721165120601654
Test set avg_accuracy=81.12% avg_sensitivity=57.16%, avg_specificity=90.20% avg_auc=83.83%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.287150 Test loss=0.465468 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.2788769006729126
[5/24] Train loss=0.26202309131622314
[10/24] Train loss=0.3379243314266205
[15/24] Train loss=0.29264089465141296
[20/24] Train loss=0.26637858152389526
Test set avg_accuracy=81.20% avg_sensitivity=57.87%, avg_specificity=90.04% avg_auc=83.84%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.286965 Test loss=0.465374 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.2722150683403015
[5/24] Train loss=0.2619294822216034
[10/24] Train loss=0.33137425780296326
[15/24] Train loss=0.2921203672885895
[20/24] Train loss=0.2653445303440094
Test set avg_accuracy=81.24% avg_sensitivity=57.54%, avg_specificity=90.22% avg_auc=83.84%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.286461 Test loss=0.465329 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.27547645568847656
[5/24] Train loss=0.2668301463127136
[10/24] Train loss=0.3347133696079254
[15/24] Train loss=0.2932544946670532
[20/24] Train loss=0.27029019594192505
Test set avg_accuracy=81.24% avg_sensitivity=57.63%, avg_specificity=90.18% avg_auc=83.85%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.287192 Test loss=0.465205 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.2748557925224304
[5/24] Train loss=0.2676981985569
[10/24] Train loss=0.33167868852615356
[15/24] Train loss=0.2901306748390198
[20/24] Train loss=0.2776009440422058
Test set avg_accuracy=81.13% avg_sensitivity=57.16%, avg_specificity=90.22% avg_auc=83.84%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.287224 Test loss=0.465393 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.2725865840911865
[5/24] Train loss=0.26494351029396057
[10/24] Train loss=0.3322894275188446
[15/24] Train loss=0.2920500934123993
[20/24] Train loss=0.26879051327705383
Test set avg_accuracy=81.12% avg_sensitivity=57.58%, avg_specificity=90.04% avg_auc=83.85%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.286420 Test loss=0.465292 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.27461308240890503
[5/24] Train loss=0.2606569826602936
[10/24] Train loss=0.344630628824234
[15/24] Train loss=0.29379090666770935
[20/24] Train loss=0.2705010175704956
Test set avg_accuracy=81.12% avg_sensitivity=57.58%, avg_specificity=90.04% avg_auc=83.85%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.288223 Test loss=0.465343 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.2751828134059906
[5/24] Train loss=0.26234352588653564
[10/24] Train loss=0.33526045083999634
[15/24] Train loss=0.294237345457077
[20/24] Train loss=0.2697996199131012
Test set avg_accuracy=81.13% avg_sensitivity=57.58%, avg_specificity=90.05% avg_auc=83.84%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.287059 Test loss=0.465436 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.27073168754577637
[5/24] Train loss=0.2683607339859009
[10/24] Train loss=0.3370709717273712
[15/24] Train loss=0.29038748145103455
[20/24] Train loss=0.27560773491859436
Test set avg_accuracy=81.13% avg_sensitivity=57.58%, avg_specificity=90.05% avg_auc=83.84%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.286885 Test loss=0.465454 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.27279025316238403
[5/24] Train loss=0.2614617645740509
[10/24] Train loss=0.3386140465736389
[15/24] Train loss=0.2896333932876587
[20/24] Train loss=0.26981326937675476
Test set avg_accuracy=81.12% avg_sensitivity=57.58%, avg_specificity=90.04% avg_auc=83.84%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.286294 Test loss=0.465448 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.2767420709133148
[5/24] Train loss=0.260355144739151
[10/24] Train loss=0.338089257478714
[15/24] Train loss=0.2880219519138336
[20/24] Train loss=0.2695574164390564
Test set avg_accuracy=81.13% avg_sensitivity=57.58%, avg_specificity=90.05% avg_auc=83.84%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.286253 Test loss=0.465463 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.2738201916217804
[5/24] Train loss=0.2617710530757904
[10/24] Train loss=0.32965850830078125
[15/24] Train loss=0.29101985692977905
[20/24] Train loss=0.2690511643886566
Test set avg_accuracy=81.13% avg_sensitivity=57.58%, avg_specificity=90.05% avg_auc=83.84%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.285897 Test loss=0.465460 Current lr=[4.388541022775342e-09]

Fold[3] Result: acc=80.78% sen=51.23%, spe=91.97%, auc=85.61%!
Fold[3] Avg_jsc=0.45%(±0.3039560491174502)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.6989486217498779
[5/24] Train loss=0.6899828910827637
[10/24] Train loss=0.6831418871879578
[15/24] Train loss=0.6747219562530518
[20/24] Train loss=0.6650870442390442
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.62%
Best model saved!! Metric=50.61530689136855!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.678845 Test loss=0.656024 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6564862132072449
[5/24] Train loss=0.6386118531227112
[10/24] Train loss=0.6378424763679504
[15/24] Train loss=0.6231303215026855
[20/24] Train loss=0.6072998642921448
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.04%
Best model saved!! Metric=51.0405696957825!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.625361 Test loss=0.593731 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.5946263670921326
[5/24] Train loss=0.5625649690628052
[10/24] Train loss=0.5941795706748962
[15/24] Train loss=0.5879721641540527
[20/24] Train loss=0.5843443870544434
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.77%
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.574632 Test loss=0.578083 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.5782846212387085
[5/24] Train loss=0.544463574886322
[10/24] Train loss=0.5984514951705933
[15/24] Train loss=0.5875454545021057
[20/24] Train loss=0.5802415609359741
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.65%
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.569626 Test loss=0.574502 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5742496848106384
[5/24] Train loss=0.5488393306732178
[10/24] Train loss=0.5922299027442932
[15/24] Train loss=0.5854002833366394
[20/24] Train loss=0.5794169306755066
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.59%
Best model saved!! Metric=52.58888428650616!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.568671 Test loss=0.573535 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5735384821891785
[5/24] Train loss=0.5453210473060608
[10/24] Train loss=0.5932676792144775
[15/24] Train loss=0.5857212543487549
[20/24] Train loss=0.5792137384414673
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.21%
Best model saved!! Metric=53.20656276897648!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.567439 Test loss=0.572948 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5731459856033325
[5/24] Train loss=0.5447821617126465
[10/24] Train loss=0.5918388962745667
[15/24] Train loss=0.5844284892082214
[20/24] Train loss=0.5782586336135864
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.51%
Best model saved!! Metric=54.51165947225367!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.566892 Test loss=0.572352 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.572428822517395
[5/24] Train loss=0.543997585773468
[10/24] Train loss=0.5915427803993225
[15/24] Train loss=0.584108829498291
[20/24] Train loss=0.5774703621864319
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.13%
Best model saved!! Metric=56.13484418206463!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.566149 Test loss=0.571398 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.5715631246566772
[5/24] Train loss=0.5429426431655884
[10/24] Train loss=0.5902099013328552
[15/24] Train loss=0.5827956199645996
[20/24] Train loss=0.5762952566146851
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.08%
Best model saved!! Metric=58.07862048901593!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.565226 Test loss=0.570203 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.5704815983772278
[5/24] Train loss=0.5413297414779663
[10/24] Train loss=0.5889847278594971
[15/24] Train loss=0.5816248655319214
[20/24] Train loss=0.5747337937355042
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.18%
Best model saved!! Metric=60.182754194306256!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.564066 Test loss=0.568606 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.5690107345581055
[5/24] Train loss=0.5393975377082825
[10/24] Train loss=0.5870031118392944
[15/24] Train loss=0.579633891582489
[20/24] Train loss=0.5725221037864685
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.07%
Best model saved!! Metric=62.068358319519575!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.562444 Test loss=0.566391 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.5668894648551941
[5/24] Train loss=0.5364627838134766
[10/24] Train loss=0.5841765403747559
[15/24] Train loss=0.5767561793327332
[20/24] Train loss=0.5692856311798096
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.95%
Best model saved!! Metric=63.95491724115051!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.560162 Test loss=0.563226 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.5638004541397095
[5/24] Train loss=0.5325062870979309
[10/24] Train loss=0.5791719555854797
[15/24] Train loss=0.5721974968910217
[20/24] Train loss=0.5634004473686218
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=66.52%
Best model saved!! Metric=66.52060041470725!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.556436 Test loss=0.558643 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.5586170554161072
[5/24] Train loss=0.5264902710914612
[10/24] Train loss=0.5715517997741699
[15/24] Train loss=0.5636627674102783
[20/24] Train loss=0.5522412657737732
Test set avg_accuracy=73.95% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=70.60%
Best model saved!! Metric=70.60464309137913!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.548874 Test loss=0.545220 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.5431297421455383
[5/24] Train loss=0.5126718878746033
[10/24] Train loss=0.5619920492172241
[15/24] Train loss=0.5491560697555542
[20/24] Train loss=0.5172233581542969
Test set avg_accuracy=73.87% avg_sensitivity=0.65%, avg_specificity=99.67% avg_auc=73.19%
Best model saved!! Metric=73.19326337887581!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.530140 Test loss=0.526757 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.5170234441757202
[5/24] Train loss=0.4940386414527893
[10/24] Train loss=0.5492520928382874
[15/24] Train loss=0.5270812511444092
[20/24] Train loss=0.4963342547416687
Test set avg_accuracy=74.01% avg_sensitivity=3.55%, avg_specificity=98.84% avg_auc=74.55%
Best model saved!! Metric=74.55026668739937!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.508283 Test loss=0.507040 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.4963681697845459
[5/24] Train loss=0.47719886898994446
[10/24] Train loss=0.5340657830238342
[15/24] Train loss=0.5068086385726929
[20/24] Train loss=0.4818035960197449
Test set avg_accuracy=74.66% avg_sensitivity=9.05%, avg_specificity=97.78% avg_auc=76.16%
Best model saved!! Metric=76.15846505343912!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.492034 Test loss=0.490533 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.48043519258499146
[5/24] Train loss=0.4727587103843689
[10/24] Train loss=0.5231057405471802
[15/24] Train loss=0.49004536867141724
[20/24] Train loss=0.46769577264785767
Test set avg_accuracy=75.17% avg_sensitivity=10.49%, avg_specificity=97.96% avg_auc=77.50%
Best model saved!! Metric=77.5008164169368!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.476829 Test loss=0.487181 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.47308987379074097
[5/24] Train loss=0.4559394121170044
[10/24] Train loss=0.5079302787780762
[15/24] Train loss=0.46961286664009094
[20/24] Train loss=0.45458197593688965
Test set avg_accuracy=74.58% avg_sensitivity=6.30%, avg_specificity=98.64% avg_auc=79.02%
Best model saved!! Metric=79.02200510943683!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.463466 Test loss=0.489238 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.472441703081131
[5/24] Train loss=0.43245846033096313
[10/24] Train loss=0.4989992380142212
[15/24] Train loss=0.4695819020271301
[20/24] Train loss=0.45021525025367737
Test set avg_accuracy=77.38% avg_sensitivity=26.79%, avg_specificity=95.21% avg_auc=80.97%
Best model saved!! Metric=80.97018139987938!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.449647 Test loss=0.452893 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.4384671747684479
[5/24] Train loss=0.4140656292438507
[10/24] Train loss=0.48347198963165283
[15/24] Train loss=0.45529183745384216
[20/24] Train loss=0.4217774569988251
Test set avg_accuracy=77.51% avg_sensitivity=27.84%, avg_specificity=95.02% avg_auc=81.92%
Best model saved!! Metric=81.91782784430993!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.432223 Test loss=0.443806 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.4170607924461365
[5/24] Train loss=0.3966638147830963
[10/24] Train loss=0.4684070944786072
[15/24] Train loss=0.4437900185585022
[20/24] Train loss=0.4284602105617523
Test set avg_accuracy=77.64% avg_sensitivity=26.69%, avg_specificity=95.60% avg_auc=83.02%
Best model saved!! Metric=83.02328849662157!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.421550 Test loss=0.437030 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.41516828536987305
[5/24] Train loss=0.3899884819984436
[10/24] Train loss=0.4637698233127594
[15/24] Train loss=0.4315366744995117
[20/24] Train loss=0.4044729769229889
Test set avg_accuracy=78.88% avg_sensitivity=37.23%, avg_specificity=93.56% avg_auc=84.09%
Best model saved!! Metric=84.08884129866745!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.411154 Test loss=0.422108 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.3984326422214508
[5/24] Train loss=0.3717348575592041
[10/24] Train loss=0.44769197702407837
[15/24] Train loss=0.41681748628616333
[20/24] Train loss=0.41345834732055664
Test set avg_accuracy=79.49% avg_sensitivity=36.78%, avg_specificity=94.54% avg_auc=84.77%
Best model saved!! Metric=84.77044274129885!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.400691 Test loss=0.416274 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.3924240171909332
[5/24] Train loss=0.3717130422592163
[10/24] Train loss=0.4408954083919525
[15/24] Train loss=0.4084154963493347
[20/24] Train loss=0.4059801697731018
Test set avg_accuracy=80.76% avg_sensitivity=44.78%, avg_specificity=93.43% avg_auc=85.38%
Best model saved!! Metric=85.38012205378205!!
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.394636 Test loss=0.406844 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.38840386271476746
[5/24] Train loss=0.36342132091522217
[10/24] Train loss=0.43125274777412415
[15/24] Train loss=0.3994639217853546
[20/24] Train loss=0.3980571925640106
Test set avg_accuracy=81.29% avg_sensitivity=45.98%, avg_specificity=93.73% avg_auc=85.85%
Best model saved!! Metric=85.84892269484205!!
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.386260 Test loss=0.400065 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.37593939900398254
[5/24] Train loss=0.35967981815338135
[10/24] Train loss=0.42598751187324524
[15/24] Train loss=0.39667949080467224
[20/24] Train loss=0.40201690793037415
Test set avg_accuracy=81.59% avg_sensitivity=53.52%, avg_specificity=91.48% avg_auc=86.16%
Best model saved!! Metric=86.16192872044344!!
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.381588 Test loss=0.395954 Current lr=[0.000669125424222739]

[0/24] Train loss=0.37645405530929565
[5/24] Train loss=0.3583664894104004
[10/24] Train loss=0.4173932671546936
[15/24] Train loss=0.3934015929698944
[20/24] Train loss=0.3964211344718933
Test set avg_accuracy=81.76% avg_sensitivity=53.47%, avg_specificity=91.72% avg_auc=86.53%
Best model saved!! Metric=86.53059893719278!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.376071 Test loss=0.391535 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.3697744309902191
[5/24] Train loss=0.3593856692314148
[10/24] Train loss=0.4209784269332886
[15/24] Train loss=0.39010152220726013
[20/24] Train loss=0.37769871950149536
Test set avg_accuracy=82.24% avg_sensitivity=50.67%, avg_specificity=93.36% avg_auc=86.89%
Best model saved!! Metric=86.89170118233717!!
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.371495 Test loss=0.387147 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.3627937436103821
[5/24] Train loss=0.34913355112075806
[10/24] Train loss=0.4139191210269928
[15/24] Train loss=0.3738956153392792
[20/24] Train loss=0.3799845278263092
Test set avg_accuracy=82.23% avg_sensitivity=48.28%, avg_specificity=94.19% avg_auc=87.18%
Best model saved!! Metric=87.17748891006161!!
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.364953 Test loss=0.384370 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.36341020464897156
[5/24] Train loss=0.3435613512992859
[10/24] Train loss=0.40212079882621765
[15/24] Train loss=0.3714447021484375
[20/24] Train loss=0.3751656115055084
Test set avg_accuracy=82.24% avg_sensitivity=47.28%, avg_specificity=94.56% avg_auc=87.44%
Best model saved!! Metric=87.43864553020197!!
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.360289 Test loss=0.382156 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.3590162694454193
[5/24] Train loss=0.3442102074623108
[10/24] Train loss=0.39783719182014465
[15/24] Train loss=0.3671632409095764
[20/24] Train loss=0.37054985761642456
Test set avg_accuracy=82.66% avg_sensitivity=48.38%, avg_specificity=94.73% avg_auc=87.66%
Best model saved!! Metric=87.6598415002747!!
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.356172 Test loss=0.379376 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.34865403175354004
[5/24] Train loss=0.3369986414909363
[10/24] Train loss=0.39083436131477356
[15/24] Train loss=0.3613571226596832
[20/24] Train loss=0.3728848695755005
Test set avg_accuracy=82.40% avg_sensitivity=47.38%, avg_specificity=94.73% avg_auc=87.57%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.353424 Test loss=0.381641 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.344172865152359
[5/24] Train loss=0.3362548351287842
[10/24] Train loss=0.38893213868141174
[15/24] Train loss=0.35703733563423157
[20/24] Train loss=0.3649228811264038
Test set avg_accuracy=82.27% avg_sensitivity=44.43%, avg_specificity=95.60% avg_auc=87.49%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.351330 Test loss=0.385162 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.34640854597091675
[5/24] Train loss=0.3374512493610382
[10/24] Train loss=0.3844939172267914
[15/24] Train loss=0.3524840772151947
[20/24] Train loss=0.3697359263896942
Test set avg_accuracy=82.43% avg_sensitivity=44.08%, avg_specificity=95.95% avg_auc=87.76%
Best model saved!! Metric=87.75899952823376!!
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.349074 Test loss=0.384768 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.34748151898384094
[5/24] Train loss=0.3307298719882965
[10/24] Train loss=0.382656067609787
[15/24] Train loss=0.3498219847679138
[20/24] Train loss=0.36601781845092773
Test set avg_accuracy=82.57% avg_sensitivity=49.43%, avg_specificity=94.24% avg_auc=87.82%
Best model saved!! Metric=87.82306328786656!!
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.346028 Test loss=0.375795 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.34263888001441956
[5/24] Train loss=0.3318043053150177
[10/24] Train loss=0.37636256217956543
[15/24] Train loss=0.350509911775589
[20/24] Train loss=0.35883447527885437
Test set avg_accuracy=82.67% avg_sensitivity=51.27%, avg_specificity=93.73% avg_auc=87.83%
Best model saved!! Metric=87.83042886023091!!
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.345585 Test loss=0.375988 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.33633363246917725
[5/24] Train loss=0.3312375843524933
[10/24] Train loss=0.37727612257003784
[15/24] Train loss=0.3544212579727173
[20/24] Train loss=0.3686840534210205
Test set avg_accuracy=82.79% avg_sensitivity=53.37%, avg_specificity=93.15% avg_auc=88.18%
Best model saved!! Metric=88.17558116521948!!
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.345403 Test loss=0.370143 Current lr=[0.000944367614404117]

[0/24] Train loss=0.33759212493896484
[5/24] Train loss=0.3278140425682068
[10/24] Train loss=0.37492379546165466
[15/24] Train loss=0.35657548904418945
[20/24] Train loss=0.36500832438468933
Test set avg_accuracy=82.85% avg_sensitivity=56.57%, avg_specificity=92.11% avg_auc=88.32%
Best model saved!! Metric=88.31850142898263!!
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.342935 Test loss=0.367808 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.33791583776474
[5/24] Train loss=0.3282075822353363
[10/24] Train loss=0.37708988785743713
[15/24] Train loss=0.35536426305770874
[20/24] Train loss=0.35838454961776733
Test set avg_accuracy=82.68% avg_sensitivity=57.57%, avg_specificity=91.53% avg_auc=88.46%
Best model saved!! Metric=88.46264928813987!!
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.342557 Test loss=0.364997 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.34440746903419495
[5/24] Train loss=0.32574477791786194
[10/24] Train loss=0.3716128170490265
[15/24] Train loss=0.35423076152801514
[20/24] Train loss=0.36112093925476074
Test set avg_accuracy=83.23% avg_sensitivity=60.42%, avg_specificity=91.27% avg_auc=88.57%
Best model saved!! Metric=88.56813449235939!!
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.342128 Test loss=0.362816 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.3376688063144684
[5/24] Train loss=0.32031428813934326
[10/24] Train loss=0.37133949995040894
[15/24] Train loss=0.35382208228111267
[20/24] Train loss=0.3634612560272217
Test set avg_accuracy=83.55% avg_sensitivity=59.57%, avg_specificity=92.01% avg_auc=88.70%
Best model saved!! Metric=88.69550081448095!!
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.340743 Test loss=0.361354 Current lr=[0.000989780311725182]

[0/24] Train loss=0.33128371834754944
[5/24] Train loss=0.32820257544517517
[10/24] Train loss=0.3810034692287445
[15/24] Train loss=0.3557998538017273
[20/24] Train loss=0.3616085350513458
Test set avg_accuracy=83.83% avg_sensitivity=62.22%, avg_specificity=91.44% avg_auc=88.75%
Best model saved!! Metric=88.75016620937637!!
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.341952 Test loss=0.359948 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.3342614769935608
[5/24] Train loss=0.324348509311676
[10/24] Train loss=0.37361419200897217
[15/24] Train loss=0.3591402769088745
[20/24] Train loss=0.3582012951374054
Test set avg_accuracy=83.59% avg_sensitivity=64.47%, avg_specificity=90.33% avg_auc=88.91%
Best model saved!! Metric=88.90815201661364!!
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.341061 Test loss=0.359320 Current lr=[0.000998924125869967]

[0/24] Train loss=0.33626022934913635
[5/24] Train loss=0.32624319195747375
[10/24] Train loss=0.3758125603199005
[15/24] Train loss=0.3463192880153656
[20/24] Train loss=0.3438725471496582
Test set avg_accuracy=83.16% avg_sensitivity=56.72%, avg_specificity=92.48% avg_auc=88.79%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.338736 Test loss=0.361275 Current lr=[0.000999999611458977]

[0/24] Train loss=0.3270440101623535
[5/24] Train loss=0.3312624990940094
[10/24] Train loss=0.37149178981781006
[15/24] Train loss=0.34570568799972534
[20/24] Train loss=0.342894583940506
Test set avg_accuracy=83.09% avg_sensitivity=60.77%, avg_specificity=90.95% avg_auc=88.58%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.338057 Test loss=0.364725 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.32799041271209717
[5/24] Train loss=0.32697492837905884
[10/24] Train loss=0.37485289573669434
[15/24] Train loss=0.34001752734184265
[20/24] Train loss=0.3381282687187195
Test set avg_accuracy=82.97% avg_sensitivity=59.47%, avg_specificity=91.25% avg_auc=88.68%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.336471 Test loss=0.363569 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.32601994276046753
[5/24] Train loss=0.32677263021469116
[10/24] Train loss=0.37158238887786865
[15/24] Train loss=0.34140002727508545
[20/24] Train loss=0.3413791060447693
Test set avg_accuracy=83.19% avg_sensitivity=57.57%, avg_specificity=92.22% avg_auc=89.08%
Best model saved!! Metric=89.08190736468356!!
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.335059 Test loss=0.356949 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3256899416446686
[5/24] Train loss=0.3229556977748871
[10/24] Train loss=0.36910179257392883
[15/24] Train loss=0.33817657828330994
[20/24] Train loss=0.33958932757377625
Test set avg_accuracy=83.35% avg_sensitivity=59.17%, avg_specificity=91.86% avg_auc=88.83%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.334793 Test loss=0.361165 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3228178918361664
[5/24] Train loss=0.32798120379447937
[10/24] Train loss=0.3704603910446167
[15/24] Train loss=0.3354683220386505
[20/24] Train loss=0.3401448130607605
Test set avg_accuracy=83.92% avg_sensitivity=59.57%, avg_specificity=92.50% avg_auc=89.20%
Best model saved!! Metric=89.2047021039577!!
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.334741 Test loss=0.354928 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.3223346471786499
[5/24] Train loss=0.32578161358833313
[10/24] Train loss=0.368965744972229
[15/24] Train loss=0.33606186509132385
[20/24] Train loss=0.34464025497436523
Test set avg_accuracy=84.52% avg_sensitivity=61.82%, avg_specificity=92.52% avg_auc=89.30%
Best model saved!! Metric=89.2973437563662!!
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.334114 Test loss=0.353282 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.32150131464004517
[5/24] Train loss=0.317569762468338
[10/24] Train loss=0.3671685755252838
[15/24] Train loss=0.33396077156066895
[20/24] Train loss=0.3425927460193634
Test set avg_accuracy=84.73% avg_sensitivity=63.67%, avg_specificity=92.15% avg_auc=89.35%
Best model saved!! Metric=89.34763116768785!!
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.333359 Test loss=0.352385 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.3231377899646759
[5/24] Train loss=0.31790614128112793
[10/24] Train loss=0.36862310767173767
[15/24] Train loss=0.3413786292076111
[20/24] Train loss=0.3440268635749817
Test set avg_accuracy=84.84% avg_sensitivity=63.52%, avg_specificity=92.36% avg_auc=89.30%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.333167 Test loss=0.352408 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.322783499956131
[5/24] Train loss=0.3181474208831787
[10/24] Train loss=0.3605896234512329
[15/24] Train loss=0.33507853746414185
[20/24] Train loss=0.34203943610191345
Test set avg_accuracy=84.67% avg_sensitivity=63.92%, avg_specificity=91.99% avg_auc=89.36%
Best model saved!! Metric=89.36361190772813!!
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.332131 Test loss=0.351706 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.32296761870384216
[5/24] Train loss=0.31887519359588623
[10/24] Train loss=0.373884916305542
[15/24] Train loss=0.3367665112018585
[20/24] Train loss=0.33103621006011963
Test set avg_accuracy=84.35% avg_sensitivity=60.57%, avg_specificity=92.73% avg_auc=89.52%
Best model saved!! Metric=89.52094651740867!!
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.333645 Test loss=0.349748 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.3196142315864563
[5/24] Train loss=0.3171360492706299
[10/24] Train loss=0.3697567880153656
[15/24] Train loss=0.3309280574321747
[20/24] Train loss=0.33873996138572693
Test set avg_accuracy=84.91% avg_sensitivity=62.57%, avg_specificity=92.78% avg_auc=89.36%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.332159 Test loss=0.350923 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.3194776773452759
[5/24] Train loss=0.3178556561470032
[10/24] Train loss=0.3687763810157776
[15/24] Train loss=0.33369389176368713
[20/24] Train loss=0.33487799763679504
Test set avg_accuracy=85.23% avg_sensitivity=63.52%, avg_specificity=92.89% avg_auc=89.59%
Best model saved!! Metric=89.59442184172926!!
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.331799 Test loss=0.347381 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.31701794266700745
[5/24] Train loss=0.3129088580608368
[10/24] Train loss=0.365728497505188
[15/24] Train loss=0.32967281341552734
[20/24] Train loss=0.332610160112381
Test set avg_accuracy=84.95% avg_sensitivity=62.67%, avg_specificity=92.80% avg_auc=89.35%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.330718 Test loss=0.350923 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.3146655559539795
[5/24] Train loss=0.31289103627204895
[10/24] Train loss=0.36927321553230286
[15/24] Train loss=0.3270150423049927
[20/24] Train loss=0.33030015230178833
Test set avg_accuracy=85.13% avg_sensitivity=62.42%, avg_specificity=93.13% avg_auc=89.44%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.329512 Test loss=0.349681 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.31110522150993347
[5/24] Train loss=0.315204381942749
[10/24] Train loss=0.36166346073150635
[15/24] Train loss=0.33355653285980225
[20/24] Train loss=0.3310767710208893
Test set avg_accuracy=85.17% avg_sensitivity=66.87%, avg_specificity=91.62% avg_auc=89.40%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.328022 Test loss=0.350764 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.3085879981517792
[5/24] Train loss=0.31374016404151917
[10/24] Train loss=0.3677215278148651
[15/24] Train loss=0.32969045639038086
[20/24] Train loss=0.3329341411590576
Test set avg_accuracy=85.12% avg_sensitivity=63.62%, avg_specificity=92.69% avg_auc=89.38%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.328364 Test loss=0.350412 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.3111564517021179
[5/24] Train loss=0.3134772777557373
[10/24] Train loss=0.3605389893054962
[15/24] Train loss=0.33043327927589417
[20/24] Train loss=0.3306743800640106
Test set avg_accuracy=85.23% avg_sensitivity=62.17%, avg_specificity=93.36% avg_auc=89.43%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.327521 Test loss=0.350207 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.3148842751979828
[5/24] Train loss=0.31271976232528687
[10/24] Train loss=0.3565591871738434
[15/24] Train loss=0.32660412788391113
[20/24] Train loss=0.33413952589035034
Test set avg_accuracy=85.13% avg_sensitivity=67.37%, avg_specificity=91.39% avg_auc=89.44%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.326747 Test loss=0.350508 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.3077670633792877
[5/24] Train loss=0.3087058663368225
[10/24] Train loss=0.36122527718544006
[15/24] Train loss=0.32918399572372437
[20/24] Train loss=0.32836318016052246
Test set avg_accuracy=84.99% avg_sensitivity=64.17%, avg_specificity=92.32% avg_auc=89.34%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.326503 Test loss=0.351751 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.3047889173030853
[5/24] Train loss=0.31273001432418823
[10/24] Train loss=0.36227235198020935
[15/24] Train loss=0.32963842153549194
[20/24] Train loss=0.3273387551307678
Test set avg_accuracy=84.60% avg_sensitivity=63.47%, avg_specificity=92.04% avg_auc=89.16%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.326593 Test loss=0.354839 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.31157660484313965
[5/24] Train loss=0.3133108913898468
[10/24] Train loss=0.35286399722099304
[15/24] Train loss=0.33302175998687744
[20/24] Train loss=0.3311382830142975
Test set avg_accuracy=84.80% avg_sensitivity=63.02%, avg_specificity=92.48% avg_auc=89.27%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.325762 Test loss=0.353308 Current lr=[0.000904142181093812]

[0/24] Train loss=0.30988237261772156
[5/24] Train loss=0.31012845039367676
[10/24] Train loss=0.3539819121360779
[15/24] Train loss=0.32432007789611816
[20/24] Train loss=0.3333270251750946
Test set avg_accuracy=84.88% avg_sensitivity=64.32%, avg_specificity=92.13% avg_auc=89.37%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.325618 Test loss=0.351877 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.3056698143482208
[5/24] Train loss=0.308143675327301
[10/24] Train loss=0.3567791283130646
[15/24] Train loss=0.3267846703529358
[20/24] Train loss=0.32374081015586853
Test set avg_accuracy=84.78% avg_sensitivity=66.32%, avg_specificity=91.28% avg_auc=89.24%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.324481 Test loss=0.354214 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.30086666345596313
[5/24] Train loss=0.30746182799339294
[10/24] Train loss=0.3589116632938385
[15/24] Train loss=0.32177817821502686
[20/24] Train loss=0.3205878734588623
Test set avg_accuracy=84.83% avg_sensitivity=64.12%, avg_specificity=92.13% avg_auc=89.36%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.324656 Test loss=0.352461 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.30323493480682373
[5/24] Train loss=0.30848515033721924
[10/24] Train loss=0.35789352655410767
[15/24] Train loss=0.32465147972106934
[20/24] Train loss=0.32230380177497864
Test set avg_accuracy=84.52% avg_sensitivity=62.77%, avg_specificity=92.18% avg_auc=89.45%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.324485 Test loss=0.350876 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.3036467432975769
[5/24] Train loss=0.30774247646331787
[10/24] Train loss=0.35810530185699463
[15/24] Train loss=0.3172316253185272
[20/24] Train loss=0.31687650084495544
Test set avg_accuracy=84.56% avg_sensitivity=63.67%, avg_specificity=91.92% avg_auc=89.44%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.322961 Test loss=0.350935 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.29807817935943604
[5/24] Train loss=0.3052231967449188
[10/24] Train loss=0.35135960578918457
[15/24] Train loss=0.31925952434539795
[20/24] Train loss=0.31555214524269104
Test set avg_accuracy=84.28% avg_sensitivity=62.77%, avg_specificity=91.86% avg_auc=89.21%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.321763 Test loss=0.354511 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.3007062077522278
[5/24] Train loss=0.30920884013175964
[10/24] Train loss=0.3565819263458252
[15/24] Train loss=0.31878575682640076
[20/24] Train loss=0.31599071621894836
Test set avg_accuracy=84.19% avg_sensitivity=62.67%, avg_specificity=91.78% avg_auc=89.15%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.321952 Test loss=0.355442 Current lr=[0.000834102481048427]

[0/24] Train loss=0.3038989007472992
[5/24] Train loss=0.3053622841835022
[10/24] Train loss=0.35387319326400757
[15/24] Train loss=0.3173914849758148
[20/24] Train loss=0.316396027803421
Test set avg_accuracy=84.36% avg_sensitivity=65.87%, avg_specificity=90.88% avg_auc=89.01%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.321233 Test loss=0.358557 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.29705747961997986
[5/24] Train loss=0.3005812466144562
[10/24] Train loss=0.354529470205307
[15/24] Train loss=0.3173743784427643
[20/24] Train loss=0.31500744819641113
Test set avg_accuracy=84.38% avg_sensitivity=65.22%, avg_specificity=91.13% avg_auc=89.15%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.319520 Test loss=0.356447 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.2995278537273407
[5/24] Train loss=0.30275002121925354
[10/24] Train loss=0.3541397452354431
[15/24] Train loss=0.3140260577201843
[20/24] Train loss=0.31442686915397644
Test set avg_accuracy=84.38% avg_sensitivity=65.22%, avg_specificity=91.13% avg_auc=89.32%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.319282 Test loss=0.353849 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.29312455654144287
[5/24] Train loss=0.2986697554588318
[10/24] Train loss=0.3609919548034668
[15/24] Train loss=0.31485164165496826
[20/24] Train loss=0.31068962812423706
Test set avg_accuracy=84.71% avg_sensitivity=65.42%, avg_specificity=91.51% avg_auc=89.46%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.320549 Test loss=0.352109 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.3005424737930298
[5/24] Train loss=0.2967337667942047
[10/24] Train loss=0.36209726333618164
[15/24] Train loss=0.31486549973487854
[20/24] Train loss=0.31555449962615967
Test set avg_accuracy=84.54% avg_sensitivity=69.37%, avg_specificity=89.89% avg_auc=89.56%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.321189 Test loss=0.351783 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.2977803647518158
[5/24] Train loss=0.29711586236953735
[10/24] Train loss=0.3579533100128174
[15/24] Train loss=0.31597697734832764
[20/24] Train loss=0.3170061409473419
Test set avg_accuracy=84.65% avg_sensitivity=71.96%, avg_specificity=89.12% avg_auc=89.48%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.320087 Test loss=0.354680 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.2994687259197235
[5/24] Train loss=0.29787224531173706
[10/24] Train loss=0.3510071635246277
[15/24] Train loss=0.31757381558418274
[20/24] Train loss=0.32063326239585876
Test set avg_accuracy=84.65% avg_sensitivity=72.26%, avg_specificity=89.01% avg_auc=89.53%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.320354 Test loss=0.354110 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.30198222398757935
[5/24] Train loss=0.2962486445903778
[10/24] Train loss=0.3556082546710968
[15/24] Train loss=0.3169627785682678
[20/24] Train loss=0.32174819707870483
Test set avg_accuracy=83.84% avg_sensitivity=72.96%, avg_specificity=87.67% avg_auc=89.44%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.319791 Test loss=0.357746 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.29975205659866333
[5/24] Train loss=0.2975219786167145
[10/24] Train loss=0.35340332984924316
[15/24] Train loss=0.31350335478782654
[20/24] Train loss=0.32461613416671753
Test set avg_accuracy=83.98% avg_sensitivity=75.21%, avg_specificity=87.08% avg_auc=89.44%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.318390 Test loss=0.361413 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.3027997612953186
[5/24] Train loss=0.3016592264175415
[10/24] Train loss=0.3439757823944092
[15/24] Train loss=0.3147002160549164
[20/24] Train loss=0.33220982551574707
Test set avg_accuracy=83.87% avg_sensitivity=75.56%, avg_specificity=86.79% avg_auc=89.41%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.319567 Test loss=0.363084 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.29917025566101074
[5/24] Train loss=0.30229541659355164
[10/24] Train loss=0.35402122139930725
[15/24] Train loss=0.31522318720817566
[20/24] Train loss=0.3170621395111084
Test set avg_accuracy=84.64% avg_sensitivity=70.86%, avg_specificity=89.49% avg_auc=89.43%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.319677 Test loss=0.356105 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.30119770765304565
[5/24] Train loss=0.2970403730869293
[10/24] Train loss=0.34939372539520264
[15/24] Train loss=0.3191053569316864
[20/24] Train loss=0.30863308906555176
Test set avg_accuracy=84.14% avg_sensitivity=65.82%, avg_specificity=90.60% avg_auc=89.30%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.317512 Test loss=0.355418 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.2986133098602295
[5/24] Train loss=0.295840859413147
[10/24] Train loss=0.34683191776275635
[15/24] Train loss=0.31497320532798767
[20/24] Train loss=0.30887430906295776
Test set avg_accuracy=84.18% avg_sensitivity=67.17%, avg_specificity=90.17% avg_auc=89.25%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.315030 Test loss=0.357692 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.29446476697921753
[5/24] Train loss=0.2949988842010498
[10/24] Train loss=0.3431529402732849
[15/24] Train loss=0.30841508507728577
[20/24] Train loss=0.3063388168811798
Test set avg_accuracy=84.10% avg_sensitivity=69.02%, avg_specificity=89.42% avg_auc=89.22%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.314502 Test loss=0.359113 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.2969467043876648
[5/24] Train loss=0.2937820553779602
[10/24] Train loss=0.3481026887893677
[15/24] Train loss=0.31261637806892395
[20/24] Train loss=0.31020092964172363
Test set avg_accuracy=83.87% avg_sensitivity=68.22%, avg_specificity=89.38% avg_auc=89.16%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.314667 Test loss=0.359839 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.2952623665332794
[5/24] Train loss=0.29908570647239685
[10/24] Train loss=0.34433284401893616
[15/24] Train loss=0.3133069574832916
[20/24] Train loss=0.30443358421325684
Test set avg_accuracy=83.57% avg_sensitivity=66.92%, avg_specificity=89.43% avg_auc=89.04%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.313655 Test loss=0.361793 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.2941190004348755
[5/24] Train loss=0.2981697916984558
[10/24] Train loss=0.3443707227706909
[15/24] Train loss=0.3130243122577667
[20/24] Train loss=0.3083895444869995
Test set avg_accuracy=83.71% avg_sensitivity=66.42%, avg_specificity=89.80% avg_auc=89.12%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.313500 Test loss=0.359241 Current lr=[0.00061065423442182]

[0/24] Train loss=0.29686135053634644
[5/24] Train loss=0.29890426993370056
[10/24] Train loss=0.34680265188217163
[15/24] Train loss=0.3148114085197449
[20/24] Train loss=0.30610397458076477
Test set avg_accuracy=83.79% avg_sensitivity=65.52%, avg_specificity=90.23% avg_auc=89.26%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.312405 Test loss=0.356612 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.29184862971305847
[5/24] Train loss=0.29845207929611206
[10/24] Train loss=0.34325459599494934
[15/24] Train loss=0.3140132427215576
[20/24] Train loss=0.30335643887519836
Test set avg_accuracy=84.48% avg_sensitivity=63.97%, avg_specificity=91.71% avg_auc=89.20%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.312352 Test loss=0.356733 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.2961755394935608
[5/24] Train loss=0.2962583601474762
[10/24] Train loss=0.34360066056251526
[15/24] Train loss=0.31199967861175537
[20/24] Train loss=0.3028114438056946
Test set avg_accuracy=83.97% avg_sensitivity=64.62%, avg_specificity=90.79% avg_auc=89.29%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.311008 Test loss=0.355649 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.29566994309425354
[5/24] Train loss=0.29082244634628296
[10/24] Train loss=0.34687480330467224
[15/24] Train loss=0.31103840470314026
[20/24] Train loss=0.3035958707332611
Test set avg_accuracy=84.36% avg_sensitivity=64.32%, avg_specificity=91.42% avg_auc=89.25%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.310452 Test loss=0.356337 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.29174789786338806
[5/24] Train loss=0.2877870202064514
[10/24] Train loss=0.34505191445350647
[15/24] Train loss=0.3096027672290802
[20/24] Train loss=0.3012569546699524
Test set avg_accuracy=84.31% avg_sensitivity=64.62%, avg_specificity=91.25% avg_auc=89.18%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.308926 Test loss=0.357871 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.29079750180244446
[5/24] Train loss=0.28944119811058044
[10/24] Train loss=0.3448016345500946
[15/24] Train loss=0.3092852234840393
[20/24] Train loss=0.30446794629096985
Test set avg_accuracy=84.60% avg_sensitivity=63.32%, avg_specificity=92.09% avg_auc=89.23%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.309422 Test loss=0.356704 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.29349425435066223
[5/24] Train loss=0.28562799096107483
[10/24] Train loss=0.3433974087238312
[15/24] Train loss=0.3156716227531433
[20/24] Train loss=0.2993692457675934
Test set avg_accuracy=84.23% avg_sensitivity=63.47%, avg_specificity=91.55% avg_auc=89.20%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.307904 Test loss=0.358034 Current lr=[0.000506858408304961]

[0/24] Train loss=0.2938022315502167
[5/24] Train loss=0.286899596452713
[10/24] Train loss=0.3412235379219055
[15/24] Train loss=0.3096695840358734
[20/24] Train loss=0.30185168981552124
Test set avg_accuracy=84.18% avg_sensitivity=63.97%, avg_specificity=91.30% avg_auc=89.22%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.308565 Test loss=0.357981 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.29432323575019836
[5/24] Train loss=0.2808026671409607
[10/24] Train loss=0.33686113357543945
[15/24] Train loss=0.31221258640289307
[20/24] Train loss=0.30341845750808716
Test set avg_accuracy=84.05% avg_sensitivity=65.57%, avg_specificity=90.56% avg_auc=89.22%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.306439 Test loss=0.358306 Current lr=[0.000476946990416354]

[0/24] Train loss=0.2919099032878876
[5/24] Train loss=0.27979007363319397
[10/24] Train loss=0.34113097190856934
[15/24] Train loss=0.31166020035743713
[20/24] Train loss=0.299054890871048
Test set avg_accuracy=84.09% avg_sensitivity=64.32%, avg_specificity=91.05% avg_auc=89.22%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.307297 Test loss=0.357909 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.29311689734458923
[5/24] Train loss=0.27794116735458374
[10/24] Train loss=0.34064191579818726
[15/24] Train loss=0.31469061970710754
[20/24] Train loss=0.30034342408180237
Test set avg_accuracy=83.98% avg_sensitivity=62.37%, avg_specificity=91.60% avg_auc=89.16%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.306558 Test loss=0.358755 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.29513028264045715
[5/24] Train loss=0.28059208393096924
[10/24] Train loss=0.3362644612789154
[15/24] Train loss=0.3096771836280823
[20/24] Train loss=0.29994329810142517
Test set avg_accuracy=84.38% avg_sensitivity=64.22%, avg_specificity=91.48% avg_auc=89.17%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.305603 Test loss=0.358668 Current lr=[0.000432267999769856]

[0/24] Train loss=0.2899685204029083
[5/24] Train loss=0.2791205942630768
[10/24] Train loss=0.33757004141807556
[15/24] Train loss=0.30777525901794434
[20/24] Train loss=0.29655909538269043
Test set avg_accuracy=84.34% avg_sensitivity=63.87%, avg_specificity=91.55% avg_auc=89.11%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.304561 Test loss=0.360155 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.2938864827156067
[5/24] Train loss=0.27937695384025574
[10/24] Train loss=0.3357013761997223
[15/24] Train loss=0.3078223168849945
[20/24] Train loss=0.29599177837371826
Test set avg_accuracy=84.31% avg_sensitivity=63.07%, avg_specificity=91.79% avg_auc=89.01%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.304741 Test loss=0.361739 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.2912132740020752
[5/24] Train loss=0.2758709192276001
[10/24] Train loss=0.3393939435482025
[15/24] Train loss=0.30989471077919006
[20/24] Train loss=0.29289475083351135
Test set avg_accuracy=84.28% avg_sensitivity=64.82%, avg_specificity=91.14% avg_auc=88.98%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.304805 Test loss=0.362718 Current lr=[0.000388134363466264]

[0/24] Train loss=0.28978800773620605
[5/24] Train loss=0.28320467472076416
[10/24] Train loss=0.34032633900642395
[15/24] Train loss=0.31363406777381897
[20/24] Train loss=0.29384157061576843
Test set avg_accuracy=83.62% avg_sensitivity=66.22%, avg_specificity=89.75% avg_auc=88.87%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.304693 Test loss=0.366023 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.28643596172332764
[5/24] Train loss=0.2893502116203308
[10/24] Train loss=0.34631335735321045
[15/24] Train loss=0.31414759159088135
[20/24] Train loss=0.2932574152946472
Test set avg_accuracy=83.14% avg_sensitivity=70.31%, avg_specificity=87.66% avg_auc=88.90%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.305824 Test loss=0.369947 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.29175224900245667
[5/24] Train loss=0.2923194468021393
[10/24] Train loss=0.3567785620689392
[15/24] Train loss=0.3085229694843292
[20/24] Train loss=0.29771021008491516
Test set avg_accuracy=83.12% avg_sensitivity=79.51%, avg_specificity=84.40% avg_auc=89.05%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.308743 Test loss=0.381105 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.3005222678184509
[5/24] Train loss=0.2985419034957886
[10/24] Train loss=0.3465566039085388
[15/24] Train loss=0.30213087797164917
[20/24] Train loss=0.3215109705924988
Test set avg_accuracy=83.42% avg_sensitivity=74.76%, avg_specificity=86.48% avg_auc=89.08%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.310334 Test loss=0.369712 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.2926081418991089
[5/24] Train loss=0.28121840953826904
[10/24] Train loss=0.33873143792152405
[15/24] Train loss=0.3000549376010895
[20/24] Train loss=0.3033803403377533
Test set avg_accuracy=83.59% avg_sensitivity=66.37%, avg_specificity=89.66% avg_auc=88.93%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.306015 Test loss=0.364109 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.2899097204208374
[5/24] Train loss=0.281714528799057
[10/24] Train loss=0.3359798789024353
[15/24] Train loss=0.2972399592399597
[20/24] Train loss=0.29676100611686707
Test set avg_accuracy=83.42% avg_sensitivity=68.52%, avg_specificity=88.68% avg_auc=88.84%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.301525 Test loss=0.369766 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.291894793510437
[5/24] Train loss=0.27960214018821716
[10/24] Train loss=0.33314889669418335
[15/24] Train loss=0.3015953302383423
[20/24] Train loss=0.2978205382823944
Test set avg_accuracy=83.42% avg_sensitivity=69.82%, avg_specificity=88.22% avg_auc=88.82%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.301095 Test loss=0.371303 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2858620285987854
[5/24] Train loss=0.28031784296035767
[10/24] Train loss=0.32694268226623535
[15/24] Train loss=0.29459577798843384
[20/24] Train loss=0.3003884255886078
Test set avg_accuracy=83.49% avg_sensitivity=69.77%, avg_specificity=88.33% avg_auc=88.77%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.299639 Test loss=0.371482 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.2923988997936249
[5/24] Train loss=0.27850455045700073
[10/24] Train loss=0.33096951246261597
[15/24] Train loss=0.2963043749332428
[20/24] Train loss=0.3025680184364319
Test set avg_accuracy=82.79% avg_sensitivity=66.77%, avg_specificity=88.43% avg_auc=88.67%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.300557 Test loss=0.371887 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.28479132056236267
[5/24] Train loss=0.2729882001876831
[10/24] Train loss=0.33333829045295715
[15/24] Train loss=0.29657045006752014
[20/24] Train loss=0.2949138879776001
Test set avg_accuracy=83.12% avg_sensitivity=67.42%, avg_specificity=88.66% avg_auc=88.62%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.296976 Test loss=0.372766 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.28811928629875183
[5/24] Train loss=0.2756739556789398
[10/24] Train loss=0.32545900344848633
[15/24] Train loss=0.29795604944229126
[20/24] Train loss=0.2990444302558899
Test set avg_accuracy=82.93% avg_sensitivity=69.12%, avg_specificity=87.80% avg_auc=88.59%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.297796 Test loss=0.375841 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.2858329713344574
[5/24] Train loss=0.2736036479473114
[10/24] Train loss=0.3232530951499939
[15/24] Train loss=0.29307863116264343
[20/24] Train loss=0.29322245717048645
Test set avg_accuracy=82.83% avg_sensitivity=65.27%, avg_specificity=89.01% avg_auc=88.51%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.297354 Test loss=0.373752 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.2873495817184448
[5/24] Train loss=0.2706719934940338
[10/24] Train loss=0.33011651039123535
[15/24] Train loss=0.29394495487213135
[20/24] Train loss=0.29064640402793884
Test set avg_accuracy=82.90% avg_sensitivity=67.47%, avg_specificity=88.34% avg_auc=88.55%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.295957 Test loss=0.374992 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.2884736657142639
[5/24] Train loss=0.2711879312992096
[10/24] Train loss=0.32560595870018005
[15/24] Train loss=0.29141756892204285
[20/24] Train loss=0.29624369740486145
Test set avg_accuracy=82.89% avg_sensitivity=66.87%, avg_specificity=88.54% avg_auc=88.50%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.296261 Test loss=0.375047 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.29079535603523254
[5/24] Train loss=0.2714492380619049
[10/24] Train loss=0.326288640499115
[15/24] Train loss=0.2906585931777954
[20/24] Train loss=0.29086533188819885
Test set avg_accuracy=82.68% avg_sensitivity=65.67%, avg_specificity=88.68% avg_auc=88.48%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.296102 Test loss=0.375257 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2861613631248474
[5/24] Train loss=0.2697813808917999
[10/24] Train loss=0.32882097363471985
[15/24] Train loss=0.2951267957687378
[20/24] Train loss=0.2936379909515381
Test set avg_accuracy=83.01% avg_sensitivity=67.27%, avg_specificity=88.55% avg_auc=88.44%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.295423 Test loss=0.376819 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.2863113582134247
[5/24] Train loss=0.2721254825592041
[10/24] Train loss=0.32916030287742615
[15/24] Train loss=0.2907600700855255
[20/24] Train loss=0.2923720180988312
Test set avg_accuracy=83.02% avg_sensitivity=66.82%, avg_specificity=88.73% avg_auc=88.39%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.294465 Test loss=0.376849 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.2868792414665222
[5/24] Train loss=0.27272191643714905
[10/24] Train loss=0.3295117914676666
[15/24] Train loss=0.2914542555809021
[20/24] Train loss=0.29265856742858887
Test set avg_accuracy=82.98% avg_sensitivity=66.07%, avg_specificity=88.94% avg_auc=88.41%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.294720 Test loss=0.376656 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.28198859095573425
[5/24] Train loss=0.2709394693374634
[10/24] Train loss=0.33051854372024536
[15/24] Train loss=0.28988999128341675
[20/24] Train loss=0.28968989849090576
Test set avg_accuracy=82.89% avg_sensitivity=65.67%, avg_specificity=88.96% avg_auc=88.37%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.294635 Test loss=0.376855 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.29054203629493713
[5/24] Train loss=0.26794588565826416
[10/24] Train loss=0.3262149393558502
[15/24] Train loss=0.29211974143981934
[20/24] Train loss=0.294764906167984
Test set avg_accuracy=82.63% avg_sensitivity=64.37%, avg_specificity=89.06% avg_auc=88.32%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.293954 Test loss=0.377776 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.2873576581478119
[5/24] Train loss=0.27125582098960876
[10/24] Train loss=0.3233587145805359
[15/24] Train loss=0.29182466864585876
[20/24] Train loss=0.2982082664966583
Test set avg_accuracy=83.01% avg_sensitivity=65.82%, avg_specificity=89.06% avg_auc=88.34%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.293195 Test loss=0.377550 Current lr=[0.000123057953306828]

[0/24] Train loss=0.2837388217449188
[5/24] Train loss=0.27035367488861084
[10/24] Train loss=0.3197914958000183
[15/24] Train loss=0.29138413071632385
[20/24] Train loss=0.29605942964553833
Test set avg_accuracy=82.73% avg_sensitivity=64.37%, avg_specificity=89.21% avg_auc=88.33%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.293144 Test loss=0.377223 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.2879251539707184
[5/24] Train loss=0.2781560719013214
[10/24] Train loss=0.3291669189929962
[15/24] Train loss=0.2885120213031769
[20/24] Train loss=0.2948327660560608
Test set avg_accuracy=82.77% avg_sensitivity=64.02%, avg_specificity=89.38% avg_auc=88.34%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.294713 Test loss=0.376688 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.285290002822876
[5/24] Train loss=0.27072808146476746
[10/24] Train loss=0.3266604244709015
[15/24] Train loss=0.28996360301971436
[20/24] Train loss=0.29336798191070557
Test set avg_accuracy=82.70% avg_sensitivity=62.47%, avg_specificity=89.82% avg_auc=88.25%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.293269 Test loss=0.377640 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.28817158937454224
[5/24] Train loss=0.2722041606903076
[10/24] Train loss=0.3262653648853302
[15/24] Train loss=0.289229154586792
[20/24] Train loss=0.2935124337673187
Test set avg_accuracy=82.81% avg_sensitivity=61.97%, avg_specificity=90.16% avg_auc=88.23%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.292902 Test loss=0.377367 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.2822722792625427
[5/24] Train loss=0.2687860131263733
[10/24] Train loss=0.32642239332199097
[15/24] Train loss=0.29166319966316223
[20/24] Train loss=0.29450175166130066
Test set avg_accuracy=82.80% avg_sensitivity=61.67%, avg_specificity=90.24% avg_auc=88.22%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.293010 Test loss=0.377590 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.28453320264816284
[5/24] Train loss=0.26747429370880127
[10/24] Train loss=0.3251316547393799
[15/24] Train loss=0.2910611629486084
[20/24] Train loss=0.2898615598678589
Test set avg_accuracy=82.72% avg_sensitivity=61.97%, avg_specificity=90.03% avg_auc=88.23%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.292994 Test loss=0.377810 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.28562450408935547
[5/24] Train loss=0.2749454081058502
[10/24] Train loss=0.3287733495235443
[15/24] Train loss=0.28516554832458496
[20/24] Train loss=0.2848607003688812
Test set avg_accuracy=82.93% avg_sensitivity=64.27%, avg_specificity=89.51% avg_auc=88.30%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.292972 Test loss=0.377524 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.2868660092353821
[5/24] Train loss=0.2681616544723511
[10/24] Train loss=0.3197612166404724
[15/24] Train loss=0.2903837263584137
[20/24] Train loss=0.28790703415870667
Test set avg_accuracy=82.96% avg_sensitivity=66.07%, avg_specificity=88.91% avg_auc=88.30%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.291912 Test loss=0.378301 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.2864135801792145
[5/24] Train loss=0.2736000120639801
[10/24] Train loss=0.3273560702800751
[15/24] Train loss=0.28668537735939026
[20/24] Train loss=0.28945010900497437
Test set avg_accuracy=82.86% avg_sensitivity=65.87%, avg_specificity=88.85% avg_auc=88.29%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.292005 Test loss=0.378415 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.2853519022464752
[5/24] Train loss=0.26783257722854614
[10/24] Train loss=0.3197745084762573
[15/24] Train loss=0.2871268093585968
[20/24] Train loss=0.28664430975914
Test set avg_accuracy=82.83% avg_sensitivity=65.07%, avg_specificity=89.08% avg_auc=88.28%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.291209 Test loss=0.378624 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.28404802083969116
[5/24] Train loss=0.27193355560302734
[10/24] Train loss=0.3235417604446411
[15/24] Train loss=0.29457810521125793
[20/24] Train loss=0.2901725172996521
Test set avg_accuracy=82.90% avg_sensitivity=65.67%, avg_specificity=88.98% avg_auc=88.26%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.292101 Test loss=0.379154 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.2853580713272095
[5/24] Train loss=0.26996827125549316
[10/24] Train loss=0.3286157250404358
[15/24] Train loss=0.2875700891017914
[20/24] Train loss=0.28788021206855774
Test set avg_accuracy=82.84% avg_sensitivity=65.82%, avg_specificity=88.84% avg_auc=88.25%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.291166 Test loss=0.379388 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.283204048871994
[5/24] Train loss=0.27002379298210144
[10/24] Train loss=0.32601198554039
[15/24] Train loss=0.2843656539916992
[20/24] Train loss=0.291446715593338
Test set avg_accuracy=82.80% avg_sensitivity=65.67%, avg_specificity=88.84% avg_auc=88.26%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.292199 Test loss=0.379216 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.28565725684165955
[5/24] Train loss=0.2666827142238617
[10/24] Train loss=0.3217971622943878
[15/24] Train loss=0.2893764078617096
[20/24] Train loss=0.2946917414665222
Test set avg_accuracy=82.85% avg_sensitivity=65.72%, avg_specificity=88.89% avg_auc=88.25%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.290990 Test loss=0.379230 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.2864716351032257
[5/24] Train loss=0.2713734209537506
[10/24] Train loss=0.322266548871994
[15/24] Train loss=0.28709813952445984
[20/24] Train loss=0.2857517898082733
Test set avg_accuracy=82.83% avg_sensitivity=65.92%, avg_specificity=88.78% avg_auc=88.25%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.290784 Test loss=0.379446 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.2861989438533783
[5/24] Train loss=0.2696581780910492
[10/24] Train loss=0.32609304785728455
[15/24] Train loss=0.2882818281650543
[20/24] Train loss=0.287918359041214
Test set avg_accuracy=82.79% avg_sensitivity=65.77%, avg_specificity=88.78% avg_auc=88.25%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.291511 Test loss=0.379380 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.28718101978302
[5/24] Train loss=0.2681826949119568
[10/24] Train loss=0.3275905251502991
[15/24] Train loss=0.28909316658973694
[20/24] Train loss=0.28706175088882446
Test set avg_accuracy=82.79% avg_sensitivity=65.77%, avg_specificity=88.78% avg_auc=88.25%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.291242 Test loss=0.379510 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.2824789881706238
[5/24] Train loss=0.2732349634170532
[10/24] Train loss=0.3243921399116516
[15/24] Train loss=0.29210108518600464
[20/24] Train loss=0.2884543240070343
Test set avg_accuracy=82.81% avg_sensitivity=65.77%, avg_specificity=88.82% avg_auc=88.25%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.291536 Test loss=0.379548 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.28289109468460083
[5/24] Train loss=0.2688848078250885
[10/24] Train loss=0.32964733242988586
[15/24] Train loss=0.2866404950618744
[20/24] Train loss=0.2838839292526245
Test set avg_accuracy=82.77% avg_sensitivity=65.82%, avg_specificity=88.75% avg_auc=88.25%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.291246 Test loss=0.379635 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.28687193989753723
[5/24] Train loss=0.2686159014701843
[10/24] Train loss=0.3217495083808899
[15/24] Train loss=0.2891677916049957
[20/24] Train loss=0.29048049449920654
Test set avg_accuracy=82.77% avg_sensitivity=65.82%, avg_specificity=88.75% avg_auc=88.25%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.290548 Test loss=0.379628 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.2870468199253082
[5/24] Train loss=0.2688449025154114
[10/24] Train loss=0.3249240219593048
[15/24] Train loss=0.2875206768512726
[20/24] Train loss=0.29130592942237854
Test set avg_accuracy=82.77% avg_sensitivity=65.82%, avg_specificity=88.75% avg_auc=88.25%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.291537 Test loss=0.379632 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.28275278210639954
[5/24] Train loss=0.2689136564731598
[10/24] Train loss=0.32644277811050415
[15/24] Train loss=0.29160743951797485
[20/24] Train loss=0.2922084331512451
Test set avg_accuracy=82.77% avg_sensitivity=65.82%, avg_specificity=88.75% avg_auc=88.25%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.291159 Test loss=0.379631 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.2850903868675232
[5/24] Train loss=0.270345002412796
[10/24] Train loss=0.3208511173725128
[15/24] Train loss=0.28738290071487427
[20/24] Train loss=0.28874441981315613
Test set avg_accuracy=82.76% avg_sensitivity=65.77%, avg_specificity=88.75% avg_auc=88.25%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.290905 Test loss=0.379632 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.2822231352329254
[5/24] Train loss=0.2650105953216553
[10/24] Train loss=0.3234331011772156
[15/24] Train loss=0.28445908427238464
[20/24] Train loss=0.2857811748981476
Test set avg_accuracy=82.77% avg_sensitivity=65.77%, avg_specificity=88.77% avg_auc=88.25%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.290621 Test loss=0.379632 Current lr=[4.388541022775342e-09]

Fold[4] Result: acc=85.23% sen=63.52%, spe=92.89%, auc=89.59%!
Fold[4] Avg_jsc=0.56%(±0.27553565269243324)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.6923471689224243
[5/24] Train loss=0.682111918926239
[10/24] Train loss=0.6741656064987183
[15/24] Train loss=0.6615155935287476
[20/24] Train loss=0.6551042199134827
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.84%
Best model saved!! Metric=49.837538895312775!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.669758 Test loss=0.644652 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6512010097503662
[5/24] Train loss=0.6326050162315369
[10/24] Train loss=0.6251636743545532
[15/24] Train loss=0.6019173860549927
[20/24] Train loss=0.6037091612815857
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=49.83%
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.616390 Test loss=0.589306 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.6082053184509277
[5/24] Train loss=0.5839923024177551
[10/24] Train loss=0.5866644978523254
[15/24] Train loss=0.5634641647338867
[20/24] Train loss=0.5859530568122864
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.63%
Best model saved!! Metric=53.629665928792306!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.576862 Test loss=0.568883 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.6010463833808899
[5/24] Train loss=0.5709566473960876
[10/24] Train loss=0.5748448967933655
[15/24] Train loss=0.555193305015564
[20/24] Train loss=0.5771806240081787
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.49%
Best model saved!! Metric=59.49089887902643!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.565861 Test loss=0.560467 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5907319784164429
[5/24] Train loss=0.561188280582428
[10/24] Train loss=0.5664755702018738
[15/24] Train loss=0.5515353083610535
[20/24] Train loss=0.5721749663352966
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.48%
Best model saved!! Metric=61.476400492774545!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.559624 Test loss=0.554876 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5861970782279968
[5/24] Train loss=0.5539474487304688
[10/24] Train loss=0.5591794848442078
[15/24] Train loss=0.5440729856491089
[20/24] Train loss=0.5655774474143982
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.23%
Best model saved!! Metric=63.22622129918637!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.553028 Test loss=0.549100 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5804371237754822
[5/24] Train loss=0.5468863248825073
[10/24] Train loss=0.5511416792869568
[15/24] Train loss=0.53611159324646
[20/24] Train loss=0.5558106899261475
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.57%
Best model saved!! Metric=65.57434350147983!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.545300 Test loss=0.541797 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.5709903836250305
[5/24] Train loss=0.5387118458747864
[10/24] Train loss=0.5411232709884644
[15/24] Train loss=0.5234822034835815
[20/24] Train loss=0.5420346856117249
Test set avg_accuracy=74.39% avg_sensitivity=0.00%, avg_specificity=99.76% avg_auc=68.40%
Best model saved!! Metric=68.40412698233885!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.534571 Test loss=0.530882 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.5594834685325623
[5/24] Train loss=0.5287527441978455
[10/24] Train loss=0.5285468697547913
[15/24] Train loss=0.5068097114562988
[20/24] Train loss=0.5236825346946716
Test set avg_accuracy=74.34% avg_sensitivity=1.02%, avg_specificity=99.34% avg_auc=71.18%
Best model saved!! Metric=71.18456237738414!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.520478 Test loss=0.517181 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.545045018196106
[5/24] Train loss=0.5213173627853394
[10/24] Train loss=0.5153706669807434
[15/24] Train loss=0.4873692989349365
[20/24] Train loss=0.5090444087982178
Test set avg_accuracy=74.88% avg_sensitivity=5.27%, avg_specificity=98.62% avg_auc=73.34%
Best model saved!! Metric=73.34185022554209!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.505378 Test loss=0.504291 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.5308409929275513
[5/24] Train loss=0.5078284740447998
[10/24] Train loss=0.5033712983131409
[15/24] Train loss=0.4690606892108917
[20/24] Train loss=0.4919378459453583
Test set avg_accuracy=75.39% avg_sensitivity=12.49%, avg_specificity=96.84% avg_auc=75.51%
Best model saved!! Metric=75.50728750394173!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.489628 Test loss=0.490615 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.5162721276283264
[5/24] Train loss=0.5004118084907532
[10/24] Train loss=0.49179887771606445
[15/24] Train loss=0.4546468257904053
[20/24] Train loss=0.47935858368873596
Test set avg_accuracy=75.25% avg_sensitivity=15.31%, avg_specificity=95.69% avg_auc=76.96%
Best model saved!! Metric=76.96422502941708!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.476810 Test loss=0.479415 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.5029085874557495
[5/24] Train loss=0.49141645431518555
[10/24] Train loss=0.48305246233940125
[15/24] Train loss=0.4435712993144989
[20/24] Train loss=0.4652809500694275
Test set avg_accuracy=75.66% avg_sensitivity=19.76%, avg_specificity=94.73% avg_auc=78.17%
Best model saved!! Metric=78.17199920141843!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.465581 Test loss=0.470949 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.4900808334350586
[5/24] Train loss=0.4828386604785919
[10/24] Train loss=0.47661998867988586
[15/24] Train loss=0.43421152234077454
[20/24] Train loss=0.45454171299934387
Test set avg_accuracy=75.76% avg_sensitivity=22.68%, avg_specificity=93.85% avg_auc=79.23%
Best model saved!! Metric=79.23451860828294!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.455913 Test loss=0.463465 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.4778079390525818
[5/24] Train loss=0.47296011447906494
[10/24] Train loss=0.46923041343688965
[15/24] Train loss=0.42440417408943176
[20/24] Train loss=0.44283658266067505
Test set avg_accuracy=76.43% avg_sensitivity=30.36%, avg_specificity=92.14% avg_auc=80.16%
Best model saved!! Metric=80.16479194008384!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.446051 Test loss=0.455734 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.4658800959587097
[5/24] Train loss=0.46402508020401
[10/24] Train loss=0.4601666033267975
[15/24] Train loss=0.4166508615016937
[20/24] Train loss=0.4325052499771118
Test set avg_accuracy=77.45% avg_sensitivity=32.72%, avg_specificity=92.70% avg_auc=80.88%
Best model saved!! Metric=80.87592025306418!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.435901 Test loss=0.448222 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.45141515135765076
[5/24] Train loss=0.4512096643447876
[10/24] Train loss=0.45015788078308105
[15/24] Train loss=0.4057518243789673
[20/24] Train loss=0.4198245406150818
Test set avg_accuracy=77.94% avg_sensitivity=34.15%, avg_specificity=92.88% avg_auc=81.51%
Best model saved!! Metric=81.51009165896204!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.424961 Test loss=0.441080 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.439378559589386
[5/24] Train loss=0.44234499335289
[10/24] Train loss=0.43789586424827576
[15/24] Train loss=0.3991168439388275
[20/24] Train loss=0.41099122166633606
Test set avg_accuracy=78.50% avg_sensitivity=32.72%, avg_specificity=94.12% avg_auc=81.97%
Best model saved!! Metric=81.97483269975201!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.415103 Test loss=0.435566 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.4258248805999756
[5/24] Train loss=0.42397552728652954
[10/24] Train loss=0.42116209864616394
[15/24] Train loss=0.3862078785896301
[20/24] Train loss=0.401253342628479
Test set avg_accuracy=77.98% avg_sensitivity=28.73%, avg_specificity=94.78% avg_auc=82.39%
Best model saved!! Metric=82.39379745657311!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.403812 Test loss=0.432057 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.41578537225723267
[5/24] Train loss=0.4080623388290405
[10/24] Train loss=0.4068010747432709
[15/24] Train loss=0.3716924786567688
[20/24] Train loss=0.39046093821525574
Test set avg_accuracy=78.92% avg_sensitivity=35.02%, avg_specificity=93.89% avg_auc=82.89%
Best model saved!! Metric=82.89020191722165!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.393343 Test loss=0.426467 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.40040305256843567
[5/24] Train loss=0.40083229541778564
[10/24] Train loss=0.3981388211250305
[15/24] Train loss=0.36100882291793823
[20/24] Train loss=0.3898825943470001
Test set avg_accuracy=79.66% avg_sensitivity=42.04%, avg_specificity=92.49% avg_auc=83.45%
Best model saved!! Metric=83.44536452987086!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.383767 Test loss=0.420955 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.39399924874305725
[5/24] Train loss=0.3838658928871155
[10/24] Train loss=0.38901597261428833
[15/24] Train loss=0.3561258912086487
[20/24] Train loss=0.3847978711128235
Test set avg_accuracy=79.80% avg_sensitivity=42.09%, avg_specificity=92.67% avg_auc=83.51%
Best model saved!! Metric=83.5143865830427!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.377064 Test loss=0.420139 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.3819095492362976
[5/24] Train loss=0.3765451908111572
[10/24] Train loss=0.3819196820259094
[15/24] Train loss=0.34402862191200256
[20/24] Train loss=0.3692958354949951
Test set avg_accuracy=80.29% avg_sensitivity=43.06%, avg_specificity=92.98% avg_auc=83.82%
Best model saved!! Metric=83.81820878652525!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.368459 Test loss=0.417360 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.3771456778049469
[5/24] Train loss=0.37231987714767456
[10/24] Train loss=0.3718256950378418
[15/24] Train loss=0.34236910939216614
[20/24] Train loss=0.37216320633888245
Test set avg_accuracy=80.07% avg_sensitivity=36.25%, avg_specificity=95.01% avg_auc=83.50%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.364544 Test loss=0.425020 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.372820109128952
[5/24] Train loss=0.3616010844707489
[10/24] Train loss=0.36907732486724854
[15/24] Train loss=0.33792272210121155
[20/24] Train loss=0.3599221408367157
Test set avg_accuracy=80.29% avg_sensitivity=38.25%, avg_specificity=94.62% avg_auc=83.83%
Best model saved!! Metric=83.8281150604779!!
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.359347 Test loss=0.421506 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.36491748690605164
[5/24] Train loss=0.3571133613586426
[10/24] Train loss=0.3690958321094513
[15/24] Train loss=0.3287169933319092
[20/24] Train loss=0.3556666672229767
Test set avg_accuracy=80.33% avg_sensitivity=36.82%, avg_specificity=95.16% avg_auc=84.00%
Best model saved!! Metric=83.99796563756752!!
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.354277 Test loss=0.423302 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.36191973090171814
[5/24] Train loss=0.35598883032798767
[10/24] Train loss=0.35908567905426025
[15/24] Train loss=0.3252438008785248
[20/24] Train loss=0.35599425435066223
Test set avg_accuracy=80.33% avg_sensitivity=34.51%, avg_specificity=95.95% avg_auc=84.01%
Best model saved!! Metric=84.00835917860539!!
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.351448 Test loss=0.424652 Current lr=[0.000669125424222739]

[0/24] Train loss=0.36825641989707947
[5/24] Train loss=0.352525532245636
[10/24] Train loss=0.3501010537147522
[15/24] Train loss=0.3196888267993927
[20/24] Train loss=0.3397427499294281
Test set avg_accuracy=79.82% avg_sensitivity=31.18%, avg_specificity=96.40% avg_auc=84.00%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.347469 Test loss=0.431797 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.37296029925346375
[5/24] Train loss=0.3518720865249634
[10/24] Train loss=0.35273534059524536
[15/24] Train loss=0.3152296245098114
[20/24] Train loss=0.3452880382537842
Test set avg_accuracy=80.13% avg_sensitivity=30.62%, avg_specificity=97.01% avg_auc=83.85%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.347159 Test loss=0.435884 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.37405380606651306
[5/24] Train loss=0.352518767118454
[10/24] Train loss=0.34614765644073486
[15/24] Train loss=0.30653172731399536
[20/24] Train loss=0.34819167852401733
Test set avg_accuracy=80.91% avg_sensitivity=36.46%, avg_specificity=96.07% avg_auc=84.48%
Best model saved!! Metric=84.48242087877769!!
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.343929 Test loss=0.420497 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.3567849099636078
[5/24] Train loss=0.34916555881500244
[10/24] Train loss=0.34769657254219055
[15/24] Train loss=0.3075796365737915
[20/24] Train loss=0.3499356508255005
Test set avg_accuracy=81.39% avg_sensitivity=44.24%, avg_specificity=94.06% avg_auc=84.74%
Best model saved!! Metric=84.73974707351411!!
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.342686 Test loss=0.411725 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.3525645136833191
[5/24] Train loss=0.34633001685142517
[10/24] Train loss=0.3411714434623718
[15/24] Train loss=0.2984777092933655
[20/24] Train loss=0.3382703959941864
Test set avg_accuracy=81.37% avg_sensitivity=41.32%, avg_specificity=95.02% avg_auc=84.75%
Best model saved!! Metric=84.75435614539012!!
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.337958 Test loss=0.412327 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.35672277212142944
[5/24] Train loss=0.3412606418132782
[10/24] Train loss=0.3428807854652405
[15/24] Train loss=0.3027612864971161
[20/24] Train loss=0.3271690905094147
Test set avg_accuracy=81.17% avg_sensitivity=36.61%, avg_specificity=96.37% avg_auc=84.80%
Best model saved!! Metric=84.80393221855564!!
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.334310 Test loss=0.417015 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.34961289167404175
[5/24] Train loss=0.3420812487602234
[10/24] Train loss=0.3353763818740845
[15/24] Train loss=0.29769212007522583
[20/24] Train loss=0.32256415486335754
Test set avg_accuracy=80.72% avg_sensitivity=32.87%, avg_specificity=97.03% avg_auc=84.83%
Best model saved!! Metric=84.82796923797954!!
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.332002 Test loss=0.423293 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.36536821722984314
[5/24] Train loss=0.34293270111083984
[10/24] Train loss=0.3372156322002411
[15/24] Train loss=0.30281510949134827
[20/24] Train loss=0.32249724864959717
Test set avg_accuracy=80.68% avg_sensitivity=31.44%, avg_specificity=97.47% avg_auc=85.18%
Best model saved!! Metric=85.18074166699525!!
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.334119 Test loss=0.423508 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.3722970187664032
[5/24] Train loss=0.3269155025482178
[10/24] Train loss=0.3407699763774872
[15/24] Train loss=0.2950313687324524
[20/24] Train loss=0.3245273232460022
Test set avg_accuracy=80.65% avg_sensitivity=32.05%, avg_specificity=97.22% avg_auc=85.38%
Best model saved!! Metric=85.38092797289472!!
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.331806 Test loss=0.417503 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.369600772857666
[5/24] Train loss=0.33229056000709534
[10/24] Train loss=0.34288910031318665
[15/24] Train loss=0.2992860972881317
[20/24] Train loss=0.33209267258644104
Test set avg_accuracy=81.50% avg_sensitivity=38.76%, avg_specificity=96.07% avg_auc=85.61%
Best model saved!! Metric=85.6117718721007!!
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.333722 Test loss=0.408965 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.35529428720474243
[5/24] Train loss=0.3335469663143158
[10/24] Train loss=0.3407265841960907
[15/24] Train loss=0.3010331094264984
[20/24] Train loss=0.332473486661911
Test set avg_accuracy=81.55% avg_sensitivity=39.27%, avg_specificity=95.97% avg_auc=85.76%
Best model saved!! Metric=85.76465303767219!!
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.332402 Test loss=0.405866 Current lr=[0.000944367614404117]

[0/24] Train loss=0.35658520460128784
[5/24] Train loss=0.3305474817752838
[10/24] Train loss=0.33964747190475464
[15/24] Train loss=0.2930132746696472
[20/24] Train loss=0.3257770836353302
Test set avg_accuracy=82.07% avg_sensitivity=40.71%, avg_specificity=96.18% avg_auc=86.14%
Best model saved!! Metric=86.1358030353789!!
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.328399 Test loss=0.401525 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.3541235029697418
[5/24] Train loss=0.323898047208786
[10/24] Train loss=0.3388987183570862
[15/24] Train loss=0.3008997142314911
[20/24] Train loss=0.3229159116744995
Test set avg_accuracy=82.30% avg_sensitivity=41.68%, avg_specificity=96.16% avg_auc=86.42%
Best model saved!! Metric=86.41801561418318!!
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.327230 Test loss=0.396799 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.3459465205669403
[5/24] Train loss=0.324418842792511
[10/24] Train loss=0.3351188898086548
[15/24] Train loss=0.29246941208839417
[20/24] Train loss=0.32428979873657227
Test set avg_accuracy=82.03% avg_sensitivity=40.76%, avg_specificity=96.11% avg_auc=86.72%
Best model saved!! Metric=86.7165002314295!!
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.324064 Test loss=0.393902 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.3527894616127014
[5/24] Train loss=0.32944244146347046
[10/24] Train loss=0.33509573340415955
[15/24] Train loss=0.29137110710144043
[20/24] Train loss=0.31723684072494507
Test set avg_accuracy=82.50% avg_sensitivity=40.30%, avg_specificity=96.89% avg_auc=86.84%
Best model saved!! Metric=86.8424923005095!!
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.323242 Test loss=0.394279 Current lr=[0.000989780311725182]

[0/24] Train loss=0.34917566180229187
[5/24] Train loss=0.3240377902984619
[10/24] Train loss=0.3338373005390167
[15/24] Train loss=0.2919760048389435
[20/24] Train loss=0.31582921743392944
Test set avg_accuracy=81.56% avg_sensitivity=35.18%, avg_specificity=97.38% avg_auc=86.57%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.323033 Test loss=0.407428 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.3610151410102844
[5/24] Train loss=0.32695508003234863
[10/24] Train loss=0.3323999345302582
[15/24] Train loss=0.2938585877418518
[20/24] Train loss=0.31796717643737793
Test set avg_accuracy=81.98% avg_sensitivity=36.51%, avg_specificity=97.49% avg_auc=86.55%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.322853 Test loss=0.408883 Current lr=[0.000998924125869967]

[0/24] Train loss=0.3610110282897949
[5/24] Train loss=0.32918691635131836
[10/24] Train loss=0.33321884274482727
[15/24] Train loss=0.2918999493122101
[20/24] Train loss=0.3191778361797333
Test set avg_accuracy=82.47% avg_sensitivity=42.19%, avg_specificity=96.21% avg_auc=86.66%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.322311 Test loss=0.397043 Current lr=[0.000999999611458977]

[0/24] Train loss=0.34626320004463196
[5/24] Train loss=0.3268081247806549
[10/24] Train loss=0.3280990719795227
[15/24] Train loss=0.2960103154182434
[20/24] Train loss=0.3195129632949829
Test set avg_accuracy=82.17% avg_sensitivity=38.50%, avg_specificity=97.07% avg_auc=86.80%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.320914 Test loss=0.403357 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.3524157404899597
[5/24] Train loss=0.325236976146698
[10/24] Train loss=0.33265674114227295
[15/24] Train loss=0.2865969240665436
[20/24] Train loss=0.3163585364818573
Test set avg_accuracy=82.14% avg_sensitivity=38.81%, avg_specificity=96.91% avg_auc=86.96%
Best model saved!! Metric=86.96081773609275!!
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.321091 Test loss=0.399594 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.3521374464035034
[5/24] Train loss=0.32473793625831604
[10/24] Train loss=0.33265605568885803
[15/24] Train loss=0.28990548849105835
[20/24] Train loss=0.3195318579673767
Test set avg_accuracy=81.86% avg_sensitivity=36.87%, avg_specificity=97.21% avg_auc=86.92%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.320603 Test loss=0.400451 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3503001630306244
[5/24] Train loss=0.3268451988697052
[10/24] Train loss=0.33229756355285645
[15/24] Train loss=0.2925158441066742
[20/24] Train loss=0.31832319498062134
Test set avg_accuracy=82.24% avg_sensitivity=40.50%, avg_specificity=96.47% avg_auc=87.18%
Best model saved!! Metric=87.18318587022011!!
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.319900 Test loss=0.394449 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3445870876312256
[5/24] Train loss=0.3216046094894409
[10/24] Train loss=0.3298828601837158
[15/24] Train loss=0.2851508557796478
[20/24] Train loss=0.3213275372982025
Test set avg_accuracy=82.37% avg_sensitivity=44.65%, avg_specificity=95.23% avg_auc=87.30%
Best model saved!! Metric=87.30223997126107!!
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.319731 Test loss=0.385616 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.33858662843704224
[5/24] Train loss=0.32651466131210327
[10/24] Train loss=0.3319167494773865
[15/24] Train loss=0.28312602639198303
[20/24] Train loss=0.32007575035095215
Test set avg_accuracy=82.43% avg_sensitivity=48.80%, avg_specificity=93.91% avg_auc=87.43%
Best model saved!! Metric=87.43468721163512!!
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.318450 Test loss=0.382068 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.33685457706451416
[5/24] Train loss=0.32432878017425537
[10/24] Train loss=0.33104363083839417
[15/24] Train loss=0.2844303846359253
[20/24] Train loss=0.3221418261528015
Test set avg_accuracy=82.66% avg_sensitivity=50.03%, avg_specificity=93.78% avg_auc=87.45%
Best model saved!! Metric=87.44730698210816!!
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.319842 Test loss=0.382535 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.33762773871421814
[5/24] Train loss=0.3228982090950012
[10/24] Train loss=0.32999783754348755
[15/24] Train loss=0.2858264148235321
[20/24] Train loss=0.3204612135887146
Test set avg_accuracy=82.73% avg_sensitivity=51.46%, avg_specificity=93.40% avg_auc=87.42%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.318959 Test loss=0.382874 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.33918502926826477
[5/24] Train loss=0.32402727007865906
[10/24] Train loss=0.3340691924095154
[15/24] Train loss=0.29223158955574036
[20/24] Train loss=0.3159128725528717
Test set avg_accuracy=82.71% avg_sensitivity=49.82%, avg_specificity=93.92% avg_auc=87.61%
Best model saved!! Metric=87.61060404041866!!
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.318382 Test loss=0.381455 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.3336874842643738
[5/24] Train loss=0.3196191191673279
[10/24] Train loss=0.3322569727897644
[15/24] Train loss=0.2934204339981079
[20/24] Train loss=0.3172180652618408
Test set avg_accuracy=82.60% avg_sensitivity=47.57%, avg_specificity=94.55% avg_auc=87.54%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.318305 Test loss=0.384629 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.3337239623069763
[5/24] Train loss=0.3209439516067505
[10/24] Train loss=0.3303755521774292
[15/24] Train loss=0.2854733169078827
[20/24] Train loss=0.3162009119987488
Test set avg_accuracy=82.43% avg_sensitivity=47.06%, avg_specificity=94.50% avg_auc=87.54%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.316423 Test loss=0.384682 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.3364916145801544
[5/24] Train loss=0.3182810842990875
[10/24] Train loss=0.3346197009086609
[15/24] Train loss=0.289279580116272
[20/24] Train loss=0.31492260098457336
Test set avg_accuracy=82.49% avg_sensitivity=46.39%, avg_specificity=94.80% avg_auc=87.45%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.315872 Test loss=0.387760 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.334797739982605
[5/24] Train loss=0.32040223479270935
[10/24] Train loss=0.3323436379432678
[15/24] Train loss=0.28535425662994385
[20/24] Train loss=0.31167465448379517
Test set avg_accuracy=82.49% avg_sensitivity=46.08%, avg_specificity=94.90% avg_auc=87.48%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.315924 Test loss=0.387184 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.33391937613487244
[5/24] Train loss=0.3208997845649719
[10/24] Train loss=0.3359090983867645
[15/24] Train loss=0.2894420325756073
[20/24] Train loss=0.3120179772377014
Test set avg_accuracy=82.15% avg_sensitivity=43.93%, avg_specificity=95.18% avg_auc=87.45%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.315817 Test loss=0.390175 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.3384595811367035
[5/24] Train loss=0.3222084641456604
[10/24] Train loss=0.33785635232925415
[15/24] Train loss=0.29114142060279846
[20/24] Train loss=0.3205704391002655
Test set avg_accuracy=82.54% avg_sensitivity=45.67%, avg_specificity=95.11% avg_auc=87.63%
Best model saved!! Metric=87.6303093001584!!
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.318130 Test loss=0.386767 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.33145350217819214
[5/24] Train loss=0.3200208246707916
[10/24] Train loss=0.33860933780670166
[15/24] Train loss=0.28837016224861145
[20/24] Train loss=0.32669076323509216
Test set avg_accuracy=83.14% avg_sensitivity=54.58%, avg_specificity=92.88% avg_auc=88.07%
Best model saved!! Metric=88.07370446634376!!
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.317536 Test loss=0.370696 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.3369765281677246
[5/24] Train loss=0.31706860661506653
[10/24] Train loss=0.3418620228767395
[15/24] Train loss=0.28803929686546326
[20/24] Train loss=0.3150308132171631
Test set avg_accuracy=83.71% avg_sensitivity=55.76%, avg_specificity=93.24% avg_auc=88.24%
Best model saved!! Metric=88.24060908922092!!
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.318126 Test loss=0.368849 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.3272019922733307
[5/24] Train loss=0.31732040643692017
[10/24] Train loss=0.3345191478729248
[15/24] Train loss=0.2896580398082733
[20/24] Train loss=0.31669747829437256
Test set avg_accuracy=83.55% avg_sensitivity=52.02%, avg_specificity=94.31% avg_auc=88.11%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.315787 Test loss=0.373342 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.32976359128952026
[5/24] Train loss=0.3200475871562958
[10/24] Train loss=0.33562248945236206
[15/24] Train loss=0.2881525158882141
[20/24] Train loss=0.3207820951938629
Test set avg_accuracy=83.42% avg_sensitivity=52.43%, avg_specificity=93.99% avg_auc=88.28%
Best model saved!! Metric=88.2828180416852!!
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.317026 Test loss=0.369952 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.32749149203300476
[5/24] Train loss=0.31673726439476013
[10/24] Train loss=0.32965198159217834
[15/24] Train loss=0.2910424768924713
[20/24] Train loss=0.3165188729763031
Test set avg_accuracy=83.58% avg_sensitivity=52.59%, avg_specificity=94.15% avg_auc=88.27%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.316743 Test loss=0.369481 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.32727834582328796
[5/24] Train loss=0.31456077098846436
[10/24] Train loss=0.3337719738483429
[15/24] Train loss=0.2817326784133911
[20/24] Train loss=0.3191775977611542
Test set avg_accuracy=83.01% avg_sensitivity=50.18%, avg_specificity=94.20% avg_auc=88.36%
Best model saved!! Metric=88.35840702465688!!
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.314886 Test loss=0.371848 Current lr=[0.000904142181093812]

[0/24] Train loss=0.331865519285202
[5/24] Train loss=0.3186299502849579
[10/24] Train loss=0.33221739530563354
[15/24] Train loss=0.282246857881546
[20/24] Train loss=0.3178623616695404
Test set avg_accuracy=83.67% avg_sensitivity=51.87%, avg_specificity=94.52% avg_auc=88.32%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.315081 Test loss=0.371281 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.3231227397918701
[5/24] Train loss=0.3159514367580414
[10/24] Train loss=0.3256485164165497
[15/24] Train loss=0.2848484218120575
[20/24] Train loss=0.3143821060657501
Test set avg_accuracy=83.59% avg_sensitivity=53.46%, avg_specificity=93.87% avg_auc=88.36%
Best model saved!! Metric=88.35883170697885!!
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.314059 Test loss=0.369474 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.3220805525779724
[5/24] Train loss=0.319507896900177
[10/24] Train loss=0.32583940029144287
[15/24] Train loss=0.27861514687538147
[20/24] Train loss=0.3143661618232727
Test set avg_accuracy=83.24% avg_sensitivity=51.87%, avg_specificity=93.94% avg_auc=88.23%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.312563 Test loss=0.373768 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.32526934146881104
[5/24] Train loss=0.3197046220302582
[10/24] Train loss=0.32510727643966675
[15/24] Train loss=0.27943140268325806
[20/24] Train loss=0.3179531395435333
Test set avg_accuracy=82.94% avg_sensitivity=52.69%, avg_specificity=93.26% avg_auc=88.19%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.312730 Test loss=0.374706 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.31697091460227966
[5/24] Train loss=0.3105136752128601
[10/24] Train loss=0.3194538354873657
[15/24] Train loss=0.2805621027946472
[20/24] Train loss=0.31775182485580444
Test set avg_accuracy=83.39% avg_sensitivity=52.89%, avg_specificity=93.78% avg_auc=88.14%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.311336 Test loss=0.375387 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.31727689504623413
[5/24] Train loss=0.31466105580329895
[10/24] Train loss=0.3249508738517761
[15/24] Train loss=0.28010889887809753
[20/24] Train loss=0.31537339091300964
Test set avg_accuracy=83.53% avg_sensitivity=56.89%, avg_specificity=92.61% avg_auc=88.44%
Best model saved!! Metric=88.44200685732311!!
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.311498 Test loss=0.369808 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.31637027859687805
[5/24] Train loss=0.30968859791755676
[10/24] Train loss=0.32091689109802246
[15/24] Train loss=0.2794695794582367
[20/24] Train loss=0.3082018792629242
Test set avg_accuracy=83.28% avg_sensitivity=54.38%, avg_specificity=93.14% avg_auc=88.21%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.310143 Test loss=0.374676 Current lr=[0.000834102481048427]

[0/24] Train loss=0.32011130452156067
[5/24] Train loss=0.3112693727016449
[10/24] Train loss=0.32653117179870605
[15/24] Train loss=0.2790414094924927
[20/24] Train loss=0.31262025237083435
Test set avg_accuracy=83.48% avg_sensitivity=54.02%, avg_specificity=93.52% avg_auc=88.05%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.310182 Test loss=0.376921 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.3166152536869049
[5/24] Train loss=0.3141983151435852
[10/24] Train loss=0.3247672915458679
[15/24] Train loss=0.27696800231933594
[20/24] Train loss=0.31482890248298645
Test set avg_accuracy=83.49% avg_sensitivity=54.69%, avg_specificity=93.31% avg_auc=88.19%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.309734 Test loss=0.375306 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.3190079629421234
[5/24] Train loss=0.30944716930389404
[10/24] Train loss=0.32245466113090515
[15/24] Train loss=0.27585071325302124
[20/24] Train loss=0.31120720505714417
Test set avg_accuracy=83.48% avg_sensitivity=56.07%, avg_specificity=92.82% avg_auc=88.35%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.309417 Test loss=0.375095 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.32407307624816895
[5/24] Train loss=0.310377299785614
[10/24] Train loss=0.3307419419288635
[15/24] Train loss=0.2776937186717987
[20/24] Train loss=0.3081420361995697
Test set avg_accuracy=83.16% avg_sensitivity=57.65%, avg_specificity=91.86% avg_auc=88.30%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.310634 Test loss=0.375944 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.3261798322200775
[5/24] Train loss=0.31389930844306946
[10/24] Train loss=0.33088165521621704
[15/24] Train loss=0.28781822323799133
[20/24] Train loss=0.3098995089530945
Test set avg_accuracy=83.29% avg_sensitivity=54.94%, avg_specificity=92.96% avg_auc=88.43%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.312929 Test loss=0.374710 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.32834258675575256
[5/24] Train loss=0.3097018301486969
[10/24] Train loss=0.31653696298599243
[15/24] Train loss=0.27543145418167114
[20/24] Train loss=0.3085532486438751
Test set avg_accuracy=83.32% avg_sensitivity=56.73%, avg_specificity=92.39% avg_auc=88.44%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.308070 Test loss=0.373393 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.32639080286026
[5/24] Train loss=0.3087276518344879
[10/24] Train loss=0.3262815773487091
[15/24] Train loss=0.27750375866889954
[20/24] Train loss=0.31295040249824524
Test set avg_accuracy=82.92% avg_sensitivity=56.02%, avg_specificity=92.09% avg_auc=88.31%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.309447 Test loss=0.375395 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.3228914141654968
[5/24] Train loss=0.31042978167533875
[10/24] Train loss=0.3263147175312042
[15/24] Train loss=0.2802850604057312
[20/24] Train loss=0.3193657398223877
Test set avg_accuracy=83.09% avg_sensitivity=58.01%, avg_specificity=91.64% avg_auc=88.59%
Best model saved!! Metric=88.59217899671438!!
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.310187 Test loss=0.369166 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.31934159994125366
[5/24] Train loss=0.30943912267684937
[10/24] Train loss=0.3322966396808624
[15/24] Train loss=0.28818005323410034
[20/24] Train loss=0.3161778151988983
Test set avg_accuracy=83.24% avg_sensitivity=60.42%, avg_specificity=91.02% avg_auc=88.76%
Best model saved!! Metric=88.75735359792205!!
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.310968 Test loss=0.366185 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.3202630877494812
[5/24] Train loss=0.30870309472084045
[10/24] Train loss=0.32874706387519836
[15/24] Train loss=0.2900356352329254
[20/24] Train loss=0.3243125081062317
Test set avg_accuracy=83.11% avg_sensitivity=66.05%, avg_specificity=88.93% avg_auc=88.55%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.310789 Test loss=0.372248 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.32596227526664734
[5/24] Train loss=0.30982643365859985
[10/24] Train loss=0.3216419517993927
[15/24] Train loss=0.2841224670410156
[20/24] Train loss=0.3129006326198578
Test set avg_accuracy=82.86% avg_sensitivity=61.60%, avg_specificity=90.12% avg_auc=88.42%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.312801 Test loss=0.369835 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.32748642563819885
[5/24] Train loss=0.31674447655677795
[10/24] Train loss=0.3119872212409973
[15/24] Train loss=0.2824203073978424
[20/24] Train loss=0.3142056167125702
Test set avg_accuracy=82.96% avg_sensitivity=60.16%, avg_specificity=90.73% avg_auc=88.33%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.309996 Test loss=0.371036 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.3217220604419708
[5/24] Train loss=0.3109619915485382
[10/24] Train loss=0.30822211503982544
[15/24] Train loss=0.2739104628562927
[20/24] Train loss=0.30855032801628113
Test set avg_accuracy=83.29% avg_sensitivity=61.55%, avg_specificity=90.71% avg_auc=88.42%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.306184 Test loss=0.370966 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.32105258107185364
[5/24] Train loss=0.3058440387248993
[10/24] Train loss=0.3181897699832916
[15/24] Train loss=0.27563631534576416
[20/24] Train loss=0.31251025199890137
Test set avg_accuracy=82.86% avg_sensitivity=61.34%, avg_specificity=90.20% avg_auc=88.35%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.304658 Test loss=0.371480 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.3191604018211365
[5/24] Train loss=0.3053916096687317
[10/24] Train loss=0.3143385052680969
[15/24] Train loss=0.27655497193336487
[20/24] Train loss=0.3096392750740051
Test set avg_accuracy=83.06% avg_sensitivity=60.06%, avg_specificity=90.90% avg_auc=88.26%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.305204 Test loss=0.372366 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.3161179721355438
[5/24] Train loss=0.3078976273536682
[10/24] Train loss=0.30900058150291443
[15/24] Train loss=0.27417463064193726
[20/24] Train loss=0.3067847788333893
Test set avg_accuracy=82.89% avg_sensitivity=60.52%, avg_specificity=90.52% avg_auc=88.16%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.303339 Test loss=0.374451 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.3236120343208313
[5/24] Train loss=0.3044624924659729
[10/24] Train loss=0.31086012721061707
[15/24] Train loss=0.27013298869132996
[20/24] Train loss=0.3040720820426941
Test set avg_accuracy=82.98% avg_sensitivity=60.01%, avg_specificity=90.82% avg_auc=88.15%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.302484 Test loss=0.376104 Current lr=[0.00061065423442182]

[0/24] Train loss=0.32379424571990967
[5/24] Train loss=0.3058894872665405
[10/24] Train loss=0.3115842342376709
[15/24] Train loss=0.2737556993961334
[20/24] Train loss=0.3043692111968994
Test set avg_accuracy=82.88% avg_sensitivity=56.58%, avg_specificity=91.85% avg_auc=88.17%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.302901 Test loss=0.375384 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.31794673204421997
[5/24] Train loss=0.30745476484298706
[10/24] Train loss=0.3087373375892639
[15/24] Train loss=0.2705179750919342
[20/24] Train loss=0.29966798424720764
Test set avg_accuracy=82.53% avg_sensitivity=56.27%, avg_specificity=91.48% avg_auc=88.09%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.299895 Test loss=0.376977 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.31495344638824463
[5/24] Train loss=0.2974714934825897
[10/24] Train loss=0.3068636655807495
[15/24] Train loss=0.2695699632167816
[20/24] Train loss=0.2970972955226898
Test set avg_accuracy=82.33% avg_sensitivity=54.99%, avg_specificity=91.65% avg_auc=88.07%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.298584 Test loss=0.378308 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.31099221110343933
[5/24] Train loss=0.3001364469528198
[10/24] Train loss=0.3010573089122772
[15/24] Train loss=0.27127254009246826
[20/24] Train loss=0.3044887185096741
Test set avg_accuracy=82.58% avg_sensitivity=54.79%, avg_specificity=92.06% avg_auc=87.90%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.298146 Test loss=0.381949 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.3130587041378021
[5/24] Train loss=0.2987208664417267
[10/24] Train loss=0.3064214885234833
[15/24] Train loss=0.2650519907474518
[20/24] Train loss=0.302329957485199
Test set avg_accuracy=82.81% avg_sensitivity=54.89%, avg_specificity=92.33% avg_auc=88.01%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.297794 Test loss=0.380539 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.3106233775615692
[5/24] Train loss=0.2963818311691284
[10/24] Train loss=0.3044813573360443
[15/24] Train loss=0.26458773016929626
[20/24] Train loss=0.29806673526763916
Test set avg_accuracy=82.67% avg_sensitivity=54.89%, avg_specificity=92.14% avg_auc=87.90%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.297516 Test loss=0.383688 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.30920544266700745
[5/24] Train loss=0.29770681262016296
[10/24] Train loss=0.3055432140827179
[15/24] Train loss=0.2693915367126465
[20/24] Train loss=0.3005416989326477
Test set avg_accuracy=82.89% avg_sensitivity=54.84%, avg_specificity=92.46% avg_auc=88.00%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.297009 Test loss=0.382181 Current lr=[0.000506858408304961]

[0/24] Train loss=0.31139159202575684
[5/24] Train loss=0.2989543676376343
[10/24] Train loss=0.30961206555366516
[15/24] Train loss=0.2697007656097412
[20/24] Train loss=0.29992079734802246
Test set avg_accuracy=82.93% avg_sensitivity=52.94%, avg_specificity=93.16% avg_auc=87.93%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.296095 Test loss=0.384574 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.3142302930355072
[5/24] Train loss=0.29678764939308167
[10/24] Train loss=0.30331358313560486
[15/24] Train loss=0.27527502179145813
[20/24] Train loss=0.2997071444988251
Test set avg_accuracy=83.09% avg_sensitivity=54.28%, avg_specificity=92.91% avg_auc=88.27%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.298556 Test loss=0.377263 Current lr=[0.000476946990416354]

[0/24] Train loss=0.31239035725593567
[5/24] Train loss=0.2994435727596283
[10/24] Train loss=0.30904802680015564
[15/24] Train loss=0.27308592200279236
[20/24] Train loss=0.29999834299087524
Test set avg_accuracy=83.07% avg_sensitivity=52.74%, avg_specificity=93.42% avg_auc=88.38%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.299396 Test loss=0.375340 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.3171737492084503
[5/24] Train loss=0.29574453830718994
[10/24] Train loss=0.30682051181793213
[15/24] Train loss=0.27732571959495544
[20/24] Train loss=0.3039998412132263
Test set avg_accuracy=83.12% avg_sensitivity=58.88%, avg_specificity=91.39% avg_auc=88.52%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.301498 Test loss=0.369574 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.3034970164299011
[5/24] Train loss=0.31235188245773315
[10/24] Train loss=0.3298587203025818
[15/24] Train loss=0.28039437532424927
[20/24] Train loss=0.30228230357170105
Test set avg_accuracy=82.79% avg_sensitivity=70.46%, avg_specificity=86.99% avg_auc=88.75%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.309036 Test loss=0.376232 Current lr=[0.000432267999769856]

[0/24] Train loss=0.32462960481643677
[5/24] Train loss=0.33057212829589844
[10/24] Train loss=0.3181792199611664
[15/24] Train loss=0.26588937640190125
[20/24] Train loss=0.315398246049881
Test set avg_accuracy=82.98% avg_sensitivity=69.02%, avg_specificity=87.74% avg_auc=88.82%
Best model saved!! Metric=88.82159685738658!!
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.306900 Test loss=0.371985 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.31552350521087646
[5/24] Train loss=0.304185688495636
[10/24] Train loss=0.2991340756416321
[15/24] Train loss=0.26017576456069946
[20/24] Train loss=0.31354060769081116
Test set avg_accuracy=83.03% avg_sensitivity=66.26%, avg_specificity=88.76% avg_auc=88.63%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.299224 Test loss=0.373847 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.3058488368988037
[5/24] Train loss=0.3014847934246063
[10/24] Train loss=0.30198773741722107
[15/24] Train loss=0.26409971714019775
[20/24] Train loss=0.3080832362174988
Test set avg_accuracy=83.18% avg_sensitivity=66.31%, avg_specificity=88.93% avg_auc=88.72%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.296004 Test loss=0.372498 Current lr=[0.000388134363466264]

[0/24] Train loss=0.3075796365737915
[5/24] Train loss=0.30493661761283875
[10/24] Train loss=0.30389127135276794
[15/24] Train loss=0.26482945680618286
[20/24] Train loss=0.30000123381614685
Test set avg_accuracy=82.99% avg_sensitivity=66.97%, avg_specificity=88.46% avg_auc=88.64%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.295075 Test loss=0.375499 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.3068573474884033
[5/24] Train loss=0.30268168449401855
[10/24] Train loss=0.30248361825942993
[15/24] Train loss=0.26225873827934265
[20/24] Train loss=0.30165407061576843
Test set avg_accuracy=83.12% avg_sensitivity=66.15%, avg_specificity=88.91% avg_auc=88.48%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.293075 Test loss=0.377460 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.3063455820083618
[5/24] Train loss=0.2991954982280731
[10/24] Train loss=0.29833921790122986
[15/24] Train loss=0.26197314262390137
[20/24] Train loss=0.30102822184562683
Test set avg_accuracy=83.29% avg_sensitivity=65.03%, avg_specificity=89.52% avg_auc=88.49%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.292374 Test loss=0.375971 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.30235716700553894
[5/24] Train loss=0.29313164949417114
[10/24] Train loss=0.30190804600715637
[15/24] Train loss=0.2582831084728241
[20/24] Train loss=0.30311137437820435
Test set avg_accuracy=83.37% avg_sensitivity=63.13%, avg_specificity=90.27% avg_auc=88.32%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.290349 Test loss=0.376890 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.3041180968284607
[5/24] Train loss=0.2935224771499634
[10/24] Train loss=0.294818252325058
[15/24] Train loss=0.2600499391555786
[20/24] Train loss=0.29294365644454956
Test set avg_accuracy=82.99% avg_sensitivity=62.78%, avg_specificity=89.89% avg_auc=88.24%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.288817 Test loss=0.379179 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.2993652820587158
[5/24] Train loss=0.29571396112442017
[10/24] Train loss=0.2916029691696167
[15/24] Train loss=0.26155757904052734
[20/24] Train loss=0.2947830855846405
Test set avg_accuracy=83.39% avg_sensitivity=64.06%, avg_specificity=89.98% avg_auc=88.23%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.289146 Test loss=0.379434 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.3023846447467804
[5/24] Train loss=0.289993554353714
[10/24] Train loss=0.2956956624984741
[15/24] Train loss=0.2572372257709503
[20/24] Train loss=0.2999248206615448
Test set avg_accuracy=83.07% avg_sensitivity=63.90%, avg_specificity=89.61% avg_auc=88.16%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.287944 Test loss=0.381083 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2998899519443512
[5/24] Train loss=0.2900078594684601
[10/24] Train loss=0.2923133373260498
[15/24] Train loss=0.25809186697006226
[20/24] Train loss=0.2983362376689911
Test set avg_accuracy=83.11% avg_sensitivity=63.18%, avg_specificity=89.91% avg_auc=88.04%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.286901 Test loss=0.383389 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.3007007837295532
[5/24] Train loss=0.28701314330101013
[10/24] Train loss=0.2958822548389435
[15/24] Train loss=0.2531224489212036
[20/24] Train loss=0.29462626576423645
Test set avg_accuracy=83.03% avg_sensitivity=61.65%, avg_specificity=90.33% avg_auc=87.83%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.286698 Test loss=0.385826 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.29795682430267334
[5/24] Train loss=0.29185187816619873
[10/24] Train loss=0.2934688627719879
[15/24] Train loss=0.25341930985450745
[20/24] Train loss=0.2938345670700073
Test set avg_accuracy=83.07% avg_sensitivity=63.29%, avg_specificity=89.82% avg_auc=87.82%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.285943 Test loss=0.387107 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.30144399404525757
[5/24] Train loss=0.29003435373306274
[10/24] Train loss=0.2923390865325928
[15/24] Train loss=0.25305992364883423
[20/24] Train loss=0.2953460216522217
Test set avg_accuracy=83.41% avg_sensitivity=60.83%, avg_specificity=91.11% avg_auc=87.72%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.285616 Test loss=0.388372 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.30003824830055237
[5/24] Train loss=0.2831835448741913
[10/24] Train loss=0.29169777035713196
[15/24] Train loss=0.2535046935081482
[20/24] Train loss=0.28735172748565674
Test set avg_accuracy=83.10% avg_sensitivity=61.03%, avg_specificity=90.62% avg_auc=87.67%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.283499 Test loss=0.389958 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.297046422958374
[5/24] Train loss=0.28205689787864685
[10/24] Train loss=0.2942107617855072
[15/24] Train loss=0.2548307478427887
[20/24] Train loss=0.2872888147830963
Test set avg_accuracy=83.12% avg_sensitivity=60.42%, avg_specificity=90.87% avg_auc=87.69%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.282719 Test loss=0.389758 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.298712819814682
[5/24] Train loss=0.28938615322113037
[10/24] Train loss=0.28796887397766113
[15/24] Train loss=0.2501368522644043
[20/24] Train loss=0.28911101818084717
Test set avg_accuracy=83.23% avg_sensitivity=60.52%, avg_specificity=90.97% avg_auc=87.60%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.281824 Test loss=0.391714 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.2948559522628784
[5/24] Train loss=0.2809669077396393
[10/24] Train loss=0.2866242825984955
[15/24] Train loss=0.2518714666366577
[20/24] Train loss=0.29113876819610596
Test set avg_accuracy=83.37% avg_sensitivity=60.11%, avg_specificity=91.30% avg_auc=87.64%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.281142 Test loss=0.390999 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2918771207332611
[5/24] Train loss=0.28515028953552246
[10/24] Train loss=0.29038459062576294
[15/24] Train loss=0.25422364473342896
[20/24] Train loss=0.2844250798225403
Test set avg_accuracy=83.28% avg_sensitivity=59.55%, avg_specificity=91.37% avg_auc=87.53%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.281728 Test loss=0.392425 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.29809486865997314
[5/24] Train loss=0.28334179520606995
[10/24] Train loss=0.28978437185287476
[15/24] Train loss=0.25689512491226196
[20/24] Train loss=0.285317599773407
Test set avg_accuracy=83.52% avg_sensitivity=59.81%, avg_specificity=91.60% avg_auc=87.53%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.281245 Test loss=0.392227 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.2938762903213501
[5/24] Train loss=0.28141143918037415
[10/24] Train loss=0.2905324399471283
[15/24] Train loss=0.256655216217041
[20/24] Train loss=0.28331923484802246
Test set avg_accuracy=83.29% avg_sensitivity=59.96%, avg_specificity=91.25% avg_auc=87.48%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.280710 Test loss=0.393244 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.297324001789093
[5/24] Train loss=0.2822018563747406
[10/24] Train loss=0.28962671756744385
[15/24] Train loss=0.2552010416984558
[20/24] Train loss=0.28879937529563904
Test set avg_accuracy=83.44% avg_sensitivity=59.86%, avg_specificity=91.48% avg_auc=87.44%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.281095 Test loss=0.393911 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.2905600965023041
[5/24] Train loss=0.28722769021987915
[10/24] Train loss=0.2888743281364441
[15/24] Train loss=0.25729477405548096
[20/24] Train loss=0.28327760100364685
Test set avg_accuracy=83.27% avg_sensitivity=58.32%, avg_specificity=91.78% avg_auc=87.50%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.281147 Test loss=0.392739 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.2943345010280609
[5/24] Train loss=0.286488801240921
[10/24] Train loss=0.28530845046043396
[15/24] Train loss=0.25744304060935974
[20/24] Train loss=0.28368079662323
Test set avg_accuracy=83.19% avg_sensitivity=58.47%, avg_specificity=91.62% avg_auc=87.56%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.280982 Test loss=0.391681 Current lr=[0.000123057953306828]

[0/24] Train loss=0.2933194637298584
[5/24] Train loss=0.2928216755390167
[10/24] Train loss=0.29154136776924133
[15/24] Train loss=0.25571176409721375
[20/24] Train loss=0.27872174978256226
Test set avg_accuracy=83.66% avg_sensitivity=61.09%, avg_specificity=91.36% avg_auc=87.62%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.281892 Test loss=0.390755 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.2887687087059021
[5/24] Train loss=0.293232798576355
[10/24] Train loss=0.28939032554626465
[15/24] Train loss=0.25890105962753296
[20/24] Train loss=0.2849080264568329
Test set avg_accuracy=82.97% avg_sensitivity=63.39%, avg_specificity=89.65% avg_auc=87.73%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.284247 Test loss=0.390292 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.29457634687423706
[5/24] Train loss=0.29025205969810486
[10/24] Train loss=0.3004409968852997
[15/24] Train loss=0.24764660000801086
[20/24] Train loss=0.2896403670310974
Test set avg_accuracy=82.81% avg_sensitivity=66.46%, avg_specificity=88.39% avg_auc=87.92%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.283658 Test loss=0.392001 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.3000052869319916
[5/24] Train loss=0.28379181027412415
[10/24] Train loss=0.30352553725242615
[15/24] Train loss=0.25132814049720764
[20/24] Train loss=0.2853821814060211
Test set avg_accuracy=82.46% avg_sensitivity=68.36%, avg_specificity=87.27% avg_auc=87.94%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.284789 Test loss=0.396118 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.3022879362106323
[5/24] Train loss=0.2721361517906189
[10/24] Train loss=0.29585254192352295
[15/24] Train loss=0.25357550382614136
[20/24] Train loss=0.28447389602661133
Test set avg_accuracy=82.63% avg_sensitivity=66.21%, avg_specificity=88.23% avg_auc=87.83%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.282111 Test loss=0.392629 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.3019382953643799
[5/24] Train loss=0.2752995193004608
[10/24] Train loss=0.2896363437175751
[15/24] Train loss=0.25103604793548584
[20/24] Train loss=0.2884884178638458
Test set avg_accuracy=82.89% avg_sensitivity=63.80%, avg_specificity=89.40% avg_auc=87.70%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.279603 Test loss=0.391497 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.2978765070438385
[5/24] Train loss=0.27541473507881165
[10/24] Train loss=0.28751078248023987
[15/24] Train loss=0.24679547548294067
[20/24] Train loss=0.2859881818294525
Test set avg_accuracy=82.94% avg_sensitivity=63.44%, avg_specificity=89.59% avg_auc=87.62%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.279300 Test loss=0.393070 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.2959548830986023
[5/24] Train loss=0.27311593294143677
[10/24] Train loss=0.2874109447002411
[15/24] Train loss=0.25190049409866333
[20/24] Train loss=0.2838256359100342
Test set avg_accuracy=82.89% avg_sensitivity=64.00%, avg_specificity=89.33% avg_auc=87.63%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.277824 Test loss=0.393741 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.28915080428123474
[5/24] Train loss=0.27137941122055054
[10/24] Train loss=0.2849985957145691
[15/24] Train loss=0.25072726607322693
[20/24] Train loss=0.2819354236125946
Test set avg_accuracy=83.01% avg_sensitivity=63.18%, avg_specificity=89.77% avg_auc=87.56%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.277716 Test loss=0.394421 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.28808271884918213
[5/24] Train loss=0.27801892161369324
[10/24] Train loss=0.28810662031173706
[15/24] Train loss=0.2491655945777893
[20/24] Train loss=0.28365761041641235
Test set avg_accuracy=82.99% avg_sensitivity=63.24%, avg_specificity=89.73% avg_auc=87.55%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.278129 Test loss=0.394481 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.2908429205417633
[5/24] Train loss=0.27823206782341003
[10/24] Train loss=0.2871093153953552
[15/24] Train loss=0.2472562938928604
[20/24] Train loss=0.2801416516304016
Test set avg_accuracy=83.02% avg_sensitivity=63.13%, avg_specificity=89.80% avg_auc=87.54%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.277866 Test loss=0.394500 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.2893981337547302
[5/24] Train loss=0.27741098403930664
[10/24] Train loss=0.28170740604400635
[15/24] Train loss=0.25384458899497986
[20/24] Train loss=0.2838210165500641
Test set avg_accuracy=82.99% avg_sensitivity=62.98%, avg_specificity=89.82% avg_auc=87.52%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.277266 Test loss=0.394878 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.2965337932109833
[5/24] Train loss=0.2736216187477112
[10/24] Train loss=0.28648415207862854
[15/24] Train loss=0.2490418255329132
[20/24] Train loss=0.27953413128852844
Test set avg_accuracy=83.12% avg_sensitivity=62.93%, avg_specificity=90.01% avg_auc=87.53%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.277525 Test loss=0.394765 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.29381605982780457
[5/24] Train loss=0.27607461810112
[10/24] Train loss=0.28300997614860535
[15/24] Train loss=0.2487632930278778
[20/24] Train loss=0.2784171998500824
Test set avg_accuracy=83.23% avg_sensitivity=62.78%, avg_specificity=90.20% avg_auc=87.50%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.276315 Test loss=0.395080 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.2896091938018799
[5/24] Train loss=0.2769048810005188
[10/24] Train loss=0.28757643699645996
[15/24] Train loss=0.24851390719413757
[20/24] Train loss=0.28381654620170593
Test set avg_accuracy=83.06% avg_sensitivity=62.78%, avg_specificity=89.98% avg_auc=87.50%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.276425 Test loss=0.395414 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.292551189661026
[5/24] Train loss=0.2702193856239319
[10/24] Train loss=0.2801174223423004
[15/24] Train loss=0.25388455390930176
[20/24] Train loss=0.2860347628593445
Test set avg_accuracy=83.23% avg_sensitivity=62.62%, avg_specificity=90.26% avg_auc=87.48%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.276395 Test loss=0.395483 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.2908099591732025
[5/24] Train loss=0.27775824069976807
[10/24] Train loss=0.2817983627319336
[15/24] Train loss=0.24484623968601227
[20/24] Train loss=0.2850908935070038
Test set avg_accuracy=83.26% avg_sensitivity=62.67%, avg_specificity=90.27% avg_auc=87.48%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.276441 Test loss=0.395595 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.2969553470611572
[5/24] Train loss=0.27177175879478455
[10/24] Train loss=0.2845943570137024
[15/24] Train loss=0.2535479962825775
[20/24] Train loss=0.28264957666397095
Test set avg_accuracy=83.11% avg_sensitivity=62.67%, avg_specificity=90.08% avg_auc=87.48%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.276705 Test loss=0.395515 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.2878468632698059
[5/24] Train loss=0.27786168456077576
[10/24] Train loss=0.28221437335014343
[15/24] Train loss=0.2490052878856659
[20/24] Train loss=0.2810256779193878
Test set avg_accuracy=83.28% avg_sensitivity=62.67%, avg_specificity=90.31% avg_auc=87.47%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.276310 Test loss=0.395516 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.2871343195438385
[5/24] Train loss=0.27761518955230713
[10/24] Train loss=0.28167515993118286
[15/24] Train loss=0.24863524734973907
[20/24] Train loss=0.28463685512542725
Test set avg_accuracy=83.27% avg_sensitivity=62.62%, avg_specificity=90.31% avg_auc=87.47%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.276872 Test loss=0.395529 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.28820765018463135
[5/24] Train loss=0.27654802799224854
[10/24] Train loss=0.2809735834598541
[15/24] Train loss=0.2490958720445633
[20/24] Train loss=0.2850603461265564
Test set avg_accuracy=83.26% avg_sensitivity=62.57%, avg_specificity=90.31% avg_auc=87.47%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.277186 Test loss=0.395555 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.288147896528244
[5/24] Train loss=0.2748927175998688
[10/24] Train loss=0.28463056683540344
[15/24] Train loss=0.24874819815158844
[20/24] Train loss=0.2838347852230072
Test set avg_accuracy=83.26% avg_sensitivity=62.57%, avg_specificity=90.31% avg_auc=87.46%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.277327 Test loss=0.395568 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.29580751061439514
[5/24] Train loss=0.2775380313396454
[10/24] Train loss=0.2857353389263153
[15/24] Train loss=0.24979498982429504
[20/24] Train loss=0.2824825942516327
Test set avg_accuracy=83.26% avg_sensitivity=62.57%, avg_specificity=90.31% avg_auc=87.46%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.276719 Test loss=0.395568 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.291048139333725
[5/24] Train loss=0.2728422284126282
[10/24] Train loss=0.2804608941078186
[15/24] Train loss=0.2506422996520996
[20/24] Train loss=0.2835438549518585
Test set avg_accuracy=83.26% avg_sensitivity=62.57%, avg_specificity=90.31% avg_auc=87.46%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.275377 Test loss=0.395569 Current lr=[4.388541022775342e-09]

Fold[5] Result: acc=82.98% sen=69.02%, spe=87.74%, auc=88.82%!
Fold[5] Avg_jsc=0.56%(±0.26615249277205116)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.698405385017395
[5/24] Train loss=0.6895509958267212
[10/24] Train loss=0.6796396970748901
[15/24] Train loss=0.668279767036438
[20/24] Train loss=0.6598572134971619
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.45%
Best model saved!! Metric=54.44746315918005!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.676405 Test loss=0.652197 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.649856448173523
[5/24] Train loss=0.633411169052124
[10/24] Train loss=0.6225362420082092
[15/24] Train loss=0.6001792550086975
[20/24] Train loss=0.5941031575202942
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.09%
Best model saved!! Metric=56.094860223713404!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.617426 Test loss=0.591767 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.5830194354057312
[5/24] Train loss=0.5607144236564636
[10/24] Train loss=0.5630380511283875
[15/24] Train loss=0.5418580770492554
[20/24] Train loss=0.5597478747367859
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=62.81%
Best model saved!! Metric=62.80617650529101!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.564661 Test loss=0.577001 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.5578086972236633
[5/24] Train loss=0.5398766994476318
[10/24] Train loss=0.5481793284416199
[15/24] Train loss=0.5299859046936035
[20/24] Train loss=0.545861005783081
Test set avg_accuracy=72.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=67.01%
Best model saved!! Metric=67.01168849699333!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.550287 Test loss=0.563972 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5486561059951782
[5/24] Train loss=0.5270732641220093
[10/24] Train loss=0.53809654712677
[15/24] Train loss=0.5210741758346558
[20/24] Train loss=0.5327446460723877
Test set avg_accuracy=72.10% avg_sensitivity=0.86%, avg_specificity=98.62% avg_auc=70.05%
Best model saved!! Metric=70.04957269999548!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.539816 Test loss=0.552507 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5373997688293457
[5/24] Train loss=0.5088914632797241
[10/24] Train loss=0.5240511894226074
[15/24] Train loss=0.5039269328117371
[20/24] Train loss=0.5169482231140137
Test set avg_accuracy=71.29% avg_sensitivity=4.13%, avg_specificity=96.30% avg_auc=72.04%
Best model saved!! Metric=72.03765988593443!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.526546 Test loss=0.538134 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5253826975822449
[5/24] Train loss=0.48704424500465393
[10/24] Train loss=0.5094941258430481
[15/24] Train loss=0.48947522044181824
[20/24] Train loss=0.5012271404266357
Test set avg_accuracy=71.88% avg_sensitivity=8.45%, avg_specificity=95.50% avg_auc=74.50%
Best model saved!! Metric=74.5008645124911!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.511942 Test loss=0.521521 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.5080401301383972
[5/24] Train loss=0.4697515666484833
[10/24] Train loss=0.49014464020729065
[15/24] Train loss=0.47290459275245667
[20/24] Train loss=0.48203331232070923
Test set avg_accuracy=72.36% avg_sensitivity=9.93%, avg_specificity=95.60% avg_auc=77.54%
Best model saved!! Metric=77.54310900711916!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.494015 Test loss=0.499145 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.4847908616065979
[5/24] Train loss=0.4492492973804474
[10/24] Train loss=0.46727877855300903
[15/24] Train loss=0.4541570842266083
[20/24] Train loss=0.4618000388145447
Test set avg_accuracy=74.38% avg_sensitivity=19.63%, avg_specificity=94.76% avg_auc=79.66%
Best model saved!! Metric=79.65526085262438!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.473605 Test loss=0.478130 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.462519109249115
[5/24] Train loss=0.42738014459609985
[10/24] Train loss=0.44756433367729187
[15/24] Train loss=0.43572378158569336
[20/24] Train loss=0.44581568241119385
Test set avg_accuracy=75.59% avg_sensitivity=28.31%, avg_specificity=93.19% avg_auc=81.86%
Best model saved!! Metric=81.86216436472995!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.454966 Test loss=0.456411 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.44354498386383057
[5/24] Train loss=0.4089485704898834
[10/24] Train loss=0.42673447728157043
[15/24] Train loss=0.41912320256233215
[20/24] Train loss=0.42928025126457214
Test set avg_accuracy=77.66% avg_sensitivity=39.25%, avg_specificity=91.96% avg_auc=83.45%
Best model saved!! Metric=83.4535550482316!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.437533 Test loss=0.438411 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.4248411953449249
[5/24] Train loss=0.39600831270217896
[10/24] Train loss=0.41134098172187805
[15/24] Train loss=0.4037306010723114
[20/24] Train loss=0.41409507393836975
Test set avg_accuracy=79.01% avg_sensitivity=45.06%, avg_specificity=91.65% avg_auc=84.67%
Best model saved!! Metric=84.67004640001976!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.421532 Test loss=0.423467 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.4061712622642517
[5/24] Train loss=0.3841578960418701
[10/24] Train loss=0.40037864446640015
[15/24] Train loss=0.39129945635795593
[20/24] Train loss=0.4017101526260376
Test set avg_accuracy=79.78% avg_sensitivity=42.90%, avg_specificity=93.51% avg_auc=85.39%
Best model saved!! Metric=85.39061353118966!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.408912 Test loss=0.414144 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.3929300606250763
[5/24] Train loss=0.3728853464126587
[10/24] Train loss=0.38753488659858704
[15/24] Train loss=0.38392147421836853
[20/24] Train loss=0.3940911889076233
Test set avg_accuracy=81.11% avg_sensitivity=49.62%, avg_specificity=92.83% avg_auc=86.06%
Best model saved!! Metric=86.05713791315156!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.398834 Test loss=0.405201 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.3828199505805969
[5/24] Train loss=0.36604011058807373
[10/24] Train loss=0.37767094373703003
[15/24] Train loss=0.37697726488113403
[20/24] Train loss=0.3855868875980377
Test set avg_accuracy=81.33% avg_sensitivity=49.04%, avg_specificity=93.35% avg_auc=86.59%
Best model saved!! Metric=86.58703982416836!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.390171 Test loss=0.398682 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.37471914291381836
[5/24] Train loss=0.3559783697128296
[10/24] Train loss=0.3705803155899048
[15/24] Train loss=0.3687233030796051
[20/24] Train loss=0.3773236870765686
Test set avg_accuracy=82.08% avg_sensitivity=53.45%, avg_specificity=92.74% avg_auc=86.93%
Best model saved!! Metric=86.93286197023102!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.382437 Test loss=0.393542 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.36800146102905273
[5/24] Train loss=0.3514488935470581
[10/24] Train loss=0.36358487606048584
[15/24] Train loss=0.3648514747619629
[20/24] Train loss=0.3721197843551636
Test set avg_accuracy=82.55% avg_sensitivity=54.51%, avg_specificity=92.99% avg_auc=87.16%
Best model saved!! Metric=87.15692179360359!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.376273 Test loss=0.389966 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.36219438910484314
[5/24] Train loss=0.3417696952819824
[10/24] Train loss=0.3595285415649414
[15/24] Train loss=0.35695043206214905
[20/24] Train loss=0.3646910786628723
Test set avg_accuracy=82.85% avg_sensitivity=55.04%, avg_specificity=93.21% avg_auc=87.39%
Best model saved!! Metric=87.38898191606562!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.369758 Test loss=0.386174 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.3562639057636261
[5/24] Train loss=0.3328186571598053
[10/24] Train loss=0.3543100655078888
[15/24] Train loss=0.35467877984046936
[20/24] Train loss=0.3612803816795349
Test set avg_accuracy=83.01% avg_sensitivity=58.45%, avg_specificity=92.16% avg_auc=87.67%
Best model saved!! Metric=87.67353703426768!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.365253 Test loss=0.382325 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.3523823320865631
[5/24] Train loss=0.3327893614768982
[10/24] Train loss=0.34724876284599304
[15/24] Train loss=0.34807008504867554
[20/24] Train loss=0.3571067750453949
Test set avg_accuracy=83.42% avg_sensitivity=58.88%, avg_specificity=92.57% avg_auc=87.89%
Best model saved!! Metric=87.89339520002635!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.359306 Test loss=0.378638 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.34742146730422974
[5/24] Train loss=0.3256055414676666
[10/24] Train loss=0.3420409560203552
[15/24] Train loss=0.3430067300796509
[20/24] Train loss=0.3495890498161316
Test set avg_accuracy=83.66% avg_sensitivity=58.40%, avg_specificity=93.07% avg_auc=88.15%
Best model saved!! Metric=88.15369217661643!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.354471 Test loss=0.375268 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.3399341106414795
[5/24] Train loss=0.32226061820983887
[10/24] Train loss=0.3381179869174957
[15/24] Train loss=0.34011784195899963
[20/24] Train loss=0.34569835662841797
Test set avg_accuracy=83.80% avg_sensitivity=57.68%, avg_specificity=93.53% avg_auc=88.41%
Best model saved!! Metric=88.4122313168578!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.350458 Test loss=0.371577 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.33640342950820923
[5/24] Train loss=0.32110869884490967
[10/24] Train loss=0.33401593565940857
[15/24] Train loss=0.3380625545978546
[20/24] Train loss=0.3443107008934021
Test set avg_accuracy=84.19% avg_sensitivity=61.56%, avg_specificity=92.62% avg_auc=88.60%
Best model saved!! Metric=88.60490304289189!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.347558 Test loss=0.368480 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.3371143639087677
[5/24] Train loss=0.3183194398880005
[10/24] Train loss=0.3281603753566742
[15/24] Train loss=0.3337462246417999
[20/24] Train loss=0.34166502952575684
Test set avg_accuracy=84.58% avg_sensitivity=64.59%, avg_specificity=92.03% avg_auc=88.78%
Best model saved!! Metric=88.78023650015983!!
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.344145 Test loss=0.366014 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.33235806226730347
[5/24] Train loss=0.3149990737438202
[10/24] Train loss=0.32515445351600647
[15/24] Train loss=0.3280513882637024
[20/24] Train loss=0.34082210063934326
Test set avg_accuracy=85.05% avg_sensitivity=65.31%, avg_specificity=92.41% avg_auc=88.96%
Best model saved!! Metric=88.96144799068159!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.339933 Test loss=0.363044 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.3273860514163971
[5/24] Train loss=0.31476983428001404
[10/24] Train loss=0.3234970271587372
[15/24] Train loss=0.3232196867465973
[20/24] Train loss=0.33336564898490906
Test set avg_accuracy=84.91% avg_sensitivity=61.28%, avg_specificity=93.71% avg_auc=89.16%
Best model saved!! Metric=89.15968048194557!!
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.336668 Test loss=0.360127 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.32511213421821594
[5/24] Train loss=0.3091430068016052
[10/24] Train loss=0.3214920163154602
[15/24] Train loss=0.31969770789146423
[20/24] Train loss=0.3280336260795593
Test set avg_accuracy=85.35% avg_sensitivity=62.09%, avg_specificity=94.01% avg_auc=89.29%
Best model saved!! Metric=89.29084079799254!!
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.334615 Test loss=0.358347 Current lr=[0.000669125424222739]

[0/24] Train loss=0.3227321207523346
[5/24] Train loss=0.30893391370773315
[10/24] Train loss=0.32112929224967957
[15/24] Train loss=0.32059505581855774
[20/24] Train loss=0.32748574018478394
Test set avg_accuracy=84.99% avg_sensitivity=62.19%, avg_specificity=93.48% avg_auc=89.31%
Best model saved!! Metric=89.31196055861123!!
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.333378 Test loss=0.357601 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.32232704758644104
[5/24] Train loss=0.3088323771953583
[10/24] Train loss=0.3204464614391327
[15/24] Train loss=0.31577053666114807
[20/24] Train loss=0.32187601923942566
Test set avg_accuracy=84.84% avg_sensitivity=60.17%, avg_specificity=94.03% avg_auc=89.27%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.332031 Test loss=0.359634 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.317073255777359
[5/24] Train loss=0.3069716989994049
[10/24] Train loss=0.31670981645584106
[15/24] Train loss=0.3151310384273529
[20/24] Train loss=0.3188003599643707
Test set avg_accuracy=84.83% avg_sensitivity=61.04%, avg_specificity=93.69% avg_auc=89.36%
Best model saved!! Metric=89.35921634455102!!
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.329388 Test loss=0.357574 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.3159457743167877
[5/24] Train loss=0.30950191617012024
[10/24] Train loss=0.316621869802475
[15/24] Train loss=0.3146003186702728
[20/24] Train loss=0.31786471605300903
Test set avg_accuracy=85.03% avg_sensitivity=60.32%, avg_specificity=94.23% avg_auc=89.39%
Best model saved!! Metric=89.39099459581084!!
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.328511 Test loss=0.357841 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.3187137842178345
[5/24] Train loss=0.30542248487472534
[10/24] Train loss=0.31498733162879944
[15/24] Train loss=0.3096935749053955
[20/24] Train loss=0.3175394833087921
Test set avg_accuracy=85.18% avg_sensitivity=59.17%, avg_specificity=94.87% avg_auc=89.40%
Best model saved!! Metric=89.4020218033446!!
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.327010 Test loss=0.359163 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.3194461166858673
[5/24] Train loss=0.3027246594429016
[10/24] Train loss=0.31188416481018066
[15/24] Train loss=0.3079964816570282
[20/24] Train loss=0.313530296087265
Test set avg_accuracy=85.43% avg_sensitivity=58.78%, avg_specificity=95.35% avg_auc=89.39%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.326276 Test loss=0.361148 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.3189956843852997
[5/24] Train loss=0.30100882053375244
[10/24] Train loss=0.3145889937877655
[15/24] Train loss=0.3005058765411377
[20/24] Train loss=0.3105092942714691
Test set avg_accuracy=85.14% avg_sensitivity=56.19%, avg_specificity=95.93% avg_auc=89.46%
Best model saved!! Metric=89.4611880023982!!
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.324772 Test loss=0.362404 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.32158929109573364
[5/24] Train loss=0.3069179058074951
[10/24] Train loss=0.31283360719680786
[15/24] Train loss=0.3045438528060913
[20/24] Train loss=0.30921581387519836
Test set avg_accuracy=84.52% avg_sensitivity=54.03%, avg_specificity=95.87% avg_auc=89.32%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.325058 Test loss=0.366970 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.3180605173110962
[5/24] Train loss=0.30009764432907104
[10/24] Train loss=0.3065586984157562
[15/24] Train loss=0.3001716136932373
[20/24] Train loss=0.30689671635627747
Test set avg_accuracy=84.83% avg_sensitivity=55.85%, avg_specificity=95.62% avg_auc=89.42%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.322809 Test loss=0.364335 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.31797149777412415
[5/24] Train loss=0.3029734492301941
[10/24] Train loss=0.31059399247169495
[15/24] Train loss=0.3010307550430298
[20/24] Train loss=0.30787402391433716
Test set avg_accuracy=85.01% avg_sensitivity=56.19%, avg_specificity=95.75% avg_auc=89.49%
Best model saved!! Metric=89.49079682635939!!
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.321797 Test loss=0.363335 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.3177284002304077
[5/24] Train loss=0.3005511164665222
[10/24] Train loss=0.3080829679965973
[15/24] Train loss=0.30133554339408875
[20/24] Train loss=0.30107828974723816
Test set avg_accuracy=85.05% avg_sensitivity=57.01%, avg_specificity=95.50% avg_auc=89.59%
Best model saved!! Metric=89.59303001595602!!
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.319998 Test loss=0.361197 Current lr=[0.000944367614404117]

[0/24] Train loss=0.31517520546913147
[5/24] Train loss=0.2973259389400482
[10/24] Train loss=0.30892837047576904
[15/24] Train loss=0.3005467653274536
[20/24] Train loss=0.30442091822624207
Test set avg_accuracy=85.07% avg_sensitivity=58.11%, avg_specificity=95.10% avg_auc=89.48%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.320235 Test loss=0.363989 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.31841808557510376
[5/24] Train loss=0.3013139069080353
[10/24] Train loss=0.3090408444404602
[15/24] Train loss=0.30232664942741394
[20/24] Train loss=0.3018866777420044
Test set avg_accuracy=84.95% avg_sensitivity=56.38%, avg_specificity=95.59% avg_auc=89.45%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.319150 Test loss=0.366056 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.3187515437602997
[5/24] Train loss=0.2968558967113495
[10/24] Train loss=0.3060161769390106
[15/24] Train loss=0.29936906695365906
[20/24] Train loss=0.29994362592697144
Test set avg_accuracy=85.14% avg_sensitivity=57.10%, avg_specificity=95.59% avg_auc=89.60%
Best model saved!! Metric=89.60499616534432!!
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.318526 Test loss=0.363448 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.31714728474617004
[5/24] Train loss=0.2996000051498413
[10/24] Train loss=0.30654215812683105
[15/24] Train loss=0.2992347776889801
[20/24] Train loss=0.299335777759552
Test set avg_accuracy=84.65% avg_sensitivity=54.89%, avg_specificity=95.73% avg_auc=89.74%
Best model saved!! Metric=89.74040958787398!!
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.317339 Test loss=0.364469 Current lr=[0.000989780311725182]

[0/24] Train loss=0.3188456594944
[5/24] Train loss=0.3005720376968384
[10/24] Train loss=0.30691245198249817
[15/24] Train loss=0.29978495836257935
[20/24] Train loss=0.29907160997390747
Test set avg_accuracy=84.39% avg_sensitivity=52.59%, avg_specificity=96.23% avg_auc=89.73%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.316902 Test loss=0.369458 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.31646209955215454
[5/24] Train loss=0.297198623418808
[10/24] Train loss=0.3061700463294983
[15/24] Train loss=0.2976410388946533
[20/24] Train loss=0.2997142970561981
Test set avg_accuracy=84.53% avg_sensitivity=54.89%, avg_specificity=95.57% avg_auc=89.62%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.316646 Test loss=0.364853 Current lr=[0.000998924125869967]

[0/24] Train loss=0.3105528950691223
[5/24] Train loss=0.29774877429008484
[10/24] Train loss=0.3035091459751129
[15/24] Train loss=0.2925098240375519
[20/24] Train loss=0.29799044132232666
Test set avg_accuracy=84.73% avg_sensitivity=55.18%, avg_specificity=95.73% avg_auc=89.73%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.316154 Test loss=0.363212 Current lr=[0.000999999611458977]

[0/24] Train loss=0.31070488691329956
[5/24] Train loss=0.2954747676849365
[10/24] Train loss=0.3054857552051544
[15/24] Train loss=0.29019415378570557
[20/24] Train loss=0.2996011972427368
Test set avg_accuracy=84.73% avg_sensitivity=54.56%, avg_specificity=95.96% avg_auc=89.88%
Best model saved!! Metric=89.87954447857601!!
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.315577 Test loss=0.362513 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.308939129114151
[5/24] Train loss=0.29663869738578796
[10/24] Train loss=0.3043162226676941
[15/24] Train loss=0.29167482256889343
[20/24] Train loss=0.2973538935184479
Test set avg_accuracy=85.00% avg_sensitivity=55.13%, avg_specificity=96.12% avg_auc=89.91%
Best model saved!! Metric=89.91405380728489!!
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.314597 Test loss=0.361096 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.3102867603302002
[5/24] Train loss=0.2952507436275482
[10/24] Train loss=0.30363136529922485
[15/24] Train loss=0.29219892621040344
[20/24] Train loss=0.2966313660144806
Test set avg_accuracy=84.92% avg_sensitivity=55.28%, avg_specificity=95.96% avg_auc=90.02%
Best model saved!! Metric=90.02183489989423!!
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.313729 Test loss=0.359650 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3069097101688385
[5/24] Train loss=0.29296356439590454
[10/24] Train loss=0.30258995294570923
[15/24] Train loss=0.2885266840457916
[20/24] Train loss=0.29460930824279785
Test set avg_accuracy=84.99% avg_sensitivity=55.23%, avg_specificity=96.07% avg_auc=90.14%
Best model saved!! Metric=90.13980715592025!!
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.312377 Test loss=0.358418 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3071647882461548
[5/24] Train loss=0.291533499956131
[10/24] Train loss=0.3032011389732361
[15/24] Train loss=0.29137128591537476
[20/24] Train loss=0.2946249842643738
Test set avg_accuracy=85.49% avg_sensitivity=58.25%, avg_specificity=95.64% avg_auc=90.33%
Best model saved!! Metric=90.33220877539345!!
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.311189 Test loss=0.352683 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.305379182100296
[5/24] Train loss=0.28643929958343506
[10/24] Train loss=0.30677467584609985
[15/24] Train loss=0.28854379057884216
[20/24] Train loss=0.2973605692386627
Test set avg_accuracy=85.52% avg_sensitivity=59.79%, avg_specificity=95.10% avg_auc=90.35%
Best model saved!! Metric=90.34776348337653!!
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.310387 Test loss=0.348729 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.3034730553627014
[5/24] Train loss=0.28845521807670593
[10/24] Train loss=0.30753186345100403
[15/24] Train loss=0.2898975610733032
[20/24] Train loss=0.2944803535938263
Test set avg_accuracy=85.33% avg_sensitivity=58.49%, avg_specificity=95.32% avg_auc=90.29%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.310598 Test loss=0.352212 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.3025107681751251
[5/24] Train loss=0.2884272634983063
[10/24] Train loss=0.3002122640609741
[15/24] Train loss=0.29275861382484436
[20/24] Train loss=0.2913726270198822
Test set avg_accuracy=85.49% avg_sensitivity=59.69%, avg_specificity=95.10% avg_auc=90.40%
Best model saved!! Metric=90.39628405400622!!
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.309406 Test loss=0.350096 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.304501473903656
[5/24] Train loss=0.28504201769828796
[10/24] Train loss=0.30271831154823303
[15/24] Train loss=0.29254183173179626
[20/24] Train loss=0.2929944396018982
Test set avg_accuracy=85.16% avg_sensitivity=59.31%, avg_specificity=94.78% avg_auc=90.25%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.309020 Test loss=0.351957 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.3051275610923767
[5/24] Train loss=0.2848184108734131
[10/24] Train loss=0.30085980892181396
[15/24] Train loss=0.28638726472854614
[20/24] Train loss=0.29621800780296326
Test set avg_accuracy=85.55% avg_sensitivity=60.12%, avg_specificity=95.01% avg_auc=90.33%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.309389 Test loss=0.349269 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.3019925355911255
[5/24] Train loss=0.28534963726997375
[10/24] Train loss=0.300490140914917
[15/24] Train loss=0.2897288203239441
[20/24] Train loss=0.2969460189342499
Test set avg_accuracy=85.69% avg_sensitivity=60.80%, avg_specificity=94.96% avg_auc=90.40%
Best model saved!! Metric=90.39742450393001!!
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.308813 Test loss=0.346546 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.30073338747024536
[5/24] Train loss=0.28629133105278015
[10/24] Train loss=0.3007248342037201
[15/24] Train loss=0.29046863317489624
[20/24] Train loss=0.2922931909561157
Test set avg_accuracy=85.35% avg_sensitivity=58.40%, avg_specificity=95.39% avg_auc=90.43%
Best model saved!! Metric=90.43413755918336!!
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.308509 Test loss=0.349515 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.2994999587535858
[5/24] Train loss=0.2872147858142853
[10/24] Train loss=0.3012121915817261
[15/24] Train loss=0.28471261262893677
[20/24] Train loss=0.29154497385025024
Test set avg_accuracy=85.68% avg_sensitivity=58.88%, avg_specificity=95.66% avg_auc=90.31%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.307967 Test loss=0.350613 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.3042386770248413
[5/24] Train loss=0.28228625655174255
[10/24] Train loss=0.2964669167995453
[15/24] Train loss=0.28958919644355774
[20/24] Train loss=0.29608792066574097
Test set avg_accuracy=85.27% avg_sensitivity=57.34%, avg_specificity=95.68% avg_auc=90.38%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.309594 Test loss=0.352028 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.2958213984966278
[5/24] Train loss=0.2836412787437439
[10/24] Train loss=0.2981504201889038
[15/24] Train loss=0.2874644696712494
[20/24] Train loss=0.2950040400028229
Test set avg_accuracy=85.31% avg_sensitivity=58.73%, avg_specificity=95.21% avg_auc=90.48%
Best model saved!! Metric=90.47669434844467!!
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.307675 Test loss=0.347727 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.29887086153030396
[5/24] Train loss=0.2826036810874939
[10/24] Train loss=0.2995927333831787
[15/24] Train loss=0.2902494966983795
[20/24] Train loss=0.2944692075252533
Test set avg_accuracy=85.65% avg_sensitivity=58.69%, avg_specificity=95.69% avg_auc=90.45%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.309227 Test loss=0.350447 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.29990318417549133
[5/24] Train loss=0.28406330943107605
[10/24] Train loss=0.30634036660194397
[15/24] Train loss=0.28965166211128235
[20/24] Train loss=0.29143646359443665
Test set avg_accuracy=85.46% avg_sensitivity=61.28%, avg_specificity=94.46% avg_auc=90.35%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.310099 Test loss=0.347707 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.300737202167511
[5/24] Train loss=0.2819182276725769
[10/24] Train loss=0.30226293206214905
[15/24] Train loss=0.28410714864730835
[20/24] Train loss=0.293071448802948
Test set avg_accuracy=85.30% avg_sensitivity=62.33%, avg_specificity=93.85% avg_auc=90.34%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.311595 Test loss=0.345305 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.29678142070770264
[5/24] Train loss=0.281222939491272
[10/24] Train loss=0.3121914565563202
[15/24] Train loss=0.2975987195968628
[20/24] Train loss=0.30329325795173645
Test set avg_accuracy=85.96% avg_sensitivity=72.50%, avg_specificity=90.98% avg_auc=90.49%
Best model saved!! Metric=90.48710416955352!!
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.315359 Test loss=0.341766 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.29951727390289307
[5/24] Train loss=0.27703016996383667
[10/24] Train loss=0.3081667125225067
[15/24] Train loss=0.29917728900909424
[20/24] Train loss=0.31391724944114685
Test set avg_accuracy=85.70% avg_sensitivity=73.70%, avg_specificity=90.17% avg_auc=90.40%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.314621 Test loss=0.344530 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.30013301968574524
[5/24] Train loss=0.28184446692466736
[10/24] Train loss=0.30471673607826233
[15/24] Train loss=0.2925845980644226
[20/24] Train loss=0.30655181407928467
Test set avg_accuracy=85.83% avg_sensitivity=72.70%, avg_specificity=90.73% avg_auc=90.56%
Best model saved!! Metric=90.56139633601737!!
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.311763 Test loss=0.340548 Current lr=[0.000904142181093812]

[0/24] Train loss=0.2968052625656128
[5/24] Train loss=0.28428053855895996
[10/24] Train loss=0.3018716871738434
[15/24] Train loss=0.2871934473514557
[20/24] Train loss=0.30721646547317505
Test set avg_accuracy=85.85% avg_sensitivity=71.50%, avg_specificity=91.19% avg_auc=90.47%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.308021 Test loss=0.340745 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.2932066023349762
[5/24] Train loss=0.2756916582584381
[10/24] Train loss=0.3058054745197296
[15/24] Train loss=0.28315111994743347
[20/24] Train loss=0.2994868755340576
Test set avg_accuracy=86.09% avg_sensitivity=72.17%, avg_specificity=91.28% avg_auc=90.48%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.307354 Test loss=0.340313 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.29342201352119446
[5/24] Train loss=0.26955685019493103
[10/24] Train loss=0.3035767078399658
[15/24] Train loss=0.2839059829711914
[20/24] Train loss=0.2978445887565613
Test set avg_accuracy=86.13% avg_sensitivity=72.31%, avg_specificity=91.28% avg_auc=90.45%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.305520 Test loss=0.340793 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.2921694219112396
[5/24] Train loss=0.2708543837070465
[10/24] Train loss=0.3031975030899048
[15/24] Train loss=0.28561460971832275
[20/24] Train loss=0.3046562969684601
Test set avg_accuracy=86.07% avg_sensitivity=72.41%, avg_specificity=91.15% avg_auc=90.51%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.306117 Test loss=0.340363 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.2886890470981598
[5/24] Train loss=0.2752092480659485
[10/24] Train loss=0.30073967576026917
[15/24] Train loss=0.28436630964279175
[20/24] Train loss=0.2991367280483246
Test set avg_accuracy=86.07% avg_sensitivity=72.65%, avg_specificity=91.07% avg_auc=90.43%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.305420 Test loss=0.341589 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.29096442461013794
[5/24] Train loss=0.2750680446624756
[10/24] Train loss=0.2960733473300934
[15/24] Train loss=0.28900161385536194
[20/24] Train loss=0.30062153935432434
Test set avg_accuracy=85.83% avg_sensitivity=73.37%, avg_specificity=90.48% avg_auc=90.42%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.304854 Test loss=0.342452 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.2878895103931427
[5/24] Train loss=0.2746514081954956
[10/24] Train loss=0.30175483226776123
[15/24] Train loss=0.2845242917537689
[20/24] Train loss=0.30178719758987427
Test set avg_accuracy=86.11% avg_sensitivity=73.13%, avg_specificity=90.94% avg_auc=90.46%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.304222 Test loss=0.341827 Current lr=[0.000834102481048427]

[0/24] Train loss=0.2921687662601471
[5/24] Train loss=0.2694314420223236
[10/24] Train loss=0.2978760600090027
[15/24] Train loss=0.2838282287120819
[20/24] Train loss=0.2959922254085541
Test set avg_accuracy=85.95% avg_sensitivity=72.98%, avg_specificity=90.78% avg_auc=90.52%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.302842 Test loss=0.340662 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.28807440400123596
[5/24] Train loss=0.2701636552810669
[10/24] Train loss=0.2992423474788666
[15/24] Train loss=0.27468782663345337
[20/24] Train loss=0.2941988706588745
Test set avg_accuracy=85.73% avg_sensitivity=72.65%, avg_specificity=90.60% avg_auc=90.44%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.300991 Test loss=0.342253 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.2901532053947449
[5/24] Train loss=0.2680813670158386
[10/24] Train loss=0.2930889427661896
[15/24] Train loss=0.2771342694759369
[20/24] Train loss=0.2945280969142914
Test set avg_accuracy=85.72% avg_sensitivity=73.37%, avg_specificity=90.31% avg_auc=90.39%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.300485 Test loss=0.343597 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.28467604517936707
[5/24] Train loss=0.2701760530471802
[10/24] Train loss=0.2941334843635559
[15/24] Train loss=0.27607470750808716
[20/24] Train loss=0.29982542991638184
Test set avg_accuracy=85.82% avg_sensitivity=73.32%, avg_specificity=90.48% avg_auc=90.48%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.300855 Test loss=0.342142 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.2846977710723877
[5/24] Train loss=0.2668163478374481
[10/24] Train loss=0.2963690459728241
[15/24] Train loss=0.2722644805908203
[20/24] Train loss=0.2957683801651001
Test set avg_accuracy=85.57% avg_sensitivity=73.08%, avg_specificity=90.23% avg_auc=90.42%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.299598 Test loss=0.344163 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.2835872769355774
[5/24] Train loss=0.2684589624404907
[10/24] Train loss=0.2948239743709564
[15/24] Train loss=0.27562618255615234
[20/24] Train loss=0.2893865704536438
Test set avg_accuracy=85.70% avg_sensitivity=72.22%, avg_specificity=90.73% avg_auc=90.34%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.299055 Test loss=0.344249 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.28627049922943115
[5/24] Train loss=0.2660394310951233
[10/24] Train loss=0.29626187682151794
[15/24] Train loss=0.2745288014411926
[20/24] Train loss=0.29186147451400757
Test set avg_accuracy=85.86% avg_sensitivity=71.59%, avg_specificity=91.17% avg_auc=90.28%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.297748 Test loss=0.344453 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.28543686866760254
[5/24] Train loss=0.26960262656211853
[10/24] Train loss=0.29532015323638916
[15/24] Train loss=0.27441471815109253
[20/24] Train loss=0.28510141372680664
Test set avg_accuracy=85.90% avg_sensitivity=70.63%, avg_specificity=91.58% avg_auc=90.20%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.295926 Test loss=0.344644 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.28052592277526855
[5/24] Train loss=0.269295334815979
[10/24] Train loss=0.29352670907974243
[15/24] Train loss=0.27384692430496216
[20/24] Train loss=0.2802658975124359
Test set avg_accuracy=85.85% avg_sensitivity=71.07%, avg_specificity=91.35% avg_auc=90.11%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.295407 Test loss=0.346760 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.2821848690509796
[5/24] Train loss=0.26264458894729614
[10/24] Train loss=0.2919010519981384
[15/24] Train loss=0.28060004115104675
[20/24] Train loss=0.28625020384788513
Test set avg_accuracy=85.72% avg_sensitivity=70.83%, avg_specificity=91.26% avg_auc=90.08%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.295135 Test loss=0.347532 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.2850266098976135
[5/24] Train loss=0.26323384046554565
[10/24] Train loss=0.2923986613750458
[15/24] Train loss=0.2793281674385071
[20/24] Train loss=0.285238116979599
Test set avg_accuracy=86.15% avg_sensitivity=72.26%, avg_specificity=91.32% avg_auc=90.29%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.295728 Test loss=0.344503 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.27877485752105713
[5/24] Train loss=0.26399388909339905
[10/24] Train loss=0.2900591194629669
[15/24] Train loss=0.2729087769985199
[20/24] Train loss=0.29142308235168457
Test set avg_accuracy=85.96% avg_sensitivity=73.13%, avg_specificity=90.74% avg_auc=90.10%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.294384 Test loss=0.348621 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.28616639971733093
[5/24] Train loss=0.270700603723526
[10/24] Train loss=0.2913871109485626
[15/24] Train loss=0.27188530564308167
[20/24] Train loss=0.29307255148887634
Test set avg_accuracy=85.89% avg_sensitivity=73.32%, avg_specificity=90.56% avg_auc=90.27%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.295508 Test loss=0.347196 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.2835389971733093
[5/24] Train loss=0.2667858898639679
[10/24] Train loss=0.29190829396247864
[15/24] Train loss=0.27567705512046814
[20/24] Train loss=0.2843145430088043
Test set avg_accuracy=85.64% avg_sensitivity=72.84%, avg_specificity=90.40% avg_auc=90.20%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.294323 Test loss=0.348807 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.28237324953079224
[5/24] Train loss=0.272400826215744
[10/24] Train loss=0.28969183564186096
[15/24] Train loss=0.27094292640686035
[20/24] Train loss=0.285132497549057
Test set avg_accuracy=85.47% avg_sensitivity=72.17%, avg_specificity=90.42% avg_auc=90.11%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.293967 Test loss=0.350073 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.2791523039340973
[5/24] Train loss=0.26799145340919495
[10/24] Train loss=0.2933942973613739
[15/24] Train loss=0.2764001488685608
[20/24] Train loss=0.283786416053772
Test set avg_accuracy=85.53% avg_sensitivity=72.02%, avg_specificity=90.56% avg_auc=90.13%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.293683 Test loss=0.348837 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.2818078398704529
[5/24] Train loss=0.26544511318206787
[10/24] Train loss=0.2856891453266144
[15/24] Train loss=0.26857563853263855
[20/24] Train loss=0.2819855809211731
Test set avg_accuracy=85.61% avg_sensitivity=71.31%, avg_specificity=90.94% avg_auc=89.95%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.291996 Test loss=0.351991 Current lr=[0.00061065423442182]

[0/24] Train loss=0.28151556849479675
[5/24] Train loss=0.2655183970928192
[10/24] Train loss=0.28734686970710754
[15/24] Train loss=0.2667989432811737
[20/24] Train loss=0.2833086848258972
Test set avg_accuracy=85.48% avg_sensitivity=71.83%, avg_specificity=90.56% avg_auc=90.08%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.290946 Test loss=0.350515 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.27709877490997314
[5/24] Train loss=0.26765626668930054
[10/24] Train loss=0.28835129737854004
[15/24] Train loss=0.270889550447464
[20/24] Train loss=0.2805243134498596
Test set avg_accuracy=85.56% avg_sensitivity=71.74%, avg_specificity=90.71% avg_auc=90.10%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.290971 Test loss=0.349580 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.27582135796546936
[5/24] Train loss=0.26669207215309143
[10/24] Train loss=0.2830987870693207
[15/24] Train loss=0.26857948303222656
[20/24] Train loss=0.27958744764328003
Test set avg_accuracy=85.69% avg_sensitivity=72.84%, avg_specificity=90.48% avg_auc=89.99%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.288388 Test loss=0.352429 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.2749251425266266
[5/24] Train loss=0.2643313407897949
[10/24] Train loss=0.2819089889526367
[15/24] Train loss=0.2639656364917755
[20/24] Train loss=0.2741149365901947
Test set avg_accuracy=85.76% avg_sensitivity=70.39%, avg_specificity=91.48% avg_auc=90.00%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.286951 Test loss=0.350595 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.27017271518707275
[5/24] Train loss=0.26325523853302
[10/24] Train loss=0.28398001194000244
[15/24] Train loss=0.26116642355918884
[20/24] Train loss=0.27670031785964966
Test set avg_accuracy=85.68% avg_sensitivity=71.11%, avg_specificity=91.10% avg_auc=89.98%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.286525 Test loss=0.350919 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.271098256111145
[5/24] Train loss=0.25872573256492615
[10/24] Train loss=0.2789336144924164
[15/24] Train loss=0.2626841366291046
[20/24] Train loss=0.2783040404319763
Test set avg_accuracy=85.52% avg_sensitivity=70.39%, avg_specificity=91.15% avg_auc=89.94%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.286903 Test loss=0.352559 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.27067917585372925
[5/24] Train loss=0.255180299282074
[10/24] Train loss=0.28205886483192444
[15/24] Train loss=0.2612694203853607
[20/24] Train loss=0.27577584981918335
Test set avg_accuracy=85.83% avg_sensitivity=71.55%, avg_specificity=91.15% avg_auc=89.92%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.285894 Test loss=0.353634 Current lr=[0.000506858408304961]

[0/24] Train loss=0.27018579840660095
[5/24] Train loss=0.257741242647171
[10/24] Train loss=0.27975043654441833
[15/24] Train loss=0.2603037357330322
[20/24] Train loss=0.27985644340515137
Test set avg_accuracy=85.82% avg_sensitivity=71.40%, avg_specificity=91.19% avg_auc=89.90%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.285441 Test loss=0.354097 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.2719056308269501
[5/24] Train loss=0.25611791014671326
[10/24] Train loss=0.28083157539367676
[15/24] Train loss=0.26314133405685425
[20/24] Train loss=0.2709265947341919
Test set avg_accuracy=85.66% avg_sensitivity=70.97%, avg_specificity=91.14% avg_auc=89.83%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.284725 Test loss=0.355553 Current lr=[0.000476946990416354]

[0/24] Train loss=0.26575443148612976
[5/24] Train loss=0.2591356933116913
[10/24] Train loss=0.2770560681819916
[15/24] Train loss=0.2639767825603485
[20/24] Train loss=0.2740018665790558
Test set avg_accuracy=85.42% avg_sensitivity=69.19%, avg_specificity=91.46% avg_auc=89.73%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.283615 Test loss=0.357689 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.2632404863834381
[5/24] Train loss=0.2588249146938324
[10/24] Train loss=0.2777118682861328
[15/24] Train loss=0.26344627141952515
[20/24] Train loss=0.27948305010795593
Test set avg_accuracy=85.22% avg_sensitivity=70.49%, avg_specificity=90.71% avg_auc=89.68%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.282293 Test loss=0.359711 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.26692843437194824
[5/24] Train loss=0.26268261671066284
[10/24] Train loss=0.27688878774642944
[15/24] Train loss=0.26722168922424316
[20/24] Train loss=0.27126413583755493
Test set avg_accuracy=85.10% avg_sensitivity=68.33%, avg_specificity=91.35% avg_auc=89.62%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.282651 Test loss=0.360973 Current lr=[0.000432267999769856]

[0/24] Train loss=0.26602017879486084
[5/24] Train loss=0.25619497895240784
[10/24] Train loss=0.27523478865623474
[15/24] Train loss=0.26001328229904175
[20/24] Train loss=0.2684858739376068
Test set avg_accuracy=85.27% avg_sensitivity=68.95%, avg_specificity=91.35% avg_auc=89.62%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.281593 Test loss=0.361980 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.2648501992225647
[5/24] Train loss=0.2568092942237854
[10/24] Train loss=0.2727642059326172
[15/24] Train loss=0.256854772567749
[20/24] Train loss=0.27271735668182373
Test set avg_accuracy=85.29% avg_sensitivity=69.19%, avg_specificity=91.28% avg_auc=89.56%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.281510 Test loss=0.363009 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.26767274737358093
[5/24] Train loss=0.2595781087875366
[10/24] Train loss=0.2803836464881897
[15/24] Train loss=0.2575724124908447
[20/24] Train loss=0.2697433531284332
Test set avg_accuracy=85.00% avg_sensitivity=68.19%, avg_specificity=91.26% avg_auc=89.50%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.281732 Test loss=0.364302 Current lr=[0.000388134363466264]

[0/24] Train loss=0.2660081088542938
[5/24] Train loss=0.25905975699424744
[10/24] Train loss=0.27641430497169495
[15/24] Train loss=0.25639501214027405
[20/24] Train loss=0.27198049426078796
Test set avg_accuracy=85.27% avg_sensitivity=68.71%, avg_specificity=91.44% avg_auc=89.50%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.280530 Test loss=0.364520 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.2643634080886841
[5/24] Train loss=0.2566509246826172
[10/24] Train loss=0.27412834763526917
[15/24] Train loss=0.25474849343299866
[20/24] Train loss=0.2676965892314911
Test set avg_accuracy=85.25% avg_sensitivity=70.97%, avg_specificity=90.56% avg_auc=89.47%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.279777 Test loss=0.365788 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.26123571395874023
[5/24] Train loss=0.256141722202301
[10/24] Train loss=0.27382880449295044
[15/24] Train loss=0.26136520504951477
[20/24] Train loss=0.27275416254997253
Test set avg_accuracy=85.47% avg_sensitivity=69.72%, avg_specificity=91.33% avg_auc=89.50%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.279185 Test loss=0.364813 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.26814332604408264
[5/24] Train loss=0.2571218013763428
[10/24] Train loss=0.2735030949115753
[15/24] Train loss=0.2592735290527344
[20/24] Train loss=0.2657962441444397
Test set avg_accuracy=85.65% avg_sensitivity=69.96%, avg_specificity=91.49% avg_auc=89.46%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.278508 Test loss=0.364979 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.2596369683742523
[5/24] Train loss=0.25801336765289307
[10/24] Train loss=0.2749558389186859
[15/24] Train loss=0.2590586543083191
[20/24] Train loss=0.27491050958633423
Test set avg_accuracy=85.53% avg_sensitivity=72.12%, avg_specificity=90.53% avg_auc=89.50%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.278350 Test loss=0.365302 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.2608567178249359
[5/24] Train loss=0.2574493885040283
[10/24] Train loss=0.2765706181526184
[15/24] Train loss=0.25096970796585083
[20/24] Train loss=0.2682807147502899
Test set avg_accuracy=85.55% avg_sensitivity=73.03%, avg_specificity=90.21% avg_auc=89.53%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.278416 Test loss=0.365647 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.26975131034851074
[5/24] Train loss=0.25866764783859253
[10/24] Train loss=0.2767104506492615
[15/24] Train loss=0.2511028051376343
[20/24] Train loss=0.2693083584308624
Test set avg_accuracy=85.13% avg_sensitivity=74.86%, avg_specificity=88.96% avg_auc=89.51%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.279125 Test loss=0.369149 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2691324055194855
[5/24] Train loss=0.2618793547153473
[10/24] Train loss=0.2714351415634155
[15/24] Train loss=0.24897707998752594
[20/24] Train loss=0.27878591418266296
Test set avg_accuracy=85.44% avg_sensitivity=74.38%, avg_specificity=89.56% avg_auc=89.56%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.279561 Test loss=0.365967 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.26597607135772705
[5/24] Train loss=0.2506943345069885
[10/24] Train loss=0.2747993469238281
[15/24] Train loss=0.25611042976379395
[20/24] Train loss=0.27462679147720337
Test set avg_accuracy=85.68% avg_sensitivity=70.87%, avg_specificity=91.19% avg_auc=89.42%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.278206 Test loss=0.365213 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.2627830505371094
[5/24] Train loss=0.2545016407966614
[10/24] Train loss=0.26803267002105713
[15/24] Train loss=0.2509373724460602
[20/24] Train loss=0.2760777175426483
Test set avg_accuracy=85.57% avg_sensitivity=68.57%, avg_specificity=91.90% avg_auc=89.39%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.277670 Test loss=0.366509 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.2632594108581543
[5/24] Train loss=0.2479659467935562
[10/24] Train loss=0.2750210762023926
[15/24] Train loss=0.2485707700252533
[20/24] Train loss=0.2643619477748871
Test set avg_accuracy=85.70% avg_sensitivity=69.87%, avg_specificity=91.60% avg_auc=89.48%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.275064 Test loss=0.364476 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.2601107358932495
[5/24] Train loss=0.249458447098732
[10/24] Train loss=0.26902079582214355
[15/24] Train loss=0.24865782260894775
[20/24] Train loss=0.2636995017528534
Test set avg_accuracy=85.81% avg_sensitivity=70.87%, avg_specificity=91.37% avg_auc=89.58%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.274350 Test loss=0.363306 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.2616289258003235
[5/24] Train loss=0.24912454187870026
[10/24] Train loss=0.27246367931365967
[15/24] Train loss=0.2460477203130722
[20/24] Train loss=0.2651231586933136
Test set avg_accuracy=85.70% avg_sensitivity=69.24%, avg_specificity=91.83% avg_auc=89.56%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.274231 Test loss=0.363295 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.25588157773017883
[5/24] Train loss=0.24561505019664764
[10/24] Train loss=0.2654959559440613
[15/24] Train loss=0.25007444620132446
[20/24] Train loss=0.26962822675704956
Test set avg_accuracy=85.73% avg_sensitivity=70.44%, avg_specificity=91.42% avg_auc=89.55%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.272471 Test loss=0.364092 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.2600008249282837
[5/24] Train loss=0.24697229266166687
[10/24] Train loss=0.2692670524120331
[15/24] Train loss=0.24581179022789001
[20/24] Train loss=0.26306384801864624
Test set avg_accuracy=85.81% avg_sensitivity=69.67%, avg_specificity=91.82% avg_auc=89.56%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.273098 Test loss=0.363527 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2641247808933258
[5/24] Train loss=0.24481546878814697
[10/24] Train loss=0.26681047677993774
[15/24] Train loss=0.24571827054023743
[20/24] Train loss=0.26608577370643616
Test set avg_accuracy=85.78% avg_sensitivity=70.39%, avg_specificity=91.51% avg_auc=89.53%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.271753 Test loss=0.364253 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.2560737431049347
[5/24] Train loss=0.25142765045166016
[10/24] Train loss=0.2674299478530884
[15/24] Train loss=0.24557533860206604
[20/24] Train loss=0.2668518126010895
Test set avg_accuracy=85.64% avg_sensitivity=70.01%, avg_specificity=91.46% avg_auc=89.52%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.271374 Test loss=0.364149 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.25577372312545776
[5/24] Train loss=0.24655918776988983
[10/24] Train loss=0.268809974193573
[15/24] Train loss=0.24141739308834076
[20/24] Train loss=0.26649054884910583
Test set avg_accuracy=85.78% avg_sensitivity=70.20%, avg_specificity=91.58% avg_auc=89.53%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.270702 Test loss=0.364308 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.2568756341934204
[5/24] Train loss=0.24823559820652008
[10/24] Train loss=0.2665177881717682
[15/24] Train loss=0.24645136296749115
[20/24] Train loss=0.26669928431510925
Test set avg_accuracy=85.72% avg_sensitivity=69.67%, avg_specificity=91.69% avg_auc=89.51%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.271335 Test loss=0.364486 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.2561608850955963
[5/24] Train loss=0.24424153566360474
[10/24] Train loss=0.26794910430908203
[15/24] Train loss=0.2499568909406662
[20/24] Train loss=0.2662145793437958
Test set avg_accuracy=85.82% avg_sensitivity=71.11%, avg_specificity=91.30% avg_auc=89.48%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.269793 Test loss=0.365805 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.25680041313171387
[5/24] Train loss=0.2454870343208313
[10/24] Train loss=0.266593337059021
[15/24] Train loss=0.24417515099048615
[20/24] Train loss=0.26315465569496155
Test set avg_accuracy=85.64% avg_sensitivity=69.77%, avg_specificity=91.55% avg_auc=89.47%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.270316 Test loss=0.365875 Current lr=[0.000123057953306828]

[0/24] Train loss=0.2562945783138275
[5/24] Train loss=0.24778899550437927
[10/24] Train loss=0.2694215774536133
[15/24] Train loss=0.24709412455558777
[20/24] Train loss=0.26277586817741394
Test set avg_accuracy=85.65% avg_sensitivity=69.87%, avg_specificity=91.53% avg_auc=89.51%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.269265 Test loss=0.364884 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.25877097249031067
[5/24] Train loss=0.2454977184534073
[10/24] Train loss=0.2656940817832947
[15/24] Train loss=0.24516774713993073
[20/24] Train loss=0.26391157507896423
Test set avg_accuracy=85.68% avg_sensitivity=70.25%, avg_specificity=91.42% avg_auc=89.48%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.269630 Test loss=0.365722 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.25570768117904663
[5/24] Train loss=0.2436758130788803
[10/24] Train loss=0.26481160521507263
[15/24] Train loss=0.2473469227552414
[20/24] Train loss=0.26213088631629944
Test set avg_accuracy=85.61% avg_sensitivity=69.91%, avg_specificity=91.46% avg_auc=89.47%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.270691 Test loss=0.366095 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.25312289595603943
[5/24] Train loss=0.2438928782939911
[10/24] Train loss=0.26539719104766846
[15/24] Train loss=0.24261049926280975
[20/24] Train loss=0.259988933801651
Test set avg_accuracy=85.60% avg_sensitivity=69.91%, avg_specificity=91.44% avg_auc=89.45%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.267950 Test loss=0.366438 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.25851744413375854
[5/24] Train loss=0.24406014382839203
[10/24] Train loss=0.26587003469467163
[15/24] Train loss=0.24816027283668518
[20/24] Train loss=0.2611564099788666
Test set avg_accuracy=85.66% avg_sensitivity=70.25%, avg_specificity=91.40% avg_auc=89.48%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.269383 Test loss=0.365889 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.25622016191482544
[5/24] Train loss=0.24359796941280365
[10/24] Train loss=0.2669099271297455
[15/24] Train loss=0.24552875757217407
[20/24] Train loss=0.26135343313217163
Test set avg_accuracy=85.53% avg_sensitivity=71.16%, avg_specificity=90.89% avg_auc=89.48%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.268863 Test loss=0.366361 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.2526562213897705
[5/24] Train loss=0.24148280918598175
[10/24] Train loss=0.2655828595161438
[15/24] Train loss=0.2482597380876541
[20/24] Train loss=0.2618287205696106
Test set avg_accuracy=85.64% avg_sensitivity=71.31%, avg_specificity=90.98% avg_auc=89.49%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.268265 Test loss=0.366067 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.2532293200492859
[5/24] Train loss=0.24154457449913025
[10/24] Train loss=0.2701784372329712
[15/24] Train loss=0.24653565883636475
[20/24] Train loss=0.26228275895118713
Test set avg_accuracy=85.56% avg_sensitivity=71.55%, avg_specificity=90.78% avg_auc=89.47%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.269173 Test loss=0.367088 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.25554749369621277
[5/24] Train loss=0.24198415875434875
[10/24] Train loss=0.2661246657371521
[15/24] Train loss=0.24508211016654968
[20/24] Train loss=0.25955942273139954
Test set avg_accuracy=85.64% avg_sensitivity=71.64%, avg_specificity=90.85% avg_auc=89.48%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.268431 Test loss=0.366699 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.2552762031555176
[5/24] Train loss=0.24383403360843658
[10/24] Train loss=0.2623717486858368
[15/24] Train loss=0.24818304181098938
[20/24] Train loss=0.2682644724845886
Test set avg_accuracy=85.69% avg_sensitivity=70.39%, avg_specificity=91.39% avg_auc=89.44%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.268344 Test loss=0.367110 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.25686416029930115
[5/24] Train loss=0.24054256081581116
[10/24] Train loss=0.26965054869651794
[15/24] Train loss=0.24630093574523926
[20/24] Train loss=0.26513925194740295
Test set avg_accuracy=85.60% avg_sensitivity=70.49%, avg_specificity=91.23% avg_auc=89.46%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.268353 Test loss=0.366657 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.2581044137477875
[5/24] Train loss=0.24325326085090637
[10/24] Train loss=0.2675364911556244
[15/24] Train loss=0.24633371829986572
[20/24] Train loss=0.26261091232299805
Test set avg_accuracy=85.68% avg_sensitivity=71.02%, avg_specificity=91.14% avg_auc=89.46%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.268578 Test loss=0.366771 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.2568097710609436
[5/24] Train loss=0.24338418245315552
[10/24] Train loss=0.26465925574302673
[15/24] Train loss=0.2445729821920395
[20/24] Train loss=0.26177138090133667
Test set avg_accuracy=85.70% avg_sensitivity=70.20%, avg_specificity=91.48% avg_auc=89.46%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.267979 Test loss=0.366488 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.2557668685913086
[5/24] Train loss=0.24102257192134857
[10/24] Train loss=0.2619290053844452
[15/24] Train loss=0.24299344420433044
[20/24] Train loss=0.26221415400505066
Test set avg_accuracy=85.73% avg_sensitivity=70.39%, avg_specificity=91.44% avg_auc=89.46%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.267297 Test loss=0.366597 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.25462207198143005
[5/24] Train loss=0.2471737414598465
[10/24] Train loss=0.2637074291706085
[15/24] Train loss=0.2463512420654297
[20/24] Train loss=0.2608233690261841
Test set avg_accuracy=85.70% avg_sensitivity=70.25%, avg_specificity=91.46% avg_auc=89.45%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.268196 Test loss=0.366745 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.25352954864501953
[5/24] Train loss=0.23800969123840332
[10/24] Train loss=0.26260796189308167
[15/24] Train loss=0.24303577840328217
[20/24] Train loss=0.26575642824172974
Test set avg_accuracy=85.68% avg_sensitivity=70.25%, avg_specificity=91.42% avg_auc=89.45%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.266615 Test loss=0.366779 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.24900703132152557
[5/24] Train loss=0.24129916727542877
[10/24] Train loss=0.26949208974838257
[15/24] Train loss=0.24267159402370453
[20/24] Train loss=0.26398414373397827
Test set avg_accuracy=85.70% avg_sensitivity=70.25%, avg_specificity=91.46% avg_auc=89.44%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.267382 Test loss=0.366888 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.25311169028282166
[5/24] Train loss=0.24168430268764496
[10/24] Train loss=0.26754212379455566
[15/24] Train loss=0.24763402342796326
[20/24] Train loss=0.2626610994338989
Test set avg_accuracy=85.66% avg_sensitivity=70.06%, avg_specificity=91.48% avg_auc=89.44%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.266834 Test loss=0.366900 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.2585868239402771
[5/24] Train loss=0.24471566081047058
[10/24] Train loss=0.2698778212070465
[15/24] Train loss=0.24651120603084564
[20/24] Train loss=0.2635849118232727
Test set avg_accuracy=85.69% avg_sensitivity=70.20%, avg_specificity=91.46% avg_auc=89.45%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.267723 Test loss=0.366919 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.2518537938594818
[5/24] Train loss=0.24316659569740295
[10/24] Train loss=0.2696997821331024
[15/24] Train loss=0.2422385811805725
[20/24] Train loss=0.2644621431827545
Test set avg_accuracy=85.73% avg_sensitivity=70.35%, avg_specificity=91.46% avg_auc=89.45%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.267437 Test loss=0.366877 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.2520308792591095
[5/24] Train loss=0.242532879114151
[10/24] Train loss=0.2677791118621826
[15/24] Train loss=0.2451733499765396
[20/24] Train loss=0.26512446999549866
Test set avg_accuracy=85.73% avg_sensitivity=70.35%, avg_specificity=91.46% avg_auc=89.45%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.267715 Test loss=0.366842 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.2571602463722229
[5/24] Train loss=0.2421431541442871
[10/24] Train loss=0.2714379131793976
[15/24] Train loss=0.24368642270565033
[20/24] Train loss=0.2646760046482086
Test set avg_accuracy=85.73% avg_sensitivity=70.35%, avg_specificity=91.46% avg_auc=89.45%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.268216 Test loss=0.366818 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.2580181956291199
[5/24] Train loss=0.24030473828315735
[10/24] Train loss=0.2661391794681549
[15/24] Train loss=0.24337810277938843
[20/24] Train loss=0.2678820788860321
Test set avg_accuracy=85.73% avg_sensitivity=70.35%, avg_specificity=91.46% avg_auc=89.45%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.267661 Test loss=0.366813 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.2532532215118408
[5/24] Train loss=0.2405805140733719
[10/24] Train loss=0.26348406076431274
[15/24] Train loss=0.24413169920444489
[20/24] Train loss=0.26082655787467957
Test set avg_accuracy=85.73% avg_sensitivity=70.35%, avg_specificity=91.46% avg_auc=89.45%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.266822 Test loss=0.366812 Current lr=[4.388541022775342e-09]

Fold[6] Result: acc=85.83% sen=72.70%, spe=90.73%, auc=90.56%!
Fold[6] Avg_jsc=0.61%(±0.27648730605850114)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.6943104863166809
[5/24] Train loss=0.6877607107162476
[10/24] Train loss=0.6811864376068115
[15/24] Train loss=0.6716647148132324
[20/24] Train loss=0.6658318638801575
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.12%
Best model saved!! Metric=52.124914519051934!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.677911 Test loss=0.660990 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6598044633865356
[5/24] Train loss=0.6406124234199524
[10/24] Train loss=0.636634111404419
[15/24] Train loss=0.6147157549858093
[20/24] Train loss=0.6092968583106995
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.96%
Best model saved!! Metric=53.960192488295164!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.628890 Test loss=0.607396 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.6043734550476074
[5/24] Train loss=0.56077641248703
[10/24] Train loss=0.57795250415802
[15/24] Train loss=0.5502698421478271
[20/24] Train loss=0.5679938197135925
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.20%
Best model saved!! Metric=57.20229836567806!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.571840 Test loss=0.588173 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.5806774497032166
[5/24] Train loss=0.5214818716049194
[10/24] Train loss=0.5669572949409485
[15/24] Train loss=0.5377335548400879
[20/24] Train loss=0.5576871037483215
Test set avg_accuracy=71.98% avg_sensitivity=1.84%, avg_specificity=98.74% avg_auc=63.75%
Best model saved!! Metric=63.753495463647056!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.556970 Test loss=0.577844 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.570236325263977
[5/24] Train loss=0.5186546444892883
[10/24] Train loss=0.5596796870231628
[15/24] Train loss=0.5343227386474609
[20/24] Train loss=0.5504032373428345
Test set avg_accuracy=71.59% avg_sensitivity=1.84%, avg_specificity=98.20% avg_auc=66.14%
Best model saved!! Metric=66.14447698720993!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.550753 Test loss=0.571943 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5652846693992615
[5/24] Train loss=0.5088088512420654
[10/24] Train loss=0.5524876117706299
[15/24] Train loss=0.5223554372787476
[20/24] Train loss=0.5396650433540344
Test set avg_accuracy=71.46% avg_sensitivity=1.84%, avg_specificity=98.02% avg_auc=68.27%
Best model saved!! Metric=68.27369576831246!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.543307 Test loss=0.565486 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5584683418273926
[5/24] Train loss=0.4973846673965454
[10/24] Train loss=0.5438503623008728
[15/24] Train loss=0.5109928250312805
[20/24] Train loss=0.5253334641456604
Test set avg_accuracy=71.12% avg_sensitivity=4.48%, avg_specificity=96.55% avg_auc=70.29%
Best model saved!! Metric=70.28606337620887!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.534584 Test loss=0.555623 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.5487834215164185
[5/24] Train loss=0.4829912483692169
[10/24] Train loss=0.533281147480011
[15/24] Train loss=0.49657294154167175
[20/24] Train loss=0.5098704695701599
Test set avg_accuracy=71.03% avg_sensitivity=7.12%, avg_specificity=95.41% avg_auc=72.40%
Best model saved!! Metric=72.40109293482739!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.523971 Test loss=0.543587 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.5361855030059814
[5/24] Train loss=0.46848756074905396
[10/24] Train loss=0.5212583541870117
[15/24] Train loss=0.48206964135169983
[20/24] Train loss=0.49333304166793823
Test set avg_accuracy=71.48% avg_sensitivity=10.28%, avg_specificity=94.84% avg_auc=75.17%
Best model saved!! Metric=75.17048482274794!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.511034 Test loss=0.526650 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.5174944996833801
[5/24] Train loss=0.45198461413383484
[10/24] Train loss=0.5041282176971436
[15/24] Train loss=0.4630303978919983
[20/24] Train loss=0.469989150762558
Test set avg_accuracy=71.73% avg_sensitivity=14.24%, avg_specificity=93.67% avg_auc=78.46%
Best model saved!! Metric=78.45838126330558!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.493013 Test loss=0.500877 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.49033352732658386
[5/24] Train loss=0.4285663068294525
[10/24] Train loss=0.47995856404304504
[15/24] Train loss=0.43478286266326904
[20/24] Train loss=0.43993961811065674
Test set avg_accuracy=73.88% avg_sensitivity=25.04%, avg_specificity=92.52% avg_auc=81.53%
Best model saved!! Metric=81.53033096849119!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.467984 Test loss=0.467194 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.4551841616630554
[5/24] Train loss=0.40175706148147583
[10/24] Train loss=0.45501312613487244
[15/24] Train loss=0.4074312448501587
[20/24] Train loss=0.4106539189815521
Test set avg_accuracy=76.71% avg_sensitivity=37.86%, avg_specificity=91.53% avg_auc=83.88%
Best model saved!! Metric=83.8817980942339!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.441812 Test loss=0.439059 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.42876699566841125
[5/24] Train loss=0.38053804636001587
[10/24] Train loss=0.4339730143547058
[15/24] Train loss=0.3868429362773895
[20/24] Train loss=0.3900902569293976
Test set avg_accuracy=78.92% avg_sensitivity=47.48%, avg_specificity=90.92% avg_auc=85.71%
Best model saved!! Metric=85.7128523738196!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.420419 Test loss=0.417676 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.4077994227409363
[5/24] Train loss=0.3630264401435852
[10/24] Train loss=0.4152860939502716
[15/24] Train loss=0.3653545379638672
[20/24] Train loss=0.3702770471572876
Test set avg_accuracy=80.52% avg_sensitivity=52.95%, avg_specificity=91.04% avg_auc=87.05%
Best model saved!! Metric=87.04766552516789!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.401270 Test loss=0.400538 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.3885882794857025
[5/24] Train loss=0.3489820659160614
[10/24] Train loss=0.39932042360305786
[15/24] Train loss=0.3470378518104553
[20/24] Train loss=0.3547431528568268
Test set avg_accuracy=81.86% avg_sensitivity=59.36%, avg_specificity=90.45% avg_auc=87.96%
Best model saved!! Metric=87.96318842430848!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.384923 Test loss=0.387163 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.372479647397995
[5/24] Train loss=0.33774334192276
[10/24] Train loss=0.38781601190567017
[15/24] Train loss=0.3304213583469391
[20/24] Train loss=0.3403918743133545
Test set avg_accuracy=82.08% avg_sensitivity=61.39%, avg_specificity=89.98% avg_auc=88.65%
Best model saved!! Metric=88.64612002793064!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.371000 Test loss=0.376172 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.3567119836807251
[5/24] Train loss=0.32916319370269775
[10/24] Train loss=0.3789606988430023
[15/24] Train loss=0.3157593905925751
[20/24] Train loss=0.32671472430229187
Test set avg_accuracy=82.33% avg_sensitivity=62.00%, avg_specificity=90.09% avg_auc=89.15%
Best model saved!! Metric=89.15227580116736!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.359036 Test loss=0.367668 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.34417492151260376
[5/24] Train loss=0.3229943811893463
[10/24] Train loss=0.3706102669239044
[15/24] Train loss=0.3049624562263489
[20/24] Train loss=0.31694090366363525
Test set avg_accuracy=83.23% avg_sensitivity=64.64%, avg_specificity=90.32% avg_auc=89.49%
Best model saved!! Metric=89.4871685919652!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.349455 Test loss=0.362009 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.3370916545391083
[5/24] Train loss=0.3193399906158447
[10/24] Train loss=0.3636246621608734
[15/24] Train loss=0.2971923351287842
[20/24] Train loss=0.30504852533340454
Test set avg_accuracy=83.65% avg_sensitivity=65.82%, avg_specificity=90.45% avg_auc=89.68%
Best model saved!! Metric=89.68256088580102!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.342504 Test loss=0.358259 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.32916802167892456
[5/24] Train loss=0.3149837851524353
[10/24] Train loss=0.3582388162612915
[15/24] Train loss=0.29158246517181396
[20/24] Train loss=0.29602134227752686
Test set avg_accuracy=83.52% avg_sensitivity=64.83%, avg_specificity=90.65% avg_auc=89.78%
Best model saved!! Metric=89.78088464925436!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.336126 Test loss=0.355713 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.32273516058921814
[5/24] Train loss=0.3095628321170807
[10/24] Train loss=0.3554764688014984
[15/24] Train loss=0.2870309352874756
[20/24] Train loss=0.28953051567077637
Test set avg_accuracy=84.11% avg_sensitivity=64.83%, avg_specificity=91.47% avg_auc=89.87%
Best model saved!! Metric=89.87317396453238!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.330761 Test loss=0.353622 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.318301260471344
[5/24] Train loss=0.30334746837615967
[10/24] Train loss=0.35075241327285767
[15/24] Train loss=0.2816157937049866
[20/24] Train loss=0.28451356291770935
Test set avg_accuracy=84.22% avg_sensitivity=62.61%, avg_specificity=92.46% avg_auc=89.92%
Best model saved!! Metric=89.91632260134502!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.325325 Test loss=0.352996 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.31378963589668274
[5/24] Train loss=0.2940163314342499
[10/24] Train loss=0.34511449933052063
[15/24] Train loss=0.27619850635528564
[20/24] Train loss=0.2824537456035614
Test set avg_accuracy=84.23% avg_sensitivity=60.25%, avg_specificity=93.38% avg_auc=90.03%
Best model saved!! Metric=90.03298718585143!!
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.319915 Test loss=0.352051 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.31143563985824585
[5/24] Train loss=0.2874335050582886
[10/24] Train loss=0.3411999046802521
[15/24] Train loss=0.2714408040046692
[20/24] Train loss=0.28159618377685547
Test set avg_accuracy=83.98% avg_sensitivity=58.93%, avg_specificity=93.54% avg_auc=90.12%
Best model saved!! Metric=90.1175457920474!!
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.315334 Test loss=0.351022 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.3068520128726959
[5/24] Train loss=0.2825804650783539
[10/24] Train loss=0.33969390392303467
[15/24] Train loss=0.26974621415138245
[20/24] Train loss=0.2798955738544464
Test set avg_accuracy=84.28% avg_sensitivity=59.26%, avg_specificity=93.83% avg_auc=90.15%
Best model saved!! Metric=90.14636102419894!!
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.311666 Test loss=0.350828 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.30406802892684937
[5/24] Train loss=0.2802691161632538
[10/24] Train loss=0.3363153636455536
[15/24] Train loss=0.2672555446624756
[20/24] Train loss=0.2767157554626465
Test set avg_accuracy=84.54% avg_sensitivity=57.90%, avg_specificity=94.71% avg_auc=90.10%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.309213 Test loss=0.352609 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.30599939823150635
[5/24] Train loss=0.2764568030834198
[10/24] Train loss=0.3342771828174591
[15/24] Train loss=0.2660242021083832
[20/24] Train loss=0.27531537413597107
Test set avg_accuracy=84.61% avg_sensitivity=56.62%, avg_specificity=95.29% avg_auc=90.07%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.307327 Test loss=0.354295 Current lr=[0.000669125424222739]

[0/24] Train loss=0.3040371835231781
[5/24] Train loss=0.2757968306541443
[10/24] Train loss=0.33426058292388916
[15/24] Train loss=0.26188695430755615
[20/24] Train loss=0.2693747878074646
Test set avg_accuracy=84.32% avg_sensitivity=54.93%, avg_specificity=95.54% avg_auc=90.05%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.305246 Test loss=0.356555 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.30492621660232544
[5/24] Train loss=0.2753613293170929
[10/24] Train loss=0.33657917380332947
[15/24] Train loss=0.2607865333557129
[20/24] Train loss=0.26961538195610046
Test set avg_accuracy=84.35% avg_sensitivity=55.30%, avg_specificity=95.43% avg_auc=90.01%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.303979 Test loss=0.356552 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.3021825850009918
[5/24] Train loss=0.27534613013267517
[10/24] Train loss=0.32998234033584595
[15/24] Train loss=0.2588263154029846
[20/24] Train loss=0.2668985426425934
Test set avg_accuracy=84.21% avg_sensitivity=53.70%, avg_specificity=95.84% avg_auc=89.97%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.301566 Test loss=0.359624 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.3038119673728943
[5/24] Train loss=0.2735748887062073
[10/24] Train loss=0.3293701708316803
[15/24] Train loss=0.25614842772483826
[20/24] Train loss=0.26722803711891174
Test set avg_accuracy=83.72% avg_sensitivity=51.49%, avg_specificity=96.02% avg_auc=89.81%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.300553 Test loss=0.363462 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.30208852887153625
[5/24] Train loss=0.2708478569984436
[10/24] Train loss=0.32768023014068604
[15/24] Train loss=0.253316730260849
[20/24] Train loss=0.2657600939273834
Test set avg_accuracy=83.59% avg_sensitivity=50.40%, avg_specificity=96.26% avg_auc=89.74%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.298589 Test loss=0.365945 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.3050652742385864
[5/24] Train loss=0.27047547698020935
[10/24] Train loss=0.32498520612716675
[15/24] Train loss=0.2533319592475891
[20/24] Train loss=0.26352161169052124
Test set avg_accuracy=83.27% avg_sensitivity=48.70%, avg_specificity=96.46% avg_auc=89.60%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.296844 Test loss=0.370308 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.3065270781517029
[5/24] Train loss=0.2686801552772522
[10/24] Train loss=0.3196411728858948
[15/24] Train loss=0.25284719467163086
[20/24] Train loss=0.2624070942401886
Test set avg_accuracy=83.33% avg_sensitivity=48.23%, avg_specificity=96.73% avg_auc=89.50%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.295513 Test loss=0.375131 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.31063714623451233
[5/24] Train loss=0.268484890460968
[10/24] Train loss=0.3216352164745331
[15/24] Train loss=0.25040432810783386
[20/24] Train loss=0.26323896646499634
Test set avg_accuracy=83.18% avg_sensitivity=48.00%, avg_specificity=96.60% avg_auc=89.61%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.295470 Test loss=0.374703 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.3085837960243225
[5/24] Train loss=0.26891982555389404
[10/24] Train loss=0.3157304525375366
[15/24] Train loss=0.24881476163864136
[20/24] Train loss=0.25953441858291626
Test set avg_accuracy=83.62% avg_sensitivity=49.65%, avg_specificity=96.58% avg_auc=89.74%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.294418 Test loss=0.370755 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.3026508390903473
[5/24] Train loss=0.2671176493167877
[10/24] Train loss=0.3148598074913025
[15/24] Train loss=0.24924729764461517
[20/24] Train loss=0.2623174488544464
Test set avg_accuracy=83.65% avg_sensitivity=50.78%, avg_specificity=96.19% avg_auc=89.73%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.292830 Test loss=0.370444 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.298359751701355
[5/24] Train loss=0.2656669020652771
[10/24] Train loss=0.3157009780406952
[15/24] Train loss=0.2513244152069092
[20/24] Train loss=0.2572110593318939
Test set avg_accuracy=83.46% avg_sensitivity=48.84%, avg_specificity=96.67% avg_auc=89.67%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.291204 Test loss=0.374981 Current lr=[0.000944367614404117]

[0/24] Train loss=0.30521851778030396
[5/24] Train loss=0.26942378282546997
[10/24] Train loss=0.3175755441188812
[15/24] Train loss=0.24797971546649933
[20/24] Train loss=0.25347962975502014
Test set avg_accuracy=83.44% avg_sensitivity=49.03%, avg_specificity=96.56% avg_auc=89.62%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.290638 Test loss=0.375518 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.30616042017936707
[5/24] Train loss=0.27076759934425354
[10/24] Train loss=0.3151317834854126
[15/24] Train loss=0.24643442034721375
[20/24] Train loss=0.2557593286037445
Test set avg_accuracy=83.44% avg_sensitivity=48.28%, avg_specificity=96.85% avg_auc=89.53%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.290698 Test loss=0.380368 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.3122965693473816
[5/24] Train loss=0.2734197676181793
[10/24] Train loss=0.31341925263404846
[15/24] Train loss=0.25023290514945984
[20/24] Train loss=0.2561849355697632
Test set avg_accuracy=83.26% avg_sensitivity=47.19%, avg_specificity=97.01% avg_auc=89.50%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.292729 Test loss=0.380268 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.3090457022190094
[5/24] Train loss=0.26657286286354065
[10/24] Train loss=0.31220462918281555
[15/24] Train loss=0.25163039565086365
[20/24] Train loss=0.2578114867210388
Test set avg_accuracy=83.70% avg_sensitivity=48.94%, avg_specificity=96.96% avg_auc=89.56%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.292745 Test loss=0.376912 Current lr=[0.000989780311725182]

[0/24] Train loss=0.304222047328949
[5/24] Train loss=0.2678181231021881
[10/24] Train loss=0.31256893277168274
[15/24] Train loss=0.24678991734981537
[20/24] Train loss=0.2577049732208252
Test set avg_accuracy=83.57% avg_sensitivity=49.74%, avg_specificity=96.47% avg_auc=89.53%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.290172 Test loss=0.374431 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.2969016432762146
[5/24] Train loss=0.2638428509235382
[10/24] Train loss=0.31570449471473694
[15/24] Train loss=0.2469431757926941
[20/24] Train loss=0.25921857357025146
Test set avg_accuracy=84.02% avg_sensitivity=52.19%, avg_specificity=96.17% avg_auc=89.34%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.289332 Test loss=0.372249 Current lr=[0.000998924125869967]

[0/24] Train loss=0.29423651099205017
[5/24] Train loss=0.26242175698280334
[10/24] Train loss=0.31547224521636963
[15/24] Train loss=0.24313445389270782
[20/24] Train loss=0.254423588514328
Test set avg_accuracy=84.02% avg_sensitivity=51.67%, avg_specificity=96.37% avg_auc=89.35%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.288249 Test loss=0.373310 Current lr=[0.000999999611458977]

[0/24] Train loss=0.2950059771537781
[5/24] Train loss=0.261729896068573
[10/24] Train loss=0.3125307559967041
[15/24] Train loss=0.2471458911895752
[20/24] Train loss=0.2566887438297272
Test set avg_accuracy=83.45% avg_sensitivity=49.08%, avg_specificity=96.56% avg_auc=89.33%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.288451 Test loss=0.377449 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.30513492226600647
[5/24] Train loss=0.26271212100982666
[10/24] Train loss=0.314578115940094
[15/24] Train loss=0.2461976557970047
[20/24] Train loss=0.25506144762039185
Test set avg_accuracy=83.76% avg_sensitivity=50.21%, avg_specificity=96.56% avg_auc=89.48%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.288940 Test loss=0.374593 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.29758647084236145
[5/24] Train loss=0.263415664434433
[10/24] Train loss=0.3138686418533325
[15/24] Train loss=0.24622505903244019
[20/24] Train loss=0.2560579776763916
Test set avg_accuracy=83.84% avg_sensitivity=50.54%, avg_specificity=96.55% avg_auc=89.46%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.287683 Test loss=0.374092 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.295998215675354
[5/24] Train loss=0.2624336779117584
[10/24] Train loss=0.3142372965812683
[15/24] Train loss=0.2469342201948166
[20/24] Train loss=0.25880393385887146
Test set avg_accuracy=84.22% avg_sensitivity=52.62%, avg_specificity=96.28% avg_auc=89.51%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.287884 Test loss=0.370362 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.2916859984397888
[5/24] Train loss=0.2651636600494385
[10/24] Train loss=0.31623733043670654
[15/24] Train loss=0.24601076543331146
[20/24] Train loss=0.257639616727829
Test set avg_accuracy=84.01% avg_sensitivity=52.66%, avg_specificity=95.97% avg_auc=89.56%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.287766 Test loss=0.368130 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.29162245988845825
[5/24] Train loss=0.2616539001464844
[10/24] Train loss=0.31432804465293884
[15/24] Train loss=0.24377939105033875
[20/24] Train loss=0.2594504952430725
Test set avg_accuracy=83.97% avg_sensitivity=52.76%, avg_specificity=95.88% avg_auc=89.43%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.287170 Test loss=0.369730 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.29063451290130615
[5/24] Train loss=0.2620837092399597
[10/24] Train loss=0.3182379901409149
[15/24] Train loss=0.24221587181091309
[20/24] Train loss=0.2624582052230835
Test set avg_accuracy=83.92% avg_sensitivity=52.85%, avg_specificity=95.77% avg_auc=89.50%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.287173 Test loss=0.369710 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.28877899050712585
[5/24] Train loss=0.26118960976600647
[10/24] Train loss=0.31928902864456177
[15/24] Train loss=0.24572446942329407
[20/24] Train loss=0.25641679763793945
Test set avg_accuracy=83.78% avg_sensitivity=51.86%, avg_specificity=95.95% avg_auc=89.46%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.287159 Test loss=0.372199 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.29267001152038574
[5/24] Train loss=0.26282572746276855
[10/24] Train loss=0.31742092967033386
[15/24] Train loss=0.2423507571220398
[20/24] Train loss=0.25524595379829407
Test set avg_accuracy=83.80% avg_sensitivity=51.82%, avg_specificity=96.01% avg_auc=89.57%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.287130 Test loss=0.371078 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.2876732647418976
[5/24] Train loss=0.26308226585388184
[10/24] Train loss=0.31056419014930725
[15/24] Train loss=0.24046590924263
[20/24] Train loss=0.25488752126693726
Test set avg_accuracy=84.01% avg_sensitivity=52.52%, avg_specificity=96.02% avg_auc=89.80%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.286310 Test loss=0.367171 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.28621917963027954
[5/24] Train loss=0.2637733817100525
[10/24] Train loss=0.3163583278656006
[15/24] Train loss=0.24274791777133942
[20/24] Train loss=0.25759249925613403
Test set avg_accuracy=84.31% avg_sensitivity=56.11%, avg_specificity=95.07% avg_auc=89.71%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.287266 Test loss=0.362682 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.28045138716697693
[5/24] Train loss=0.2613188624382019
[10/24] Train loss=0.3171212077140808
[15/24] Train loss=0.24588319659233093
[20/24] Train loss=0.2556648850440979
Test set avg_accuracy=84.47% avg_sensitivity=55.07%, avg_specificity=95.68% avg_auc=89.54%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.287501 Test loss=0.367286 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.28370243310928345
[5/24] Train loss=0.2622513175010681
[10/24] Train loss=0.31939780712127686
[15/24] Train loss=0.24526575207710266
[20/24] Train loss=0.2618592381477356
Test set avg_accuracy=84.36% avg_sensitivity=55.73%, avg_specificity=95.29% avg_auc=89.62%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.286994 Test loss=0.366710 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.28087279200553894
[5/24] Train loss=0.26196107268333435
[10/24] Train loss=0.31505337357521057
[15/24] Train loss=0.24710404872894287
[20/24] Train loss=0.25695058703422546
Test set avg_accuracy=84.32% avg_sensitivity=55.59%, avg_specificity=95.29% avg_auc=89.77%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.286082 Test loss=0.363128 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.28149986267089844
[5/24] Train loss=0.2613738775253296
[10/24] Train loss=0.3204958438873291
[15/24] Train loss=0.24592339992523193
[20/24] Train loss=0.2600861191749573
Test set avg_accuracy=84.28% avg_sensitivity=55.82%, avg_specificity=95.14% avg_auc=89.63%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.287650 Test loss=0.364763 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.27920588850975037
[5/24] Train loss=0.26173242926597595
[10/24] Train loss=0.31954118609428406
[15/24] Train loss=0.2442973405122757
[20/24] Train loss=0.2586386799812317
Test set avg_accuracy=84.54% avg_sensitivity=57.61%, avg_specificity=94.82% avg_auc=89.74%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.287216 Test loss=0.361005 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.27778664231300354
[5/24] Train loss=0.2605081796646118
[10/24] Train loss=0.31608232855796814
[15/24] Train loss=0.24473941326141357
[20/24] Train loss=0.2565498352050781
Test set avg_accuracy=84.53% avg_sensitivity=57.14%, avg_specificity=94.98% avg_auc=89.69%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.287455 Test loss=0.361044 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.27729538083076477
[5/24] Train loss=0.2611176669597626
[10/24] Train loss=0.325011283159256
[15/24] Train loss=0.24627871811389923
[20/24] Train loss=0.2522185444831848
Test set avg_accuracy=84.56% avg_sensitivity=57.38%, avg_specificity=94.93% avg_auc=90.00%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.287861 Test loss=0.356993 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.27292031049728394
[5/24] Train loss=0.2623310387134552
[10/24] Train loss=0.32675331830978394
[15/24] Train loss=0.24979884922504425
[20/24] Train loss=0.2570488750934601
Test set avg_accuracy=84.38% avg_sensitivity=57.85%, avg_specificity=94.50% avg_auc=90.01%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.287996 Test loss=0.357745 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.27844610810279846
[5/24] Train loss=0.263700932264328
[10/24] Train loss=0.32618463039398193
[15/24] Train loss=0.2469186633825302
[20/24] Train loss=0.2539813220500946
Test set avg_accuracy=84.56% avg_sensitivity=58.23%, avg_specificity=94.60% avg_auc=90.12%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.288553 Test loss=0.356999 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.2758176028728485
[5/24] Train loss=0.263543039560318
[10/24] Train loss=0.3213178217411041
[15/24] Train loss=0.24534659087657928
[20/24] Train loss=0.253063827753067
Test set avg_accuracy=84.66% avg_sensitivity=59.31%, avg_specificity=94.33% avg_auc=89.96%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.287834 Test loss=0.357202 Current lr=[0.000904142181093812]

[0/24] Train loss=0.27564945816993713
[5/24] Train loss=0.2628847658634186
[10/24] Train loss=0.3272593915462494
[15/24] Train loss=0.2486073076725006
[20/24] Train loss=0.2567344605922699
Test set avg_accuracy=84.96% avg_sensitivity=60.68%, avg_specificity=94.23% avg_auc=90.04%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.288341 Test loss=0.354854 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.27075591683387756
[5/24] Train loss=0.26313909888267517
[10/24] Train loss=0.3286283016204834
[15/24] Train loss=0.2513839304447174
[20/24] Train loss=0.2579638659954071
Test set avg_accuracy=84.97% avg_sensitivity=63.70%, avg_specificity=93.09% avg_auc=90.16%
Best model saved!! Metric=90.15947312100727!!
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.289259 Test loss=0.350458 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.2733951807022095
[5/24] Train loss=0.2629445493221283
[10/24] Train loss=0.3277696669101715
[15/24] Train loss=0.2512878179550171
[20/24] Train loss=0.2634243965148926
Test set avg_accuracy=85.03% avg_sensitivity=68.13%, avg_specificity=91.47% avg_auc=90.15%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.291415 Test loss=0.349312 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.2758026123046875
[5/24] Train loss=0.26582279801368713
[10/24] Train loss=0.3310629427433014
[15/24] Train loss=0.256161093711853
[20/24] Train loss=0.26462042331695557
Test set avg_accuracy=85.09% avg_sensitivity=70.25%, avg_specificity=90.75% avg_auc=90.29%
Best model saved!! Metric=90.29160336432996!!
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.292589 Test loss=0.349679 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.2830139398574829
[5/24] Train loss=0.2690228223800659
[10/24] Train loss=0.31816408038139343
[15/24] Train loss=0.2556317150592804
[20/24] Train loss=0.26434171199798584
Test set avg_accuracy=85.01% avg_sensitivity=69.97%, avg_specificity=90.75% avg_auc=90.17%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.293762 Test loss=0.350932 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.2813090682029724
[5/24] Train loss=0.2718115746974945
[10/24] Train loss=0.31465601921081543
[15/24] Train loss=0.24791255593299866
[20/24] Train loss=0.26128214597702026
Test set avg_accuracy=85.07% avg_sensitivity=68.22%, avg_specificity=91.49% avg_auc=90.08%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.291303 Test loss=0.350798 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.279850572347641
[5/24] Train loss=0.2698097825050354
[10/24] Train loss=0.3161924481391907
[15/24] Train loss=0.2440493106842041
[20/24] Train loss=0.2599864900112152
Test set avg_accuracy=85.18% avg_sensitivity=67.47%, avg_specificity=91.94% avg_auc=90.08%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.289229 Test loss=0.350952 Current lr=[0.000834102481048427]

[0/24] Train loss=0.2748996317386627
[5/24] Train loss=0.262395441532135
[10/24] Train loss=0.3132931888103485
[15/24] Train loss=0.24521924555301666
[20/24] Train loss=0.2564806640148163
Test set avg_accuracy=84.83% avg_sensitivity=66.95%, avg_specificity=91.65% avg_auc=90.01%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.286662 Test loss=0.352447 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.27247869968414307
[5/24] Train loss=0.2583566904067993
[10/24] Train loss=0.31658557057380676
[15/24] Train loss=0.24409915506839752
[20/24] Train loss=0.25943952798843384
Test set avg_accuracy=84.84% avg_sensitivity=67.28%, avg_specificity=91.55% avg_auc=90.05%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.285373 Test loss=0.352871 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.2714913785457611
[5/24] Train loss=0.26522207260131836
[10/24] Train loss=0.3132646381855011
[15/24] Train loss=0.24634386599063873
[20/24] Train loss=0.25851425528526306
Test set avg_accuracy=84.92% avg_sensitivity=67.80%, avg_specificity=91.46% avg_auc=90.04%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.284998 Test loss=0.353837 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.27399539947509766
[5/24] Train loss=0.2614186704158783
[10/24] Train loss=0.3092018961906433
[15/24] Train loss=0.24551770091056824
[20/24] Train loss=0.258171945810318
Test set avg_accuracy=85.12% avg_sensitivity=67.99%, avg_specificity=91.65% avg_auc=90.12%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.285921 Test loss=0.351366 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.2727528214454651
[5/24] Train loss=0.2579886019229889
[10/24] Train loss=0.30849477648735046
[15/24] Train loss=0.2444334477186203
[20/24] Train loss=0.25370728969573975
Test set avg_accuracy=84.93% avg_sensitivity=67.37%, avg_specificity=91.64% avg_auc=90.06%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.285065 Test loss=0.353085 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.2729033827781677
[5/24] Train loss=0.260906845331192
[10/24] Train loss=0.30753812193870544
[15/24] Train loss=0.24088072776794434
[20/24] Train loss=0.2583213746547699
Test set avg_accuracy=84.95% avg_sensitivity=66.24%, avg_specificity=92.08% avg_auc=90.00%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.283783 Test loss=0.353703 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.2733660638332367
[5/24] Train loss=0.2600983679294586
[10/24] Train loss=0.310321569442749
[15/24] Train loss=0.24113282561302185
[20/24] Train loss=0.2559998631477356
Test set avg_accuracy=84.74% avg_sensitivity=66.62%, avg_specificity=91.65% avg_auc=89.99%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.282614 Test loss=0.354354 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.26972320675849915
[5/24] Train loss=0.25930657982826233
[10/24] Train loss=0.3056807219982147
[15/24] Train loss=0.23988088965415955
[20/24] Train loss=0.25999414920806885
Test set avg_accuracy=84.58% avg_sensitivity=66.43%, avg_specificity=91.51% avg_auc=89.91%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.283193 Test loss=0.356998 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.2696436941623688
[5/24] Train loss=0.2672203779220581
[10/24] Train loss=0.30711299180984497
[15/24] Train loss=0.2435152679681778
[20/24] Train loss=0.25290051102638245
Test set avg_accuracy=84.60% avg_sensitivity=65.35%, avg_specificity=91.94% avg_auc=89.93%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.284828 Test loss=0.356195 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.2703668773174286
[5/24] Train loss=0.2553844451904297
[10/24] Train loss=0.3083330988883972
[15/24] Train loss=0.23684006929397583
[20/24] Train loss=0.2518869936466217
Test set avg_accuracy=84.49% avg_sensitivity=64.45%, avg_specificity=92.14% avg_auc=89.76%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.280977 Test loss=0.358614 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.26759111881256104
[5/24] Train loss=0.2570630609989166
[10/24] Train loss=0.300810843706131
[15/24] Train loss=0.23750737309455872
[20/24] Train loss=0.24686451256275177
Test set avg_accuracy=84.61% avg_sensitivity=64.50%, avg_specificity=92.28% avg_auc=89.79%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.281302 Test loss=0.358452 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.2708840072154999
[5/24] Train loss=0.2611338496208191
[10/24] Train loss=0.30817705392837524
[15/24] Train loss=0.23595628142356873
[20/24] Train loss=0.25346532464027405
Test set avg_accuracy=84.61% avg_sensitivity=63.93%, avg_specificity=92.50% avg_auc=89.78%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.280543 Test loss=0.358714 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.26895251870155334
[5/24] Train loss=0.2570708692073822
[10/24] Train loss=0.30316221714019775
[15/24] Train loss=0.2381807565689087
[20/24] Train loss=0.2449130117893219
Test set avg_accuracy=84.86% avg_sensitivity=62.99%, avg_specificity=93.20% avg_auc=89.64%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.279992 Test loss=0.361456 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.2667010426521301
[5/24] Train loss=0.2556389272212982
[10/24] Train loss=0.3059174120426178
[15/24] Train loss=0.2370072603225708
[20/24] Train loss=0.24362899363040924
Test set avg_accuracy=84.71% avg_sensitivity=62.89%, avg_specificity=93.04% avg_auc=89.62%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.279143 Test loss=0.362231 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.2649981677532196
[5/24] Train loss=0.2588042914867401
[10/24] Train loss=0.3033134937286377
[15/24] Train loss=0.23637044429779053
[20/24] Train loss=0.24290414154529572
Test set avg_accuracy=84.66% avg_sensitivity=62.85%, avg_specificity=92.98% avg_auc=89.55%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.278347 Test loss=0.364286 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.2662718594074249
[5/24] Train loss=0.25582098960876465
[10/24] Train loss=0.3009444773197174
[15/24] Train loss=0.23745796084403992
[20/24] Train loss=0.2477205991744995
Test set avg_accuracy=84.44% avg_sensitivity=61.53%, avg_specificity=93.18% avg_auc=89.40%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.277238 Test loss=0.368151 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.2647620439529419
[5/24] Train loss=0.2527701258659363
[10/24] Train loss=0.30340489745140076
[15/24] Train loss=0.23510843515396118
[20/24] Train loss=0.23983649909496307
Test set avg_accuracy=84.39% avg_sensitivity=62.19%, avg_specificity=92.86% avg_auc=89.38%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.276536 Test loss=0.369297 Current lr=[0.00061065423442182]

[0/24] Train loss=0.26509323716163635
[5/24] Train loss=0.2526482045650482
[10/24] Train loss=0.29762932658195496
[15/24] Train loss=0.23903636634349823
[20/24] Train loss=0.24110198020935059
Test set avg_accuracy=84.39% avg_sensitivity=62.94%, avg_specificity=92.57% avg_auc=89.34%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.276501 Test loss=0.368928 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.266710489988327
[5/24] Train loss=0.2506447732448578
[10/24] Train loss=0.29884153604507446
[15/24] Train loss=0.23906201124191284
[20/24] Train loss=0.2450367957353592
Test set avg_accuracy=84.39% avg_sensitivity=61.01%, avg_specificity=93.31% avg_auc=89.28%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.276846 Test loss=0.370966 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.26552873849868774
[5/24] Train loss=0.2591354548931122
[10/24] Train loss=0.3056252598762512
[15/24] Train loss=0.24161165952682495
[20/24] Train loss=0.2397957146167755
Test set avg_accuracy=83.96% avg_sensitivity=60.68%, avg_specificity=92.84% avg_auc=89.09%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.278311 Test loss=0.373948 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.26929864287376404
[5/24] Train loss=0.25908124446868896
[10/24] Train loss=0.3086656630039215
[15/24] Train loss=0.24868716299533844
[20/24] Train loss=0.23956631124019623
Test set avg_accuracy=84.21% avg_sensitivity=59.83%, avg_specificity=93.51% avg_auc=89.20%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.277621 Test loss=0.373771 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.266583651304245
[5/24] Train loss=0.26458239555358887
[10/24] Train loss=0.2969581186771393
[15/24] Train loss=0.24381470680236816
[20/24] Train loss=0.24063195288181305
Test set avg_accuracy=84.35% avg_sensitivity=62.42%, avg_specificity=92.71% avg_auc=89.38%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.277246 Test loss=0.369927 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.2631511390209198
[5/24] Train loss=0.2616526186466217
[10/24] Train loss=0.30340564250946045
[15/24] Train loss=0.24205565452575684
[20/24] Train loss=0.2387552112340927
Test set avg_accuracy=84.74% avg_sensitivity=62.61%, avg_specificity=93.18% avg_auc=89.30%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.276584 Test loss=0.371536 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.2603771686553955
[5/24] Train loss=0.2630264163017273
[10/24] Train loss=0.2979834973812103
[15/24] Train loss=0.24164961278438568
[20/24] Train loss=0.24595338106155396
Test set avg_accuracy=84.23% avg_sensitivity=61.67%, avg_specificity=92.84% avg_auc=89.36%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.276532 Test loss=0.370200 Current lr=[0.000506858408304961]

[0/24] Train loss=0.2603451907634735
[5/24] Train loss=0.25836360454559326
[10/24] Train loss=0.2995697855949402
[15/24] Train loss=0.239030122756958
[20/24] Train loss=0.24453666806221008
Test set avg_accuracy=84.30% avg_sensitivity=62.80%, avg_specificity=92.50% avg_auc=89.36%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.276125 Test loss=0.368506 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.26308292150497437
[5/24] Train loss=0.2567000687122345
[10/24] Train loss=0.29905417561531067
[15/24] Train loss=0.23670832812786102
[20/24] Train loss=0.24132277071475983
Test set avg_accuracy=84.52% avg_sensitivity=63.88%, avg_specificity=92.39% avg_auc=89.38%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.275120 Test loss=0.367138 Current lr=[0.000476946990416354]

[0/24] Train loss=0.25708672404289246
[5/24] Train loss=0.268672376871109
[10/24] Train loss=0.3048546016216278
[15/24] Train loss=0.2471841275691986
[20/24] Train loss=0.24274472892284393
Test set avg_accuracy=84.45% avg_sensitivity=64.17%, avg_specificity=92.19% avg_auc=89.49%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.276624 Test loss=0.366645 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.2617921531200409
[5/24] Train loss=0.25576621294021606
[10/24] Train loss=0.3082040250301361
[15/24] Train loss=0.24467644095420837
[20/24] Train loss=0.23576198518276215
Test set avg_accuracy=84.30% avg_sensitivity=68.18%, avg_specificity=90.45% avg_auc=89.54%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.276602 Test loss=0.367615 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.2620888352394104
[5/24] Train loss=0.2707081735134125
[10/24] Train loss=0.3097449839115143
[15/24] Train loss=0.24598833918571472
[20/24] Train loss=0.24014930427074432
Test set avg_accuracy=84.13% avg_sensitivity=71.90%, avg_specificity=88.79% avg_auc=89.73%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.281324 Test loss=0.370486 Current lr=[0.000432267999769856]

[0/24] Train loss=0.2745589315891266
[5/24] Train loss=0.2725261449813843
[10/24] Train loss=0.30210545659065247
[15/24] Train loss=0.24342674016952515
[20/24] Train loss=0.26806461811065674
Test set avg_accuracy=84.17% avg_sensitivity=70.30%, avg_specificity=89.46% avg_auc=89.84%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.285191 Test loss=0.364338 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.27175724506378174
[5/24] Train loss=0.26010388135910034
[10/24] Train loss=0.29555532336235046
[15/24] Train loss=0.25251251459121704
[20/24] Train loss=0.25623226165771484
Test set avg_accuracy=84.23% avg_sensitivity=65.68%, avg_specificity=91.31% avg_auc=89.63%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.280698 Test loss=0.366305 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.26002374291419983
[5/24] Train loss=0.2550649642944336
[10/24] Train loss=0.29277193546295166
[15/24] Train loss=0.24189439415931702
[20/24] Train loss=0.25258538126945496
Test set avg_accuracy=83.92% avg_sensitivity=65.82%, avg_specificity=90.83% avg_auc=89.37%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.274441 Test loss=0.371557 Current lr=[0.000388134363466264]

[0/24] Train loss=0.25973179936408997
[5/24] Train loss=0.2567003667354584
[10/24] Train loss=0.2944081127643585
[15/24] Train loss=0.23444236814975739
[20/24] Train loss=0.24666069447994232
Test set avg_accuracy=84.04% avg_sensitivity=67.00%, avg_specificity=90.54% avg_auc=89.31%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.271731 Test loss=0.374377 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.2657524049282074
[5/24] Train loss=0.25648239254951477
[10/24] Train loss=0.2919364869594574
[15/24] Train loss=0.23516573011875153
[20/24] Train loss=0.24794845283031464
Test set avg_accuracy=83.76% avg_sensitivity=66.29%, avg_specificity=90.43% avg_auc=89.24%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.272061 Test loss=0.376567 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.2602437138557434
[5/24] Train loss=0.2544633448123932
[10/24] Train loss=0.2952958047389984
[15/24] Train loss=0.24050414562225342
[20/24] Train loss=0.2484787404537201
Test set avg_accuracy=84.21% avg_sensitivity=65.91%, avg_specificity=91.19% avg_auc=89.16%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.270943 Test loss=0.376074 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.25542110204696655
[5/24] Train loss=0.24914224445819855
[10/24] Train loss=0.2901977300643921
[15/24] Train loss=0.23277512192726135
[20/24] Train loss=0.24562163650989532
Test set avg_accuracy=83.92% avg_sensitivity=64.07%, avg_specificity=91.49% avg_auc=89.11%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.268614 Test loss=0.376331 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.2534734010696411
[5/24] Train loss=0.2462078034877777
[10/24] Train loss=0.2936461865901947
[15/24] Train loss=0.23033632338047028
[20/24] Train loss=0.2451671063899994
Test set avg_accuracy=83.98% avg_sensitivity=64.12%, avg_specificity=91.56% avg_auc=89.05%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.266878 Test loss=0.378363 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.2630428075790405
[5/24] Train loss=0.24752791225910187
[10/24] Train loss=0.29319649934768677
[15/24] Train loss=0.234686478972435
[20/24] Train loss=0.24165977537631989
Test set avg_accuracy=83.78% avg_sensitivity=63.13%, avg_specificity=91.65% avg_auc=89.02%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.267450 Test loss=0.379040 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.2546341121196747
[5/24] Train loss=0.24569031596183777
[10/24] Train loss=0.2914279103279114
[15/24] Train loss=0.2298535257577896
[20/24] Train loss=0.24168448150157928
Test set avg_accuracy=83.85% avg_sensitivity=63.22%, avg_specificity=91.73% avg_auc=88.96%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.265323 Test loss=0.379776 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2510749399662018
[5/24] Train loss=0.24965102970600128
[10/24] Train loss=0.2918224632740021
[15/24] Train loss=0.229766845703125
[20/24] Train loss=0.23630650341510773
Test set avg_accuracy=83.88% avg_sensitivity=63.70%, avg_specificity=91.58% avg_auc=89.00%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.264770 Test loss=0.379349 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.2538345456123352
[5/24] Train loss=0.24359221756458282
[10/24] Train loss=0.29265284538269043
[15/24] Train loss=0.22682027518749237
[20/24] Train loss=0.2382696568965912
Test set avg_accuracy=83.88% avg_sensitivity=63.37%, avg_specificity=91.71% avg_auc=88.97%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.264430 Test loss=0.380501 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.2556423842906952
[5/24] Train loss=0.24512940645217896
[10/24] Train loss=0.28767985105514526
[15/24] Train loss=0.23108543455600739
[20/24] Train loss=0.23633238673210144
Test set avg_accuracy=84.04% avg_sensitivity=63.08%, avg_specificity=92.03% avg_auc=89.00%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.264468 Test loss=0.379573 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.2533878982067108
[5/24] Train loss=0.24873687326908112
[10/24] Train loss=0.28592178225517273
[15/24] Train loss=0.23382464051246643
[20/24] Train loss=0.23843811452388763
Test set avg_accuracy=83.87% avg_sensitivity=62.66%, avg_specificity=91.96% avg_auc=89.01%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.263700 Test loss=0.380378 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.2520119249820709
[5/24] Train loss=0.2444583922624588
[10/24] Train loss=0.28664857149124146
[15/24] Train loss=0.22873155772686005
[20/24] Train loss=0.23748879134655
Test set avg_accuracy=83.98% avg_sensitivity=63.41%, avg_specificity=91.83% avg_auc=88.93%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.261621 Test loss=0.380716 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.24252748489379883
[5/24] Train loss=0.24410726130008698
[10/24] Train loss=0.2888171672821045
[15/24] Train loss=0.23005101084709167
[20/24] Train loss=0.23635895550251007
Test set avg_accuracy=83.95% avg_sensitivity=61.86%, avg_specificity=92.37% avg_auc=88.88%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.261473 Test loss=0.382492 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.2511252164840698
[5/24] Train loss=0.24540495872497559
[10/24] Train loss=0.28863126039505005
[15/24] Train loss=0.22897320985794067
[20/24] Train loss=0.2351822704076767
Test set avg_accuracy=83.92% avg_sensitivity=63.08%, avg_specificity=91.87% avg_auc=88.89%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.262017 Test loss=0.381979 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.24932144582271576
[5/24] Train loss=0.23865222930908203
[10/24] Train loss=0.28211531043052673
[15/24] Train loss=0.23016266524791718
[20/24] Train loss=0.22958563268184662
Test set avg_accuracy=84.02% avg_sensitivity=62.89%, avg_specificity=92.08% avg_auc=88.86%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.260831 Test loss=0.383289 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2504391670227051
[5/24] Train loss=0.24642305076122284
[10/24] Train loss=0.2833769619464874
[15/24] Train loss=0.232014998793602
[20/24] Train loss=0.23427782952785492
Test set avg_accuracy=83.91% avg_sensitivity=62.05%, avg_specificity=92.25% avg_auc=88.86%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.260692 Test loss=0.383693 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.24607647955417633
[5/24] Train loss=0.24210937321186066
[10/24] Train loss=0.2899360954761505
[15/24] Train loss=0.22533605992794037
[20/24] Train loss=0.23448482155799866
Test set avg_accuracy=83.96% avg_sensitivity=62.19%, avg_specificity=92.26% avg_auc=88.82%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.259370 Test loss=0.383848 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.24625051021575928
[5/24] Train loss=0.24347665905952454
[10/24] Train loss=0.2836662530899048
[15/24] Train loss=0.22737392783164978
[20/24] Train loss=0.23127056658267975
Test set avg_accuracy=84.08% avg_sensitivity=62.38%, avg_specificity=92.35% avg_auc=88.83%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.259394 Test loss=0.384429 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.24555614590644836
[5/24] Train loss=0.24184179306030273
[10/24] Train loss=0.2775459289550781
[15/24] Train loss=0.2317045032978058
[20/24] Train loss=0.23195011913776398
Test set avg_accuracy=84.14% avg_sensitivity=61.53%, avg_specificity=92.77% avg_auc=88.79%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.259542 Test loss=0.385667 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.24615813791751862
[5/24] Train loss=0.24564380943775177
[10/24] Train loss=0.2805494964122772
[15/24] Train loss=0.227240189909935
[20/24] Train loss=0.23397411406040192
Test set avg_accuracy=83.93% avg_sensitivity=62.00%, avg_specificity=92.30% avg_auc=88.79%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.258902 Test loss=0.385839 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.24710878729820251
[5/24] Train loss=0.24201826751232147
[10/24] Train loss=0.27802005410194397
[15/24] Train loss=0.22842465341091156
[20/24] Train loss=0.23201368749141693
Test set avg_accuracy=84.01% avg_sensitivity=61.67%, avg_specificity=92.53% avg_auc=88.79%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.258416 Test loss=0.385819 Current lr=[0.000123057953306828]

[0/24] Train loss=0.24976053833961487
[5/24] Train loss=0.2413340061903
[10/24] Train loss=0.27680811285972595
[15/24] Train loss=0.22879871726036072
[20/24] Train loss=0.23366497457027435
Test set avg_accuracy=84.27% avg_sensitivity=61.57%, avg_specificity=92.93% avg_auc=88.77%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.258937 Test loss=0.386469 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.2503408193588257
[5/24] Train loss=0.2390245497226715
[10/24] Train loss=0.27953603863716125
[15/24] Train loss=0.22886280715465546
[20/24] Train loss=0.22529003024101257
Test set avg_accuracy=84.11% avg_sensitivity=61.72%, avg_specificity=92.66% avg_auc=88.74%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.258184 Test loss=0.386408 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.2509150207042694
[5/24] Train loss=0.24632863700389862
[10/24] Train loss=0.27452874183654785
[15/24] Train loss=0.22505564987659454
[20/24] Train loss=0.22350218892097473
Test set avg_accuracy=84.08% avg_sensitivity=62.94%, avg_specificity=92.14% avg_auc=88.77%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.257802 Test loss=0.385141 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.24112248420715332
[5/24] Train loss=0.24969735741615295
[10/24] Train loss=0.28396081924438477
[15/24] Train loss=0.22841884195804596
[20/24] Train loss=0.22054816782474518
Test set avg_accuracy=83.91% avg_sensitivity=65.39%, avg_specificity=90.97% avg_auc=88.85%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.257292 Test loss=0.383881 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.24799112975597382
[5/24] Train loss=0.2452549785375595
[10/24] Train loss=0.2774791121482849
[15/24] Train loss=0.22353240847587585
[20/24] Train loss=0.22469177842140198
Test set avg_accuracy=83.88% avg_sensitivity=66.20%, avg_specificity=90.63% avg_auc=88.87%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.258502 Test loss=0.384094 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.24728268384933472
[5/24] Train loss=0.24315936863422394
[10/24] Train loss=0.28235384821891785
[15/24] Train loss=0.22327986359596252
[20/24] Train loss=0.2264387160539627
Test set avg_accuracy=83.98% avg_sensitivity=66.24%, avg_specificity=90.75% avg_auc=88.83%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.258061 Test loss=0.384421 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.24596069753170013
[5/24] Train loss=0.24267320334911346
[10/24] Train loss=0.2813872694969177
[15/24] Train loss=0.2264990657567978
[20/24] Train loss=0.2240978628396988
Test set avg_accuracy=83.76% avg_sensitivity=64.40%, avg_specificity=91.15% avg_auc=88.81%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.257628 Test loss=0.384813 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.24225032329559326
[5/24] Train loss=0.2388376146554947
[10/24] Train loss=0.2766738533973694
[15/24] Train loss=0.22157737612724304
[20/24] Train loss=0.22516341507434845
Test set avg_accuracy=83.82% avg_sensitivity=63.93%, avg_specificity=91.40% avg_auc=88.76%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.256698 Test loss=0.385384 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.24985943734645844
[5/24] Train loss=0.23517952859401703
[10/24] Train loss=0.27683258056640625
[15/24] Train loss=0.22510382533073425
[20/24] Train loss=0.22555622458457947
Test set avg_accuracy=83.79% avg_sensitivity=63.93%, avg_specificity=91.37% avg_auc=88.75%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.257131 Test loss=0.385648 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.2448423057794571
[5/24] Train loss=0.241977259516716
[10/24] Train loss=0.2838587462902069
[15/24] Train loss=0.22909830510616302
[20/24] Train loss=0.2298303097486496
Test set avg_accuracy=83.84% avg_sensitivity=63.84%, avg_specificity=91.47% avg_auc=88.75%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.256947 Test loss=0.385886 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.2409733235836029
[5/24] Train loss=0.24123482406139374
[10/24] Train loss=0.274867981672287
[15/24] Train loss=0.22314192354679108
[20/24] Train loss=0.22871094942092896
Test set avg_accuracy=83.89% avg_sensitivity=63.74%, avg_specificity=91.58% avg_auc=88.72%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.255278 Test loss=0.386620 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.24186834692955017
[5/24] Train loss=0.2400730848312378
[10/24] Train loss=0.2770764231681824
[15/24] Train loss=0.224318265914917
[20/24] Train loss=0.2302609235048294
Test set avg_accuracy=83.95% avg_sensitivity=63.70%, avg_specificity=91.67% avg_auc=88.71%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.254784 Test loss=0.386934 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.24350181221961975
[5/24] Train loss=0.23816749453544617
[10/24] Train loss=0.2775523364543915
[15/24] Train loss=0.2253917157649994
[20/24] Train loss=0.2259664386510849
Test set avg_accuracy=84.02% avg_sensitivity=63.41%, avg_specificity=91.89% avg_auc=88.71%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.255304 Test loss=0.387026 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.2402966320514679
[5/24] Train loss=0.23812764883041382
[10/24] Train loss=0.27969473600387573
[15/24] Train loss=0.22530420124530792
[20/24] Train loss=0.22865891456604004
Test set avg_accuracy=84.02% avg_sensitivity=63.70%, avg_specificity=91.78% avg_auc=88.72%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.256179 Test loss=0.386874 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.2447982281446457
[5/24] Train loss=0.2467060536146164
[10/24] Train loss=0.2789384424686432
[15/24] Train loss=0.22491468489170074
[20/24] Train loss=0.23107650876045227
Test set avg_accuracy=83.97% avg_sensitivity=63.18%, avg_specificity=91.91% avg_auc=88.71%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.256553 Test loss=0.387055 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.25014302134513855
[5/24] Train loss=0.2462354302406311
[10/24] Train loss=0.2781009078025818
[15/24] Train loss=0.2230665683746338
[20/24] Train loss=0.22708939015865326
Test set avg_accuracy=84.02% avg_sensitivity=63.41%, avg_specificity=91.89% avg_auc=88.70%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.256535 Test loss=0.387056 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.24147385358810425
[5/24] Train loss=0.23750440776348114
[10/24] Train loss=0.2774781882762909
[15/24] Train loss=0.22437605261802673
[20/24] Train loss=0.2280646413564682
Test set avg_accuracy=84.01% avg_sensitivity=63.18%, avg_specificity=91.96% avg_auc=88.69%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.255926 Test loss=0.387372 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.2490728497505188
[5/24] Train loss=0.2406802922487259
[10/24] Train loss=0.28227129578590393
[15/24] Train loss=0.2221449613571167
[20/24] Train loss=0.2311236709356308
Test set avg_accuracy=84.04% avg_sensitivity=63.27%, avg_specificity=91.96% avg_auc=88.69%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.255057 Test loss=0.387333 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.24548549950122833
[5/24] Train loss=0.2394176870584488
[10/24] Train loss=0.28119081258773804
[15/24] Train loss=0.21956950426101685
[20/24] Train loss=0.2256922721862793
Test set avg_accuracy=83.95% avg_sensitivity=63.27%, avg_specificity=91.83% avg_auc=88.69%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.255448 Test loss=0.387330 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.24126717448234558
[5/24] Train loss=0.24439553916454315
[10/24] Train loss=0.27643856406211853
[15/24] Train loss=0.2215094268321991
[20/24] Train loss=0.23198364675045013
Test set avg_accuracy=83.96% avg_sensitivity=63.27%, avg_specificity=91.85% avg_auc=88.69%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.255715 Test loss=0.387380 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.24280741810798645
[5/24] Train loss=0.24150091409683228
[10/24] Train loss=0.279282808303833
[15/24] Train loss=0.22282108664512634
[20/24] Train loss=0.22669242322444916
Test set avg_accuracy=83.97% avg_sensitivity=63.08%, avg_specificity=91.94% avg_auc=88.69%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.255272 Test loss=0.387433 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.24389179050922394
[5/24] Train loss=0.2397211343050003
[10/24] Train loss=0.27733734250068665
[15/24] Train loss=0.22917862236499786
[20/24] Train loss=0.2266928106546402
Test set avg_accuracy=83.97% avg_sensitivity=63.08%, avg_specificity=91.94% avg_auc=88.68%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.255872 Test loss=0.387461 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.2458985149860382
[5/24] Train loss=0.2422296553850174
[10/24] Train loss=0.27439722418785095
[15/24] Train loss=0.22552332282066345
[20/24] Train loss=0.22563490271568298
Test set avg_accuracy=83.97% avg_sensitivity=63.08%, avg_specificity=91.94% avg_auc=88.68%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.255192 Test loss=0.387479 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.2430935651063919
[5/24] Train loss=0.24206270277500153
[10/24] Train loss=0.2835412621498108
[15/24] Train loss=0.22465276718139648
[20/24] Train loss=0.2300657331943512
Test set avg_accuracy=83.97% avg_sensitivity=63.08%, avg_specificity=91.94% avg_auc=88.68%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.255150 Test loss=0.387480 Current lr=[4.388541022775342e-09]

Fold[7] Result: acc=85.09% sen=70.25%, spe=90.75%, auc=90.29%!
Fold[7] Avg_jsc=0.59%(±0.28629261860403515)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.6959312558174133
[5/24] Train loss=0.6857287287712097
[10/24] Train loss=0.6780406832695007
[15/24] Train loss=0.6665554642677307
[20/24] Train loss=0.6512118577957153
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.56%
Best model saved!! Metric=50.56489233396499!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.673721 Test loss=0.646914 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6497021317481995
[5/24] Train loss=0.6293102502822876
[10/24] Train loss=0.6260620355606079
[15/24] Train loss=0.6052060127258301
[20/24] Train loss=0.5792222619056702
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.83%
Best model saved!! Metric=50.832819955898934!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.617475 Test loss=0.585325 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.5936583280563354
[5/24] Train loss=0.5646487474441528
[10/24] Train loss=0.5843150019645691
[15/24] Train loss=0.5665430426597595
[20/24] Train loss=0.5423244833946228
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.70%
Best model saved!! Metric=57.69518919328416!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.574668 Test loss=0.565597 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.5789492726325989
[5/24] Train loss=0.5467984676361084
[10/24] Train loss=0.572086751461029
[15/24] Train loss=0.5531935095787048
[20/24] Train loss=0.5280926823616028
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.61%
Best model saved!! Metric=65.6101360568055!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.560769 Test loss=0.552952 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5645259022712708
[5/24] Train loss=0.5357721447944641
[10/24] Train loss=0.558207631111145
[15/24] Train loss=0.5362381935119629
[20/24] Train loss=0.5054011940956116
Test set avg_accuracy=74.86% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=72.23%
Best model saved!! Metric=72.22741279662353!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.546541 Test loss=0.534279 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5469341278076172
[5/24] Train loss=0.5143540501594543
[10/24] Train loss=0.5419996380805969
[15/24] Train loss=0.5088242292404175
[20/24] Train loss=0.47151175141334534
Test set avg_accuracy=73.98% avg_sensitivity=3.73%, avg_specificity=97.58% avg_auc=74.01%
Best model saved!! Metric=74.01390771673168!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.526184 Test loss=0.512448 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5222676396369934
[5/24] Train loss=0.4918763041496277
[10/24] Train loss=0.5287860631942749
[15/24] Train loss=0.4823532998561859
[20/24] Train loss=0.44069069623947144
Test set avg_accuracy=74.64% avg_sensitivity=9.79%, avg_specificity=96.42% avg_auc=75.11%
Best model saved!! Metric=75.11232223846554!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.506398 Test loss=0.496015 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.49872252345085144
[5/24] Train loss=0.480665922164917
[10/24] Train loss=0.514145016670227
[15/24] Train loss=0.4717632830142975
[20/24] Train loss=0.427927166223526
Test set avg_accuracy=75.26% avg_sensitivity=8.44%, avg_specificity=97.70% avg_auc=76.30%
Best model saved!! Metric=76.29754626454749!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.492976 Test loss=0.486584 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.4827229976654053
[5/24] Train loss=0.4705198407173157
[10/24] Train loss=0.4995892345905304
[15/24] Train loss=0.4604525864124298
[20/24] Train loss=0.4159061908721924
Test set avg_accuracy=75.31% avg_sensitivity=7.35%, avg_specificity=98.14% avg_auc=77.50%
Best model saved!! Metric=77.50235805312865!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.480431 Test loss=0.475991 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.46717798709869385
[5/24] Train loss=0.4560738503932953
[10/24] Train loss=0.486073762178421
[15/24] Train loss=0.440613329410553
[20/24] Train loss=0.4071759879589081
Test set avg_accuracy=75.68% avg_sensitivity=10.67%, avg_specificity=97.51% avg_auc=78.95%
Best model saved!! Metric=78.95380720074795!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.465958 Test loss=0.461871 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.44865432381629944
[5/24] Train loss=0.43831464648246765
[10/24] Train loss=0.46811050176620483
[15/24] Train loss=0.41861066222190857
[20/24] Train loss=0.3869485855102539
Test set avg_accuracy=75.49% avg_sensitivity=26.62%, avg_specificity=91.91% avg_auc=80.93%
Best model saved!! Metric=80.92563595370964!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.448328 Test loss=0.444823 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.4268711507320404
[5/24] Train loss=0.42491090297698975
[10/24] Train loss=0.4479431211948395
[15/24] Train loss=0.3948362469673157
[20/24] Train loss=0.37174031138420105
Test set avg_accuracy=77.33% avg_sensitivity=44.90%, avg_specificity=88.22% avg_auc=83.44%
Best model saved!! Metric=83.44117487300383!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.431362 Test loss=0.425898 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.41070762276649475
[5/24] Train loss=0.4030866324901581
[10/24] Train loss=0.4273511469364166
[15/24] Train loss=0.37562039494514465
[20/24] Train loss=0.3506309688091278
Test set avg_accuracy=79.08% avg_sensitivity=56.50%, avg_specificity=86.66% avg_auc=85.03%
Best model saved!! Metric=85.02804036169034!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.414654 Test loss=0.409684 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.3946183919906616
[5/24] Train loss=0.39314088225364685
[10/24] Train loss=0.4163079559803009
[15/24] Train loss=0.365883469581604
[20/24] Train loss=0.34573420882225037
Test set avg_accuracy=80.61% avg_sensitivity=60.18%, avg_specificity=87.48% avg_auc=85.64%
Best model saved!! Metric=85.63685540429925!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.405022 Test loss=0.401817 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.38819631934165955
[5/24] Train loss=0.381986141204834
[10/24] Train loss=0.40686482191085815
[15/24] Train loss=0.3575190007686615
[20/24] Train loss=0.3374675512313843
Test set avg_accuracy=81.33% avg_sensitivity=61.32%, avg_specificity=88.05% avg_auc=86.11%
Best model saved!! Metric=86.10568257699828!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.397783 Test loss=0.395465 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.37981271743774414
[5/24] Train loss=0.37786585092544556
[10/24] Train loss=0.4016224443912506
[15/24] Train loss=0.35095733404159546
[20/24] Train loss=0.33088958263397217
Test set avg_accuracy=81.93% avg_sensitivity=60.18%, avg_specificity=89.23% avg_auc=86.46%
Best model saved!! Metric=86.45583466252975!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.392203 Test loss=0.389273 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.37536385655403137
[5/24] Train loss=0.3708798289299011
[10/24] Train loss=0.39720553159713745
[15/24] Train loss=0.347027987241745
[20/24] Train loss=0.322335809469223
Test set avg_accuracy=82.25% avg_sensitivity=55.72%, avg_specificity=91.16% avg_auc=86.93%
Best model saved!! Metric=86.92972429672547!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.386989 Test loss=0.381567 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.37090861797332764
[5/24] Train loss=0.3667527735233307
[10/24] Train loss=0.3961840271949768
[15/24] Train loss=0.3490813970565796
[20/24] Train loss=0.31750357151031494
Test set avg_accuracy=83.09% avg_sensitivity=53.86%, avg_specificity=92.90% avg_auc=87.18%
Best model saved!! Metric=87.17737955282612!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.383363 Test loss=0.378479 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.37044408917427063
[5/24] Train loss=0.3587629199028015
[10/24] Train loss=0.3906957507133484
[15/24] Train loss=0.34511667490005493
[20/24] Train loss=0.3142634332180023
Test set avg_accuracy=82.76% avg_sensitivity=47.33%, avg_specificity=94.66% avg_auc=87.28%
Best model saved!! Metric=87.27915124319911!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.377826 Test loss=0.376719 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.3705874979496002
[5/24] Train loss=0.3519788980484009
[10/24] Train loss=0.3783799707889557
[15/24] Train loss=0.33800208568573
[20/24] Train loss=0.31216204166412354
Test set avg_accuracy=82.79% avg_sensitivity=47.38%, avg_specificity=94.68% avg_auc=87.61%
Best model saved!! Metric=87.61482306742109!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.371741 Test loss=0.372770 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.3656073808670044
[5/24] Train loss=0.3448503017425537
[10/24] Train loss=0.3748883008956909
[15/24] Train loss=0.32874560356140137
[20/24] Train loss=0.3120850920677185
Test set avg_accuracy=83.05% avg_sensitivity=45.31%, avg_specificity=95.72% avg_auc=87.81%
Best model saved!! Metric=87.80744882657638!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.367162 Test loss=0.371174 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.36559006571769714
[5/24] Train loss=0.33945852518081665
[10/24] Train loss=0.3733535408973694
[15/24] Train loss=0.3285662531852722
[20/24] Train loss=0.30412834882736206
Test set avg_accuracy=82.59% avg_sensitivity=41.07%, avg_specificity=96.54% avg_auc=87.91%
Best model saved!! Metric=87.91425595463025!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.363228 Test loss=0.374081 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.3650346100330353
[5/24] Train loss=0.33884716033935547
[10/24] Train loss=0.3687121868133545
[15/24] Train loss=0.32920151948928833
[20/24] Train loss=0.30258363485336304
Test set avg_accuracy=82.92% avg_sensitivity=42.78%, avg_specificity=96.40% avg_auc=88.32%
Best model saved!! Metric=88.32060406515657!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.359317 Test loss=0.369452 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.3612390160560608
[5/24] Train loss=0.3356875777244568
[10/24] Train loss=0.3669624328613281
[15/24] Train loss=0.32399803400039673
[20/24] Train loss=0.3012647032737732
Test set avg_accuracy=82.80% avg_sensitivity=41.79%, avg_specificity=96.57% avg_auc=88.32%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.356225 Test loss=0.372269 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.3613000810146332
[5/24] Train loss=0.33601921796798706
[10/24] Train loss=0.36823493242263794
[15/24] Train loss=0.3220149874687195
[20/24] Train loss=0.29666703939437866
Test set avg_accuracy=83.33% avg_sensitivity=44.48%, avg_specificity=96.38% avg_auc=88.62%
Best model saved!! Metric=88.62470306456376!!
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.354894 Test loss=0.366414 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.3572017252445221
[5/24] Train loss=0.3383358120918274
[10/24] Train loss=0.36646679043769836
[15/24] Train loss=0.3176698386669159
[20/24] Train loss=0.2938234806060791
Test set avg_accuracy=82.92% avg_sensitivity=40.65%, avg_specificity=97.11% avg_auc=88.78%
Best model saved!! Metric=88.77618056016588!!
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.353986 Test loss=0.369387 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.35849717259407043
[5/24] Train loss=0.33149778842926025
[10/24] Train loss=0.35890382528305054
[15/24] Train loss=0.31684890389442444
[20/24] Train loss=0.294220894575119
Test set avg_accuracy=82.57% avg_sensitivity=38.84%, avg_specificity=97.25% avg_auc=88.85%
Best model saved!! Metric=88.84872148976172!!
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.351004 Test loss=0.374425 Current lr=[0.000669125424222739]

[0/24] Train loss=0.3589220643043518
[5/24] Train loss=0.3321689963340759
[10/24] Train loss=0.36093589663505554
[15/24] Train loss=0.3135431408882141
[20/24] Train loss=0.29688721895217896
Test set avg_accuracy=83.50% avg_sensitivity=44.90%, avg_specificity=96.47% avg_auc=89.11%
Best model saved!! Metric=89.1117983367562!!
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.350688 Test loss=0.362034 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.34690406918525696
[5/24] Train loss=0.3217499554157257
[10/24] Train loss=0.3564494848251343
[15/24] Train loss=0.31443318724632263
[20/24] Train loss=0.2920212149620056
Test set avg_accuracy=83.58% avg_sensitivity=44.90%, avg_specificity=96.57% avg_auc=89.25%
Best model saved!! Metric=89.25455614778748!!
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.346160 Test loss=0.361034 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.3475131094455719
[5/24] Train loss=0.3232230544090271
[10/24] Train loss=0.3535696566104889
[15/24] Train loss=0.3110957741737366
[20/24] Train loss=0.2889668345451355
Test set avg_accuracy=82.83% avg_sensitivity=40.65%, avg_specificity=96.99% avg_auc=89.43%
Best model saved!! Metric=89.43006682359096!!
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.344856 Test loss=0.363346 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.34912899136543274
[5/24] Train loss=0.3179212808609009
[10/24] Train loss=0.3525392711162567
[15/24] Train loss=0.30758729577064514
[20/24] Train loss=0.28969770669937134
Test set avg_accuracy=83.42% avg_sensitivity=43.09%, avg_specificity=96.97% avg_auc=89.60%
Best model saved!! Metric=89.60271297491767!!
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.343003 Test loss=0.358504 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.3423595726490021
[5/24] Train loss=0.3195224106311798
[10/24] Train loss=0.3487175405025482
[15/24] Train loss=0.3072952330112457
[20/24] Train loss=0.2909390926361084
Test set avg_accuracy=83.37% avg_sensitivity=42.15%, avg_specificity=97.22% avg_auc=89.70%
Best model saved!! Metric=89.7029307958811!!
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.341947 Test loss=0.360341 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.3425108790397644
[5/24] Train loss=0.31407707929611206
[10/24] Train loss=0.34460070729255676
[15/24] Train loss=0.30590686202049255
[20/24] Train loss=0.28878504037857056
Test set avg_accuracy=83.59% avg_sensitivity=44.07%, avg_specificity=96.87% avg_auc=89.87%
Best model saved!! Metric=89.87485180815!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.340479 Test loss=0.353379 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.3383622169494629
[5/24] Train loss=0.31493502855300903
[10/24] Train loss=0.34674081206321716
[15/24] Train loss=0.3051730990409851
[20/24] Train loss=0.28927910327911377
Test set avg_accuracy=84.02% avg_sensitivity=44.38%, avg_specificity=97.34% avg_auc=89.95%
Best model saved!! Metric=89.94687027730669!!
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.337619 Test loss=0.352396 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.3394332528114319
[5/24] Train loss=0.31261950731277466
[10/24] Train loss=0.34190306067466736
[15/24] Train loss=0.3058127760887146
[20/24] Train loss=0.28550606966018677
Test set avg_accuracy=84.39% avg_sensitivity=45.68%, avg_specificity=97.39% avg_auc=89.99%
Best model saved!! Metric=89.98976608094948!!
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.336593 Test loss=0.350595 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.3401462137699127
[5/24] Train loss=0.31573769450187683
[10/24] Train loss=0.34011441469192505
[15/24] Train loss=0.30469509959220886
[20/24] Train loss=0.28564003109931946
Test set avg_accuracy=84.30% avg_sensitivity=45.57%, avg_specificity=97.30% avg_auc=90.14%
Best model saved!! Metric=90.14385587874739!!
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.335006 Test loss=0.350945 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.3394036889076233
[5/24] Train loss=0.3093852698802948
[10/24] Train loss=0.3406580090522766
[15/24] Train loss=0.3055478632450104
[20/24] Train loss=0.2849436402320862
Test set avg_accuracy=84.57% avg_sensitivity=46.66%, avg_specificity=97.30% avg_auc=90.19%
Best model saved!! Metric=90.1859229520384!!
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.334374 Test loss=0.346430 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.3328084349632263
[5/24] Train loss=0.3092797100543976
[10/24] Train loss=0.34068140387535095
[15/24] Train loss=0.30506160855293274
[20/24] Train loss=0.28956785798072815
Test set avg_accuracy=84.70% avg_sensitivity=47.90%, avg_specificity=97.06% avg_auc=90.37%
Best model saved!! Metric=90.37052263789556!!
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.332575 Test loss=0.342923 Current lr=[0.000944367614404117]

[0/24] Train loss=0.3335115611553192
[5/24] Train loss=0.31442299485206604
[10/24] Train loss=0.3395563066005707
[15/24] Train loss=0.3025467097759247
[20/24] Train loss=0.2881522476673126
Test set avg_accuracy=84.75% avg_sensitivity=48.58%, avg_specificity=96.90% avg_auc=90.36%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.331302 Test loss=0.340073 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.3263240456581116
[5/24] Train loss=0.3120492994785309
[10/24] Train loss=0.33764365315437317
[15/24] Train loss=0.30456361174583435
[20/24] Train loss=0.2884659469127655
Test set avg_accuracy=85.10% avg_sensitivity=49.97%, avg_specificity=96.90% avg_auc=90.40%
Best model saved!! Metric=90.39958224783918!!
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.329739 Test loss=0.340117 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.32626014947891235
[5/24] Train loss=0.30735400319099426
[10/24] Train loss=0.3323178291320801
[15/24] Train loss=0.3036549985408783
[20/24] Train loss=0.28451165556907654
Test set avg_accuracy=84.70% avg_sensitivity=49.66%, avg_specificity=96.47% avg_auc=90.52%
Best model saved!! Metric=90.5180006087565!!
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.328411 Test loss=0.339203 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.32773357629776
[5/24] Train loss=0.3100028932094574
[10/24] Train loss=0.33632054924964905
[15/24] Train loss=0.3071266710758209
[20/24] Train loss=0.2865963578224182
Test set avg_accuracy=84.51% avg_sensitivity=47.90%, avg_specificity=96.80% avg_auc=90.37%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.330145 Test loss=0.345297 Current lr=[0.000989780311725182]

[0/24] Train loss=0.3287879228591919
[5/24] Train loss=0.3065459728240967
[10/24] Train loss=0.34067410230636597
[15/24] Train loss=0.3068355619907379
[20/24] Train loss=0.2859176695346832
Test set avg_accuracy=84.30% avg_sensitivity=47.44%, avg_specificity=96.68% avg_auc=90.54%
Best model saved!! Metric=90.53609755741637!!
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.330116 Test loss=0.343250 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.33639177680015564
[5/24] Train loss=0.3094927668571472
[10/24] Train loss=0.3396145701408386
[15/24] Train loss=0.3050737679004669
[20/24] Train loss=0.2845877408981323
Test set avg_accuracy=84.31% avg_sensitivity=48.47%, avg_specificity=96.35% avg_auc=90.60%
Best model saved!! Metric=90.6025266006679!!
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.329821 Test loss=0.338415 Current lr=[0.000998924125869967]

[0/24] Train loss=0.32521262764930725
[5/24] Train loss=0.3073776364326477
[10/24] Train loss=0.3348938822746277
[15/24] Train loss=0.3075038194656372
[20/24] Train loss=0.286899596452713
Test set avg_accuracy=84.57% avg_sensitivity=49.61%, avg_specificity=96.31% avg_auc=90.62%
Best model saved!! Metric=90.6194840450941!!
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.329266 Test loss=0.337854 Current lr=[0.000999999611458977]

[0/24] Train loss=0.325900137424469
[5/24] Train loss=0.30778375267982483
[10/24] Train loss=0.3333251476287842
[15/24] Train loss=0.3030513823032379
[20/24] Train loss=0.2861942946910858
Test set avg_accuracy=85.23% avg_sensitivity=53.55%, avg_specificity=95.88% avg_auc=90.77%
Best model saved!! Metric=90.77333062854964!!
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.328153 Test loss=0.330698 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.3202267289161682
[5/24] Train loss=0.30512550473213196
[10/24] Train loss=0.33331847190856934
[15/24] Train loss=0.3065815269947052
[20/24] Train loss=0.2849713861942291
Test set avg_accuracy=85.27% avg_sensitivity=53.39%, avg_specificity=95.98% avg_auc=90.80%
Best model saved!! Metric=90.79564329247722!!
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.326790 Test loss=0.330496 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.31775596737861633
[5/24] Train loss=0.3013196587562561
[10/24] Train loss=0.3347994089126587
[15/24] Train loss=0.30100950598716736
[20/24] Train loss=0.2813148498535156
Test set avg_accuracy=85.20% avg_sensitivity=52.62%, avg_specificity=96.14% avg_auc=90.83%
Best model saved!! Metric=90.82716206966036!!
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.325916 Test loss=0.331864 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3170877695083618
[5/24] Train loss=0.3015895485877991
[10/24] Train loss=0.3313738703727722
[15/24] Train loss=0.30409368872642517
[20/24] Train loss=0.285498708486557
Test set avg_accuracy=85.42% avg_sensitivity=54.01%, avg_specificity=95.96% avg_auc=90.74%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.325305 Test loss=0.331207 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.31611767411231995
[5/24] Train loss=0.3030994236469269
[10/24] Train loss=0.3300955593585968
[15/24] Train loss=0.30368703603744507
[20/24] Train loss=0.28284257650375366
Test set avg_accuracy=85.38% avg_sensitivity=54.53%, avg_specificity=95.74% avg_auc=90.72%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.326195 Test loss=0.331012 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.3156956434249878
[5/24] Train loss=0.30018407106399536
[10/24] Train loss=0.33416682481765747
[15/24] Train loss=0.30386611819267273
[20/24] Train loss=0.28612110018730164
Test set avg_accuracy=85.65% avg_sensitivity=56.03%, avg_specificity=95.60% avg_auc=90.67%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.325780 Test loss=0.329552 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.3155505061149597
[5/24] Train loss=0.3048444092273712
[10/24] Train loss=0.3299448788166046
[15/24] Train loss=0.30326831340789795
[20/24] Train loss=0.28315111994743347
Test set avg_accuracy=85.55% avg_sensitivity=55.46%, avg_specificity=95.65% avg_auc=90.62%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.325018 Test loss=0.330650 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.3134300708770752
[5/24] Train loss=0.29957714676856995
[10/24] Train loss=0.33037495613098145
[15/24] Train loss=0.3032190501689911
[20/24] Train loss=0.28624778985977173
Test set avg_accuracy=85.65% avg_sensitivity=56.34%, avg_specificity=95.49% avg_auc=90.55%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.324976 Test loss=0.331408 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.31378549337387085
[5/24] Train loss=0.2999526262283325
[10/24] Train loss=0.3265151381492615
[15/24] Train loss=0.3009447455406189
[20/24] Train loss=0.2845268249511719
Test set avg_accuracy=85.61% avg_sensitivity=57.02%, avg_specificity=95.22% avg_auc=90.52%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.323977 Test loss=0.331256 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.3094627857208252
[5/24] Train loss=0.30002889037132263
[10/24] Train loss=0.3287723958492279
[15/24] Train loss=0.2992327809333801
[20/24] Train loss=0.2818012237548828
Test set avg_accuracy=85.64% avg_sensitivity=57.28%, avg_specificity=95.16% avg_auc=90.44%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.322947 Test loss=0.331562 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.3063594698905945
[5/24] Train loss=0.3001787066459656
[10/24] Train loss=0.3299356997013092
[15/24] Train loss=0.2991882860660553
[20/24] Train loss=0.27856892347335815
Test set avg_accuracy=85.59% avg_sensitivity=56.76%, avg_specificity=95.27% avg_auc=90.44%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.322468 Test loss=0.332300 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.3084527850151062
[5/24] Train loss=0.29758742451667786
[10/24] Train loss=0.32774603366851807
[15/24] Train loss=0.2989736795425415
[20/24] Train loss=0.2828369140625
Test set avg_accuracy=85.42% avg_sensitivity=56.03%, avg_specificity=95.29% avg_auc=90.43%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.322314 Test loss=0.332897 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.30873963236808777
[5/24] Train loss=0.29629456996917725
[10/24] Train loss=0.32513564825057983
[15/24] Train loss=0.299342542886734
[20/24] Train loss=0.2819986939430237
Test set avg_accuracy=85.47% avg_sensitivity=58.62%, avg_specificity=94.49% avg_auc=90.32%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.322050 Test loss=0.332482 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.3051983118057251
[5/24] Train loss=0.29951897263526917
[10/24] Train loss=0.3272327780723572
[15/24] Train loss=0.2985377907752991
[20/24] Train loss=0.2838519513607025
Test set avg_accuracy=85.34% avg_sensitivity=58.00%, avg_specificity=94.52% avg_auc=90.36%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.320835 Test loss=0.332067 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.30811887979507446
[5/24] Train loss=0.2984846234321594
[10/24] Train loss=0.32880640029907227
[15/24] Train loss=0.30209147930145264
[20/24] Train loss=0.27964332699775696
Test set avg_accuracy=85.05% avg_sensitivity=56.50%, avg_specificity=94.64% avg_auc=90.28%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.321826 Test loss=0.334914 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.3093753457069397
[5/24] Train loss=0.2996751368045807
[10/24] Train loss=0.32713478803634644
[15/24] Train loss=0.3024428188800812
[20/24] Train loss=0.27890872955322266
Test set avg_accuracy=85.10% avg_sensitivity=54.63%, avg_specificity=95.34% avg_auc=90.12%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.320533 Test loss=0.339212 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.3054178059101105
[5/24] Train loss=0.2948782742023468
[10/24] Train loss=0.32760709524154663
[15/24] Train loss=0.29810628294944763
[20/24] Train loss=0.27784642577171326
Test set avg_accuracy=85.25% avg_sensitivity=56.55%, avg_specificity=94.89% avg_auc=90.23%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.320765 Test loss=0.337073 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.30554309487342834
[5/24] Train loss=0.29829058051109314
[10/24] Train loss=0.32466554641723633
[15/24] Train loss=0.29819223284721375
[20/24] Train loss=0.2761293649673462
Test set avg_accuracy=85.01% avg_sensitivity=56.08%, avg_specificity=94.73% avg_auc=90.16%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.319553 Test loss=0.338518 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.31025025248527527
[5/24] Train loss=0.2964080274105072
[10/24] Train loss=0.3226499855518341
[15/24] Train loss=0.2981272041797638
[20/24] Train loss=0.2737211287021637
Test set avg_accuracy=85.27% avg_sensitivity=55.20%, avg_specificity=95.37% avg_auc=90.02%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.318662 Test loss=0.340641 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.30306240916252136
[5/24] Train loss=0.29381564259529114
[10/24] Train loss=0.32873252034187317
[15/24] Train loss=0.29801830649375916
[20/24] Train loss=0.27842003107070923
Test set avg_accuracy=85.40% avg_sensitivity=56.19%, avg_specificity=95.22% avg_auc=89.99%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.318623 Test loss=0.340021 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.30385687947273254
[5/24] Train loss=0.2950371503829956
[10/24] Train loss=0.3294825553894043
[15/24] Train loss=0.29759466648101807
[20/24] Train loss=0.28171291947364807
Test set avg_accuracy=85.26% avg_sensitivity=58.00%, avg_specificity=94.42% avg_auc=90.05%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.319009 Test loss=0.338454 Current lr=[0.000904142181093812]

[0/24] Train loss=0.30094802379608154
[5/24] Train loss=0.2872546911239624
[10/24] Train loss=0.32928699254989624
[15/24] Train loss=0.2974754869937897
[20/24] Train loss=0.2772873640060425
Test set avg_accuracy=85.23% avg_sensitivity=57.53%, avg_specificity=94.54% avg_auc=90.06%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.316774 Test loss=0.338841 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.3012487292289734
[5/24] Train loss=0.28893986344337463
[10/24] Train loss=0.32670772075653076
[15/24] Train loss=0.2963612675666809
[20/24] Train loss=0.2776102125644684
Test set avg_accuracy=85.17% avg_sensitivity=57.22%, avg_specificity=94.56% avg_auc=89.92%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.316113 Test loss=0.339991 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.2946050763130188
[5/24] Train loss=0.29100486636161804
[10/24] Train loss=0.32407960295677185
[15/24] Train loss=0.29610100388526917
[20/24] Train loss=0.27898547053337097
Test set avg_accuracy=84.93% avg_sensitivity=57.59%, avg_specificity=94.12% avg_auc=89.84%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.316144 Test loss=0.340886 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.301503986120224
[5/24] Train loss=0.2893403470516205
[10/24] Train loss=0.32594457268714905
[15/24] Train loss=0.29856303334236145
[20/24] Train loss=0.2752429246902466
Test set avg_accuracy=84.36% avg_sensitivity=56.14%, avg_specificity=93.84% avg_auc=89.76%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.315561 Test loss=0.342963 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.2956758439540863
[5/24] Train loss=0.2852526307106018
[10/24] Train loss=0.33069688081741333
[15/24] Train loss=0.2929787337779999
[20/24] Train loss=0.27575820684432983
Test set avg_accuracy=84.70% avg_sensitivity=54.95%, avg_specificity=94.69% avg_auc=89.70%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.314201 Test loss=0.344300 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.3038080334663391
[5/24] Train loss=0.28878992795944214
[10/24] Train loss=0.3266492486000061
[15/24] Train loss=0.2958388924598694
[20/24] Train loss=0.27175775170326233
Test set avg_accuracy=84.64% avg_sensitivity=54.01%, avg_specificity=94.92% avg_auc=89.56%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.313954 Test loss=0.348404 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.2972938120365143
[5/24] Train loss=0.2883455753326416
[10/24] Train loss=0.3244766592979431
[15/24] Train loss=0.2966778576374054
[20/24] Train loss=0.27592045068740845
Test set avg_accuracy=84.65% avg_sensitivity=58.16%, avg_specificity=93.55% avg_auc=89.64%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.313450 Test loss=0.342837 Current lr=[0.000834102481048427]

[0/24] Train loss=0.2968479096889496
[5/24] Train loss=0.2857213616371155
[10/24] Train loss=0.3248043954372406
[15/24] Train loss=0.29348164796829224
[20/24] Train loss=0.27592700719833374
Test set avg_accuracy=84.65% avg_sensitivity=55.41%, avg_specificity=94.47% avg_auc=89.72%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.312087 Test loss=0.344573 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.29936090111732483
[5/24] Train loss=0.2842865586280823
[10/24] Train loss=0.3222534954547882
[15/24] Train loss=0.29687684774398804
[20/24] Train loss=0.2763001620769501
Test set avg_accuracy=85.36% avg_sensitivity=58.57%, avg_specificity=94.36% avg_auc=89.74%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.312524 Test loss=0.342056 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.2991672158241272
[5/24] Train loss=0.28455081582069397
[10/24] Train loss=0.32158151268959045
[15/24] Train loss=0.29898369312286377
[20/24] Train loss=0.2718910276889801
Test set avg_accuracy=84.95% avg_sensitivity=57.95%, avg_specificity=94.02% avg_auc=89.57%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.311557 Test loss=0.344955 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.2963463068008423
[5/24] Train loss=0.28115272521972656
[10/24] Train loss=0.31784787774086
[15/24] Train loss=0.2950091063976288
[20/24] Train loss=0.27606284618377686
Test set avg_accuracy=84.96% avg_sensitivity=58.73%, avg_specificity=93.77% avg_auc=89.58%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.310466 Test loss=0.343379 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.2934277355670929
[5/24] Train loss=0.28204119205474854
[10/24] Train loss=0.3183543086051941
[15/24] Train loss=0.288062185049057
[20/24] Train loss=0.2706461548805237
Test set avg_accuracy=84.92% avg_sensitivity=58.36%, avg_specificity=93.84% avg_auc=89.54%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.309465 Test loss=0.344491 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.2928270399570465
[5/24] Train loss=0.27921196818351746
[10/24] Train loss=0.3216600716114044
[15/24] Train loss=0.2923610508441925
[20/24] Train loss=0.2725740075111389
Test set avg_accuracy=84.82% avg_sensitivity=59.45%, avg_specificity=93.34% avg_auc=89.34%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.308651 Test loss=0.346926 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.2943994998931885
[5/24] Train loss=0.2795739769935608
[10/24] Train loss=0.3170263469219208
[15/24] Train loss=0.2875775098800659
[20/24] Train loss=0.2676633298397064
Test set avg_accuracy=84.82% avg_sensitivity=58.57%, avg_specificity=93.63% avg_auc=89.43%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.306737 Test loss=0.347067 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.296280175447464
[5/24] Train loss=0.2744271159172058
[10/24] Train loss=0.3217560350894928
[15/24] Train loss=0.2890247702598572
[20/24] Train loss=0.2717262804508209
Test set avg_accuracy=85.12% avg_sensitivity=58.36%, avg_specificity=94.10% avg_auc=89.37%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.306487 Test loss=0.348089 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.29896268248558044
[5/24] Train loss=0.27567973732948303
[10/24] Train loss=0.3211384117603302
[15/24] Train loss=0.29047274589538574
[20/24] Train loss=0.27390068769454956
Test set avg_accuracy=84.80% avg_sensitivity=60.07%, avg_specificity=93.11% avg_auc=89.48%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.306972 Test loss=0.343976 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.29296594858169556
[5/24] Train loss=0.27568379044532776
[10/24] Train loss=0.3229086101055145
[15/24] Train loss=0.2909170985221863
[20/24] Train loss=0.269940584897995
Test set avg_accuracy=84.86% avg_sensitivity=59.61%, avg_specificity=93.34% avg_auc=89.45%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.306204 Test loss=0.344566 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.2922438383102417
[5/24] Train loss=0.2740090489387512
[10/24] Train loss=0.320659875869751
[15/24] Train loss=0.2821717858314514
[20/24] Train loss=0.27168309688568115
Test set avg_accuracy=85.04% avg_sensitivity=59.45%, avg_specificity=93.63% avg_auc=89.25%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.304733 Test loss=0.348017 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.29126206040382385
[5/24] Train loss=0.27067068219184875
[10/24] Train loss=0.322083055973053
[15/24] Train loss=0.2851354777812958
[20/24] Train loss=0.2677893340587616
Test set avg_accuracy=85.21% avg_sensitivity=57.69%, avg_specificity=94.45% avg_auc=89.26%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.303984 Test loss=0.350035 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.29396700859069824
[5/24] Train loss=0.2735252380371094
[10/24] Train loss=0.3219483494758606
[15/24] Train loss=0.2875972390174866
[20/24] Train loss=0.2717840373516083
Test set avg_accuracy=84.93% avg_sensitivity=57.48%, avg_specificity=94.16% avg_auc=89.32%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.304170 Test loss=0.347510 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.2979729473590851
[5/24] Train loss=0.2701154351234436
[10/24] Train loss=0.3193660378456116
[15/24] Train loss=0.2882704436779022
[20/24] Train loss=0.26821714639663696
Test set avg_accuracy=85.27% avg_sensitivity=59.04%, avg_specificity=94.09% avg_auc=89.21%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.304060 Test loss=0.348890 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.2944805324077606
[5/24] Train loss=0.27148953080177307
[10/24] Train loss=0.3214893043041229
[15/24] Train loss=0.28377699851989746
[20/24] Train loss=0.26431483030319214
Test set avg_accuracy=85.46% avg_sensitivity=61.21%, avg_specificity=93.60% avg_auc=89.31%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.303810 Test loss=0.346738 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.2948916256427765
[5/24] Train loss=0.26896142959594727
[10/24] Train loss=0.3207745850086212
[15/24] Train loss=0.28591981530189514
[20/24] Train loss=0.2699021100997925
Test set avg_accuracy=85.55% avg_sensitivity=63.34%, avg_specificity=93.01% avg_auc=89.33%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.303904 Test loss=0.347038 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.2864176034927368
[5/24] Train loss=0.26622647047042847
[10/24] Train loss=0.32382822036743164
[15/24] Train loss=0.2914930582046509
[20/24] Train loss=0.2770766615867615
Test set avg_accuracy=85.08% avg_sensitivity=69.34%, avg_specificity=90.36% avg_auc=89.45%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.305020 Test loss=0.350682 Current lr=[0.00061065423442182]

[0/24] Train loss=0.29164278507232666
[5/24] Train loss=0.267507940530777
[10/24] Train loss=0.3173166513442993
[15/24] Train loss=0.2891444265842438
[20/24] Train loss=0.2783125638961792
Test set avg_accuracy=85.18% avg_sensitivity=70.69%, avg_specificity=90.05% avg_auc=89.47%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.307003 Test loss=0.350422 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.28670328855514526
[5/24] Train loss=0.27800750732421875
[10/24] Train loss=0.33143991231918335
[15/24] Train loss=0.2817578911781311
[20/24] Train loss=0.2671876549720764
Test set avg_accuracy=85.56% avg_sensitivity=63.59%, avg_specificity=92.94% avg_auc=89.39%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.304189 Test loss=0.343660 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.28713637590408325
[5/24] Train loss=0.2695342004299164
[10/24] Train loss=0.3247971832752228
[15/24] Train loss=0.2779565453529358
[20/24] Train loss=0.2681995630264282
Test set avg_accuracy=85.56% avg_sensitivity=64.94%, avg_specificity=92.49% avg_auc=89.32%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.299520 Test loss=0.346162 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.2888369858264923
[5/24] Train loss=0.2641720175743103
[10/24] Train loss=0.31984955072402954
[15/24] Train loss=0.27411964535713196
[20/24] Train loss=0.2694990038871765
Test set avg_accuracy=85.13% avg_sensitivity=65.92%, avg_specificity=91.58% avg_auc=89.37%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.298496 Test loss=0.346255 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.29080310463905334
[5/24] Train loss=0.26911652088165283
[10/24] Train loss=0.3167301416397095
[15/24] Train loss=0.2784793972969055
[20/24] Train loss=0.2648479640483856
Test set avg_accuracy=85.48% avg_sensitivity=64.99%, avg_specificity=92.36% avg_auc=89.32%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.299402 Test loss=0.346558 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.29219046235084534
[5/24] Train loss=0.26486390829086304
[10/24] Train loss=0.3221190869808197
[15/24] Train loss=0.27591004967689514
[20/24] Train loss=0.2684856057167053
Test set avg_accuracy=85.47% avg_sensitivity=61.94%, avg_specificity=93.37% avg_auc=89.45%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.299148 Test loss=0.343675 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.2907865643501282
[5/24] Train loss=0.2627565860748291
[10/24] Train loss=0.3168676495552063
[15/24] Train loss=0.2759842574596405
[20/24] Train loss=0.263715922832489
Test set avg_accuracy=85.53% avg_sensitivity=64.37%, avg_specificity=92.64% avg_auc=89.36%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.297753 Test loss=0.346345 Current lr=[0.000506858408304961]

[0/24] Train loss=0.2858262360095978
[5/24] Train loss=0.26567983627319336
[10/24] Train loss=0.3167795240879059
[15/24] Train loss=0.2724592387676239
[20/24] Train loss=0.2608433663845062
Test set avg_accuracy=85.53% avg_sensitivity=63.70%, avg_specificity=92.87% avg_auc=89.39%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.297686 Test loss=0.346734 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.28482210636138916
[5/24] Train loss=0.2686771750450134
[10/24] Train loss=0.3151341378688812
[15/24] Train loss=0.2707687020301819
[20/24] Train loss=0.2605628967285156
Test set avg_accuracy=85.47% avg_sensitivity=62.77%, avg_specificity=93.09% avg_auc=89.18%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.295775 Test loss=0.350541 Current lr=[0.000476946990416354]

[0/24] Train loss=0.2824346721172333
[5/24] Train loss=0.26177161931991577
[10/24] Train loss=0.31069284677505493
[15/24] Train loss=0.2730342745780945
[20/24] Train loss=0.2651593089103699
Test set avg_accuracy=85.51% avg_sensitivity=63.49%, avg_specificity=92.90% avg_auc=89.25%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.297142 Test loss=0.349403 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.28401675820350647
[5/24] Train loss=0.26214513182640076
[10/24] Train loss=0.31828171014785767
[15/24] Train loss=0.27255237102508545
[20/24] Train loss=0.2608250081539154
Test set avg_accuracy=85.35% avg_sensitivity=63.08%, avg_specificity=92.83% avg_auc=88.99%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.296432 Test loss=0.354232 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.2862221300601959
[5/24] Train loss=0.2629847228527069
[10/24] Train loss=0.319589763879776
[15/24] Train loss=0.27224692702293396
[20/24] Train loss=0.2611698806285858
Test set avg_accuracy=85.59% avg_sensitivity=63.90%, avg_specificity=92.87% avg_auc=89.05%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.295954 Test loss=0.352278 Current lr=[0.000432267999769856]

[0/24] Train loss=0.2806010842323303
[5/24] Train loss=0.25994133949279785
[10/24] Train loss=0.3164444863796234
[15/24] Train loss=0.27540042996406555
[20/24] Train loss=0.26265206933021545
Test set avg_accuracy=85.44% avg_sensitivity=64.32%, avg_specificity=92.54% avg_auc=89.15%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.296549 Test loss=0.351360 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.2860342860221863
[5/24] Train loss=0.2637294828891754
[10/24] Train loss=0.3178670108318329
[15/24] Train loss=0.2794651687145233
[20/24] Train loss=0.2652810215950012
Test set avg_accuracy=85.48% avg_sensitivity=67.58%, avg_specificity=91.49% avg_auc=89.28%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.297970 Test loss=0.351186 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.28525352478027344
[5/24] Train loss=0.26142191886901855
[10/24] Train loss=0.3250811994075775
[15/24] Train loss=0.27423131465911865
[20/24] Train loss=0.25573718547821045
Test set avg_accuracy=84.61% avg_sensitivity=70.22%, avg_specificity=89.44% avg_auc=89.25%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.298499 Test loss=0.355905 Current lr=[0.000388134363466264]

[0/24] Train loss=0.28785720467567444
[5/24] Train loss=0.2743488550186157
[10/24] Train loss=0.3327251374721527
[15/24] Train loss=0.27434611320495605
[20/24] Train loss=0.2622426748275757
Test set avg_accuracy=84.26% avg_sensitivity=74.37%, avg_specificity=87.58% avg_auc=89.38%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.301236 Test loss=0.362246 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.29015275835990906
[5/24] Train loss=0.2753896117210388
[10/24] Train loss=0.32148319482803345
[15/24] Train loss=0.27903711795806885
[20/24] Train loss=0.2760055661201477
Test set avg_accuracy=84.64% avg_sensitivity=71.57%, avg_specificity=89.02% avg_auc=89.36%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.299976 Test loss=0.354454 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.2849148213863373
[5/24] Train loss=0.2603399455547333
[10/24] Train loss=0.3111880123615265
[15/24] Train loss=0.2781359553337097
[20/24] Train loss=0.270199716091156
Test set avg_accuracy=85.43% avg_sensitivity=66.86%, avg_specificity=91.67% avg_auc=89.12%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.295686 Test loss=0.352976 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.28548356890678406
[5/24] Train loss=0.26306572556495667
[10/24] Train loss=0.3048878610134125
[15/24] Train loss=0.2729848325252533
[20/24] Train loss=0.2632611095905304
Test set avg_accuracy=85.18% avg_sensitivity=66.80%, avg_specificity=91.36% avg_auc=89.05%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.292554 Test loss=0.354780 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.27980586886405945
[5/24] Train loss=0.25646206736564636
[10/24] Train loss=0.30801525712013245
[15/24] Train loss=0.2755775451660156
[20/24] Train loss=0.26075485348701477
Test set avg_accuracy=85.01% avg_sensitivity=67.06%, avg_specificity=91.04% avg_auc=88.96%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.291134 Test loss=0.356906 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.2822670340538025
[5/24] Train loss=0.25708645582199097
[10/24] Train loss=0.307434618473053
[15/24] Train loss=0.2712777554988861
[20/24] Train loss=0.2666385769844055
Test set avg_accuracy=85.43% avg_sensitivity=66.44%, avg_specificity=91.81% avg_auc=88.97%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.291846 Test loss=0.355868 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.2814123332500458
[5/24] Train loss=0.25826889276504517
[10/24] Train loss=0.30507785081863403
[15/24] Train loss=0.27652016282081604
[20/24] Train loss=0.2639017701148987
Test set avg_accuracy=85.20% avg_sensitivity=66.29%, avg_specificity=91.55% avg_auc=88.88%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.290386 Test loss=0.357609 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.28399285674095154
[5/24] Train loss=0.25541749596595764
[10/24] Train loss=0.3090812563896179
[15/24] Train loss=0.26976102590560913
[20/24] Train loss=0.26211830973625183
Test set avg_accuracy=85.23% avg_sensitivity=66.55%, avg_specificity=91.51% avg_auc=88.84%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.289723 Test loss=0.357955 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.2789478302001953
[5/24] Train loss=0.2557480037212372
[10/24] Train loss=0.3034183084964752
[15/24] Train loss=0.2763630747795105
[20/24] Train loss=0.2617335915565491
Test set avg_accuracy=85.20% avg_sensitivity=65.82%, avg_specificity=91.70% avg_auc=88.83%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.289159 Test loss=0.357771 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.2804042398929596
[5/24] Train loss=0.2544967532157898
[10/24] Train loss=0.30931001901626587
[15/24] Train loss=0.2696361541748047
[20/24] Train loss=0.256002813577652
Test set avg_accuracy=85.23% avg_sensitivity=66.44%, avg_specificity=91.55% avg_auc=88.86%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.288393 Test loss=0.357460 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.2788024842739105
[5/24] Train loss=0.24969708919525146
[10/24] Train loss=0.3084871172904968
[15/24] Train loss=0.2697887420654297
[20/24] Train loss=0.25832897424697876
Test set avg_accuracy=85.36% avg_sensitivity=64.68%, avg_specificity=92.31% avg_auc=88.87%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.286881 Test loss=0.356213 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.27640044689178467
[5/24] Train loss=0.25068578124046326
[10/24] Train loss=0.3054414987564087
[15/24] Train loss=0.2708142399787903
[20/24] Train loss=0.25717848539352417
Test set avg_accuracy=85.14% avg_sensitivity=64.27%, avg_specificity=92.16% avg_auc=88.82%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.286518 Test loss=0.357301 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.2767004072666168
[5/24] Train loss=0.2532171308994293
[10/24] Train loss=0.30577483773231506
[15/24] Train loss=0.2687189280986786
[20/24] Train loss=0.25771066546440125
Test set avg_accuracy=85.31% avg_sensitivity=65.15%, avg_specificity=92.09% avg_auc=88.85%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.285133 Test loss=0.357199 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.2762477695941925
[5/24] Train loss=0.2504667341709137
[10/24] Train loss=0.31064164638519287
[15/24] Train loss=0.2693046033382416
[20/24] Train loss=0.261506050825119
Test set avg_accuracy=85.12% avg_sensitivity=63.85%, avg_specificity=92.26% avg_auc=88.83%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.286419 Test loss=0.357224 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.2771969437599182
[5/24] Train loss=0.2464931309223175
[10/24] Train loss=0.30650290846824646
[15/24] Train loss=0.2667497396469116
[20/24] Train loss=0.25851428508758545
Test set avg_accuracy=85.23% avg_sensitivity=63.44%, avg_specificity=92.56% avg_auc=88.84%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.285550 Test loss=0.357001 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2779432535171509
[5/24] Train loss=0.25119879841804504
[10/24] Train loss=0.3058927655220032
[15/24] Train loss=0.27130040526390076
[20/24] Train loss=0.25313830375671387
Test set avg_accuracy=85.30% avg_sensitivity=63.54%, avg_specificity=92.61% avg_auc=88.83%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.285320 Test loss=0.356501 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.27629661560058594
[5/24] Train loss=0.2536082863807678
[10/24] Train loss=0.3022744059562683
[15/24] Train loss=0.2684115767478943
[20/24] Train loss=0.25798678398132324
Test set avg_accuracy=85.39% avg_sensitivity=63.34%, avg_specificity=92.80% avg_auc=88.83%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.284852 Test loss=0.356858 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.2740125060081482
[5/24] Train loss=0.2570329010486603
[10/24] Train loss=0.30550867319107056
[15/24] Train loss=0.2685982882976532
[20/24] Train loss=0.2587054669857025
Test set avg_accuracy=85.64% avg_sensitivity=63.65%, avg_specificity=93.02% avg_auc=88.82%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.284258 Test loss=0.356884 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.2746427357196808
[5/24] Train loss=0.24908724427223206
[10/24] Train loss=0.30874890089035034
[15/24] Train loss=0.27121299505233765
[20/24] Train loss=0.24970681965351105
Test set avg_accuracy=85.55% avg_sensitivity=62.30%, avg_specificity=93.36% avg_auc=88.87%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.285142 Test loss=0.356094 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.27600836753845215
[5/24] Train loss=0.2529132664203644
[10/24] Train loss=0.305881142616272
[15/24] Train loss=0.2707827389240265
[20/24] Train loss=0.2505119740962982
Test set avg_accuracy=85.49% avg_sensitivity=62.09%, avg_specificity=93.36% avg_auc=88.83%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.284650 Test loss=0.356619 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.27750322222709656
[5/24] Train loss=0.2535347640514374
[10/24] Train loss=0.2971205413341522
[15/24] Train loss=0.27113524079322815
[20/24] Train loss=0.25458183884620667
Test set avg_accuracy=85.49% avg_sensitivity=63.08%, avg_specificity=93.02% avg_auc=88.82%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.284870 Test loss=0.357182 Current lr=[0.000123057953306828]

[0/24] Train loss=0.2727384567260742
[5/24] Train loss=0.25451624393463135
[10/24] Train loss=0.3051791787147522
[15/24] Train loss=0.2715560495853424
[20/24] Train loss=0.25244173407554626
Test set avg_accuracy=85.33% avg_sensitivity=64.06%, avg_specificity=92.47% avg_auc=88.88%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.285828 Test loss=0.356269 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.27750393748283386
[5/24] Train loss=0.2556583285331726
[10/24] Train loss=0.3047756850719452
[15/24] Train loss=0.270503431558609
[20/24] Train loss=0.2525900602340698
Test set avg_accuracy=85.16% avg_sensitivity=67.69%, avg_specificity=91.02% avg_auc=88.92%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.287569 Test loss=0.357503 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.27629390358924866
[5/24] Train loss=0.2569888234138489
[10/24] Train loss=0.30263787508010864
[15/24] Train loss=0.26736629009246826
[20/24] Train loss=0.2553974986076355
Test set avg_accuracy=84.17% avg_sensitivity=70.53%, avg_specificity=88.75% avg_auc=88.94%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.288302 Test loss=0.363143 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.275271475315094
[5/24] Train loss=0.252009779214859
[10/24] Train loss=0.3098493814468384
[15/24] Train loss=0.27066466212272644
[20/24] Train loss=0.252422034740448
Test set avg_accuracy=83.72% avg_sensitivity=71.88%, avg_specificity=87.70% avg_auc=88.91%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.288064 Test loss=0.368674 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.285757839679718
[5/24] Train loss=0.2505588233470917
[10/24] Train loss=0.3091590404510498
[15/24] Train loss=0.2748621702194214
[20/24] Train loss=0.25504380464553833
Test set avg_accuracy=84.09% avg_sensitivity=70.22%, avg_specificity=88.75% avg_auc=88.90%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.287096 Test loss=0.363954 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.2788057327270508
[5/24] Train loss=0.25137072801589966
[10/24] Train loss=0.2976197302341461
[15/24] Train loss=0.2704983949661255
[20/24] Train loss=0.25408005714416504
Test set avg_accuracy=84.79% avg_sensitivity=68.88%, avg_specificity=90.14% avg_auc=88.87%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.285319 Test loss=0.359665 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.27724000811576843
[5/24] Train loss=0.25317618250846863
[10/24] Train loss=0.3020969033241272
[15/24] Train loss=0.2634272277355194
[20/24] Train loss=0.250154972076416
Test set avg_accuracy=84.66% avg_sensitivity=68.62%, avg_specificity=90.05% avg_auc=88.83%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.283589 Test loss=0.360800 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.275107741355896
[5/24] Train loss=0.25114691257476807
[10/24] Train loss=0.3076575994491577
[15/24] Train loss=0.2700059413909912
[20/24] Train loss=0.2515094578266144
Test set avg_accuracy=84.77% avg_sensitivity=69.03%, avg_specificity=90.05% avg_auc=88.82%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.283222 Test loss=0.361120 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.2717205286026001
[5/24] Train loss=0.24805794656276703
[10/24] Train loss=0.2979477643966675
[15/24] Train loss=0.2690553069114685
[20/24] Train loss=0.24928341805934906
Test set avg_accuracy=84.71% avg_sensitivity=68.41%, avg_specificity=90.19% avg_auc=88.80%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.282644 Test loss=0.360814 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.27904224395751953
[5/24] Train loss=0.2503106892108917
[10/24] Train loss=0.30217477679252625
[15/24] Train loss=0.2617534101009369
[20/24] Train loss=0.2518080770969391
Test set avg_accuracy=84.83% avg_sensitivity=67.89%, avg_specificity=90.52% avg_auc=88.79%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.282630 Test loss=0.360608 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.27466753125190735
[5/24] Train loss=0.245814710855484
[10/24] Train loss=0.29914361238479614
[15/24] Train loss=0.2670314610004425
[20/24] Train loss=0.25289276242256165
Test set avg_accuracy=84.84% avg_sensitivity=68.20%, avg_specificity=90.43% avg_auc=88.78%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.282747 Test loss=0.361160 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.27182886004447937
[5/24] Train loss=0.2503579556941986
[10/24] Train loss=0.3021947741508484
[15/24] Train loss=0.26354309916496277
[20/24] Train loss=0.2542187571525574
Test set avg_accuracy=84.82% avg_sensitivity=67.69%, avg_specificity=90.57% avg_auc=88.78%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.281588 Test loss=0.361067 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.2770145535469055
[5/24] Train loss=0.24750281870365143
[10/24] Train loss=0.3051496744155884
[15/24] Train loss=0.2646530866622925
[20/24] Train loss=0.2531231641769409
Test set avg_accuracy=84.90% avg_sensitivity=67.94%, avg_specificity=90.59% avg_auc=88.78%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.282312 Test loss=0.360982 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.2758384943008423
[5/24] Train loss=0.2509375214576721
[10/24] Train loss=0.2952060103416443
[15/24] Train loss=0.2659194767475128
[20/24] Train loss=0.25114190578460693
Test set avg_accuracy=84.91% avg_sensitivity=67.89%, avg_specificity=90.62% avg_auc=88.78%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.281533 Test loss=0.360688 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.2755090594291687
[5/24] Train loss=0.24872323870658875
[10/24] Train loss=0.3013850450515747
[15/24] Train loss=0.2642766237258911
[20/24] Train loss=0.24542532861232758
Test set avg_accuracy=84.93% avg_sensitivity=68.00%, avg_specificity=90.62% avg_auc=88.78%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.282050 Test loss=0.360914 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.2747848629951477
[5/24] Train loss=0.25227612257003784
[10/24] Train loss=0.30033010244369507
[15/24] Train loss=0.26996320486068726
[20/24] Train loss=0.2517974078655243
Test set avg_accuracy=84.93% avg_sensitivity=67.94%, avg_specificity=90.64% avg_auc=88.77%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.282618 Test loss=0.360748 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.27683353424072266
[5/24] Train loss=0.2505802512168884
[10/24] Train loss=0.29715806245803833
[15/24] Train loss=0.2592979073524475
[20/24] Train loss=0.2493620067834854
Test set avg_accuracy=84.93% avg_sensitivity=67.94%, avg_specificity=90.64% avg_auc=88.77%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.281503 Test loss=0.360801 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.27293699979782104
[5/24] Train loss=0.24567973613739014
[10/24] Train loss=0.29999595880508423
[15/24] Train loss=0.26495423913002014
[20/24] Train loss=0.25213634967803955
Test set avg_accuracy=84.93% avg_sensitivity=67.84%, avg_specificity=90.68% avg_auc=88.77%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.281784 Test loss=0.360759 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.26975899934768677
[5/24] Train loss=0.24872083961963654
[10/24] Train loss=0.29093214869499207
[15/24] Train loss=0.2625173330307007
[20/24] Train loss=0.25094497203826904
Test set avg_accuracy=84.95% avg_sensitivity=67.84%, avg_specificity=90.69% avg_auc=88.77%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.280007 Test loss=0.360701 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.27303943037986755
[5/24] Train loss=0.24937547743320465
[10/24] Train loss=0.29446664452552795
[15/24] Train loss=0.2647148370742798
[20/24] Train loss=0.255331814289093
Test set avg_accuracy=84.95% avg_sensitivity=67.84%, avg_specificity=90.69% avg_auc=88.77%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.281793 Test loss=0.360683 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.2766077220439911
[5/24] Train loss=0.24355918169021606
[10/24] Train loss=0.3024066388607025
[15/24] Train loss=0.26415371894836426
[20/24] Train loss=0.2524031698703766
Test set avg_accuracy=84.95% avg_sensitivity=67.84%, avg_specificity=90.69% avg_auc=88.77%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.281980 Test loss=0.360664 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.2763321101665497
[5/24] Train loss=0.24669399857521057
[10/24] Train loss=0.2992536127567291
[15/24] Train loss=0.265341579914093
[20/24] Train loss=0.250972181558609
Test set avg_accuracy=84.95% avg_sensitivity=67.84%, avg_specificity=90.69% avg_auc=88.77%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.281687 Test loss=0.360632 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.2745165526866913
[5/24] Train loss=0.24995093047618866
[10/24] Train loss=0.29622703790664673
[15/24] Train loss=0.2653046250343323
[20/24] Train loss=0.24996019899845123
Test set avg_accuracy=84.95% avg_sensitivity=67.84%, avg_specificity=90.69% avg_auc=88.77%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.281624 Test loss=0.360623 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.27395692467689514
[5/24] Train loss=0.24402295053005219
[10/24] Train loss=0.3018682897090912
[15/24] Train loss=0.2680729925632477
[20/24] Train loss=0.256464421749115
Test set avg_accuracy=84.95% avg_sensitivity=67.84%, avg_specificity=90.69% avg_auc=88.77%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.281983 Test loss=0.360618 Current lr=[4.388541022775342e-09]

Fold[8] Result: acc=85.20% sen=52.62%, spe=96.14%, auc=90.83%!
Fold[8] Avg_jsc=0.53%(±0.2988940227585911)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/23] Train loss=0.6942799091339111
[5/23] Train loss=0.6867955327033997
[10/23] Train loss=0.6799892783164978
[15/23] Train loss=0.671546459197998
[20/23] Train loss=0.6633132100105286
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.31%
Best model saved!! Metric=51.30594727161251!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.678528 Test loss=0.657341 Current lr=[4.117151766482193e-05]

[0/23] Train loss=0.6591545343399048
[5/23] Train loss=0.6467903256416321
[10/23] Train loss=0.6377413272857666
[15/23] Train loss=0.6204015612602234
[20/23] Train loss=0.6057807207107544
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=50.79%
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.635361 Test loss=0.596088 Current lr=[4.4680352102458476e-05]

[0/23] Train loss=0.6015345454216003
[5/23] Train loss=0.5811417102813721
[10/23] Train loss=0.5793602466583252
[15/23] Train loss=0.560773491859436
[20/23] Train loss=0.557242751121521
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.24%
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.584324 Test loss=0.554882 Current lr=[5.0509375556548764e-05]

[0/23] Train loss=0.5662620663642883
[5/23] Train loss=0.5529887080192566
[10/23] Train loss=0.5682520270347595
[15/23] Train loss=0.5525147914886475
[20/23] Train loss=0.5539238452911377
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.74%
Best model saved!! Metric=52.739335747255424!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.572846 Test loss=0.553332 Current lr=[5.863013467732154e-05]

[0/23] Train loss=0.5646451711654663
[5/23] Train loss=0.5540234446525574
[10/23] Train loss=0.5673972368240356
[15/23] Train loss=0.5554620027542114
[20/23] Train loss=0.5560208559036255
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.17%
Best model saved!! Metric=54.17348773180015!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.571341 Test loss=0.554386 Current lr=[6.900298941160253e-05]

[0/23] Train loss=0.5649464130401611
[5/23] Train loss=0.5526593923568726
[10/23] Train loss=0.5655975341796875
[15/23] Train loss=0.5521235466003418
[20/23] Train loss=0.5530483722686768
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=55.47%
Best model saved!! Metric=55.47400252189305!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.570169 Test loss=0.551950 Current lr=[8.157730649874272e-05]

[0/23] Train loss=0.5628746151924133
[5/23] Train loss=0.5512358546257019
[10/23] Train loss=0.5650042295455933
[15/23] Train loss=0.5521888732910156
[20/23] Train loss=0.553232729434967
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.15%
Best model saved!! Metric=57.14508751431578!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.569305 Test loss=0.552095 Current lr=[9.629170662794775e-05]

[0/23] Train loss=0.5625817775726318
[5/23] Train loss=0.5507462620735168
[10/23] Train loss=0.5639747381210327
[15/23] Train loss=0.5505604147911072
[20/23] Train loss=0.5514918565750122
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.45%
Best model saved!! Metric=58.45298751778629!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.568334 Test loss=0.550536 Current lr=[0.00011307436405055631]

[0/23] Train loss=0.561339795589447
[5/23] Train loss=0.5493243932723999
[10/23] Train loss=0.5626200437545776
[15/23] Train loss=0.5495185852050781
[20/23] Train loss=0.5503684282302856
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.74%
Best model saved!! Metric=60.73826683479287!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.567042 Test loss=0.549345 Current lr=[0.00013184335718476351]

[0/23] Train loss=0.5600419044494629
[5/23] Train loss=0.5477300882339478
[10/23] Train loss=0.5604466199874878
[15/23] Train loss=0.5471522808074951
[20/23] Train loss=0.5478426218032837
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=63.16%
Best model saved!! Metric=63.16375415013361!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.565016 Test loss=0.547010 Current lr=[0.00015250706850137067]

[0/23] Train loss=0.5578187108039856
[5/23] Train loss=0.5449581146240234
[10/23] Train loss=0.5564273595809937
[15/23] Train loss=0.5429502725601196
[20/23] Train loss=0.5422723293304443
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=67.28%
Best model saved!! Metric=67.28490681720902!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.561122 Test loss=0.541616 Current lr=[0.00017496463173859395]

[0/23] Train loss=0.552795946598053
[5/23] Train loss=0.538425624370575
[10/23] Train loss=0.5470930933952332
[15/23] Train loss=0.5329808592796326
[20/23] Train loss=0.5256779789924622
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=71.57%
Best model saved!! Metric=71.57290700230209!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.551659 Test loss=0.527032 Current lr=[0.00019910642426292774]

[0/23] Train loss=0.5389362573623657
[5/23] Train loss=0.5219413638114929
[10/23] Train loss=0.531629204750061
[15/23] Train loss=0.4966421127319336
[20/23] Train loss=0.49001815915107727
Test set avg_accuracy=75.33% avg_sensitivity=7.39%, avg_specificity=96.96% avg_auc=73.50%
Best model saved!! Metric=73.49972120356767!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.528059 Test loss=0.501295 Current lr=[0.00022481460217269435]

[0/23] Train loss=0.5127233862876892
[5/23] Train loss=0.5014142990112305
[10/23] Train loss=0.5204824805259705
[15/23] Train loss=0.4784541726112366
[20/23] Train loss=0.470602810382843
Test set avg_accuracy=75.07% avg_sensitivity=19.89%, avg_specificity=92.64% avg_auc=75.29%
Best model saved!! Metric=75.28684103976029!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.508514 Test loss=0.497273 Current lr=[0.00025196367553226176]

[0/23] Train loss=0.5044626593589783
[5/23] Train loss=0.4966791868209839
[10/23] Train loss=0.5050870776176453
[15/23] Train loss=0.4621348977088928
[20/23] Train loss=0.46273112297058105
Test set avg_accuracy=75.00% avg_sensitivity=23.13%, avg_specificity=91.52% avg_auc=76.53%
Best model saved!! Metric=76.52500260287127!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.495823 Test loss=0.484901 Current lr=[0.0002804211209290286]

[0/23] Train loss=0.490368515253067
[5/23] Train loss=0.48275429010391235
[10/23] Train loss=0.4911209046840668
[15/23] Train loss=0.4524775445461273
[20/23] Train loss=0.4456935524940491
Test set avg_accuracy=76.22% avg_sensitivity=29.16%, avg_specificity=91.21% avg_auc=77.77%
Best model saved!! Metric=77.77392270050785!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.482372 Test loss=0.474377 Current lr=[0.00031004802836308656]

[0/23] Train loss=0.47847962379455566
[5/23] Train loss=0.4734898507595062
[10/23] Train loss=0.4857614040374756
[15/23] Train loss=0.43999528884887695
[20/23] Train loss=0.42753419280052185
Test set avg_accuracy=77.58% avg_sensitivity=31.64%, avg_specificity=92.21% avg_auc=79.01%
Best model saved!! Metric=79.01149659313074!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.471547 Test loss=0.461292 Current lr=[0.0003406997793118814]

[0/23] Train loss=0.4631660580635071
[5/23] Train loss=0.46735477447509766
[10/23] Train loss=0.47409993410110474
[15/23] Train loss=0.43243497610092163
[20/23] Train loss=0.4141838550567627
Test set avg_accuracy=78.06% avg_sensitivity=28.79%, avg_specificity=93.75% avg_auc=80.46%
Best model saved!! Metric=80.45938248325486!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.460312 Test loss=0.443942 Current lr=[0.00037222675266002016]

[0/23] Train loss=0.44131502509117126
[5/23] Train loss=0.44805970788002014
[10/23] Train loss=0.45275717973709106
[15/23] Train loss=0.4078242778778076
[20/23] Train loss=0.39617666602134705
Test set avg_accuracy=78.79% avg_sensitivity=32.45%, avg_specificity=93.55% avg_auc=82.24%
Best model saved!! Metric=82.23640549263676!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.442173 Test loss=0.426512 Current lr=[0.0004044750550483546]

[0/23] Train loss=0.4244559705257416
[5/23] Train loss=0.42931219935417175
[10/23] Train loss=0.42346835136413574
[15/23] Train loss=0.38659408688545227
[20/23] Train loss=0.38343122601509094
Test set avg_accuracy=80.22% avg_sensitivity=47.82%, avg_specificity=90.54% avg_auc=84.10%
Best model saved!! Metric=84.10094050414723!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.420335 Test loss=0.414394 Current lr=[0.00043728727207726563]

[0/23] Train loss=0.4093121290206909
[5/23] Train loss=0.4091982841491699
[10/23] Train loss=0.40220001339912415
[15/23] Train loss=0.3649011254310608
[20/23] Train loss=0.3624187111854553
Test set avg_accuracy=81.51% avg_sensitivity=51.97%, avg_specificity=90.92% avg_auc=85.16%
Best model saved!! Metric=85.16053353076593!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.399721 Test loss=0.404762 Current lr=[0.0004705032366972895]

[0/23] Train loss=0.3935272991657257
[5/23] Train loss=0.3990875482559204
[10/23] Train loss=0.39668217301368713
[15/23] Train loss=0.3470565974712372
[20/23] Train loss=0.34822332859039307
Test set avg_accuracy=81.60% avg_sensitivity=54.18%, avg_specificity=90.33% avg_auc=85.67%
Best model saved!! Metric=85.66896567680435!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.385465 Test loss=0.399883 Current lr=[0.0005039608110363163]

[0/23] Train loss=0.3784957230091095
[5/23] Train loss=0.38610249757766724
[10/23] Train loss=0.38637030124664307
[15/23] Train loss=0.3403676748275757
[20/23] Train loss=0.33193016052246094
Test set avg_accuracy=82.17% avg_sensitivity=57.74%, avg_specificity=89.96% avg_auc=86.12%
Best model saved!! Metric=86.12090279143482!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.373601 Test loss=0.396239 Current lr=[0.0005374966778470111]

[0/23] Train loss=0.37147247791290283
[5/23] Train loss=0.38200482726097107
[10/23] Train loss=0.37376919388771057
[15/23] Train loss=0.3290311098098755
[20/23] Train loss=0.3265708088874817
Test set avg_accuracy=82.54% avg_sensitivity=57.95%, avg_specificity=90.37% avg_auc=86.30%
Best model saved!! Metric=86.29509850421665!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.364532 Test loss=0.393142 Current lr=[0.0005709471377111496]

[0/23] Train loss=0.35885944962501526
[5/23] Train loss=0.373079389333725
[10/23] Train loss=0.3723779320716858
[15/23] Train loss=0.32336166501045227
[20/23] Train loss=0.31624671816825867
Test set avg_accuracy=82.21% avg_sensitivity=53.15%, avg_specificity=91.47% avg_auc=86.34%
Best model saved!! Metric=86.34300058998416!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.358005 Test loss=0.389918 Current lr=[0.0006041489081094521]

[0/23] Train loss=0.3458908200263977
[5/23] Train loss=0.37256497144699097
[10/23] Train loss=0.3711903691291809
[15/23] Train loss=0.31359606981277466
[20/23] Train loss=0.31263047456741333
Test set avg_accuracy=82.79% avg_sensitivity=51.00%, avg_specificity=92.91% avg_auc=86.46%
Best model saved!! Metric=86.46483810140786!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.351819 Test loss=0.387975 Current lr=[0.0006369399204563973]

[0/23] Train loss=0.34046676754951477
[5/23] Train loss=0.37377098202705383
[10/23] Train loss=0.3604743182659149
[15/23] Train loss=0.3090347349643707
[20/23] Train loss=0.30681130290031433
Test set avg_accuracy=83.01% avg_sensitivity=49.38%, avg_specificity=93.72% avg_auc=86.63%
Best model saved!! Metric=86.63405018335783!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.347186 Test loss=0.386801 Current lr=[0.000669160111209436]

[0/23] Train loss=0.33535340428352356
[5/23] Train loss=0.36549630761146545
[10/23] Train loss=0.3549789488315582
[15/23] Train loss=0.30110761523246765
[20/23] Train loss=0.30718234181404114
Test set avg_accuracy=83.16% avg_sensitivity=49.22%, avg_specificity=93.97% avg_auc=86.62%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.342599 Test loss=0.388359 Current lr=[0.0007006522031909389]

[0/23] Train loss=0.3374323844909668
[5/23] Train loss=0.3645506501197815
[10/23] Train loss=0.35641005635261536
[15/23] Train loss=0.300104022026062
[20/23] Train loss=0.3043822646141052
Test set avg_accuracy=83.26% avg_sensitivity=47.92%, avg_specificity=94.51% avg_auc=86.85%
Best model saved!! Metric=86.8481288247747!!
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.339621 Test loss=0.386359 Current lr=[0.0007312624733089952]

[0/23] Train loss=0.33036690950393677
[5/23] Train loss=0.3614199459552765
[10/23] Train loss=0.3487381935119629
[15/23] Train loss=0.29539817571640015
[20/23] Train loss=0.2976883351802826
Test set avg_accuracy=83.50% avg_sensitivity=45.98%, avg_specificity=95.45% avg_auc=86.78%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.335892 Test loss=0.390736 Current lr=[0.0007608415029295701]

[0/23] Train loss=0.33534157276153564
[5/23] Train loss=0.3549235463142395
[10/23] Train loss=0.3414631187915802
[15/23] Train loss=0.2929951548576355
[20/23] Train loss=0.29661422967910767
Test set avg_accuracy=83.19% avg_sensitivity=48.57%, avg_specificity=94.21% avg_auc=86.92%
Best model saved!! Metric=86.92402623694227!!
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.333519 Test loss=0.387476 Current lr=[0.0007892449072372111]

[0/23] Train loss=0.33136266469955444
[5/23] Train loss=0.3485303521156311
[10/23] Train loss=0.345121294260025
[15/23] Train loss=0.28826409578323364
[20/23] Train loss=0.2937672436237335
Test set avg_accuracy=83.42% avg_sensitivity=49.11%, avg_specificity=94.35% avg_auc=87.08%
Best model saved!! Metric=87.08380782712308!!
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.329828 Test loss=0.386095 Current lr=[0.000816334040024053]

[0/23] Train loss=0.32706910371780396
[5/23] Train loss=0.33734840154647827
[10/23] Train loss=0.3453836739063263
[15/23] Train loss=0.2853105664253235
[20/23] Train loss=0.2911555767059326
Test set avg_accuracy=83.46% avg_sensitivity=47.65%, avg_specificity=94.87% avg_auc=87.26%
Best model saved!! Metric=87.25523639855165!!
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.327908 Test loss=0.384384 Current lr=[0.0008419766704668272]

[0/23] Train loss=0.3224923312664032
[5/23] Train loss=0.3368842303752899
[10/23] Train loss=0.3411431312561035
[15/23] Train loss=0.2853512465953827
[20/23] Train loss=0.292551189661026
Test set avg_accuracy=83.58% avg_sensitivity=50.84%, avg_specificity=94.01% avg_auc=87.35%
Best model saved!! Metric=87.34994389366403!!
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.327859 Test loss=0.380938 Current lr=[0.0008660476285882998]

[0/23] Train loss=0.3173263669013977
[5/23] Train loss=0.33581721782684326
[10/23] Train loss=0.33736175298690796
[15/23] Train loss=0.2808598279953003
[20/23] Train loss=0.2930747866630554
Test set avg_accuracy=84.00% avg_sensitivity=51.91%, avg_specificity=94.21% avg_auc=87.44%
Best model saved!! Metric=87.4449244010504!!
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.324918 Test loss=0.379252 Current lr=[0.0008884294162524352]

[0/23] Train loss=0.31828370690345764
[5/23] Train loss=0.33313411474227905
[10/23] Train loss=0.3417397439479828
[15/23] Train loss=0.2794336974620819
[20/23] Train loss=0.2868058383464813
Test set avg_accuracy=83.79% avg_sensitivity=48.84%, avg_specificity=94.92% avg_auc=87.30%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.324080 Test loss=0.383877 Current lr=[0.0009090127807108216]

[0/23] Train loss=0.32298949360847473
[5/23] Train loss=0.32943663001060486
[10/23] Train loss=0.3395375609397888
[15/23] Train loss=0.28059473633766174
[20/23] Train loss=0.2864290773868561
Test set avg_accuracy=84.00% avg_sensitivity=50.40%, avg_specificity=94.70% avg_auc=87.59%
Best model saved!! Metric=87.58593755422648!!
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.322200 Test loss=0.379162 Current lr=[0.0009276972479006904]

[0/23] Train loss=0.31790295243263245
[5/23] Train loss=0.334822416305542
[10/23] Train loss=0.33869725465774536
[15/23] Train loss=0.2804291844367981
[20/23] Train loss=0.288036584854126
Test set avg_accuracy=84.11% avg_sensitivity=50.40%, avg_specificity=94.85% avg_auc=87.60%
Best model saved!! Metric=87.59670071607881!!
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.321957 Test loss=0.378968 Current lr=[0.0009443916128913304]

[0/23] Train loss=0.31655624508857727
[5/23] Train loss=0.3242710828781128
[10/23] Train loss=0.3397299647331238
[15/23] Train loss=0.27691659331321716
[20/23] Train loss=0.28515100479125977
Test set avg_accuracy=83.82% avg_sensitivity=49.92%, avg_specificity=94.61% avg_auc=87.64%
Best model saved!! Metric=87.64198373494672!!
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.320398 Test loss=0.378944 Current lr=[0.0009590143850848684]

[0/23] Train loss=0.31153443455696106
[5/23] Train loss=0.32188326120376587
[10/23] Train loss=0.3384009897708893
[15/23] Train loss=0.2790742516517639
[20/23] Train loss=0.290519654750824
Test set avg_accuracy=84.26% avg_sensitivity=53.64%, avg_specificity=94.01% avg_auc=87.81%
Best model saved!! Metric=87.8116307856044!!
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.320308 Test loss=0.373435 Current lr=[0.0009714941859982488]

[0/23] Train loss=0.309695839881897
[5/23] Train loss=0.324246346950531
[10/23] Train loss=0.3365270793437958
[15/23] Train loss=0.27918699383735657
[20/23] Train loss=0.29033443331718445
Test set avg_accuracy=84.36% avg_sensitivity=55.47%, avg_specificity=93.56% avg_auc=87.87%
Best model saved!! Metric=87.86594634614715!!
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.319473 Test loss=0.372441 Current lr=[0.000981770097684707]

[0/23] Train loss=0.3064872920513153
[5/23] Train loss=0.3265373408794403
[10/23] Train loss=0.3347500264644623
[15/23] Train loss=0.2764843702316284
[20/23] Train loss=0.2914847135543823
Test set avg_accuracy=84.34% avg_sensitivity=54.12%, avg_specificity=93.96% avg_auc=87.88%
Best model saved!! Metric=87.87881956896452!!
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.317338 Test loss=0.372538 Current lr=[0.0009897919600939812]

[0/23] Train loss=0.30884918570518494
[5/23] Train loss=0.3234909772872925
[10/23] Train loss=0.3268272876739502
[15/23] Train loss=0.2753674387931824
[20/23] Train loss=0.28678762912750244
Test set avg_accuracy=84.15% avg_sensitivity=52.45%, avg_specificity=94.25% avg_auc=87.92%
Best model saved!! Metric=87.91765209444374!!
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.316306 Test loss=0.373384 Current lr=[0.0009955206159197494]

[0/23] Train loss=0.30843251943588257
[5/23] Train loss=0.3205263316631317
[10/23] Train loss=0.33189108967781067
[15/23] Train loss=0.273275762796402
[20/23] Train loss=0.28604593873023987
Test set avg_accuracy=84.41% avg_sensitivity=53.91%, avg_specificity=94.13% avg_auc=87.97%
Best model saved!! Metric=87.96566523605152!!
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.316465 Test loss=0.372614 Current lr=[0.0009989281017391135]

[0/23] Train loss=0.3057860732078552
[5/23] Train loss=0.3191991448402405
[10/23] Train loss=0.3319929838180542
[15/23] Train loss=0.2743009030818939
[20/23] Train loss=0.2903224527835846
Test set avg_accuracy=84.51% avg_sensitivity=53.75%, avg_specificity=94.30% avg_auc=88.00%
Best model saved!! Metric=88.00061080712146!!
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.315170 Test loss=0.371415 Current lr=[0.000999999576938324]

[0/23] Train loss=0.3030615448951721
[5/23] Train loss=0.3169430196285248
[10/23] Train loss=0.3295053243637085
[15/23] Train loss=0.2747081220149994
[20/23] Train loss=0.28597384691238403
Test set avg_accuracy=84.75% avg_sensitivity=56.17%, avg_specificity=93.85% avg_auc=88.08%
Best model saved!! Metric=88.0779426905591!!
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.314574 Test loss=0.369668 Current lr=[0.0009997563362336467]

[0/23] Train loss=0.3049618899822235
[5/23] Train loss=0.31966596841812134
[10/23] Train loss=0.3236856758594513
[15/23] Train loss=0.274191290140152
[20/23] Train loss=0.28961342573165894
Test set avg_accuracy=84.60% avg_sensitivity=56.55%, avg_specificity=93.53% avg_auc=88.17%
Best model saved!! Metric=88.16715754890507!!
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.315459 Test loss=0.367948 Current lr=[0.0009990657477148147]

[0/23] Train loss=0.30494317412376404
[5/23] Train loss=0.32020673155784607
[10/23] Train loss=0.3272121846675873
[15/23] Train loss=0.2740813195705414
[20/23] Train loss=0.28455474972724915
Test set avg_accuracy=84.56% avg_sensitivity=56.93%, avg_specificity=93.36% avg_auc=88.16%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.314024 Test loss=0.368144 Current lr=[0.0009979284295520807]

[0/23] Train loss=0.30050209164619446
[5/23] Train loss=0.3168424665927887
[10/23] Train loss=0.32016757130622864
[15/23] Train loss=0.2705996632575989
[20/23] Train loss=0.2863142788410187
Test set avg_accuracy=84.79% avg_sensitivity=57.14%, avg_specificity=93.60% avg_auc=88.16%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.312369 Test loss=0.368223 Current lr=[0.0009963453997992307]

[0/23] Train loss=0.3044532239437103
[5/23] Train loss=0.31715691089630127
[10/23] Train loss=0.32633352279663086
[15/23] Train loss=0.2685335874557495
[20/23] Train loss=0.28699496388435364
Test set avg_accuracy=84.70% avg_sensitivity=56.50%, avg_specificity=93.68% avg_auc=88.22%
Best model saved!! Metric=88.22069571856599!!
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.313696 Test loss=0.366629 Current lr=[0.000994318075482288]

[0/23] Train loss=0.30110087990760803
[5/23] Train loss=0.31260085105895996
[10/23] Train loss=0.3252761662006378
[15/23] Train loss=0.27176523208618164
[20/23] Train loss=0.2867136597633362
Test set avg_accuracy=84.87% avg_sensitivity=57.14%, avg_specificity=93.70% avg_auc=88.17%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.311635 Test loss=0.367933 Current lr=[0.000991848271331083]

[0/23] Train loss=0.3009977638721466
[5/23] Train loss=0.31318050622940063
[10/23] Train loss=0.32707661390304565
[15/23] Train loss=0.2709536552429199
[20/23] Train loss=0.28523966670036316
Test set avg_accuracy=84.73% avg_sensitivity=57.57%, avg_specificity=93.37% avg_auc=88.28%
Best model saved!! Metric=88.27628842127183!!
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.311965 Test loss=0.366261 Current lr=[0.000988938198154824]

[0/23] Train loss=0.2983279824256897
[5/23] Train loss=0.31097832322120667
[10/23] Train loss=0.32681772112846375
[15/23] Train loss=0.26913920044898987
[20/23] Train loss=0.28510648012161255
Test set avg_accuracy=84.58% avg_sensitivity=57.30%, avg_specificity=93.27% avg_auc=88.21%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.311080 Test loss=0.366968 Current lr=[0.0009855904608631237]

[0/23] Train loss=0.30060267448425293
[5/23] Train loss=0.315363347530365
[10/23] Train loss=0.3257705867290497
[15/23] Train loss=0.27003905177116394
[20/23] Train loss=0.283782958984375
Test set avg_accuracy=84.70% avg_sensitivity=58.60%, avg_specificity=93.01% avg_auc=88.30%
Best model saved!! Metric=88.2965005842!!
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.311857 Test loss=0.366022 Current lr=[0.0009818080561342518]

[0/23] Train loss=0.2965744733810425
[5/23] Train loss=0.3165988326072693
[10/23] Train loss=0.3276662230491638
[15/23] Train loss=0.273914098739624
[20/23] Train loss=0.28563687205314636
Test set avg_accuracy=84.71% avg_sensitivity=59.41%, avg_specificity=92.77% avg_auc=88.24%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.312572 Test loss=0.366568 Current lr=[0.0009775943697327037]

[0/23] Train loss=0.29693350195884705
[5/23] Train loss=0.31914180517196655
[10/23] Train loss=0.32426881790161133
[15/23] Train loss=0.2709121108055115
[20/23] Train loss=0.28057265281677246
Test set avg_accuracy=84.48% avg_sensitivity=58.33%, avg_specificity=92.81% avg_auc=88.32%
Best model saved!! Metric=88.32153442152631!!
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.311336 Test loss=0.365250 Current lr=[0.0009729531734784804]

[0/23] Train loss=0.2984427213668823
[5/23] Train loss=0.31316983699798584
[10/23] Train loss=0.3202797770500183
[15/23] Train loss=0.2662239074707031
[20/23] Train loss=0.2796095311641693
Test set avg_accuracy=84.61% avg_sensitivity=58.22%, avg_specificity=93.01% avg_auc=88.38%
Best model saved!! Metric=88.37978320974514!!
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.310808 Test loss=0.364390 Current lr=[0.0009678886218708009]

[0/23] Train loss=0.2992810308933258
[5/23] Train loss=0.3099439740180969
[10/23] Train loss=0.31945478916168213
[15/23] Train loss=0.27198073267936707
[20/23] Train loss=0.2822212278842926
Test set avg_accuracy=84.75% avg_sensitivity=56.33%, avg_specificity=93.80% avg_auc=88.34%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.311059 Test loss=0.364967 Current lr=[0.0009624052483692612]

[0/23] Train loss=0.297110378742218
[5/23] Train loss=0.30688172578811646
[10/23] Train loss=0.324381023645401
[15/23] Train loss=0.2687961161136627
[20/23] Train loss=0.2827286124229431
Test set avg_accuracy=84.43% avg_sensitivity=58.22%, avg_specificity=92.77% avg_auc=88.35%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.310549 Test loss=0.364821 Current lr=[0.0009565079613357751]

[0/23] Train loss=0.29754048585891724
[5/23] Train loss=0.30981409549713135
[10/23] Train loss=0.32659709453582764
[15/23] Train loss=0.2679859399795532
[20/23] Train loss=0.27979525923728943
Test set avg_accuracy=84.41% avg_sensitivity=58.33%, avg_specificity=92.72% avg_auc=88.37%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.310141 Test loss=0.365000 Current lr=[0.0009502020396409247]

[0/23] Train loss=0.29679611325263977
[5/23] Train loss=0.30630436539649963
[10/23] Train loss=0.3211992084980011
[15/23] Train loss=0.26821181178092957
[20/23] Train loss=0.28418809175491333
Test set avg_accuracy=84.58% avg_sensitivity=58.06%, avg_specificity=93.03% avg_auc=88.33%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.310101 Test loss=0.365545 Current lr=[0.0009434931279386567]

[0/23] Train loss=0.2961662709712982
[5/23] Train loss=0.3083687722682953
[10/23] Train loss=0.3201819360256195
[15/23] Train loss=0.26752886176109314
[20/23] Train loss=0.28257691860198975
Test set avg_accuracy=85.00% avg_sensitivity=58.92%, avg_specificity=93.30% avg_auc=88.40%
Best model saved!! Metric=88.40444686093726!!
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.309730 Test loss=0.364382 Current lr=[0.0009363872316135528]

[0/23] Train loss=0.29604804515838623
[5/23] Train loss=0.30888909101486206
[10/23] Train loss=0.3212539255619049
[15/23] Train loss=0.26306310296058655
[20/23] Train loss=0.28110092878341675
Test set avg_accuracy=84.60% avg_sensitivity=59.89%, avg_specificity=92.46% avg_auc=88.48%
Best model saved!! Metric=88.4831484330715!!
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.309308 Test loss=0.363396 Current lr=[0.0009288907114051963]

[0/23] Train loss=0.2957339882850647
[5/23] Train loss=0.3089527189731598
[10/23] Train loss=0.31896907091140747
[15/23] Train loss=0.26678648591041565
[20/23] Train loss=0.2833746671676636
Test set avg_accuracy=84.56% avg_sensitivity=59.35%, avg_specificity=92.58% avg_auc=88.46%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.310305 Test loss=0.364021 Current lr=[0.0009210102777144504]

[0/23] Train loss=0.29428189992904663
[5/23] Train loss=0.31259697675704956
[10/23] Train loss=0.3217512369155884
[15/23] Train loss=0.2645440697669983
[20/23] Train loss=0.2832990288734436
Test set avg_accuracy=84.40% avg_sensitivity=60.22%, avg_specificity=92.10% avg_auc=88.47%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.310706 Test loss=0.363647 Current lr=[0.0009127529845967387]

[0/23] Train loss=0.2958369553089142
[5/23] Train loss=0.30775877833366394
[10/23] Train loss=0.3264763653278351
[15/23] Train loss=0.2666858434677124
[20/23] Train loss=0.2837599515914917
Test set avg_accuracy=84.48% avg_sensitivity=63.67%, avg_specificity=91.11% avg_auc=88.59%
Best model saved!! Metric=88.58771676133405!!
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.312307 Test loss=0.364486 Current lr=[0.0009041262234477117]

[0/23] Train loss=0.29835715889930725
[5/23] Train loss=0.3082979619503021
[10/23] Train loss=0.33091381192207336
[15/23] Train loss=0.2730785012245178
[20/23] Train loss=0.2799471318721771
Test set avg_accuracy=83.67% avg_sensitivity=67.17%, avg_specificity=88.93% avg_auc=88.75%
Best model saved!! Metric=88.74960378515323!!
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.314836 Test loss=0.369519 Current lr=[0.0008951377163869459]

[0/23] Train loss=0.301431804895401
[5/23] Train loss=0.30364471673965454
[10/23] Train loss=0.3267034590244293
[15/23] Train loss=0.2755500376224518
[20/23] Train loss=0.2844998240470886
Test set avg_accuracy=83.45% avg_sensitivity=69.00%, avg_specificity=88.05% avg_auc=88.80%
Best model saved!! Metric=88.8024247191791!!
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.314994 Test loss=0.373735 Current lr=[0.0008857955093456007]

[0/23] Train loss=0.306209534406662
[5/23] Train loss=0.30992254614830017
[10/23] Train loss=0.32309505343437195
[15/23] Train loss=0.2733634412288666
[20/23] Train loss=0.289074569940567
Test set avg_accuracy=83.68% avg_sensitivity=67.55%, avg_specificity=88.82% avg_auc=88.73%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.314730 Test loss=0.369625 Current lr=[0.0008761079648642216]

[0/23] Train loss=0.30078473687171936
[5/23] Train loss=0.30328086018562317
[10/23] Train loss=0.3215883672237396
[15/23] Train loss=0.2666705250740051
[20/23] Train loss=0.28267669677734375
Test set avg_accuracy=83.58% avg_sensitivity=67.60%, avg_specificity=88.67% avg_auc=88.72%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.310403 Test loss=0.370619 Current lr=[0.0008660837546071324]

[0/23] Train loss=0.2976771295070648
[5/23] Train loss=0.3018093407154083
[10/23] Train loss=0.31959110498428345
[15/23] Train loss=0.26651185750961304
[20/23] Train loss=0.2807494103908539
Test set avg_accuracy=83.82% avg_sensitivity=67.60%, avg_specificity=88.98% avg_auc=88.80%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.309656 Test loss=0.369496 Current lr=[0.000855731851600122]

[0/23] Train loss=0.29923173785209656
[5/23] Train loss=0.3006596267223358
[10/23] Train loss=0.3224641680717468
[15/23] Train loss=0.2670402228832245
[20/23] Train loss=0.2818664014339447
Test set avg_accuracy=83.72% avg_sensitivity=67.39%, avg_specificity=88.93% avg_auc=88.85%
Best model saved!! Metric=88.84781416656062!!
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.310210 Test loss=0.368320 Current lr=[0.0008450615221983708]

[0/23] Train loss=0.29984545707702637
[5/23] Train loss=0.30004775524139404
[10/23] Train loss=0.3199765086174011
[15/23] Train loss=0.26759931445121765
[20/23] Train loss=0.2833314538002014
Test set avg_accuracy=83.97% avg_sensitivity=67.39%, avg_specificity=89.25% avg_auc=88.80%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.309955 Test loss=0.367827 Current lr=[0.0008340823177918083]

[0/23] Train loss=0.2946522533893585
[5/23] Train loss=0.2978331744670868
[10/23] Train loss=0.32208147644996643
[15/23] Train loss=0.2635730504989624
[20/23] Train loss=0.2785910367965698
Test set avg_accuracy=84.24% avg_sensitivity=67.22%, avg_specificity=89.67% avg_auc=88.76%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.308354 Test loss=0.367025 Current lr=[0.0008228040662553245]

[0/23] Train loss=0.29796507954597473
[5/23] Train loss=0.2959420084953308
[10/23] Train loss=0.3201574981212616
[15/23] Train loss=0.26427173614501953
[20/23] Train loss=0.2802867293357849
Test set avg_accuracy=84.57% avg_sensitivity=66.25%, avg_specificity=90.40% avg_auc=88.71%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.307899 Test loss=0.365631 Current lr=[0.0008112368631514922]

[0/23] Train loss=0.296059250831604
[5/23] Train loss=0.29856613278388977
[10/23] Train loss=0.3218976855278015
[15/23] Train loss=0.262981116771698
[20/23] Train loss=0.27954116463661194
Test set avg_accuracy=84.18% avg_sensitivity=66.79%, avg_specificity=89.72% avg_auc=88.73%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.306906 Test loss=0.366707 Current lr=[0.0007993910626936701]

[0/23] Train loss=0.29494133591651917
[5/23] Train loss=0.301004022359848
[10/23] Train loss=0.3166872262954712
[15/23] Train loss=0.26438793540000916
[20/23] Train loss=0.2798479497432709
Test set avg_accuracy=84.32% avg_sensitivity=67.33%, avg_specificity=89.73% avg_auc=88.76%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.307019 Test loss=0.367370 Current lr=[0.0007872772684775804]

[0/23] Train loss=0.29414719343185425
[5/23] Train loss=0.29616522789001465
[10/23] Train loss=0.31497105956077576
[15/23] Train loss=0.26541319489479065
[20/23] Train loss=0.28134840726852417
Test set avg_accuracy=84.51% avg_sensitivity=67.55%, avg_specificity=89.91% avg_auc=88.75%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.306997 Test loss=0.368807 Current lr=[0.0007749063239896537]

[0/23] Train loss=0.299466073513031
[5/23] Train loss=0.29773110151290894
[10/23] Train loss=0.31321418285369873
[15/23] Train loss=0.26650646328926086
[20/23] Train loss=0.27818650007247925
Test set avg_accuracy=84.32% avg_sensitivity=69.33%, avg_specificity=89.10% avg_auc=88.88%
Best model saved!! Metric=88.88459215899496!!
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.307635 Test loss=0.369006 Current lr=[0.0007622893029006409]

[0/23] Train loss=0.3002541661262512
[5/23] Train loss=0.3001537621021271
[10/23] Train loss=0.313865602016449
[15/23] Train loss=0.2602999806404114
[20/23] Train loss=0.28308242559432983
Test set avg_accuracy=84.23% avg_sensitivity=67.82%, avg_specificity=89.46% avg_auc=88.92%
Best model saved!! Metric=88.91583124139606!!
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.307158 Test loss=0.367351 Current lr=[0.0007494374991531773]

[0/23] Train loss=0.2948680520057678
[5/23] Train loss=0.29851752519607544
[10/23] Train loss=0.31301063299179077
[15/23] Train loss=0.2620140314102173
[20/23] Train loss=0.2788664400577545
Test set avg_accuracy=84.66% avg_sensitivity=67.28%, avg_specificity=90.20% avg_auc=88.95%
Best model saved!! Metric=88.9479819071527!!
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.305552 Test loss=0.365563 Current lr=[0.0007363624168521753]

[0/23] Train loss=0.2956715226173401
[5/23] Train loss=0.2983130216598511
[10/23] Train loss=0.3120110332965851
[15/23] Train loss=0.2604776620864868
[20/23] Train loss=0.2769796550273895
Test set avg_accuracy=84.53% avg_sensitivity=66.04%, avg_specificity=90.42% avg_auc=88.85%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.305107 Test loss=0.366394 Current lr=[0.0007230757599670921]

[0/23] Train loss=0.29554593563079834
[5/23] Train loss=0.29615798592567444
[10/23] Train loss=0.3133051097393036
[15/23] Train loss=0.25719404220581055
[20/23] Train loss=0.2790215313434601
Test set avg_accuracy=84.65% avg_sensitivity=66.31%, avg_specificity=90.49% avg_auc=88.85%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.304879 Test loss=0.365745 Current lr=[0.0007095894218552912]

[0/23] Train loss=0.29076093435287476
[5/23] Train loss=0.2972869277000427
[10/23] Train loss=0.3120996057987213
[15/23] Train loss=0.2580004632472992
[20/23] Train loss=0.2769058644771576
Test set avg_accuracy=84.61% avg_sensitivity=66.47%, avg_specificity=90.39% avg_auc=88.84%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.303439 Test loss=0.367237 Current lr=[0.0006959154746158778]

[0/23] Train loss=0.2972222566604614
[5/23] Train loss=0.2951740324497223
[10/23] Train loss=0.31527629494667053
[15/23] Train loss=0.2584456503391266
[20/23] Train loss=0.27295997738838196
Test set avg_accuracy=84.64% avg_sensitivity=65.98%, avg_specificity=90.58% avg_auc=88.76%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.302604 Test loss=0.367867 Current lr=[0.0006820661582835351]

[0/23] Train loss=0.285789430141449
[5/23] Train loss=0.29557880759239197
[10/23] Train loss=0.3112914264202118
[15/23] Train loss=0.2568371891975403
[20/23] Train loss=0.27773475646972656
Test set avg_accuracy=84.60% avg_sensitivity=67.17%, avg_specificity=90.15% avg_auc=88.70%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.302076 Test loss=0.370387 Current lr=[0.0006680538698720346]

[0/23] Train loss=0.2862783670425415
[5/23] Train loss=0.2937614619731903
[10/23] Train loss=0.3138502240180969
[15/23] Train loss=0.25684475898742676
[20/23] Train loss=0.2764788568019867
Test set avg_accuracy=84.35% avg_sensitivity=65.82%, avg_specificity=90.25% avg_auc=88.69%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.301320 Test loss=0.369705 Current lr=[0.000653891152277231]

[0/23] Train loss=0.2907002866268158
[5/23] Train loss=0.2943592667579651
[10/23] Train loss=0.31579890847206116
[15/23] Train loss=0.26019734144210815
[20/23] Train loss=0.27324721217155457
Test set avg_accuracy=84.34% avg_sensitivity=65.50%, avg_specificity=90.33% avg_auc=88.59%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.301727 Test loss=0.371228 Current lr=[0.0006395906830494706]

[0/23] Train loss=0.29057955741882324
[5/23] Train loss=0.29785385727882385
[10/23] Train loss=0.3122231960296631
[15/23] Train loss=0.254708856344223
[20/23] Train loss=0.27476146817207336
Test set avg_accuracy=84.35% avg_sensitivity=65.07%, avg_specificity=90.49% avg_auc=88.57%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.301028 Test loss=0.372143 Current lr=[0.0006251652630454678]

[0/23] Train loss=0.2903464138507843
[5/23] Train loss=0.29414045810699463
[10/23] Train loss=0.3153127133846283
[15/23] Train loss=0.2564238905906677
[20/23] Train loss=0.2771652340888977
Test set avg_accuracy=84.30% avg_sensitivity=64.31%, avg_specificity=90.66% avg_auc=88.50%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.301091 Test loss=0.372516 Current lr=[0.0006106278049698039]

[0/23] Train loss=0.28613558411598206
[5/23] Train loss=0.29327934980392456
[10/23] Train loss=0.31656700372695923
[15/23] Train loss=0.255824476480484
[20/23] Train loss=0.273636132478714
Test set avg_accuracy=84.23% avg_sensitivity=63.29%, avg_specificity=90.90% avg_auc=88.43%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.300071 Test loss=0.373402 Current lr=[0.0005959913218163081]

[0/23] Train loss=0.28774458169937134
[5/23] Train loss=0.2895311415195465
[10/23] Train loss=0.3142056167125702
[15/23] Train loss=0.2544094920158386
[20/23] Train loss=0.26860368251800537
Test set avg_accuracy=84.11% avg_sensitivity=61.08%, avg_specificity=91.45% avg_auc=88.26%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.298554 Test loss=0.375220 Current lr=[0.0005812689152196656]

[0/23] Train loss=0.2861037850379944
[5/23] Train loss=0.2920697033405304
[10/23] Train loss=0.3119884133338928
[15/23] Train loss=0.25419163703918457
[20/23] Train loss=0.27133646607398987
Test set avg_accuracy=84.14% avg_sensitivity=62.91%, avg_specificity=90.90% avg_auc=88.29%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.298415 Test loss=0.375704 Current lr=[0.00056647376372768]

[0/23] Train loss=0.28760820627212524
[5/23] Train loss=0.2892478406429291
[10/23] Train loss=0.31362125277519226
[15/23] Train loss=0.2519806921482086
[20/23] Train loss=0.27051132917404175
Test set avg_accuracy=84.00% avg_sensitivity=62.86%, avg_specificity=90.73% avg_auc=88.16%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.298250 Test loss=0.378804 Current lr=[0.000551619111004688]

[0/23] Train loss=0.28700196743011475
[5/23] Train loss=0.2924419641494751
[10/23] Train loss=0.3128128945827484
[15/23] Train loss=0.25376760959625244
[20/23] Train loss=0.27005380392074585
Test set avg_accuracy=83.85% avg_sensitivity=62.80%, avg_specificity=90.56% avg_auc=88.17%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.297229 Test loss=0.379027 Current lr=[0.0005367182539766872]

[0/23] Train loss=0.28543657064437866
[5/23] Train loss=0.28912022709846497
[10/23] Train loss=0.3148327171802521
[15/23] Train loss=0.25639936327934265
[20/23] Train loss=0.27360138297080994
Test set avg_accuracy=84.08% avg_sensitivity=61.83%, avg_specificity=91.16% avg_auc=88.12%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.297549 Test loss=0.378727 Current lr=[0.0005217845309287847]

[0/23] Train loss=0.28377145528793335
[5/23] Train loss=0.28808853030204773
[10/23] Train loss=0.31320053339004517
[15/23] Train loss=0.254226416349411
[20/23] Train loss=0.2677353024482727
Test set avg_accuracy=83.82% avg_sensitivity=61.62%, avg_specificity=90.88% avg_auc=87.94%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.296431 Test loss=0.382866 Current lr=[0.0005068313095656279]

[0/23] Train loss=0.2855762243270874
[5/23] Train loss=0.29141777753829956
[10/23] Train loss=0.30928274989128113
[15/23] Train loss=0.25326818227767944
[20/23] Train loss=0.27267974615097046
Test set avg_accuracy=83.61% avg_sensitivity=62.91%, avg_specificity=90.20% avg_auc=87.91%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.295724 Test loss=0.384992 Current lr=[0.000491871975045496]

[0/23] Train loss=0.28529688715934753
[5/23] Train loss=0.2866107225418091
[10/23] Train loss=0.3136559724807739
[15/23] Train loss=0.2536988854408264
[20/23] Train loss=0.2711467146873474
Test set avg_accuracy=83.45% avg_sensitivity=63.18%, avg_specificity=89.91% avg_auc=87.86%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.295853 Test loss=0.386362 Current lr=[0.0004769199179987721]

[0/23] Train loss=0.28205975890159607
[5/23] Train loss=0.2902519404888153
[10/23] Train loss=0.31833311915397644
[15/23] Train loss=0.24962124228477478
[20/23] Train loss=0.26893356442451477
Test set avg_accuracy=83.39% avg_sensitivity=63.34%, avg_specificity=89.77% avg_auc=87.84%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.294983 Test loss=0.386121 Current lr=[0.0004619885225415145]

[0/23] Train loss=0.28452226519584656
[5/23] Train loss=0.28940349817276
[10/23] Train loss=0.31683412194252014
[15/23] Train loss=0.24755620956420898
[20/23] Train loss=0.26938408613204956
Test set avg_accuracy=83.42% avg_sensitivity=62.91%, avg_specificity=89.96% avg_auc=87.81%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.294317 Test loss=0.384969 Current lr=[0.0004470911542948614]

[0/23] Train loss=0.2888782322406769
[5/23] Train loss=0.28986656665802
[10/23] Train loss=0.3139035701751709
[15/23] Train loss=0.2472882866859436
[20/23] Train loss=0.2702283263206482
Test set avg_accuracy=83.62% avg_sensitivity=63.72%, avg_specificity=89.96% avg_auc=87.77%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.294056 Test loss=0.386760 Current lr=[0.00043224114842098864]

[0/23] Train loss=0.28424781560897827
[5/23] Train loss=0.2903555631637573
[10/23] Train loss=0.3107486367225647
[15/23] Train loss=0.2500794231891632
[20/23] Train loss=0.26829224824905396
Test set avg_accuracy=83.80% avg_sensitivity=62.86%, avg_specificity=90.47% avg_auc=87.86%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.293334 Test loss=0.384575 Current lr=[0.00041745179768633387]

[0/23] Train loss=0.27880552411079407
[5/23] Train loss=0.2820162773132324
[10/23] Train loss=0.3087235987186432
[15/23] Train loss=0.2462797611951828
[20/23] Train loss=0.2660333514213562
Test set avg_accuracy=83.95% avg_sensitivity=63.23%, avg_specificity=90.54% avg_auc=87.99%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.291146 Test loss=0.382736 Current lr=[0.000402736340562771]

[0/23] Train loss=0.2805943191051483
[5/23] Train loss=0.28528156876564026
[10/23] Train loss=0.3020557463169098
[15/23] Train loss=0.24622036516666412
[20/23] Train loss=0.26812130212783813
Test set avg_accuracy=83.92% avg_sensitivity=63.94%, avg_specificity=90.28% avg_auc=87.96%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.291619 Test loss=0.384385 Current lr=[0.00038810794937738395]

[0/23] Train loss=0.28183841705322266
[5/23] Train loss=0.28764134645462036
[10/23] Train loss=0.30640071630477905
[15/23] Train loss=0.24501493573188782
[20/23] Train loss=0.26625001430511475
Test set avg_accuracy=83.75% avg_sensitivity=61.83%, avg_specificity=90.73% avg_auc=87.94%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.290107 Test loss=0.383352 Current lr=[0.00037357971852145]

[0/23] Train loss=0.2788653075695038
[5/23] Train loss=0.28765690326690674
[10/23] Train loss=0.30328020453453064
[15/23] Train loss=0.24769288301467896
[20/23] Train loss=0.2697812616825104
Test set avg_accuracy=83.79% avg_sensitivity=62.75%, avg_specificity=90.49% avg_auc=88.08%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.290002 Test loss=0.382180 Current lr=[0.00035916465272918763]

[0/23] Train loss=0.2762393355369568
[5/23] Train loss=0.28350934386253357
[10/23] Train loss=0.2998120188713074
[15/23] Train loss=0.24379229545593262
[20/23] Train loss=0.2717286944389343
Test set avg_accuracy=83.75% avg_sensitivity=62.64%, avg_specificity=90.47% avg_auc=88.08%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.288599 Test loss=0.382589 Current lr=[0.00034487565543675616]

[0/23] Train loss=0.2747882306575775
[5/23] Train loss=0.28112277388572693
[10/23] Train loss=0.30137819051742554
[15/23] Train loss=0.2460898905992508
[20/23] Train loss=0.26921674609184265
Test set avg_accuracy=83.88% avg_sensitivity=63.88%, avg_specificity=90.25% avg_auc=88.05%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.288019 Test loss=0.384684 Current lr=[0.00033072551723193396]

[0/23] Train loss=0.2764595150947571
[5/23] Train loss=0.2886349856853485
[10/23] Train loss=0.30269312858581543
[15/23] Train loss=0.23984266817569733
[20/23] Train loss=0.26200735569000244
Test set avg_accuracy=83.71% avg_sensitivity=63.67%, avg_specificity=90.09% avg_auc=87.95%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.288367 Test loss=0.387187 Current lr=[0.0003167269044048097]

[0/23] Train loss=0.2735160291194916
[5/23] Train loss=0.2817022502422333
[10/23] Train loss=0.3076636791229248
[15/23] Train loss=0.24340128898620605
[20/23] Train loss=0.26638463139533997
Test set avg_accuracy=83.61% avg_sensitivity=64.91%, avg_specificity=89.56% avg_auc=87.98%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.287979 Test loss=0.387453 Current lr=[0.0003028923476097381]

[0/23] Train loss=0.27716487646102905
[5/23] Train loss=0.28022506833076477
[10/23] Train loss=0.3031904697418213
[15/23] Train loss=0.24656616151332855
[20/23] Train loss=0.2640141248703003
Test set avg_accuracy=83.67% avg_sensitivity=65.44%, avg_specificity=89.48% avg_auc=88.03%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.288069 Test loss=0.386516 Current lr=[0.00028923423064870595]

[0/23] Train loss=0.2765628695487976
[5/23] Train loss=0.28296223282814026
[10/23] Train loss=0.3056027889251709
[15/23] Train loss=0.2441415935754776
[20/23] Train loss=0.269753098487854
Test set avg_accuracy=83.71% avg_sensitivity=66.79%, avg_specificity=89.10% avg_auc=88.14%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.287282 Test loss=0.387375 Current lr=[0.000275764779386153]

[0/23] Train loss=0.27518925070762634
[5/23] Train loss=0.2828458249568939
[10/23] Train loss=0.3089812099933624
[15/23] Train loss=0.24147772789001465
[20/23] Train loss=0.267789363861084
Test set avg_accuracy=83.74% avg_sensitivity=68.30%, avg_specificity=88.65% avg_auc=88.26%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.288285 Test loss=0.387625 Current lr=[0.0002624960508051677]

[0/23] Train loss=0.2782735228538513
[5/23] Train loss=0.2808651328086853
[10/23] Train loss=0.30381879210472107
[15/23] Train loss=0.24330809712409973
[20/23] Train loss=0.2636898159980774
Test set avg_accuracy=83.71% avg_sensitivity=68.52%, avg_specificity=88.55% avg_auc=88.32%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.287186 Test loss=0.387625 Current lr=[0.00024943992221485327]

[0/23] Train loss=0.27566784620285034
[5/23] Train loss=0.2788679003715515
[10/23] Train loss=0.29935920238494873
[15/23] Train loss=0.24239970743656158
[20/23] Train loss=0.26632753014564514
Test set avg_accuracy=83.89% avg_sensitivity=67.17%, avg_specificity=89.22% avg_auc=88.24%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.287695 Test loss=0.386077 Current lr=[0.00023660808061852864]

[0/23] Train loss=0.27366435527801514
[5/23] Train loss=0.2725423276424408
[10/23] Train loss=0.2995423674583435
[15/23] Train loss=0.24704642593860626
[20/23] Train loss=0.26602283120155334
Test set avg_accuracy=83.91% avg_sensitivity=62.32%, avg_specificity=90.78% avg_auc=87.98%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.286752 Test loss=0.384203 Current lr=[0.0002240120122522775]

[0/23] Train loss=0.2724861204624176
[5/23] Train loss=0.2744161784648895
[10/23] Train loss=0.29397162795066833
[15/23] Train loss=0.2430248111486435
[20/23] Train loss=0.26744329929351807
Test set avg_accuracy=83.84% avg_sensitivity=61.40%, avg_specificity=90.99% avg_auc=87.90%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.284933 Test loss=0.385307 Current lr=[0.00021166299230321068]

[0/23] Train loss=0.2683422565460205
[5/23] Train loss=0.27985772490501404
[10/23] Train loss=0.29726389050483704
[15/23] Train loss=0.2425059825181961
[20/23] Train loss=0.26123014092445374
Test set avg_accuracy=84.00% avg_sensitivity=63.29%, avg_specificity=90.59% avg_auc=87.99%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.283261 Test loss=0.385914 Current lr=[0.00019957207481664747]

[0/23] Train loss=0.26853716373443604
[5/23] Train loss=0.27574071288108826
[10/23] Train loss=0.29596400260925293
[15/23] Train loss=0.2411239743232727
[20/23] Train loss=0.26312312483787537
Test set avg_accuracy=83.93% avg_sensitivity=62.75%, avg_specificity=90.68% avg_auc=87.85%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.283406 Test loss=0.388261 Current lr=[0.00018775008280124715]

[0/23] Train loss=0.26859068870544434
[5/23] Train loss=0.2801167964935303
[10/23] Train loss=0.2919958829879761
[15/23] Train loss=0.24068428575992584
[20/23] Train loss=0.260027676820755
Test set avg_accuracy=83.91% avg_sensitivity=63.45%, avg_specificity=90.42% avg_auc=87.87%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.282880 Test loss=0.388618 Current lr=[0.0001762075985409517]

[0/23] Train loss=0.26986703276634216
[5/23] Train loss=0.27573153376579285
[10/23] Train loss=0.29682332277297974
[15/23] Train loss=0.2387777417898178
[20/23] Train loss=0.26475629210472107
Test set avg_accuracy=83.70% avg_sensitivity=62.21%, avg_specificity=90.54% avg_auc=87.82%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.282487 Test loss=0.389165 Current lr=[0.0001649549541224071]

[0/23] Train loss=0.2696004807949066
[5/23] Train loss=0.27538007497787476
[10/23] Train loss=0.29375311732292175
[15/23] Train loss=0.2404637634754181
[20/23] Train loss=0.26272955536842346
Test set avg_accuracy=84.06% avg_sensitivity=63.77%, avg_specificity=90.52% avg_auc=87.86%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.282298 Test loss=0.389538 Current lr=[0.00015400222218634707]

[0/23] Train loss=0.2692350447177887
[5/23] Train loss=0.2736472487449646
[10/23] Train loss=0.29437270760536194
[15/23] Train loss=0.24073366820812225
[20/23] Train loss=0.25706830620765686
Test set avg_accuracy=83.72% avg_sensitivity=62.05%, avg_specificity=90.63% avg_auc=87.85%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.281338 Test loss=0.388559 Current lr=[0.000143359206911216]

[0/23] Train loss=0.26509201526641846
[5/23] Train loss=0.27437061071395874
[10/23] Train loss=0.29497581720352173
[15/23] Train loss=0.2398800402879715
[20/23] Train loss=0.262735515832901
Test set avg_accuracy=83.91% avg_sensitivity=62.91%, avg_specificity=90.59% avg_auc=87.88%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.282545 Test loss=0.388554 Current lr=[0.0001330354352371004]

[0/23] Train loss=0.2680373787879944
[5/23] Train loss=0.27674442529678345
[10/23] Train loss=0.29639574885368347
[15/23] Train loss=0.23592136800289154
[20/23] Train loss=0.2609468698501587
Test set avg_accuracy=83.82% avg_sensitivity=62.48%, avg_specificity=90.61% avg_auc=87.82%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.281589 Test loss=0.389961 Current lr=[0.0001230401483378278]

[0/23] Train loss=0.26361480355262756
[5/23] Train loss=0.2745245695114136
[10/23] Train loss=0.29608994722366333
[15/23] Train loss=0.23604872822761536
[20/23] Train loss=0.25877559185028076
Test set avg_accuracy=83.83% avg_sensitivity=61.99%, avg_specificity=90.78% avg_auc=87.82%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.281509 Test loss=0.388805 Current lr=[0.00011338229334886483]

[0/23] Train loss=0.26598307490348816
[5/23] Train loss=0.27441415190696716
[10/23] Train loss=0.2976795434951782
[15/23] Train loss=0.2401045262813568
[20/23] Train loss=0.26100459694862366
Test set avg_accuracy=83.91% avg_sensitivity=61.40%, avg_specificity=91.07% avg_auc=87.75%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.281263 Test loss=0.389445 Current lr=[0.00010407051535841877]

[0/23] Train loss=0.2676541209220886
[5/23] Train loss=0.2728947699069977
[10/23] Train loss=0.29601454734802246
[15/23] Train loss=0.2396610677242279
[20/23] Train loss=0.25941866636276245
Test set avg_accuracy=83.87% avg_sensitivity=60.86%, avg_specificity=91.19% avg_auc=87.75%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.281928 Test loss=0.388919 Current lr=[9.511314966891289e-05]

[0/23] Train loss=0.2668473720550537
[5/23] Train loss=0.27155542373657227
[10/23] Train loss=0.299592524766922
[15/23] Train loss=0.2391309291124344
[20/23] Train loss=0.263406902551651
Test set avg_accuracy=83.63% avg_sensitivity=58.65%, avg_specificity=91.59% avg_auc=87.67%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.282209 Test loss=0.389692 Current lr=[8.651821433576242e-05]

[0/23] Train loss=0.26604214310646057
[5/23] Train loss=0.2719983458518982
[10/23] Train loss=0.3001392185688019
[15/23] Train loss=0.23694340884685516
[20/23] Train loss=0.25873762369155884
Test set avg_accuracy=83.39% avg_sensitivity=56.12%, avg_specificity=92.07% avg_auc=87.55%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.281705 Test loss=0.391645 Current lr=[7.829340299012822e-05]

[0/23] Train loss=0.2690655589103699
[5/23] Train loss=0.2727382779121399
[10/23] Train loss=0.29982030391693115
[15/23] Train loss=0.24154077470302582
[20/23] Train loss=0.26280200481414795
Test set avg_accuracy=83.22% avg_sensitivity=54.29%, avg_specificity=92.43% avg_auc=87.57%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.283323 Test loss=0.391255 Current lr=[7.044607795207541e-05]

[0/23] Train loss=0.27401867508888245
[5/23] Train loss=0.27492937445640564
[10/23] Train loss=0.3006289303302765
[15/23] Train loss=0.24993214011192322
[20/23] Train loss=0.26228588819503784
Test set avg_accuracy=83.72% avg_sensitivity=58.38%, avg_specificity=91.79% avg_auc=87.75%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.284756 Test loss=0.387804 Current lr=[6.298326364029966e-05]

[0/23] Train loss=0.27289465069770813
[5/23] Train loss=0.2767797112464905
[10/23] Train loss=0.2954935133457184
[15/23] Train loss=0.2475348562002182
[20/23] Train loss=0.2641463279724121
Test set avg_accuracy=83.96% avg_sensitivity=63.34%, avg_specificity=90.52% avg_auc=88.00%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.284739 Test loss=0.386657 Current lr=[5.591164028432157e-05]

[0/23] Train loss=0.26373833417892456
[5/23] Train loss=0.2785922884941101
[10/23] Train loss=0.2896665036678314
[15/23] Train loss=0.23927107453346252
[20/23] Train loss=0.2658914029598236
Test set avg_accuracy=84.11% avg_sensitivity=65.66%, avg_specificity=89.99% avg_auc=88.05%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.282400 Test loss=0.387735 Current lr=[4.92375379447757e-05]

[0/23] Train loss=0.26881521940231323
[5/23] Train loss=0.2727188467979431
[10/23] Train loss=0.2899494469165802
[15/23] Train loss=0.2414405792951584
[20/23] Train loss=0.2636287212371826
Test set avg_accuracy=83.88% avg_sensitivity=63.07%, avg_specificity=90.51% avg_auc=87.94%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.281242 Test loss=0.387967 Current lr=[4.296693084714953e-05]

[0/23] Train loss=0.2644746005535126
[5/23] Train loss=0.26987144351005554
[10/23] Train loss=0.2973381578922272
[15/23] Train loss=0.24038884043693542
[20/23] Train loss=0.26214325428009033
Test set avg_accuracy=83.84% avg_sensitivity=62.96%, avg_specificity=90.49% avg_auc=87.91%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.280624 Test loss=0.388705 Current lr=[3.7105432034042674e-05]

[0/23] Train loss=0.26487451791763306
[5/23] Train loss=0.2701716125011444
[10/23] Train loss=0.29716864228248596
[15/23] Train loss=0.2417905032634735
[20/23] Train loss=0.26024842262268066
Test set avg_accuracy=83.87% avg_sensitivity=63.13%, avg_specificity=90.47% avg_auc=87.90%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.280656 Test loss=0.389093 Current lr=[3.165828834073305e-05]

[0/23] Train loss=0.26660820841789246
[5/23] Train loss=0.27077198028564453
[10/23] Train loss=0.2915342152118683
[15/23] Train loss=0.23530162870883942
[20/23] Train loss=0.26081332564353943
Test set avg_accuracy=83.82% avg_sensitivity=63.07%, avg_specificity=90.42% avg_auc=87.88%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.280133 Test loss=0.389643 Current lr=[2.6630375698549288e-05]

[0/23] Train loss=0.2659112215042114
[5/23] Train loss=0.2765682637691498
[10/23] Train loss=0.2956308424472809
[15/23] Train loss=0.2388232946395874
[20/23] Train loss=0.2602415978908539
Test set avg_accuracy=83.89% avg_sensitivity=63.29%, avg_specificity=90.45% avg_auc=87.88%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.280451 Test loss=0.389767 Current lr=[2.2026194770251297e-05]

[0/23] Train loss=0.2697525918483734
[5/23] Train loss=0.27437886595726013
[10/23] Train loss=0.2939189076423645
[15/23] Train loss=0.2399163693189621
[20/23] Train loss=0.2629852890968323
Test set avg_accuracy=83.82% avg_sensitivity=62.91%, avg_specificity=90.47% avg_auc=87.86%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.279796 Test loss=0.389890 Current lr=[1.784986692132802e-05]

[0/23] Train loss=0.26277121901512146
[5/23] Train loss=0.27127304673194885
[10/23] Train loss=0.291865736246109
[15/23] Train loss=0.23845696449279785
[20/23] Train loss=0.26073992252349854
Test set avg_accuracy=83.82% avg_sensitivity=63.07%, avg_specificity=90.42% avg_auc=87.87%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.279832 Test loss=0.390156 Current lr=[1.4105130530816705e-05]

[0/23] Train loss=0.26336508989334106
[5/23] Train loss=0.2736579477787018
[10/23] Train loss=0.2914249897003174
[15/23] Train loss=0.23994921147823334
[20/23] Train loss=0.25901442766189575
Test set avg_accuracy=83.83% avg_sensitivity=63.02%, avg_specificity=90.45% avg_auc=87.87%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.279539 Test loss=0.390095 Current lr=[1.0795337644947743e-05]

[0/23] Train loss=0.2645955979824066
[5/23] Train loss=0.2702811062335968
[10/23] Train loss=0.2924329936504364
[15/23] Train loss=0.24183541536331177
[20/23] Train loss=0.26183295249938965
Test set avg_accuracy=83.84% avg_sensitivity=63.02%, avg_specificity=90.47% avg_auc=87.87%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.279894 Test loss=0.390035 Current lr=[7.923450976609226e-06]

[0/23] Train loss=0.2657197415828705
[5/23] Train loss=0.2698543071746826
[10/23] Train loss=0.2870415449142456
[15/23] Train loss=0.23580165207386017
[20/23] Train loss=0.2599044442176819
Test set avg_accuracy=83.79% avg_sensitivity=62.80%, avg_specificity=90.47% avg_auc=87.87%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.278829 Test loss=0.390054 Current lr=[5.492041253317393e-06]

[0/23] Train loss=0.2674306333065033
[5/23] Train loss=0.27343645691871643
[10/23] Train loss=0.29274699091911316
[15/23] Train loss=0.24050554633140564
[20/23] Train loss=0.26215195655822754
Test set avg_accuracy=83.79% avg_sensitivity=62.80%, avg_specificity=90.47% avg_auc=87.86%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.279809 Test loss=0.390083 Current lr=[3.5032849160677956e-06]

[0/23] Train loss=0.26601532101631165
[5/23] Train loss=0.2731917202472687
[10/23] Train loss=0.2897185683250427
[15/23] Train loss=0.2394111007452011
[20/23] Train loss=0.26049351692199707
Test set avg_accuracy=83.84% avg_sensitivity=63.07%, avg_specificity=90.45% avg_auc=87.87%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.279560 Test loss=0.390160 Current lr=[1.958962171125453e-06]

[0/23] Train loss=0.2670983076095581
[5/23] Train loss=0.26988181471824646
[10/23] Train loss=0.2914903461933136
[15/23] Train loss=0.24139291048049927
[20/23] Train loss=0.2612456977367401
Test set avg_accuracy=83.84% avg_sensitivity=63.07%, avg_specificity=90.45% avg_auc=87.87%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.280187 Test loss=0.390183 Current lr=[8.604553964993598e-07]

[0/23] Train loss=0.2606823444366455
[5/23] Train loss=0.2723601460456848
[10/23] Train loss=0.29602229595184326
[15/23] Train loss=0.23973435163497925
[20/23] Train loss=0.26075178384780884
Test set avg_accuracy=83.84% avg_sensitivity=63.07%, avg_specificity=90.45% avg_auc=87.87%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.279665 Test loss=0.390185 Current lr=[2.0874790452682528e-07]

[0/23] Train loss=0.2624185085296631
[5/23] Train loss=0.27276596426963806
[10/23] Train loss=0.2928130030632019
[15/23] Train loss=0.23734574019908905
[20/23] Train loss=0.2643187344074249
Test set avg_accuracy=83.84% avg_sensitivity=63.07%, avg_specificity=90.45% avg_auc=87.87%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.280053 Test loss=0.390185 Current lr=[4.423061675917745e-09]

Fold[9] Result: acc=84.66% sen=67.28%, spe=90.20%, auc=88.95%!
Fold[9] Avg_jsc=0.55%(±0.28135220520862925)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.001,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient',
 'type': 2}
Transformer(
  (point_cnn): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc_out): Sequential(
    (0): Linear(in_features=3904, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=15, bias=True)
    (2): Sigmoid()
  )
  (audio_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (imu_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
  (gas_transform): MFCC(
    (amplitude_to_DB): AmplitudeToDB()
    (MelSpectrogram): MelSpectrogram(
      (spectrogram): Spectrogram()
      (mel_scale): MelScale()
    )
  )
)
[0/24] Train loss=0.691726803779602
[5/24] Train loss=0.6837259531021118
[10/24] Train loss=0.6756237149238586
[15/24] Train loss=0.666266679763794
[20/24] Train loss=0.6573485136032104
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.54%
Best model saved!! Metric=51.53801781210991!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.671743 Test loss=0.637555 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.6486842632293701
[5/24] Train loss=0.635952889919281
[10/24] Train loss=0.6228986382484436
[15/24] Train loss=0.6096171140670776
[20/24] Train loss=0.6025927662849426
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.24%
Best model saved!! Metric=52.244034118664096!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.617919 Test loss=0.561149 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.595603883266449
[5/24] Train loss=0.5874196887016296
[10/24] Train loss=0.5810381174087524
[15/24] Train loss=0.5806112885475159
[20/24] Train loss=0.5874406695365906
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.71%
Best model saved!! Metric=61.705277346485275!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.579949 Test loss=0.533509 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.586057186126709
[5/24] Train loss=0.5786065459251404
[10/24] Train loss=0.571209728717804
[15/24] Train loss=0.5691430568695068
[20/24] Train loss=0.5727695822715759
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=65.58%
Best model saved!! Metric=65.58244824846807!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.569273 Test loss=0.529520 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.5740923881530762
[5/24] Train loss=0.5659292936325073
[10/24] Train loss=0.5609678626060486
[15/24] Train loss=0.5568978786468506
[20/24] Train loss=0.558283269405365
Test set avg_accuracy=77.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=74.33%
Best model saved!! Metric=74.32611979599486!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.558407 Test loss=0.510678 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.5606259703636169
[5/24] Train loss=0.5508836507797241
[10/24] Train loss=0.5458225011825562
[15/24] Train loss=0.5381505489349365
[20/24] Train loss=0.5365291237831116
Test set avg_accuracy=77.12% avg_sensitivity=1.22%, avg_specificity=99.13% avg_auc=76.54%
Best model saved!! Metric=76.53787671491477!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.543072 Test loss=0.490580 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5420256853103638
[5/24] Train loss=0.5336627960205078
[10/24] Train loss=0.5315747261047363
[15/24] Train loss=0.518738329410553
[20/24] Train loss=0.5155084729194641
Test set avg_accuracy=77.02% avg_sensitivity=3.65%, avg_specificity=98.29% avg_auc=77.85%
Best model saved!! Metric=77.85269822598984!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.527584 Test loss=0.469373 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.5245882272720337
[5/24] Train loss=0.524789571762085
[10/24] Train loss=0.521012544631958
[15/24] Train loss=0.5062118768692017
[20/24] Train loss=0.5011634826660156
Test set avg_accuracy=77.34% avg_sensitivity=3.01%, avg_specificity=98.89% avg_auc=79.54%
Best model saved!! Metric=79.54244417708418!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.515016 Test loss=0.454644 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.5079179406166077
[5/24] Train loss=0.5134381651878357
[10/24] Train loss=0.5093024373054504
[15/24] Train loss=0.48992156982421875
[20/24] Train loss=0.49056532979011536
Test set avg_accuracy=77.14% avg_sensitivity=3.30%, avg_specificity=98.54% avg_auc=81.14%
Best model saved!! Metric=81.14187819244567!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.500862 Test loss=0.436494 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.4867565929889679
[5/24] Train loss=0.4937339425086975
[10/24] Train loss=0.4936513900756836
[15/24] Train loss=0.4662063419818878
[20/24] Train loss=0.467192679643631
Test set avg_accuracy=77.57% avg_sensitivity=14.31%, avg_specificity=95.90% avg_auc=83.15%
Best model saved!! Metric=83.15202181576716!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.481834 Test loss=0.414715 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.46096619963645935
[5/24] Train loss=0.48197513818740845
[10/24] Train loss=0.4769119322299957
[15/24] Train loss=0.4413447976112366
[20/24] Train loss=0.4446120262145996
Test set avg_accuracy=79.34% avg_sensitivity=32.04%, avg_specificity=93.05% avg_auc=85.61%
Best model saved!! Metric=85.61127781123024!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.461389 Test loss=0.391825 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.43601366877555847
[5/24] Train loss=0.4680190086364746
[10/24] Train loss=0.4614099860191345
[15/24] Train loss=0.42050838470458984
[20/24] Train loss=0.4239541292190552
Test set avg_accuracy=81.51% avg_sensitivity=46.00%, avg_specificity=91.80% avg_auc=87.43%
Best model saved!! Metric=87.42867293514472!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.441285 Test loss=0.369485 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.41226184368133545
[5/24] Train loss=0.44838622212409973
[10/24] Train loss=0.44586247205734253
[15/24] Train loss=0.40399184823036194
[20/24] Train loss=0.4068130850791931
Test set avg_accuracy=82.84% avg_sensitivity=52.67%, avg_specificity=91.59% avg_auc=88.36%
Best model saved!! Metric=88.3558323352734!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.424670 Test loss=0.354731 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.3951191008090973
[5/24] Train loss=0.43207260966300964
[10/24] Train loss=0.43435555696487427
[15/24] Train loss=0.39322811365127563
[20/24] Train loss=0.3994738757610321
Test set avg_accuracy=84.11% avg_sensitivity=56.95%, avg_specificity=91.99% avg_auc=88.68%
Best model saved!! Metric=88.6829540186622!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.413952 Test loss=0.348227 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.39301466941833496
[5/24] Train loss=0.42207205295562744
[10/24] Train loss=0.4282798171043396
[15/24] Train loss=0.3880148231983185
[20/24] Train loss=0.3909972310066223
Test set avg_accuracy=84.40% avg_sensitivity=55.16%, avg_specificity=92.88% avg_auc=88.97%
Best model saved!! Metric=88.96906020704894!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.407425 Test loss=0.343080 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.38624539971351624
[5/24] Train loss=0.41312989592552185
[10/24] Train loss=0.4251902401447296
[15/24] Train loss=0.38835209608078003
[20/24] Train loss=0.3805805742740631
Test set avg_accuracy=84.19% avg_sensitivity=48.26%, avg_specificity=94.61% avg_auc=89.25%
Best model saved!! Metric=89.25263637676416!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.401187 Test loss=0.338319 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.3865249752998352
[5/24] Train loss=0.4042854607105255
[10/24] Train loss=0.41586431860923767
[15/24] Train loss=0.3812749683856964
[20/24] Train loss=0.37318742275238037
Test set avg_accuracy=84.26% avg_sensitivity=42.99%, avg_specificity=96.22% avg_auc=89.39%
Best model saved!! Metric=89.39126193828234!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.395036 Test loss=0.338247 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.3876885175704956
[5/24] Train loss=0.3926006555557251
[10/24] Train loss=0.39999300241470337
[15/24] Train loss=0.3661072552204132
[20/24] Train loss=0.3754866421222687
Test set avg_accuracy=84.80% avg_sensitivity=49.19%, avg_specificity=95.13% avg_auc=89.52%
Best model saved!! Metric=89.51743202326372!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.388089 Test loss=0.334602 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.3817217946052551
[5/24] Train loss=0.38771626353263855
[10/24] Train loss=0.39361998438835144
[15/24] Train loss=0.35874253511428833
[20/24] Train loss=0.3664303421974182
Test set avg_accuracy=84.83% avg_sensitivity=41.31%, avg_specificity=97.45% avg_auc=89.43%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.382674 Test loss=0.339889 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.39262494444847107
[5/24] Train loss=0.38461431860923767
[10/24] Train loss=0.3901664614677429
[15/24] Train loss=0.3540956676006317
[20/24] Train loss=0.35691070556640625
Test set avg_accuracy=83.78% avg_sensitivity=34.18%, avg_specificity=98.15% avg_auc=89.32%
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.378803 Test loss=0.347499 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.4004915952682495
[5/24] Train loss=0.3801369369029999
[10/24] Train loss=0.39436373114585876
[15/24] Train loss=0.34992995858192444
[20/24] Train loss=0.35710012912750244
Test set avg_accuracy=85.30% avg_sensitivity=43.16%, avg_specificity=97.51% avg_auc=89.60%
Best model saved!! Metric=89.60062098335207!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.377682 Test loss=0.334842 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.385150283575058
[5/24] Train loss=0.374455988407135
[10/24] Train loss=0.3824213147163391
[15/24] Train loss=0.34708234667778015
[20/24] Train loss=0.34833547472953796
Test set avg_accuracy=84.17% avg_sensitivity=34.47%, avg_specificity=98.57% avg_auc=89.43%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.372044 Test loss=0.344883 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.396414577960968
[5/24] Train loss=0.3803293704986572
[10/24] Train loss=0.3824624717235565
[15/24] Train loss=0.33993542194366455
[20/24] Train loss=0.34159010648727417
Test set avg_accuracy=83.49% avg_sensitivity=31.23%, avg_specificity=98.64% avg_auc=88.80%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.372618 Test loss=0.355260 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.40704745054244995
[5/24] Train loss=0.3904556930065155
[10/24] Train loss=0.38351383805274963
[15/24] Train loss=0.3437485098838806
[20/24] Train loss=0.34616509079933167
Test set avg_accuracy=83.97% avg_sensitivity=33.60%, avg_specificity=98.57% avg_auc=89.37%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.374194 Test loss=0.347716 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.39535441994667053
[5/24] Train loss=0.3788105547428131
[10/24] Train loss=0.3898220360279083
[15/24] Train loss=0.33893847465515137
[20/24] Train loss=0.34879767894744873
Test set avg_accuracy=84.92% avg_sensitivity=39.22%, avg_specificity=98.17% avg_auc=89.67%
Best model saved!! Metric=89.67411316033973!!
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.370582 Test loss=0.338404 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.38364338874816895
[5/24] Train loss=0.37416204810142517
[10/24] Train loss=0.3831080198287964
[15/24] Train loss=0.3357396125793457
[20/24] Train loss=0.3424279987812042
Test set avg_accuracy=85.52% avg_sensitivity=43.40%, avg_specificity=97.73% avg_auc=89.78%
Best model saved!! Metric=89.78109889220212!!
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.366908 Test loss=0.333145 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.3760775327682495
[5/24] Train loss=0.3791736662387848
[10/24] Train loss=0.36858344078063965
[15/24] Train loss=0.3377606272697449
[20/24] Train loss=0.33470651507377625
Test set avg_accuracy=84.83% avg_sensitivity=38.76%, avg_specificity=98.19% avg_auc=89.61%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.364232 Test loss=0.339576 Current lr=[0.000669125424222739]

[0/24] Train loss=0.3825484812259674
[5/24] Train loss=0.3870016932487488
[10/24] Train loss=0.36887121200561523
[15/24] Train loss=0.33263254165649414
[20/24] Train loss=0.33646681904792786
Test set avg_accuracy=85.52% avg_sensitivity=42.76%, avg_specificity=97.92% avg_auc=89.88%
Best model saved!! Metric=89.88375926522029!!
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.363902 Test loss=0.334427 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.37151968479156494
[5/24] Train loss=0.3796532452106476
[10/24] Train loss=0.3617181181907654
[15/24] Train loss=0.3324805200099945
[20/24] Train loss=0.3322647213935852
Test set avg_accuracy=85.72% avg_sensitivity=43.45%, avg_specificity=97.97% avg_auc=89.93%
Best model saved!! Metric=89.9301169919557!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.360782 Test loss=0.333141 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.3684867024421692
[5/24] Train loss=0.3768366575241089
[10/24] Train loss=0.364702433347702
[15/24] Train loss=0.3314397633075714
[20/24] Train loss=0.3289332389831543
Test set avg_accuracy=85.90% avg_sensitivity=45.48%, avg_specificity=97.62% avg_auc=89.95%
Best model saved!! Metric=89.94943757684932!!
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.358918 Test loss=0.332454 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.36224913597106934
[5/24] Train loss=0.3846971392631531
[10/24] Train loss=0.3594280779361725
[15/24] Train loss=0.32913580536842346
[20/24] Train loss=0.32956382632255554
Test set avg_accuracy=86.07% avg_sensitivity=48.44%, avg_specificity=96.98% avg_auc=90.19%
Best model saved!! Metric=90.18944390578834!!
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.358515 Test loss=0.325330 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.35127711296081543
[5/24] Train loss=0.38064873218536377
[10/24] Train loss=0.366010457277298
[15/24] Train loss=0.3332177698612213
[20/24] Train loss=0.32827675342559814
Test set avg_accuracy=85.86% avg_sensitivity=44.73%, avg_specificity=97.78% avg_auc=90.27%
Best model saved!! Metric=90.26657541732658!!
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.357754 Test loss=0.328459 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.3643757104873657
[5/24] Train loss=0.3824397027492523
[10/24] Train loss=0.35790491104125977
[15/24] Train loss=0.3287007212638855
[20/24] Train loss=0.3311852514743805
Test set avg_accuracy=85.70% avg_sensitivity=42.82%, avg_specificity=98.14% avg_auc=90.01%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.357449 Test loss=0.333293 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.36252260208129883
[5/24] Train loss=0.3814994990825653
[10/24] Train loss=0.36203068494796753
[15/24] Train loss=0.3282563090324402
[20/24] Train loss=0.32918861508369446
Test set avg_accuracy=85.76% avg_sensitivity=43.34%, avg_specificity=98.05% avg_auc=90.19%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.358300 Test loss=0.331118 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.3599225580692291
[5/24] Train loss=0.3781416118144989
[10/24] Train loss=0.365437775850296
[15/24] Train loss=0.3250214457511902
[20/24] Train loss=0.327517032623291
Test set avg_accuracy=85.79% avg_sensitivity=43.63%, avg_specificity=98.02% avg_auc=90.48%
Best model saved!! Metric=90.48242979879345!!
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.356733 Test loss=0.325665 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.355245977640152
[5/24] Train loss=0.3655913174152374
[10/24] Train loss=0.3601738512516022
[15/24] Train loss=0.32350122928619385
[20/24] Train loss=0.32423654198646545
Test set avg_accuracy=85.87% avg_sensitivity=44.26%, avg_specificity=97.93% avg_auc=90.56%
Best model saved!! Metric=90.55907963370001!!
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.353396 Test loss=0.325973 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.35714444518089294
[5/24] Train loss=0.36601895093917847
[10/24] Train loss=0.3592687249183655
[15/24] Train loss=0.3238956332206726
[20/24] Train loss=0.3229268491268158
Test set avg_accuracy=86.22% avg_sensitivity=45.37%, avg_specificity=98.07% avg_auc=90.54%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.352425 Test loss=0.325569 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.360220342874527
[5/24] Train loss=0.36461201310157776
[10/24] Train loss=0.35795533657073975
[15/24] Train loss=0.31855425238609314
[20/24] Train loss=0.3269004225730896
Test set avg_accuracy=85.83% avg_sensitivity=44.09%, avg_specificity=97.93% avg_auc=90.80%
Best model saved!! Metric=90.80092022617589!!
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.352826 Test loss=0.320698 Current lr=[0.000944367614404117]

[0/24] Train loss=0.3568456172943115
[5/24] Train loss=0.3690415620803833
[10/24] Train loss=0.35327112674713135
[15/24] Train loss=0.31804022192955017
[20/24] Train loss=0.3189249336719513
Test set avg_accuracy=86.38% avg_sensitivity=46.81%, avg_specificity=97.85% avg_auc=91.04%
Best model saved!! Metric=91.0364746953371!!
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.350677 Test loss=0.315933 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.3607099652290344
[5/24] Train loss=0.36824095249176025
[10/24] Train loss=0.3555363714694977
[15/24] Train loss=0.3218330144882202
[20/24] Train loss=0.3242993950843811
Test set avg_accuracy=85.99% avg_sensitivity=44.73%, avg_specificity=97.95% avg_auc=90.85%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.351062 Test loss=0.320928 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.3561246991157532
[5/24] Train loss=0.3605158030986786
[10/24] Train loss=0.35038334131240845
[15/24] Train loss=0.316776305437088
[20/24] Train loss=0.32386425137519836
Test set avg_accuracy=86.21% avg_sensitivity=46.93%, avg_specificity=97.60% avg_auc=90.73%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.347712 Test loss=0.320050 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.3577921688556671
[5/24] Train loss=0.36262017488479614
[10/24] Train loss=0.3509973883628845
[15/24] Train loss=0.3165450692176819
[20/24] Train loss=0.31745225191116333
Test set avg_accuracy=86.17% avg_sensitivity=47.39%, avg_specificity=97.41% avg_auc=90.87%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.346629 Test loss=0.316452 Current lr=[0.000989780311725182]

[0/24] Train loss=0.348962664604187
[5/24] Train loss=0.3565869927406311
[10/24] Train loss=0.35151243209838867
[15/24] Train loss=0.3128437101840973
[20/24] Train loss=0.3203756511211395
Test set avg_accuracy=86.33% avg_sensitivity=47.57%, avg_specificity=97.56% avg_auc=90.79%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.344688 Test loss=0.316741 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.3463627099990845
[5/24] Train loss=0.35073819756507874
[10/24] Train loss=0.3518727719783783
[15/24] Train loss=0.31090039014816284
[20/24] Train loss=0.32118868827819824
Test set avg_accuracy=86.26% avg_sensitivity=46.52%, avg_specificity=97.78% avg_auc=90.85%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.344208 Test loss=0.317491 Current lr=[0.000998924125869967]

[0/24] Train loss=0.34312963485717773
[5/24] Train loss=0.3530454933643341
[10/24] Train loss=0.3485742211341858
[15/24] Train loss=0.30649828910827637
[20/24] Train loss=0.31732484698295593
Test set avg_accuracy=86.00% avg_sensitivity=44.55%, avg_specificity=98.02% avg_auc=90.79%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.342922 Test loss=0.318254 Current lr=[0.000999999611458977]

[0/24] Train loss=0.34455206990242004
[5/24] Train loss=0.35497400164604187
[10/24] Train loss=0.34971439838409424
[15/24] Train loss=0.3062969148159027
[20/24] Train loss=0.3194257915019989
Test set avg_accuracy=86.65% avg_sensitivity=49.59%, avg_specificity=97.40% avg_auc=90.73%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.342608 Test loss=0.315767 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.34157469868659973
[5/24] Train loss=0.35141241550445557
[10/24] Train loss=0.34718984365463257
[15/24] Train loss=0.3066342771053314
[20/24] Train loss=0.31787189841270447
Test set avg_accuracy=86.48% avg_sensitivity=50.29%, avg_specificity=96.98% avg_auc=90.76%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.340953 Test loss=0.314332 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.33839306235313416
[5/24] Train loss=0.3527103066444397
[10/24] Train loss=0.34950152039527893
[15/24] Train loss=0.3060244917869568
[20/24] Train loss=0.32184353470802307
Test set avg_accuracy=86.80% avg_sensitivity=52.90%, avg_specificity=96.62% avg_auc=90.59%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.340529 Test loss=0.313900 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3366035223007202
[5/24] Train loss=0.35202327370643616
[10/24] Train loss=0.3507761061191559
[15/24] Train loss=0.30407002568244934
[20/24] Train loss=0.320978045463562
Test set avg_accuracy=87.27% avg_sensitivity=54.40%, avg_specificity=96.79% avg_auc=90.78%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.339491 Test loss=0.310559 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3364355266094208
[5/24] Train loss=0.3444879651069641
[10/24] Train loss=0.3447567820549011
[15/24] Train loss=0.30549463629722595
[20/24] Train loss=0.31254562735557556
Test set avg_accuracy=87.14% avg_sensitivity=53.77%, avg_specificity=96.81% avg_auc=90.70%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.337638 Test loss=0.311842 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.32974880933761597
[5/24] Train loss=0.3465263545513153
[10/24] Train loss=0.34424611926078796
[15/24] Train loss=0.3076840341091156
[20/24] Train loss=0.31375449895858765
Test set avg_accuracy=86.94% avg_sensitivity=52.95%, avg_specificity=96.79% avg_auc=90.72%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.335580 Test loss=0.311498 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.33228176832199097
[5/24] Train loss=0.34970590472221375
[10/24] Train loss=0.3422318696975708
[15/24] Train loss=0.2993153929710388
[20/24] Train loss=0.31341874599456787
Test set avg_accuracy=87.04% avg_sensitivity=53.53%, avg_specificity=96.76% avg_auc=90.76%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.334861 Test loss=0.310434 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.32607153058052063
[5/24] Train loss=0.34774526953697205
[10/24] Train loss=0.3440759778022766
[15/24] Train loss=0.30114176869392395
[20/24] Train loss=0.31622520089149475
Test set avg_accuracy=87.42% avg_sensitivity=55.85%, avg_specificity=96.57% avg_auc=90.84%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.334918 Test loss=0.308808 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.32463502883911133
[5/24] Train loss=0.341911643743515
[10/24] Train loss=0.34574753046035767
[15/24] Train loss=0.30328699946403503
[20/24] Train loss=0.3152455687522888
Test set avg_accuracy=87.11% avg_sensitivity=54.23%, avg_specificity=96.64% avg_auc=90.65%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.334631 Test loss=0.311538 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.33355310559272766
[5/24] Train loss=0.3423548638820648
[10/24] Train loss=0.3447277843952179
[15/24] Train loss=0.30431345105171204
[20/24] Train loss=0.32076090574264526
Test set avg_accuracy=87.38% avg_sensitivity=58.57%, avg_specificity=95.73% avg_auc=90.63%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.335151 Test loss=0.309574 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.3213959336280823
[5/24] Train loss=0.3419977128505707
[10/24] Train loss=0.3407866358757019
[15/24] Train loss=0.30549705028533936
[20/24] Train loss=0.31320732831954956
Test set avg_accuracy=87.38% avg_sensitivity=58.63%, avg_specificity=95.72% avg_auc=90.71%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.333495 Test loss=0.309487 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.32032233476638794
[5/24] Train loss=0.3383603096008301
[10/24] Train loss=0.33682766556739807
[15/24] Train loss=0.30102425813674927
[20/24] Train loss=0.3153742551803589
Test set avg_accuracy=87.30% avg_sensitivity=58.29%, avg_specificity=95.72% avg_auc=90.76%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.331700 Test loss=0.308460 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.31793972849845886
[5/24] Train loss=0.33907467126846313
[10/24] Train loss=0.34455904364585876
[15/24] Train loss=0.3045560419559479
[20/24] Train loss=0.31238898634910583
Test set avg_accuracy=87.54% avg_sensitivity=59.21%, avg_specificity=95.75% avg_auc=90.84%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.332272 Test loss=0.307236 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.3161492943763733
[5/24] Train loss=0.3334061801433563
[10/24] Train loss=0.3404833674430847
[15/24] Train loss=0.3035164177417755
[20/24] Train loss=0.3133741617202759
Test set avg_accuracy=87.27% avg_sensitivity=59.10%, avg_specificity=95.43% avg_auc=90.67%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.332470 Test loss=0.309131 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.3201994001865387
[5/24] Train loss=0.3325696289539337
[10/24] Train loss=0.3436761498451233
[15/24] Train loss=0.3011542856693268
[20/24] Train loss=0.30712684988975525
Test set avg_accuracy=87.67% avg_sensitivity=59.68%, avg_specificity=95.78% avg_auc=90.61%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.331565 Test loss=0.309604 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.32018980383872986
[5/24] Train loss=0.329571932554245
[10/24] Train loss=0.3447551727294922
[15/24] Train loss=0.3029523193836212
[20/24] Train loss=0.3131387233734131
Test set avg_accuracy=87.24% avg_sensitivity=57.94%, avg_specificity=95.73% avg_auc=90.79%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.332031 Test loss=0.307883 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.3167267143726349
[5/24] Train loss=0.32760852575302124
[10/24] Train loss=0.3414713144302368
[15/24] Train loss=0.30345970392227173
[20/24] Train loss=0.30986183881759644
Test set avg_accuracy=87.45% avg_sensitivity=60.37%, avg_specificity=95.30% avg_auc=91.06%
Best model saved!! Metric=91.05903078487796!!
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.330456 Test loss=0.303695 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.31140056252479553
[5/24] Train loss=0.33008357882499695
[10/24] Train loss=0.33744168281555176
[15/24] Train loss=0.299156129360199
[20/24] Train loss=0.308113694190979
Test set avg_accuracy=87.37% avg_sensitivity=57.65%, avg_specificity=95.99% avg_auc=91.17%
Best model saved!! Metric=91.17380605499638!!
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.328671 Test loss=0.302826 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.3213488459587097
[5/24] Train loss=0.3273756802082062
[10/24] Train loss=0.33657851815223694
[15/24] Train loss=0.30335989594459534
[20/24] Train loss=0.3095105290412903
Test set avg_accuracy=87.25% avg_sensitivity=59.50%, avg_specificity=95.30% avg_auc=91.08%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.330163 Test loss=0.303424 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.3139578402042389
[5/24] Train loss=0.32852447032928467
[10/24] Train loss=0.3348561227321625
[15/24] Train loss=0.3016095757484436
[20/24] Train loss=0.3106137216091156
Test set avg_accuracy=87.27% avg_sensitivity=59.44%, avg_specificity=95.33% avg_auc=90.94%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.328060 Test loss=0.305339 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.31274789571762085
[5/24] Train loss=0.32696205377578735
[10/24] Train loss=0.3378481864929199
[15/24] Train loss=0.29796621203422546
[20/24] Train loss=0.3065457046031952
Test set avg_accuracy=87.27% avg_sensitivity=58.17%, avg_specificity=95.70% avg_auc=90.87%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.327452 Test loss=0.307147 Current lr=[0.000904142181093812]

[0/24] Train loss=0.3149651885032654
[5/24] Train loss=0.3251703083515167
[10/24] Train loss=0.33846360445022583
[15/24] Train loss=0.29911190271377563
[20/24] Train loss=0.31033244729042053
Test set avg_accuracy=87.36% avg_sensitivity=59.62%, avg_specificity=95.40% avg_auc=90.85%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.327257 Test loss=0.306061 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.3154032528400421
[5/24] Train loss=0.3261294960975647
[10/24] Train loss=0.33442774415016174
[15/24] Train loss=0.29859021306037903
[20/24] Train loss=0.31149059534072876
Test set avg_accuracy=87.15% avg_sensitivity=58.17%, avg_specificity=95.55% avg_auc=91.00%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.326807 Test loss=0.304573 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.3140714168548584
[5/24] Train loss=0.32071128487586975
[10/24] Train loss=0.33284881711006165
[15/24] Train loss=0.29642540216445923
[20/24] Train loss=0.3108298182487488
Test set avg_accuracy=87.24% avg_sensitivity=59.79%, avg_specificity=95.20% avg_auc=90.92%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.324964 Test loss=0.305358 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.3141818642616272
[5/24] Train loss=0.323953777551651
[10/24] Train loss=0.33460864424705505
[15/24] Train loss=0.29696980118751526
[20/24] Train loss=0.31160739064216614
Test set avg_accuracy=87.45% avg_sensitivity=60.31%, avg_specificity=95.31% avg_auc=90.93%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.324926 Test loss=0.305299 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.31104427576065063
[5/24] Train loss=0.3173626661300659
[10/24] Train loss=0.33406153321266174
[15/24] Train loss=0.2934284508228302
[20/24] Train loss=0.31289249658584595
Test set avg_accuracy=87.17% avg_sensitivity=59.39%, avg_specificity=95.23% avg_auc=90.81%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.323251 Test loss=0.306886 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.31310248374938965
[5/24] Train loss=0.3170721232891083
[10/24] Train loss=0.3322727382183075
[15/24] Train loss=0.29335907101631165
[20/24] Train loss=0.30751723051071167
Test set avg_accuracy=87.41% avg_sensitivity=60.95%, avg_specificity=95.08% avg_auc=90.69%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.322475 Test loss=0.308823 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.30678942799568176
[5/24] Train loss=0.31744638085365295
[10/24] Train loss=0.33075445890426636
[15/24] Train loss=0.29275190830230713
[20/24] Train loss=0.31014737486839294
Test set avg_accuracy=86.89% avg_sensitivity=60.25%, avg_specificity=94.61% avg_auc=90.63%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.321444 Test loss=0.309234 Current lr=[0.000834102481048427]

[0/24] Train loss=0.30794432759284973
[5/24] Train loss=0.31460607051849365
[10/24] Train loss=0.33088549971580505
[15/24] Train loss=0.29236525297164917
[20/24] Train loss=0.30780571699142456
Test set avg_accuracy=87.36% avg_sensitivity=61.36%, avg_specificity=94.89% avg_auc=90.60%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.320992 Test loss=0.310109 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.3148888051509857
[5/24] Train loss=0.3199743926525116
[10/24] Train loss=0.33343592286109924
[15/24] Train loss=0.292706698179245
[20/24] Train loss=0.30318477749824524
Test set avg_accuracy=87.17% avg_sensitivity=61.65%, avg_specificity=94.58% avg_auc=90.66%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.319839 Test loss=0.310435 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.30785778164863586
[5/24] Train loss=0.3178650438785553
[10/24] Train loss=0.33124393224716187
[15/24] Train loss=0.29188570380210876
[20/24] Train loss=0.3080139756202698
Test set avg_accuracy=87.19% avg_sensitivity=61.88%, avg_specificity=94.52% avg_auc=90.63%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.318133 Test loss=0.310860 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.30739626288414
[5/24] Train loss=0.3129575252532959
[10/24] Train loss=0.326011598110199
[15/24] Train loss=0.289476215839386
[20/24] Train loss=0.304331511259079
Test set avg_accuracy=86.90% avg_sensitivity=60.72%, avg_specificity=94.49% avg_auc=90.72%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.317403 Test loss=0.309351 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.3069906532764435
[5/24] Train loss=0.3103320002555847
[10/24] Train loss=0.33269864320755005
[15/24] Train loss=0.289650559425354
[20/24] Train loss=0.30715376138687134
Test set avg_accuracy=86.85% avg_sensitivity=61.99%, avg_specificity=94.05% avg_auc=90.52%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.316447 Test loss=0.312819 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.3063275218009949
[5/24] Train loss=0.3126700818538666
[10/24] Train loss=0.3286101818084717
[15/24] Train loss=0.2896377146244049
[20/24] Train loss=0.30623486638069153
Test set avg_accuracy=86.65% avg_sensitivity=61.94%, avg_specificity=93.82% avg_auc=90.23%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.316554 Test loss=0.317082 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.30972760915756226
[5/24] Train loss=0.3120124936103821
[10/24] Train loss=0.32899558544158936
[15/24] Train loss=0.2889452874660492
[20/24] Train loss=0.29792270064353943
Test set avg_accuracy=87.17% avg_sensitivity=61.41%, avg_specificity=94.64% avg_auc=90.52%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.316245 Test loss=0.312691 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.3052418529987335
[5/24] Train loss=0.3125673830509186
[10/24] Train loss=0.32718586921691895
[15/24] Train loss=0.2863648235797882
[20/24] Train loss=0.2975800931453705
Test set avg_accuracy=87.03% avg_sensitivity=61.99%, avg_specificity=94.29% avg_auc=90.54%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.314501 Test loss=0.312719 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.30314797163009644
[5/24] Train loss=0.31613630056381226
[10/24] Train loss=0.3264596164226532
[15/24] Train loss=0.29028385877609253
[20/24] Train loss=0.3013952374458313
Test set avg_accuracy=86.76% avg_sensitivity=62.05%, avg_specificity=93.92% avg_auc=90.58%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.314542 Test loss=0.312986 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.30021122097969055
[5/24] Train loss=0.3108118176460266
[10/24] Train loss=0.32824814319610596
[15/24] Train loss=0.2937007546424866
[20/24] Train loss=0.30290478467941284
Test set avg_accuracy=86.91% avg_sensitivity=62.22%, avg_specificity=94.07% avg_auc=90.51%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.314792 Test loss=0.313386 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.30042579770088196
[5/24] Train loss=0.3069712519645691
[10/24] Train loss=0.32919058203697205
[15/24] Train loss=0.2918318808078766
[20/24] Train loss=0.2948542535305023
Test set avg_accuracy=86.85% avg_sensitivity=62.57%, avg_specificity=93.89% avg_auc=90.50%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.313605 Test loss=0.313727 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.30336815118789673
[5/24] Train loss=0.3081960082054138
[10/24] Train loss=0.3224148452281952
[15/24] Train loss=0.2902536690235138
[20/24] Train loss=0.29740214347839355
Test set avg_accuracy=87.06% avg_sensitivity=61.30%, avg_specificity=94.52% avg_auc=90.65%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.313772 Test loss=0.309732 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.301238089799881
[5/24] Train loss=0.3137041926383972
[10/24] Train loss=0.3216235041618347
[15/24] Train loss=0.29035651683807373
[20/24] Train loss=0.29328981041908264
Test set avg_accuracy=87.11% avg_sensitivity=62.17%, avg_specificity=94.34% avg_auc=90.75%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.313560 Test loss=0.309064 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.30097633600234985
[5/24] Train loss=0.3062512278556824
[10/24] Train loss=0.32084304094314575
[15/24] Train loss=0.28360602259635925
[20/24] Train loss=0.2966700494289398
Test set avg_accuracy=87.14% avg_sensitivity=61.12%, avg_specificity=94.68% avg_auc=90.78%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.312281 Test loss=0.308127 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.3069065809249878
[5/24] Train loss=0.3082301616668701
[10/24] Train loss=0.320704847574234
[15/24] Train loss=0.2887781858444214
[20/24] Train loss=0.2953532636165619
Test set avg_accuracy=87.10% avg_sensitivity=58.23%, avg_specificity=95.47% avg_auc=90.43%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.312469 Test loss=0.315114 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.303546279668808
[5/24] Train loss=0.29871541261672974
[10/24] Train loss=0.317585825920105
[15/24] Train loss=0.28170907497406006
[20/24] Train loss=0.28857067227363586
Test set avg_accuracy=87.04% avg_sensitivity=60.72%, avg_specificity=94.68% avg_auc=90.58%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.309534 Test loss=0.312513 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.29742470383644104
[5/24] Train loss=0.30044153332710266
[10/24] Train loss=0.3197256028652191
[15/24] Train loss=0.28093421459198
[20/24] Train loss=0.2907179296016693
Test set avg_accuracy=86.84% avg_sensitivity=59.50%, avg_specificity=94.76% avg_auc=90.52%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.309045 Test loss=0.313763 Current lr=[0.00061065423442182]

[0/24] Train loss=0.3013494610786438
[5/24] Train loss=0.3023105263710022
[10/24] Train loss=0.31628182530403137
[15/24] Train loss=0.2841489911079407
[20/24] Train loss=0.29144835472106934
Test set avg_accuracy=87.10% avg_sensitivity=61.01%, avg_specificity=94.66% avg_auc=90.65%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.309525 Test loss=0.312199 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.30045264959335327
[5/24] Train loss=0.3067883253097534
[10/24] Train loss=0.3222704827785492
[15/24] Train loss=0.2821551263332367
[20/24] Train loss=0.29107293486595154
Test set avg_accuracy=87.06% avg_sensitivity=60.78%, avg_specificity=94.68% avg_auc=90.45%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.308845 Test loss=0.315035 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.29579100012779236
[5/24] Train loss=0.3042607605457306
[10/24] Train loss=0.3250810503959656
[15/24] Train loss=0.2854832410812378
[20/24] Train loss=0.28507208824157715
Test set avg_accuracy=86.99% avg_sensitivity=60.83%, avg_specificity=94.58% avg_auc=90.43%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.307447 Test loss=0.316034 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.30040308833122253
[5/24] Train loss=0.30394434928894043
[10/24] Train loss=0.3170730471611023
[15/24] Train loss=0.28204345703125
[20/24] Train loss=0.2852934002876282
Test set avg_accuracy=86.77% avg_sensitivity=59.27%, avg_specificity=94.74% avg_auc=90.30%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.306407 Test loss=0.317586 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.30195656418800354
[5/24] Train loss=0.30154696106910706
[10/24] Train loss=0.3188247084617615
[15/24] Train loss=0.27991995215415955
[20/24] Train loss=0.2817131578922272
Test set avg_accuracy=86.72% avg_sensitivity=59.62%, avg_specificity=94.58% avg_auc=90.46%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.305606 Test loss=0.315980 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.2938101887702942
[5/24] Train loss=0.3044828474521637
[10/24] Train loss=0.3158871531486511
[15/24] Train loss=0.28165552020072937
[20/24] Train loss=0.27985817193984985
Test set avg_accuracy=86.91% avg_sensitivity=58.29%, avg_specificity=95.21% avg_auc=90.41%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.304470 Test loss=0.317269 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.30069348216056824
[5/24] Train loss=0.29890176653862
[10/24] Train loss=0.31634002923965454
[15/24] Train loss=0.28051358461380005
[20/24] Train loss=0.28549861907958984
Test set avg_accuracy=87.08% avg_sensitivity=59.50%, avg_specificity=95.08% avg_auc=90.39%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.304946 Test loss=0.316302 Current lr=[0.000506858408304961]

[0/24] Train loss=0.295431911945343
[5/24] Train loss=0.2923891544342041
[10/24] Train loss=0.31586751341819763
[15/24] Train loss=0.28308963775634766
[20/24] Train loss=0.28265389800071716
Test set avg_accuracy=86.91% avg_sensitivity=60.60%, avg_specificity=94.54% avg_auc=90.47%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.303114 Test loss=0.315331 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.2905617654323578
[5/24] Train loss=0.2997291088104248
[10/24] Train loss=0.3239617943763733
[15/24] Train loss=0.27991247177124023
[20/24] Train loss=0.2806060314178467
Test set avg_accuracy=86.88% avg_sensitivity=61.12%, avg_specificity=94.34% avg_auc=90.42%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.303281 Test loss=0.315705 Current lr=[0.000476946990416354]

[0/24] Train loss=0.29369649291038513
[5/24] Train loss=0.29777148365974426
[10/24] Train loss=0.31673911213874817
[15/24] Train loss=0.2775983214378357
[20/24] Train loss=0.27718815207481384
Test set avg_accuracy=86.97% avg_sensitivity=60.14%, avg_specificity=94.74% avg_auc=90.52%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.301751 Test loss=0.315653 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.2907666563987732
[5/24] Train loss=0.29298415780067444
[10/24] Train loss=0.3143176734447479
[15/24] Train loss=0.2773551940917969
[20/24] Train loss=0.2776589095592499
Test set avg_accuracy=87.02% avg_sensitivity=60.20%, avg_specificity=94.79% avg_auc=90.48%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.301123 Test loss=0.315970 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.29704153537750244
[5/24] Train loss=0.29329636693000793
[10/24] Train loss=0.3118332028388977
[15/24] Train loss=0.28050073981285095
[20/24] Train loss=0.27551883459091187
Test set avg_accuracy=87.04% avg_sensitivity=59.56%, avg_specificity=95.01% avg_auc=90.49%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.299766 Test loss=0.315919 Current lr=[0.000432267999769856]

[0/24] Train loss=0.2900852859020233
[5/24] Train loss=0.2869214415550232
[10/24] Train loss=0.31116461753845215
[15/24] Train loss=0.269004762172699
[20/24] Train loss=0.2770068645477295
Test set avg_accuracy=87.24% avg_sensitivity=60.08%, avg_specificity=95.11% avg_auc=90.61%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.297941 Test loss=0.314191 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.29628786444664
[5/24] Train loss=0.2904468774795532
[10/24] Train loss=0.3137068450450897
[15/24] Train loss=0.2712104022502899
[20/24] Train loss=0.274409681558609
Test set avg_accuracy=86.73% avg_sensitivity=59.15%, avg_specificity=94.73% avg_auc=90.48%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.299387 Test loss=0.315666 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.29484492540359497
[5/24] Train loss=0.2868466079235077
[10/24] Train loss=0.3073193430900574
[15/24] Train loss=0.27340927720069885
[20/24] Train loss=0.27721792459487915
Test set avg_accuracy=86.93% avg_sensitivity=60.02%, avg_specificity=94.73% avg_auc=90.48%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.296633 Test loss=0.315787 Current lr=[0.000388134363466264]

[0/24] Train loss=0.288558691740036
[5/24] Train loss=0.28715014457702637
[10/24] Train loss=0.3123859763145447
[15/24] Train loss=0.273733913898468
[20/24] Train loss=0.27592939138412476
Test set avg_accuracy=86.85% avg_sensitivity=57.47%, avg_specificity=95.36% avg_auc=90.27%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.297484 Test loss=0.320942 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.29911595582962036
[5/24] Train loss=0.2859690487384796
[10/24] Train loss=0.3142613172531128
[15/24] Train loss=0.27449601888656616
[20/24] Train loss=0.2795908749103546
Test set avg_accuracy=86.85% avg_sensitivity=58.81%, avg_specificity=94.98% avg_auc=90.26%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.297739 Test loss=0.320411 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.2891841530799866
[5/24] Train loss=0.28314638137817383
[10/24] Train loss=0.31055980920791626
[15/24] Train loss=0.271627277135849
[20/24] Train loss=0.274008184671402
Test set avg_accuracy=86.91% avg_sensitivity=57.94%, avg_specificity=95.31% avg_auc=90.25%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.296388 Test loss=0.320703 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.2952329218387604
[5/24] Train loss=0.28620874881744385
[10/24] Train loss=0.3143845498561859
[15/24] Train loss=0.27231264114379883
[20/24] Train loss=0.27232712507247925
Test set avg_accuracy=86.98% avg_sensitivity=59.62%, avg_specificity=94.91% avg_auc=90.31%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.296916 Test loss=0.318995 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.2910086512565613
[5/24] Train loss=0.28818124532699585
[10/24] Train loss=0.3129698932170868
[15/24] Train loss=0.27288687229156494
[20/24] Train loss=0.27457061409950256
Test set avg_accuracy=86.76% avg_sensitivity=59.97%, avg_specificity=94.52% avg_auc=90.38%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.296558 Test loss=0.317846 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.2876855731010437
[5/24] Train loss=0.28548213839530945
[10/24] Train loss=0.31438586115837097
[15/24] Train loss=0.27147841453552246
[20/24] Train loss=0.2702673375606537
Test set avg_accuracy=86.94% avg_sensitivity=62.51%, avg_specificity=94.02% avg_auc=90.45%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.297161 Test loss=0.316467 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.2827387750148773
[5/24] Train loss=0.29751527309417725
[10/24] Train loss=0.3187278211116791
[15/24] Train loss=0.27528661489486694
[20/24] Train loss=0.27531760931015015
Test set avg_accuracy=86.58% avg_sensitivity=64.83%, avg_specificity=92.88% avg_auc=90.60%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.297988 Test loss=0.315217 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.2854282557964325
[5/24] Train loss=0.29707959294319153
[10/24] Train loss=0.31961122155189514
[15/24] Train loss=0.2732362151145935
[20/24] Train loss=0.2762852907180786
Test set avg_accuracy=86.46% avg_sensitivity=66.28%, avg_specificity=92.31% avg_auc=90.56%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.296923 Test loss=0.317017 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.28587278723716736
[5/24] Train loss=0.2908633053302765
[10/24] Train loss=0.3138546645641327
[15/24] Train loss=0.2731355130672455
[20/24] Train loss=0.2792207896709442
Test set avg_accuracy=86.64% avg_sensitivity=65.18%, avg_specificity=92.86% avg_auc=90.55%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.296021 Test loss=0.315973 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.2879158854484558
[5/24] Train loss=0.2863875925540924
[10/24] Train loss=0.30502933263778687
[15/24] Train loss=0.2712244987487793
[20/24] Train loss=0.2776651382446289
Test set avg_accuracy=86.98% avg_sensitivity=63.67%, avg_specificity=93.74% avg_auc=90.47%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.293071 Test loss=0.316805 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.2810540199279785
[5/24] Train loss=0.27827975153923035
[10/24] Train loss=0.30204659700393677
[15/24] Train loss=0.2721653878688812
[20/24] Train loss=0.2696756422519684
Test set avg_accuracy=86.82% avg_sensitivity=61.82%, avg_specificity=94.07% avg_auc=90.42%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.290655 Test loss=0.318388 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.28198251128196716
[5/24] Train loss=0.28159186244010925
[10/24] Train loss=0.31172457337379456
[15/24] Train loss=0.26625823974609375
[20/24] Train loss=0.2700842022895813
Test set avg_accuracy=86.99% avg_sensitivity=63.73%, avg_specificity=93.74% avg_auc=90.38%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.290361 Test loss=0.319389 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.28306400775909424
[5/24] Train loss=0.28486359119415283
[10/24] Train loss=0.30225247144699097
[15/24] Train loss=0.2707782983779907
[20/24] Train loss=0.2712928056716919
Test set avg_accuracy=86.72% avg_sensitivity=61.59%, avg_specificity=94.00% avg_auc=90.38%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.290238 Test loss=0.319414 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.2813688814640045
[5/24] Train loss=0.2788054943084717
[10/24] Train loss=0.29526692628860474
[15/24] Train loss=0.2651125192642212
[20/24] Train loss=0.272303968667984
Test set avg_accuracy=86.73% avg_sensitivity=62.28%, avg_specificity=93.82% avg_auc=90.32%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.288629 Test loss=0.320560 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.2872377634048462
[5/24] Train loss=0.27447962760925293
[10/24] Train loss=0.30644679069519043
[15/24] Train loss=0.2705571949481964
[20/24] Train loss=0.270150363445282
Test set avg_accuracy=86.55% avg_sensitivity=60.95%, avg_specificity=93.97% avg_auc=90.31%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.289593 Test loss=0.320867 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.2821601331233978
[5/24] Train loss=0.2763039469718933
[10/24] Train loss=0.3007613718509674
[15/24] Train loss=0.2655188739299774
[20/24] Train loss=0.2678544819355011
Test set avg_accuracy=86.55% avg_sensitivity=61.30%, avg_specificity=93.87% avg_auc=90.25%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.287941 Test loss=0.322016 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.282068133354187
[5/24] Train loss=0.2770662307739258
[10/24] Train loss=0.3046007454395294
[15/24] Train loss=0.2695454955101013
[20/24] Train loss=0.264188677072525
Test set avg_accuracy=86.55% avg_sensitivity=60.54%, avg_specificity=94.09% avg_auc=90.19%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.288469 Test loss=0.322566 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.2833832800388336
[5/24] Train loss=0.2803804278373718
[10/24] Train loss=0.30444589257240295
[15/24] Train loss=0.2646508514881134
[20/24] Train loss=0.26925966143608093
Test set avg_accuracy=86.52% avg_sensitivity=61.01%, avg_specificity=93.92% avg_auc=90.21%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.288154 Test loss=0.322390 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.27726614475250244
[5/24] Train loss=0.27507510781288147
[10/24] Train loss=0.2967236042022705
[15/24] Train loss=0.2641560435295105
[20/24] Train loss=0.2652215361595154
Test set avg_accuracy=86.55% avg_sensitivity=60.66%, avg_specificity=94.05% avg_auc=90.19%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.286800 Test loss=0.323341 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.2805889844894409
[5/24] Train loss=0.27802711725234985
[10/24] Train loss=0.3010941743850708
[15/24] Train loss=0.26857057213783264
[20/24] Train loss=0.26780936121940613
Test set avg_accuracy=86.52% avg_sensitivity=59.79%, avg_specificity=94.27% avg_auc=90.19%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.287316 Test loss=0.323601 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.2789984941482544
[5/24] Train loss=0.27429696917533875
[10/24] Train loss=0.3007475733757019
[15/24] Train loss=0.2659056782722473
[20/24] Train loss=0.26492998003959656
Test set avg_accuracy=86.55% avg_sensitivity=59.39%, avg_specificity=94.42% avg_auc=90.20%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.286886 Test loss=0.323568 Current lr=[0.000123057953306828]

[0/24] Train loss=0.2836822271347046
[5/24] Train loss=0.2719350755214691
[10/24] Train loss=0.30275559425354004
[15/24] Train loss=0.26360803842544556
[20/24] Train loss=0.2686871886253357
Test set avg_accuracy=86.55% avg_sensitivity=59.15%, avg_specificity=94.49% avg_auc=90.20%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.286957 Test loss=0.323783 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.2834634780883789
[5/24] Train loss=0.2703254818916321
[10/24] Train loss=0.300740122795105
[15/24] Train loss=0.26351580023765564
[20/24] Train loss=0.26709049940109253
Test set avg_accuracy=86.59% avg_sensitivity=59.79%, avg_specificity=94.36% avg_auc=90.16%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.286152 Test loss=0.324076 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.281838059425354
[5/24] Train loss=0.2832498550415039
[10/24] Train loss=0.3003855049610138
[15/24] Train loss=0.2670454680919647
[20/24] Train loss=0.2686566114425659
Test set avg_accuracy=86.56% avg_sensitivity=59.62%, avg_specificity=94.37% avg_auc=90.14%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.287187 Test loss=0.324424 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.2812231779098511
[5/24] Train loss=0.27387046813964844
[10/24] Train loss=0.30225443840026855
[15/24] Train loss=0.26290687918663025
[20/24] Train loss=0.26679545640945435
Test set avg_accuracy=86.65% avg_sensitivity=59.97%, avg_specificity=94.39% avg_auc=90.18%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.287107 Test loss=0.323784 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.27867934107780457
[5/24] Train loss=0.2800389230251312
[10/24] Train loss=0.3014191687107086
[15/24] Train loss=0.26416122913360596
[20/24] Train loss=0.26241084933280945
Test set avg_accuracy=86.51% avg_sensitivity=61.30%, avg_specificity=93.82% avg_auc=90.26%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.288690 Test loss=0.322098 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.28098952770233154
[5/24] Train loss=0.2795851230621338
[10/24] Train loss=0.2989650070667267
[15/24] Train loss=0.2636081576347351
[20/24] Train loss=0.265198677778244
Test set avg_accuracy=86.30% avg_sensitivity=64.14%, avg_specificity=92.73% avg_auc=90.25%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.288119 Test loss=0.323340 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.2796373963356018
[5/24] Train loss=0.27386024594306946
[10/24] Train loss=0.298006147146225
[15/24] Train loss=0.2635470926761627
[20/24] Train loss=0.26198500394821167
Test set avg_accuracy=86.29% avg_sensitivity=65.87%, avg_specificity=92.21% avg_auc=90.28%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.287347 Test loss=0.324208 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.28384897112846375
[5/24] Train loss=0.2749752700328827
[10/24] Train loss=0.3025286793708801
[15/24] Train loss=0.26506945490837097
[20/24] Train loss=0.25993484258651733
Test set avg_accuracy=86.24% avg_sensitivity=64.14%, avg_specificity=92.64% avg_auc=90.28%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.286175 Test loss=0.323239 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.2779442071914673
[5/24] Train loss=0.2692786753177643
[10/24] Train loss=0.296927809715271
[15/24] Train loss=0.26452669501304626
[20/24] Train loss=0.26349154114723206
Test set avg_accuracy=86.68% avg_sensitivity=63.09%, avg_specificity=93.52% avg_auc=90.21%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.284643 Test loss=0.323560 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.27510830760002136
[5/24] Train loss=0.2671926021575928
[10/24] Train loss=0.29750603437423706
[15/24] Train loss=0.26268383860588074
[20/24] Train loss=0.2623863220214844
Test set avg_accuracy=86.63% avg_sensitivity=63.21%, avg_specificity=93.42% avg_auc=90.20%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.283951 Test loss=0.324138 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.27952831983566284
[5/24] Train loss=0.27493560314178467
[10/24] Train loss=0.29507002234458923
[15/24] Train loss=0.26105499267578125
[20/24] Train loss=0.27020031213760376
Test set avg_accuracy=86.37% avg_sensitivity=63.56%, avg_specificity=92.98% avg_auc=90.20%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.284327 Test loss=0.324455 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.2803037166595459
[5/24] Train loss=0.2703516185283661
[10/24] Train loss=0.2907969355583191
[15/24] Train loss=0.2587372958660126
[20/24] Train loss=0.26355069875717163
Test set avg_accuracy=86.58% avg_sensitivity=62.92%, avg_specificity=93.43% avg_auc=90.18%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.284618 Test loss=0.324467 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.2780519127845764
[5/24] Train loss=0.2749321162700653
[10/24] Train loss=0.2941780388355255
[15/24] Train loss=0.2661174535751343
[20/24] Train loss=0.2660762369632721
Test set avg_accuracy=86.47% avg_sensitivity=62.86%, avg_specificity=93.32% avg_auc=90.18%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.284757 Test loss=0.324543 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.2749451696872711
[5/24] Train loss=0.27454492449760437
[10/24] Train loss=0.29963138699531555
[15/24] Train loss=0.26220351457595825
[20/24] Train loss=0.2638167440891266
Test set avg_accuracy=86.39% avg_sensitivity=62.11%, avg_specificity=93.43% avg_auc=90.17%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.284175 Test loss=0.324744 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.28169798851013184
[5/24] Train loss=0.2722229063510895
[10/24] Train loss=0.2953818440437317
[15/24] Train loss=0.26394230127334595
[20/24] Train loss=0.263312429189682
Test set avg_accuracy=86.35% avg_sensitivity=62.11%, avg_specificity=93.38% avg_auc=90.16%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.284117 Test loss=0.324844 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.2779443860054016
[5/24] Train loss=0.26716506481170654
[10/24] Train loss=0.29248934984207153
[15/24] Train loss=0.2657027840614319
[20/24] Train loss=0.26389870047569275
Test set avg_accuracy=86.35% avg_sensitivity=61.94%, avg_specificity=93.43% avg_auc=90.16%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.283291 Test loss=0.324905 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.2782844305038452
[5/24] Train loss=0.2706584334373474
[10/24] Train loss=0.2970888912677765
[15/24] Train loss=0.26313987374305725
[20/24] Train loss=0.2624589800834656
Test set avg_accuracy=86.39% avg_sensitivity=62.11%, avg_specificity=93.43% avg_auc=90.15%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.284035 Test loss=0.325136 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.2825002074241638
[5/24] Train loss=0.2726881504058838
[10/24] Train loss=0.2977835536003113
[15/24] Train loss=0.2618519067764282
[20/24] Train loss=0.26119789481163025
Test set avg_accuracy=86.42% avg_sensitivity=62.11%, avg_specificity=93.47% avg_auc=90.14%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.284465 Test loss=0.325189 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.27411922812461853
[5/24] Train loss=0.2730167508125305
[10/24] Train loss=0.2939709424972534
[15/24] Train loss=0.2656715512275696
[20/24] Train loss=0.26305022835731506
Test set avg_accuracy=86.41% avg_sensitivity=62.05%, avg_specificity=93.47% avg_auc=90.14%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.284751 Test loss=0.325178 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.27990037202835083
[5/24] Train loss=0.2693876028060913
[10/24] Train loss=0.2956436276435852
[15/24] Train loss=0.26139411330223083
[20/24] Train loss=0.26158010959625244
Test set avg_accuracy=86.35% avg_sensitivity=61.82%, avg_specificity=93.47% avg_auc=90.14%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.285514 Test loss=0.325113 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.28215742111206055
[5/24] Train loss=0.27309852838516235
[10/24] Train loss=0.2964765429496765
[15/24] Train loss=0.25660252571105957
[20/24] Train loss=0.2689395844936371
Test set avg_accuracy=86.35% avg_sensitivity=61.82%, avg_specificity=93.47% avg_auc=90.14%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.284375 Test loss=0.325085 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.27666839957237244
[5/24] Train loss=0.2685518264770508
[10/24] Train loss=0.2969040274620056
[15/24] Train loss=0.2662867307662964
[20/24] Train loss=0.26248010993003845
Test set avg_accuracy=86.35% avg_sensitivity=61.82%, avg_specificity=93.47% avg_auc=90.15%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.283483 Test loss=0.325067 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.27555638551712036
[5/24] Train loss=0.2686915397644043
[10/24] Train loss=0.2972164452075958
[15/24] Train loss=0.26010534167289734
[20/24] Train loss=0.2636001706123352
Test set avg_accuracy=86.35% avg_sensitivity=61.82%, avg_specificity=93.47% avg_auc=90.15%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.283519 Test loss=0.325063 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.2806133031845093
[5/24] Train loss=0.26665613055229187
[10/24] Train loss=0.29748764634132385
[15/24] Train loss=0.2607227563858032
[20/24] Train loss=0.26325124502182007
Test set avg_accuracy=86.35% avg_sensitivity=61.82%, avg_specificity=93.47% avg_auc=90.15%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.283685 Test loss=0.325062 Current lr=[4.388541022775342e-09]

Fold[10] Result: acc=87.37% sen=57.65%, spe=95.99%, auc=91.17%!
Fold[10] Avg_jsc=0.54%(±0.2953559452269878)
Final Avg Result: avg_acc=84.48%(±1.78234869056124) avg_sen=62.93% (±9.047825979795846) avg_spe=91.85% (±3.021648111609857) avg_auc=89.31% (±1.6128565540924058) avg_jsc=0.55% (±0.048013760457618564)
