{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=2.057849884033203
[5/24] Train loss=1.9349303245544434
[10/24] Train loss=1.7950009107589722
[15/24] Train loss=1.7334259748458862
[20/24] Train loss=1.67813241481781
Test set avg_accuracy=51.89% avg_sensitivity=50.87%, avg_specificity=52.25% avg_auc=51.42%
Best model saved!! Metric=51.42187015135913!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=1.829981 Test loss=0.788489 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.6586253643035889
[5/24] Train loss=1.6121925115585327
[10/24] Train loss=1.5661677122116089
[15/24] Train loss=1.5929272174835205
[20/24] Train loss=1.5882506370544434
Test set avg_accuracy=50.83% avg_sensitivity=56.56%, avg_specificity=48.79% avg_auc=54.17%
Best model saved!! Metric=54.17043992662658!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=1.609904 Test loss=0.766202 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.579099178314209
[5/24] Train loss=1.5454427003860474
[10/24] Train loss=1.505900263786316
[15/24] Train loss=1.544179081916809
[20/24] Train loss=1.4958603382110596
Test set avg_accuracy=52.76% avg_sensitivity=57.05%, avg_specificity=51.23% avg_auc=56.31%
Best model saved!! Metric=56.306677045991464!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=1.547151 Test loss=0.728427 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.5256680250167847
[5/24] Train loss=1.5078171491622925
[10/24] Train loss=1.4613337516784668
[15/24] Train loss=1.4735383987426758
[20/24] Train loss=1.4918920993804932
Test set avg_accuracy=53.83% avg_sensitivity=59.03%, avg_specificity=51.97% avg_auc=58.22%
Best model saved!! Metric=58.2169688670095!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=1.495760 Test loss=0.707821 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.4820303916931152
[5/24] Train loss=1.461921215057373
[10/24] Train loss=1.4509323835372925
[15/24] Train loss=1.435994267463684
[20/24] Train loss=1.4265276193618774
Test set avg_accuracy=54.09% avg_sensitivity=62.05%, avg_specificity=51.25% avg_auc=59.97%
Best model saved!! Metric=59.967771689362756!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=1.452232 Test loss=0.692352 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.4410359859466553
[5/24] Train loss=1.413893222808838
[10/24] Train loss=1.428144931793213
[15/24] Train loss=1.4171260595321655
[20/24] Train loss=1.4060413837432861
Test set avg_accuracy=55.25% avg_sensitivity=64.57%, avg_specificity=51.92% avg_auc=61.56%
Best model saved!! Metric=61.56300267932424!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=1.421752 Test loss=0.679259 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.4225727319717407
[5/24] Train loss=1.3903005123138428
[10/24] Train loss=1.3809782266616821
[15/24] Train loss=1.3817793130874634
[20/24] Train loss=1.388216495513916
Test set avg_accuracy=55.69% avg_sensitivity=67.94%, avg_specificity=51.32% avg_auc=63.03%
Best model saved!! Metric=63.02892783574203!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=1.396289 Test loss=0.671542 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.4309755563735962
[5/24] Train loss=1.3658417463302612
[10/24] Train loss=1.3625714778900146
[15/24] Train loss=1.35525643825531
[20/24] Train loss=1.357839822769165
Test set avg_accuracy=55.99% avg_sensitivity=69.27%, avg_specificity=51.25% avg_auc=64.62%
Best model saved!! Metric=64.61544138201123!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=1.374229 Test loss=0.664441 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.4167839288711548
[5/24] Train loss=1.335298776626587
[10/24] Train loss=1.3444889783859253
[15/24] Train loss=1.3262507915496826
[20/24] Train loss=1.3605527877807617
Test set avg_accuracy=57.41% avg_sensitivity=69.97%, avg_specificity=52.92% avg_auc=66.36%
Best model saved!! Metric=66.35901318537404!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=1.352022 Test loss=0.653510 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.3611395359039307
[5/24] Train loss=1.3124384880065918
[10/24] Train loss=1.3291685581207275
[15/24] Train loss=1.3052887916564941
[20/24] Train loss=1.3200867176055908
Test set avg_accuracy=58.98% avg_sensitivity=72.04%, avg_specificity=54.32% avg_auc=68.17%
Best model saved!! Metric=68.16577552591237!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=1.329181 Test loss=0.646775 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.3431404829025269
[5/24] Train loss=1.2832667827606201
[10/24] Train loss=1.2964330911636353
[15/24] Train loss=1.2671183347702026
[20/24] Train loss=1.3060585260391235
Test set avg_accuracy=60.62% avg_sensitivity=73.58%, avg_specificity=56.00% avg_auc=70.13%
Best model saved!! Metric=70.13093827761325!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=1.305504 Test loss=0.639724 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.3093074560165405
[5/24] Train loss=1.2550184726715088
[10/24] Train loss=1.2820632457733154
[15/24] Train loss=1.2330849170684814
[20/24] Train loss=1.252432107925415
Test set avg_accuracy=62.14% avg_sensitivity=74.67%, avg_specificity=57.66% avg_auc=72.25%
Best model saved!! Metric=72.24503204075882!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=1.274879 Test loss=0.631375 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.274794340133667
[5/24] Train loss=1.2216522693634033
[10/24] Train loss=1.2442517280578613
[15/24] Train loss=1.207080602645874
[20/24] Train loss=1.2314077615737915
Test set avg_accuracy=63.61% avg_sensitivity=75.85%, avg_specificity=59.23% avg_auc=74.16%
Best model saved!! Metric=74.1619909137481!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=1.241404 Test loss=0.626848 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.2205816507339478
[5/24] Train loss=1.189052939414978
[10/24] Train loss=1.2054146528244019
[15/24] Train loss=1.1596769094467163
[20/24] Train loss=1.1698949337005615
Test set avg_accuracy=64.09% avg_sensitivity=79.42%, avg_specificity=58.61% avg_auc=75.61%
Best model saved!! Metric=75.6066164785567!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=1.201383 Test loss=0.631439 Current lr=[7.558439349929357e-05]

[0/24] Train loss=1.1760724782943726
[5/24] Train loss=1.1633681058883667
[10/24] Train loss=1.1649640798568726
[15/24] Train loss=1.105207920074463
[20/24] Train loss=1.1362943649291992
Test set avg_accuracy=64.22% avg_sensitivity=81.94%, avg_specificity=57.89% avg_auc=77.03%
Best model saved!! Metric=77.02523398292132!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=1.162337 Test loss=0.634097 Current lr=[8.412106591444728e-05]

[0/24] Train loss=1.1292027235031128
[5/24] Train loss=1.1110903024673462
[10/24] Train loss=1.1312509775161743
[15/24] Train loss=1.088693380355835
[20/24] Train loss=1.0853536128997803
Test set avg_accuracy=65.73% avg_sensitivity=81.35%, avg_specificity=60.15% avg_auc=78.55%
Best model saved!! Metric=78.55261405708343!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=1.122960 Test loss=0.608493 Current lr=[9.300857440308985e-05]

[0/24] Train loss=1.0923831462860107
[5/24] Train loss=1.0652962923049927
[10/24] Train loss=1.1147375106811523
[15/24] Train loss=1.031445860862732
[20/24] Train loss=1.058693528175354
Test set avg_accuracy=67.15% avg_sensitivity=82.38%, avg_specificity=61.71% avg_auc=79.90%
Best model saved!! Metric=79.89847107229542!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=1.087294 Test loss=0.591566 Current lr=[0.00010220353965498347]

[0/24] Train loss=1.048896312713623
[5/24] Train loss=1.0434178113937378
[10/24] Train loss=1.0768558979034424
[15/24] Train loss=0.983988344669342
[20/24] Train loss=1.0215842723846436
Test set avg_accuracy=67.10% avg_sensitivity=84.91%, avg_specificity=60.74% avg_auc=81.01%
Best model saved!! Metric=81.01103373056138!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=1.054640 Test loss=0.599885 Current lr=[0.0001116610816848323]

[0/24] Train loss=1.0239202976226807
[5/24] Train loss=1.011157751083374
[10/24] Train loss=1.0603936910629272
[15/24] Train loss=0.9712754487991333
[20/24] Train loss=1.011622667312622
Test set avg_accuracy=67.10% avg_sensitivity=85.01%, avg_specificity=60.70% avg_auc=81.84%
Best model saved!! Metric=81.83571964246416!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=1.029612 Test loss=0.598874 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.9835442900657654
[5/24] Train loss=0.9835498332977295
[10/24] Train loss=1.0450992584228516
[15/24] Train loss=0.9417440891265869
[20/24] Train loss=0.9909269213676453
Test set avg_accuracy=67.64% avg_sensitivity=86.10%, avg_specificity=61.05% avg_auc=82.52%
Best model saved!! Metric=82.51536110633366!!
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=1.005457 Test loss=0.597091 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.9725973010063171
[5/24] Train loss=0.9661016464233398
[10/24] Train loss=1.0083528757095337
[15/24] Train loss=0.921603798866272
[20/24] Train loss=0.959677517414093
Test set avg_accuracy=68.31% avg_sensitivity=85.90%, avg_specificity=62.03% avg_auc=83.01%
Best model saved!! Metric=83.00976344949859!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.987065 Test loss=0.587272 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.9453679919242859
[5/24] Train loss=0.9392794966697693
[10/24] Train loss=0.9855687618255615
[15/24] Train loss=0.8844989538192749
[20/24] Train loss=0.9298568367958069
Test set avg_accuracy=69.45% avg_sensitivity=84.96%, avg_specificity=63.92% avg_auc=83.48%
Best model saved!! Metric=83.47925506339644!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.964476 Test loss=0.570350 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.9311601519584656
[5/24] Train loss=0.929423451423645
[10/24] Train loss=0.9793775677680969
[15/24] Train loss=0.8933486938476562
[20/24] Train loss=0.9124525785446167
Test set avg_accuracy=70.70% avg_sensitivity=84.66%, avg_specificity=65.72% avg_auc=83.84%
Best model saved!! Metric=83.83754462225096!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.948566 Test loss=0.553708 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.8995997309684753
[5/24] Train loss=0.9184240102767944
[10/24] Train loss=0.9597428441047668
[15/24] Train loss=0.8722391128540039
[20/24] Train loss=0.8800600171089172
Test set avg_accuracy=71.97% avg_sensitivity=82.24%, avg_specificity=68.30% avg_auc=84.08%
Best model saved!! Metric=84.08235877063582!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.929156 Test loss=0.529211 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.8694003224372864
[5/24] Train loss=0.891974687576294
[10/24] Train loss=0.9415410757064819
[15/24] Train loss=0.8556472659111023
[20/24] Train loss=0.856442928314209
Test set avg_accuracy=72.49% avg_sensitivity=81.59%, avg_specificity=69.23% avg_auc=84.30%
Best model saved!! Metric=84.29545086714955!!
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.911438 Test loss=0.519340 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.860468864440918
[5/24] Train loss=0.8825388550758362
[10/24] Train loss=0.9247997999191284
[15/24] Train loss=0.8340253829956055
[20/24] Train loss=0.8405084013938904
Test set avg_accuracy=72.97% avg_sensitivity=80.95%, avg_specificity=70.12% avg_auc=84.55%
Best model saved!! Metric=84.54645553723367!!
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.892368 Test loss=0.510432 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.8268947601318359
[5/24] Train loss=0.8727899193763733
[10/24] Train loss=0.9045339226722717
[15/24] Train loss=0.835382878780365
[20/24] Train loss=0.8357628583908081
Test set avg_accuracy=73.37% avg_sensitivity=80.60%, avg_specificity=70.79% avg_auc=84.68%
Best model saved!! Metric=84.6825770652188!!
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.878393 Test loss=0.505185 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.8379422426223755
[5/24] Train loss=0.8608132004737854
[10/24] Train loss=0.8947075605392456
[15/24] Train loss=0.813452959060669
[20/24] Train loss=0.8180548548698425
Test set avg_accuracy=74.35% avg_sensitivity=79.56%, avg_specificity=72.49% avg_auc=84.87%
Best model saved!! Metric=84.8716459154492!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.867961 Test loss=0.491010 Current lr=[0.000210185142098938]

[0/24] Train loss=0.8161856532096863
[5/24] Train loss=0.8343372941017151
[10/24] Train loss=0.8742675185203552
[15/24] Train loss=0.8084923624992371
[20/24] Train loss=0.7903680801391602
Test set avg_accuracy=75.07% avg_sensitivity=78.87%, avg_specificity=73.71% avg_auc=85.08%
Best model saved!! Metric=85.07595499071027!!
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.853877 Test loss=0.484581 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.8023937940597534
[5/24] Train loss=0.8143635392189026
[10/24] Train loss=0.8654704093933105
[15/24] Train loss=0.7667135000228882
[20/24] Train loss=0.7829934358596802
Test set avg_accuracy=76.18% avg_sensitivity=77.63%, avg_specificity=75.67% avg_auc=85.30%
Best model saved!! Metric=85.30142813062247!!
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.839070 Test loss=0.469693 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7955526113510132
[5/24] Train loss=0.7971039414405823
[10/24] Train loss=0.8456152677536011
[15/24] Train loss=0.7694575190544128
[20/24] Train loss=0.7773081660270691
Test set avg_accuracy=76.05% avg_sensitivity=78.13%, avg_specificity=75.31% avg_auc=85.53%
Best model saved!! Metric=85.52934949945522!!
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.823674 Test loss=0.473079 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7873440384864807
[5/24] Train loss=0.7808734774589539
[10/24] Train loss=0.819952130317688
[15/24] Train loss=0.74560546875
[20/24] Train loss=0.7720727920532227
Test set avg_accuracy=76.63% avg_sensitivity=77.39%, avg_specificity=76.36% avg_auc=85.50%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.815443 Test loss=0.467089 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7663977742195129
[5/24] Train loss=0.7696616649627686
[10/24] Train loss=0.8162121176719666
[15/24] Train loss=0.7632991075515747
[20/24] Train loss=0.7568357586860657
Test set avg_accuracy=76.89% avg_sensitivity=76.40%, avg_specificity=77.06% avg_auc=85.60%
Best model saved!! Metric=85.59658835802443!!
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.803745 Test loss=0.460622 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7602682113647461
[5/24] Train loss=0.750707745552063
[10/24] Train loss=0.7994441390037537
[15/24] Train loss=0.7387029528617859
[20/24] Train loss=0.7304710149765015
Test set avg_accuracy=77.08% avg_sensitivity=76.84%, avg_specificity=77.17% avg_auc=85.70%
Best model saved!! Metric=85.70412244152426!!
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.788917 Test loss=0.460861 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.749052107334137
[5/24] Train loss=0.7423845529556274
[10/24] Train loss=0.7935320734977722
[15/24] Train loss=0.7193865776062012
[20/24] Train loss=0.722872793674469
Test set avg_accuracy=77.27% avg_sensitivity=75.80%, avg_specificity=77.79% avg_auc=85.53%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.775303 Test loss=0.458707 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7287738919258118
[5/24] Train loss=0.7137588858604431
[10/24] Train loss=0.7692142128944397
[15/24] Train loss=0.7038242816925049
[20/24] Train loss=0.6991117000579834
Test set avg_accuracy=77.51% avg_sensitivity=75.01%, avg_specificity=78.41% avg_auc=85.65%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.763826 Test loss=0.452588 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.7309837937355042
[5/24] Train loss=0.7154125571250916
[10/24] Train loss=0.7518368363380432
[15/24] Train loss=0.695216178894043
[20/24] Train loss=0.7046757340431213
Test set avg_accuracy=77.06% avg_sensitivity=76.30%, avg_specificity=77.33% avg_auc=85.80%
Best model saved!! Metric=85.80049522424858!!
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.745161 Test loss=0.457515 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.702023983001709
[5/24] Train loss=0.6962248086929321
[10/24] Train loss=0.7346310019493103
[15/24] Train loss=0.66336590051651
[20/24] Train loss=0.6864099502563477
Test set avg_accuracy=76.88% avg_sensitivity=75.75%, avg_specificity=77.28% avg_auc=85.70%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.729820 Test loss=0.460417 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.6967753171920776
[5/24] Train loss=0.6871764659881592
[10/24] Train loss=0.7273654341697693
[15/24] Train loss=0.666333794593811
[20/24] Train loss=0.6850466728210449
Test set avg_accuracy=77.45% avg_sensitivity=75.06%, avg_specificity=78.30% avg_auc=85.70%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.718865 Test loss=0.453962 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6780876517295837
[5/24] Train loss=0.6645466089248657
[10/24] Train loss=0.697824239730835
[15/24] Train loss=0.639685869216919
[20/24] Train loss=0.6689887642860413
Test set avg_accuracy=76.88% avg_sensitivity=76.45%, avg_specificity=77.03% avg_auc=85.74%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.707155 Test loss=0.462908 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.676223635673523
[5/24] Train loss=0.6568270921707153
[10/24] Train loss=0.6945045590400696
[15/24] Train loss=0.6203455924987793
[20/24] Train loss=0.6578466296195984
Test set avg_accuracy=77.54% avg_sensitivity=74.27%, avg_specificity=78.71% avg_auc=85.71%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.692811 Test loss=0.450614 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6589144468307495
[5/24] Train loss=0.6387826800346375
[10/24] Train loss=0.6888672113418579
[15/24] Train loss=0.6205874681472778
[20/24] Train loss=0.6435526013374329
Test set avg_accuracy=76.98% avg_sensitivity=76.10%, avg_specificity=77.29% avg_auc=85.74%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.677922 Test loss=0.464282 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6535598635673523
[5/24] Train loss=0.6128093004226685
[10/24] Train loss=0.692179262638092
[15/24] Train loss=0.6195687651634216
[20/24] Train loss=0.6454917192459106
Test set avg_accuracy=76.90% avg_sensitivity=73.58%, avg_specificity=78.09% avg_auc=85.43%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.667879 Test loss=0.458202 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6406750082969666
[5/24] Train loss=0.6062315106391907
[10/24] Train loss=0.6810320019721985
[15/24] Train loss=0.601195752620697
[20/24] Train loss=0.6371980309486389
Test set avg_accuracy=78.20% avg_sensitivity=69.92%, avg_specificity=81.16% avg_auc=85.36%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.659223 Test loss=0.439957 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6412219405174255
[5/24] Train loss=0.598508358001709
[10/24] Train loss=0.6495369076728821
[15/24] Train loss=0.6159701347351074
[20/24] Train loss=0.612943172454834
Test set avg_accuracy=78.24% avg_sensitivity=69.67%, avg_specificity=81.30% avg_auc=85.28%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.644244 Test loss=0.443746 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6437729597091675
[5/24] Train loss=0.5798869132995605
[10/24] Train loss=0.6501064300537109
[15/24] Train loss=0.5937561392784119
[20/24] Train loss=0.608457088470459
Test set avg_accuracy=78.14% avg_sensitivity=69.97%, avg_specificity=81.06% avg_auc=85.25%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.632125 Test loss=0.447293 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6057789325714111
[5/24] Train loss=0.5606297850608826
[10/24] Train loss=0.6448284387588501
[15/24] Train loss=0.587357759475708
[20/24] Train loss=0.5829853415489197
Test set avg_accuracy=78.07% avg_sensitivity=70.21%, avg_specificity=80.88% avg_auc=85.27%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.623729 Test loss=0.449406 Current lr=[0.000299720220882401]

[0/24] Train loss=0.593455970287323
[5/24] Train loss=0.5619237422943115
[10/24] Train loss=0.6305463314056396
[15/24] Train loss=0.5706649422645569
[20/24] Train loss=0.5808135271072388
Test set avg_accuracy=79.10% avg_sensitivity=66.16%, avg_specificity=83.73% avg_auc=85.05%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.612869 Test loss=0.435415 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.5973209738731384
[5/24] Train loss=0.5458881855010986
[10/24] Train loss=0.6288087964057922
[15/24] Train loss=0.5608193874359131
[20/24] Train loss=0.6014159321784973
Test set avg_accuracy=78.23% avg_sensitivity=70.66%, avg_specificity=80.93% avg_auc=85.28%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.609709 Test loss=0.449407 Current lr=[0.000298904600941902]

[0/24] Train loss=0.5515721440315247
[5/24] Train loss=0.604072630405426
[10/24] Train loss=0.596903920173645
[15/24] Train loss=0.5757635831832886
[20/24] Train loss=0.5603247880935669
Test set avg_accuracy=76.61% avg_sensitivity=76.25%, avg_specificity=76.75% avg_auc=85.55%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.613112 Test loss=0.484212 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.5620195865631104
[5/24] Train loss=0.5703541040420532
[10/24] Train loss=0.5802615880966187
[15/24] Train loss=0.5621885061264038
[20/24] Train loss=0.5611878633499146
Test set avg_accuracy=76.13% avg_sensitivity=78.43%, avg_specificity=75.31% avg_auc=85.82%
Best model saved!! Metric=85.81615514566568!!
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.587309 Test loss=0.497133 Current lr=[0.000297555943323901]

[0/24] Train loss=0.5663081407546997
[5/24] Train loss=0.5625268220901489
[10/24] Train loss=0.5809398889541626
[15/24] Train loss=0.5516622066497803
[20/24] Train loss=0.5219718217849731
Test set avg_accuracy=77.33% avg_sensitivity=73.97%, avg_specificity=78.53% avg_auc=85.55%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.579233 Test loss=0.467727 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.5299414992332458
[5/24] Train loss=0.5462126731872559
[10/24] Train loss=0.5717383027076721
[15/24] Train loss=0.5144062042236328
[20/24] Train loss=0.5286254286766052
Test set avg_accuracy=77.45% avg_sensitivity=73.23%, avg_specificity=78.95% avg_auc=85.36%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.559317 Test loss=0.467267 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.5275526642799377
[5/24] Train loss=0.5124519467353821
[10/24] Train loss=0.5500519275665283
[15/24] Train loss=0.5138012170791626
[20/24] Train loss=0.5150325894355774
Test set avg_accuracy=77.40% avg_sensitivity=73.92%, avg_specificity=78.64% avg_auc=85.39%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.543161 Test loss=0.478157 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.5092449188232422
[5/24] Train loss=0.5215661525726318
[10/24] Train loss=0.5183960199356079
[15/24] Train loss=0.5135695934295654
[20/24] Train loss=0.5213106274604797
Test set avg_accuracy=77.32% avg_sensitivity=73.03%, avg_specificity=78.85% avg_auc=85.18%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.538132 Test loss=0.478720 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.5134613513946533
[5/24] Train loss=0.5123490691184998
[10/24] Train loss=0.5144240260124207
[15/24] Train loss=0.49132615327835083
[20/24] Train loss=0.5098292231559753
Test set avg_accuracy=77.41% avg_sensitivity=73.23%, avg_specificity=78.90% avg_auc=85.23%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.528576 Test loss=0.481444 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.5128912329673767
[5/24] Train loss=0.47691887617111206
[10/24] Train loss=0.5289124250411987
[15/24] Train loss=0.4827001690864563
[20/24] Train loss=0.48367828130722046
Test set avg_accuracy=77.10% avg_sensitivity=74.02%, avg_specificity=78.19% avg_auc=85.08%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.519822 Test loss=0.489009 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.4967600107192993
[5/24] Train loss=0.48764169216156006
[10/24] Train loss=0.501379668712616
[15/24] Train loss=0.47421687841415405
[20/24] Train loss=0.49033528566360474
Test set avg_accuracy=77.73% avg_sensitivity=72.24%, avg_specificity=79.70% avg_auc=85.11%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.509724 Test loss=0.476043 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.4947963058948517
[5/24] Train loss=0.4654916226863861
[10/24] Train loss=0.4907684028148651
[15/24] Train loss=0.47454434633255005
[20/24] Train loss=0.48830753564834595
Test set avg_accuracy=78.19% avg_sensitivity=71.40%, avg_specificity=80.61% avg_auc=85.04%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.502452 Test loss=0.474160 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.4830506443977356
[5/24] Train loss=0.44979041814804077
[10/24] Train loss=0.4894910752773285
[15/24] Train loss=0.465405136346817
[20/24] Train loss=0.4898606240749359
Test set avg_accuracy=78.63% avg_sensitivity=69.77%, avg_specificity=81.80% avg_auc=84.81%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.492805 Test loss=0.468527 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.4758799970149994
[5/24] Train loss=0.4623759090900421
[10/24] Train loss=0.4901964068412781
[15/24] Train loss=0.4555276334285736
[20/24] Train loss=0.48176780343055725
Test set avg_accuracy=77.77% avg_sensitivity=72.93%, avg_specificity=79.50% avg_auc=84.90%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.492935 Test loss=0.485289 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.465203195810318
[5/24] Train loss=0.4332647919654846
[10/24] Train loss=0.4799618422985077
[15/24] Train loss=0.4496988356113434
[20/24] Train loss=0.4726269841194153
Test set avg_accuracy=77.77% avg_sensitivity=70.86%, avg_specificity=80.24% avg_auc=84.79%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.480306 Test loss=0.481050 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.46423834562301636
[5/24] Train loss=0.4422191083431244
[10/24] Train loss=0.46052420139312744
[15/24] Train loss=0.444969117641449
[20/24] Train loss=0.45729976892471313
Test set avg_accuracy=78.03% avg_sensitivity=70.16%, avg_specificity=80.84% avg_auc=84.68%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.476478 Test loss=0.479232 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.47727033495903015
[5/24] Train loss=0.4402565360069275
[10/24] Train loss=0.45656442642211914
[15/24] Train loss=0.46532028913497925
[20/24] Train loss=0.4729650914669037
Test set avg_accuracy=78.92% avg_sensitivity=67.94%, avg_specificity=82.84% avg_auc=84.51%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.477981 Test loss=0.466820 Current lr=[0.000276307469034998]

[0/24] Train loss=0.4510745704174042
[5/24] Train loss=0.41660210490226746
[10/24] Train loss=0.49204203486442566
[15/24] Train loss=0.44239529967308044
[20/24] Train loss=0.4537028968334198
Test set avg_accuracy=78.96% avg_sensitivity=67.59%, avg_specificity=83.02% avg_auc=84.27%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.466762 Test loss=0.468638 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.4638412594795227
[5/24] Train loss=0.4284237027168274
[10/24] Train loss=0.48584839701652527
[15/24] Train loss=0.4231128990650177
[20/24] Train loss=0.4513215124607086
Test set avg_accuracy=78.57% avg_sensitivity=69.17%, avg_specificity=81.92% avg_auc=84.50%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.461196 Test loss=0.477575 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.4421963393688202
[5/24] Train loss=0.4207168221473694
[10/24] Train loss=0.4729207158088684
[15/24] Train loss=0.4316469132900238
[20/24] Train loss=0.44492456316947937
Test set avg_accuracy=78.27% avg_sensitivity=71.65%, avg_specificity=80.63% avg_auc=84.84%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.456486 Test loss=0.483198 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.42845264077186584
[5/24] Train loss=0.4224644601345062
[10/24] Train loss=0.4601581394672394
[15/24] Train loss=0.4393990933895111
[20/24] Train loss=0.4511425197124481
Test set avg_accuracy=79.34% avg_sensitivity=67.14%, avg_specificity=83.69% avg_auc=84.57%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.458675 Test loss=0.466251 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4460159242153168
[5/24] Train loss=0.4162924587726593
[10/24] Train loss=0.45906805992126465
[15/24] Train loss=0.42215001583099365
[20/24] Train loss=0.43327340483665466
Test set avg_accuracy=79.66% avg_sensitivity=65.12%, avg_specificity=84.86% avg_auc=84.37%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.448192 Test loss=0.461351 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.4482055902481079
[5/24] Train loss=0.40976014733314514
[10/24] Train loss=0.4384194314479828
[15/24] Train loss=0.4273149073123932
[20/24] Train loss=0.4282703995704651
Test set avg_accuracy=78.20% avg_sensitivity=69.82%, avg_specificity=81.20% avg_auc=84.63%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.445326 Test loss=0.482160 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.43873223662376404
[5/24] Train loss=0.403000146150589
[10/24] Train loss=0.44643107056617737
[15/24] Train loss=0.43439409136772156
[20/24] Train loss=0.4113438129425049
Test set avg_accuracy=78.46% avg_sensitivity=69.17%, avg_specificity=81.78% avg_auc=84.67%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.441455 Test loss=0.479144 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.42447996139526367
[5/24] Train loss=0.41308271884918213
[10/24] Train loss=0.4449695646762848
[15/24] Train loss=0.4118848741054535
[20/24] Train loss=0.42054712772369385
Test set avg_accuracy=79.10% avg_sensitivity=66.16%, avg_specificity=83.73% avg_auc=84.35%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.438865 Test loss=0.468675 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4276638925075531
[5/24] Train loss=0.410431444644928
[10/24] Train loss=0.4327676296234131
[15/24] Train loss=0.4132855534553528
[20/24] Train loss=0.4153977930545807
Test set avg_accuracy=78.45% avg_sensitivity=68.09%, avg_specificity=82.15% avg_auc=84.59%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.436098 Test loss=0.475121 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.4109818935394287
[5/24] Train loss=0.4133739769458771
[10/24] Train loss=0.4149927794933319
[15/24] Train loss=0.42039042711257935
[20/24] Train loss=0.4327596426010132
Test set avg_accuracy=77.46% avg_sensitivity=72.59%, avg_specificity=79.20% avg_auc=84.88%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.435324 Test loss=0.495072 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.4060453772544861
[5/24] Train loss=0.460754930973053
[10/24] Train loss=0.45792368054389954
[15/24] Train loss=0.4107779264450073
[20/24] Train loss=0.42052823305130005
Test set avg_accuracy=77.76% avg_sensitivity=72.29%, avg_specificity=79.71% avg_auc=84.78%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.453730 Test loss=0.483638 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.4299321174621582
[5/24] Train loss=0.4246786832809448
[10/24] Train loss=0.6031667590141296
[15/24] Train loss=0.47156283259391785
[20/24] Train loss=0.5169709920883179
Test set avg_accuracy=72.19% avg_sensitivity=84.56%, avg_specificity=67.77% avg_auc=85.28%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.477483 Test loss=0.617154 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.5125739574432373
[5/24] Train loss=0.47094932198524475
[10/24] Train loss=0.459560364484787
[15/24] Train loss=0.43833547830581665
[20/24] Train loss=0.4116419553756714
Test set avg_accuracy=77.57% avg_sensitivity=75.26%, avg_specificity=78.39% avg_auc=85.09%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.490257 Test loss=0.489786 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.43990039825439453
[5/24] Train loss=0.41893771290779114
[10/24] Train loss=0.4328438639640808
[15/24] Train loss=0.4192013740539551
[20/24] Train loss=0.425937294960022
Test set avg_accuracy=75.07% avg_sensitivity=79.56%, avg_specificity=73.46% avg_auc=85.10%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.443584 Test loss=0.542951 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.42929980158805847
[5/24] Train loss=0.404462605714798
[10/24] Train loss=0.439343124628067
[15/24] Train loss=0.40516144037246704
[20/24] Train loss=0.40458133816719055
Test set avg_accuracy=76.24% avg_sensitivity=77.09%, avg_specificity=75.93% avg_auc=84.91%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.440396 Test loss=0.517979 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.4220884442329407
[5/24] Train loss=0.3889922797679901
[10/24] Train loss=0.4312637448310852
[15/24] Train loss=0.411264568567276
[20/24] Train loss=0.3933292031288147
Test set avg_accuracy=76.88% avg_sensitivity=74.96%, avg_specificity=77.56% avg_auc=84.88%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.427175 Test loss=0.503602 Current lr=[0.000224838296036774]

[0/24] Train loss=0.4135020077228546
[5/24] Train loss=0.3675437867641449
[10/24] Train loss=0.4346562922000885
[15/24] Train loss=0.41966497898101807
[20/24] Train loss=0.3818316161632538
Test set avg_accuracy=77.32% avg_sensitivity=73.82%, avg_specificity=78.57% avg_auc=84.96%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.418216 Test loss=0.498425 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3955543637275696
[5/24] Train loss=0.3593209683895111
[10/24] Train loss=0.40199434757232666
[15/24] Train loss=0.38997575640678406
[20/24] Train loss=0.3911009132862091
Test set avg_accuracy=77.11% avg_sensitivity=73.38%, avg_specificity=78.44% avg_auc=84.91%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.406154 Test loss=0.501071 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.40218400955200195
[5/24] Train loss=0.3438374996185303
[10/24] Train loss=0.4273702800273895
[15/24] Train loss=0.40466687083244324
[20/24] Train loss=0.37217023968696594
Test set avg_accuracy=77.15% avg_sensitivity=74.17%, avg_specificity=78.21% avg_auc=84.91%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.402562 Test loss=0.504987 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3979671001434326
[5/24] Train loss=0.36167776584625244
[10/24] Train loss=0.40937232971191406
[15/24] Train loss=0.37674301862716675
[20/24] Train loss=0.3737916648387909
Test set avg_accuracy=77.28% avg_sensitivity=74.07%, avg_specificity=78.42% avg_auc=84.96%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.401040 Test loss=0.508957 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.38606640696525574
[5/24] Train loss=0.3660857677459717
[10/24] Train loss=0.3959486782550812
[15/24] Train loss=0.3894919157028198
[20/24] Train loss=0.38488078117370605
Test set avg_accuracy=76.98% avg_sensitivity=73.68%, avg_specificity=78.16% avg_auc=84.71%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.395750 Test loss=0.509979 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.38209590315818787
[5/24] Train loss=0.3503586947917938
[10/24] Train loss=0.41115617752075195
[15/24] Train loss=0.38416120409965515
[20/24] Train loss=0.38840270042419434
Test set avg_accuracy=76.81% avg_sensitivity=74.57%, avg_specificity=77.61% avg_auc=84.86%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.394057 Test loss=0.515582 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.37707772850990295
[5/24] Train loss=0.35760822892189026
[10/24] Train loss=0.3911052942276001
[15/24] Train loss=0.3711341321468353
[20/24] Train loss=0.39157676696777344
Test set avg_accuracy=76.94% avg_sensitivity=75.85%, avg_specificity=77.33% avg_auc=85.14%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.390280 Test loss=0.521478 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3970523476600647
[5/24] Train loss=0.34741631150245667
[10/24] Train loss=0.376983642578125
[15/24] Train loss=0.3796341121196747
[20/24] Train loss=0.3970080018043518
Test set avg_accuracy=76.38% avg_sensitivity=77.19%, avg_specificity=76.09% avg_auc=85.22%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.391032 Test loss=0.532089 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.38860657811164856
[5/24] Train loss=0.3440820276737213
[10/24] Train loss=0.39454954862594604
[15/24] Train loss=0.36503031849861145
[20/24] Train loss=0.36448994278907776
Test set avg_accuracy=76.09% avg_sensitivity=77.29%, avg_specificity=75.67% avg_auc=85.23%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.391516 Test loss=0.533638 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3904096186161041
[5/24] Train loss=0.3693736493587494
[10/24] Train loss=0.4168088734149933
[15/24] Train loss=0.3851306438446045
[20/24] Train loss=0.35653024911880493
Test set avg_accuracy=78.23% avg_sensitivity=71.25%, avg_specificity=80.72% avg_auc=84.92%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.402551 Test loss=0.485123 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.38921090960502625
[5/24] Train loss=0.3385440409183502
[10/24] Train loss=0.4192756414413452
[15/24] Train loss=0.41946324706077576
[20/24] Train loss=0.38973256945610046
Test set avg_accuracy=79.69% avg_sensitivity=63.88%, avg_specificity=85.33% avg_auc=84.40%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.397195 Test loss=0.462800 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.4121902883052826
[5/24] Train loss=0.3500874936580658
[10/24] Train loss=0.39546728134155273
[15/24] Train loss=0.3664976954460144
[20/24] Train loss=0.37127894163131714
Test set avg_accuracy=78.44% avg_sensitivity=67.99%, avg_specificity=82.17% avg_auc=84.56%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.386316 Test loss=0.480374 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3744775950908661
[5/24] Train loss=0.33949995040893555
[10/24] Train loss=0.3918794095516205
[15/24] Train loss=0.36142560839653015
[20/24] Train loss=0.3737315833568573
Test set avg_accuracy=78.40% avg_sensitivity=69.03%, avg_specificity=81.75% avg_auc=84.65%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.384624 Test loss=0.482463 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3804880976676941
[5/24] Train loss=0.3297959864139557
[10/24] Train loss=0.39386993646621704
[15/24] Train loss=0.3660876154899597
[20/24] Train loss=0.3586801588535309
Test set avg_accuracy=78.50% avg_sensitivity=69.12%, avg_specificity=81.85% avg_auc=84.68%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.381677 Test loss=0.482346 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.367827445268631
[5/24] Train loss=0.348257839679718
[10/24] Train loss=0.3851436674594879
[15/24] Train loss=0.3790275454521179
[20/24] Train loss=0.3647385537624359
Test set avg_accuracy=78.65% avg_sensitivity=68.58%, avg_specificity=82.24% avg_auc=84.49%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.383448 Test loss=0.482890 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.37395212054252625
[5/24] Train loss=0.34033527970314026
[10/24] Train loss=0.3937860131263733
[15/24] Train loss=0.39300698041915894
[20/24] Train loss=0.3794204890727997
Test set avg_accuracy=78.88% avg_sensitivity=67.39%, avg_specificity=82.98% avg_auc=84.54%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.388308 Test loss=0.475314 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3676164150238037
[5/24] Train loss=0.3351563811302185
[10/24] Train loss=0.4079968333244324
[15/24] Train loss=0.4056715965270996
[20/24] Train loss=0.39150598645210266
Test set avg_accuracy=78.09% avg_sensitivity=72.69%, avg_specificity=80.01% avg_auc=84.99%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.397921 Test loss=0.494383 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3820068836212158
[5/24] Train loss=0.36297109723091125
[10/24] Train loss=0.4878443479537964
[15/24] Train loss=0.4828830361366272
[20/24] Train loss=0.395612508058548
Test set avg_accuracy=72.67% avg_sensitivity=84.66%, avg_specificity=68.39% avg_auc=85.48%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.436268 Test loss=0.632152 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.4929367005825043
[5/24] Train loss=0.4782167673110962
[10/24] Train loss=0.45850494503974915
[15/24] Train loss=0.38838279247283936
[20/24] Train loss=0.5047453045845032
Test set avg_accuracy=75.17% avg_sensitivity=80.06%, avg_specificity=73.42% avg_auc=85.43%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.454139 Test loss=0.559756 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.42594993114471436
[5/24] Train loss=0.34656769037246704
[10/24] Train loss=0.4014293849468231
[15/24] Train loss=0.3813261091709137
[20/24] Train loss=0.41106826066970825
Test set avg_accuracy=76.20% avg_sensitivity=78.33%, avg_specificity=75.44% avg_auc=85.58%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.405705 Test loss=0.545010 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.40735337138175964
[5/24] Train loss=0.3342796862125397
[10/24] Train loss=0.3978213965892792
[15/24] Train loss=0.35097038745880127
[20/24] Train loss=0.3943621516227722
Test set avg_accuracy=75.83% avg_sensitivity=78.82%, avg_specificity=74.77% avg_auc=85.71%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.392911 Test loss=0.559584 Current lr=[0.000134135431043539]

[0/24] Train loss=0.4033656418323517
[5/24] Train loss=0.3359486758708954
[10/24] Train loss=0.38956430554389954
[15/24] Train loss=0.3808959424495697
[20/24] Train loss=0.3838815689086914
Test set avg_accuracy=76.18% avg_sensitivity=78.48%, avg_specificity=75.37% avg_auc=85.71%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.387183 Test loss=0.552552 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.4001491069793701
[5/24] Train loss=0.31789711117744446
[10/24] Train loss=0.3848043382167816
[15/24] Train loss=0.3733924329280853
[20/24] Train loss=0.3857739567756653
Test set avg_accuracy=76.48% avg_sensitivity=78.48%, avg_specificity=75.77% avg_auc=85.68%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.383137 Test loss=0.546228 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3879565894603729
[5/24] Train loss=0.32069045305252075
[10/24] Train loss=0.38320428133010864
[15/24] Train loss=0.3705373704433441
[20/24] Train loss=0.3603322505950928
Test set avg_accuracy=76.71% avg_sensitivity=78.13%, avg_specificity=76.20% avg_auc=85.71%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.376657 Test loss=0.539455 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3763270080089569
[5/24] Train loss=0.3241664171218872
[10/24] Train loss=0.38538897037506104
[15/24] Train loss=0.36733773350715637
[20/24] Train loss=0.35887426137924194
Test set avg_accuracy=76.51% avg_sensitivity=77.93%, avg_specificity=76.00% avg_auc=85.66%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.371990 Test loss=0.541575 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.38911715149879456
[5/24] Train loss=0.3202999234199524
[10/24] Train loss=0.39309370517730713
[15/24] Train loss=0.348882794380188
[20/24] Train loss=0.3695976436138153
Test set avg_accuracy=77.07% avg_sensitivity=77.34%, avg_specificity=76.97% avg_auc=85.58%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.369682 Test loss=0.535535 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.36583977937698364
[5/24] Train loss=0.3176518380641937
[10/24] Train loss=0.3787405788898468
[15/24] Train loss=0.3521348237991333
[20/24] Train loss=0.35603898763656616
Test set avg_accuracy=76.78% avg_sensitivity=77.68%, avg_specificity=76.46% avg_auc=85.53%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.363864 Test loss=0.538839 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3735300898551941
[5/24] Train loss=0.31531983613967896
[10/24] Train loss=0.37949416041374207
[15/24] Train loss=0.3458336889743805
[20/24] Train loss=0.3526346683502197
Test set avg_accuracy=77.23% avg_sensitivity=76.79%, avg_specificity=77.38% avg_auc=85.54%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.364622 Test loss=0.533419 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.35674870014190674
[5/24] Train loss=0.3137976825237274
[10/24] Train loss=0.38437721133232117
[15/24] Train loss=0.3417908847332001
[20/24] Train loss=0.34808820486068726
Test set avg_accuracy=76.72% avg_sensitivity=77.78%, avg_specificity=76.34% avg_auc=85.59%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.359763 Test loss=0.542808 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3715170919895172
[5/24] Train loss=0.3126589059829712
[10/24] Train loss=0.37608587741851807
[15/24] Train loss=0.35222136974334717
[20/24] Train loss=0.3470432460308075
Test set avg_accuracy=77.25% avg_sensitivity=76.50%, avg_specificity=77.52% avg_auc=85.55%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.360643 Test loss=0.530580 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3551587164402008
[5/24] Train loss=0.3062700629234314
[10/24] Train loss=0.3955933451652527
[15/24] Train loss=0.35799098014831543
[20/24] Train loss=0.35599976778030396
Test set avg_accuracy=77.58% avg_sensitivity=76.15%, avg_specificity=78.09% avg_auc=85.51%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.358495 Test loss=0.526984 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3566122055053711
[5/24] Train loss=0.3131248950958252
[10/24] Train loss=0.3717893064022064
[15/24] Train loss=0.3510430157184601
[20/24] Train loss=0.33980733156204224
Test set avg_accuracy=77.46% avg_sensitivity=76.35%, avg_specificity=77.86% avg_auc=85.52%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.354898 Test loss=0.531101 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3575398325920105
[5/24] Train loss=0.31030529737472534
[10/24] Train loss=0.3743840157985687
[15/24] Train loss=0.34657740592956543
[20/24] Train loss=0.34638261795043945
Test set avg_accuracy=77.30% avg_sensitivity=76.30%, avg_specificity=77.66% avg_auc=85.54%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.356712 Test loss=0.530983 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3470793664455414
[5/24] Train loss=0.3115091621875763
[10/24] Train loss=0.36794593930244446
[15/24] Train loss=0.35680973529815674
[20/24] Train loss=0.34315842390060425
Test set avg_accuracy=77.49% avg_sensitivity=75.80%, avg_specificity=78.09% avg_auc=85.46%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.353425 Test loss=0.529810 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.35689106583595276
[5/24] Train loss=0.30051520466804504
[10/24] Train loss=0.37275397777557373
[15/24] Train loss=0.3393826484680176
[20/24] Train loss=0.3273935317993164
Test set avg_accuracy=77.21% avg_sensitivity=76.25%, avg_specificity=77.56% avg_auc=85.46%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.352044 Test loss=0.537120 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.36074143648147583
[5/24] Train loss=0.3078455328941345
[10/24] Train loss=0.3587549924850464
[15/24] Train loss=0.34394368529319763
[20/24] Train loss=0.3371993601322174
Test set avg_accuracy=77.63% avg_sensitivity=75.36%, avg_specificity=78.44% avg_auc=85.41%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.350045 Test loss=0.528907 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3512861430644989
[5/24] Train loss=0.31491827964782715
[10/24] Train loss=0.3617493212223053
[15/24] Train loss=0.36228975653648376
[20/24] Train loss=0.3316376805305481
Test set avg_accuracy=77.60% avg_sensitivity=75.31%, avg_specificity=78.42% avg_auc=85.39%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.350889 Test loss=0.527083 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.354358434677124
[5/24] Train loss=0.3026212155818939
[10/24] Train loss=0.353018194437027
[15/24] Train loss=0.3586771786212921
[20/24] Train loss=0.34617799520492554
Test set avg_accuracy=77.42% avg_sensitivity=75.41%, avg_specificity=78.14% avg_auc=85.42%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.351129 Test loss=0.528866 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3462943434715271
[5/24] Train loss=0.3050256073474884
[10/24] Train loss=0.36520183086395264
[15/24] Train loss=0.3416854441165924
[20/24] Train loss=0.34572991728782654
Test set avg_accuracy=77.46% avg_sensitivity=75.36%, avg_specificity=78.21% avg_auc=85.37%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.348698 Test loss=0.528049 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.35677534341812134
[5/24] Train loss=0.30237942934036255
[10/24] Train loss=0.35766929388046265
[15/24] Train loss=0.35659143328666687
[20/24] Train loss=0.341971218585968
Test set avg_accuracy=77.49% avg_sensitivity=75.41%, avg_specificity=78.23% avg_auc=85.33%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.348486 Test loss=0.529404 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3351515531539917
[5/24] Train loss=0.2996590733528137
[10/24] Train loss=0.37048694491386414
[15/24] Train loss=0.33780866861343384
[20/24] Train loss=0.3344411849975586
Test set avg_accuracy=77.72% avg_sensitivity=75.26%, avg_specificity=78.60% avg_auc=85.43%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.344436 Test loss=0.525281 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.34513846039772034
[5/24] Train loss=0.30846235156059265
[10/24] Train loss=0.36767247319221497
[15/24] Train loss=0.35583600401878357
[20/24] Train loss=0.34254011511802673
Test set avg_accuracy=77.77% avg_sensitivity=75.06%, avg_specificity=78.74% avg_auc=85.34%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.346956 Test loss=0.526104 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3436810076236725
[5/24] Train loss=0.2963419556617737
[10/24] Train loss=0.35091879963874817
[15/24] Train loss=0.3425051271915436
[20/24] Train loss=0.34295064210891724
Test set avg_accuracy=78.18% avg_sensitivity=74.02%, avg_specificity=79.66% avg_auc=85.32%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.346597 Test loss=0.517792 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.334527850151062
[5/24] Train loss=0.291118323802948
[10/24] Train loss=0.3707929253578186
[15/24] Train loss=0.3435458540916443
[20/24] Train loss=0.32614099979400635
Test set avg_accuracy=77.54% avg_sensitivity=75.46%, avg_specificity=78.28% avg_auc=85.36%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.345065 Test loss=0.529515 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.33978381752967834
[5/24] Train loss=0.2991607189178467
[10/24] Train loss=0.35394784808158875
[15/24] Train loss=0.3363756239414215
[20/24] Train loss=0.32466328144073486
Test set avg_accuracy=77.85% avg_sensitivity=74.57%, avg_specificity=79.02% avg_auc=85.33%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.342519 Test loss=0.523198 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3347986340522766
[5/24] Train loss=0.29172396659851074
[10/24] Train loss=0.35533756017684937
[15/24] Train loss=0.32984742522239685
[20/24] Train loss=0.32563185691833496
Test set avg_accuracy=77.75% avg_sensitivity=74.72%, avg_specificity=78.83% avg_auc=85.36%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.342731 Test loss=0.524444 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.33946293592453003
[5/24] Train loss=0.30965501070022583
[10/24] Train loss=0.3568461239337921
[15/24] Train loss=0.3481804132461548
[20/24] Train loss=0.333028107881546
Test set avg_accuracy=77.93% avg_sensitivity=74.52%, avg_specificity=79.15% avg_auc=85.31%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.345147 Test loss=0.522771 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3403683304786682
[5/24] Train loss=0.3081737756729126
[10/24] Train loss=0.3633997440338135
[15/24] Train loss=0.3323960304260254
[20/24] Train loss=0.3336641490459442
Test set avg_accuracy=77.86% avg_sensitivity=73.92%, avg_specificity=79.27% avg_auc=85.25%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.340882 Test loss=0.520673 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3332417905330658
[5/24] Train loss=0.29670923948287964
[10/24] Train loss=0.3442816734313965
[15/24] Train loss=0.3392954170703888
[20/24] Train loss=0.31751665472984314
Test set avg_accuracy=77.72% avg_sensitivity=74.42%, avg_specificity=78.90% avg_auc=85.29%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.339316 Test loss=0.524430 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3286815881729126
[5/24] Train loss=0.2943747341632843
[10/24] Train loss=0.3464753031730652
[15/24] Train loss=0.34923097491264343
[20/24] Train loss=0.3234926462173462
Test set avg_accuracy=77.49% avg_sensitivity=74.86%, avg_specificity=78.42% avg_auc=85.30%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.340999 Test loss=0.528769 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3335261642932892
[5/24] Train loss=0.2997763156890869
[10/24] Train loss=0.3655346632003784
[15/24] Train loss=0.33674973249435425
[20/24] Train loss=0.33459457755088806
Test set avg_accuracy=77.76% avg_sensitivity=74.72%, avg_specificity=78.85% avg_auc=85.32%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.342378 Test loss=0.525683 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3298867642879486
[5/24] Train loss=0.2977350056171417
[10/24] Train loss=0.3696543276309967
[15/24] Train loss=0.34331244230270386
[20/24] Train loss=0.3374476432800293
Test set avg_accuracy=77.71% avg_sensitivity=74.91%, avg_specificity=78.71% avg_auc=85.30%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.342275 Test loss=0.526443 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3357298970222473
[5/24] Train loss=0.29103827476501465
[10/24] Train loss=0.3587563931941986
[15/24] Train loss=0.33262258768081665
[20/24] Train loss=0.3257012665271759
Test set avg_accuracy=77.63% avg_sensitivity=75.21%, avg_specificity=78.49% avg_auc=85.35%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.338240 Test loss=0.529285 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.33547866344451904
[5/24] Train loss=0.28769946098327637
[10/24] Train loss=0.35810166597366333
[15/24] Train loss=0.34155797958374023
[20/24] Train loss=0.3377681374549866
Test set avg_accuracy=77.70% avg_sensitivity=74.86%, avg_specificity=78.71% avg_auc=85.34%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.340057 Test loss=0.526605 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.34090518951416016
[5/24] Train loss=0.28903162479400635
[10/24] Train loss=0.3592621684074402
[15/24] Train loss=0.33712103962898254
[20/24] Train loss=0.3321501910686493
Test set avg_accuracy=77.67% avg_sensitivity=75.01%, avg_specificity=78.62% avg_auc=85.29%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.340292 Test loss=0.526944 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3300115168094635
[5/24] Train loss=0.3037964105606079
[10/24] Train loss=0.3490338623523712
[15/24] Train loss=0.3406180143356323
[20/24] Train loss=0.3458012342453003
Test set avg_accuracy=77.77% avg_sensitivity=74.67%, avg_specificity=78.88% avg_auc=85.31%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.340470 Test loss=0.525233 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.33078446984291077
[5/24] Train loss=0.3052830398082733
[10/24] Train loss=0.3487957715988159
[15/24] Train loss=0.33331751823425293
[20/24] Train loss=0.33003875613212585
Test set avg_accuracy=77.59% avg_sensitivity=75.01%, avg_specificity=78.51% avg_auc=85.31%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.337495 Test loss=0.528118 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.32608461380004883
[5/24] Train loss=0.30187880992889404
[10/24] Train loss=0.351271390914917
[15/24] Train loss=0.3347562849521637
[20/24] Train loss=0.32990482449531555
Test set avg_accuracy=77.67% avg_sensitivity=74.67%, avg_specificity=78.74% avg_auc=85.30%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.337777 Test loss=0.525959 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3370627760887146
[5/24] Train loss=0.29534658789634705
[10/24] Train loss=0.3492957651615143
[15/24] Train loss=0.3431395888328552
[20/24] Train loss=0.32805952429771423
Test set avg_accuracy=77.68% avg_sensitivity=74.86%, avg_specificity=78.69% avg_auc=85.29%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.339766 Test loss=0.526320 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.33264854550361633
[5/24] Train loss=0.2818417549133301
[10/24] Train loss=0.36062800884246826
[15/24] Train loss=0.3345258831977844
[20/24] Train loss=0.33569177985191345
Test set avg_accuracy=77.66% avg_sensitivity=75.11%, avg_specificity=78.57% avg_auc=85.31%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.338488 Test loss=0.527953 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.33028802275657654
[5/24] Train loss=0.294477641582489
[10/24] Train loss=0.3631734549999237
[15/24] Train loss=0.34683477878570557
[20/24] Train loss=0.3364034593105316
Test set avg_accuracy=77.67% avg_sensitivity=75.01%, avg_specificity=78.62% avg_auc=85.32%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.340391 Test loss=0.527610 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3351943790912628
[5/24] Train loss=0.27915599942207336
[10/24] Train loss=0.35429251194000244
[15/24] Train loss=0.34363120794296265
[20/24] Train loss=0.34157800674438477
Test set avg_accuracy=77.79% avg_sensitivity=74.86%, avg_specificity=78.83% avg_auc=85.31%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.339257 Test loss=0.526402 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.32767125964164734
[5/24] Train loss=0.29867473244667053
[10/24] Train loss=0.3551981449127197
[15/24] Train loss=0.33894914388656616
[20/24] Train loss=0.33148059248924255
Test set avg_accuracy=77.75% avg_sensitivity=74.72%, avg_specificity=78.83% avg_auc=85.29%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.339447 Test loss=0.525872 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.32930171489715576
[5/24] Train loss=0.3004973828792572
[10/24] Train loss=0.35696595907211304
[15/24] Train loss=0.3322954475879669
[20/24] Train loss=0.3255469501018524
Test set avg_accuracy=77.75% avg_sensitivity=74.76%, avg_specificity=78.81% avg_auc=85.28%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.338728 Test loss=0.526089 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.32838180661201477
[5/24] Train loss=0.29277095198631287
[10/24] Train loss=0.3564900755882263
[15/24] Train loss=0.3391037583351135
[20/24] Train loss=0.3288314938545227
Test set avg_accuracy=77.71% avg_sensitivity=74.57%, avg_specificity=78.83% avg_auc=85.28%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.339104 Test loss=0.525684 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3406721353530884
[5/24] Train loss=0.3019563555717468
[10/24] Train loss=0.3512963056564331
[15/24] Train loss=0.33357203006744385
[20/24] Train loss=0.3182850480079651
Test set avg_accuracy=77.72% avg_sensitivity=74.76%, avg_specificity=78.78% avg_auc=85.28%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.337492 Test loss=0.526088 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.32619786262512207
[5/24] Train loss=0.2926633954048157
[10/24] Train loss=0.36012282967567444
[15/24] Train loss=0.3395904302597046
[20/24] Train loss=0.3287314474582672
Test set avg_accuracy=77.71% avg_sensitivity=74.91%, avg_specificity=78.71% avg_auc=85.29%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.337949 Test loss=0.526749 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.331253319978714
[5/24] Train loss=0.2990080714225769
[10/24] Train loss=0.3581603169441223
[15/24] Train loss=0.33381038904190063
[20/24] Train loss=0.32246634364128113
Test set avg_accuracy=77.70% avg_sensitivity=74.91%, avg_specificity=78.69% avg_auc=85.29%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.337124 Test loss=0.526966 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.32191094756126404
[5/24] Train loss=0.2998291850090027
[10/24] Train loss=0.3492492139339447
[15/24] Train loss=0.3464714288711548
[20/24] Train loss=0.32196083664894104
Test set avg_accuracy=77.70% avg_sensitivity=74.91%, avg_specificity=78.69% avg_auc=85.29%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.338726 Test loss=0.526866 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.33273565769195557
[5/24] Train loss=0.3093659579753876
[10/24] Train loss=0.35902929306030273
[15/24] Train loss=0.34655991196632385
[20/24] Train loss=0.32616063952445984
Test set avg_accuracy=77.70% avg_sensitivity=74.91%, avg_specificity=78.69% avg_auc=85.29%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.340830 Test loss=0.526857 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=76.13% sen=78.43%, spe=75.31%, auc=85.82%!
Fold[1] Avg_jsc=0.55%(±0.21532978495793945)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.9111998081207275
[5/24] Train loss=1.7953288555145264
[10/24] Train loss=1.6725752353668213
[15/24] Train loss=1.6295807361602783
[20/24] Train loss=1.551406979560852
Test set avg_accuracy=56.59% avg_sensitivity=38.55%, avg_specificity=62.59% avg_auc=50.57%
Best model saved!! Metric=50.56586134760892!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=1.690342 Test loss=0.680803 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.5277940034866333
[5/24] Train loss=1.5137686729431152
[10/24] Train loss=1.516213297843933
[15/24] Train loss=1.525518536567688
[20/24] Train loss=1.5209333896636963
Test set avg_accuracy=51.73% avg_sensitivity=51.85%, avg_specificity=51.69% avg_auc=52.13%
Best model saved!! Metric=52.13186562126986!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=1.522861 Test loss=0.703506 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.5122162103652954
[5/24] Train loss=1.518293023109436
[10/24] Train loss=1.4989502429962158
[15/24] Train loss=1.5091230869293213
[20/24] Train loss=1.5126105546951294
Test set avg_accuracy=53.66% avg_sensitivity=47.73%, avg_specificity=55.63% avg_auc=53.33%
Best model saved!! Metric=53.330579811799254!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=1.503219 Test loss=0.686042 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.5250141620635986
[5/24] Train loss=1.4930033683776855
[10/24] Train loss=1.4925079345703125
[15/24] Train loss=1.511064052581787
[20/24] Train loss=1.460476279258728
Test set avg_accuracy=55.29% avg_sensitivity=47.57%, avg_specificity=57.85% avg_auc=54.61%
Best model saved!! Metric=54.60985396831604!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=1.485409 Test loss=0.683207 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.492020606994629
[5/24] Train loss=1.4986258745193481
[10/24] Train loss=1.4855599403381348
[15/24] Train loss=1.471120834350586
[20/24] Train loss=1.4179881811141968
Test set avg_accuracy=55.44% avg_sensitivity=50.50%, avg_specificity=57.09% avg_auc=56.17%
Best model saved!! Metric=56.16753522077187!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=1.466955 Test loss=0.682107 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.4572854042053223
[5/24] Train loss=1.4526921510696411
[10/24] Train loss=1.4483221769332886
[15/24] Train loss=1.44778573513031
[20/24] Train loss=1.4512355327606201
Test set avg_accuracy=57.79% avg_sensitivity=48.04%, avg_specificity=61.03% avg_auc=57.74%
Best model saved!! Metric=57.73768516459261!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=1.457208 Test loss=0.676727 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.4222184419631958
[5/24] Train loss=1.4346591234207153
[10/24] Train loss=1.4339587688446045
[15/24] Train loss=1.4418091773986816
[20/24] Train loss=1.4197758436203003
Test set avg_accuracy=59.14% avg_sensitivity=48.72%, avg_specificity=62.61% avg_auc=59.28%
Best model saved!! Metric=59.28068006369849!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=1.443106 Test loss=0.672450 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.418751835823059
[5/24] Train loss=1.4355255365371704
[10/24] Train loss=1.4240163564682007
[15/24] Train loss=1.4249098300933838
[20/24] Train loss=1.429101586341858
Test set avg_accuracy=61.04% avg_sensitivity=48.57%, avg_specificity=65.19% avg_auc=60.85%
Best model saved!! Metric=60.8472681708208!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=1.432721 Test loss=0.667000 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.4277067184448242
[5/24] Train loss=1.394166111946106
[10/24] Train loss=1.414320945739746
[15/24] Train loss=1.413686990737915
[20/24] Train loss=1.4042887687683105
Test set avg_accuracy=61.77% avg_sensitivity=51.49%, avg_specificity=65.19% avg_auc=62.35%
Best model saved!! Metric=62.347063919626144!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=1.420437 Test loss=0.663215 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.4116302728652954
[5/24] Train loss=1.4048378467559814
[10/24] Train loss=1.3695894479751587
[15/24] Train loss=1.388388991355896
[20/24] Train loss=1.3923463821411133
Test set avg_accuracy=61.98% avg_sensitivity=57.38%, avg_specificity=63.51% avg_auc=64.89%
Best model saved!! Metric=64.89213427879959!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=1.406569 Test loss=0.662615 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.3970484733581543
[5/24] Train loss=1.37562894821167
[10/24] Train loss=1.3763364553451538
[15/24] Train loss=1.3789912462234497
[20/24] Train loss=1.3717690706253052
Test set avg_accuracy=61.81% avg_sensitivity=64.32%, avg_specificity=60.98% avg_auc=67.35%
Best model saved!! Metric=67.35029039152234!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=1.390570 Test loss=0.662494 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.3613083362579346
[5/24] Train loss=1.3717290163040161
[10/24] Train loss=1.357422113418579
[15/24] Train loss=1.3557124137878418
[20/24] Train loss=1.323378086090088
Test set avg_accuracy=66.43% avg_sensitivity=61.66%, avg_specificity=68.02% avg_auc=69.83%
Best model saved!! Metric=69.8318269977446!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=1.370771 Test loss=0.637543 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.3528457880020142
[5/24] Train loss=1.3382219076156616
[10/24] Train loss=1.303951621055603
[15/24] Train loss=1.3517705202102661
[20/24] Train loss=1.2976362705230713
Test set avg_accuracy=68.58% avg_sensitivity=63.22%, avg_specificity=70.36% avg_auc=72.10%
Best model saved!! Metric=72.09702388856438!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=1.345893 Test loss=0.619606 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.3025482892990112
[5/24] Train loss=1.2992908954620361
[10/24] Train loss=1.276808738708496
[15/24] Train loss=1.3207613229751587
[20/24] Train loss=1.2709604501724243
Test set avg_accuracy=67.76% avg_sensitivity=72.72%, avg_specificity=66.11% avg_auc=74.01%
Best model saved!! Metric=74.00962157544336!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=1.315580 Test loss=0.626101 Current lr=[7.558439349929357e-05]

[0/24] Train loss=1.2607346773147583
[5/24] Train loss=1.2798315286636353
[10/24] Train loss=1.2281676530838013
[15/24] Train loss=1.2663838863372803
[20/24] Train loss=1.2470052242279053
Test set avg_accuracy=64.91% avg_sensitivity=81.01%, avg_specificity=59.55% avg_auc=75.64%
Best model saved!! Metric=75.64216023449649!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=1.281284 Test loss=0.655415 Current lr=[8.412106591444728e-05]

[0/24] Train loss=1.2129899263381958
[5/24] Train loss=1.242408037185669
[10/24] Train loss=1.200899600982666
[15/24] Train loss=1.2391941547393799
[20/24] Train loss=1.2336230278015137
Test set avg_accuracy=66.50% avg_sensitivity=81.79%, avg_specificity=61.41% avg_auc=76.98%
Best model saved!! Metric=76.97727421462858!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=1.246569 Test loss=0.638742 Current lr=[9.300857440308985e-05]

[0/24] Train loss=1.1835777759552002
[5/24] Train loss=1.2091703414916992
[10/24] Train loss=1.2081116437911987
[15/24] Train loss=1.237354040145874
[20/24] Train loss=1.159906268119812
Test set avg_accuracy=66.68% avg_sensitivity=82.99%, avg_specificity=61.25% avg_auc=77.96%
Best model saved!! Metric=77.95566142402322!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=1.219902 Test loss=0.633726 Current lr=[0.00010220353965498347]

[0/24] Train loss=1.1459161043167114
[5/24] Train loss=1.1731613874435425
[10/24] Train loss=1.1917425394058228
[15/24] Train loss=1.2418357133865356
[20/24] Train loss=1.1405315399169922
Test set avg_accuracy=66.55% avg_sensitivity=84.25%, avg_specificity=60.66% avg_auc=78.78%
Best model saved!! Metric=78.77720562098564!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=1.200887 Test loss=0.634088 Current lr=[0.0001116610816848323]

[0/24] Train loss=1.1273479461669922
[5/24] Train loss=1.1529910564422607
[10/24] Train loss=1.1635103225708008
[15/24] Train loss=1.2097967863082886
[20/24] Train loss=1.1310336589813232
Test set avg_accuracy=66.18% avg_sensitivity=85.13%, avg_specificity=59.88% avg_auc=79.55%
Best model saved!! Metric=79.55283968901682!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=1.176251 Test loss=0.638523 Current lr=[0.00012133503888836635]

[0/24] Train loss=1.1313406229019165
[5/24] Train loss=1.1337459087371826
[10/24] Train loss=1.116580843925476
[15/24] Train loss=1.1757742166519165
[20/24] Train loss=1.099745512008667
Test set avg_accuracy=67.58% avg_sensitivity=84.82%, avg_specificity=61.84% avg_auc=80.33%
Best model saved!! Metric=80.3256270031937!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=1.151234 Test loss=0.621894 Current lr=[0.00013117819335391835]

[0/24] Train loss=1.0739456415176392
[5/24] Train loss=1.0897505283355713
[10/24] Train loss=1.1179144382476807
[15/24] Train loss=1.1556336879730225
[20/24] Train loss=1.0660778284072876
Test set avg_accuracy=68.95% avg_sensitivity=84.51%, avg_specificity=63.77% avg_auc=81.13%
Best model saved!! Metric=81.13479302560694!!
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=1.126719 Test loss=0.606511 Current lr=[0.00014114250132976375]

[0/24] Train loss=1.0437768697738647
[5/24] Train loss=1.0636272430419922
[10/24] Train loss=1.0933698415756226
[15/24] Train loss=1.1403864622116089
[20/24] Train loss=1.0406345129013062
Test set avg_accuracy=69.99% avg_sensitivity=83.88%, avg_specificity=65.37% avg_auc=81.77%
Best model saved!! Metric=81.77390058049339!!
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=1.105522 Test loss=0.591131 Current lr=[0.00015117932772232805]

[0/24] Train loss=1.0160878896713257
[5/24] Train loss=1.03432297706604
[10/24] Train loss=1.091724157333374
[15/24] Train loss=1.1050151586532593
[20/24] Train loss=0.999134361743927
Test set avg_accuracy=71.55% avg_sensitivity=82.16%, avg_specificity=68.02% avg_auc=82.37%
Best model saved!! Metric=82.371886346!!
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=1.084376 Test loss=0.568874 Current lr=[0.00016123968348069324]

[0/24] Train loss=1.0003973245620728
[5/24] Train loss=1.0066359043121338
[10/24] Train loss=1.0538820028305054
[15/24] Train loss=1.068461537361145
[20/24] Train loss=0.9955599904060364
Test set avg_accuracy=72.41% avg_sensitivity=82.58%, avg_specificity=69.03% avg_auc=82.95%
Best model saved!! Metric=82.94548688135264!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=1.061951 Test loss=0.562900 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.9688418507575989
[5/24] Train loss=0.9682228565216064
[10/24] Train loss=1.0298439264297485
[15/24] Train loss=1.0481621026992798
[20/24] Train loss=0.9690514802932739
Test set avg_accuracy=73.63% avg_sensitivity=81.12%, avg_specificity=71.14% avg_auc=83.55%
Best model saved!! Metric=83.5485234851762!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=1.037470 Test loss=0.544251 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.9264737367630005
[5/24] Train loss=0.9532557725906372
[10/24] Train loss=0.9914783835411072
[15/24] Train loss=0.9949575066566467
[20/24] Train loss=0.9445561170578003
Test set avg_accuracy=74.62% avg_sensitivity=81.59%, avg_specificity=72.31% avg_auc=84.21%
Best model saved!! Metric=84.20878934573632!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=1.013094 Test loss=0.533170 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.9181939959526062
[5/24] Train loss=0.9196265339851379
[10/24] Train loss=0.9775142073631287
[15/24] Train loss=0.9836517572402954
[20/24] Train loss=0.9315780997276306
Test set avg_accuracy=75.16% avg_sensitivity=82.42%, avg_specificity=72.74% avg_auc=84.81%
Best model saved!! Metric=84.8091330742923!!
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.993860 Test loss=0.527520 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.8971327543258667
[5/24] Train loss=0.8868200182914734
[10/24] Train loss=0.9406782984733582
[15/24] Train loss=0.9401782751083374
[20/24] Train loss=0.91246497631073
Test set avg_accuracy=75.40% avg_sensitivity=83.20%, avg_specificity=72.81% avg_auc=85.30%
Best model saved!! Metric=85.30440488316496!!
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.970583 Test loss=0.526051 Current lr=[0.000210185142098938]

[0/24] Train loss=0.8789122104644775
[5/24] Train loss=0.8623191118240356
[10/24] Train loss=0.9105893969535828
[15/24] Train loss=0.9160096049308777
[20/24] Train loss=0.8870306015014648
Test set avg_accuracy=75.40% avg_sensitivity=83.83%, avg_specificity=72.60% avg_auc=85.78%
Best model saved!! Metric=85.7771380049243!!
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.948416 Test loss=0.524813 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.8664867877960205
[5/24] Train loss=0.8466755151748657
[10/24] Train loss=0.8748253583908081
[15/24] Train loss=0.9020060896873474
[20/24] Train loss=0.8708375692367554
Test set avg_accuracy=75.87% avg_sensitivity=83.93%, avg_specificity=73.19% avg_auc=86.09%
Best model saved!! Metric=86.09206411016405!!
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.931468 Test loss=0.519344 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.8488925099372864
[5/24] Train loss=0.8185288906097412
[10/24] Train loss=0.8400317430496216
[15/24] Train loss=0.8647105097770691
[20/24] Train loss=0.8555411100387573
Test set avg_accuracy=76.46% avg_sensitivity=84.19%, avg_specificity=73.89% avg_auc=86.36%
Best model saved!! Metric=86.36308955978144!!
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.915869 Test loss=0.510899 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.8366551399230957
[5/24] Train loss=0.8050134181976318
[10/24] Train loss=0.8306979537010193
[15/24] Train loss=0.8684656620025635
[20/24] Train loss=0.8362842798233032
Test set avg_accuracy=76.65% avg_sensitivity=84.51%, avg_specificity=74.04% avg_auc=86.53%
Best model saved!! Metric=86.53185816268424!!
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.898193 Test loss=0.510180 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.8216338157653809
[5/24] Train loss=0.7816879749298096
[10/24] Train loss=0.8224570155143738
[15/24] Train loss=0.8263189792633057
[20/24] Train loss=0.8125784397125244
Test set avg_accuracy=77.27% avg_sensitivity=84.09%, avg_specificity=75.00% avg_auc=86.79%
Best model saved!! Metric=86.792818142394!!
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.881368 Test loss=0.495744 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7966591119766235
[5/24] Train loss=0.7736173272132874
[10/24] Train loss=0.7906193137168884
[15/24] Train loss=0.8258092403411865
[20/24] Train loss=0.7904141545295715
Test set avg_accuracy=77.67% avg_sensitivity=84.09%, avg_specificity=75.53% avg_auc=87.01%
Best model saved!! Metric=87.00572274464002!!
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.865982 Test loss=0.489413 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7813670039176941
[5/24] Train loss=0.7486423850059509
[10/24] Train loss=0.7794719934463501
[15/24] Train loss=0.7883715629577637
[20/24] Train loss=0.7662432789802551
Test set avg_accuracy=78.50% avg_sensitivity=81.95%, avg_specificity=77.36% avg_auc=87.19%
Best model saved!! Metric=87.18555250242336!!
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.847793 Test loss=0.466838 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7563509941101074
[5/24] Train loss=0.7411338090896606
[10/24] Train loss=0.7954238653182983
[15/24] Train loss=0.7808716297149658
[20/24] Train loss=0.763949453830719
Test set avg_accuracy=79.87% avg_sensitivity=80.07%, avg_specificity=79.80% avg_auc=87.43%
Best model saved!! Metric=87.4323918588814!!
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.832493 Test loss=0.443111 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.728797197341919
[5/24] Train loss=0.7246727347373962
[10/24] Train loss=0.7601850032806396
[15/24] Train loss=0.7595440149307251
[20/24] Train loss=0.7549082636833191
Test set avg_accuracy=80.38% avg_sensitivity=79.24%, avg_specificity=80.76% avg_auc=87.55%
Best model saved!! Metric=87.55091457738014!!
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.819009 Test loss=0.436975 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.7186205983161926
[5/24] Train loss=0.7094351053237915
[10/24] Train loss=0.7535699605941772
[15/24] Train loss=0.745335042476654
[20/24] Train loss=0.7540667653083801
Test set avg_accuracy=80.64% avg_sensitivity=78.25%, avg_specificity=81.43% avg_auc=87.61%
Best model saved!! Metric=87.6074423287949!!
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.803690 Test loss=0.430083 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.7205680012702942
[5/24] Train loss=0.6947256326675415
[10/24] Train loss=0.7308502793312073
[15/24] Train loss=0.7202861309051514
[20/24] Train loss=0.7309911847114563
Test set avg_accuracy=81.29% avg_sensitivity=77.73%, avg_specificity=82.47% avg_auc=87.69%
Best model saved!! Metric=87.68933741781413!!
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.793352 Test loss=0.423665 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.7074861526489258
[5/24] Train loss=0.6845442652702332
[10/24] Train loss=0.7359979152679443
[15/24] Train loss=0.7147387266159058
[20/24] Train loss=0.716037929058075
Test set avg_accuracy=81.76% avg_sensitivity=76.37%, avg_specificity=83.55% avg_auc=87.76%
Best model saved!! Metric=87.75779981138105!!
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.778699 Test loss=0.415564 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6847596764564514
[5/24] Train loss=0.6975763440132141
[10/24] Train loss=0.711167573928833
[15/24] Train loss=0.7008405327796936
[20/24] Train loss=0.6962141990661621
Test set avg_accuracy=81.76% avg_sensitivity=76.00%, avg_specificity=83.67% avg_auc=87.72%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.763996 Test loss=0.416811 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6716710925102234
[5/24] Train loss=0.6823887228965759
[10/24] Train loss=0.7017126083374023
[15/24] Train loss=0.6885574460029602
[20/24] Train loss=0.6810916066169739
Test set avg_accuracy=81.64% avg_sensitivity=76.42%, avg_specificity=83.38% avg_auc=87.78%
Best model saved!! Metric=87.78001263795781!!
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.753203 Test loss=0.419048 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6659183502197266
[5/24] Train loss=0.6655398607254028
[10/24] Train loss=0.704392671585083
[15/24] Train loss=0.6716002225875854
[20/24] Train loss=0.6704515218734741
Test set avg_accuracy=81.67% avg_sensitivity=75.01%, avg_specificity=83.88% avg_auc=87.78%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.742394 Test loss=0.415743 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6569300889968872
[5/24] Train loss=0.6699414849281311
[10/24] Train loss=0.6851096153259277
[15/24] Train loss=0.6676866412162781
[20/24] Train loss=0.6650859713554382
Test set avg_accuracy=81.56% avg_sensitivity=75.27%, avg_specificity=83.65% avg_auc=87.75%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.730060 Test loss=0.418430 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6352211236953735
[5/24] Train loss=0.6826329827308655
[10/24] Train loss=0.7046989798545837
[15/24] Train loss=0.6484256982803345
[20/24] Train loss=0.6465986967086792
Test set avg_accuracy=81.68% avg_sensitivity=74.60%, avg_specificity=84.04% avg_auc=87.76%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.719182 Test loss=0.417144 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.630932092666626
[5/24] Train loss=0.6626355648040771
[10/24] Train loss=0.6735559701919556
[15/24] Train loss=0.6299315690994263
[20/24] Train loss=0.6297100186347961
Test set avg_accuracy=81.46% avg_sensitivity=74.65%, avg_specificity=83.72% avg_auc=87.75%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.706050 Test loss=0.420175 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6128117442131042
[5/24] Train loss=0.6444066762924194
[10/24] Train loss=0.6562636494636536
[15/24] Train loss=0.6291016936302185
[20/24] Train loss=0.6258994936943054
Test set avg_accuracy=81.39% avg_sensitivity=75.33%, avg_specificity=83.41% avg_auc=87.68%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.697947 Test loss=0.425547 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6048645377159119
[5/24] Train loss=0.6617360711097717
[10/24] Train loss=0.6487327218055725
[15/24] Train loss=0.6296585202217102
[20/24] Train loss=0.6198248863220215
Test set avg_accuracy=81.77% avg_sensitivity=74.49%, avg_specificity=84.19% avg_auc=87.71%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.687096 Test loss=0.420821 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.5978967547416687
[5/24] Train loss=0.6413989067077637
[10/24] Train loss=0.6380836963653564
[15/24] Train loss=0.6216806173324585
[20/24] Train loss=0.6091513633728027
Test set avg_accuracy=81.59% avg_sensitivity=75.38%, avg_specificity=83.65% avg_auc=87.67%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.674047 Test loss=0.423722 Current lr=[0.000298904600941902]

[0/24] Train loss=0.5897828936576843
[5/24] Train loss=0.6241183876991272
[10/24] Train loss=0.6224185228347778
[15/24] Train loss=0.6135777831077576
[20/24] Train loss=0.6097341179847717
Test set avg_accuracy=81.48% avg_sensitivity=75.64%, avg_specificity=83.43% avg_auc=87.54%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.662186 Test loss=0.430858 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.5729079842567444
[5/24] Train loss=0.6092594265937805
[10/24] Train loss=0.6230627298355103
[15/24] Train loss=0.5871001482009888
[20/24] Train loss=0.6027733087539673
Test set avg_accuracy=81.41% avg_sensitivity=74.54%, avg_specificity=83.69% avg_auc=87.62%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.653219 Test loss=0.424866 Current lr=[0.000297555943323901]

[0/24] Train loss=0.5632939338684082
[5/24] Train loss=0.6077100038528442
[10/24] Train loss=0.60866379737854
[15/24] Train loss=0.5939545035362244
[20/24] Train loss=0.5849799513816833
Test set avg_accuracy=81.08% avg_sensitivity=75.59%, avg_specificity=82.91% avg_auc=87.62%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.641906 Test loss=0.431495 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.5661206841468811
[5/24] Train loss=0.5795415639877319
[10/24] Train loss=0.597721517086029
[15/24] Train loss=0.5827977657318115
[20/24] Train loss=0.5763813257217407
Test set avg_accuracy=80.69% avg_sensitivity=75.69%, avg_specificity=82.35% avg_auc=87.54%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.630298 Test loss=0.436669 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.5484375953674316
[5/24] Train loss=0.5835486650466919
[10/24] Train loss=0.5854950547218323
[15/24] Train loss=0.5822980403900146
[20/24] Train loss=0.5719260573387146
Test set avg_accuracy=80.81% avg_sensitivity=76.37%, avg_specificity=82.28% avg_auc=87.61%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.625570 Test loss=0.436279 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.5467174053192139
[5/24] Train loss=0.5759124159812927
[10/24] Train loss=0.5727397203445435
[15/24] Train loss=0.5739133954048157
[20/24] Train loss=0.5472238063812256
Test set avg_accuracy=81.12% avg_sensitivity=74.60%, avg_specificity=83.29% avg_auc=87.48%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.612110 Test loss=0.430770 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.5398409962654114
[5/24] Train loss=0.5605617761611938
[10/24] Train loss=0.5736362934112549
[15/24] Train loss=0.5736157298088074
[20/24] Train loss=0.5460776090621948
Test set avg_accuracy=80.66% avg_sensitivity=75.38%, avg_specificity=82.42% avg_auc=87.51%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.606238 Test loss=0.437768 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.5247921943664551
[5/24] Train loss=0.5590576529502869
[10/24] Train loss=0.5667492151260376
[15/24] Train loss=0.5715696215629578
[20/24] Train loss=0.539574921131134
Test set avg_accuracy=79.90% avg_sensitivity=77.41%, avg_specificity=80.72% avg_auc=87.37%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.598549 Test loss=0.455512 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.5321197509765625
[5/24] Train loss=0.5519015192985535
[10/24] Train loss=0.5490210652351379
[15/24] Train loss=0.5497300624847412
[20/24] Train loss=0.5310492515563965
Test set avg_accuracy=80.26% avg_sensitivity=76.53%, avg_specificity=81.50% avg_auc=87.37%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.586074 Test loss=0.449151 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.5285742878913879
[5/24] Train loss=0.533307671546936
[10/24] Train loss=0.5469374656677246
[15/24] Train loss=0.535977303981781
[20/24] Train loss=0.5246666073799133
Test set avg_accuracy=80.43% avg_sensitivity=75.12%, avg_specificity=82.20% avg_auc=87.36%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.574840 Test loss=0.443101 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.502729594707489
[5/24] Train loss=0.5347889065742493
[10/24] Train loss=0.5307223796844482
[15/24] Train loss=0.5443270206451416
[20/24] Train loss=0.5204628705978394
Test set avg_accuracy=80.17% avg_sensitivity=76.42%, avg_specificity=81.42% avg_auc=87.29%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.568219 Test loss=0.453621 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.511366605758667
[5/24] Train loss=0.5387600660324097
[10/24] Train loss=0.5254748463630676
[15/24] Train loss=0.5322414040565491
[20/24] Train loss=0.5048660039901733
Test set avg_accuracy=80.92% avg_sensitivity=73.45%, avg_specificity=83.41% avg_auc=87.16%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.558656 Test loss=0.435342 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.4952228367328644
[5/24] Train loss=0.5057638883590698
[10/24] Train loss=0.5265533328056335
[15/24] Train loss=0.5288904309272766
[20/24] Train loss=0.49501746892929077
Test set avg_accuracy=80.44% avg_sensitivity=74.07%, avg_specificity=82.56% avg_auc=87.10%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.553869 Test loss=0.444921 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.48850518465042114
[5/24] Train loss=0.5304533243179321
[10/24] Train loss=0.5114525556564331
[15/24] Train loss=0.5540177226066589
[20/24] Train loss=0.5117637515068054
Test set avg_accuracy=78.46% avg_sensitivity=80.86%, avg_specificity=77.67% avg_auc=87.15%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.556783 Test loss=0.496337 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.48953261971473694
[5/24] Train loss=0.4845278561115265
[10/24] Train loss=0.5033645629882812
[15/24] Train loss=0.515201210975647
[20/24] Train loss=0.5002710223197937
Test set avg_accuracy=79.74% avg_sensitivity=76.79%, avg_specificity=80.72% avg_auc=87.21%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.544688 Test loss=0.461258 Current lr=[0.000276307469034998]

[0/24] Train loss=0.47086361050605774
[5/24] Train loss=0.5078009963035583
[10/24] Train loss=0.5206226706504822
[15/24] Train loss=0.512959897518158
[20/24] Train loss=0.4937741756439209
Test set avg_accuracy=80.43% avg_sensitivity=75.85%, avg_specificity=81.95% avg_auc=87.22%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.536467 Test loss=0.451650 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.45874878764152527
[5/24] Train loss=0.49317336082458496
[10/24] Train loss=0.5036719441413879
[15/24] Train loss=0.5009368062019348
[20/24] Train loss=0.4734630882740021
Test set avg_accuracy=81.02% avg_sensitivity=72.61%, avg_specificity=83.81% avg_auc=87.19%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.531989 Test loss=0.439589 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.47003936767578125
[5/24] Train loss=0.47772523760795593
[10/24] Train loss=0.5123398900032043
[15/24] Train loss=0.50188148021698
[20/24] Train loss=0.47866958379745483
Test set avg_accuracy=81.73% avg_sensitivity=68.81%, avg_specificity=86.03% avg_auc=87.21%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.529436 Test loss=0.422436 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.46841344237327576
[5/24] Train loss=0.5055586099624634
[10/24] Train loss=0.5480636358261108
[15/24] Train loss=0.5150344371795654
[20/24] Train loss=0.4806665778160095
Test set avg_accuracy=80.64% avg_sensitivity=74.49%, avg_specificity=82.68% avg_auc=87.16%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.532650 Test loss=0.446599 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4474926292896271
[5/24] Train loss=0.4669550061225891
[10/24] Train loss=0.48463717103004456
[15/24] Train loss=0.47700080275535583
[20/24] Train loss=0.46331143379211426
Test set avg_accuracy=80.17% avg_sensitivity=75.59%, avg_specificity=81.69% avg_auc=87.11%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.514520 Test loss=0.459466 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.44433555006980896
[5/24] Train loss=0.4703547954559326
[10/24] Train loss=0.49423715472221375
[15/24] Train loss=0.481889933347702
[20/24] Train loss=0.4407057464122772
Test set avg_accuracy=79.91% avg_sensitivity=74.70%, avg_specificity=81.64% avg_auc=87.05%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.509862 Test loss=0.458743 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.44257864356040955
[5/24] Train loss=0.46781936287879944
[10/24] Train loss=0.48294609785079956
[15/24] Train loss=0.4883791506290436
[20/24] Train loss=0.44986745715141296
Test set avg_accuracy=79.88% avg_sensitivity=75.22%, avg_specificity=81.43% avg_auc=86.96%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.500741 Test loss=0.461944 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.43203186988830566
[5/24] Train loss=0.45594292879104614
[10/24] Train loss=0.4665832221508026
[15/24] Train loss=0.47429314255714417
[20/24] Train loss=0.44592663645744324
Test set avg_accuracy=79.52% avg_sensitivity=76.00%, avg_specificity=80.69% avg_auc=87.04%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.492838 Test loss=0.469196 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4367343485355377
[5/24] Train loss=0.44197359681129456
[10/24] Train loss=0.4684290289878845
[15/24] Train loss=0.4630519151687622
[20/24] Train loss=0.42132073640823364
Test set avg_accuracy=79.83% avg_sensitivity=75.43%, avg_specificity=81.29% avg_auc=87.02%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.491533 Test loss=0.464466 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.4259166419506073
[5/24] Train loss=0.4544826149940491
[10/24] Train loss=0.4597139060497284
[15/24] Train loss=0.46095654368400574
[20/24] Train loss=0.42246100306510925
Test set avg_accuracy=79.45% avg_sensitivity=75.59%, avg_specificity=80.74% avg_auc=87.01%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.482775 Test loss=0.470930 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.44152623414993286
[5/24] Train loss=0.43312686681747437
[10/24] Train loss=0.45758405327796936
[15/24] Train loss=0.4570228159427643
[20/24] Train loss=0.4324018061161041
Test set avg_accuracy=79.15% avg_sensitivity=77.20%, avg_specificity=79.80% avg_auc=86.97%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.481518 Test loss=0.483546 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.4279123544692993
[5/24] Train loss=0.4432356655597687
[10/24] Train loss=0.4468061029911041
[15/24] Train loss=0.4535447061061859
[20/24] Train loss=0.42793917655944824
Test set avg_accuracy=78.53% avg_sensitivity=79.08%, avg_specificity=78.34% avg_auc=87.01%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.476241 Test loss=0.501561 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.4259817898273468
[5/24] Train loss=0.44685453176498413
[10/24] Train loss=0.4579451382160187
[15/24] Train loss=0.4594711661338806
[20/24] Train loss=0.41963887214660645
Test set avg_accuracy=78.88% avg_sensitivity=78.20%, avg_specificity=79.11% avg_auc=87.01%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.474667 Test loss=0.494214 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.43073198199272156
[5/24] Train loss=0.4410403072834015
[10/24] Train loss=0.4613005518913269
[15/24] Train loss=0.46222078800201416
[20/24] Train loss=0.4345916509628296
Test set avg_accuracy=81.37% avg_sensitivity=71.41%, avg_specificity=84.68% avg_auc=87.12%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.480713 Test loss=0.439570 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.4214481711387634
[5/24] Train loss=0.45451903343200684
[10/24] Train loss=0.5019041299819946
[15/24] Train loss=0.46135878562927246
[20/24] Train loss=0.41577789187431335
Test set avg_accuracy=80.38% avg_sensitivity=73.97%, avg_specificity=82.51% avg_auc=86.95%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.476035 Test loss=0.457581 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.41138842701911926
[5/24] Train loss=0.445765882730484
[10/24] Train loss=0.500787079334259
[15/24] Train loss=0.4566981792449951
[20/24] Train loss=0.42215850949287415
Test set avg_accuracy=80.44% avg_sensitivity=74.33%, avg_specificity=82.47% avg_auc=87.02%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.468925 Test loss=0.459744 Current lr=[0.000224838296036774]

[0/24] Train loss=0.41335394978523254
[5/24] Train loss=0.43547385931015015
[10/24] Train loss=0.4668121635913849
[15/24] Train loss=0.4212155044078827
[20/24] Train loss=0.46727603673934937
Test set avg_accuracy=81.91% avg_sensitivity=68.75%, avg_specificity=86.29% avg_auc=86.99%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.475959 Test loss=0.434905 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.4383728802204132
[5/24] Train loss=0.4300820231437683
[10/24] Train loss=0.4270382225513458
[15/24] Train loss=0.4745008051395416
[20/24] Train loss=0.40811362862586975
Test set avg_accuracy=81.35% avg_sensitivity=71.10%, avg_specificity=84.76% avg_auc=86.96%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.472956 Test loss=0.441800 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.4032190144062042
[5/24] Train loss=0.4250577390193939
[10/24] Train loss=0.424701988697052
[15/24] Train loss=0.4473108649253845
[20/24] Train loss=0.4210035502910614
Test set avg_accuracy=80.53% avg_sensitivity=73.03%, avg_specificity=83.03% avg_auc=86.85%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.460868 Test loss=0.457137 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.39964595437049866
[5/24] Train loss=0.39763861894607544
[10/24] Train loss=0.430497944355011
[15/24] Train loss=0.44453102350234985
[20/24] Train loss=0.4077794551849365
Test set avg_accuracy=79.90% avg_sensitivity=74.70%, avg_specificity=81.62% avg_auc=86.79%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.454916 Test loss=0.470055 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3890162408351898
[5/24] Train loss=0.4010569453239441
[10/24] Train loss=0.42295631766319275
[15/24] Train loss=0.4389679431915283
[20/24] Train loss=0.3973579704761505
Test set avg_accuracy=79.83% avg_sensitivity=74.54%, avg_specificity=81.59% avg_auc=86.76%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.447406 Test loss=0.469567 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3952294886112213
[5/24] Train loss=0.3977009654045105
[10/24] Train loss=0.43195316195487976
[15/24] Train loss=0.4649076461791992
[20/24] Train loss=0.3973950147628784
Test set avg_accuracy=79.56% avg_sensitivity=75.27%, avg_specificity=80.98% avg_auc=86.73%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.450971 Test loss=0.476083 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3869587779045105
[5/24] Train loss=0.4009985327720642
[10/24] Train loss=0.4199383854866028
[15/24] Train loss=0.4667844772338867
[20/24] Train loss=0.406649649143219
Test set avg_accuracy=78.07% avg_sensitivity=79.50%, avg_specificity=77.60% avg_auc=86.65%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.455780 Test loss=0.514579 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.41011255979537964
[5/24] Train loss=0.40199899673461914
[10/24] Train loss=0.4125996232032776
[15/24] Train loss=0.47369125485420227
[20/24] Train loss=0.4784219264984131
Test set avg_accuracy=75.59% avg_sensitivity=83.36%, avg_specificity=73.00% avg_auc=86.28%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.473323 Test loss=0.576143 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.46529436111450195
[5/24] Train loss=0.5244771838188171
[10/24] Train loss=0.4975418150424957
[15/24] Train loss=0.47725391387939453
[20/24] Train loss=0.4057518243789673
Test set avg_accuracy=80.77% avg_sensitivity=73.14%, avg_specificity=83.31% avg_auc=87.00%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.485296 Test loss=0.448266 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3922823965549469
[5/24] Train loss=0.3955982029438019
[10/24] Train loss=0.4277937412261963
[15/24] Train loss=0.4379245340824127
[20/24] Train loss=0.390595018863678
Test set avg_accuracy=79.57% avg_sensitivity=77.36%, avg_specificity=80.31% avg_auc=86.97%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.445598 Test loss=0.482906 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3848240077495575
[5/24] Train loss=0.41057121753692627
[10/24] Train loss=0.4370148181915283
[15/24] Train loss=0.4327685534954071
[20/24] Train loss=0.38200998306274414
Test set avg_accuracy=80.34% avg_sensitivity=74.39%, avg_specificity=82.32% avg_auc=86.94%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.444096 Test loss=0.461305 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3817255198955536
[5/24] Train loss=0.3998985290527344
[10/24] Train loss=0.4206802546977997
[15/24] Train loss=0.42060524225234985
[20/24] Train loss=0.367482453584671
Test set avg_accuracy=80.17% avg_sensitivity=74.28%, avg_specificity=82.13% avg_auc=86.85%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.432878 Test loss=0.464676 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.37855663895606995
[5/24] Train loss=0.3846791386604309
[10/24] Train loss=0.4310855269432068
[15/24] Train loss=0.4018765985965729
[20/24] Train loss=0.3760078251361847
Test set avg_accuracy=79.93% avg_sensitivity=74.39%, avg_specificity=81.78% avg_auc=86.83%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.428620 Test loss=0.469242 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3753983676433563
[5/24] Train loss=0.38378214836120605
[10/24] Train loss=0.41588008403778076
[15/24] Train loss=0.40407294034957886
[20/24] Train loss=0.3844364583492279
Test set avg_accuracy=79.34% avg_sensitivity=76.79%, avg_specificity=80.18% avg_auc=86.69%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.427630 Test loss=0.491058 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.38647013902664185
[5/24] Train loss=0.3843422830104828
[10/24] Train loss=0.40804705023765564
[15/24] Train loss=0.3992658257484436
[20/24] Train loss=0.3651823103427887
Test set avg_accuracy=79.24% avg_sensitivity=76.84%, avg_specificity=80.05% avg_auc=86.60%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.424755 Test loss=0.494809 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3755171000957489
[5/24] Train loss=0.3805398643016815
[10/24] Train loss=0.3979385495185852
[15/24] Train loss=0.39842644333839417
[20/24] Train loss=0.3564271926879883
Test set avg_accuracy=79.41% avg_sensitivity=75.80%, avg_specificity=80.62% avg_auc=86.68%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.419042 Test loss=0.488200 Current lr=[0.000156543481933168]

[0/24] Train loss=0.37458115816116333
[5/24] Train loss=0.3821314573287964
[10/24] Train loss=0.41733846068382263
[15/24] Train loss=0.3908230662345886
[20/24] Train loss=0.3789406716823578
Test set avg_accuracy=79.74% avg_sensitivity=74.75%, avg_specificity=81.40% avg_auc=86.63%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.420830 Test loss=0.476484 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.36947640776634216
[5/24] Train loss=0.38107314705848694
[10/24] Train loss=0.40060457587242126
[15/24] Train loss=0.39228346943855286
[20/24] Train loss=0.35661986470222473
Test set avg_accuracy=79.99% avg_sensitivity=73.71%, avg_specificity=82.08% avg_auc=86.68%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.412115 Test loss=0.471233 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3650846481323242
[5/24] Train loss=0.361526757478714
[10/24] Train loss=0.4017350375652313
[15/24] Train loss=0.3876835107803345
[20/24] Train loss=0.36743202805519104
Test set avg_accuracy=79.82% avg_sensitivity=74.60%, avg_specificity=81.55% avg_auc=86.70%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.410724 Test loss=0.479232 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3761667311191559
[5/24] Train loss=0.35460472106933594
[10/24] Train loss=0.41103944182395935
[15/24] Train loss=0.37668633460998535
[20/24] Train loss=0.3621898293495178
Test set avg_accuracy=79.60% avg_sensitivity=74.75%, avg_specificity=81.21% avg_auc=86.58%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.408814 Test loss=0.482812 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3600710928440094
[5/24] Train loss=0.37390875816345215
[10/24] Train loss=0.4073425531387329
[15/24] Train loss=0.3819130063056946
[20/24] Train loss=0.3619658350944519
Test set avg_accuracy=79.67% avg_sensitivity=73.92%, avg_specificity=81.59% avg_auc=86.57%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.405247 Test loss=0.480132 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3590489327907562
[5/24] Train loss=0.353169709444046
[10/24] Train loss=0.3888496160507202
[15/24] Train loss=0.3892210125923157
[20/24] Train loss=0.36693885922431946
Test set avg_accuracy=79.69% avg_sensitivity=74.54%, avg_specificity=81.40% avg_auc=86.61%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.402209 Test loss=0.486085 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.35613399744033813
[5/24] Train loss=0.3648205101490021
[10/24] Train loss=0.4097897410392761
[15/24] Train loss=0.3771432042121887
[20/24] Train loss=0.3654249906539917
Test set avg_accuracy=79.56% avg_sensitivity=74.91%, avg_specificity=81.10% avg_auc=86.62%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.405003 Test loss=0.489839 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3534291088581085
[5/24] Train loss=0.3492153286933899
[10/24] Train loss=0.40102145075798035
[15/24] Train loss=0.38672125339508057
[20/24] Train loss=0.3526504635810852
Test set avg_accuracy=79.70% avg_sensitivity=74.60%, avg_specificity=81.40% avg_auc=86.66%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.399667 Test loss=0.489465 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.35734736919403076
[5/24] Train loss=0.3573811948299408
[10/24] Train loss=0.3931141495704651
[15/24] Train loss=0.38285282254219055
[20/24] Train loss=0.3690784275531769
Test set avg_accuracy=79.62% avg_sensitivity=74.91%, avg_specificity=81.19% avg_auc=86.62%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.400833 Test loss=0.490625 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.363253116607666
[5/24] Train loss=0.3624650835990906
[10/24] Train loss=0.39821478724479675
[15/24] Train loss=0.38752681016921997
[20/24] Train loss=0.3459835350513458
Test set avg_accuracy=79.78% avg_sensitivity=74.18%, avg_specificity=81.64% avg_auc=86.73%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.399852 Test loss=0.487796 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.34496188163757324
[5/24] Train loss=0.3623009920120239
[10/24] Train loss=0.39202338457107544
[15/24] Train loss=0.3764580190181732
[20/24] Train loss=0.3643074333667755
Test set avg_accuracy=79.38% avg_sensitivity=75.17%, avg_specificity=80.77% avg_auc=86.72%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.397512 Test loss=0.501153 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3478356897830963
[5/24] Train loss=0.3587873578071594
[10/24] Train loss=0.40595462918281555
[15/24] Train loss=0.38603565096855164
[20/24] Train loss=0.35955968499183655
Test set avg_accuracy=79.75% avg_sensitivity=74.18%, avg_specificity=81.61% avg_auc=86.75%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.400712 Test loss=0.491767 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3559054732322693
[5/24] Train loss=0.3450329005718231
[10/24] Train loss=0.4000881016254425
[15/24] Train loss=0.38463661074638367
[20/24] Train loss=0.3551146984100342
Test set avg_accuracy=79.41% avg_sensitivity=74.96%, avg_specificity=80.90% avg_auc=86.79%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.396736 Test loss=0.500911 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3385056257247925
[5/24] Train loss=0.3526049256324768
[10/24] Train loss=0.39184820652008057
[15/24] Train loss=0.37877705693244934
[20/24] Train loss=0.3454738259315491
Test set avg_accuracy=79.26% avg_sensitivity=75.33%, avg_specificity=80.57% avg_auc=86.74%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.394333 Test loss=0.504712 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.348325252532959
[5/24] Train loss=0.35282081365585327
[10/24] Train loss=0.38686034083366394
[15/24] Train loss=0.37271878123283386
[20/24] Train loss=0.36179497838020325
Test set avg_accuracy=79.28% avg_sensitivity=75.74%, avg_specificity=80.46% avg_auc=86.69%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.394079 Test loss=0.507934 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.35305705666542053
[5/24] Train loss=0.34961366653442383
[10/24] Train loss=0.3853560984134674
[15/24] Train loss=0.3752621114253998
[20/24] Train loss=0.3385854661464691
Test set avg_accuracy=79.00% avg_sensitivity=76.21%, avg_specificity=79.92% avg_auc=86.63%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.395103 Test loss=0.511010 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.34660735726356506
[5/24] Train loss=0.3762720227241516
[10/24] Train loss=0.38714346289634705
[15/24] Train loss=0.37462177872657776
[20/24] Train loss=0.35944852232933044
Test set avg_accuracy=78.85% avg_sensitivity=76.47%, avg_specificity=79.65% avg_auc=86.59%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.396667 Test loss=0.514407 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3568190634250641
[5/24] Train loss=0.36550599336624146
[10/24] Train loss=0.39422252774238586
[15/24] Train loss=0.3625202178955078
[20/24] Train loss=0.35804450511932373
Test set avg_accuracy=78.42% avg_sensitivity=77.88%, avg_specificity=78.60% avg_auc=86.42%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.394664 Test loss=0.528550 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.35874810814857483
[5/24] Train loss=0.3704163432121277
[10/24] Train loss=0.39321908354759216
[15/24] Train loss=0.36824119091033936
[20/24] Train loss=0.3648744821548462
Test set avg_accuracy=77.54% avg_sensitivity=79.45%, avg_specificity=76.90% avg_auc=86.37%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.398465 Test loss=0.553229 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3740055561065674
[5/24] Train loss=0.35981497168540955
[10/24] Train loss=0.38780227303504944
[15/24] Train loss=0.41180065274238586
[20/24] Train loss=0.37290582060813904
Test set avg_accuracy=79.26% avg_sensitivity=75.80%, avg_specificity=80.41% avg_auc=86.52%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.409796 Test loss=0.502733 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3514639735221863
[5/24] Train loss=0.34559592604637146
[10/24] Train loss=0.4304867386817932
[15/24] Train loss=0.4002780616283417
[20/24] Train loss=0.34602898359298706
Test set avg_accuracy=81.12% avg_sensitivity=70.21%, avg_specificity=84.75% avg_auc=86.62%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.407799 Test loss=0.460121 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3597217798233032
[5/24] Train loss=0.35393527150154114
[10/24] Train loss=0.3872700035572052
[15/24] Train loss=0.38402119278907776
[20/24] Train loss=0.3380305767059326
Test set avg_accuracy=79.90% avg_sensitivity=74.23%, avg_specificity=81.78% avg_auc=86.53%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.391031 Test loss=0.485799 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.34016260504722595
[5/24] Train loss=0.351138710975647
[10/24] Train loss=0.38867342472076416
[15/24] Train loss=0.37309056520462036
[20/24] Train loss=0.3495897054672241
Test set avg_accuracy=80.22% avg_sensitivity=72.46%, avg_specificity=82.80% avg_auc=86.53%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.385922 Test loss=0.477200 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.33849042654037476
[5/24] Train loss=0.3503844738006592
[10/24] Train loss=0.38068798184394836
[15/24] Train loss=0.36920294165611267
[20/24] Train loss=0.3563099801540375
Test set avg_accuracy=79.96% avg_sensitivity=73.55%, avg_specificity=82.09% avg_auc=86.47%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.384873 Test loss=0.484306 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.33869582414627075
[5/24] Train loss=0.3355228006839752
[10/24] Train loss=0.3816955089569092
[15/24] Train loss=0.36758753657341003
[20/24] Train loss=0.34057846665382385
Test set avg_accuracy=79.78% avg_sensitivity=73.87%, avg_specificity=81.75% avg_auc=86.48%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.381531 Test loss=0.488717 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3328690528869629
[5/24] Train loss=0.33740735054016113
[10/24] Train loss=0.3821789622306824
[15/24] Train loss=0.3626325726509094
[20/24] Train loss=0.3409641981124878
Test set avg_accuracy=79.97% avg_sensitivity=73.29%, avg_specificity=82.20% avg_auc=86.45%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.381285 Test loss=0.485132 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3316963016986847
[5/24] Train loss=0.33643755316734314
[10/24] Train loss=0.36897823214530945
[15/24] Train loss=0.35690873861312866
[20/24] Train loss=0.34161093831062317
Test set avg_accuracy=79.65% avg_sensitivity=74.13%, avg_specificity=81.49% avg_auc=86.42%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.379159 Test loss=0.491433 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.33842983841896057
[5/24] Train loss=0.34796422719955444
[10/24] Train loss=0.37545284628868103
[15/24] Train loss=0.36942586302757263
[20/24] Train loss=0.34109318256378174
Test set avg_accuracy=79.75% avg_sensitivity=73.19%, avg_specificity=81.94% avg_auc=86.34%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.380059 Test loss=0.488328 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.33751121163368225
[5/24] Train loss=0.3497004508972168
[10/24] Train loss=0.37723618745803833
[15/24] Train loss=0.3640082776546478
[20/24] Train loss=0.3429936170578003
Test set avg_accuracy=79.70% avg_sensitivity=73.55%, avg_specificity=81.75% avg_auc=86.35%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.379151 Test loss=0.491570 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.33436477184295654
[5/24] Train loss=0.34201982617378235
[10/24] Train loss=0.3710804879665375
[15/24] Train loss=0.37482360005378723
[20/24] Train loss=0.3325565457344055
Test set avg_accuracy=79.61% avg_sensitivity=73.92%, avg_specificity=81.50% avg_auc=86.31%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.377528 Test loss=0.496023 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.338481068611145
[5/24] Train loss=0.3388756811618805
[10/24] Train loss=0.3763718605041504
[15/24] Train loss=0.3701134920120239
[20/24] Train loss=0.339272677898407
Test set avg_accuracy=79.73% avg_sensitivity=73.66%, avg_specificity=81.75% avg_auc=86.32%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.380034 Test loss=0.493307 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.33523574471473694
[5/24] Train loss=0.3350858986377716
[10/24] Train loss=0.3744910657405853
[15/24] Train loss=0.36817246675491333
[20/24] Train loss=0.3257625102996826
Test set avg_accuracy=79.60% avg_sensitivity=73.55%, avg_specificity=81.61% avg_auc=86.29%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.377813 Test loss=0.494787 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3395363688468933
[5/24] Train loss=0.33835726976394653
[10/24] Train loss=0.3692499101161957
[15/24] Train loss=0.3707541525363922
[20/24] Train loss=0.32996729016304016
Test set avg_accuracy=79.51% avg_sensitivity=74.18%, avg_specificity=81.28% avg_auc=86.32%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.378014 Test loss=0.498180 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3377183675765991
[5/24] Train loss=0.344194233417511
[10/24] Train loss=0.3741142153739929
[15/24] Train loss=0.35937273502349854
[20/24] Train loss=0.34048113226890564
Test set avg_accuracy=79.60% avg_sensitivity=73.97%, avg_specificity=81.47% avg_auc=86.35%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.378487 Test loss=0.494887 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.337638795375824
[5/24] Train loss=0.3384815454483032
[10/24] Train loss=0.37626466155052185
[15/24] Train loss=0.36944177746772766
[20/24] Train loss=0.33176782727241516
Test set avg_accuracy=79.62% avg_sensitivity=74.07%, avg_specificity=81.47% avg_auc=86.32%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.373699 Test loss=0.494814 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3315926492214203
[5/24] Train loss=0.329330712556839
[10/24] Train loss=0.36302632093429565
[15/24] Train loss=0.35840219259262085
[20/24] Train loss=0.33423593640327454
Test set avg_accuracy=79.73% avg_sensitivity=73.60%, avg_specificity=81.76% avg_auc=86.34%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.376561 Test loss=0.493204 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.33131587505340576
[5/24] Train loss=0.34154677391052246
[10/24] Train loss=0.3631693720817566
[15/24] Train loss=0.3557370603084564
[20/24] Train loss=0.3364499509334564
Test set avg_accuracy=80.03% avg_sensitivity=72.87%, avg_specificity=82.40% avg_auc=86.34%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.377141 Test loss=0.485208 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.33125659823417664
[5/24] Train loss=0.3427188992500305
[10/24] Train loss=0.36417922377586365
[15/24] Train loss=0.3615214228630066
[20/24] Train loss=0.34991565346717834
Test set avg_accuracy=80.23% avg_sensitivity=72.09%, avg_specificity=82.94% avg_auc=86.35%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.378125 Test loss=0.480561 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.34236881136894226
[5/24] Train loss=0.3408036231994629
[10/24] Train loss=0.3642841875553131
[15/24] Train loss=0.36002135276794434
[20/24] Train loss=0.331189900636673
Test set avg_accuracy=80.44% avg_sensitivity=71.31%, avg_specificity=83.48% avg_auc=86.35%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.376434 Test loss=0.476428 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.336906760931015
[5/24] Train loss=0.33584773540496826
[10/24] Train loss=0.36751556396484375
[15/24] Train loss=0.36241304874420166
[20/24] Train loss=0.32818931341171265
Test set avg_accuracy=80.25% avg_sensitivity=71.78%, avg_specificity=83.06% avg_auc=86.34%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.372429 Test loss=0.479653 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3370853662490845
[5/24] Train loss=0.331099271774292
[10/24] Train loss=0.3738201856613159
[15/24] Train loss=0.3590211272239685
[20/24] Train loss=0.3287322223186493
Test set avg_accuracy=80.05% avg_sensitivity=72.56%, avg_specificity=82.54% avg_auc=86.32%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.375317 Test loss=0.484783 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.33397287130355835
[5/24] Train loss=0.3405442535877228
[10/24] Train loss=0.3595495820045471
[15/24] Train loss=0.35725265741348267
[20/24] Train loss=0.3297498822212219
Test set avg_accuracy=80.07% avg_sensitivity=72.40%, avg_specificity=82.61% avg_auc=86.33%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.373550 Test loss=0.484253 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3230084776878357
[5/24] Train loss=0.33002549409866333
[10/24] Train loss=0.3688566982746124
[15/24] Train loss=0.35897669196128845
[20/24] Train loss=0.3280473053455353
Test set avg_accuracy=80.00% avg_sensitivity=72.56%, avg_specificity=82.47% avg_auc=86.30%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.373214 Test loss=0.485323 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.34941136837005615
[5/24] Train loss=0.3370001018047333
[10/24] Train loss=0.36611953377723694
[15/24] Train loss=0.35434281826019287
[20/24] Train loss=0.33552679419517517
Test set avg_accuracy=80.04% avg_sensitivity=72.51%, avg_specificity=82.54% avg_auc=86.31%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.373724 Test loss=0.485015 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3322947323322296
[5/24] Train loss=0.33790209889411926
[10/24] Train loss=0.36407122015953064
[15/24] Train loss=0.36593300104141235
[20/24] Train loss=0.3368825912475586
Test set avg_accuracy=80.03% avg_sensitivity=72.82%, avg_specificity=82.42% avg_auc=86.30%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.372990 Test loss=0.486639 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.336596816778183
[5/24] Train loss=0.335812509059906
[10/24] Train loss=0.37549570202827454
[15/24] Train loss=0.3533419966697693
[20/24] Train loss=0.3342322111129761
Test set avg_accuracy=80.04% avg_sensitivity=72.77%, avg_specificity=82.46% avg_auc=86.29%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.372911 Test loss=0.485968 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3430522680282593
[5/24] Train loss=0.3294435441493988
[10/24] Train loss=0.36493393778800964
[15/24] Train loss=0.3571482002735138
[20/24] Train loss=0.34270381927490234
Test set avg_accuracy=80.04% avg_sensitivity=72.82%, avg_specificity=82.44% avg_auc=86.29%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.373154 Test loss=0.486194 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3324190378189087
[5/24] Train loss=0.3410063087940216
[10/24] Train loss=0.3740890920162201
[15/24] Train loss=0.3636593818664551
[20/24] Train loss=0.33382341265678406
Test set avg_accuracy=80.03% avg_sensitivity=73.03%, avg_specificity=82.35% avg_auc=86.29%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.374348 Test loss=0.487647 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.33360686898231506
[5/24] Train loss=0.3305160701274872
[10/24] Train loss=0.37657126784324646
[15/24] Train loss=0.357180118560791
[20/24] Train loss=0.3277294933795929
Test set avg_accuracy=80.04% avg_sensitivity=73.08%, avg_specificity=82.35% avg_auc=86.29%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.373000 Test loss=0.487721 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.32774221897125244
[5/24] Train loss=0.3355998396873474
[10/24] Train loss=0.3651280403137207
[15/24] Train loss=0.3587885797023773
[20/24] Train loss=0.3336680829524994
Test set avg_accuracy=80.04% avg_sensitivity=73.08%, avg_specificity=82.35% avg_auc=86.29%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.371790 Test loss=0.487737 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3360193967819214
[5/24] Train loss=0.3338709771633148
[10/24] Train loss=0.3678824007511139
[15/24] Train loss=0.3475593626499176
[20/24] Train loss=0.324603796005249
Test set avg_accuracy=80.05% avg_sensitivity=73.08%, avg_specificity=82.37% avg_auc=86.29%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.370319 Test loss=0.487486 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.33607879281044006
[5/24] Train loss=0.3279328942298889
[10/24] Train loss=0.37126684188842773
[15/24] Train loss=0.36343061923980713
[20/24] Train loss=0.3285934031009674
Test set avg_accuracy=80.05% avg_sensitivity=73.08%, avg_specificity=82.37% avg_auc=86.29%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.374024 Test loss=0.487484 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3298336863517761
[5/24] Train loss=0.33799877762794495
[10/24] Train loss=0.3596932888031006
[15/24] Train loss=0.3641659617424011
[20/24] Train loss=0.3339636027812958
Test set avg_accuracy=80.05% avg_sensitivity=73.08%, avg_specificity=82.37% avg_auc=86.29%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.373260 Test loss=0.487517 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.33766523003578186
[5/24] Train loss=0.32746240496635437
[10/24] Train loss=0.37713709473609924
[15/24] Train loss=0.3521084785461426
[20/24] Train loss=0.32547271251678467
Test set avg_accuracy=80.05% avg_sensitivity=73.08%, avg_specificity=82.37% avg_auc=86.29%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.370205 Test loss=0.487529 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=81.64% sen=76.42%, spe=83.38%, auc=87.78%!
Fold[2] Avg_jsc=0.60%(±0.23807617162427652)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.9876829385757446
[5/24] Train loss=1.840777039527893
[10/24] Train loss=1.7670477628707886
[15/24] Train loss=1.692747712135315
[20/24] Train loss=1.5962085723876953
Test set avg_accuracy=51.17% avg_sensitivity=48.91%, avg_specificity=52.03% avg_auc=52.63%
Best model saved!! Metric=52.626273111710496!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=1.743414 Test loss=0.749943 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.617721438407898
[5/24] Train loss=1.5832228660583496
[10/24] Train loss=1.516905665397644
[15/24] Train loss=1.500410556793213
[20/24] Train loss=1.4753470420837402
Test set avg_accuracy=56.02% avg_sensitivity=58.39%, avg_specificity=55.12% avg_auc=60.06%
Best model saved!! Metric=60.05864609834336!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=1.529163 Test loss=0.688017 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.4577617645263672
[5/24] Train loss=1.4662585258483887
[10/24] Train loss=1.4507720470428467
[15/24] Train loss=1.40592360496521
[20/24] Train loss=1.3804832696914673
Test set avg_accuracy=62.03% avg_sensitivity=63.27%, avg_specificity=61.56% avg_auc=67.30%
Best model saved!! Metric=67.29884196822857!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=1.430020 Test loss=0.641555 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.4151175022125244
[5/24] Train loss=1.40419602394104
[10/24] Train loss=1.3691638708114624
[15/24] Train loss=1.3577615022659302
[20/24] Train loss=1.3010141849517822
Test set avg_accuracy=64.27% avg_sensitivity=70.90%, avg_specificity=61.76% avg_auc=71.91%
Best model saved!! Metric=71.9110034289993!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=1.362607 Test loss=0.623714 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.3438268899917603
[5/24] Train loss=1.3298050165176392
[10/24] Train loss=1.3475518226623535
[15/24] Train loss=1.2912100553512573
[20/24] Train loss=1.2442973852157593
Test set avg_accuracy=66.55% avg_sensitivity=73.27%, avg_specificity=64.00% avg_auc=75.52%
Best model saved!! Metric=75.51613246317866!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=1.307772 Test loss=0.599328 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.2875196933746338
[5/24] Train loss=1.2927883863449097
[10/24] Train loss=1.2873581647872925
[15/24] Train loss=1.2366399765014648
[20/24] Train loss=1.1886746883392334
Test set avg_accuracy=70.20% avg_sensitivity=76.40%, avg_specificity=67.85% avg_auc=78.44%
Best model saved!! Metric=78.44264296714798!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=1.251627 Test loss=0.573025 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.221469759941101
[5/24] Train loss=1.2593742609024048
[10/24] Train loss=1.2553905248641968
[15/24] Train loss=1.1884909868240356
[20/24] Train loss=1.1079931259155273
Test set avg_accuracy=71.60% avg_sensitivity=80.38%, avg_specificity=68.28% avg_auc=80.46%
Best model saved!! Metric=80.4580904813362!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=1.202467 Test loss=0.556628 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.1349968910217285
[5/24] Train loss=1.2117432355880737
[10/24] Train loss=1.2274001836776733
[15/24] Train loss=1.129010796546936
[20/24] Train loss=1.0484378337860107
Test set avg_accuracy=73.06% avg_sensitivity=81.85%, avg_specificity=69.73% avg_auc=82.03%
Best model saved!! Metric=82.02948684132156!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=1.139804 Test loss=0.539276 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.0903908014297485
[5/24] Train loss=1.1698583364486694
[10/24] Train loss=1.1850125789642334
[15/24] Train loss=1.06784987449646
[20/24] Train loss=0.9789085984230042
Test set avg_accuracy=74.22% avg_sensitivity=83.03%, avg_specificity=70.88% avg_auc=83.40%
Best model saved!! Metric=83.40300526687484!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=1.087051 Test loss=0.524958 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.0109001398086548
[5/24] Train loss=1.1282848119735718
[10/24] Train loss=1.1464107036590576
[15/24] Train loss=1.0168640613555908
[20/24] Train loss=0.9351568222045898
Test set avg_accuracy=75.47% avg_sensitivity=83.46%, avg_specificity=72.44% avg_auc=84.63%
Best model saved!! Metric=84.63371395509117!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=1.043275 Test loss=0.506948 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.9634425640106201
[5/24] Train loss=1.0854740142822266
[10/24] Train loss=1.1070239543914795
[15/24] Train loss=0.9901441931724548
[20/24] Train loss=0.9086846113204956
Test set avg_accuracy=76.37% avg_sensitivity=84.12%, avg_specificity=73.43% avg_auc=85.69%
Best model saved!! Metric=85.69400222927497!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=1.006583 Test loss=0.491702 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.9371007680892944
[5/24] Train loss=1.075239658355713
[10/24] Train loss=1.0779681205749512
[15/24] Train loss=0.9406082630157471
[20/24] Train loss=0.8789287805557251
Test set avg_accuracy=77.23% avg_sensitivity=84.98%, avg_specificity=74.29% avg_auc=86.46%
Best model saved!! Metric=86.45507415317331!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.976836 Test loss=0.479149 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.9061051607131958
[5/24] Train loss=1.0408350229263306
[10/24] Train loss=1.0595452785491943
[15/24] Train loss=0.9422661066055298
[20/24] Train loss=0.8698385953903198
Test set avg_accuracy=77.50% avg_sensitivity=85.83%, avg_specificity=74.34% avg_auc=87.00%
Best model saved!! Metric=87.00119121563557!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.957493 Test loss=0.473486 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.8788909912109375
[5/24] Train loss=1.0315964221954346
[10/24] Train loss=1.029603362083435
[15/24] Train loss=0.9152365326881409
[20/24] Train loss=0.8251174092292786
Test set avg_accuracy=77.30% avg_sensitivity=86.54%, avg_specificity=73.81% avg_auc=87.39%
Best model saved!! Metric=87.39082083265973!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.939040 Test loss=0.474194 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.8540944457054138
[5/24] Train loss=1.0083287954330444
[10/24] Train loss=1.013018250465393
[15/24] Train loss=0.9079418778419495
[20/24] Train loss=0.8154975175857544
Test set avg_accuracy=77.67% avg_sensitivity=86.78%, avg_specificity=74.22% avg_auc=87.70%
Best model saved!! Metric=87.7014941247543!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.919900 Test loss=0.468436 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.8343109488487244
[5/24] Train loss=0.9986100792884827
[10/24] Train loss=0.9930523633956909
[15/24] Train loss=0.8901057839393616
[20/24] Train loss=0.804606556892395
Test set avg_accuracy=77.89% avg_sensitivity=87.63%, avg_specificity=74.20% avg_auc=87.93%
Best model saved!! Metric=87.93049256766531!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.911571 Test loss=0.467489 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.8229658007621765
[5/24] Train loss=0.9927417635917664
[10/24] Train loss=0.9862111806869507
[15/24] Train loss=0.8775575757026672
[20/24] Train loss=0.8112319707870483
Test set avg_accuracy=77.68% avg_sensitivity=87.73%, avg_specificity=73.88% avg_auc=88.11%
Best model saved!! Metric=88.10803474946182!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.900460 Test loss=0.469088 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.822044849395752
[5/24] Train loss=0.9799286127090454
[10/24] Train loss=0.9730339646339417
[15/24] Train loss=0.8822640180587769
[20/24] Train loss=0.7913364768028259
Test set avg_accuracy=78.05% avg_sensitivity=87.20%, avg_specificity=74.58% avg_auc=88.28%
Best model saved!! Metric=88.28339019969879!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.887469 Test loss=0.460876 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8194518089294434
[5/24] Train loss=0.9661186933517456
[10/24] Train loss=0.9583302736282349
[15/24] Train loss=0.858106791973114
[20/24] Train loss=0.7815977334976196
Test set avg_accuracy=78.59% avg_sensitivity=87.25%, avg_specificity=75.31% avg_auc=88.44%
Best model saved!! Metric=88.4411667106282!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.878327 Test loss=0.455697 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.8051764369010925
[5/24] Train loss=0.9596723318099976
[10/24] Train loss=0.9436609148979187
[15/24] Train loss=0.8455328941345215
[20/24] Train loss=0.7815425395965576
Test set avg_accuracy=78.72% avg_sensitivity=87.06%, avg_specificity=75.57% avg_auc=88.57%
Best model saved!! Metric=88.56616351987205!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.870602 Test loss=0.453630 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.7976925373077393
[5/24] Train loss=0.9379125237464905
[10/24] Train loss=0.9307475090026855
[15/24] Train loss=0.844340443611145
[20/24] Train loss=0.7669209837913513
Test set avg_accuracy=78.63% avg_sensitivity=87.73%, avg_specificity=75.19% avg_auc=88.70%
Best model saved!! Metric=88.69646123869408!!
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.865282 Test loss=0.457205 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.7936373949050903
[5/24] Train loss=0.9421396851539612
[10/24] Train loss=0.9291391372680664
[15/24] Train loss=0.8330422639846802
[20/24] Train loss=0.7728388905525208
Test set avg_accuracy=78.54% avg_sensitivity=88.29%, avg_specificity=74.85% avg_auc=88.86%
Best model saved!! Metric=88.8552332655475!!
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.856133 Test loss=0.459739 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.7815297842025757
[5/24] Train loss=0.930198609828949
[10/24] Train loss=0.9245048761367798
[15/24] Train loss=0.8215991258621216
[20/24] Train loss=0.7568570971488953
Test set avg_accuracy=78.28% avg_sensitivity=89.43%, avg_specificity=74.06% avg_auc=88.95%
Best model saved!! Metric=88.95382763109754!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.851095 Test loss=0.470889 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.779032289981842
[5/24] Train loss=0.9179876446723938
[10/24] Train loss=0.9027493596076965
[15/24] Train loss=0.8170987367630005
[20/24] Train loss=0.7760619521141052
Test set avg_accuracy=77.99% avg_sensitivity=89.34%, avg_specificity=73.70% avg_auc=89.04%
Best model saved!! Metric=89.03606830770802!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.842668 Test loss=0.470426 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7835608720779419
[5/24] Train loss=0.9096162915229797
[10/24] Train loss=0.8841177821159363
[15/24] Train loss=0.8027493357658386
[20/24] Train loss=0.759628415107727
Test set avg_accuracy=78.12% avg_sensitivity=89.24%, avg_specificity=73.91% avg_auc=89.18%
Best model saved!! Metric=89.17828669156874!!
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.837300 Test loss=0.468488 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7750306129455566
[5/24] Train loss=0.8991256952285767
[10/24] Train loss=0.8890287280082703
[15/24] Train loss=0.8039365410804749
[20/24] Train loss=0.7587308883666992
Test set avg_accuracy=77.85% avg_sensitivity=89.67%, avg_specificity=73.38% avg_auc=89.26%
Best model saved!! Metric=89.26118253677878!!
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.832797 Test loss=0.473616 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.770117461681366
[5/24] Train loss=0.8823667168617249
[10/24] Train loss=0.8725272417068481
[15/24] Train loss=0.7954760789871216
[20/24] Train loss=0.7540619373321533
Test set avg_accuracy=77.88% avg_sensitivity=89.53%, avg_specificity=73.46% avg_auc=89.39%
Best model saved!! Metric=89.38678771686506!!
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.824880 Test loss=0.473024 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7588886022567749
[5/24] Train loss=0.8748078346252441
[10/24] Train loss=0.8674038648605347
[15/24] Train loss=0.7792324423789978
[20/24] Train loss=0.7450708150863647
Test set avg_accuracy=78.35% avg_sensitivity=88.77%, avg_specificity=74.40% avg_auc=89.48%
Best model saved!! Metric=89.47693721442732!!
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.816107 Test loss=0.461700 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7550156712532043
[5/24] Train loss=0.8652763366699219
[10/24] Train loss=0.8663954734802246
[15/24] Train loss=0.7688803672790527
[20/24] Train loss=0.7227379083633423
Test set avg_accuracy=78.42% avg_sensitivity=88.20%, avg_specificity=74.72% avg_auc=89.62%
Best model saved!! Metric=89.62251227377538!!
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.808930 Test loss=0.456374 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.752851128578186
[5/24] Train loss=0.8447927236557007
[10/24] Train loss=0.8470685482025146
[15/24] Train loss=0.7655494809150696
[20/24] Train loss=0.7234776020050049
Test set avg_accuracy=78.57% avg_sensitivity=87.87%, avg_specificity=75.04% avg_auc=89.71%
Best model saved!! Metric=89.71466131186875!!
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.799673 Test loss=0.453952 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7324903011322021
[5/24] Train loss=0.8309856653213501
[10/24] Train loss=0.8552967309951782
[15/24] Train loss=0.7587936520576477
[20/24] Train loss=0.7045542001724243
Test set avg_accuracy=79.13% avg_sensitivity=87.16%, avg_specificity=76.09% avg_auc=89.85%
Best model saved!! Metric=89.84927293302816!!
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.791090 Test loss=0.440527 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7347530126571655
[5/24] Train loss=0.8103436231613159
[10/24] Train loss=0.8318848013877869
[15/24] Train loss=0.7482900619506836
[20/24] Train loss=0.7013558149337769
Test set avg_accuracy=79.23% avg_sensitivity=87.25%, avg_specificity=76.19% avg_auc=89.92%
Best model saved!! Metric=89.91550026802352!!
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.782847 Test loss=0.441995 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7347701191902161
[5/24] Train loss=0.8132205009460449
[10/24] Train loss=0.831882119178772
[15/24] Train loss=0.7447708249092102
[20/24] Train loss=0.6896765828132629
Test set avg_accuracy=79.52% avg_sensitivity=86.82%, avg_specificity=76.75% avg_auc=90.03%
Best model saved!! Metric=90.02752984420603!!
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.777467 Test loss=0.435757 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7145920395851135
[5/24] Train loss=0.8050956130027771
[10/24] Train loss=0.8166124820709229
[15/24] Train loss=0.731587827205658
[20/24] Train loss=0.6713610887527466
Test set avg_accuracy=79.19% avg_sensitivity=87.44%, avg_specificity=76.07% avg_auc=90.11%
Best model saved!! Metric=90.1070051988054!!
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.765405 Test loss=0.440352 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7177225947380066
[5/24] Train loss=0.8005616068840027
[10/24] Train loss=0.8115494251251221
[15/24] Train loss=0.7213465571403503
[20/24] Train loss=0.6751155853271484
Test set avg_accuracy=79.23% avg_sensitivity=87.01%, avg_specificity=76.28% avg_auc=90.16%
Best model saved!! Metric=90.15601095918385!!
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.759134 Test loss=0.439994 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7131460905075073
[5/24] Train loss=0.7888555526733398
[10/24] Train loss=0.8013878464698792
[15/24] Train loss=0.7196987867355347
[20/24] Train loss=0.6523244380950928
Test set avg_accuracy=79.49% avg_sensitivity=86.68%, avg_specificity=76.77% avg_auc=90.22%
Best model saved!! Metric=90.21540156729941!!
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.750456 Test loss=0.432961 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.6996085047721863
[5/24] Train loss=0.7812506556510925
[10/24] Train loss=0.7857546806335449
[15/24] Train loss=0.7101960778236389
[20/24] Train loss=0.6524003744125366
Test set avg_accuracy=79.82% avg_sensitivity=86.73%, avg_specificity=77.20% avg_auc=90.31%
Best model saved!! Metric=90.30692521718413!!
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.741250 Test loss=0.428681 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.688622236251831
[5/24] Train loss=0.7703697681427002
[10/24] Train loss=0.7785219550132751
[15/24] Train loss=0.7037950158119202
[20/24] Train loss=0.6394877433776855
Test set avg_accuracy=80.10% avg_sensitivity=86.02%, avg_specificity=77.86% avg_auc=90.41%
Best model saved!! Metric=90.40548129366017!!
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.733835 Test loss=0.421396 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.6834356188774109
[5/24] Train loss=0.753336489200592
[10/24] Train loss=0.7697568535804749
[15/24] Train loss=0.6868947148323059
[20/24] Train loss=0.6222947835922241
Test set avg_accuracy=80.48% avg_sensitivity=85.64%, avg_specificity=78.53% avg_auc=90.43%
Best model saved!! Metric=90.43225811941085!!
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.722808 Test loss=0.416993 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6699449419975281
[5/24] Train loss=0.744324803352356
[10/24] Train loss=0.7740137577056885
[15/24] Train loss=0.6859467029571533
[20/24] Train loss=0.6158512830734253
Test set avg_accuracy=80.90% avg_sensitivity=84.55%, avg_specificity=79.52% avg_auc=90.46%
Best model saved!! Metric=90.4612599657951!!
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.713951 Test loss=0.407429 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6587410569190979
[5/24] Train loss=0.7248279452323914
[10/24] Train loss=0.7519016861915588
[15/24] Train loss=0.6747291088104248
[20/24] Train loss=0.599620521068573
Test set avg_accuracy=81.39% avg_sensitivity=83.98%, avg_specificity=80.41% avg_auc=90.51%
Best model saved!! Metric=90.50841934193845!!
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.703852 Test loss=0.398899 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6545823216438293
[5/24] Train loss=0.7158467769622803
[10/24] Train loss=0.7439324855804443
[15/24] Train loss=0.6663846969604492
[20/24] Train loss=0.5878530144691467
Test set avg_accuracy=81.72% avg_sensitivity=82.94%, avg_specificity=81.26% avg_auc=90.48%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.692267 Test loss=0.393413 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6490217447280884
[5/24] Train loss=0.7004268765449524
[10/24] Train loss=0.731758177280426
[15/24] Train loss=0.6550784111022949
[20/24] Train loss=0.5804136991500854
Test set avg_accuracy=82.02% avg_sensitivity=82.04%, avg_specificity=82.01% avg_auc=90.53%
Best model saved!! Metric=90.52524526279068!!
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.683711 Test loss=0.385590 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6379993557929993
[5/24] Train loss=0.7013245224952698
[10/24] Train loss=0.7222892045974731
[15/24] Train loss=0.6511842608451843
[20/24] Train loss=0.5741550922393799
Test set avg_accuracy=82.41% avg_sensitivity=81.04%, avg_specificity=82.93% avg_auc=90.53%
Best model saved!! Metric=90.52618547227446!!
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.672889 Test loss=0.378942 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6349907517433167
[5/24] Train loss=0.6773958206176758
[10/24] Train loss=0.7191663384437561
[15/24] Train loss=0.6309724450111389
[20/24] Train loss=0.5605834722518921
Test set avg_accuracy=82.70% avg_sensitivity=79.62%, avg_specificity=83.86% avg_auc=90.51%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.664085 Test loss=0.371467 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6244766712188721
[5/24] Train loss=0.6743472218513489
[10/24] Train loss=0.7139096260070801
[15/24] Train loss=0.626188337802887
[20/24] Train loss=0.5591961145401001
Test set avg_accuracy=82.70% avg_sensitivity=80.05%, avg_specificity=83.70% avg_auc=90.43%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.653978 Test loss=0.373702 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6134227514266968
[5/24] Train loss=0.6641179323196411
[10/24] Train loss=0.7025094628334045
[15/24] Train loss=0.6208257079124451
[20/24] Train loss=0.5542221069335938
Test set avg_accuracy=82.96% avg_sensitivity=78.86%, avg_specificity=84.51% avg_auc=90.39%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.645523 Test loss=0.369055 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6057953238487244
[5/24] Train loss=0.6507349014282227
[10/24] Train loss=0.6861627101898193
[15/24] Train loss=0.6026341915130615
[20/24] Train loss=0.5439939498901367
Test set avg_accuracy=83.27% avg_sensitivity=78.25%, avg_specificity=85.17% avg_auc=90.37%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.634532 Test loss=0.365469 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6015247702598572
[5/24] Train loss=0.6493765711784363
[10/24] Train loss=0.6710702776908875
[15/24] Train loss=0.5990187525749207
[20/24] Train loss=0.5392228960990906
Test set avg_accuracy=83.42% avg_sensitivity=78.39%, avg_specificity=85.33% avg_auc=90.37%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.626267 Test loss=0.365379 Current lr=[0.000298904600941902]

[0/24] Train loss=0.596706211566925
[5/24] Train loss=0.6279659867286682
[10/24] Train loss=0.666159987449646
[15/24] Train loss=0.5892844200134277
[20/24] Train loss=0.5248206257820129
Test set avg_accuracy=83.78% avg_sensitivity=77.73%, avg_specificity=86.07% avg_auc=90.38%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.616239 Test loss=0.361800 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.5676292777061462
[5/24] Train loss=0.6259694695472717
[10/24] Train loss=0.6498286128044128
[15/24] Train loss=0.5845667719841003
[20/24] Train loss=0.5149625539779663
Test set avg_accuracy=83.29% avg_sensitivity=78.48%, avg_specificity=85.12% avg_auc=90.36%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.606987 Test loss=0.367227 Current lr=[0.000297555943323901]

[0/24] Train loss=0.5559643507003784
[5/24] Train loss=0.6086477041244507
[10/24] Train loss=0.6500853300094604
[15/24] Train loss=0.5649133920669556
[20/24] Train loss=0.5031685829162598
Test set avg_accuracy=83.72% avg_sensitivity=76.82%, avg_specificity=86.34% avg_auc=90.27%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.597926 Test loss=0.360703 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.5584185719490051
[5/24] Train loss=0.6053920984268188
[10/24] Train loss=0.6421478986740112
[15/24] Train loss=0.5553037524223328
[20/24] Train loss=0.5001481175422668
Test set avg_accuracy=83.72% avg_sensitivity=77.06%, avg_specificity=86.25% avg_auc=90.19%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.588315 Test loss=0.363761 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.5524489879608154
[5/24] Train loss=0.5918187499046326
[10/24] Train loss=0.6299192905426025
[15/24] Train loss=0.5432111620903015
[20/24] Train loss=0.49865633249282837
Test set avg_accuracy=83.33% avg_sensitivity=78.15%, avg_specificity=85.30% avg_auc=90.16%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.582415 Test loss=0.369097 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.5492663383483887
[5/24] Train loss=0.5774534940719604
[10/24] Train loss=0.6086085438728333
[15/24] Train loss=0.5347757339477539
[20/24] Train loss=0.49057549238204956
Test set avg_accuracy=83.05% avg_sensitivity=78.25%, avg_specificity=84.87% avg_auc=90.10%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.572065 Test loss=0.372776 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.5199363231658936
[5/24] Train loss=0.563502311706543
[10/24] Train loss=0.6176297664642334
[15/24] Train loss=0.5256553292274475
[20/24] Train loss=0.4802928566932678
Test set avg_accuracy=83.66% avg_sensitivity=75.97%, avg_specificity=86.57% avg_auc=90.01%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.563440 Test loss=0.363635 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.5363146066665649
[5/24] Train loss=0.5636747479438782
[10/24] Train loss=0.6005448698997498
[15/24] Train loss=0.517774224281311
[20/24] Train loss=0.4819810390472412
Test set avg_accuracy=83.91% avg_sensitivity=75.40%, avg_specificity=87.13% avg_auc=89.88%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.559011 Test loss=0.363220 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.5138917565345764
[5/24] Train loss=0.5646412968635559
[10/24] Train loss=0.6048513650894165
[15/24] Train loss=0.5182603597640991
[20/24] Train loss=0.4869755506515503
Test set avg_accuracy=83.67% avg_sensitivity=76.73%, avg_specificity=86.30% avg_auc=89.85%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.551434 Test loss=0.368484 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.5015053153038025
[5/24] Train loss=0.5293067097663879
[10/24] Train loss=0.5826457142829895
[15/24] Train loss=0.5093575716018677
[20/24] Train loss=0.4691794514656067
Test set avg_accuracy=83.37% avg_sensitivity=76.87%, avg_specificity=85.83% avg_auc=89.84%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.541195 Test loss=0.371317 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.49733227491378784
[5/24] Train loss=0.5123346447944641
[10/24] Train loss=0.5882065296173096
[15/24] Train loss=0.49988260865211487
[20/24] Train loss=0.46528151631355286
Test set avg_accuracy=83.35% avg_sensitivity=76.68%, avg_specificity=85.87% avg_auc=89.77%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.533466 Test loss=0.372234 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.49122515320777893
[5/24] Train loss=0.5195745229721069
[10/24] Train loss=0.5776202082633972
[15/24] Train loss=0.4913640022277832
[20/24] Train loss=0.4595825970172882
Test set avg_accuracy=83.22% avg_sensitivity=77.16%, avg_specificity=85.51% avg_auc=89.88%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.526598 Test loss=0.372823 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.4794282019138336
[5/24] Train loss=0.502068042755127
[10/24] Train loss=0.5676811933517456
[15/24] Train loss=0.4851224422454834
[20/24] Train loss=0.45296570658683777
Test set avg_accuracy=83.15% avg_sensitivity=77.58%, avg_specificity=85.26% avg_auc=89.74%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.518336 Test loss=0.376834 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.4673168361186981
[5/24] Train loss=0.5022908449172974
[10/24] Train loss=0.5634793639183044
[15/24] Train loss=0.4842499792575836
[20/24] Train loss=0.4489460587501526
Test set avg_accuracy=82.60% avg_sensitivity=78.44%, avg_specificity=84.18% avg_auc=89.63%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.512890 Test loss=0.386271 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.46468788385391235
[5/24] Train loss=0.4917232394218445
[10/24] Train loss=0.5760309100151062
[15/24] Train loss=0.4734831154346466
[20/24] Train loss=0.4498996138572693
Test set avg_accuracy=83.09% avg_sensitivity=76.78%, avg_specificity=85.48% avg_auc=89.58%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.507813 Test loss=0.379222 Current lr=[0.000276307469034998]

[0/24] Train loss=0.4713278114795685
[5/24] Train loss=0.4791649878025055
[10/24] Train loss=0.5634440183639526
[15/24] Train loss=0.45651766657829285
[20/24] Train loss=0.43288958072662354
Test set avg_accuracy=83.62% avg_sensitivity=73.46%, avg_specificity=87.47% avg_auc=89.36%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.502796 Test loss=0.372666 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.4914785623550415
[5/24] Train loss=0.513052225112915
[10/24] Train loss=0.549700915813446
[15/24] Train loss=0.4658169746398926
[20/24] Train loss=0.45290568470954895
Test set avg_accuracy=83.84% avg_sensitivity=70.90%, avg_specificity=88.74% avg_auc=89.28%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.507937 Test loss=0.367099 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.4877888560295105
[5/24] Train loss=0.5193192958831787
[10/24] Train loss=0.5512959957122803
[15/24] Train loss=0.4579818546772003
[20/24] Train loss=0.4325961768627167
Test set avg_accuracy=83.48% avg_sensitivity=74.17%, avg_specificity=87.00% avg_auc=89.42%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.502480 Test loss=0.373250 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.4484429657459259
[5/24] Train loss=0.4679357707500458
[10/24] Train loss=0.5713071823120117
[15/24] Train loss=0.45915865898132324
[20/24] Train loss=0.45318275690078735
Test set avg_accuracy=82.84% avg_sensitivity=77.68%, avg_specificity=84.79% avg_auc=89.63%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.508175 Test loss=0.384130 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.43654635548591614
[5/24] Train loss=0.517744243144989
[10/24] Train loss=0.5569297671318054
[15/24] Train loss=0.48222753405570984
[20/24] Train loss=0.4294769763946533
Test set avg_accuracy=82.10% avg_sensitivity=81.33%, avg_specificity=82.39% avg_auc=89.62%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.504922 Test loss=0.405522 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.43504205346107483
[5/24] Train loss=0.4815422296524048
[10/24] Train loss=0.5422303676605225
[15/24] Train loss=0.45932307839393616
[20/24] Train loss=0.4270464777946472
Test set avg_accuracy=82.15% avg_sensitivity=81.09%, avg_specificity=82.55% avg_auc=89.65%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.487358 Test loss=0.403179 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.430128812789917
[5/24] Train loss=0.4747590720653534
[10/24] Train loss=0.5184482336044312
[15/24] Train loss=0.465393602848053
[20/24] Train loss=0.4265195429325104
Test set avg_accuracy=82.24% avg_sensitivity=79.38%, avg_specificity=83.32% avg_auc=89.54%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.477888 Test loss=0.397920 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.4251265227794647
[5/24] Train loss=0.46718350052833557
[10/24] Train loss=0.5276655554771423
[15/24] Train loss=0.4408048987388611
[20/24] Train loss=0.42605453729629517
Test set avg_accuracy=82.04% avg_sensitivity=80.14%, avg_specificity=82.76% avg_auc=89.49%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.474788 Test loss=0.402754 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4353625178337097
[5/24] Train loss=0.4593716263771057
[10/24] Train loss=0.5081956386566162
[15/24] Train loss=0.4380750358104706
[20/24] Train loss=0.42463523149490356
Test set avg_accuracy=82.68% avg_sensitivity=78.91%, avg_specificity=84.11% avg_auc=89.45%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.467362 Test loss=0.394943 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.42131420969963074
[5/24] Train loss=0.45259907841682434
[10/24] Train loss=0.5125061869621277
[15/24] Train loss=0.4406968951225281
[20/24] Train loss=0.4227486550807953
Test set avg_accuracy=82.67% avg_sensitivity=77.96%, avg_specificity=84.45% avg_auc=89.34%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.464299 Test loss=0.395035 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.4263499975204468
[5/24] Train loss=0.461966335773468
[10/24] Train loss=0.506966233253479
[15/24] Train loss=0.43416279554367065
[20/24] Train loss=0.4123040735721588
Test set avg_accuracy=82.33% avg_sensitivity=77.91%, avg_specificity=84.00% avg_auc=89.21%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.461867 Test loss=0.399483 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.4245748519897461
[5/24] Train loss=0.4485228955745697
[10/24] Train loss=0.5026810765266418
[15/24] Train loss=0.42838913202285767
[20/24] Train loss=0.4020993113517761
Test set avg_accuracy=82.53% avg_sensitivity=77.01%, avg_specificity=84.61% avg_auc=89.20%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.456337 Test loss=0.397140 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.42179620265960693
[5/24] Train loss=0.45563045144081116
[10/24] Train loss=0.5005425214767456
[15/24] Train loss=0.42994260787963867
[20/24] Train loss=0.4090588092803955
Test set avg_accuracy=82.72% avg_sensitivity=77.63%, avg_specificity=84.65% avg_auc=89.26%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.452067 Test loss=0.397726 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.41512331366539
[5/24] Train loss=0.4358493685722351
[10/24] Train loss=0.50184166431427
[15/24] Train loss=0.41724738478660583
[20/24] Train loss=0.40862157940864563
Test set avg_accuracy=82.68% avg_sensitivity=77.96%, avg_specificity=84.47% avg_auc=89.20%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.448298 Test loss=0.400524 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.4115329682826996
[5/24] Train loss=0.4446912407875061
[10/24] Train loss=0.4985376000404358
[15/24] Train loss=0.42237842082977295
[20/24] Train loss=0.3794602155685425
Test set avg_accuracy=82.79% avg_sensitivity=76.49%, avg_specificity=85.17% avg_auc=89.22%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.444850 Test loss=0.394872 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.4078715145587921
[5/24] Train loss=0.43306684494018555
[10/24] Train loss=0.5155289173126221
[15/24] Train loss=0.41829460859298706
[20/24] Train loss=0.38887953758239746
Test set avg_accuracy=82.99% avg_sensitivity=75.64%, avg_specificity=85.78% avg_auc=89.17%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.444570 Test loss=0.391220 Current lr=[0.000224838296036774]

[0/24] Train loss=0.41053423285484314
[5/24] Train loss=0.44730716943740845
[10/24] Train loss=0.4868498146533966
[15/24] Train loss=0.42270994186401367
[20/24] Train loss=0.3934669494628906
Test set avg_accuracy=82.76% avg_sensitivity=76.68%, avg_specificity=85.06% avg_auc=89.19%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.440529 Test loss=0.398692 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.39533647894859314
[5/24] Train loss=0.42250096797943115
[10/24] Train loss=0.48447543382644653
[15/24] Train loss=0.400418758392334
[20/24] Train loss=0.38986319303512573
Test set avg_accuracy=83.05% avg_sensitivity=74.36%, avg_specificity=86.34% avg_auc=89.15%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.438667 Test loss=0.391123 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.4076034128665924
[5/24] Train loss=0.42822369933128357
[10/24] Train loss=0.47021350264549255
[15/24] Train loss=0.40318676829338074
[20/24] Train loss=0.38687920570373535
Test set avg_accuracy=82.34% avg_sensitivity=76.92%, avg_specificity=84.40% avg_auc=89.09%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.433417 Test loss=0.405522 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.39110231399536133
[5/24] Train loss=0.41621172428131104
[10/24] Train loss=0.46590927243232727
[15/24] Train loss=0.4064975380897522
[20/24] Train loss=0.39174848794937134
Test set avg_accuracy=82.75% avg_sensitivity=75.97%, avg_specificity=85.31% avg_auc=88.98%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.430264 Test loss=0.400382 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.39023497700691223
[5/24] Train loss=0.41257020831108093
[10/24] Train loss=0.471017986536026
[15/24] Train loss=0.4031347930431366
[20/24] Train loss=0.39495912194252014
Test set avg_accuracy=82.25% avg_sensitivity=76.21%, avg_specificity=84.54% avg_auc=88.86%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.427362 Test loss=0.408022 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3798607885837555
[5/24] Train loss=0.4237743616104126
[10/24] Train loss=0.45505857467651367
[15/24] Train loss=0.4028856158256531
[20/24] Train loss=0.3815476894378662
Test set avg_accuracy=82.55% avg_sensitivity=75.64%, avg_specificity=85.17% avg_auc=88.95%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.422225 Test loss=0.403507 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3951224982738495
[5/24] Train loss=0.4204131066799164
[10/24] Train loss=0.46588024497032166
[15/24] Train loss=0.4040587246417999
[20/24] Train loss=0.37522876262664795
Test set avg_accuracy=82.30% avg_sensitivity=75.45%, avg_specificity=84.90% avg_auc=88.89%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.421863 Test loss=0.406222 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.37683728337287903
[5/24] Train loss=0.40432918071746826
[10/24] Train loss=0.46361538767814636
[15/24] Train loss=0.39587903022766113
[20/24] Train loss=0.3795463740825653
Test set avg_accuracy=82.03% avg_sensitivity=77.91%, avg_specificity=83.59% avg_auc=88.86%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.419293 Test loss=0.418670 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.38770174980163574
[5/24] Train loss=0.4090976417064667
[10/24] Train loss=0.44855520129203796
[15/24] Train loss=0.4118780493736267
[20/24] Train loss=0.3746858835220337
Test set avg_accuracy=81.51% avg_sensitivity=79.05%, avg_specificity=82.44% avg_auc=88.87%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.422918 Test loss=0.427136 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3818126320838928
[5/24] Train loss=0.41517341136932373
[10/24] Train loss=0.468570351600647
[15/24] Train loss=0.3977185785770416
[20/24] Train loss=0.372376412153244
Test set avg_accuracy=81.91% avg_sensitivity=78.10%, avg_specificity=83.36% avg_auc=88.88%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.423712 Test loss=0.419555 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.387218177318573
[5/24] Train loss=0.4191224277019501
[10/24] Train loss=0.4731054902076721
[15/24] Train loss=0.3950296640396118
[20/24] Train loss=0.38133174180984497
Test set avg_accuracy=82.80% avg_sensitivity=74.64%, avg_specificity=85.89% avg_auc=88.88%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.421194 Test loss=0.402462 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.39522600173950195
[5/24] Train loss=0.40995562076568604
[10/24] Train loss=0.4493243098258972
[15/24] Train loss=0.3916611671447754
[20/24] Train loss=0.37042829394340515
Test set avg_accuracy=81.91% avg_sensitivity=78.39%, avg_specificity=83.25% avg_auc=88.91%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.418447 Test loss=0.422056 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3872469663619995
[5/24] Train loss=0.4090208411216736
[10/24] Train loss=0.46654391288757324
[15/24] Train loss=0.41070666909217834
[20/24] Train loss=0.41464582085609436
Test set avg_accuracy=79.36% avg_sensitivity=83.65%, avg_specificity=77.74% avg_auc=88.96%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.428629 Test loss=0.482236 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.4184865653514862
[5/24] Train loss=0.4392286241054535
[10/24] Train loss=0.4507826864719391
[15/24] Train loss=0.3985992968082428
[20/24] Train loss=0.3982783555984497
Test set avg_accuracy=81.48% avg_sensitivity=78.91%, avg_specificity=82.46% avg_auc=88.77%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.448794 Test loss=0.428605 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.389969140291214
[5/24] Train loss=0.4220908582210541
[10/24] Train loss=0.46469300985336304
[15/24] Train loss=0.41234463453292847
[20/24] Train loss=0.37336045503616333
Test set avg_accuracy=81.54% avg_sensitivity=78.72%, avg_specificity=82.60% avg_auc=88.93%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.423871 Test loss=0.427285 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3821580410003662
[5/24] Train loss=0.4025012254714966
[10/24] Train loss=0.45405465364456177
[15/24] Train loss=0.4028404951095581
[20/24] Train loss=0.3840522766113281
Test set avg_accuracy=82.01% avg_sensitivity=77.49%, avg_specificity=83.72% avg_auc=88.92%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.419737 Test loss=0.418625 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3819338083267212
[5/24] Train loss=0.4053875207901001
[10/24] Train loss=0.4459618926048279
[15/24] Train loss=0.3891488015651703
[20/24] Train loss=0.3593272268772125
Test set avg_accuracy=81.78% avg_sensitivity=77.54%, avg_specificity=83.39% avg_auc=88.97%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.408956 Test loss=0.420984 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3761375844478607
[5/24] Train loss=0.3873395025730133
[10/24] Train loss=0.448324978351593
[15/24] Train loss=0.39171409606933594
[20/24] Train loss=0.3624524772167206
Test set avg_accuracy=81.97% avg_sensitivity=76.59%, avg_specificity=84.00% avg_auc=88.96%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.407033 Test loss=0.416890 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3714037835597992
[5/24] Train loss=0.38395482301712036
[10/24] Train loss=0.441895991563797
[15/24] Train loss=0.40005555748939514
[20/24] Train loss=0.36041808128356934
Test set avg_accuracy=81.80% avg_sensitivity=77.35%, avg_specificity=83.48% avg_auc=88.92%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.404155 Test loss=0.423152 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3683808147907257
[5/24] Train loss=0.3771972954273224
[10/24] Train loss=0.4397307336330414
[15/24] Train loss=0.39024120569229126
[20/24] Train loss=0.3647063076496124
Test set avg_accuracy=81.64% avg_sensitivity=76.68%, avg_specificity=83.52% avg_auc=88.94%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.403230 Test loss=0.421719 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.364789217710495
[5/24] Train loss=0.38826289772987366
[10/24] Train loss=0.4377105236053467
[15/24] Train loss=0.3832201063632965
[20/24] Train loss=0.3621096611022949
Test set avg_accuracy=82.21% avg_sensitivity=75.40%, avg_specificity=84.79% avg_auc=88.89%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.402508 Test loss=0.414383 Current lr=[0.000134135431043539]

[0/24] Train loss=0.35742712020874023
[5/24] Train loss=0.38365620374679565
[10/24] Train loss=0.43811896443367004
[15/24] Train loss=0.38677912950515747
[20/24] Train loss=0.3638419210910797
Test set avg_accuracy=81.94% avg_sensitivity=76.87%, avg_specificity=83.86% avg_auc=88.93%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.400073 Test loss=0.422567 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3787572383880615
[5/24] Train loss=0.3865016996860504
[10/24] Train loss=0.45419034361839294
[15/24] Train loss=0.3960247039794922
[20/24] Train loss=0.36185672879219055
Test set avg_accuracy=82.16% avg_sensitivity=76.16%, avg_specificity=84.43% avg_auc=88.96%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.400864 Test loss=0.417727 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.37165266275405884
[5/24] Train loss=0.4089410603046417
[10/24] Train loss=0.4402436912059784
[15/24] Train loss=0.3907358646392822
[20/24] Train loss=0.36422955989837646
Test set avg_accuracy=82.02% avg_sensitivity=76.11%, avg_specificity=84.25% avg_auc=88.91%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.404901 Test loss=0.421057 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3779068887233734
[5/24] Train loss=0.4033186137676239
[10/24] Train loss=0.4473033547401428
[15/24] Train loss=0.37670332193374634
[20/24] Train loss=0.367641806602478
Test set avg_accuracy=81.89% avg_sensitivity=78.06%, avg_specificity=83.34% avg_auc=88.91%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.403968 Test loss=0.433012 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.37113499641418457
[5/24] Train loss=0.40331390500068665
[10/24] Train loss=0.4705827236175537
[15/24] Train loss=0.4070538878440857
[20/24] Train loss=0.3625982403755188
Test set avg_accuracy=81.07% avg_sensitivity=80.19%, avg_specificity=81.40% avg_auc=88.85%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.412933 Test loss=0.457994 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.39044389128685
[5/24] Train loss=0.4346085786819458
[10/24] Train loss=0.47869881987571716
[15/24] Train loss=0.38529539108276367
[20/24] Train loss=0.372637003660202
Test set avg_accuracy=79.99% avg_sensitivity=82.27%, avg_specificity=79.12% avg_auc=88.82%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.414778 Test loss=0.488613 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.4143564999103546
[5/24] Train loss=0.43781957030296326
[10/24] Train loss=0.46127742528915405
[15/24] Train loss=0.38130176067352295
[20/24] Train loss=0.40376484394073486
Test set avg_accuracy=80.46% avg_sensitivity=81.04%, avg_specificity=80.23% avg_auc=88.77%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.423841 Test loss=0.467110 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3792146146297455
[5/24] Train loss=0.4032517373561859
[10/24] Train loss=0.459092915058136
[15/24] Train loss=0.3831496238708496
[20/24] Train loss=0.37000828981399536
Test set avg_accuracy=81.73% avg_sensitivity=76.92%, avg_specificity=83.55% avg_auc=88.62%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.409881 Test loss=0.427441 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3581007719039917
[5/24] Train loss=0.3984314203262329
[10/24] Train loss=0.44197505712509155
[15/24] Train loss=0.3856498599052429
[20/24] Train loss=0.3671727180480957
Test set avg_accuracy=81.45% avg_sensitivity=78.48%, avg_specificity=82.57% avg_auc=88.67%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.395720 Test loss=0.436674 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3611706793308258
[5/24] Train loss=0.3753608465194702
[10/24] Train loss=0.43860435485839844
[15/24] Train loss=0.37810230255126953
[20/24] Train loss=0.3745950162410736
Test set avg_accuracy=81.60% avg_sensitivity=78.06%, avg_specificity=82.94% avg_auc=88.72%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.393027 Test loss=0.435298 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3600146770477295
[5/24] Train loss=0.3825697898864746
[10/24] Train loss=0.4433819055557251
[15/24] Train loss=0.36828261613845825
[20/24] Train loss=0.374601274728775
Test set avg_accuracy=81.52% avg_sensitivity=78.25%, avg_specificity=82.76% avg_auc=88.70%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.390580 Test loss=0.436386 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3568744659423828
[5/24] Train loss=0.36871981620788574
[10/24] Train loss=0.4346177279949188
[15/24] Train loss=0.36823704838752747
[20/24] Train loss=0.3529720604419708
Test set avg_accuracy=81.63% avg_sensitivity=77.49%, avg_specificity=83.20% avg_auc=88.63%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.387294 Test loss=0.433772 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.35774680972099304
[5/24] Train loss=0.3701398968696594
[10/24] Train loss=0.4281635582447052
[15/24] Train loss=0.3715510070323944
[20/24] Train loss=0.35448750853538513
Test set avg_accuracy=81.50% avg_sensitivity=77.96%, avg_specificity=82.84% avg_auc=88.62%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.383083 Test loss=0.436686 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.35397252440452576
[5/24] Train loss=0.3674139976501465
[10/24] Train loss=0.43160390853881836
[15/24] Train loss=0.3626304566860199
[20/24] Train loss=0.3548782467842102
Test set avg_accuracy=81.58% avg_sensitivity=77.58%, avg_specificity=83.09% avg_auc=88.60%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.383652 Test loss=0.435177 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.35198283195495605
[5/24] Train loss=0.35937464237213135
[10/24] Train loss=0.4347425103187561
[15/24] Train loss=0.3655972182750702
[20/24] Train loss=0.34530210494995117
Test set avg_accuracy=81.73% avg_sensitivity=77.01%, avg_specificity=83.52% avg_auc=88.63%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.380465 Test loss=0.430380 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3530956506729126
[5/24] Train loss=0.3716951906681061
[10/24] Train loss=0.4291835129261017
[15/24] Train loss=0.3576749265193939
[20/24] Train loss=0.35291871428489685
Test set avg_accuracy=81.60% avg_sensitivity=77.11%, avg_specificity=83.30% avg_auc=88.59%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.378956 Test loss=0.433748 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.34946513175964355
[5/24] Train loss=0.36117082834243774
[10/24] Train loss=0.41724854707717896
[15/24] Train loss=0.3589499592781067
[20/24] Train loss=0.35457146167755127
Test set avg_accuracy=81.80% avg_sensitivity=77.77%, avg_specificity=83.32% avg_auc=88.62%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.380600 Test loss=0.434118 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3518482446670532
[5/24] Train loss=0.3693137764930725
[10/24] Train loss=0.4135585129261017
[15/24] Train loss=0.361946702003479
[20/24] Train loss=0.35837894678115845
Test set avg_accuracy=81.64% avg_sensitivity=77.87%, avg_specificity=83.07% avg_auc=88.58%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.377870 Test loss=0.436274 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3441576361656189
[5/24] Train loss=0.3670807182788849
[10/24] Train loss=0.4065028727054596
[15/24] Train loss=0.35731321573257446
[20/24] Train loss=0.34997138381004333
Test set avg_accuracy=81.64% avg_sensitivity=76.59%, avg_specificity=83.55% avg_auc=88.55%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.374133 Test loss=0.431698 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3651360273361206
[5/24] Train loss=0.3662279546260834
[10/24] Train loss=0.4073706269264221
[15/24] Train loss=0.35163670778274536
[20/24] Train loss=0.3473740518093109
Test set avg_accuracy=81.67% avg_sensitivity=77.25%, avg_specificity=83.34% avg_auc=88.54%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.374957 Test loss=0.435197 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.33935534954071045
[5/24] Train loss=0.3678475320339203
[10/24] Train loss=0.4261492192745209
[15/24] Train loss=0.3505244255065918
[20/24] Train loss=0.34398531913757324
Test set avg_accuracy=81.72% avg_sensitivity=77.44%, avg_specificity=83.34% avg_auc=88.55%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.375387 Test loss=0.435361 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3449776768684387
[5/24] Train loss=0.37648114562034607
[10/24] Train loss=0.41617125272750854
[15/24] Train loss=0.35432738065719604
[20/24] Train loss=0.347104549407959
Test set avg_accuracy=81.63% avg_sensitivity=77.01%, avg_specificity=83.38% avg_auc=88.51%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.373480 Test loss=0.435363 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.35181325674057007
[5/24] Train loss=0.3517301082611084
[10/24] Train loss=0.41502615809440613
[15/24] Train loss=0.3566536009311676
[20/24] Train loss=0.33482298254966736
Test set avg_accuracy=81.54% avg_sensitivity=77.01%, avg_specificity=83.25% avg_auc=88.52%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.371707 Test loss=0.435409 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.351115882396698
[5/24] Train loss=0.36478671431541443
[10/24] Train loss=0.4132494330406189
[15/24] Train loss=0.3607237637042999
[20/24] Train loss=0.34818804264068604
Test set avg_accuracy=81.60% avg_sensitivity=76.78%, avg_specificity=83.43% avg_auc=88.52%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.373199 Test loss=0.433639 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3563089668750763
[5/24] Train loss=0.3673692047595978
[10/24] Train loss=0.40264901518821716
[15/24] Train loss=0.3571627140045166
[20/24] Train loss=0.34823983907699585
Test set avg_accuracy=81.67% avg_sensitivity=77.06%, avg_specificity=83.41% avg_auc=88.48%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.370362 Test loss=0.436277 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3305082619190216
[5/24] Train loss=0.3537229597568512
[10/24] Train loss=0.40689295530319214
[15/24] Train loss=0.35192856192588806
[20/24] Train loss=0.3500324487686157
Test set avg_accuracy=81.50% avg_sensitivity=77.16%, avg_specificity=83.14% avg_auc=88.49%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.371739 Test loss=0.437617 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.34880685806274414
[5/24] Train loss=0.3567022383213043
[10/24] Train loss=0.4130556583404541
[15/24] Train loss=0.3437724709510803
[20/24] Train loss=0.3453214168548584
Test set avg_accuracy=81.73% avg_sensitivity=77.01%, avg_specificity=83.52% avg_auc=88.47%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.370409 Test loss=0.435192 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.35728350281715393
[5/24] Train loss=0.35748445987701416
[10/24] Train loss=0.4174281060695648
[15/24] Train loss=0.3537973165512085
[20/24] Train loss=0.34192219376564026
Test set avg_accuracy=81.60% avg_sensitivity=76.97%, avg_specificity=83.36% avg_auc=88.48%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.372348 Test loss=0.436018 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3427550196647644
[5/24] Train loss=0.36341559886932373
[10/24] Train loss=0.4038260877132416
[15/24] Train loss=0.35432058572769165
[20/24] Train loss=0.34246233105659485
Test set avg_accuracy=81.39% avg_sensitivity=77.82%, avg_specificity=82.75% avg_auc=88.46%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.369447 Test loss=0.442531 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.35740768909454346
[5/24] Train loss=0.3602364659309387
[10/24] Train loss=0.40412840247154236
[15/24] Train loss=0.3493044674396515
[20/24] Train loss=0.34393006563186646
Test set avg_accuracy=81.37% avg_sensitivity=77.73%, avg_specificity=82.75% avg_auc=88.47%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.369759 Test loss=0.442114 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.35933852195739746
[5/24] Train loss=0.370737224817276
[10/24] Train loss=0.4133352041244507
[15/24] Train loss=0.3573763072490692
[20/24] Train loss=0.3347604274749756
Test set avg_accuracy=81.38% avg_sensitivity=77.63%, avg_specificity=82.80% avg_auc=88.45%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.370770 Test loss=0.442997 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.33639317750930786
[5/24] Train loss=0.3511054217815399
[10/24] Train loss=0.4092760980129242
[15/24] Train loss=0.36706051230430603
[20/24] Train loss=0.34339937567710876
Test set avg_accuracy=81.38% avg_sensitivity=77.39%, avg_specificity=82.89% avg_auc=88.43%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.370000 Test loss=0.441684 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.34992897510528564
[5/24] Train loss=0.35995256900787354
[10/24] Train loss=0.40882590413093567
[15/24] Train loss=0.35890763998031616
[20/24] Train loss=0.3423331081867218
Test set avg_accuracy=81.54% avg_sensitivity=77.01%, avg_specificity=83.25% avg_auc=88.45%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.367005 Test loss=0.438483 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.34448230266571045
[5/24] Train loss=0.3553747534751892
[10/24] Train loss=0.41102132201194763
[15/24] Train loss=0.3487960994243622
[20/24] Train loss=0.34119322896003723
Test set avg_accuracy=81.61% avg_sensitivity=76.87%, avg_specificity=83.41% avg_auc=88.43%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.370841 Test loss=0.437657 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.33966192603111267
[5/24] Train loss=0.35216188430786133
[10/24] Train loss=0.4105253517627716
[15/24] Train loss=0.36430126428604126
[20/24] Train loss=0.3406789004802704
Test set avg_accuracy=81.50% avg_sensitivity=76.73%, avg_specificity=83.30% avg_auc=88.42%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.368157 Test loss=0.438135 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3377341330051422
[5/24] Train loss=0.35783305764198303
[10/24] Train loss=0.40346255898475647
[15/24] Train loss=0.35515373945236206
[20/24] Train loss=0.34268778562545776
Test set avg_accuracy=81.59% avg_sensitivity=76.49%, avg_specificity=83.52% avg_auc=88.42%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.365704 Test loss=0.435975 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.33954179286956787
[5/24] Train loss=0.34776777029037476
[10/24] Train loss=0.4118894934654236
[15/24] Train loss=0.3588683307170868
[20/24] Train loss=0.3430187404155731
Test set avg_accuracy=81.61% avg_sensitivity=76.82%, avg_specificity=83.43% avg_auc=88.41%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.369650 Test loss=0.437396 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.34290868043899536
[5/24] Train loss=0.35790693759918213
[10/24] Train loss=0.4027147591114044
[15/24] Train loss=0.3497765362262726
[20/24] Train loss=0.3379940986633301
Test set avg_accuracy=81.67% avg_sensitivity=76.40%, avg_specificity=83.66% avg_auc=88.39%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.366259 Test loss=0.435958 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3529134690761566
[5/24] Train loss=0.35397282242774963
[10/24] Train loss=0.4091409146785736
[15/24] Train loss=0.349649041891098
[20/24] Train loss=0.34935489296913147
Test set avg_accuracy=81.52% avg_sensitivity=76.68%, avg_specificity=83.36% avg_auc=88.41%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.367773 Test loss=0.438320 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.33830803632736206
[5/24] Train loss=0.36004766821861267
[10/24] Train loss=0.4042353630065918
[15/24] Train loss=0.3520144820213318
[20/24] Train loss=0.3410308063030243
Test set avg_accuracy=81.63% avg_sensitivity=76.54%, avg_specificity=83.55% avg_auc=88.41%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.366178 Test loss=0.437024 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3381558954715729
[5/24] Train loss=0.34633052349090576
[10/24] Train loss=0.40218833088874817
[15/24] Train loss=0.3481689393520355
[20/24] Train loss=0.33582791686058044
Test set avg_accuracy=81.63% avg_sensitivity=76.59%, avg_specificity=83.54% avg_auc=88.42%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.365991 Test loss=0.437154 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.35028696060180664
[5/24] Train loss=0.3509984612464905
[10/24] Train loss=0.41271358728408813
[15/24] Train loss=0.3518274128437042
[20/24] Train loss=0.343143492937088
Test set avg_accuracy=81.64% avg_sensitivity=76.78%, avg_specificity=83.48% avg_auc=88.42%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.365534 Test loss=0.437959 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.34938597679138184
[5/24] Train loss=0.35607534646987915
[10/24] Train loss=0.41332897543907166
[15/24] Train loss=0.35435357689857483
[20/24] Train loss=0.3449063301086426
Test set avg_accuracy=81.60% avg_sensitivity=76.45%, avg_specificity=83.55% avg_auc=88.41%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.368197 Test loss=0.436820 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.34790271520614624
[5/24] Train loss=0.3593873977661133
[10/24] Train loss=0.4128696620464325
[15/24] Train loss=0.3575202524662018
[20/24] Train loss=0.33628109097480774
Test set avg_accuracy=81.59% avg_sensitivity=76.49%, avg_specificity=83.52% avg_auc=88.40%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.366705 Test loss=0.437147 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.34332436323165894
[5/24] Train loss=0.3572402000427246
[10/24] Train loss=0.4163915812969208
[15/24] Train loss=0.35199058055877686
[20/24] Train loss=0.33828020095825195
Test set avg_accuracy=81.59% avg_sensitivity=76.54%, avg_specificity=83.50% avg_auc=88.40%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.367577 Test loss=0.437506 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.34162187576293945
[5/24] Train loss=0.3574962019920349
[10/24] Train loss=0.42233654856681824
[15/24] Train loss=0.3500653803348541
[20/24] Train loss=0.33742812275886536
Test set avg_accuracy=81.60% avg_sensitivity=76.59%, avg_specificity=83.50% avg_auc=88.40%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.367289 Test loss=0.437690 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3533713221549988
[5/24] Train loss=0.3601212501525879
[10/24] Train loss=0.41028761863708496
[15/24] Train loss=0.35138875246047974
[20/24] Train loss=0.3316875100135803
Test set avg_accuracy=81.59% avg_sensitivity=76.54%, avg_specificity=83.50% avg_auc=88.40%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.367311 Test loss=0.437453 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.33582156896591187
[5/24] Train loss=0.36126908659935
[10/24] Train loss=0.41348791122436523
[15/24] Train loss=0.35289767384529114
[20/24] Train loss=0.34662458300590515
Test set avg_accuracy=81.59% avg_sensitivity=76.54%, avg_specificity=83.50% avg_auc=88.40%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.367962 Test loss=0.437338 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.33144503831863403
[5/24] Train loss=0.3627277612686157
[10/24] Train loss=0.408283531665802
[15/24] Train loss=0.3497680127620697
[20/24] Train loss=0.34941577911376953
Test set avg_accuracy=81.59% avg_sensitivity=76.54%, avg_specificity=83.50% avg_auc=88.40%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.366958 Test loss=0.437331 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=82.41% sen=81.04%, spe=82.93%, auc=90.53%!
Fold[3] Avg_jsc=0.60%(±0.23950507516679123)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.9636729955673218
[5/24] Train loss=1.8322843313217163
[10/24] Train loss=1.7344878911972046
[15/24] Train loss=1.653480887413025
[20/24] Train loss=1.5781996250152588
Test set avg_accuracy=53.58% avg_sensitivity=48.48%, avg_specificity=55.38% avg_auc=52.73%
Best model saved!! Metric=52.72793696478051!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=1.726617 Test loss=0.708911 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.5813019275665283
[5/24] Train loss=1.5542171001434326
[10/24] Train loss=1.5320038795471191
[15/24] Train loss=1.5163017511367798
[20/24] Train loss=1.515475869178772
Test set avg_accuracy=55.64% avg_sensitivity=43.23%, avg_specificity=60.01% avg_auc=53.79%
Best model saved!! Metric=53.78783578804013!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=1.531234 Test loss=0.682852 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.4896793365478516
[5/24] Train loss=1.5107526779174805
[10/24] Train loss=1.4819302558898926
[15/24] Train loss=1.461878776550293
[20/24] Train loss=1.482520580291748
Test set avg_accuracy=52.24% avg_sensitivity=57.62%, avg_specificity=50.34% avg_auc=55.85%
Best model saved!! Metric=55.85370723689045!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=1.484585 Test loss=0.695841 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.4432235956192017
[5/24] Train loss=1.482936143875122
[10/24] Train loss=1.4714325666427612
[15/24] Train loss=1.4340296983718872
[20/24] Train loss=1.455376148223877
Test set avg_accuracy=54.10% avg_sensitivity=57.12%, avg_specificity=53.04% avg_auc=57.42%
Best model saved!! Metric=57.417571369272224!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=1.456530 Test loss=0.686314 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.4337197542190552
[5/24] Train loss=1.4460088014602661
[10/24] Train loss=1.448060154914856
[15/24] Train loss=1.4198137521743774
[20/24] Train loss=1.4317395687103271
Test set avg_accuracy=56.84% avg_sensitivity=55.52%, avg_specificity=57.30% avg_auc=59.43%
Best model saved!! Metric=59.426168233016796!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=1.433887 Test loss=0.673718 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.4340020418167114
[5/24] Train loss=1.4495794773101807
[10/24] Train loss=1.4290461540222168
[15/24] Train loss=1.4006353616714478
[20/24] Train loss=1.4015333652496338
Test set avg_accuracy=57.96% avg_sensitivity=57.42%, avg_specificity=58.14% avg_auc=61.28%
Best model saved!! Metric=61.27888688161642!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=1.421448 Test loss=0.668060 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.4146662950515747
[5/24] Train loss=1.411584496498108
[10/24] Train loss=1.3970035314559937
[15/24] Train loss=1.3848956823349
[20/24] Train loss=1.3666534423828125
Test set avg_accuracy=59.17% avg_sensitivity=58.92%, avg_specificity=59.25% avg_auc=62.97%
Best model saved!! Metric=62.96633335031727!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=1.404752 Test loss=0.663444 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.386123776435852
[5/24] Train loss=1.3893921375274658
[10/24] Train loss=1.3705190420150757
[15/24] Train loss=1.3780632019042969
[20/24] Train loss=1.3580363988876343
Test set avg_accuracy=60.91% avg_sensitivity=59.67%, avg_specificity=61.35% avg_auc=64.73%
Best model saved!! Metric=64.73316872115095!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=1.383440 Test loss=0.656519 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.3657093048095703
[5/24] Train loss=1.3892697095870972
[10/24] Train loss=1.3848178386688232
[15/24] Train loss=1.341411828994751
[20/24] Train loss=1.3412659168243408
Test set avg_accuracy=61.16% avg_sensitivity=62.27%, avg_specificity=60.77% avg_auc=66.33%
Best model saved!! Metric=66.32939473211096!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=1.368313 Test loss=0.652692 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.35445237159729
[5/24] Train loss=1.3650497198104858
[10/24] Train loss=1.3737175464630127
[15/24] Train loss=1.318931221961975
[20/24] Train loss=1.3235087394714355
Test set avg_accuracy=62.45% avg_sensitivity=65.12%, avg_specificity=61.51% avg_auc=68.07%
Best model saved!! Metric=68.07417298570296!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=1.350374 Test loss=0.646932 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.3342257738113403
[5/24] Train loss=1.363465428352356
[10/24] Train loss=1.3332056999206543
[15/24] Train loss=1.290980577468872
[20/24] Train loss=1.2859715223312378
Test set avg_accuracy=63.24% avg_sensitivity=67.97%, avg_specificity=61.58% avg_auc=69.75%
Best model saved!! Metric=69.75278428755335!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=1.327718 Test loss=0.641259 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.3056477308273315
[5/24] Train loss=1.3421549797058105
[10/24] Train loss=1.3318722248077393
[15/24] Train loss=1.2783010005950928
[20/24] Train loss=1.2440341711044312
Test set avg_accuracy=64.91% avg_sensitivity=69.32%, avg_specificity=63.36% avg_auc=71.75%
Best model saved!! Metric=71.7543895775303!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=1.301496 Test loss=0.628379 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.2630789279937744
[5/24] Train loss=1.3123159408569336
[10/24] Train loss=1.3161306381225586
[15/24] Train loss=1.2386271953582764
[20/24] Train loss=1.1821503639221191
Test set avg_accuracy=65.83% avg_sensitivity=73.71%, avg_specificity=63.06% avg_auc=74.25%
Best model saved!! Metric=74.25454819693518!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=1.265331 Test loss=0.617371 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.210221529006958
[5/24] Train loss=1.264744520187378
[10/24] Train loss=1.2533310651779175
[15/24] Train loss=1.1840922832489014
[20/24] Train loss=1.129997730255127
Test set avg_accuracy=67.03% avg_sensitivity=78.86%, avg_specificity=62.86% avg_auc=77.03%
Best model saved!! Metric=77.02709219435008!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=1.213117 Test loss=0.612755 Current lr=[7.558439349929357e-05]

[0/24] Train loss=1.1609472036361694
[5/24] Train loss=1.2371379137039185
[10/24] Train loss=1.222305417060852
[15/24] Train loss=1.1019484996795654
[20/24] Train loss=1.0678362846374512
Test set avg_accuracy=69.86% avg_sensitivity=80.36%, avg_specificity=66.16% avg_auc=79.32%
Best model saved!! Metric=79.32006879110189!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=1.160099 Test loss=0.590062 Current lr=[8.412106591444728e-05]

[0/24] Train loss=1.0990307331085205
[5/24] Train loss=1.1888985633850098
[10/24] Train loss=1.1601881980895996
[15/24] Train loss=1.090166687965393
[20/24] Train loss=1.0347896814346313
Test set avg_accuracy=69.32% avg_sensitivity=83.71%, avg_specificity=64.25% avg_auc=80.74%
Best model saved!! Metric=80.74377144936953!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=1.117518 Test loss=0.600182 Current lr=[9.300857440308985e-05]

[0/24] Train loss=1.0777572393417358
[5/24] Train loss=1.163380742073059
[10/24] Train loss=1.1340076923370361
[15/24] Train loss=1.0629903078079224
[20/24] Train loss=1.029353141784668
Test set avg_accuracy=69.06% avg_sensitivity=85.91%, avg_specificity=63.13% avg_auc=81.65%
Best model saved!! Metric=81.6450728676866!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=1.092090 Test loss=0.606792 Current lr=[0.00010220353965498347]

[0/24] Train loss=1.0563867092132568
[5/24] Train loss=1.1281260251998901
[10/24] Train loss=1.1161444187164307
[15/24] Train loss=1.030341625213623
[20/24] Train loss=1.006722092628479
Test set avg_accuracy=69.05% avg_sensitivity=86.16%, avg_specificity=63.02% avg_auc=82.21%
Best model saved!! Metric=82.214127132595!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=1.068829 Test loss=0.608037 Current lr=[0.0001116610816848323]

[0/24] Train loss=1.0274664163589478
[5/24] Train loss=1.119141936302185
[10/24] Train loss=1.1036326885223389
[15/24] Train loss=1.010658860206604
[20/24] Train loss=0.9809163212776184
Test set avg_accuracy=70.17% avg_sensitivity=86.36%, avg_specificity=64.47% avg_auc=82.69%
Best model saved!! Metric=82.69069374451706!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=1.048175 Test loss=0.595743 Current lr=[0.00012133503888836635]

[0/24] Train loss=1.019788146018982
[5/24] Train loss=1.0912059545516968
[10/24] Train loss=1.0959064960479736
[15/24] Train loss=1.0092607736587524
[20/24] Train loss=0.9633549451828003
Test set avg_accuracy=70.57% avg_sensitivity=85.51%, avg_specificity=65.31% avg_auc=83.02%
Best model saved!! Metric=83.02275609861911!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=1.033694 Test loss=0.584787 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.9914600849151611
[5/24] Train loss=1.0378388166427612
[10/24] Train loss=1.0716111660003662
[15/24] Train loss=0.9791440367698669
[20/24] Train loss=0.9500219225883484
Test set avg_accuracy=70.68% avg_sensitivity=85.66%, avg_specificity=65.40% avg_auc=83.36%
Best model saved!! Metric=83.35697444463189!!
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=1.017387 Test loss=0.583378 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.9795738458633423
[5/24] Train loss=1.017189621925354
[10/24] Train loss=1.0691486597061157
[15/24] Train loss=0.9840379357337952
[20/24] Train loss=0.9435127973556519
Test set avg_accuracy=71.03% avg_sensitivity=85.91%, avg_specificity=65.79% avg_auc=83.55%
Best model saved!! Metric=83.55275611005908!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=1.008430 Test loss=0.580946 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.9790012240409851
[5/24] Train loss=1.002841591835022
[10/24] Train loss=1.0552303791046143
[15/24] Train loss=0.9916771650314331
[20/24] Train loss=0.9457969069480896
Test set avg_accuracy=71.18% avg_sensitivity=85.51%, avg_specificity=66.14% avg_auc=83.83%
Best model saved!! Metric=83.82960307132927!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=1.004298 Test loss=0.574661 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.9614481925964355
[5/24] Train loss=0.9794361591339111
[10/24] Train loss=1.039358139038086
[15/24] Train loss=0.9677311182022095
[20/24] Train loss=0.9220289587974548
Test set avg_accuracy=72.19% avg_sensitivity=84.71%, avg_specificity=67.78% avg_auc=84.11%
Best model saved!! Metric=84.1061420337551!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.989854 Test loss=0.557277 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.9511009454727173
[5/24] Train loss=0.9575190544128418
[10/24] Train loss=1.0540121793746948
[15/24] Train loss=0.9537273645401001
[20/24] Train loss=0.8851949572563171
Test set avg_accuracy=73.98% avg_sensitivity=83.11%, avg_specificity=70.77% avg_auc=84.31%
Best model saved!! Metric=84.31402365378324!!
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.979481 Test loss=0.531050 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.9278681874275208
[5/24] Train loss=0.9352768063545227
[10/24] Train loss=1.0336183309555054
[15/24] Train loss=0.940989077091217
[20/24] Train loss=0.8648726344108582
Test set avg_accuracy=75.99% avg_sensitivity=80.51%, avg_specificity=74.40% avg_auc=84.60%
Best model saved!! Metric=84.59503739941967!!
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.964725 Test loss=0.502547 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.9166811108589172
[5/24] Train loss=0.9374780654907227
[10/24] Train loss=1.018470287322998
[15/24] Train loss=0.9393796920776367
[20/24] Train loss=0.8726305961608887
Test set avg_accuracy=76.55% avg_sensitivity=79.91%, avg_specificity=75.37% avg_auc=84.79%
Best model saved!! Metric=84.79203786027395!!
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.953261 Test loss=0.495668 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.9088308811187744
[5/24] Train loss=0.9217318892478943
[10/24] Train loss=1.0168520212173462
[15/24] Train loss=0.9319444298744202
[20/24] Train loss=0.8671680092811584
Test set avg_accuracy=77.28% avg_sensitivity=78.86%, avg_specificity=76.72% avg_auc=85.02%
Best model saved!! Metric=85.01691221654536!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.943640 Test loss=0.483887 Current lr=[0.000210185142098938]

[0/24] Train loss=0.9058200120925903
[5/24] Train loss=0.9390893578529358
[10/24] Train loss=1.009835124015808
[15/24] Train loss=0.9222107529640198
[20/24] Train loss=0.8627767562866211
Test set avg_accuracy=77.63% avg_sensitivity=79.56%, avg_specificity=76.95% avg_auc=85.25%
Best model saved!! Metric=85.24562335842117!!
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.939673 Test loss=0.480889 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.9037888050079346
[5/24] Train loss=0.9236515760421753
[10/24] Train loss=0.9877856373786926
[15/24] Train loss=0.9223273396492004
[20/24] Train loss=0.8490041494369507
Test set avg_accuracy=78.23% avg_sensitivity=78.86%, avg_specificity=78.01% avg_auc=85.45%
Best model saved!! Metric=85.45125658688528!!
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.929869 Test loss=0.471750 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.9064521193504333
[5/24] Train loss=0.9298973679542542
[10/24] Train loss=1.002663254737854
[15/24] Train loss=0.9292782545089722
[20/24] Train loss=0.84723299741745
Test set avg_accuracy=77.99% avg_sensitivity=80.96%, avg_specificity=76.95% avg_auc=85.69%
Best model saved!! Metric=85.69359887761699!!
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.927307 Test loss=0.478841 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.8869966864585876
[5/24] Train loss=0.8947095274925232
[10/24] Train loss=0.9727835655212402
[15/24] Train loss=0.9296305775642395
[20/24] Train loss=0.8610714673995972
Test set avg_accuracy=78.88% avg_sensitivity=79.06%, avg_specificity=78.82% avg_auc=85.85%
Best model saved!! Metric=85.85379787655036!!
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.919165 Test loss=0.461281 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.8825672268867493
[5/24] Train loss=0.9254917502403259
[10/24] Train loss=0.9696532487869263
[15/24] Train loss=0.9212222099304199
[20/24] Train loss=0.8479098677635193
Test set avg_accuracy=78.85% avg_sensitivity=80.41%, avg_specificity=78.31% avg_auc=86.00%
Best model saved!! Metric=86.00389891337127!!
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.916317 Test loss=0.466175 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.8667852282524109
[5/24] Train loss=0.9258261919021606
[10/24] Train loss=0.9588132500648499
[15/24] Train loss=0.9225255846977234
[20/24] Train loss=0.8477604389190674
Test set avg_accuracy=79.04% avg_sensitivity=79.96%, avg_specificity=78.71% avg_auc=86.16%
Best model saved!! Metric=86.16223671928785!!
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.907373 Test loss=0.462160 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.8699768781661987
[5/24] Train loss=0.894959568977356
[10/24] Train loss=0.9626176953315735
[15/24] Train loss=0.8979580402374268
[20/24] Train loss=0.8418568968772888
Test set avg_accuracy=79.47% avg_sensitivity=79.21%, avg_specificity=79.56% avg_auc=86.33%
Best model saved!! Metric=86.33430247369712!!
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.900323 Test loss=0.453439 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.8679840564727783
[5/24] Train loss=0.8958783745765686
[10/24] Train loss=0.9631237387657166
[15/24] Train loss=0.8931832909584045
[20/24] Train loss=0.8352439403533936
Test set avg_accuracy=79.58% avg_sensitivity=80.36%, avg_specificity=79.31% avg_auc=86.50%
Best model saved!! Metric=86.50012025154882!!
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.897206 Test loss=0.454870 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.8500030040740967
[5/24] Train loss=0.9068390727043152
[10/24] Train loss=0.9349153637886047
[15/24] Train loss=0.886378824710846
[20/24] Train loss=0.8180394768714905
Test set avg_accuracy=79.69% avg_sensitivity=79.76%, avg_specificity=79.66% avg_auc=86.62%
Best model saved!! Metric=86.61696621314276!!
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.889989 Test loss=0.450577 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.8382564783096313
[5/24] Train loss=0.871634840965271
[10/24] Train loss=0.9350353479385376
[15/24] Train loss=0.8821772933006287
[20/24] Train loss=0.8283916711807251
Test set avg_accuracy=79.90% avg_sensitivity=79.66%, avg_specificity=79.98% avg_auc=86.76%
Best model saved!! Metric=86.75612889100441!!
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.878909 Test loss=0.446709 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.8463446497917175
[5/24] Train loss=0.8667104244232178
[10/24] Train loss=0.9327694177627563
[15/24] Train loss=0.890351414680481
[20/24] Train loss=0.8106551170349121
Test set avg_accuracy=80.07% avg_sensitivity=79.46%, avg_specificity=80.28% avg_auc=86.83%
Best model saved!! Metric=86.83048421202322!!
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.872315 Test loss=0.443894 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.8444958329200745
[5/24] Train loss=0.8686955571174622
[10/24] Train loss=0.9311409592628479
[15/24] Train loss=0.8668448328971863
[20/24] Train loss=0.7944868206977844
Test set avg_accuracy=79.71% avg_sensitivity=79.36%, avg_specificity=79.84% avg_auc=86.88%
Best model saved!! Metric=86.87908202968423!!
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.866528 Test loss=0.447659 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.8254578113555908
[5/24] Train loss=0.8580474257469177
[10/24] Train loss=0.9255360960960388
[15/24] Train loss=0.879405677318573
[20/24] Train loss=0.8136371374130249
Test set avg_accuracy=79.95% avg_sensitivity=80.01%, avg_specificity=79.93% avg_auc=86.94%
Best model saved!! Metric=86.94487498282906!!
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.864115 Test loss=0.444275 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.8222473859786987
[5/24] Train loss=0.8208099007606506
[10/24] Train loss=0.9089334607124329
[15/24] Train loss=0.8463783860206604
[20/24] Train loss=0.8010144829750061
Test set avg_accuracy=79.91% avg_sensitivity=80.56%, avg_specificity=79.68% avg_auc=86.97%
Best model saved!! Metric=86.97266087857638!!
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.855374 Test loss=0.447412 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.8096861243247986
[5/24] Train loss=0.8294413089752197
[10/24] Train loss=0.9133227467536926
[15/24] Train loss=0.8605672717094421
[20/24] Train loss=0.7862120866775513
Test set avg_accuracy=79.65% avg_sensitivity=80.66%, avg_specificity=79.29% avg_auc=87.09%
Best model saved!! Metric=87.08654125129722!!
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.848696 Test loss=0.450132 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.8144923448562622
[5/24] Train loss=0.7931654453277588
[10/24] Train loss=0.9010105729103088
[15/24] Train loss=0.8419184684753418
[20/24] Train loss=0.7958117723464966
Test set avg_accuracy=80.27% avg_sensitivity=78.86%, avg_specificity=80.77% avg_auc=87.16%
Best model saved!! Metric=87.16244976648848!!
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.839349 Test loss=0.435911 Current lr=[0.00029967723776099]

[0/24] Train loss=0.8038161396980286
[5/24] Train loss=0.8149003982543945
[10/24] Train loss=0.8928284049034119
[15/24] Train loss=0.8349965810775757
[20/24] Train loss=0.7766879796981812
Test set avg_accuracy=79.86% avg_sensitivity=80.51%, avg_specificity=79.63% avg_auc=87.24%
Best model saved!! Metric=87.23866188054062!!
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.834017 Test loss=0.447674 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.7910791039466858
[5/24] Train loss=0.7951835989952087
[10/24] Train loss=0.8864201903343201
[15/24] Train loss=0.8283626437187195
[20/24] Train loss=0.7663702964782715
Test set avg_accuracy=79.67% avg_sensitivity=81.06%, avg_specificity=79.19% avg_auc=87.23%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.826699 Test loss=0.448192 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.7998615503311157
[5/24] Train loss=0.7888176441192627
[10/24] Train loss=0.8772938251495361
[15/24] Train loss=0.8274316787719727
[20/24] Train loss=0.7596413493156433
Test set avg_accuracy=79.96% avg_sensitivity=80.76%, avg_specificity=79.68% avg_auc=87.31%
Best model saved!! Metric=87.31028921179487!!
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.819120 Test loss=0.445237 Current lr=[0.000299720220882401]

[0/24] Train loss=0.7895789742469788
[5/24] Train loss=0.7997800707817078
[10/24] Train loss=0.8873239159584045
[15/24] Train loss=0.8188586831092834
[20/24] Train loss=0.7502450346946716
Test set avg_accuracy=79.90% avg_sensitivity=81.31%, avg_specificity=79.40% avg_auc=87.36%
Best model saved!! Metric=87.35793663302177!!
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.818542 Test loss=0.447782 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.783036470413208
[5/24] Train loss=0.7611234784126282
[10/24] Train loss=0.8687398433685303
[15/24] Train loss=0.8259527683258057
[20/24] Train loss=0.7637723684310913
Test set avg_accuracy=80.14% avg_sensitivity=80.71%, avg_specificity=79.94% avg_auc=87.39%
Best model saved!! Metric=87.3866113254343!!
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.810724 Test loss=0.442775 Current lr=[0.000298904600941902]

[0/24] Train loss=0.7717984914779663
[5/24] Train loss=0.7735443115234375
[10/24] Train loss=0.8758252859115601
[15/24] Train loss=0.8093271851539612
[20/24] Train loss=0.7431002259254456
Test set avg_accuracy=80.12% avg_sensitivity=80.81%, avg_specificity=79.87% avg_auc=87.40%
Best model saved!! Metric=87.40204646752166!!
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.804330 Test loss=0.443265 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.758857250213623
[5/24] Train loss=0.7517286539077759
[10/24] Train loss=0.8486919403076172
[15/24] Train loss=0.7925825119018555
[20/24] Train loss=0.7311674356460571
Test set avg_accuracy=79.65% avg_sensitivity=81.71%, avg_specificity=78.92% avg_auc=87.45%
Best model saved!! Metric=87.45256707796833!!
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.792528 Test loss=0.452760 Current lr=[0.000297555943323901]

[0/24] Train loss=0.7594177722930908
[5/24] Train loss=0.7374103665351868
[10/24] Train loss=0.8559661507606506
[15/24] Train loss=0.790408730506897
[20/24] Train loss=0.7198542356491089
Test set avg_accuracy=79.52% avg_sensitivity=81.76%, avg_specificity=78.73% avg_auc=87.45%
Best model saved!! Metric=87.45445467088608!!
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.788437 Test loss=0.454456 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.7615057826042175
[5/24] Train loss=0.73810213804245
[10/24] Train loss=0.8454245924949646
[15/24] Train loss=0.7850630283355713
[20/24] Train loss=0.7181039452552795
Test set avg_accuracy=80.12% avg_sensitivity=80.81%, avg_specificity=79.87% avg_auc=87.54%
Best model saved!! Metric=87.53597316502868!!
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.777961 Test loss=0.440207 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.7540258765220642
[5/24] Train loss=0.7378613948822021
[10/24] Train loss=0.8561833500862122
[15/24] Train loss=0.782303512096405
[20/24] Train loss=0.7198460102081299
Test set avg_accuracy=80.40% avg_sensitivity=80.46%, avg_specificity=80.38% avg_auc=87.48%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.772307 Test loss=0.437598 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.7539341449737549
[5/24] Train loss=0.7011246085166931
[10/24] Train loss=0.8301467895507812
[15/24] Train loss=0.782911479473114
[20/24] Train loss=0.7335529923439026
Test set avg_accuracy=80.64% avg_sensitivity=78.46%, avg_specificity=81.41% avg_auc=87.45%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.765675 Test loss=0.427036 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.7484767436981201
[5/24] Train loss=0.7249963283538818
[10/24] Train loss=0.8320703506469727
[15/24] Train loss=0.7887478470802307
[20/24] Train loss=0.6911835670471191
Test set avg_accuracy=80.07% avg_sensitivity=81.06%, avg_specificity=79.71% avg_auc=87.51%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.764283 Test loss=0.443074 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.7203319072723389
[5/24] Train loss=0.6917682886123657
[10/24] Train loss=0.8125712275505066
[15/24] Train loss=0.757026195526123
[20/24] Train loss=0.714600682258606
Test set avg_accuracy=79.74% avg_sensitivity=81.61%, avg_specificity=79.08% avg_auc=87.49%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.755549 Test loss=0.449459 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.7189689874649048
[5/24] Train loss=0.653812825679779
[10/24] Train loss=0.7892795205116272
[15/24] Train loss=0.7521235346794128
[20/24] Train loss=0.6898571252822876
Test set avg_accuracy=79.69% avg_sensitivity=82.41%, avg_specificity=78.73% avg_auc=87.61%
Best model saved!! Metric=87.61226887876717!!
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.748679 Test loss=0.452478 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.7245315909385681
[5/24] Train loss=0.6654704809188843
[10/24] Train loss=0.798052966594696
[15/24] Train loss=0.7546094059944153
[20/24] Train loss=0.6842899322509766
Test set avg_accuracy=79.86% avg_sensitivity=81.46%, avg_specificity=79.29% avg_auc=87.63%
Best model saved!! Metric=87.62951681405292!!
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.740988 Test loss=0.448502 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6979421377182007
[5/24] Train loss=0.652114987373352
[10/24] Train loss=0.7751249074935913
[15/24] Train loss=0.7507458329200745
[20/24] Train loss=0.6727349758148193
Test set avg_accuracy=79.88% avg_sensitivity=80.81%, avg_specificity=79.56% avg_auc=87.54%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.727620 Test loss=0.444054 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.7139469385147095
[5/24] Train loss=0.6591371297836304
[10/24] Train loss=0.7730397582054138
[15/24] Train loss=0.7311055660247803
[20/24] Train loss=0.6729496121406555
Test set avg_accuracy=79.71% avg_sensitivity=81.51%, avg_specificity=79.08% avg_auc=87.60%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.726391 Test loss=0.450139 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6996185779571533
[5/24] Train loss=0.6189923882484436
[10/24] Train loss=0.7744400501251221
[15/24] Train loss=0.7451238036155701
[20/24] Train loss=0.6622474789619446
Test set avg_accuracy=80.25% avg_sensitivity=80.06%, avg_specificity=80.31% avg_auc=87.58%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.715509 Test loss=0.441577 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6950255632400513
[5/24] Train loss=0.6175305843353271
[10/24] Train loss=0.7586939334869385
[15/24] Train loss=0.7356922626495361
[20/24] Train loss=0.6495725512504578
Test set avg_accuracy=79.62% avg_sensitivity=81.26%, avg_specificity=79.05% avg_auc=87.60%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.708321 Test loss=0.450384 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6950815916061401
[5/24] Train loss=0.6343271732330322
[10/24] Train loss=0.7616472244262695
[15/24] Train loss=0.7187134027481079
[20/24] Train loss=0.6458119750022888
Test set avg_accuracy=79.74% avg_sensitivity=80.61%, avg_specificity=79.43% avg_auc=87.53%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.701261 Test loss=0.448377 Current lr=[0.000276307469034998]

[0/24] Train loss=0.676354169845581
[5/24] Train loss=0.5899367332458496
[10/24] Train loss=0.7346308827400208
[15/24] Train loss=0.7204188108444214
[20/24] Train loss=0.6437880396842957
Test set avg_accuracy=80.29% avg_sensitivity=79.31%, avg_specificity=80.63% avg_auc=87.55%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.691064 Test loss=0.438855 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6776048541069031
[5/24] Train loss=0.6205958724021912
[10/24] Train loss=0.7257680296897888
[15/24] Train loss=0.7083708047866821
[20/24] Train loss=0.6380571126937866
Test set avg_accuracy=80.40% avg_sensitivity=79.31%, avg_specificity=80.79% avg_auc=87.53%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.686647 Test loss=0.439801 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6818069219589233
[5/24] Train loss=0.6310226917266846
[10/24] Train loss=0.7183802127838135
[15/24] Train loss=0.7093303799629211
[20/24] Train loss=0.6353315711021423
Test set avg_accuracy=80.52% avg_sensitivity=78.46%, avg_specificity=81.25% avg_auc=87.46%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.680959 Test loss=0.435704 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6752038598060608
[5/24] Train loss=0.5890443325042725
[10/24] Train loss=0.7111847996711731
[15/24] Train loss=0.7028630375862122
[20/24] Train loss=0.6055253148078918
Test set avg_accuracy=80.38% avg_sensitivity=79.01%, avg_specificity=80.86% avg_auc=87.45%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.675274 Test loss=0.439480 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6829195022583008
[5/24] Train loss=0.5906704664230347
[10/24] Train loss=0.6927855610847473
[15/24] Train loss=0.7101874351501465
[20/24] Train loss=0.6088777780532837
Test set avg_accuracy=80.74% avg_sensitivity=77.66%, avg_specificity=81.83% avg_auc=87.44%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.669523 Test loss=0.431926 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6515204906463623
[5/24] Train loss=0.5814512372016907
[10/24] Train loss=0.7043019533157349
[15/24] Train loss=0.7313238382339478
[20/24] Train loss=0.6016793251037598
Test set avg_accuracy=81.65% avg_sensitivity=75.31%, avg_specificity=83.89% avg_auc=87.41%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.669234 Test loss=0.418504 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6727100014686584
[5/24] Train loss=0.5808301568031311
[10/24] Train loss=0.7173945307731628
[15/24] Train loss=0.7520171403884888
[20/24] Train loss=0.6521073579788208
Test set avg_accuracy=79.05% avg_sensitivity=80.56%, avg_specificity=78.52% avg_auc=87.35%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.680012 Test loss=0.455754 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.645333468914032
[5/24] Train loss=0.5817854404449463
[10/24] Train loss=0.6966444253921509
[15/24] Train loss=0.6710287928581238
[20/24] Train loss=0.6772855520248413
Test set avg_accuracy=75.66% avg_sensitivity=85.81%, avg_specificity=72.09% avg_auc=87.32%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.669511 Test loss=0.524494 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6751605868339539
[5/24] Train loss=0.5723525881767273
[10/24] Train loss=0.6926153898239136
[15/24] Train loss=0.6732685565948486
[20/24] Train loss=0.6304120421409607
Test set avg_accuracy=76.81% avg_sensitivity=84.76%, avg_specificity=74.01% avg_auc=87.42%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.657310 Test loss=0.506664 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.644404947757721
[5/24] Train loss=0.5453571081161499
[10/24] Train loss=0.6867902874946594
[15/24] Train loss=0.6571927666664124
[20/24] Train loss=0.6164723634719849
Test set avg_accuracy=78.27% avg_sensitivity=82.81%, avg_specificity=76.67% avg_auc=87.35%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.641588 Test loss=0.480980 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.6399006247520447
[5/24] Train loss=0.5562688112258911
[10/24] Train loss=0.67270427942276
[15/24] Train loss=0.6624801158905029
[20/24] Train loss=0.6112865805625916
Test set avg_accuracy=77.32% avg_sensitivity=83.91%, avg_specificity=75.00% avg_auc=87.33%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.634266 Test loss=0.500838 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.643100917339325
[5/24] Train loss=0.5500674247741699
[10/24] Train loss=0.6626724600791931
[15/24] Train loss=0.6426931023597717
[20/24] Train loss=0.610874593257904
Test set avg_accuracy=77.81% avg_sensitivity=83.46%, avg_specificity=75.82% avg_auc=87.27%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.627387 Test loss=0.493038 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.618167519569397
[5/24] Train loss=0.5311095118522644
[10/24] Train loss=0.6691959500312805
[15/24] Train loss=0.6558852195739746
[20/24] Train loss=0.6022478342056274
Test set avg_accuracy=77.58% avg_sensitivity=83.46%, avg_specificity=75.51% avg_auc=87.34%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.621458 Test loss=0.498755 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.6193939447402954
[5/24] Train loss=0.5315309166908264
[10/24] Train loss=0.6659881472587585
[15/24] Train loss=0.6198973655700684
[20/24] Train loss=0.5829759240150452
Test set avg_accuracy=77.75% avg_sensitivity=82.96%, avg_specificity=75.91% avg_auc=87.22%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.614070 Test loss=0.493861 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.6268203854560852
[5/24] Train loss=0.5279212594032288
[10/24] Train loss=0.6549869179725647
[15/24] Train loss=0.627781331539154
[20/24] Train loss=0.5748580098152161
Test set avg_accuracy=77.64% avg_sensitivity=83.16%, avg_specificity=75.70% avg_auc=87.19%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.610005 Test loss=0.500347 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6127477288246155
[5/24] Train loss=0.5129854679107666
[10/24] Train loss=0.6357018947601318
[15/24] Train loss=0.6319959163665771
[20/24] Train loss=0.5719732642173767
Test set avg_accuracy=77.80% avg_sensitivity=83.31%, avg_specificity=75.86% avg_auc=87.20%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.597983 Test loss=0.501660 Current lr=[0.000224838296036774]

[0/24] Train loss=0.5986465811729431
[5/24] Train loss=0.5240660905838013
[10/24] Train loss=0.6441701650619507
[15/24] Train loss=0.620822548866272
[20/24] Train loss=0.5746042728424072
Test set avg_accuracy=78.09% avg_sensitivity=83.41%, avg_specificity=76.21% avg_auc=87.25%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.599867 Test loss=0.496961 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.5968281030654907
[5/24] Train loss=0.5190650820732117
[10/24] Train loss=0.6350507140159607
[15/24] Train loss=0.6040780544281006
[20/24] Train loss=0.5549839735031128
Test set avg_accuracy=77.27% avg_sensitivity=84.26%, avg_specificity=74.80% avg_auc=87.26%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.590100 Test loss=0.517517 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.5949912071228027
[5/24] Train loss=0.5124334096908569
[10/24] Train loss=0.6347249150276184
[15/24] Train loss=0.6300314664840698
[20/24] Train loss=0.5591926574707031
Test set avg_accuracy=77.38% avg_sensitivity=84.11%, avg_specificity=75.01% avg_auc=87.20%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.585925 Test loss=0.521102 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.5931278467178345
[5/24] Train loss=0.5100495219230652
[10/24] Train loss=0.615533709526062
[15/24] Train loss=0.6087315082550049
[20/24] Train loss=0.5550040006637573
Test set avg_accuracy=77.49% avg_sensitivity=83.51%, avg_specificity=75.37% avg_auc=87.16%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.585622 Test loss=0.510717 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.5717576742172241
[5/24] Train loss=0.49354425072669983
[10/24] Train loss=0.618545651435852
[15/24] Train loss=0.6083512902259827
[20/24] Train loss=0.5338395833969116
Test set avg_accuracy=77.93% avg_sensitivity=82.16%, avg_specificity=76.44% avg_auc=87.15%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.578466 Test loss=0.500332 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.5776890516281128
[5/24] Train loss=0.48267215490341187
[10/24] Train loss=0.5987858176231384
[15/24] Train loss=0.6107105016708374
[20/24] Train loss=0.5427798628807068
Test set avg_accuracy=78.54% avg_sensitivity=81.41%, avg_specificity=77.53% avg_auc=87.12%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.576512 Test loss=0.491145 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.5695888996124268
[5/24] Train loss=0.5004291534423828
[10/24] Train loss=0.623951256275177
[15/24] Train loss=0.5987003445625305
[20/24] Train loss=0.5370404720306396
Test set avg_accuracy=78.85% avg_sensitivity=80.61%, avg_specificity=78.24% avg_auc=87.08%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.569290 Test loss=0.481229 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.5680492520332336
[5/24] Train loss=0.48000383377075195
[10/24] Train loss=0.6047959327697754
[15/24] Train loss=0.6255039572715759
[20/24] Train loss=0.5546804070472717
Test set avg_accuracy=78.10% avg_sensitivity=82.16%, avg_specificity=76.67% avg_auc=87.08%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.571227 Test loss=0.500605 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.5695550441741943
[5/24] Train loss=0.47374075651168823
[10/24] Train loss=0.604653537273407
[15/24] Train loss=0.6042675971984863
[20/24] Train loss=0.5803652405738831
Test set avg_accuracy=75.30% avg_sensitivity=85.51%, avg_specificity=71.70% avg_auc=86.84%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.572206 Test loss=0.570578 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6054548025131226
[5/24] Train loss=0.48351526260375977
[10/24] Train loss=0.6509630084037781
[15/24] Train loss=0.6137852668762207
[20/24] Train loss=0.6193845272064209
Test set avg_accuracy=73.01% avg_sensitivity=87.66%, avg_specificity=67.85% avg_auc=86.83%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.578277 Test loss=0.628221 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6285072565078735
[5/24] Train loss=0.5312187075614929
[10/24] Train loss=0.6162437200546265
[15/24] Train loss=0.6264089941978455
[20/24] Train loss=0.6008031368255615
Test set avg_accuracy=75.25% avg_sensitivity=84.96%, avg_specificity=71.83% avg_auc=86.79%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.602451 Test loss=0.563788 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.5921711921691895
[5/24] Train loss=0.522823691368103
[10/24] Train loss=0.6694742441177368
[15/24] Train loss=0.6188751459121704
[20/24] Train loss=0.5243805646896362
Test set avg_accuracy=78.68% avg_sensitivity=79.81%, avg_specificity=78.29% avg_auc=87.04%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.594225 Test loss=0.487488 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.5757052898406982
[5/24] Train loss=0.4779508709907532
[10/24] Train loss=0.6183477640151978
[15/24] Train loss=0.5895549058914185
[20/24] Train loss=0.5381932854652405
Test set avg_accuracy=77.27% avg_sensitivity=83.41%, avg_specificity=75.10% avg_auc=86.88%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.567893 Test loss=0.532012 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.5681124925613403
[5/24] Train loss=0.46784889698028564
[10/24] Train loss=0.6288737058639526
[15/24] Train loss=0.5946637988090515
[20/24] Train loss=0.5144507884979248
Test set avg_accuracy=78.74% avg_sensitivity=78.56%, avg_specificity=78.80% avg_auc=86.86%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.574411 Test loss=0.488770 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.5497298240661621
[5/24] Train loss=0.4641723036766052
[10/24] Train loss=0.6149328947067261
[15/24] Train loss=0.5828925371170044
[20/24] Train loss=0.5281657576560974
Test set avg_accuracy=77.98% avg_sensitivity=82.36%, avg_specificity=76.44% avg_auc=86.86%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.560209 Test loss=0.523415 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.5536987781524658
[5/24] Train loss=0.4846435785293579
[10/24] Train loss=0.5834965109825134
[15/24] Train loss=0.5851031541824341
[20/24] Train loss=0.5204671025276184
Test set avg_accuracy=77.80% avg_sensitivity=82.91%, avg_specificity=76.00% avg_auc=86.84%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.558917 Test loss=0.523414 Current lr=[0.000156543481933168]

[0/24] Train loss=0.5548580884933472
[5/24] Train loss=0.47025153040885925
[10/24] Train loss=0.5826088786125183
[15/24] Train loss=0.575430691242218
[20/24] Train loss=0.5285534262657166
Test set avg_accuracy=78.11% avg_sensitivity=82.06%, avg_specificity=76.72% avg_auc=86.96%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.555824 Test loss=0.515558 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.5474625825881958
[5/24] Train loss=0.4522988796234131
[10/24] Train loss=0.5932790040969849
[15/24] Train loss=0.5604940056800842
[20/24] Train loss=0.5226386189460754
Test set avg_accuracy=77.73% avg_sensitivity=82.61%, avg_specificity=76.02% avg_auc=86.94%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.547318 Test loss=0.523379 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.5409936308860779
[5/24] Train loss=0.4576917290687561
[10/24] Train loss=0.5993269681930542
[15/24] Train loss=0.5699825286865234
[20/24] Train loss=0.5067976117134094
Test set avg_accuracy=77.75% avg_sensitivity=82.36%, avg_specificity=76.12% avg_auc=86.95%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.542355 Test loss=0.523812 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.5314315557479858
[5/24] Train loss=0.4453256130218506
[10/24] Train loss=0.5639510154724121
[15/24] Train loss=0.5727168321609497
[20/24] Train loss=0.49215784668922424
Test set avg_accuracy=77.81% avg_sensitivity=82.21%, avg_specificity=76.26% avg_auc=86.91%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.539153 Test loss=0.525116 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.5274667143821716
[5/24] Train loss=0.4484272301197052
[10/24] Train loss=0.5794236660003662
[15/24] Train loss=0.5540487766265869
[20/24] Train loss=0.5146876573562622
Test set avg_accuracy=78.10% avg_sensitivity=81.86%, avg_specificity=76.77% avg_auc=86.94%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.536601 Test loss=0.522634 Current lr=[0.000134135431043539]

[0/24] Train loss=0.5260927677154541
[5/24] Train loss=0.44114795327186584
[10/24] Train loss=0.5725991129875183
[15/24] Train loss=0.5552021265029907
[20/24] Train loss=0.4898442327976227
Test set avg_accuracy=78.26% avg_sensitivity=82.31%, avg_specificity=76.83% avg_auc=86.93%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.532460 Test loss=0.523389 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.5279391407966614
[5/24] Train loss=0.43484243750572205
[10/24] Train loss=0.5701236128807068
[15/24] Train loss=0.5499387383460999
[20/24] Train loss=0.5082190632820129
Test set avg_accuracy=77.37% avg_sensitivity=83.16%, avg_specificity=75.33% avg_auc=86.81%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.527468 Test loss=0.544750 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.5396476984024048
[5/24] Train loss=0.44055745005607605
[10/24] Train loss=0.5680567622184753
[15/24] Train loss=0.536837100982666
[20/24] Train loss=0.4925345480442047
Test set avg_accuracy=77.59% avg_sensitivity=83.11%, avg_specificity=75.65% avg_auc=86.81%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.526269 Test loss=0.538223 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.5286529660224915
[5/24] Train loss=0.4451426565647125
[10/24] Train loss=0.5500905513763428
[15/24] Train loss=0.5374142527580261
[20/24] Train loss=0.502559244632721
Test set avg_accuracy=77.70% avg_sensitivity=82.81%, avg_specificity=75.89% avg_auc=86.84%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.523163 Test loss=0.541224 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.5200761556625366
[5/24] Train loss=0.44947949051856995
[10/24] Train loss=0.5597909688949585
[15/24] Train loss=0.5356975793838501
[20/24] Train loss=0.47651344537734985
Test set avg_accuracy=77.68% avg_sensitivity=82.71%, avg_specificity=75.91% avg_auc=86.84%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.519608 Test loss=0.537386 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.542441725730896
[5/24] Train loss=0.43013614416122437
[10/24] Train loss=0.5645278096199036
[15/24] Train loss=0.5253280997276306
[20/24] Train loss=0.5059890151023865
Test set avg_accuracy=77.43% avg_sensitivity=83.46%, avg_specificity=75.31% avg_auc=86.81%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.521808 Test loss=0.545589 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.5389721393585205
[5/24] Train loss=0.4392714500427246
[10/24] Train loss=0.5608654022216797
[15/24] Train loss=0.5438863039016724
[20/24] Train loss=0.49573689699172974
Test set avg_accuracy=77.01% avg_sensitivity=83.86%, avg_specificity=74.59% avg_auc=86.85%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.520855 Test loss=0.548172 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.49912577867507935
[5/24] Train loss=0.4222199320793152
[10/24] Train loss=0.547987163066864
[15/24] Train loss=0.5351662039756775
[20/24] Train loss=0.5013713240623474
Test set avg_accuracy=77.07% avg_sensitivity=83.51%, avg_specificity=74.80% avg_auc=86.83%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.517782 Test loss=0.546235 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5196104049682617
[5/24] Train loss=0.43596816062927246
[10/24] Train loss=0.5427254438400269
[15/24] Train loss=0.5511202812194824
[20/24] Train loss=0.49058347940444946
Test set avg_accuracy=77.86% avg_sensitivity=82.31%, avg_specificity=76.30% avg_auc=86.86%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.519824 Test loss=0.522241 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.510773777961731
[5/24] Train loss=0.4226958155632019
[10/24] Train loss=0.5570284128189087
[15/24] Train loss=0.543894350528717
[20/24] Train loss=0.5064900517463684
Test set avg_accuracy=79.13% avg_sensitivity=79.26%, avg_specificity=79.08% avg_auc=86.88%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.524861 Test loss=0.490043 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.5129373073577881
[5/24] Train loss=0.4408618211746216
[10/24] Train loss=0.5714600682258606
[15/24] Train loss=0.5405251383781433
[20/24] Train loss=0.4750934839248657
Test set avg_accuracy=80.21% avg_sensitivity=73.31%, avg_specificity=82.64% avg_auc=86.76%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.525164 Test loss=0.455535 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.5498248338699341
[5/24] Train loss=0.42956244945526123
[10/24] Train loss=0.5400540232658386
[15/24] Train loss=0.5383381843566895
[20/24] Train loss=0.4728046655654907
Test set avg_accuracy=79.69% avg_sensitivity=76.46%, avg_specificity=80.82% avg_auc=86.77%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.520521 Test loss=0.468177 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.5207626223564148
[5/24] Train loss=0.4303228557109833
[10/24] Train loss=0.5342771410942078
[15/24] Train loss=0.5493567585945129
[20/24] Train loss=0.48652440309524536
Test set avg_accuracy=78.65% avg_sensitivity=80.26%, avg_specificity=78.08% avg_auc=86.71%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.510959 Test loss=0.501512 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.5042838454246521
[5/24] Train loss=0.41874200105667114
[10/24] Train loss=0.5337979793548584
[15/24] Train loss=0.5352582931518555
[20/24] Train loss=0.4808049499988556
Test set avg_accuracy=79.13% avg_sensitivity=78.71%, avg_specificity=79.27% avg_auc=86.69%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.504273 Test loss=0.491441 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.5192792415618896
[5/24] Train loss=0.4251405596733093
[10/24] Train loss=0.5191920399665833
[15/24] Train loss=0.5270727276802063
[20/24] Train loss=0.46568045020103455
Test set avg_accuracy=79.13% avg_sensitivity=78.46%, avg_specificity=79.36% avg_auc=86.68%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.501765 Test loss=0.491275 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5072281956672668
[5/24] Train loss=0.41849684715270996
[10/24] Train loss=0.5259291529655457
[15/24] Train loss=0.5114098787307739
[20/24] Train loss=0.4869724214076996
Test set avg_accuracy=78.78% avg_sensitivity=79.51%, avg_specificity=78.52% avg_auc=86.65%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.496639 Test loss=0.502972 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.4955850839614868
[5/24] Train loss=0.4137018322944641
[10/24] Train loss=0.5273087620735168
[15/24] Train loss=0.5056844353675842
[20/24] Train loss=0.46398717164993286
Test set avg_accuracy=78.92% avg_sensitivity=78.66%, avg_specificity=79.01% avg_auc=86.65%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.497707 Test loss=0.496733 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.505294919013977
[5/24] Train loss=0.4187621772289276
[10/24] Train loss=0.5265853404998779
[15/24] Train loss=0.5345605611801147
[20/24] Train loss=0.4595510959625244
Test set avg_accuracy=78.50% avg_sensitivity=79.86%, avg_specificity=78.02% avg_auc=86.66%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.495119 Test loss=0.509136 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.499080628156662
[5/24] Train loss=0.41587966680526733
[10/24] Train loss=0.5311652421951294
[15/24] Train loss=0.5130414962768555
[20/24] Train loss=0.4557431638240814
Test set avg_accuracy=78.65% avg_sensitivity=79.46%, avg_specificity=78.36% avg_auc=86.64%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.495292 Test loss=0.505218 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5004494786262512
[5/24] Train loss=0.4084216058254242
[10/24] Train loss=0.5300623178482056
[15/24] Train loss=0.5101180076599121
[20/24] Train loss=0.46720296144485474
Test set avg_accuracy=78.23% avg_sensitivity=79.51%, avg_specificity=77.78% avg_auc=86.55%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.493952 Test loss=0.508205 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.4959043562412262
[5/24] Train loss=0.4187474548816681
[10/24] Train loss=0.5352058410644531
[15/24] Train loss=0.5161447525024414
[20/24] Train loss=0.4595368206501007
Test set avg_accuracy=78.39% avg_sensitivity=80.11%, avg_specificity=77.78% avg_auc=86.63%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.492769 Test loss=0.512486 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.49086880683898926
[5/24] Train loss=0.4150163233280182
[10/24] Train loss=0.5242125391960144
[15/24] Train loss=0.5158403515815735
[20/24] Train loss=0.4653748571872711
Test set avg_accuracy=78.35% avg_sensitivity=79.91%, avg_specificity=77.80% avg_auc=86.66%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.485951 Test loss=0.511485 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.49019092321395874
[5/24] Train loss=0.413799911737442
[10/24] Train loss=0.5218015909194946
[15/24] Train loss=0.5075224041938782
[20/24] Train loss=0.4571419954299927
Test set avg_accuracy=77.98% avg_sensitivity=80.66%, avg_specificity=77.04% avg_auc=86.62%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.486997 Test loss=0.521011 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.49634474515914917
[5/24] Train loss=0.3983832895755768
[10/24] Train loss=0.5161296129226685
[15/24] Train loss=0.505189836025238
[20/24] Train loss=0.4692807197570801
Test set avg_accuracy=77.94% avg_sensitivity=80.66%, avg_specificity=76.99% avg_auc=86.61%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.487145 Test loss=0.522530 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5009016990661621
[5/24] Train loss=0.40468987822532654
[10/24] Train loss=0.5247074961662292
[15/24] Train loss=0.5051199793815613
[20/24] Train loss=0.45254015922546387
Test set avg_accuracy=78.05% avg_sensitivity=80.56%, avg_specificity=77.16% avg_auc=86.60%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.485393 Test loss=0.522403 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.4840753674507141
[5/24] Train loss=0.4010184705257416
[10/24] Train loss=0.5149713754653931
[15/24] Train loss=0.5146459341049194
[20/24] Train loss=0.4616100490093231
Test set avg_accuracy=77.53% avg_sensitivity=81.61%, avg_specificity=76.09% avg_auc=86.59%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.485980 Test loss=0.533774 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5080780386924744
[5/24] Train loss=0.41102513670921326
[10/24] Train loss=0.5238837003707886
[15/24] Train loss=0.5213155746459961
[20/24] Train loss=0.46208542585372925
Test set avg_accuracy=77.75% avg_sensitivity=81.31%, avg_specificity=76.49% avg_auc=86.55%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.490037 Test loss=0.531199 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5088281631469727
[5/24] Train loss=0.4040248990058899
[10/24] Train loss=0.5079057216644287
[15/24] Train loss=0.5428551435470581
[20/24] Train loss=0.4741594195365906
Test set avg_accuracy=77.23% avg_sensitivity=82.56%, avg_specificity=75.35% avg_auc=86.56%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.486707 Test loss=0.544317 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5046950578689575
[5/24] Train loss=0.41872623562812805
[10/24] Train loss=0.5157107710838318
[15/24] Train loss=0.5104429125785828
[20/24] Train loss=0.4667899012565613
Test set avg_accuracy=76.82% avg_sensitivity=83.16%, avg_specificity=74.59% avg_auc=86.56%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.487161 Test loss=0.553347 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.5045785903930664
[5/24] Train loss=0.40327927470207214
[10/24] Train loss=0.5216683745384216
[15/24] Train loss=0.5140436291694641
[20/24] Train loss=0.45766666531562805
Test set avg_accuracy=76.56% avg_sensitivity=83.11%, avg_specificity=74.26% avg_auc=86.57%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.490332 Test loss=0.558087 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.4963597059249878
[5/24] Train loss=0.4126946032047272
[10/24] Train loss=0.5318537354469299
[15/24] Train loss=0.5217472910881042
[20/24] Train loss=0.46036988496780396
Test set avg_accuracy=76.81% avg_sensitivity=82.96%, avg_specificity=74.64% avg_auc=86.57%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.489160 Test loss=0.553714 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.5019300580024719
[5/24] Train loss=0.40756499767303467
[10/24] Train loss=0.5115842223167419
[15/24] Train loss=0.5424301624298096
[20/24] Train loss=0.4815598428249359
Test set avg_accuracy=77.43% avg_sensitivity=81.81%, avg_specificity=75.89% avg_auc=86.56%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.489212 Test loss=0.535312 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5003823637962341
[5/24] Train loss=0.40869516134262085
[10/24] Train loss=0.5219424962997437
[15/24] Train loss=0.5219602584838867
[20/24] Train loss=0.48554089665412903
Test set avg_accuracy=78.66% avg_sensitivity=79.41%, avg_specificity=78.39% avg_auc=86.59%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.489024 Test loss=0.508445 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.47329649329185486
[5/24] Train loss=0.4083608090877533
[10/24] Train loss=0.5221085548400879
[15/24] Train loss=0.5032321214675903
[20/24] Train loss=0.46401262283325195
Test set avg_accuracy=79.06% avg_sensitivity=78.01%, avg_specificity=79.43% avg_auc=86.58%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.485100 Test loss=0.496719 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.4857633113861084
[5/24] Train loss=0.40667852759361267
[10/24] Train loss=0.5138824582099915
[15/24] Train loss=0.509770929813385
[20/24] Train loss=0.4722338020801544
Test set avg_accuracy=78.83% avg_sensitivity=78.51%, avg_specificity=78.94% avg_auc=86.57%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.483432 Test loss=0.501663 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.49735212326049805
[5/24] Train loss=0.4021909534931183
[10/24] Train loss=0.5051366090774536
[15/24] Train loss=0.5134040117263794
[20/24] Train loss=0.4781070053577423
Test set avg_accuracy=78.62% avg_sensitivity=79.26%, avg_specificity=78.39% avg_auc=86.55%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.485305 Test loss=0.508140 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.4983345866203308
[5/24] Train loss=0.4135272800922394
[10/24] Train loss=0.5120704174041748
[15/24] Train loss=0.5083167552947998
[20/24] Train loss=0.46382009983062744
Test set avg_accuracy=78.78% avg_sensitivity=78.71%, avg_specificity=78.80% avg_auc=86.55%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.483244 Test loss=0.505153 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5028519630432129
[5/24] Train loss=0.41028958559036255
[10/24] Train loss=0.5153924226760864
[15/24] Train loss=0.5236914157867432
[20/24] Train loss=0.46777158975601196
Test set avg_accuracy=78.55% avg_sensitivity=79.26%, avg_specificity=78.31% avg_auc=86.56%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.484729 Test loss=0.509597 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.49557042121887207
[5/24] Train loss=0.39890772104263306
[10/24] Train loss=0.5247357487678528
[15/24] Train loss=0.5106094479560852
[20/24] Train loss=0.4635135531425476
Test set avg_accuracy=78.65% avg_sensitivity=78.91%, avg_specificity=78.55% avg_auc=86.56%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.480250 Test loss=0.506790 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.4892246127128601
[5/24] Train loss=0.4038037955760956
[10/24] Train loss=0.5147358775138855
[15/24] Train loss=0.5013704299926758
[20/24] Train loss=0.47009357810020447
Test set avg_accuracy=78.67% avg_sensitivity=79.11%, avg_specificity=78.52% avg_auc=86.57%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.480539 Test loss=0.507697 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.49546927213668823
[5/24] Train loss=0.40912771224975586
[10/24] Train loss=0.5003746151924133
[15/24] Train loss=0.5118229389190674
[20/24] Train loss=0.4607180655002594
Test set avg_accuracy=78.59% avg_sensitivity=79.11%, avg_specificity=78.41% avg_auc=86.55%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.481876 Test loss=0.508395 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.5089589357376099
[5/24] Train loss=0.3978893458843231
[10/24] Train loss=0.5029622316360474
[15/24] Train loss=0.5005343556404114
[20/24] Train loss=0.46176591515541077
Test set avg_accuracy=78.61% avg_sensitivity=79.16%, avg_specificity=78.41% avg_auc=86.55%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.482204 Test loss=0.508187 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5015335083007812
[5/24] Train loss=0.3971312940120697
[10/24] Train loss=0.5219334363937378
[15/24] Train loss=0.49417945742607117
[20/24] Train loss=0.469494491815567
Test set avg_accuracy=78.61% avg_sensitivity=79.31%, avg_specificity=78.36% avg_auc=86.55%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.480949 Test loss=0.508859 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.48313313722610474
[5/24] Train loss=0.40279388427734375
[10/24] Train loss=0.5160542130470276
[15/24] Train loss=0.5008188486099243
[20/24] Train loss=0.46636489033699036
Test set avg_accuracy=78.62% avg_sensitivity=79.31%, avg_specificity=78.38% avg_auc=86.55%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.477423 Test loss=0.508846 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.4860972762107849
[5/24] Train loss=0.39919957518577576
[10/24] Train loss=0.5111867189407349
[15/24] Train loss=0.5055281519889832
[20/24] Train loss=0.464857816696167
Test set avg_accuracy=78.57% avg_sensitivity=79.31%, avg_specificity=78.31% avg_auc=86.55%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.480910 Test loss=0.509609 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5048971176147461
[5/24] Train loss=0.40861976146698
[10/24] Train loss=0.5154025554656982
[15/24] Train loss=0.5033857226371765
[20/24] Train loss=0.4805769622325897
Test set avg_accuracy=78.57% avg_sensitivity=79.31%, avg_specificity=78.31% avg_auc=86.55%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.481374 Test loss=0.509785 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.4853263199329376
[5/24] Train loss=0.40220341086387634
[10/24] Train loss=0.5063840746879578
[15/24] Train loss=0.518642783164978
[20/24] Train loss=0.4634445309638977
Test set avg_accuracy=78.57% avg_sensitivity=79.36%, avg_specificity=78.29% avg_auc=86.55%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.479376 Test loss=0.510547 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.49791815876960754
[5/24] Train loss=0.3979097008705139
[10/24] Train loss=0.4999774694442749
[15/24] Train loss=0.49363023042678833
[20/24] Train loss=0.4600229263305664
Test set avg_accuracy=78.55% avg_sensitivity=79.41%, avg_specificity=78.25% avg_auc=86.55%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.480486 Test loss=0.510663 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.49812713265419006
[5/24] Train loss=0.4086805284023285
[10/24] Train loss=0.5187565684318542
[15/24] Train loss=0.5122811794281006
[20/24] Train loss=0.44937601685523987
Test set avg_accuracy=78.55% avg_sensitivity=79.41%, avg_specificity=78.25% avg_auc=86.55%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.481076 Test loss=0.510668 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=79.86% sen=81.46%, spe=79.29%, auc=87.63%!
Fold[4] Avg_jsc=0.54%(±0.24067506905112357)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.9403308629989624
[5/24] Train loss=1.8183897733688354
[10/24] Train loss=1.7354004383087158
[15/24] Train loss=1.6429355144500732
[20/24] Train loss=1.5742154121398926
Test set avg_accuracy=50.99% avg_sensitivity=52.33%, avg_specificity=50.53% avg_auc=52.42%
Best model saved!! Metric=52.42059535812387!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=1.720368 Test loss=0.709651 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.5747722387313843
[5/24] Train loss=1.5426008701324463
[10/24] Train loss=1.488961100578308
[15/24] Train loss=1.5183229446411133
[20/24] Train loss=1.4893523454666138
Test set avg_accuracy=51.65% avg_sensitivity=56.73%, avg_specificity=49.92% avg_auc=54.37%
Best model saved!! Metric=54.36758946111926!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=1.531060 Test loss=0.706298 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.5104199647903442
[5/24] Train loss=1.5144973993301392
[10/24] Train loss=1.4920790195465088
[15/24] Train loss=1.4766639471054077
[20/24] Train loss=1.4687327146530151
Test set avg_accuracy=52.19% avg_sensitivity=57.81%, avg_specificity=50.27% avg_auc=56.12%
Best model saved!! Metric=56.11964990798699!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=1.495133 Test loss=0.695208 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.4637866020202637
[5/24] Train loss=1.4663870334625244
[10/24] Train loss=1.4771853685379028
[15/24] Train loss=1.478439450263977
[20/24] Train loss=1.4529967308044434
Test set avg_accuracy=51.61% avg_sensitivity=60.78%, avg_specificity=48.49% avg_auc=57.62%
Best model saved!! Metric=57.62327566683842!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=1.467660 Test loss=0.695347 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.4626210927963257
[5/24] Train loss=1.4683475494384766
[10/24] Train loss=1.4678717851638794
[15/24] Train loss=1.4514397382736206
[20/24] Train loss=1.4484323263168335
Test set avg_accuracy=56.85% avg_sensitivity=56.07%, avg_specificity=57.12% avg_auc=60.07%
Best model saved!! Metric=60.065234780927845!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=1.456821 Test loss=0.678899 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.4350711107254028
[5/24] Train loss=1.4332430362701416
[10/24] Train loss=1.4482450485229492
[15/24] Train loss=1.4252487421035767
[20/24] Train loss=1.4545867443084717
Test set avg_accuracy=56.69% avg_sensitivity=60.98%, avg_specificity=55.23% avg_auc=62.35%
Best model saved!! Metric=62.34990944431793!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=1.437668 Test loss=0.680267 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.4172784090042114
[5/24] Train loss=1.4354166984558105
[10/24] Train loss=1.4172453880310059
[15/24] Train loss=1.4348655939102173
[20/24] Train loss=1.388445496559143
Test set avg_accuracy=59.93% avg_sensitivity=60.32%, avg_specificity=59.80% avg_auc=64.39%
Best model saved!! Metric=64.38880480178915!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=1.421521 Test loss=0.671377 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.3883720636367798
[5/24] Train loss=1.420040488243103
[10/24] Train loss=1.4229291677474976
[15/24] Train loss=1.386765480041504
[20/24] Train loss=1.3826870918273926
Test set avg_accuracy=60.87% avg_sensitivity=64.21%, avg_specificity=59.73% avg_auc=66.58%
Best model saved!! Metric=66.58425594450196!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=1.404796 Test loss=0.668617 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.3663116693496704
[5/24] Train loss=1.3703863620758057
[10/24] Train loss=1.3851948976516724
[15/24] Train loss=1.3843164443969727
[20/24] Train loss=1.3549916744232178
Test set avg_accuracy=63.27% avg_sensitivity=64.62%, avg_specificity=62.81% avg_auc=69.13%
Best model saved!! Metric=69.12834445151653!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=1.380075 Test loss=0.658559 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.3647868633270264
[5/24] Train loss=1.3610420227050781
[10/24] Train loss=1.3515260219573975
[15/24] Train loss=1.337489366531372
[20/24] Train loss=1.3329887390136719
Test set avg_accuracy=66.08% avg_sensitivity=66.51%, avg_specificity=65.93% avg_auc=71.80%
Best model saved!! Metric=71.80265843981013!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=1.360012 Test loss=0.645239 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.3183602094650269
[5/24] Train loss=1.3141391277313232
[10/24] Train loss=1.3448768854141235
[15/24] Train loss=1.3038829565048218
[20/24] Train loss=1.2802720069885254
Test set avg_accuracy=68.76% avg_sensitivity=70.71%, avg_specificity=68.10% avg_auc=74.49%
Best model saved!! Metric=74.4889216475421!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=1.323447 Test loss=0.632026 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.267611026763916
[5/24] Train loss=1.2557828426361084
[10/24] Train loss=1.2842152118682861
[15/24] Train loss=1.2422794103622437
[20/24] Train loss=1.22804856300354
Test set avg_accuracy=70.31% avg_sensitivity=70.40%, avg_specificity=70.28% avg_auc=76.49%
Best model saved!! Metric=76.49224650779257!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=1.281039 Test loss=0.603297 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.2196118831634521
[5/24] Train loss=1.1794767379760742
[10/24] Train loss=1.2579376697540283
[15/24] Train loss=1.185612678527832
[20/24] Train loss=1.1573975086212158
Test set avg_accuracy=71.56% avg_sensitivity=72.91%, avg_specificity=71.10% avg_auc=78.55%
Best model saved!! Metric=78.55468714726221!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=1.237554 Test loss=0.582035 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.1514286994934082
[5/24] Train loss=1.1263039112091064
[10/24] Train loss=1.2192317247390747
[15/24] Train loss=1.1246877908706665
[20/24] Train loss=1.1095470190048218
Test set avg_accuracy=72.14% avg_sensitivity=80.13%, avg_specificity=69.41% avg_auc=80.69%
Best model saved!! Metric=80.68626159840949!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=1.190503 Test loss=0.579125 Current lr=[7.558439349929357e-05]

[0/24] Train loss=1.1260015964508057
[5/24] Train loss=1.0744141340255737
[10/24] Train loss=1.1505887508392334
[15/24] Train loss=1.0957955121994019
[20/24] Train loss=1.0837103128433228
Test set avg_accuracy=71.08% avg_sensitivity=85.77%, avg_specificity=66.07% avg_auc=82.65%
Best model saved!! Metric=82.64609451854928!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=1.150032 Test loss=0.593067 Current lr=[8.412106591444728e-05]

[0/24] Train loss=1.0795522928237915
[5/24] Train loss=1.06143319606781
[10/24] Train loss=1.1240899562835693
[15/24] Train loss=1.04129958152771
[20/24] Train loss=1.0286813974380493
Test set avg_accuracy=72.80% avg_sensitivity=86.58%, avg_specificity=68.10% avg_auc=84.29%
Best model saved!! Metric=84.28669597242909!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=1.112249 Test loss=0.569198 Current lr=[9.300857440308985e-05]

[0/24] Train loss=1.0399376153945923
[5/24] Train loss=1.0304391384124756
[10/24] Train loss=1.0670959949493408
[15/24] Train loss=1.0051391124725342
[20/24] Train loss=0.9733103513717651
Test set avg_accuracy=74.31% avg_sensitivity=87.30%, avg_specificity=69.88% avg_auc=85.57%
Best model saved!! Metric=85.57144493287382!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=1.070980 Test loss=0.554421 Current lr=[0.00010220353965498347]

[0/24] Train loss=1.0139174461364746
[5/24] Train loss=0.985787034034729
[10/24] Train loss=1.0286215543746948
[15/24] Train loss=0.9620752334594727
[20/24] Train loss=0.9258381128311157
Test set avg_accuracy=74.90% avg_sensitivity=87.56%, avg_specificity=70.58% avg_auc=86.65%
Best model saved!! Metric=86.65463072262783!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=1.033946 Test loss=0.542751 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.9731322526931763
[5/24] Train loss=0.9690611958503723
[10/24] Train loss=0.9819968342781067
[15/24] Train loss=0.9514206647872925
[20/24] Train loss=0.9084120988845825
Test set avg_accuracy=74.61% avg_sensitivity=89.66%, avg_specificity=69.48% avg_auc=87.50%
Best model saved!! Metric=87.5043574641405!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=1.006293 Test loss=0.548442 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.9505093097686768
[5/24] Train loss=0.9204611778259277
[10/24] Train loss=0.9673646092414856
[15/24] Train loss=0.9049719572067261
[20/24] Train loss=0.8826760649681091
Test set avg_accuracy=75.30% avg_sensitivity=89.25%, avg_specificity=70.54% avg_auc=88.17%
Best model saved!! Metric=88.17042474758895!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.972427 Test loss=0.530584 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.9283255338668823
[5/24] Train loss=0.8930516242980957
[10/24] Train loss=0.9494961500167847
[15/24] Train loss=0.8697634935379028
[20/24] Train loss=0.8305054306983948
Test set avg_accuracy=76.46% avg_sensitivity=88.68%, avg_specificity=72.29% avg_auc=88.66%
Best model saved!! Metric=88.65814780750823!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.946813 Test loss=0.505466 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.8842207789421082
[5/24] Train loss=0.8639237880706787
[10/24] Train loss=0.9053192138671875
[15/24] Train loss=0.8373283743858337
[20/24] Train loss=0.8191432356834412
Test set avg_accuracy=76.71% avg_sensitivity=88.27%, avg_specificity=72.76% avg_auc=89.08%
Best model saved!! Metric=89.0773539627018!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.923976 Test loss=0.495685 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.8643612265586853
[5/24] Train loss=0.8423537611961365
[10/24] Train loss=0.900800347328186
[15/24] Train loss=0.8199189305305481
[20/24] Train loss=0.804768443107605
Test set avg_accuracy=77.32% avg_sensitivity=88.27%, avg_specificity=73.58% avg_auc=89.35%
Best model saved!! Metric=89.35451505704467!!
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.903017 Test loss=0.483842 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.8335596919059753
[5/24] Train loss=0.8233556151390076
[10/24] Train loss=0.8739363551139832
[15/24] Train loss=0.7923113107681274
[20/24] Train loss=0.7818746566772461
Test set avg_accuracy=77.20% avg_sensitivity=89.04%, avg_specificity=73.16% avg_auc=89.51%
Best model saved!! Metric=89.5107847405115!!
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.883457 Test loss=0.485440 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.8447824716567993
[5/24] Train loss=0.8039495348930359
[10/24] Train loss=0.8727211356163025
[15/24] Train loss=0.7669286727905273
[20/24] Train loss=0.7608644366264343
Test set avg_accuracy=77.93% avg_sensitivity=88.68%, avg_specificity=74.26% avg_auc=89.64%
Best model saved!! Metric=89.64172547622759!!
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.871782 Test loss=0.473594 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.8248714804649353
[5/24] Train loss=0.7919119000434875
[10/24] Train loss=0.852173388004303
[15/24] Train loss=0.7468467950820923
[20/24] Train loss=0.7573236227035522
Test set avg_accuracy=78.06% avg_sensitivity=88.12%, avg_specificity=74.63% avg_auc=89.68%
Best model saved!! Metric=89.681328220337!!
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.852358 Test loss=0.468460 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.8003695607185364
[5/24] Train loss=0.7737346291542053
[10/24] Train loss=0.8520357012748718
[15/24] Train loss=0.7409037947654724
[20/24] Train loss=0.7313939929008484
Test set avg_accuracy=78.93% avg_sensitivity=87.66%, avg_specificity=75.96% avg_auc=89.78%
Best model saved!! Metric=89.77804850158219!!
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.842295 Test loss=0.454018 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.8009359240531921
[5/24] Train loss=0.7587674260139465
[10/24] Train loss=0.824836790561676
[15/24] Train loss=0.7235590219497681
[20/24] Train loss=0.7328163385391235
Test set avg_accuracy=79.00% avg_sensitivity=87.05%, avg_specificity=76.25% avg_auc=89.78%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.828695 Test loss=0.452858 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7859793305397034
[5/24] Train loss=0.7506284713745117
[10/24] Train loss=0.8192464709281921
[15/24] Train loss=0.7169476747512817
[20/24] Train loss=0.7104394435882568
Test set avg_accuracy=79.24% avg_sensitivity=86.74%, avg_specificity=76.69% avg_auc=89.84%
Best model saved!! Metric=89.84042315883003!!
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.818978 Test loss=0.447046 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.7800880670547485
[5/24] Train loss=0.7466098070144653
[10/24] Train loss=0.8185189962387085
[15/24] Train loss=0.7027334570884705
[20/24] Train loss=0.722852885723114
Test set avg_accuracy=79.62% avg_sensitivity=86.23%, avg_specificity=77.37% avg_auc=89.84%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.807622 Test loss=0.438840 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7617775797843933
[5/24] Train loss=0.7327960133552551
[10/24] Train loss=0.8071556687355042
[15/24] Train loss=0.6946558952331543
[20/24] Train loss=0.7131689786911011
Test set avg_accuracy=79.65% avg_sensitivity=86.38%, avg_specificity=77.35% avg_auc=89.87%
Best model saved!! Metric=89.87492971507572!!
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.798938 Test loss=0.437724 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.7545875906944275
[5/24] Train loss=0.7343432903289795
[10/24] Train loss=0.8022373914718628
[15/24] Train loss=0.683878481388092
[20/24] Train loss=0.7005587816238403
Test set avg_accuracy=80.22% avg_sensitivity=85.36%, avg_specificity=78.47% avg_auc=89.93%
Best model saved!! Metric=89.93385774000521!!
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.788222 Test loss=0.425419 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.7638673782348633
[5/24] Train loss=0.7232224345207214
[10/24] Train loss=0.8063446283340454
[15/24] Train loss=0.6701656579971313
[20/24] Train loss=0.6933687925338745
Test set avg_accuracy=80.29% avg_sensitivity=85.20%, avg_specificity=78.61% avg_auc=89.94%
Best model saved!! Metric=89.9443451581879!!
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.780049 Test loss=0.423850 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.7550432682037354
[5/24] Train loss=0.7091234922409058
[10/24] Train loss=0.79203200340271
[15/24] Train loss=0.6713649034500122
[20/24] Train loss=0.6795355677604675
Test set avg_accuracy=80.49% avg_sensitivity=84.59%, avg_specificity=79.10% avg_auc=89.95%
Best model saved!! Metric=89.94790354901204!!
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.771020 Test loss=0.418060 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.7395927906036377
[5/24] Train loss=0.707266628742218
[10/24] Train loss=0.7866751551628113
[15/24] Train loss=0.6551944613456726
[20/24] Train loss=0.6771301627159119
Test set avg_accuracy=80.86% avg_sensitivity=84.28%, avg_specificity=79.69% avg_auc=89.99%
Best model saved!! Metric=89.99161453579406!!
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.763156 Test loss=0.413301 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.7208287715911865
[5/24] Train loss=0.7070128321647644
[10/24] Train loss=0.7839322090148926
[15/24] Train loss=0.6456956267356873
[20/24] Train loss=0.6808056235313416
Test set avg_accuracy=81.24% avg_sensitivity=83.87%, avg_specificity=80.34% avg_auc=90.01%
Best model saved!! Metric=90.00755576905901!!
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.753889 Test loss=0.406082 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.7139791250228882
[5/24] Train loss=0.6940787434577942
[10/24] Train loss=0.7679100632667542
[15/24] Train loss=0.6430702805519104
[20/24] Train loss=0.6796392798423767
Test set avg_accuracy=81.45% avg_sensitivity=83.15%, avg_specificity=80.86% avg_auc=90.00%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.746526 Test loss=0.401978 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.706775426864624
[5/24] Train loss=0.6964207291603088
[10/24] Train loss=0.776839017868042
[15/24] Train loss=0.6394609212875366
[20/24] Train loss=0.6647612452507019
Test set avg_accuracy=81.03% avg_sensitivity=83.92%, avg_specificity=80.04% avg_auc=90.03%
Best model saved!! Metric=90.03421240785846!!
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.740023 Test loss=0.407463 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.7082412838935852
[5/24] Train loss=0.6714664697647095
[10/24] Train loss=0.7639509439468384
[15/24] Train loss=0.6283531785011292
[20/24] Train loss=0.657310962677002
Test set avg_accuracy=81.18% avg_sensitivity=84.02%, avg_specificity=80.22% avg_auc=90.11%
Best model saved!! Metric=90.11441925228911!!
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.733333 Test loss=0.406615 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6904840469360352
[5/24] Train loss=0.6814091205596924
[10/24] Train loss=0.7422526478767395
[15/24] Train loss=0.6174103021621704
[20/24] Train loss=0.6430542469024658
Test set avg_accuracy=80.98% avg_sensitivity=83.77%, avg_specificity=80.02% avg_auc=90.07%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.720915 Test loss=0.406071 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6995678544044495
[5/24] Train loss=0.6689848303794861
[10/24] Train loss=0.747746467590332
[15/24] Train loss=0.604071855545044
[20/24] Train loss=0.647733211517334
Test set avg_accuracy=81.55% avg_sensitivity=82.64%, avg_specificity=81.18% avg_auc=90.08%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.712306 Test loss=0.397219 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6792272925376892
[5/24] Train loss=0.6596753597259521
[10/24] Train loss=0.7294139266014099
[15/24] Train loss=0.6067685484886169
[20/24] Train loss=0.6331412196159363
Test set avg_accuracy=81.91% avg_sensitivity=81.62%, avg_specificity=82.02% avg_auc=90.01%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.702667 Test loss=0.388632 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.6680448055267334
[5/24] Train loss=0.6395894885063171
[10/24] Train loss=0.7123036980628967
[15/24] Train loss=0.6040157675743103
[20/24] Train loss=0.6311330199241638
Test set avg_accuracy=81.82% avg_sensitivity=81.00%, avg_specificity=82.10% avg_auc=89.96%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.695679 Test loss=0.388150 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.66385817527771
[5/24] Train loss=0.6358210444450378
[10/24] Train loss=0.7039342522621155
[15/24] Train loss=0.5914886593818665
[20/24] Train loss=0.6299595236778259
Test set avg_accuracy=81.58% avg_sensitivity=82.03%, avg_specificity=81.42% avg_auc=89.98%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.684870 Test loss=0.393017 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6549966335296631
[5/24] Train loss=0.633796215057373
[10/24] Train loss=0.7013273239135742
[15/24] Train loss=0.5754519104957581
[20/24] Train loss=0.6115582585334778
Test set avg_accuracy=81.72% avg_sensitivity=81.11%, avg_specificity=81.93% avg_auc=89.89%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.673891 Test loss=0.389231 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.6539421677589417
[5/24] Train loss=0.6180652976036072
[10/24] Train loss=0.691564679145813
[15/24] Train loss=0.575930655002594
[20/24] Train loss=0.6021265983581543
Test set avg_accuracy=81.35% avg_sensitivity=82.18%, avg_specificity=81.07% avg_auc=89.91%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.664263 Test loss=0.396126 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.6425793170928955
[5/24] Train loss=0.5999445915222168
[10/24] Train loss=0.6771572828292847
[15/24] Train loss=0.5516905784606934
[20/24] Train loss=0.5958899855613708
Test set avg_accuracy=81.54% avg_sensitivity=80.90%, avg_specificity=81.75% avg_auc=89.87%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.653419 Test loss=0.389634 Current lr=[0.000299720220882401]

[0/24] Train loss=0.6230406165122986
[5/24] Train loss=0.5967593193054199
[10/24] Train loss=0.6697264909744263
[15/24] Train loss=0.5518319606781006
[20/24] Train loss=0.596397876739502
Test set avg_accuracy=81.52% avg_sensitivity=80.13%, avg_specificity=82.00% avg_auc=89.80%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.643217 Test loss=0.389423 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.6096374988555908
[5/24] Train loss=0.5839758515357971
[10/24] Train loss=0.654935359954834
[15/24] Train loss=0.553076982498169
[20/24] Train loss=0.5915195941925049
Test set avg_accuracy=81.97% avg_sensitivity=78.29%, avg_specificity=83.22% avg_auc=89.73%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.631805 Test loss=0.382229 Current lr=[0.000298904600941902]

[0/24] Train loss=0.6052306294441223
[5/24] Train loss=0.570006787776947
[10/24] Train loss=0.6481466889381409
[15/24] Train loss=0.5469158291816711
[20/24] Train loss=0.5708941221237183
Test set avg_accuracy=81.76% avg_sensitivity=78.80%, avg_specificity=82.77% avg_auc=89.67%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.619711 Test loss=0.386767 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.6021651029586792
[5/24] Train loss=0.5734055042266846
[10/24] Train loss=0.6270707249641418
[15/24] Train loss=0.5328516960144043
[20/24] Train loss=0.5603963732719421
Test set avg_accuracy=81.41% avg_sensitivity=79.26%, avg_specificity=82.14% avg_auc=89.60%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.612531 Test loss=0.392354 Current lr=[0.000297555943323901]

[0/24] Train loss=0.5746344327926636
[5/24] Train loss=0.5578587651252747
[10/24] Train loss=0.618800699710846
[15/24] Train loss=0.5272647142410278
[20/24] Train loss=0.5581814050674438
Test set avg_accuracy=81.34% avg_sensitivity=79.83%, avg_specificity=81.86% avg_auc=89.58%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.600850 Test loss=0.396238 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.5767911672592163
[5/24] Train loss=0.5484240055084229
[10/24] Train loss=0.6103866696357727
[15/24] Train loss=0.5192665457725525
[20/24] Train loss=0.5631335973739624
Test set avg_accuracy=81.28% avg_sensitivity=79.72%, avg_specificity=81.81% avg_auc=89.46%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.592582 Test loss=0.399879 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.558079183101654
[5/24] Train loss=0.5405750274658203
[10/24] Train loss=0.6031889915466309
[15/24] Train loss=0.5159915685653687
[20/24] Train loss=0.5395419001579285
Test set avg_accuracy=81.22% avg_sensitivity=79.42%, avg_specificity=81.84% avg_auc=89.44%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.585216 Test loss=0.400910 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.5474130511283875
[5/24] Train loss=0.5281604528427124
[10/24] Train loss=0.6057029962539673
[15/24] Train loss=0.5147256851196289
[20/24] Train loss=0.5382331609725952
Test set avg_accuracy=81.43% avg_sensitivity=78.19%, avg_specificity=82.54% avg_auc=89.31%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.575865 Test loss=0.397953 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.5563051104545593
[5/24] Train loss=0.520850419998169
[10/24] Train loss=0.5799444317817688
[15/24] Train loss=0.5040757656097412
[20/24] Train loss=0.5342235565185547
Test set avg_accuracy=81.21% avg_sensitivity=79.67%, avg_specificity=81.74% avg_auc=89.40%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.569185 Test loss=0.403890 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.5421350002288818
[5/24] Train loss=0.5153578519821167
[10/24] Train loss=0.5665411949157715
[15/24] Train loss=0.49680203199386597
[20/24] Train loss=0.5271344184875488
Test set avg_accuracy=81.07% avg_sensitivity=79.37%, avg_specificity=81.65% avg_auc=89.29%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.558998 Test loss=0.406078 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.529802143573761
[5/24] Train loss=0.5114562511444092
[10/24] Train loss=0.5588030815124512
[15/24] Train loss=0.4965115785598755
[20/24] Train loss=0.5262578725814819
Test set avg_accuracy=81.45% avg_sensitivity=78.19%, avg_specificity=82.56% avg_auc=89.33%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.553489 Test loss=0.399842 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.5225375890731812
[5/24] Train loss=0.503649890422821
[10/24] Train loss=0.5614672899246216
[15/24] Train loss=0.4896494150161743
[20/24] Train loss=0.5082828998565674
Test set avg_accuracy=81.45% avg_sensitivity=77.47%, avg_specificity=82.80% avg_auc=89.30%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.547133 Test loss=0.397313 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.5156393051147461
[5/24] Train loss=0.48533767461776733
[10/24] Train loss=0.5471639037132263
[15/24] Train loss=0.4727934002876282
[20/24] Train loss=0.5186058282852173
Test set avg_accuracy=83.05% avg_sensitivity=71.58%, avg_specificity=86.96% avg_auc=89.07%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.539018 Test loss=0.377991 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.5232362747192383
[5/24] Train loss=0.5082300901412964
[10/24] Train loss=0.5386935472488403
[15/24] Train loss=0.467877596616745
[20/24] Train loss=0.5143887400627136
Test set avg_accuracy=82.85% avg_sensitivity=72.40%, avg_specificity=86.42% avg_auc=88.97%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.535557 Test loss=0.380888 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.5238297581672668
[5/24] Train loss=0.4834456145763397
[10/24] Train loss=0.5139529705047607
[15/24] Train loss=0.44897201657295227
[20/24] Train loss=0.5008544921875
Test set avg_accuracy=82.33% avg_sensitivity=74.40%, avg_specificity=85.04% avg_auc=88.87%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.525937 Test loss=0.390644 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.5032545328140259
[5/24] Train loss=0.4695869982242584
[10/24] Train loss=0.5245307087898254
[15/24] Train loss=0.4629594087600708
[20/24] Train loss=0.4953838586807251
Test set avg_accuracy=81.80% avg_sensitivity=75.58%, avg_specificity=83.92% avg_auc=88.88%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.521069 Test loss=0.399220 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.4923662841320038
[5/24] Train loss=0.47412577271461487
[10/24] Train loss=0.5382416844367981
[15/24] Train loss=0.4487992227077484
[20/24] Train loss=0.47786256670951843
Test set avg_accuracy=82.37% avg_sensitivity=75.52%, avg_specificity=84.70% avg_auc=88.99%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.515073 Test loss=0.394866 Current lr=[0.000276307469034998]

[0/24] Train loss=0.4843030571937561
[5/24] Train loss=0.4721493124961853
[10/24] Train loss=0.5138155221939087
[15/24] Train loss=0.45400312542915344
[20/24] Train loss=0.4905656576156616
Test set avg_accuracy=82.06% avg_sensitivity=74.91%, avg_specificity=84.49% avg_auc=88.93%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.510403 Test loss=0.396843 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.47803670167922974
[5/24] Train loss=0.46772560477256775
[10/24] Train loss=0.5150127410888672
[15/24] Train loss=0.4419223368167877
[20/24] Train loss=0.48921796679496765
Test set avg_accuracy=82.04% avg_sensitivity=76.55%, avg_specificity=83.92% avg_auc=89.03%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.502660 Test loss=0.403105 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.4746524691581726
[5/24] Train loss=0.46170997619628906
[10/24] Train loss=0.5284460186958313
[15/24] Train loss=0.44124528765678406
[20/24] Train loss=0.49353182315826416
Test set avg_accuracy=81.84% avg_sensitivity=76.75%, avg_specificity=83.57% avg_auc=88.91%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.501899 Test loss=0.405096 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.4583493769168854
[5/24] Train loss=0.4858607351779938
[10/24] Train loss=0.491754949092865
[15/24] Train loss=0.44060778617858887
[20/24] Train loss=0.48874717950820923
Test set avg_accuracy=79.91% avg_sensitivity=81.98%, avg_specificity=79.20% avg_auc=88.91%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.499455 Test loss=0.448719 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4715205729007721
[5/24] Train loss=0.50477135181427
[10/24] Train loss=0.5229236483573914
[15/24] Train loss=0.43379658460617065
[20/24] Train loss=0.4744676649570465
Test set avg_accuracy=81.13% avg_sensitivity=77.68%, avg_specificity=82.31% avg_auc=88.61%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.506290 Test loss=0.419470 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.4684358239173889
[5/24] Train loss=0.4669412076473236
[10/24] Train loss=0.5515748262405396
[15/24] Train loss=0.4313261806964874
[20/24] Train loss=0.45407408475875854
Test set avg_accuracy=80.38% avg_sensitivity=80.44%, avg_specificity=80.36% avg_auc=88.79%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.501478 Test loss=0.438224 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.4653845727443695
[5/24] Train loss=0.4682154655456543
[10/24] Train loss=0.5450583696365356
[15/24] Train loss=0.4768619239330292
[20/24] Train loss=0.5229399800300598
Test set avg_accuracy=76.22% avg_sensitivity=86.99%, avg_specificity=72.55% avg_auc=88.79%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.513641 Test loss=0.523708 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.5277870297431946
[5/24] Train loss=0.5022457838058472
[10/24] Train loss=0.4925941228866577
[15/24] Train loss=0.42869314551353455
[20/24] Train loss=0.49036240577697754
Test set avg_accuracy=79.06% avg_sensitivity=83.36%, avg_specificity=77.60% avg_auc=88.81%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.512985 Test loss=0.468094 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.47606515884399414
[5/24] Train loss=0.47755834460258484
[10/24] Train loss=0.4937056303024292
[15/24] Train loss=0.4220869839191437
[20/24] Train loss=0.4594079256057739
Test set avg_accuracy=78.91% avg_sensitivity=83.67%, avg_specificity=77.28% avg_auc=88.89%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.484923 Test loss=0.469016 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.4658260941505432
[5/24] Train loss=0.4590516686439514
[10/24] Train loss=0.471920907497406
[15/24] Train loss=0.4212644696235657
[20/24] Train loss=0.45298293232917786
Test set avg_accuracy=78.84% avg_sensitivity=83.46%, avg_specificity=77.27% avg_auc=88.80%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.474103 Test loss=0.473167 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.4683341681957245
[5/24] Train loss=0.434812068939209
[10/24] Train loss=0.4726691246032715
[15/24] Train loss=0.41022512316703796
[20/24] Train loss=0.46922048926353455
Test set avg_accuracy=79.41% avg_sensitivity=82.59%, avg_specificity=78.33% avg_auc=88.82%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.468569 Test loss=0.461269 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.46270430088043213
[5/24] Train loss=0.4175151288509369
[10/24] Train loss=0.4536547064781189
[15/24] Train loss=0.41595423221588135
[20/24] Train loss=0.45842477679252625
Test set avg_accuracy=78.95% avg_sensitivity=83.05%, avg_specificity=77.54% avg_auc=88.75%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.460517 Test loss=0.472209 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.4551549255847931
[5/24] Train loss=0.4216739237308502
[10/24] Train loss=0.4546341896057129
[15/24] Train loss=0.413141131401062
[20/24] Train loss=0.4423135221004486
Test set avg_accuracy=79.06% avg_sensitivity=82.59%, avg_specificity=77.86% avg_auc=88.79%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.458349 Test loss=0.469498 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.45576027035713196
[5/24] Train loss=0.42570456862449646
[10/24] Train loss=0.4621277153491974
[15/24] Train loss=0.4101926386356354
[20/24] Train loss=0.4322190284729004
Test set avg_accuracy=79.28% avg_sensitivity=82.08%, avg_specificity=78.33% avg_auc=88.79%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.451888 Test loss=0.467230 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.45260089635849
[5/24] Train loss=0.4056335389614105
[10/24] Train loss=0.44800612330436707
[15/24] Train loss=0.40458300709724426
[20/24] Train loss=0.45662713050842285
Test set avg_accuracy=79.19% avg_sensitivity=83.00%, avg_specificity=77.89% avg_auc=88.81%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.449191 Test loss=0.473672 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.4415583908557892
[5/24] Train loss=0.40227189660072327
[10/24] Train loss=0.44886916875839233
[15/24] Train loss=0.4083476662635803
[20/24] Train loss=0.43942397832870483
Test set avg_accuracy=78.76% avg_sensitivity=82.39%, avg_specificity=77.53% avg_auc=88.68%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.445486 Test loss=0.478395 Current lr=[0.000224838296036774]

[0/24] Train loss=0.43263834714889526
[5/24] Train loss=0.40134018659591675
[10/24] Train loss=0.43631985783576965
[15/24] Train loss=0.4042447507381439
[20/24] Train loss=0.44035157561302185
Test set avg_accuracy=78.92% avg_sensitivity=82.39%, avg_specificity=77.74% avg_auc=88.73%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.443447 Test loss=0.478007 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.4408210217952728
[5/24] Train loss=0.3927946984767914
[10/24] Train loss=0.45080822706222534
[15/24] Train loss=0.4001407325267792
[20/24] Train loss=0.43629762530326843
Test set avg_accuracy=78.98% avg_sensitivity=82.64%, avg_specificity=77.74% avg_auc=88.68%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.440713 Test loss=0.480293 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.42517706751823425
[5/24] Train loss=0.4075606167316437
[10/24] Train loss=0.44123753905296326
[15/24] Train loss=0.38479435443878174
[20/24] Train loss=0.439458429813385
Test set avg_accuracy=78.62% avg_sensitivity=82.69%, avg_specificity=77.23% avg_auc=88.63%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.434943 Test loss=0.486496 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.4314708411693573
[5/24] Train loss=0.4121658504009247
[10/24] Train loss=0.4469970762729645
[15/24] Train loss=0.38796088099479675
[20/24] Train loss=0.4155862629413605
Test set avg_accuracy=79.27% avg_sensitivity=82.54%, avg_specificity=78.16% avg_auc=88.65%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.433394 Test loss=0.477934 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.4221084713935852
[5/24] Train loss=0.40241649746894836
[10/24] Train loss=0.44194960594177246
[15/24] Train loss=0.40629833936691284
[20/24] Train loss=0.41394737362861633
Test set avg_accuracy=79.70% avg_sensitivity=81.11%, avg_specificity=79.22% avg_auc=88.60%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.432988 Test loss=0.464813 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.41612333059310913
[5/24] Train loss=0.38760122656822205
[10/24] Train loss=0.44609442353248596
[15/24] Train loss=0.37949836254119873
[20/24] Train loss=0.4099925458431244
Test set avg_accuracy=80.51% avg_sensitivity=78.65%, avg_specificity=81.14% avg_auc=88.39%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.429634 Test loss=0.446206 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.413484662771225
[5/24] Train loss=0.40169307589530945
[10/24] Train loss=0.43933552503585815
[15/24] Train loss=0.38743191957473755
[20/24] Train loss=0.4075694978237152
Test set avg_accuracy=80.81% avg_sensitivity=76.65%, avg_specificity=82.22% avg_auc=88.27%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.427075 Test loss=0.434693 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.4121905267238617
[5/24] Train loss=0.39425528049468994
[10/24] Train loss=0.4329024851322174
[15/24] Train loss=0.39063718914985657
[20/24] Train loss=0.4069881737232208
Test set avg_accuracy=80.46% avg_sensitivity=76.34%, avg_specificity=81.86% avg_auc=88.04%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.423337 Test loss=0.441252 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.40882304310798645
[5/24] Train loss=0.39314666390419006
[10/24] Train loss=0.43259871006011963
[15/24] Train loss=0.37485113739967346
[20/24] Train loss=0.3953067362308502
Test set avg_accuracy=80.39% avg_sensitivity=76.75%, avg_specificity=81.63% avg_auc=88.05%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.418947 Test loss=0.444189 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.4226610064506531
[5/24] Train loss=0.3963165581226349
[10/24] Train loss=0.42635443806648254
[15/24] Train loss=0.3712250590324402
[20/24] Train loss=0.3916257917881012
Test set avg_accuracy=80.33% avg_sensitivity=77.21%, avg_specificity=81.39% avg_auc=87.88%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.419467 Test loss=0.449115 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.41482827067375183
[5/24] Train loss=0.39535847306251526
[10/24] Train loss=0.42778098583221436
[15/24] Train loss=0.3644881248474121
[20/24] Train loss=0.40193966031074524
Test set avg_accuracy=79.90% avg_sensitivity=77.47%, avg_specificity=80.72% avg_auc=87.76%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.417425 Test loss=0.455791 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.40929096937179565
[5/24] Train loss=0.3873056471347809
[10/24] Train loss=0.40988337993621826
[15/24] Train loss=0.3592768609523773
[20/24] Train loss=0.402471661567688
Test set avg_accuracy=79.23% avg_sensitivity=79.83%, avg_specificity=79.03% avg_auc=88.11%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.414989 Test loss=0.470733 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.38755500316619873
[5/24] Train loss=0.3784159719944
[10/24] Train loss=0.40624454617500305
[15/24] Train loss=0.3621108829975128
[20/24] Train loss=0.42317837476730347
Test set avg_accuracy=79.00% avg_sensitivity=80.80%, avg_specificity=78.38% avg_auc=88.17%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.412781 Test loss=0.478891 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.40447500348091125
[5/24] Train loss=0.38225114345550537
[10/24] Train loss=0.41798117756843567
[15/24] Train loss=0.3572765588760376
[20/24] Train loss=0.3911750316619873
Test set avg_accuracy=79.57% avg_sensitivity=80.75%, avg_specificity=79.17% avg_auc=88.21%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.408363 Test loss=0.472087 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.38909637928009033
[5/24] Train loss=0.3858567774295807
[10/24] Train loss=0.4139755964279175
[15/24] Train loss=0.35845598578453064
[20/24] Train loss=0.39559030532836914
Test set avg_accuracy=80.23% avg_sensitivity=79.47%, avg_specificity=80.50% avg_auc=88.27%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.406939 Test loss=0.458619 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3952800929546356
[5/24] Train loss=0.38331714272499084
[10/24] Train loss=0.41924941539764404
[15/24] Train loss=0.36125877499580383
[20/24] Train loss=0.38110920786857605
Test set avg_accuracy=80.34% avg_sensitivity=79.62%, avg_specificity=80.58% avg_auc=88.28%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.403791 Test loss=0.458326 Current lr=[0.000156543481933168]

[0/24] Train loss=0.38493412733078003
[5/24] Train loss=0.37154078483581543
[10/24] Train loss=0.4060388207435608
[15/24] Train loss=0.3367123603820801
[20/24] Train loss=0.3803926110267639
Test set avg_accuracy=80.65% avg_sensitivity=79.37%, avg_specificity=81.09% avg_auc=88.31%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.401946 Test loss=0.456669 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.38577449321746826
[5/24] Train loss=0.37363457679748535
[10/24] Train loss=0.39704132080078125
[15/24] Train loss=0.34588706493377686
[20/24] Train loss=0.3906557261943817
Test set avg_accuracy=80.00% avg_sensitivity=80.75%, avg_specificity=79.75% avg_auc=88.34%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.401742 Test loss=0.472492 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3849825859069824
[5/24] Train loss=0.368451863527298
[10/24] Train loss=0.40698015689849854
[15/24] Train loss=0.34546393156051636
[20/24] Train loss=0.3827398419380188
Test set avg_accuracy=80.27% avg_sensitivity=80.44%, avg_specificity=80.22% avg_auc=88.39%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.400527 Test loss=0.469724 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3798474073410034
[5/24] Train loss=0.37744268774986267
[10/24] Train loss=0.4036922752857208
[15/24] Train loss=0.3485702872276306
[20/24] Train loss=0.38268452882766724
Test set avg_accuracy=80.25% avg_sensitivity=80.13%, avg_specificity=80.29% avg_auc=88.37%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.400074 Test loss=0.475665 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.38462841510772705
[5/24] Train loss=0.36367884278297424
[10/24] Train loss=0.3964655101299286
[15/24] Train loss=0.3670642077922821
[20/24] Train loss=0.3834652006626129
Test set avg_accuracy=80.18% avg_sensitivity=80.70%, avg_specificity=80.01% avg_auc=88.38%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.399542 Test loss=0.480773 Current lr=[0.000134135431043539]

[0/24] Train loss=0.37716540694236755
[5/24] Train loss=0.36825940012931824
[10/24] Train loss=0.41127151250839233
[15/24] Train loss=0.35766610503196716
[20/24] Train loss=0.38615819811820984
Test set avg_accuracy=80.16% avg_sensitivity=80.54%, avg_specificity=80.02% avg_auc=88.38%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.399082 Test loss=0.489197 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3778044581413269
[5/24] Train loss=0.3690333366394043
[10/24] Train loss=0.3983169198036194
[15/24] Train loss=0.3576897978782654
[20/24] Train loss=0.3812856376171112
Test set avg_accuracy=80.05% avg_sensitivity=80.49%, avg_specificity=79.90% avg_auc=88.37%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.400033 Test loss=0.492193 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3791620433330536
[5/24] Train loss=0.3588225543498993
[10/24] Train loss=0.4117072522640228
[15/24] Train loss=0.3622181713581085
[20/24] Train loss=0.3661407232284546
Test set avg_accuracy=79.92% avg_sensitivity=80.75%, avg_specificity=79.64% avg_auc=88.32%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.397970 Test loss=0.494827 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3815258741378784
[5/24] Train loss=0.3628470301628113
[10/24] Train loss=0.4077039957046509
[15/24] Train loss=0.3681577146053314
[20/24] Train loss=0.37095606327056885
Test set avg_accuracy=79.70% avg_sensitivity=82.18%, avg_specificity=78.85% avg_auc=88.41%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.396357 Test loss=0.501514 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.37870198488235474
[5/24] Train loss=0.3741960823535919
[10/24] Train loss=0.4100467264652252
[15/24] Train loss=0.3630083203315735
[20/24] Train loss=0.36998251080513
Test set avg_accuracy=78.89% avg_sensitivity=82.85%, avg_specificity=77.54% avg_auc=88.36%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.394606 Test loss=0.514391 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.39097437262535095
[5/24] Train loss=0.3730415999889374
[10/24] Train loss=0.40308547019958496
[15/24] Train loss=0.35787099599838257
[20/24] Train loss=0.38657346367836
Test set avg_accuracy=77.77% avg_sensitivity=84.28%, avg_specificity=75.55% avg_auc=88.28%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.397059 Test loss=0.539915 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.4085713326931
[5/24] Train loss=0.3792867362499237
[10/24] Train loss=0.4103621244430542
[15/24] Train loss=0.35781070590019226
[20/24] Train loss=0.42704489827156067
Test set avg_accuracy=78.07% avg_sensitivity=83.56%, avg_specificity=76.20% avg_auc=88.24%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.404859 Test loss=0.525907 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.39486411213874817
[5/24] Train loss=0.33993181586265564
[10/24] Train loss=0.41604363918304443
[15/24] Train loss=0.36635857820510864
[20/24] Train loss=0.39618709683418274
Test set avg_accuracy=80.83% avg_sensitivity=79.11%, avg_specificity=81.42% avg_auc=88.17%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.404012 Test loss=0.460604 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3749000132083893
[5/24] Train loss=0.3665767312049866
[10/24] Train loss=0.40835243463516235
[15/24] Train loss=0.3552809953689575
[20/24] Train loss=0.38960617780685425
Test set avg_accuracy=80.78% avg_sensitivity=78.44%, avg_specificity=81.58% avg_auc=88.14%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.389762 Test loss=0.458022 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.37654274702072144
[5/24] Train loss=0.3511914610862732
[10/24] Train loss=0.38682660460472107
[15/24] Train loss=0.3434824049472809
[20/24] Train loss=0.3694816529750824
Test set avg_accuracy=80.48% avg_sensitivity=79.42%, avg_specificity=80.85% avg_auc=88.16%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.379843 Test loss=0.467314 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3620315492153168
[5/24] Train loss=0.3435399830341339
[10/24] Train loss=0.3941313326358795
[15/24] Train loss=0.34294593334198
[20/24] Train loss=0.3729209005832672
Test set avg_accuracy=80.38% avg_sensitivity=79.42%, avg_specificity=80.71% avg_auc=88.22%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.378736 Test loss=0.469775 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3652941584587097
[5/24] Train loss=0.34453776478767395
[10/24] Train loss=0.38273152709007263
[15/24] Train loss=0.3430543541908264
[20/24] Train loss=0.3824590742588043
Test set avg_accuracy=80.65% avg_sensitivity=78.85%, avg_specificity=81.26% avg_auc=88.22%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.378167 Test loss=0.465082 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3702910244464874
[5/24] Train loss=0.33991295099258423
[10/24] Train loss=0.3795119822025299
[15/24] Train loss=0.33372625708580017
[20/24] Train loss=0.3678632080554962
Test set avg_accuracy=80.49% avg_sensitivity=79.47%, avg_specificity=80.85% avg_auc=88.21%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.375222 Test loss=0.470804 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3634748160839081
[5/24] Train loss=0.3478873670101166
[10/24] Train loss=0.38982653617858887
[15/24] Train loss=0.34049785137176514
[20/24] Train loss=0.3674083352088928
Test set avg_accuracy=80.53% avg_sensitivity=79.72%, avg_specificity=80.81% avg_auc=88.25%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.375321 Test loss=0.472576 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3568700850009918
[5/24] Train loss=0.3408564627170563
[10/24] Train loss=0.3751892149448395
[15/24] Train loss=0.34158772230148315
[20/24] Train loss=0.3675762414932251
Test set avg_accuracy=80.56% avg_sensitivity=79.52%, avg_specificity=80.91% avg_auc=88.23%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.370814 Test loss=0.472707 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.36971160769462585
[5/24] Train loss=0.34293732047080994
[10/24] Train loss=0.384631484746933
[15/24] Train loss=0.33530914783477783
[20/24] Train loss=0.3591229021549225
Test set avg_accuracy=80.61% avg_sensitivity=79.42%, avg_specificity=81.02% avg_auc=88.23%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.372739 Test loss=0.471665 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3637828528881073
[5/24] Train loss=0.34532248973846436
[10/24] Train loss=0.3752961754798889
[15/24] Train loss=0.3359534740447998
[20/24] Train loss=0.3663923442363739
Test set avg_accuracy=80.53% avg_sensitivity=79.57%, avg_specificity=80.86% avg_auc=88.28%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.370142 Test loss=0.473963 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3734983503818512
[5/24] Train loss=0.33197036385536194
[10/24] Train loss=0.38575708866119385
[15/24] Train loss=0.3397555947303772
[20/24] Train loss=0.36167973279953003
Test set avg_accuracy=80.39% avg_sensitivity=79.67%, avg_specificity=80.64% avg_auc=88.23%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.371919 Test loss=0.475576 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3725648522377014
[5/24] Train loss=0.3350764513015747
[10/24] Train loss=0.3754135072231293
[15/24] Train loss=0.3396824598312378
[20/24] Train loss=0.3613481819629669
Test set avg_accuracy=80.48% avg_sensitivity=79.16%, avg_specificity=80.93% avg_auc=88.19%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.370789 Test loss=0.472189 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3617779016494751
[5/24] Train loss=0.3458559513092041
[10/24] Train loss=0.37394416332244873
[15/24] Train loss=0.3294283151626587
[20/24] Train loss=0.3592841625213623
Test set avg_accuracy=80.22% avg_sensitivity=79.42%, avg_specificity=80.50% avg_auc=88.17%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.369446 Test loss=0.477380 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3625592887401581
[5/24] Train loss=0.3323945999145508
[10/24] Train loss=0.3771597146987915
[15/24] Train loss=0.3370000123977661
[20/24] Train loss=0.3541368842124939
Test set avg_accuracy=80.46% avg_sensitivity=79.37%, avg_specificity=80.83% avg_auc=88.17%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.367763 Test loss=0.476228 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3569948673248291
[5/24] Train loss=0.3442055583000183
[10/24] Train loss=0.3762792646884918
[15/24] Train loss=0.33807888627052307
[20/24] Train loss=0.3539431393146515
Test set avg_accuracy=80.40% avg_sensitivity=79.72%, avg_specificity=80.64% avg_auc=88.22%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.367117 Test loss=0.478123 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3568841218948364
[5/24] Train loss=0.3487913906574249
[10/24] Train loss=0.3632526397705078
[15/24] Train loss=0.3380640149116516
[20/24] Train loss=0.3791949450969696
Test set avg_accuracy=80.40% avg_sensitivity=79.72%, avg_specificity=80.64% avg_auc=88.24%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.368934 Test loss=0.475930 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.36204037070274353
[5/24] Train loss=0.33917126059532166
[10/24] Train loss=0.36329275369644165
[15/24] Train loss=0.33871620893478394
[20/24] Train loss=0.3718481659889221
Test set avg_accuracy=79.95% avg_sensitivity=80.18%, avg_specificity=79.87% avg_auc=88.18%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.368522 Test loss=0.483493 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3579961657524109
[5/24] Train loss=0.3393120765686035
[10/24] Train loss=0.3717517554759979
[15/24] Train loss=0.3312394618988037
[20/24] Train loss=0.35917308926582336
Test set avg_accuracy=80.22% avg_sensitivity=79.67%, avg_specificity=80.41% avg_auc=88.15%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.367037 Test loss=0.478253 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3575316369533539
[5/24] Train loss=0.34668514132499695
[10/24] Train loss=0.3669041097164154
[15/24] Train loss=0.3292244076728821
[20/24] Train loss=0.3612315058708191
Test set avg_accuracy=80.39% avg_sensitivity=79.26%, avg_specificity=80.78% avg_auc=88.14%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.366091 Test loss=0.474804 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.35099339485168457
[5/24] Train loss=0.3508402705192566
[10/24] Train loss=0.371891051530838
[15/24] Train loss=0.33150896430015564
[20/24] Train loss=0.35858312249183655
Test set avg_accuracy=80.36% avg_sensitivity=79.11%, avg_specificity=80.79% avg_auc=88.12%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.364872 Test loss=0.475093 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.35401320457458496
[5/24] Train loss=0.3396286070346832
[10/24] Train loss=0.3625500500202179
[15/24] Train loss=0.33016180992126465
[20/24] Train loss=0.36888089776039124
Test set avg_accuracy=80.53% avg_sensitivity=78.70%, avg_specificity=81.16% avg_auc=88.11%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.365404 Test loss=0.470706 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.35769546031951904
[5/24] Train loss=0.3422379493713379
[10/24] Train loss=0.37672680616378784
[15/24] Train loss=0.3273843228816986
[20/24] Train loss=0.36827877163887024
Test set avg_accuracy=80.99% avg_sensitivity=77.93%, avg_specificity=82.03% avg_auc=88.10%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.366709 Test loss=0.463158 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3456297218799591
[5/24] Train loss=0.33341288566589355
[10/24] Train loss=0.37375810742378235
[15/24] Train loss=0.32632312178611755
[20/24] Train loss=0.3644905388355255
Test set avg_accuracy=81.13% avg_sensitivity=76.34%, avg_specificity=82.77% avg_auc=88.06%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.366017 Test loss=0.454923 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3659856915473938
[5/24] Train loss=0.33303937315940857
[10/24] Train loss=0.38150814175605774
[15/24] Train loss=0.3228716552257538
[20/24] Train loss=0.3746447265148163
Test set avg_accuracy=81.34% avg_sensitivity=76.09%, avg_specificity=83.13% avg_auc=88.04%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.366611 Test loss=0.450596 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3630475103855133
[5/24] Train loss=0.33706751465797424
[10/24] Train loss=0.3811502158641815
[15/24] Train loss=0.3293238580226898
[20/24] Train loss=0.36182883381843567
Test set avg_accuracy=81.25% avg_sensitivity=76.14%, avg_specificity=82.99% avg_auc=88.05%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.366782 Test loss=0.451964 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3436456322669983
[5/24] Train loss=0.3456414043903351
[10/24] Train loss=0.3768059015274048
[15/24] Train loss=0.32860052585601807
[20/24] Train loss=0.3504118323326111
Test set avg_accuracy=81.00% avg_sensitivity=77.01%, avg_specificity=82.36% avg_auc=88.05%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.364748 Test loss=0.459162 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.349614679813385
[5/24] Train loss=0.34290266036987305
[10/24] Train loss=0.37779268622398376
[15/24] Train loss=0.3342958092689514
[20/24] Train loss=0.34684303402900696
Test set avg_accuracy=80.96% avg_sensitivity=77.21%, avg_specificity=82.24% avg_auc=88.05%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.364367 Test loss=0.459826 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3534117639064789
[5/24] Train loss=0.3347741961479187
[10/24] Train loss=0.36360397934913635
[15/24] Train loss=0.32929450273513794
[20/24] Train loss=0.36807382106781006
Test set avg_accuracy=80.98% avg_sensitivity=77.42%, avg_specificity=82.19% avg_auc=88.06%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.360746 Test loss=0.461675 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3504070043563843
[5/24] Train loss=0.3324801027774811
[10/24] Train loss=0.36977824568748474
[15/24] Train loss=0.32814279198646545
[20/24] Train loss=0.35671892762184143
Test set avg_accuracy=80.96% avg_sensitivity=77.27%, avg_specificity=82.22% avg_auc=88.05%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.362432 Test loss=0.461129 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.35549482703208923
[5/24] Train loss=0.3282823860645294
[10/24] Train loss=0.3658319115638733
[15/24] Train loss=0.3189188241958618
[20/24] Train loss=0.3544265329837799
Test set avg_accuracy=80.86% avg_sensitivity=77.93%, avg_specificity=81.86% avg_auc=88.06%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.361307 Test loss=0.465066 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.35528290271759033
[5/24] Train loss=0.33829954266548157
[10/24] Train loss=0.363748162984848
[15/24] Train loss=0.3315374553203583
[20/24] Train loss=0.35723617672920227
Test set avg_accuracy=80.94% avg_sensitivity=77.52%, avg_specificity=82.10% avg_auc=88.04%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.359729 Test loss=0.462701 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.35840368270874023
[5/24] Train loss=0.33852091431617737
[10/24] Train loss=0.37049585580825806
[15/24] Train loss=0.33485719561576843
[20/24] Train loss=0.3428354859352112
Test set avg_accuracy=80.90% avg_sensitivity=77.78%, avg_specificity=81.96% avg_auc=88.05%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.363131 Test loss=0.464324 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.34393787384033203
[5/24] Train loss=0.3431505262851715
[10/24] Train loss=0.3736581802368164
[15/24] Train loss=0.32608136534690857
[20/24] Train loss=0.3701461851596832
Test set avg_accuracy=80.90% avg_sensitivity=77.78%, avg_specificity=81.96% avg_auc=88.05%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.361697 Test loss=0.463745 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3453143239021301
[5/24] Train loss=0.3214069604873657
[10/24] Train loss=0.370982825756073
[15/24] Train loss=0.3286263942718506
[20/24] Train loss=0.3591170310974121
Test set avg_accuracy=80.89% avg_sensitivity=77.73%, avg_specificity=81.96% avg_auc=88.04%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.361327 Test loss=0.463762 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3443079888820648
[5/24] Train loss=0.3370589017868042
[10/24] Train loss=0.36679938435554504
[15/24] Train loss=0.33046260476112366
[20/24] Train loss=0.35471752285957336
Test set avg_accuracy=80.86% avg_sensitivity=77.83%, avg_specificity=81.89% avg_auc=88.05%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.360780 Test loss=0.464875 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3570404350757599
[5/24] Train loss=0.33594757318496704
[10/24] Train loss=0.36832520365715027
[15/24] Train loss=0.3207501173019409
[20/24] Train loss=0.3458229899406433
Test set avg_accuracy=80.86% avg_sensitivity=77.83%, avg_specificity=81.89% avg_auc=88.06%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.359418 Test loss=0.464468 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.354158490896225
[5/24] Train loss=0.3272591531276703
[10/24] Train loss=0.3595188856124878
[15/24] Train loss=0.3212963342666626
[20/24] Train loss=0.3404863476753235
Test set avg_accuracy=80.90% avg_sensitivity=77.83%, avg_specificity=81.95% avg_auc=88.05%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.359025 Test loss=0.464394 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3550822138786316
[5/24] Train loss=0.34297671914100647
[10/24] Train loss=0.362935870885849
[15/24] Train loss=0.3244631588459015
[20/24] Train loss=0.34700605273246765
Test set avg_accuracy=80.83% avg_sensitivity=77.78%, avg_specificity=81.88% avg_auc=88.04%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.360394 Test loss=0.464835 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3535257577896118
[5/24] Train loss=0.33057671785354614
[10/24] Train loss=0.3658357858657837
[15/24] Train loss=0.32349881529808044
[20/24] Train loss=0.3585270047187805
Test set avg_accuracy=80.79% avg_sensitivity=77.78%, avg_specificity=81.82% avg_auc=88.04%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.359157 Test loss=0.465084 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3488033711910248
[5/24] Train loss=0.3290072977542877
[10/24] Train loss=0.3650158941745758
[15/24] Train loss=0.31731945276260376
[20/24] Train loss=0.35095280408859253
Test set avg_accuracy=80.77% avg_sensitivity=77.78%, avg_specificity=81.79% avg_auc=88.04%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.356791 Test loss=0.465290 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3467312157154083
[5/24] Train loss=0.33671119809150696
[10/24] Train loss=0.3672010600566864
[15/24] Train loss=0.3300434648990631
[20/24] Train loss=0.3503965437412262
Test set avg_accuracy=80.77% avg_sensitivity=77.78%, avg_specificity=81.79% avg_auc=88.04%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.359102 Test loss=0.465403 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3440983295440674
[5/24] Train loss=0.3332239091396332
[10/24] Train loss=0.36270901560783386
[15/24] Train loss=0.32240012288093567
[20/24] Train loss=0.3461385667324066
Test set avg_accuracy=80.77% avg_sensitivity=77.78%, avg_specificity=81.79% avg_auc=88.04%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.359078 Test loss=0.465407 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=81.18% sen=84.02%, spe=80.22%, auc=90.11%!
Fold[5] Avg_jsc=0.60%(±0.24548881025916028)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=1.7539417743682861
[5/24] Train loss=1.6810452938079834
[10/24] Train loss=1.6101171970367432
[15/24] Train loss=1.5722079277038574
[20/24] Train loss=1.5413743257522583
Test set avg_accuracy=52.04% avg_sensitivity=48.27%, avg_specificity=53.45% avg_auc=52.22%
Best model saved!! Metric=52.21560265832874!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=1.616718 Test loss=0.719629 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.518967866897583
[5/24] Train loss=1.5312187671661377
[10/24] Train loss=1.4930603504180908
[15/24] Train loss=1.4846001863479614
[20/24] Train loss=1.482071876525879
Test set avg_accuracy=52.24% avg_sensitivity=60.75%, avg_specificity=49.07% avg_auc=56.96%
Best model saved!! Metric=56.95653016481474!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=1.495292 Test loss=0.694622 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.4569936990737915
[5/24] Train loss=1.4692152738571167
[10/24] Train loss=1.457478404045105
[15/24] Train loss=1.4410197734832764
[20/24] Train loss=1.4431244134902954
Test set avg_accuracy=52.40% avg_sensitivity=67.61%, avg_specificity=46.73% avg_auc=60.62%
Best model saved!! Metric=60.62347111111721!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=1.448082 Test loss=0.681075 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.4267299175262451
[5/24] Train loss=1.4166512489318848
[10/24] Train loss=1.4166858196258545
[15/24] Train loss=1.409438133239746
[20/24] Train loss=1.4066343307495117
Test set avg_accuracy=57.20% avg_sensitivity=64.88%, avg_specificity=54.34% avg_auc=63.70%
Best model saved!! Metric=63.70004915081926!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=1.415850 Test loss=0.660648 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.4056676626205444
[5/24] Train loss=1.4002339839935303
[10/24] Train loss=1.3818621635437012
[15/24] Train loss=1.382408618927002
[20/24] Train loss=1.375465989112854
Test set avg_accuracy=58.95% avg_sensitivity=70.30%, avg_specificity=54.72% avg_auc=66.86%
Best model saved!! Metric=66.86159928465493!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=1.394241 Test loss=0.653575 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.3714019060134888
[5/24] Train loss=1.3780609369277954
[10/24] Train loss=1.3432338237762451
[15/24] Train loss=1.3401719331741333
[20/24] Train loss=1.3630812168121338
Test set avg_accuracy=61.39% avg_sensitivity=72.17%, avg_specificity=57.38% avg_auc=69.79%
Best model saved!! Metric=69.7949436737785!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=1.362001 Test loss=0.642700 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.356493592262268
[5/24] Train loss=1.3526548147201538
[10/24] Train loss=1.3281913995742798
[15/24] Train loss=1.2944822311401367
[20/24] Train loss=1.3200584650039673
Test set avg_accuracy=64.13% avg_sensitivity=74.76%, avg_specificity=60.17% avg_auc=72.60%
Best model saved!! Metric=72.60023182860255!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=1.338645 Test loss=0.632530 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.3336293697357178
[5/24] Train loss=1.3189510107040405
[10/24] Train loss=1.3135554790496826
[15/24] Train loss=1.2758667469024658
[20/24] Train loss=1.2813800573349
Test set avg_accuracy=66.63% avg_sensitivity=76.10%, avg_specificity=63.10% avg_auc=75.00%
Best model saved!! Metric=75.0012776469071!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=1.310696 Test loss=0.621168 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.2647981643676758
[5/24] Train loss=1.2868112325668335
[10/24] Train loss=1.2552984952926636
[15/24] Train loss=1.214472770690918
[20/24] Train loss=1.2296202182769775
Test set avg_accuracy=69.67% avg_sensitivity=75.38%, avg_specificity=67.55% avg_auc=77.19%
Best model saved!! Metric=77.1942513778007!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=1.269186 Test loss=0.598172 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.2436587810516357
[5/24] Train loss=1.2446752786636353
[10/24] Train loss=1.230201005935669
[15/24] Train loss=1.1587649583816528
[20/24] Train loss=1.1413501501083374
Test set avg_accuracy=73.18% avg_sensitivity=72.79%, avg_specificity=73.32% avg_auc=78.94%
Best model saved!! Metric=78.93861669769605!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=1.219161 Test loss=0.558213 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.1560243368148804
[5/24] Train loss=1.1842453479766846
[10/24] Train loss=1.1902830600738525
[15/24] Train loss=1.086862564086914
[20/24] Train loss=1.087637186050415
Test set avg_accuracy=72.45% avg_sensitivity=77.64%, avg_specificity=70.51% avg_auc=80.62%
Best model saved!! Metric=80.61767625353454!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=1.168704 Test loss=0.555415 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.101155400276184
[5/24] Train loss=1.1722359657287598
[10/24] Train loss=1.1233967542648315
[15/24] Train loss=0.9991797804832458
[20/24] Train loss=1.0338996648788452
Test set avg_accuracy=72.51% avg_sensitivity=80.85%, avg_specificity=69.41% avg_auc=82.16%
Best model saved!! Metric=82.15576590901918!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=1.118962 Test loss=0.544758 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.058274507522583
[5/24] Train loss=1.1026619672775269
[10/24] Train loss=1.0904278755187988
[15/24] Train loss=0.9770010113716125
[20/24] Train loss=1.022830843925476
Test set avg_accuracy=72.24% avg_sensitivity=84.31%, avg_specificity=67.74% avg_auc=83.41%
Best model saved!! Metric=83.41371218679643!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=1.077676 Test loss=0.548450 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.0399116277694702
[5/24] Train loss=1.073138952255249
[10/24] Train loss=1.0711418390274048
[15/24] Train loss=0.9443132281303406
[20/24] Train loss=0.9872220754623413
Test set avg_accuracy=72.99% avg_sensitivity=85.51%, avg_specificity=68.33% avg_auc=84.36%
Best model saved!! Metric=84.36290522843983!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=1.048339 Test loss=0.539931 Current lr=[7.558439349929357e-05]

[0/24] Train loss=1.0003082752227783
[5/24] Train loss=1.07103431224823
[10/24] Train loss=1.0275640487670898
[15/24] Train loss=0.9261332750320435
[20/24] Train loss=0.9406880140304565
Test set avg_accuracy=74.18% avg_sensitivity=84.98%, avg_specificity=70.16% avg_auc=85.00%
Best model saved!! Metric=85.00464411788514!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=1.023833 Test loss=0.517970 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.9560405015945435
[5/24] Train loss=1.035271406173706
[10/24] Train loss=0.9937741756439209
[15/24] Train loss=0.9012909531593323
[20/24] Train loss=0.9250645637512207
Test set avg_accuracy=75.20% avg_sensitivity=83.59%, avg_specificity=72.07% avg_auc=85.43%
Best model saved!! Metric=85.42663631412071!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.995220 Test loss=0.497769 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.9211425185203552
[5/24] Train loss=0.9809942245483398
[10/24] Train loss=0.9869810342788696
[15/24] Train loss=0.903782069683075
[20/24] Train loss=0.9124289751052856
Test set avg_accuracy=74.83% avg_sensitivity=84.84%, avg_specificity=71.10% avg_auc=85.76%
Best model saved!! Metric=85.76492548831835!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.980975 Test loss=0.502061 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.9205963015556335
[5/24] Train loss=0.9691622853279114
[10/24] Train loss=0.9646626114845276
[15/24] Train loss=0.8766036033630371
[20/24] Train loss=0.9261077642440796
Test set avg_accuracy=74.19% avg_sensitivity=87.28%, avg_specificity=69.32% avg_auc=86.14%
Best model saved!! Metric=86.13711946701716!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.967347 Test loss=0.516848 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.9194226861000061
[5/24] Train loss=0.9467768669128418
[10/24] Train loss=0.9684792160987854
[15/24] Train loss=0.874285876750946
[20/24] Train loss=0.9111849665641785
Test set avg_accuracy=74.82% avg_sensitivity=87.43%, avg_specificity=70.12% avg_auc=86.39%
Best model saved!! Metric=86.39101534685456!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.958745 Test loss=0.509048 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.9086418747901917
[5/24] Train loss=0.9466245770454407
[10/24] Train loss=0.9584804773330688
[15/24] Train loss=0.8683111071586609
[20/24] Train loss=0.9040374159812927
Test set avg_accuracy=75.25% avg_sensitivity=87.52%, avg_specificity=70.68% avg_auc=86.74%
Best model saved!! Metric=86.73965860588659!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.947467 Test loss=0.504275 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.8936340808868408
[5/24] Train loss=0.9280434250831604
[10/24] Train loss=0.9402918815612793
[15/24] Train loss=0.8443208336830139
[20/24] Train loss=0.8980404138565063
Test set avg_accuracy=75.07% avg_sensitivity=88.34%, avg_specificity=70.12% avg_auc=87.04%
Best model saved!! Metric=87.0355882114864!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.941800 Test loss=0.506305 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.8837924003601074
[5/24] Train loss=0.9262272119522095
[10/24] Train loss=0.9227086901664734
[15/24] Train loss=0.8300257325172424
[20/24] Train loss=0.8963610529899597
Test set avg_accuracy=74.67% avg_sensitivity=89.01%, avg_specificity=69.34% avg_auc=87.30%
Best model saved!! Metric=87.29943087261398!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.931253 Test loss=0.510016 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.8801307082176208
[5/24] Train loss=0.9360916614532471
[10/24] Train loss=0.9070814251899719
[15/24] Train loss=0.835157573223114
[20/24] Train loss=0.8744212985038757
Test set avg_accuracy=75.78% avg_sensitivity=88.68%, avg_specificity=70.98% avg_auc=87.55%
Best model saved!! Metric=87.55291516150143!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.925679 Test loss=0.491869 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.8691498041152954
[5/24] Train loss=0.9282025098800659
[10/24] Train loss=0.910813570022583
[15/24] Train loss=0.8188924789428711
[20/24] Train loss=0.8697203397750854
Test set avg_accuracy=75.95% avg_sensitivity=88.24%, avg_specificity=71.37% avg_auc=87.78%
Best model saved!! Metric=87.78012194067878!!
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.917896 Test loss=0.484267 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.8606895804405212
[5/24] Train loss=0.9069542288780212
[10/24] Train loss=0.9009099006652832
[15/24] Train loss=0.8074631690979004
[20/24] Train loss=0.8409033417701721
Test set avg_accuracy=76.73% avg_sensitivity=87.72%, avg_specificity=72.64% avg_auc=88.01%
Best model saved!! Metric=88.01342541080207!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.909384 Test loss=0.471651 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.8517171144485474
[5/24] Train loss=0.888705313205719
[10/24] Train loss=0.9060719013214111
[15/24] Train loss=0.8096283674240112
[20/24] Train loss=0.8362232446670532
Test set avg_accuracy=76.64% avg_sensitivity=87.81%, avg_specificity=72.48% avg_auc=88.16%
Best model saved!! Metric=88.1551756189985!!
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.903059 Test loss=0.470965 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.8667512536048889
[5/24] Train loss=0.8886580467224121
[10/24] Train loss=0.885450541973114
[15/24] Train loss=0.8074921369552612
[20/24] Train loss=0.8202944397926331
Test set avg_accuracy=77.46% avg_sensitivity=87.14%, avg_specificity=73.86% avg_auc=88.31%
Best model saved!! Metric=88.31301217348833!!
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.894284 Test loss=0.461196 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.8495827317237854
[5/24] Train loss=0.8754668235778809
[10/24] Train loss=0.883937656879425
[15/24] Train loss=0.8001198172569275
[20/24] Train loss=0.7905238270759583
Test set avg_accuracy=79.27% avg_sensitivity=84.60%, avg_specificity=77.29% avg_auc=88.53%
Best model saved!! Metric=88.5332047568938!!
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.884635 Test loss=0.432977 Current lr=[0.000210185142098938]

[0/24] Train loss=0.8397873640060425
[5/24] Train loss=0.8653210997581482
[10/24] Train loss=0.8907464146614075
[15/24] Train loss=0.7819290161132812
[20/24] Train loss=0.7761945724487305
Test set avg_accuracy=80.33% avg_sensitivity=82.63%, avg_specificity=79.47% avg_auc=88.69%
Best model saved!! Metric=88.68928776244067!!
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.878361 Test loss=0.414777 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.8252542018890381
[5/24] Train loss=0.8694055080413818
[10/24] Train loss=0.8725098371505737
[15/24] Train loss=0.7864310145378113
[20/24] Train loss=0.7559972405433655
Test set avg_accuracy=80.86% avg_sensitivity=81.62%, avg_specificity=80.58% avg_auc=88.81%
Best model saved!! Metric=88.80521921333994!!
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.869422 Test loss=0.407451 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.8259536027908325
[5/24] Train loss=0.858690619468689
[10/24] Train loss=0.8491721153259277
[15/24] Train loss=0.7804931998252869
[20/24] Train loss=0.7439330220222473
Test set avg_accuracy=81.02% avg_sensitivity=81.48%, avg_specificity=80.84% avg_auc=88.92%
Best model saved!! Metric=88.91941426491915!!
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.862622 Test loss=0.405390 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.8157237768173218
[5/24] Train loss=0.8385416865348816
[10/24] Train loss=0.8413050174713135
[15/24] Train loss=0.7758336663246155
[20/24] Train loss=0.7511777877807617
Test set avg_accuracy=81.38% avg_sensitivity=80.85%, avg_specificity=81.58% avg_auc=89.05%
Best model saved!! Metric=89.04915116226424!!
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.853002 Test loss=0.399751 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.8348279595375061
[5/24] Train loss=0.8499718308448792
[10/24] Train loss=0.848319947719574
[15/24] Train loss=0.7653732895851135
[20/24] Train loss=0.7702143788337708
Test set avg_accuracy=82.04% avg_sensitivity=78.65%, avg_specificity=83.31% avg_auc=89.07%
Best model saved!! Metric=89.07105123072554!!
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.852064 Test loss=0.388417 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.8523412346839905
[5/24] Train loss=0.8485238552093506
[10/24] Train loss=0.8393501043319702
[15/24] Train loss=0.7573308944702148
[20/24] Train loss=0.7382121682167053
Test set avg_accuracy=82.32% avg_sensitivity=78.79%, avg_specificity=83.63% avg_auc=89.22%
Best model saved!! Metric=89.21984993393964!!
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.845384 Test loss=0.385567 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.8331338763237
[5/24] Train loss=0.8548030257225037
[10/24] Train loss=0.8523043990135193
[15/24] Train loss=0.7645914554595947
[20/24] Train loss=0.7244758009910583
Test set avg_accuracy=82.60% avg_sensitivity=77.45%, avg_specificity=84.52% avg_auc=89.31%
Best model saved!! Metric=89.30747164481346!!
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.838349 Test loss=0.377612 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.8217980861663818
[5/24] Train loss=0.8423216938972473
[10/24] Train loss=0.8433243036270142
[15/24] Train loss=0.7622004747390747
[20/24] Train loss=0.7293161749839783
Test set avg_accuracy=82.72% avg_sensitivity=77.50%, avg_specificity=84.67% avg_auc=89.44%
Best model saved!! Metric=89.43887634298697!!
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.838806 Test loss=0.376100 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.8247013092041016
[5/24] Train loss=0.8282033205032349
[10/24] Train loss=0.8391110301017761
[15/24] Train loss=0.7406882643699646
[20/24] Train loss=0.731884777545929
Test set avg_accuracy=82.55% avg_sensitivity=79.13%, avg_specificity=83.83% avg_auc=89.50%
Best model saved!! Metric=89.5014724666234!!
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.832299 Test loss=0.380726 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.8253322839736938
[5/24] Train loss=0.8222526907920837
[10/24] Train loss=0.8362849354743958
[15/24] Train loss=0.7401404976844788
[20/24] Train loss=0.7296844720840454
Test set avg_accuracy=82.85% avg_sensitivity=78.45%, avg_specificity=84.49% avg_auc=89.57%
Best model saved!! Metric=89.56938497336321!!
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.830277 Test loss=0.376634 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.8142668008804321
[5/24] Train loss=0.8194211721420288
[10/24] Train loss=0.828719437122345
[15/24] Train loss=0.7512745261192322
[20/24] Train loss=0.7207837700843811
Test set avg_accuracy=82.93% avg_sensitivity=79.27%, avg_specificity=84.29% avg_auc=89.62%
Best model saved!! Metric=89.6229861197812!!
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.822275 Test loss=0.377655 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.7875205278396606
[5/24] Train loss=0.8039907217025757
[10/24] Train loss=0.8306719660758972
[15/24] Train loss=0.7451955080032349
[20/24] Train loss=0.7149063944816589
Test set avg_accuracy=82.76% avg_sensitivity=79.13%, avg_specificity=84.11% avg_auc=89.78%
Best model saved!! Metric=89.78030818558362!!
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.815787 Test loss=0.374830 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.7978589534759521
[5/24] Train loss=0.8022063374519348
[10/24] Train loss=0.812865138053894
[15/24] Train loss=0.7338660359382629
[20/24] Train loss=0.703794002532959
Test set avg_accuracy=83.33% avg_sensitivity=76.87%, avg_specificity=85.74% avg_auc=89.77%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.806777 Test loss=0.365988 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.7983132600784302
[5/24] Train loss=0.8293954730033875
[10/24] Train loss=0.8044925928115845
[15/24] Train loss=0.7269560098648071
[20/24] Train loss=0.6876617670059204
Test set avg_accuracy=83.35% avg_sensitivity=78.07%, avg_specificity=85.31% avg_auc=89.90%
Best model saved!! Metric=89.9006470895718!!
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.802897 Test loss=0.367417 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.7925292253494263
[5/24] Train loss=0.8089544177055359
[10/24] Train loss=0.8132502436637878
[15/24] Train loss=0.7297815680503845
[20/24] Train loss=0.6826441884040833
Test set avg_accuracy=83.50% avg_sensitivity=77.21%, avg_specificity=85.85% avg_auc=89.93%
Best model saved!! Metric=89.92593420855863!!
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.799028 Test loss=0.364412 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.782889723777771
[5/24] Train loss=0.80295330286026
[10/24] Train loss=0.8154376149177551
[15/24] Train loss=0.7167351841926575
[20/24] Train loss=0.6815662980079651
Test set avg_accuracy=83.63% avg_sensitivity=76.54%, avg_specificity=86.28% avg_auc=89.91%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.793095 Test loss=0.361258 Current lr=[0.00029967723776099]

[0/24] Train loss=0.7920910716056824
[5/24] Train loss=0.8170835375785828
[10/24] Train loss=0.7715636491775513
[15/24] Train loss=0.7070311307907104
[20/24] Train loss=0.6778494715690613
Test set avg_accuracy=83.28% avg_sensitivity=78.79%, avg_specificity=84.95% avg_auc=90.04%
Best model saved!! Metric=90.0404250911331!!
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.784233 Test loss=0.367547 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.7540485858917236
[5/24] Train loss=0.794894814491272
[10/24] Train loss=0.7737074494361877
[15/24] Train loss=0.7141714096069336
[20/24] Train loss=0.6685614585876465
Test set avg_accuracy=83.44% avg_sensitivity=78.26%, avg_specificity=85.36% avg_auc=90.06%
Best model saved!! Metric=90.05980416502602!!
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.776036 Test loss=0.363973 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.779491126537323
[5/24] Train loss=0.819776713848114
[10/24] Train loss=0.7594325542449951
[15/24] Train loss=0.7109031677246094
[20/24] Train loss=0.668689489364624
Test set avg_accuracy=83.80% avg_sensitivity=76.63%, avg_specificity=86.47% avg_auc=90.08%
Best model saved!! Metric=90.07673941765366!!
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.773452 Test loss=0.359175 Current lr=[0.000299720220882401]

[0/24] Train loss=0.7610839605331421
[5/24] Train loss=0.8079237341880798
[10/24] Train loss=0.7647004723548889
[15/24] Train loss=0.6933945417404175
[20/24] Train loss=0.6568759679794312
Test set avg_accuracy=83.05% avg_sensitivity=79.61%, avg_specificity=84.33% avg_auc=90.09%
Best model saved!! Metric=90.08587587926117!!
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.763704 Test loss=0.370973 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.7368924617767334
[5/24] Train loss=0.7802302241325378
[10/24] Train loss=0.7512797713279724
[15/24] Train loss=0.6973632574081421
[20/24] Train loss=0.6610130667686462
Test set avg_accuracy=83.54% avg_sensitivity=77.88%, avg_specificity=85.65% avg_auc=89.94%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.756532 Test loss=0.366524 Current lr=[0.000298904600941902]

[0/24] Train loss=0.7598610520362854
[5/24] Train loss=0.8155897855758667
[10/24] Train loss=0.7371280193328857
[15/24] Train loss=0.6941914558410645
[20/24] Train loss=0.6445379853248596
Test set avg_accuracy=83.76% avg_sensitivity=77.21%, avg_specificity=86.20% avg_auc=90.09%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.755964 Test loss=0.360630 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.7542493939399719
[5/24] Train loss=0.7589218616485596
[10/24] Train loss=0.7522405385971069
[15/24] Train loss=0.6725828051567078
[20/24] Train loss=0.6460474729537964
Test set avg_accuracy=83.11% avg_sensitivity=79.85%, avg_specificity=84.33% avg_auc=90.12%
Best model saved!! Metric=90.11835726506045!!
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.746964 Test loss=0.372414 Current lr=[0.000297555943323901]

[0/24] Train loss=0.7255759835243225
[5/24] Train loss=0.7682350277900696
[10/24] Train loss=0.7409577369689941
[15/24] Train loss=0.6670981049537659
[20/24] Train loss=0.6424758434295654
Test set avg_accuracy=83.78% avg_sensitivity=77.50%, avg_specificity=86.12% avg_auc=90.06%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.741823 Test loss=0.362605 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.7472724914550781
[5/24] Train loss=0.7555556297302246
[10/24] Train loss=0.7177332043647766
[15/24] Train loss=0.6516016721725464
[20/24] Train loss=0.6513155698776245
Test set avg_accuracy=83.02% avg_sensitivity=79.75%, avg_specificity=84.24% avg_auc=90.04%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.734565 Test loss=0.374873 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.7143969535827637
[5/24] Train loss=0.75020831823349
[10/24] Train loss=0.7130213975906372
[15/24] Train loss=0.6637243032455444
[20/24] Train loss=0.6412329077720642
Test set avg_accuracy=83.40% avg_sensitivity=78.50%, avg_specificity=85.22% avg_auc=90.10%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.727916 Test loss=0.367729 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.7243342399597168
[5/24] Train loss=0.7343655824661255
[10/24] Train loss=0.7292469143867493
[15/24] Train loss=0.673902153968811
[20/24] Train loss=0.6305871605873108
Test set avg_accuracy=83.36% avg_sensitivity=77.93%, avg_specificity=85.38% avg_auc=90.06%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.727674 Test loss=0.366091 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.7093432545661926
[5/24] Train loss=0.7223766446113586
[10/24] Train loss=0.7123233675956726
[15/24] Train loss=0.6501867175102234
[20/24] Train loss=0.6260143518447876
Test set avg_accuracy=83.29% avg_sensitivity=78.31%, avg_specificity=85.15% avg_auc=90.02%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.715829 Test loss=0.368425 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.7150381803512573
[5/24] Train loss=0.7203843593597412
[10/24] Train loss=0.6986982226371765
[15/24] Train loss=0.6423407793045044
[20/24] Train loss=0.6278610825538635
Test set avg_accuracy=83.24% avg_sensitivity=78.79%, avg_specificity=84.90% avg_auc=90.00%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.712215 Test loss=0.371159 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.6967347264289856
[5/24] Train loss=0.7202868461608887
[10/24] Train loss=0.7052938938140869
[15/24] Train loss=0.6442529559135437
[20/24] Train loss=0.5989686250686646
Test set avg_accuracy=82.42% avg_sensitivity=81.09%, avg_specificity=82.92% avg_auc=90.09%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.709200 Test loss=0.384819 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.6581926941871643
[5/24] Train loss=0.695745587348938
[10/24] Train loss=0.6908593773841858
[15/24] Train loss=0.6363018155097961
[20/24] Train loss=0.6147412657737732
Test set avg_accuracy=82.16% avg_sensitivity=81.72%, avg_specificity=82.33% avg_auc=90.01%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.699921 Test loss=0.391174 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.6507278680801392
[5/24] Train loss=0.6738304495811462
[10/24] Train loss=0.6906183958053589
[15/24] Train loss=0.6431992053985596
[20/24] Train loss=0.6038420796394348
Test set avg_accuracy=82.19% avg_sensitivity=81.53%, avg_specificity=82.43% avg_auc=89.97%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.694063 Test loss=0.391655 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.6504989862442017
[5/24] Train loss=0.6752325296401978
[10/24] Train loss=0.690392255783081
[15/24] Train loss=0.6259432435035706
[20/24] Train loss=0.602461576461792
Test set avg_accuracy=82.41% avg_sensitivity=80.18%, avg_specificity=83.24% avg_auc=89.92%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.689508 Test loss=0.384742 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.6693505048751831
[5/24] Train loss=0.6944684982299805
[10/24] Train loss=0.6688827872276306
[15/24] Train loss=0.6295304298400879
[20/24] Train loss=0.5697160363197327
Test set avg_accuracy=81.38% avg_sensitivity=83.49%, avg_specificity=80.59% avg_auc=89.94%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.683583 Test loss=0.408949 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.6390591859817505
[5/24] Train loss=0.6525710821151733
[10/24] Train loss=0.6879122853279114
[15/24] Train loss=0.6298850774765015
[20/24] Train loss=0.5808682441711426
Test set avg_accuracy=81.64% avg_sensitivity=83.11%, avg_specificity=81.09% avg_auc=90.05%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.677309 Test loss=0.403095 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.6400286555290222
[5/24] Train loss=0.6322500109672546
[10/24] Train loss=0.6875337958335876
[15/24] Train loss=0.6220299005508423
[20/24] Train loss=0.5705483555793762
Test set avg_accuracy=81.74% avg_sensitivity=82.68%, avg_specificity=81.40% avg_auc=89.90%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.676339 Test loss=0.401129 Current lr=[0.000276307469034998]

[0/24] Train loss=0.6531498432159424
[5/24] Train loss=0.6215090751647949
[10/24] Train loss=0.669559895992279
[15/24] Train loss=0.6285017728805542
[20/24] Train loss=0.5800220370292664
Test set avg_accuracy=81.60% avg_sensitivity=82.92%, avg_specificity=81.11% avg_auc=89.85%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.669721 Test loss=0.408782 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.6340252757072449
[5/24] Train loss=0.6280304193496704
[10/24] Train loss=0.6472028493881226
[15/24] Train loss=0.5989193320274353
[20/24] Train loss=0.5726323127746582
Test set avg_accuracy=81.81% avg_sensitivity=84.12%, avg_specificity=80.95% avg_auc=89.90%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.663177 Test loss=0.410600 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.6389742493629456
[5/24] Train loss=0.6138251423835754
[10/24] Train loss=0.6669303178787231
[15/24] Train loss=0.6075570583343506
[20/24] Train loss=0.5618809461593628
Test set avg_accuracy=82.21% avg_sensitivity=81.33%, avg_specificity=82.54% avg_auc=89.84%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.657973 Test loss=0.396310 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.6388538479804993
[5/24] Train loss=0.6161735653877258
[10/24] Train loss=0.6650235652923584
[15/24] Train loss=0.5977088809013367
[20/24] Train loss=0.5513571500778198
Test set avg_accuracy=81.29% avg_sensitivity=84.31%, avg_specificity=80.16% avg_auc=89.80%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.656687 Test loss=0.421606 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.6531050205230713
[5/24] Train loss=0.5987016558647156
[10/24] Train loss=0.6553245782852173
[15/24] Train loss=0.5856932997703552
[20/24] Train loss=0.551775336265564
Test set avg_accuracy=81.32% avg_sensitivity=83.40%, avg_specificity=80.54% avg_auc=89.62%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.648407 Test loss=0.419909 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.6302185654640198
[5/24] Train loss=0.5927496552467346
[10/24] Train loss=0.6576107740402222
[15/24] Train loss=0.5989749431610107
[20/24] Train loss=0.5536659955978394
Test set avg_accuracy=80.64% avg_sensitivity=84.79%, avg_specificity=79.09% avg_auc=89.65%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.648452 Test loss=0.436515 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.6192359328269958
[5/24] Train loss=0.5798690319061279
[10/24] Train loss=0.6503136157989502
[15/24] Train loss=0.5737614035606384
[20/24] Train loss=0.5613073110580444
Test set avg_accuracy=80.90% avg_sensitivity=84.12%, avg_specificity=79.70% avg_auc=89.69%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.640732 Test loss=0.429946 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.6065459847450256
[5/24] Train loss=0.6056330800056458
[10/24] Train loss=0.6299286484718323
[15/24] Train loss=0.5814794898033142
[20/24] Train loss=0.5438025593757629
Test set avg_accuracy=81.64% avg_sensitivity=83.35%, avg_specificity=81.00% avg_auc=89.76%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.638334 Test loss=0.415749 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.6167236566543579
[5/24] Train loss=0.5950859189033508
[10/24] Train loss=0.63322913646698
[15/24] Train loss=0.5915391445159912
[20/24] Train loss=0.5659687519073486
Test set avg_accuracy=81.72% avg_sensitivity=83.59%, avg_specificity=81.02% avg_auc=89.72%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.635100 Test loss=0.417506 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.6018537878990173
[5/24] Train loss=0.5875501036643982
[10/24] Train loss=0.6621909141540527
[15/24] Train loss=0.5742670297622681
[20/24] Train loss=0.5174611806869507
Test set avg_accuracy=81.41% avg_sensitivity=82.39%, avg_specificity=81.04% avg_auc=89.59%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.631817 Test loss=0.419905 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.5907005667686462
[5/24] Train loss=0.5694286227226257
[10/24] Train loss=0.6312779188156128
[15/24] Train loss=0.5637403726577759
[20/24] Train loss=0.5244714617729187
Test set avg_accuracy=80.70% avg_sensitivity=84.55%, avg_specificity=79.27% avg_auc=89.57%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.626572 Test loss=0.442444 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.6014090776443481
[5/24] Train loss=0.5613659024238586
[10/24] Train loss=0.6212651133537292
[15/24] Train loss=0.5602670907974243
[20/24] Train loss=0.5451241731643677
Test set avg_accuracy=81.35% avg_sensitivity=82.10%, avg_specificity=81.08% avg_auc=89.52%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.622566 Test loss=0.421642 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.6023944020271301
[5/24] Train loss=0.5860135555267334
[10/24] Train loss=0.6291409134864807
[15/24] Train loss=0.5703054666519165
[20/24] Train loss=0.5165187120437622
Test set avg_accuracy=80.96% avg_sensitivity=83.97%, avg_specificity=79.84% avg_auc=89.55%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.620154 Test loss=0.437234 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.567054271697998
[5/24] Train loss=0.5877833366394043
[10/24] Train loss=0.6278778314590454
[15/24] Train loss=0.5632932186126709
[20/24] Train loss=0.5043651461601257
Test set avg_accuracy=81.68% avg_sensitivity=80.71%, avg_specificity=82.04% avg_auc=89.44%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.615244 Test loss=0.409795 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.5956771969795227
[5/24] Train loss=0.5928021669387817
[10/24] Train loss=0.6165087819099426
[15/24] Train loss=0.5755563378334045
[20/24] Train loss=0.5159702897071838
Test set avg_accuracy=81.43% avg_sensitivity=81.67%, avg_specificity=81.34% avg_auc=89.42%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.616376 Test loss=0.416039 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.5965006947517395
[5/24] Train loss=0.5936134457588196
[10/24] Train loss=0.6114441156387329
[15/24] Train loss=0.5643925070762634
[20/24] Train loss=0.5261287093162537
Test set avg_accuracy=81.72% avg_sensitivity=81.48%, avg_specificity=81.81% avg_auc=89.48%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.616860 Test loss=0.413137 Current lr=[0.000224838296036774]

[0/24] Train loss=0.594241738319397
[5/24] Train loss=0.5596564412117004
[10/24] Train loss=0.6165511608123779
[15/24] Train loss=0.5799203515052795
[20/24] Train loss=0.5285048484802246
Test set avg_accuracy=82.75% avg_sensitivity=76.68%, avg_specificity=85.01% avg_auc=89.41%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.632608 Test loss=0.387711 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.5978508591651917
[5/24] Train loss=0.560489296913147
[10/24] Train loss=0.7097286581993103
[15/24] Train loss=0.5939019322395325
[20/24] Train loss=0.5993682146072388
Test set avg_accuracy=77.02% avg_sensitivity=89.97%, avg_specificity=72.19% avg_auc=89.65%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.651298 Test loss=0.516561 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.611633837223053
[5/24] Train loss=0.5644828081130981
[10/24] Train loss=0.6245826482772827
[15/24] Train loss=0.5869209170341492
[20/24] Train loss=0.5389136672019958
Test set avg_accuracy=80.25% avg_sensitivity=85.75%, avg_specificity=78.20% avg_auc=89.63%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.618038 Test loss=0.452505 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.5772348046302795
[5/24] Train loss=0.5754897594451904
[10/24] Train loss=0.6377387642860413
[15/24] Train loss=0.5674839019775391
[20/24] Train loss=0.541706383228302
Test set avg_accuracy=78.54% avg_sensitivity=87.76%, avg_specificity=75.11% avg_auc=89.69%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.620530 Test loss=0.490211 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.57867830991745
[5/24] Train loss=0.5724512338638306
[10/24] Train loss=0.6181231141090393
[15/24] Train loss=0.5497860908508301
[20/24] Train loss=0.503199577331543
Test set avg_accuracy=80.18% avg_sensitivity=85.32%, avg_specificity=78.27% avg_auc=89.52%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.606417 Test loss=0.460918 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.5574630498886108
[5/24] Train loss=0.5578187704086304
[10/24] Train loss=0.6262080669403076
[15/24] Train loss=0.538346529006958
[20/24] Train loss=0.5303923487663269
Test set avg_accuracy=79.34% avg_sensitivity=87.09%, avg_specificity=76.45% avg_auc=89.68%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.609531 Test loss=0.474774 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.5638693571090698
[5/24] Train loss=0.5700135827064514
[10/24] Train loss=0.6182247400283813
[15/24] Train loss=0.5585441589355469
[20/24] Train loss=0.5190191268920898
Test set avg_accuracy=80.10% avg_sensitivity=85.99%, avg_specificity=77.91% avg_auc=89.58%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.606964 Test loss=0.469892 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.5650718808174133
[5/24] Train loss=0.5491862297058105
[10/24] Train loss=0.5975151658058167
[15/24] Train loss=0.5551659464836121
[20/24] Train loss=0.4972824156284332
Test set avg_accuracy=79.69% avg_sensitivity=86.52%, avg_specificity=77.14% avg_auc=89.67%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.595442 Test loss=0.473536 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.5647355914115906
[5/24] Train loss=0.5434415340423584
[10/24] Train loss=0.5850726962089539
[15/24] Train loss=0.5506672263145447
[20/24] Train loss=0.5174145102500916
Test set avg_accuracy=79.62% avg_sensitivity=86.56%, avg_specificity=77.04% avg_auc=89.67%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.597029 Test loss=0.473848 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.5510172247886658
[5/24] Train loss=0.5406626462936401
[10/24] Train loss=0.5907443165779114
[15/24] Train loss=0.5383550524711609
[20/24] Train loss=0.5191712975502014
Test set avg_accuracy=80.03% avg_sensitivity=86.76%, avg_specificity=77.52% avg_auc=89.60%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.592110 Test loss=0.476344 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.55070960521698
[5/24] Train loss=0.5352674722671509
[10/24] Train loss=0.5767471790313721
[15/24] Train loss=0.5204424262046814
[20/24] Train loss=0.49624013900756836
Test set avg_accuracy=80.09% avg_sensitivity=85.80%, avg_specificity=77.97% avg_auc=89.59%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.588966 Test loss=0.471512 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.5560524463653564
[5/24] Train loss=0.5539324283599854
[10/24] Train loss=0.5837363004684448
[15/24] Train loss=0.5433219075202942
[20/24] Train loss=0.48785141110420227
Test set avg_accuracy=79.15% avg_sensitivity=87.81%, avg_specificity=75.93% avg_auc=89.69%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.594053 Test loss=0.496590 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.5463911890983582
[5/24] Train loss=0.546227753162384
[10/24] Train loss=0.5925280451774597
[15/24] Train loss=0.545883059501648
[20/24] Train loss=0.49039381742477417
Test set avg_accuracy=78.33% avg_sensitivity=89.06%, avg_specificity=74.34% avg_auc=89.70%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.597550 Test loss=0.529353 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.5600279569625854
[5/24] Train loss=0.5442894101142883
[10/24] Train loss=0.5912200808525085
[15/24] Train loss=0.5619329810142517
[20/24] Train loss=0.5759412050247192
Test set avg_accuracy=75.33% avg_sensitivity=91.89%, avg_specificity=69.16% avg_auc=89.81%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.606803 Test loss=0.604809 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.632925808429718
[5/24] Train loss=0.6004049181938171
[10/24] Train loss=0.6280087232589722
[15/24] Train loss=0.5405118465423584
[20/24] Train loss=0.532814621925354
Test set avg_accuracy=77.58% avg_sensitivity=90.31%, avg_specificity=72.84% avg_auc=89.81%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.611166 Test loss=0.547049 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.5954472422599792
[5/24] Train loss=0.5682634115219116
[10/24] Train loss=0.6098135709762573
[15/24] Train loss=0.551909327507019
[20/24] Train loss=0.4971800148487091
Test set avg_accuracy=77.89% avg_sensitivity=89.44%, avg_specificity=73.59% avg_auc=89.64%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.594398 Test loss=0.543901 Current lr=[0.000156543481933168]

[0/24] Train loss=0.5649281740188599
[5/24] Train loss=0.5589740872383118
[10/24] Train loss=0.603567898273468
[15/24] Train loss=0.5424125790596008
[20/24] Train loss=0.5029013156890869
Test set avg_accuracy=77.62% avg_sensitivity=89.73%, avg_specificity=73.11% avg_auc=89.62%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.588738 Test loss=0.546959 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.5784937143325806
[5/24] Train loss=0.5802316069602966
[10/24] Train loss=0.6035412549972534
[15/24] Train loss=0.5433642268180847
[20/24] Train loss=0.5107257962226868
Test set avg_accuracy=77.99% avg_sensitivity=89.16%, avg_specificity=73.84% avg_auc=89.52%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.591950 Test loss=0.539166 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.5607687830924988
[5/24] Train loss=0.5573087930679321
[10/24] Train loss=0.6189336180686951
[15/24] Train loss=0.5278502702713013
[20/24] Train loss=0.48484838008880615
Test set avg_accuracy=78.33% avg_sensitivity=88.39%, avg_specificity=74.59% avg_auc=89.46%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.583873 Test loss=0.531874 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.5412276387214661
[5/24] Train loss=0.5481109619140625
[10/24] Train loss=0.584968090057373
[15/24] Train loss=0.5387132167816162
[20/24] Train loss=0.4870937168598175
Test set avg_accuracy=77.77% avg_sensitivity=89.20%, avg_specificity=73.52% avg_auc=89.39%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.576940 Test loss=0.549818 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.5542625188827515
[5/24] Train loss=0.5465161800384521
[10/24] Train loss=0.5906519889831543
[15/24] Train loss=0.5182041525840759
[20/24] Train loss=0.5157661437988281
Test set avg_accuracy=77.72% avg_sensitivity=88.77%, avg_specificity=73.61% avg_auc=89.37%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.574977 Test loss=0.548479 Current lr=[0.000134135431043539]

[0/24] Train loss=0.556287407875061
[5/24] Train loss=0.5473081469535828
[10/24] Train loss=0.6083487272262573
[15/24] Train loss=0.5189577341079712
[20/24] Train loss=0.48694518208503723
Test set avg_accuracy=78.22% avg_sensitivity=88.00%, avg_specificity=74.57% avg_auc=89.39%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.574428 Test loss=0.528808 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.5387923121452332
[5/24] Train loss=0.5415648818016052
[10/24] Train loss=0.5852358937263489
[15/24] Train loss=0.5090792775154114
[20/24] Train loss=0.4822438061237335
Test set avg_accuracy=78.52% avg_sensitivity=87.67%, avg_specificity=75.11% avg_auc=89.25%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.566779 Test loss=0.525345 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.5572441220283508
[5/24] Train loss=0.528241753578186
[10/24] Train loss=0.5856656432151794
[15/24] Train loss=0.520144522190094
[20/24] Train loss=0.4934248626232147
Test set avg_accuracy=78.14% avg_sensitivity=88.20%, avg_specificity=74.39% avg_auc=89.29%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.566969 Test loss=0.542114 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.5510003566741943
[5/24] Train loss=0.5348537564277649
[10/24] Train loss=0.5922566056251526
[15/24] Train loss=0.5283088088035583
[20/24] Train loss=0.47733792662620544
Test set avg_accuracy=78.63% avg_sensitivity=87.62%, avg_specificity=75.29% avg_auc=89.22%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.564333 Test loss=0.530681 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.5426377058029175
[5/24] Train loss=0.5539835691452026
[10/24] Train loss=0.5948931574821472
[15/24] Train loss=0.502587080001831
[20/24] Train loss=0.46926984190940857
Test set avg_accuracy=78.29% avg_sensitivity=87.52%, avg_specificity=74.86% avg_auc=89.12%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.561627 Test loss=0.532012 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.5448063015937805
[5/24] Train loss=0.5300569534301758
[10/24] Train loss=0.5879453420639038
[15/24] Train loss=0.5339891314506531
[20/24] Train loss=0.48978057503700256
Test set avg_accuracy=77.47% avg_sensitivity=88.10%, avg_specificity=73.52% avg_auc=89.15%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.561975 Test loss=0.554774 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.5403216481208801
[5/24] Train loss=0.5219283103942871
[10/24] Train loss=0.6001434922218323
[15/24] Train loss=0.5126807689666748
[20/24] Train loss=0.46297818422317505
Test set avg_accuracy=78.27% avg_sensitivity=87.19%, avg_specificity=74.95% avg_auc=89.08%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.558619 Test loss=0.530933 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.5360736846923828
[5/24] Train loss=0.506140947341919
[10/24] Train loss=0.5882455110549927
[15/24] Train loss=0.5104013681411743
[20/24] Train loss=0.49172452092170715
Test set avg_accuracy=77.68% avg_sensitivity=88.24%, avg_specificity=73.75% avg_auc=89.16%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.557503 Test loss=0.553143 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5360192656517029
[5/24] Train loss=0.538616418838501
[10/24] Train loss=0.5721547603607178
[15/24] Train loss=0.5199723839759827
[20/24] Train loss=0.479458212852478
Test set avg_accuracy=77.66% avg_sensitivity=88.20%, avg_specificity=73.73% avg_auc=89.22%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.559422 Test loss=0.546169 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.5253820419311523
[5/24] Train loss=0.5208547115325928
[10/24] Train loss=0.5624538660049438
[15/24] Train loss=0.504108190536499
[20/24] Train loss=0.47593265771865845
Test set avg_accuracy=77.60% avg_sensitivity=88.24%, avg_specificity=73.64% avg_auc=89.32%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.556454 Test loss=0.543085 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.5231391787528992
[5/24] Train loss=0.5201057195663452
[10/24] Train loss=0.5891817808151245
[15/24] Train loss=0.5053102374076843
[20/24] Train loss=0.46325209736824036
Test set avg_accuracy=77.07% avg_sensitivity=88.87%, avg_specificity=72.68% avg_auc=89.36%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.550451 Test loss=0.554037 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.5368784070014954
[5/24] Train loss=0.5050232410430908
[10/24] Train loss=0.5646514296531677
[15/24] Train loss=0.5017477869987488
[20/24] Train loss=0.4909789264202118
Test set avg_accuracy=76.61% avg_sensitivity=89.44%, avg_specificity=71.84% avg_auc=89.33%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.553734 Test loss=0.574607 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.5494290590286255
[5/24] Train loss=0.5217410922050476
[10/24] Train loss=0.5773940086364746
[15/24] Train loss=0.5021963119506836
[20/24] Train loss=0.49672046303749084
Test set avg_accuracy=76.11% avg_sensitivity=89.78%, avg_specificity=71.02% avg_auc=89.28%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.557125 Test loss=0.585657 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.5451990962028503
[5/24] Train loss=0.4932543933391571
[10/24] Train loss=0.586012065410614
[15/24] Train loss=0.5137124061584473
[20/24] Train loss=0.5309444665908813
Test set avg_accuracy=76.55% avg_sensitivity=89.40%, avg_specificity=71.77% avg_auc=89.30%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.564022 Test loss=0.571106 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.5474859476089478
[5/24] Train loss=0.4918118119239807
[10/24] Train loss=0.5710476040840149
[15/24] Train loss=0.5394091606140137
[20/24] Train loss=0.5186524987220764
Test set avg_accuracy=79.43% avg_sensitivity=86.04%, avg_specificity=76.97% avg_auc=89.28%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.570003 Test loss=0.489411 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.5433002710342407
[5/24] Train loss=0.5043337941169739
[10/24] Train loss=0.589907169342041
[15/24] Train loss=0.5108131170272827
[20/24] Train loss=0.4708767831325531
Test set avg_accuracy=80.49% avg_sensitivity=83.01%, avg_specificity=79.56% avg_auc=89.18%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.560800 Test loss=0.457365 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.5436520576477051
[5/24] Train loss=0.49424007534980774
[10/24] Train loss=0.5481919646263123
[15/24] Train loss=0.5069929957389832
[20/24] Train loss=0.47945329546928406
Test set avg_accuracy=78.78% avg_sensitivity=86.66%, avg_specificity=75.84% avg_auc=89.14%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.547877 Test loss=0.507465 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.5373626947402954
[5/24] Train loss=0.49526986479759216
[10/24] Train loss=0.5553439259529114
[15/24] Train loss=0.5085353255271912
[20/24] Train loss=0.47762924432754517
Test set avg_accuracy=79.44% avg_sensitivity=85.60%, avg_specificity=77.14% avg_auc=89.15%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.547436 Test loss=0.491012 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.5064566135406494
[5/24] Train loss=0.48832613229751587
[10/24] Train loss=0.5577945709228516
[15/24] Train loss=0.5028631687164307
[20/24] Train loss=0.4689183235168457
Test set avg_accuracy=79.06% avg_sensitivity=85.84%, avg_specificity=76.54% avg_auc=89.12%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.543092 Test loss=0.498761 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.517505943775177
[5/24] Train loss=0.4908325970172882
[10/24] Train loss=0.5657361745834351
[15/24] Train loss=0.4975181221961975
[20/24] Train loss=0.4591592252254486
Test set avg_accuracy=79.01% avg_sensitivity=86.18%, avg_specificity=76.34% avg_auc=89.17%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.542073 Test loss=0.499146 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.5264735817909241
[5/24] Train loss=0.4997485876083374
[10/24] Train loss=0.5720749497413635
[15/24] Train loss=0.48986825346946716
[20/24] Train loss=0.47422149777412415
Test set avg_accuracy=79.04% avg_sensitivity=86.23%, avg_specificity=76.36% avg_auc=89.10%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.545714 Test loss=0.505663 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.507187008857727
[5/24] Train loss=0.49475157260894775
[10/24] Train loss=0.5366988182067871
[15/24] Train loss=0.5056290030479431
[20/24] Train loss=0.47093990445137024
Test set avg_accuracy=79.18% avg_sensitivity=86.08%, avg_specificity=76.61% avg_auc=89.21%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.539817 Test loss=0.499612 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.5225864052772522
[5/24] Train loss=0.4897889494895935
[10/24] Train loss=0.5443311333656311
[15/24] Train loss=0.4868202209472656
[20/24] Train loss=0.4511461555957794
Test set avg_accuracy=78.79% avg_sensitivity=86.13%, avg_specificity=76.05% avg_auc=89.12%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.535045 Test loss=0.509366 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5157839059829712
[5/24] Train loss=0.4912211298942566
[10/24] Train loss=0.5763367414474487
[15/24] Train loss=0.5008502006530762
[20/24] Train loss=0.46012938022613525
Test set avg_accuracy=78.71% avg_sensitivity=86.32%, avg_specificity=75.88% avg_auc=89.13%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.539044 Test loss=0.509839 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.51783287525177
[5/24] Train loss=0.4850434958934784
[10/24] Train loss=0.5269595980644226
[15/24] Train loss=0.505765974521637
[20/24] Train loss=0.4585132896900177
Test set avg_accuracy=78.62% avg_sensitivity=86.52%, avg_specificity=75.68% avg_auc=89.14%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.534980 Test loss=0.513111 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5136181116104126
[5/24] Train loss=0.4818022549152374
[10/24] Train loss=0.5629852414131165
[15/24] Train loss=0.4946313500404358
[20/24] Train loss=0.46737757325172424
Test set avg_accuracy=78.67% avg_sensitivity=86.28%, avg_specificity=75.84% avg_auc=89.14%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.537446 Test loss=0.509096 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.5222276449203491
[5/24] Train loss=0.4884384274482727
[10/24] Train loss=0.5430399775505066
[15/24] Train loss=0.4970814883708954
[20/24] Train loss=0.4606914818286896
Test set avg_accuracy=78.62% avg_sensitivity=86.47%, avg_specificity=75.70% avg_auc=89.11%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.533558 Test loss=0.513148 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5193295478820801
[5/24] Train loss=0.4835657477378845
[10/24] Train loss=0.5486595630645752
[15/24] Train loss=0.4955654442310333
[20/24] Train loss=0.45617374777793884
Test set avg_accuracy=78.59% avg_sensitivity=86.52%, avg_specificity=75.64% avg_auc=89.07%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.533266 Test loss=0.515461 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.5103954672813416
[5/24] Train loss=0.49301981925964355
[10/24] Train loss=0.5314104557037354
[15/24] Train loss=0.5137443542480469
[20/24] Train loss=0.44755321741104126
Test set avg_accuracy=78.48% avg_sensitivity=86.47%, avg_specificity=75.50% avg_auc=89.10%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.533666 Test loss=0.517277 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.505936861038208
[5/24] Train loss=0.4887845516204834
[10/24] Train loss=0.5537708401679993
[15/24] Train loss=0.4936298727989197
[20/24] Train loss=0.4517247676849365
Test set avg_accuracy=78.41% avg_sensitivity=86.52%, avg_specificity=75.39% avg_auc=89.07%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.531917 Test loss=0.518906 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.5021583437919617
[5/24] Train loss=0.49168846011161804
[10/24] Train loss=0.5426835417747498
[15/24] Train loss=0.4815787374973297
[20/24] Train loss=0.4628733694553375
Test set avg_accuracy=78.48% avg_sensitivity=86.61%, avg_specificity=75.45% avg_auc=89.09%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.533088 Test loss=0.517599 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.52862948179245
[5/24] Train loss=0.4878372251987457
[10/24] Train loss=0.5412938594818115
[15/24] Train loss=0.5068327784538269
[20/24] Train loss=0.46494781970977783
Test set avg_accuracy=78.63% avg_sensitivity=86.56%, avg_specificity=75.68% avg_auc=89.10%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.530749 Test loss=0.513713 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.49998027086257935
[5/24] Train loss=0.473170667886734
[10/24] Train loss=0.5287283658981323
[15/24] Train loss=0.5034369826316833
[20/24] Train loss=0.4730730354785919
Test set avg_accuracy=78.76% avg_sensitivity=86.32%, avg_specificity=75.95% avg_auc=89.06%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.531834 Test loss=0.511641 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.5237852931022644
[5/24] Train loss=0.48010873794555664
[10/24] Train loss=0.5277696251869202
[15/24] Train loss=0.4902130961418152
[20/24] Train loss=0.4548429846763611
Test set avg_accuracy=78.95% avg_sensitivity=86.04%, avg_specificity=76.30% avg_auc=89.07%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.528846 Test loss=0.506499 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.5185527205467224
[5/24] Train loss=0.4851265251636505
[10/24] Train loss=0.549750566482544
[15/24] Train loss=0.48630470037460327
[20/24] Train loss=0.46246251463890076
Test set avg_accuracy=79.45% avg_sensitivity=85.56%, avg_specificity=77.18% avg_auc=89.09%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.526879 Test loss=0.494077 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.515974223613739
[5/24] Train loss=0.4802120327949524
[10/24] Train loss=0.5491443872451782
[15/24] Train loss=0.5093845129013062
[20/24] Train loss=0.4520200192928314
Test set avg_accuracy=79.35% avg_sensitivity=85.89%, avg_specificity=76.91% avg_auc=89.10%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.531723 Test loss=0.500166 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.507994532585144
[5/24] Train loss=0.48378440737724304
[10/24] Train loss=0.5471933484077454
[15/24] Train loss=0.4996219277381897
[20/24] Train loss=0.4714469611644745
Test set avg_accuracy=79.26% avg_sensitivity=85.94%, avg_specificity=76.77% avg_auc=89.12%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.529401 Test loss=0.502510 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5135788917541504
[5/24] Train loss=0.4947056174278259
[10/24] Train loss=0.5251089930534363
[15/24] Train loss=0.49043670296669006
[20/24] Train loss=0.4656725227832794
Test set avg_accuracy=79.35% avg_sensitivity=85.89%, avg_specificity=76.91% avg_auc=89.11%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.529062 Test loss=0.499715 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5111199617385864
[5/24] Train loss=0.48434126377105713
[10/24] Train loss=0.5341384410858154
[15/24] Train loss=0.502719521522522
[20/24] Train loss=0.4454067349433899
Test set avg_accuracy=79.21% avg_sensitivity=85.99%, avg_specificity=76.68% avg_auc=89.08%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.531079 Test loss=0.503697 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5019170641899109
[5/24] Train loss=0.48809605836868286
[10/24] Train loss=0.5324257612228394
[15/24] Train loss=0.4963262677192688
[20/24] Train loss=0.45613712072372437
Test set avg_accuracy=79.02% avg_sensitivity=85.99%, avg_specificity=76.43% avg_auc=89.08%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.526532 Test loss=0.505609 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5199316740036011
[5/24] Train loss=0.47572723031044006
[10/24] Train loss=0.5350601673126221
[15/24] Train loss=0.4953988790512085
[20/24] Train loss=0.4367830455303192
Test set avg_accuracy=79.05% avg_sensitivity=86.04%, avg_specificity=76.45% avg_auc=89.08%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.526716 Test loss=0.504778 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.4953104257583618
[5/24] Train loss=0.4802609384059906
[10/24] Train loss=0.5488491058349609
[15/24] Train loss=0.4889344573020935
[20/24] Train loss=0.47178342938423157
Test set avg_accuracy=79.24% avg_sensitivity=85.89%, avg_specificity=76.77% avg_auc=89.08%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.528263 Test loss=0.501745 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.5218400955200195
[5/24] Train loss=0.503528892993927
[10/24] Train loss=0.5390313267707825
[15/24] Train loss=0.5121597647666931
[20/24] Train loss=0.45055657625198364
Test set avg_accuracy=78.91% avg_sensitivity=86.04%, avg_specificity=76.25% avg_auc=89.09%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.527385 Test loss=0.507250 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5048571825027466
[5/24] Train loss=0.4886075556278229
[10/24] Train loss=0.5439094305038452
[15/24] Train loss=0.49035966396331787
[20/24] Train loss=0.45642250776290894
Test set avg_accuracy=79.05% avg_sensitivity=85.94%, avg_specificity=76.48% avg_auc=89.09%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.528087 Test loss=0.504981 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.5155625343322754
[5/24] Train loss=0.4945216774940491
[10/24] Train loss=0.5588840842247009
[15/24] Train loss=0.49565374851226807
[20/24] Train loss=0.4658646583557129
Test set avg_accuracy=79.04% avg_sensitivity=85.94%, avg_specificity=76.47% avg_auc=89.09%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.532739 Test loss=0.504876 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5091644525527954
[5/24] Train loss=0.4767705500125885
[10/24] Train loss=0.5397554039955139
[15/24] Train loss=0.47789469361305237
[20/24] Train loss=0.45542359352111816
Test set avg_accuracy=79.00% avg_sensitivity=85.99%, avg_specificity=76.39% avg_auc=89.09%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.527427 Test loss=0.505190 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5140687823295593
[5/24] Train loss=0.508752703666687
[10/24] Train loss=0.5338490009307861
[15/24] Train loss=0.4962323009967804
[20/24] Train loss=0.45613953471183777
Test set avg_accuracy=78.98% avg_sensitivity=86.04%, avg_specificity=76.36% avg_auc=89.09%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.532452 Test loss=0.505934 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.4939672648906708
[5/24] Train loss=0.46166300773620605
[10/24] Train loss=0.5375765562057495
[15/24] Train loss=0.48777875304222107
[20/24] Train loss=0.4492339789867401
Test set avg_accuracy=78.96% avg_sensitivity=86.04%, avg_specificity=76.32% avg_auc=89.09%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.522157 Test loss=0.506238 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5030434131622314
[5/24] Train loss=0.47145628929138184
[10/24] Train loss=0.5099343657493591
[15/24] Train loss=0.5132921934127808
[20/24] Train loss=0.4490900933742523
Test set avg_accuracy=78.96% avg_sensitivity=86.04%, avg_specificity=76.32% avg_auc=89.09%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.526969 Test loss=0.506241 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=83.11% sen=79.85%, spe=84.33%, auc=90.12%!
Fold[6] Avg_jsc=0.60%(±0.24509916146593175)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=2.103580951690674
[5/24] Train loss=2.0171632766723633
[10/24] Train loss=1.836207628250122
[15/24] Train loss=1.7902863025665283
[20/24] Train loss=1.6530557870864868
Test set avg_accuracy=55.20% avg_sensitivity=55.92%, avg_specificity=54.92% avg_auc=57.39%
Best model saved!! Metric=57.38896763780148!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=1.835763 Test loss=0.770147 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.625074863433838
[5/24] Train loss=1.5643587112426758
[10/24] Train loss=1.5450916290283203
[15/24] Train loss=1.5113238096237183
[20/24] Train loss=1.450110912322998
Test set avg_accuracy=59.96% avg_sensitivity=66.01%, avg_specificity=57.65% avg_auc=66.08%
Best model saved!! Metric=66.0812531025672!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=1.536858 Test loss=0.695404 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.452153205871582
[5/24] Train loss=1.4228078126907349
[10/24] Train loss=1.4235197305679321
[15/24] Train loss=1.3732540607452393
[20/24] Train loss=1.3262274265289307
Test set avg_accuracy=65.98% avg_sensitivity=68.18%, avg_specificity=65.14% avg_auc=72.31%
Best model saved!! Metric=72.3074550921286!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=1.409912 Test loss=0.627987 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.3235057592391968
[5/24] Train loss=1.3147494792938232
[10/24] Train loss=1.2966934442520142
[15/24] Train loss=1.2213284969329834
[20/24] Train loss=1.247239351272583
Test set avg_accuracy=68.72% avg_sensitivity=72.61%, avg_specificity=67.24% avg_auc=76.13%
Best model saved!! Metric=76.12868140564733!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=1.307747 Test loss=0.598740 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.2606478929519653
[5/24] Train loss=1.2288928031921387
[10/24] Train loss=1.2551060914993286
[15/24] Train loss=1.178212285041809
[20/24] Train loss=1.1704976558685303
Test set avg_accuracy=70.65% avg_sensitivity=75.25%, avg_specificity=68.90% avg_auc=78.72%
Best model saved!! Metric=78.72237458885816!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=1.245817 Test loss=0.573672 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1907987594604492
[5/24] Train loss=1.1702347993850708
[10/24] Train loss=1.2018507719039917
[15/24] Train loss=1.1118285655975342
[20/24] Train loss=1.1218550205230713
Test set avg_accuracy=72.12% avg_sensitivity=78.41%, avg_specificity=69.72% avg_auc=80.68%
Best model saved!! Metric=80.68418514043216!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=1.193912 Test loss=0.556106 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.133558988571167
[5/24] Train loss=1.1201555728912354
[10/24] Train loss=1.1653703451156616
[15/24] Train loss=1.0591821670532227
[20/24] Train loss=1.0629165172576904
Test set avg_accuracy=73.92% avg_sensitivity=80.34%, avg_specificity=71.47% avg_auc=82.27%
Best model saved!! Metric=82.27100753402765!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=1.142798 Test loss=0.535152 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.0997834205627441
[5/24] Train loss=1.0706086158752441
[10/24] Train loss=1.1283882856369019
[15/24] Train loss=1.0041717290878296
[20/24] Train loss=1.0095198154449463
Test set avg_accuracy=74.60% avg_sensitivity=81.66%, avg_specificity=71.90% avg_auc=83.64%
Best model saved!! Metric=83.64269315683399!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=1.098875 Test loss=0.517998 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.051690936088562
[5/24] Train loss=1.0500797033309937
[10/24] Train loss=1.095655918121338
[15/24] Train loss=0.9623327255249023
[20/24] Train loss=0.9692955613136292
Test set avg_accuracy=75.46% avg_sensitivity=82.56%, avg_specificity=72.75% avg_auc=84.89%
Best model saved!! Metric=84.88909718972822!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=1.060507 Test loss=0.503995 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.001765489578247
[5/24] Train loss=1.0188909769058228
[10/24] Train loss=1.061020851135254
[15/24] Train loss=0.9359117746353149
[20/24] Train loss=0.9278417229652405
Test set avg_accuracy=76.20% avg_sensitivity=82.93%, avg_specificity=73.63% avg_auc=85.94%
Best model saved!! Metric=85.93673336958243!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=1.028232 Test loss=0.488726 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.9604838490486145
[5/24] Train loss=0.9702212810516357
[10/24] Train loss=1.041827917098999
[15/24] Train loss=0.9001330733299255
[20/24] Train loss=0.8937535285949707
Test set avg_accuracy=77.04% avg_sensitivity=82.37%, avg_specificity=75.01% avg_auc=86.85%
Best model saved!! Metric=86.84720989252574!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.994648 Test loss=0.470760 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.9329739212989807
[5/24] Train loss=0.9399466514587402
[10/24] Train loss=0.9800732731819153
[15/24] Train loss=0.8859426379203796
[20/24] Train loss=0.8730893135070801
Test set avg_accuracy=78.09% avg_sensitivity=82.27%, avg_specificity=76.49% avg_auc=87.61%
Best model saved!! Metric=87.60822462633281!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.965792 Test loss=0.453089 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.9030370712280273
[5/24] Train loss=0.9273319244384766
[10/24] Train loss=0.9858574867248535
[15/24] Train loss=0.8664230704307556
[20/24] Train loss=0.8547766804695129
Test set avg_accuracy=78.62% avg_sensitivity=83.22%, avg_specificity=76.87% avg_auc=88.20%
Best model saved!! Metric=88.20361644521557!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.942947 Test loss=0.445866 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.8849440813064575
[5/24] Train loss=0.9023078083992004
[10/24] Train loss=0.946541965007782
[15/24] Train loss=0.8557186722755432
[20/24] Train loss=0.8470141291618347
Test set avg_accuracy=78.84% avg_sensitivity=83.64%, avg_specificity=77.01% avg_auc=88.71%
Best model saved!! Metric=88.71323259070184!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.925205 Test loss=0.441250 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.8570799827575684
[5/24] Train loss=0.9010289907455444
[10/24] Train loss=0.9372574090957642
[15/24] Train loss=0.8310471177101135
[20/24] Train loss=0.84595787525177
Test set avg_accuracy=79.19% avg_sensitivity=84.35%, avg_specificity=77.23% avg_auc=89.11%
Best model saved!! Metric=89.10598484102516!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.907161 Test loss=0.437531 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.8467798829078674
[5/24] Train loss=0.8749954104423523
[10/24] Train loss=0.9248706102371216
[15/24] Train loss=0.8039423823356628
[20/24] Train loss=0.817939281463623
Test set avg_accuracy=78.97% avg_sensitivity=85.67%, avg_specificity=76.42% avg_auc=89.42%
Best model saved!! Metric=89.41580689562288!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.892420 Test loss=0.443586 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.8477433919906616
[5/24] Train loss=0.8639819622039795
[10/24] Train loss=0.8938910365104675
[15/24] Train loss=0.7922387719154358
[20/24] Train loss=0.8027467727661133
Test set avg_accuracy=79.08% avg_sensitivity=86.42%, avg_specificity=76.27% avg_auc=89.73%
Best model saved!! Metric=89.72685025807337!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.878434 Test loss=0.443063 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.823274552822113
[5/24] Train loss=0.8636061549186707
[10/24] Train loss=0.8911658525466919
[15/24] Train loss=0.7807866930961609
[20/24] Train loss=0.7734916806221008
Test set avg_accuracy=79.27% avg_sensitivity=86.85%, avg_specificity=76.38% avg_auc=89.96%
Best model saved!! Metric=89.95501431262547!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.867842 Test loss=0.441650 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.8215882182121277
[5/24] Train loss=0.855674147605896
[10/24] Train loss=0.8895449638366699
[15/24] Train loss=0.7685756087303162
[20/24] Train loss=0.762032151222229
Test set avg_accuracy=80.13% avg_sensitivity=85.48%, avg_specificity=78.09% avg_auc=90.21%
Best model saved!! Metric=90.20812612446196!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.853377 Test loss=0.420282 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.7956141829490662
[5/24] Train loss=0.8011062145233154
[10/24] Train loss=0.8812651634216309
[15/24] Train loss=0.7470590472221375
[20/24] Train loss=0.7584196925163269
Test set avg_accuracy=80.36% avg_sensitivity=85.48%, avg_specificity=78.41% avg_auc=90.40%
Best model saved!! Metric=90.39838298840293!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.840823 Test loss=0.415000 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.788509726524353
[5/24] Train loss=0.8044148087501526
[10/24] Train loss=0.8789297938346863
[15/24] Train loss=0.741083562374115
[20/24] Train loss=0.7454596757888794
Test set avg_accuracy=80.42% avg_sensitivity=86.14%, avg_specificity=78.23% avg_auc=90.60%
Best model saved!! Metric=90.60217601437887!!
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.833659 Test loss=0.414507 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.7741565704345703
[5/24] Train loss=0.7824071049690247
[10/24] Train loss=0.8575550317764282
[15/24] Train loss=0.7221397161483765
[20/24] Train loss=0.7344529032707214
Test set avg_accuracy=80.68% avg_sensitivity=86.56%, avg_specificity=78.43% avg_auc=90.81%
Best model saved!! Metric=90.80780100213398!!
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.823937 Test loss=0.413207 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.7631945610046387
[5/24] Train loss=0.7752065658569336
[10/24] Train loss=0.8608384728431702
[15/24] Train loss=0.7203593254089355
[20/24] Train loss=0.7201821208000183
Test set avg_accuracy=80.99% avg_sensitivity=86.28%, avg_specificity=78.97% avg_auc=90.90%
Best model saved!! Metric=90.9021682370226!!
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.817011 Test loss=0.406036 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.7570047974586487
[5/24] Train loss=0.7579481601715088
[10/24] Train loss=0.8531943559646606
[15/24] Train loss=0.7037145495414734
[20/24] Train loss=0.6954169273376465
Test set avg_accuracy=81.39% avg_sensitivity=85.67%, avg_specificity=79.76% avg_auc=91.03%
Best model saved!! Metric=91.0289255739235!!
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.804886 Test loss=0.395190 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.7395195364952087
[5/24] Train loss=0.7462601661682129
[10/24] Train loss=0.8452976942062378
[15/24] Train loss=0.7086427807807922
[20/24] Train loss=0.6868796348571777
Test set avg_accuracy=81.81% avg_sensitivity=84.77%, avg_specificity=80.68% avg_auc=91.09%
Best model saved!! Metric=91.09317145576247!!
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.798219 Test loss=0.387285 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.7390718460083008
[5/24] Train loss=0.7220144271850586
[10/24] Train loss=0.8423213362693787
[15/24] Train loss=0.6811701059341431
[20/24] Train loss=0.657469630241394
Test set avg_accuracy=82.45% avg_sensitivity=83.31%, avg_specificity=82.12% avg_auc=91.17%
Best model saved!! Metric=91.1740194912252!!
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.788729 Test loss=0.375790 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.7192642688751221
[5/24] Train loss=0.7240760326385498
[10/24] Train loss=0.8265622854232788
[15/24] Train loss=0.6711433529853821
[20/24] Train loss=0.654213011264801
Test set avg_accuracy=83.18% avg_sensitivity=81.90%, avg_specificity=83.67% avg_auc=91.24%
Best model saved!! Metric=91.23796428675325!!
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.775569 Test loss=0.365124 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.7388603687286377
[5/24] Train loss=0.7113363742828369
[10/24] Train loss=0.8276086449623108
[15/24] Train loss=0.6671316027641296
[20/24] Train loss=0.6507270336151123
Test set avg_accuracy=83.59% avg_sensitivity=80.76%, avg_specificity=84.67% avg_auc=91.23%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.766774 Test loss=0.361157 Current lr=[0.000210185142098938]

[0/24] Train loss=0.7217098474502563
[5/24] Train loss=0.7058455944061279
[10/24] Train loss=0.8179590106010437
[15/24] Train loss=0.6595830917358398
[20/24] Train loss=0.6527198553085327
Test set avg_accuracy=83.29% avg_sensitivity=80.86%, avg_specificity=84.22% avg_auc=91.23%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.755460 Test loss=0.362833 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.721058189868927
[5/24] Train loss=0.7128796577453613
[10/24] Train loss=0.7925630211830139
[15/24] Train loss=0.6522760391235352
[20/24] Train loss=0.6418328881263733
Test set avg_accuracy=83.26% avg_sensitivity=81.33%, avg_specificity=83.99% avg_auc=91.27%
Best model saved!! Metric=91.26591866649467!!
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.748484 Test loss=0.362953 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.7023990750312805
[5/24] Train loss=0.7214645743370056
[10/24] Train loss=0.7920710444450378
[15/24] Train loss=0.6470109820365906
[20/24] Train loss=0.6331005692481995
Test set avg_accuracy=83.39% avg_sensitivity=81.75%, avg_specificity=84.01% avg_auc=91.29%
Best model saved!! Metric=91.29315213535077!!
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.738659 Test loss=0.363478 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.6991852521896362
[5/24] Train loss=0.6875134110450745
[10/24] Train loss=0.7871243953704834
[15/24] Train loss=0.647433340549469
[20/24] Train loss=0.6195825338363647
Test set avg_accuracy=83.78% avg_sensitivity=80.25%, avg_specificity=85.12% avg_auc=91.21%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.728554 Test loss=0.358398 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.6960023641586304
[5/24] Train loss=0.6865417957305908
[10/24] Train loss=0.784195601940155
[15/24] Train loss=0.6372678279876709
[20/24] Train loss=0.6203246116638184
Test set avg_accuracy=83.80% avg_sensitivity=79.96%, avg_specificity=85.27% avg_auc=91.26%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.722374 Test loss=0.355735 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.6821354031562805
[5/24] Train loss=0.6670451760292053
[10/24] Train loss=0.7667596936225891
[15/24] Train loss=0.6282360553741455
[20/24] Train loss=0.6176216006278992
Test set avg_accuracy=83.48% avg_sensitivity=80.81%, avg_specificity=84.49% avg_auc=91.23%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.712216 Test loss=0.361811 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.6854376196861267
[5/24] Train loss=0.6524261236190796
[10/24] Train loss=0.7385657429695129
[15/24] Train loss=0.6181448101997375
[20/24] Train loss=0.5983886122703552
Test set avg_accuracy=83.92% avg_sensitivity=79.68%, avg_specificity=85.54% avg_auc=91.19%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.698897 Test loss=0.356296 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.6739092469215393
[5/24] Train loss=0.6444600224494934
[10/24] Train loss=0.7340991497039795
[15/24] Train loss=0.6054987907409668
[20/24] Train loss=0.6027201414108276
Test set avg_accuracy=84.13% avg_sensitivity=79.54%, avg_specificity=85.88% avg_auc=91.19%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.690880 Test loss=0.354957 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.6705837845802307
[5/24] Train loss=0.6361079216003418
[10/24] Train loss=0.7371315360069275
[15/24] Train loss=0.5893113017082214
[20/24] Train loss=0.5825995206832886
Test set avg_accuracy=83.96% avg_sensitivity=79.35%, avg_specificity=85.72% avg_auc=91.13%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.678586 Test loss=0.356122 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.6554246544837952
[5/24] Train loss=0.6134096384048462
[10/24] Train loss=0.7122861742973328
[15/24] Train loss=0.5844670534133911
[20/24] Train loss=0.5744677782058716
Test set avg_accuracy=83.87% avg_sensitivity=79.21%, avg_specificity=85.64% avg_auc=91.16%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.667508 Test loss=0.356602 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.6379703283309937
[5/24] Train loss=0.5967459678649902
[10/24] Train loss=0.6982966661453247
[15/24] Train loss=0.57596755027771
[20/24] Train loss=0.5688376426696777
Test set avg_accuracy=84.10% avg_sensitivity=78.50%, avg_specificity=86.24% avg_auc=91.10%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.657419 Test loss=0.354008 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.6411051750183105
[5/24] Train loss=0.6016688346862793
[10/24] Train loss=0.6951246857643127
[15/24] Train loss=0.560522735118866
[20/24] Train loss=0.5675721764564514
Test set avg_accuracy=83.91% avg_sensitivity=79.07%, avg_specificity=85.75% avg_auc=91.06%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.649058 Test loss=0.356968 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.6231079697608948
[5/24] Train loss=0.5817282199859619
[10/24] Train loss=0.6809626817703247
[15/24] Train loss=0.5537025928497314
[20/24] Train loss=0.55155348777771
Test set avg_accuracy=83.12% avg_sensitivity=79.26%, avg_specificity=84.60% avg_auc=90.95%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.633294 Test loss=0.364665 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.6122782826423645
[5/24] Train loss=0.5654909014701843
[10/24] Train loss=0.6684179306030273
[15/24] Train loss=0.5589509606361389
[20/24] Train loss=0.5353807806968689
Test set avg_accuracy=83.49% avg_sensitivity=78.36%, avg_specificity=85.45% avg_auc=90.88%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.624611 Test loss=0.361844 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.5969281196594238
[5/24] Train loss=0.5513291358947754
[10/24] Train loss=0.6577163338661194
[15/24] Train loss=0.5354248285293579
[20/24] Train loss=0.5374972224235535
Test set avg_accuracy=83.97% avg_sensitivity=77.18%, avg_specificity=86.56% avg_auc=90.91%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.615364 Test loss=0.353839 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.6010127067565918
[5/24] Train loss=0.5500308275222778
[10/24] Train loss=0.6575299501419067
[15/24] Train loss=0.5343629717826843
[20/24] Train loss=0.5313116908073425
Test set avg_accuracy=84.30% avg_sensitivity=75.67%, avg_specificity=87.59% avg_auc=90.77%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.605349 Test loss=0.349247 Current lr=[0.00029967723776099]

[0/24] Train loss=0.6197012662887573
[5/24] Train loss=0.5297198295593262
[10/24] Train loss=0.6601775884628296
[15/24] Train loss=0.5249850749969482
[20/24] Train loss=0.5140714645385742
Test set avg_accuracy=83.89% avg_sensitivity=77.51%, avg_specificity=86.33% avg_auc=90.79%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.593106 Test loss=0.356674 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.5673273801803589
[5/24] Train loss=0.5340221524238586
[10/24] Train loss=0.6360234022140503
[15/24] Train loss=0.5115419030189514
[20/24] Train loss=0.5159976482391357
Test set avg_accuracy=83.28% avg_sensitivity=78.31%, avg_specificity=85.18% avg_auc=90.65%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.581047 Test loss=0.364877 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.5636407732963562
[5/24] Train loss=0.5040668845176697
[10/24] Train loss=0.6260008215904236
[15/24] Train loss=0.5061001777648926
[20/24] Train loss=0.5117173790931702
Test set avg_accuracy=83.16% avg_sensitivity=80.39%, avg_specificity=84.22% avg_auc=90.68%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.568935 Test loss=0.374107 Current lr=[0.000299720220882401]

[0/24] Train loss=0.547614336013794
[5/24] Train loss=0.5006203651428223
[10/24] Train loss=0.6153221726417542
[15/24] Train loss=0.4925079643726349
[20/24] Train loss=0.5066809058189392
Test set avg_accuracy=83.29% avg_sensitivity=79.54%, avg_specificity=84.73% avg_auc=90.63%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.559909 Test loss=0.369226 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.5335010290145874
[5/24] Train loss=0.5024391412734985
[10/24] Train loss=0.6039187908172607
[15/24] Train loss=0.4958791434764862
[20/24] Train loss=0.4913870692253113
Test set avg_accuracy=82.90% avg_sensitivity=79.96%, avg_specificity=84.03% avg_auc=90.62%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.550175 Test loss=0.373164 Current lr=[0.000298904600941902]

[0/24] Train loss=0.5230773091316223
[5/24] Train loss=0.48526135087013245
[10/24] Train loss=0.6022704243659973
[15/24] Train loss=0.48909100890159607
[20/24] Train loss=0.4792574644088745
Test set avg_accuracy=82.99% avg_sensitivity=79.73%, avg_specificity=84.24% avg_auc=90.47%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.541242 Test loss=0.374753 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.5220167636871338
[5/24] Train loss=0.4799727499485016
[10/24] Train loss=0.5918111205101013
[15/24] Train loss=0.49171072244644165
[20/24] Train loss=0.48453110456466675
Test set avg_accuracy=83.49% avg_sensitivity=78.55%, avg_specificity=85.38% avg_auc=90.38%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.536547 Test loss=0.370736 Current lr=[0.000297555943323901]

[0/24] Train loss=0.5278121829032898
[5/24] Train loss=0.46894553303718567
[10/24] Train loss=0.5872635245323181
[15/24] Train loss=0.46773794293403625
[20/24] Train loss=0.4800591468811035
Test set avg_accuracy=84.04% avg_sensitivity=76.28%, avg_specificity=86.99% avg_auc=90.53%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.532866 Test loss=0.358812 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.5140690207481384
[5/24] Train loss=0.46461644768714905
[10/24] Train loss=0.586703896522522
[15/24] Train loss=0.47782638669013977
[20/24] Train loss=0.48329901695251465
Test set avg_accuracy=84.45% avg_sensitivity=72.18%, avg_specificity=89.13% avg_auc=90.44%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.526989 Test loss=0.349583 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.5206985473632812
[5/24] Train loss=0.48971474170684814
[10/24] Train loss=0.6041243672370911
[15/24] Train loss=0.46293744444847107
[20/24] Train loss=0.4597162902355194
Test set avg_accuracy=83.95% avg_sensitivity=76.61%, avg_specificity=86.74% avg_auc=90.48%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.520997 Test loss=0.360593 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.5110383033752441
[5/24] Train loss=0.4671083688735962
[10/24] Train loss=0.5698474049568176
[15/24] Train loss=0.4582054018974304
[20/24] Train loss=0.455070436000824
Test set avg_accuracy=83.87% avg_sensitivity=77.04%, avg_specificity=86.47% avg_auc=90.44%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.510869 Test loss=0.363266 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.48818421363830566
[5/24] Train loss=0.4503398835659027
[10/24] Train loss=0.5676008462905884
[15/24] Train loss=0.44192513823509216
[20/24] Train loss=0.44530534744262695
Test set avg_accuracy=83.22% avg_sensitivity=78.74%, avg_specificity=84.93% avg_auc=90.43%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.504969 Test loss=0.373988 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.4828788638114929
[5/24] Train loss=0.45289379358291626
[10/24] Train loss=0.5627702474594116
[15/24] Train loss=0.4404267966747284
[20/24] Train loss=0.4514693319797516
Test set avg_accuracy=83.63% avg_sensitivity=77.23%, avg_specificity=86.08% avg_auc=90.33%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.498447 Test loss=0.368343 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.481341153383255
[5/24] Train loss=0.43895095586776733
[10/24] Train loss=0.5445294976234436
[15/24] Train loss=0.44422125816345215
[20/24] Train loss=0.45548954606056213
Test set avg_accuracy=83.93% avg_sensitivity=74.40%, avg_specificity=87.57% avg_auc=90.17%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.493389 Test loss=0.362414 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.5002920031547546
[5/24] Train loss=0.4339863657951355
[10/24] Train loss=0.5178393125534058
[15/24] Train loss=0.41704249382019043
[20/24] Train loss=0.4469783902168274
Test set avg_accuracy=84.04% avg_sensitivity=73.83%, avg_specificity=87.93% avg_auc=90.09%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.483397 Test loss=0.362199 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.48092857003211975
[5/24] Train loss=0.44999149441719055
[10/24] Train loss=0.519707202911377
[15/24] Train loss=0.42153581976890564
[20/24] Train loss=0.44692355394363403
Test set avg_accuracy=84.22% avg_sensitivity=71.85%, avg_specificity=88.94% avg_auc=89.95%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.479894 Test loss=0.361109 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.48036614060401917
[5/24] Train loss=0.43976154923439026
[10/24] Train loss=0.5059033632278442
[15/24] Train loss=0.44361618161201477
[20/24] Train loss=0.4599044919013977
Test set avg_accuracy=84.54% avg_sensitivity=66.67%, avg_specificity=91.37% avg_auc=89.81%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.485888 Test loss=0.358655 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.5168718695640564
[5/24] Train loss=0.42182886600494385
[10/24] Train loss=0.529686450958252
[15/24] Train loss=0.4619503915309906
[20/24] Train loss=0.4803190231323242
Test set avg_accuracy=83.12% avg_sensitivity=79.68%, avg_specificity=84.44% avg_auc=90.52%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.501516 Test loss=0.373019 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.4487071633338928
[5/24] Train loss=0.439926415681839
[10/24] Train loss=0.5241091251373291
[15/24] Train loss=0.4360440969467163
[20/24] Train loss=0.4463225305080414
Test set avg_accuracy=82.67% avg_sensitivity=81.19%, avg_specificity=83.23% avg_auc=90.51%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.489288 Test loss=0.385026 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.44655469059944153
[5/24] Train loss=0.4298108220100403
[10/24] Train loss=0.5151050686836243
[15/24] Train loss=0.43130743503570557
[20/24] Train loss=0.4356997609138489
Test set avg_accuracy=82.42% avg_sensitivity=81.52%, avg_specificity=82.77% avg_auc=90.45%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.472018 Test loss=0.392711 Current lr=[0.000276307469034998]

[0/24] Train loss=0.4445916414260864
[5/24] Train loss=0.4230465292930603
[10/24] Train loss=0.5037866830825806
[15/24] Train loss=0.4242532253265381
[20/24] Train loss=0.4356610178947449
Test set avg_accuracy=82.43% avg_sensitivity=81.71%, avg_specificity=82.71% avg_auc=90.47%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.463897 Test loss=0.393587 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.4501294195652008
[5/24] Train loss=0.4069063663482666
[10/24] Train loss=0.47950905561447144
[15/24] Train loss=0.430534690618515
[20/24] Train loss=0.44080328941345215
Test set avg_accuracy=81.74% avg_sensitivity=83.22%, avg_specificity=81.18% avg_auc=90.44%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.457583 Test loss=0.408059 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.447729229927063
[5/24] Train loss=0.40989476442337036
[10/24] Train loss=0.4895213842391968
[15/24] Train loss=0.4390103220939636
[20/24] Train loss=0.4621700942516327
Test set avg_accuracy=80.66% avg_sensitivity=86.42%, avg_specificity=78.47% avg_auc=90.44%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.462418 Test loss=0.439229 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.48153969645500183
[5/24] Train loss=0.4490521550178528
[10/24] Train loss=0.4734840393066406
[15/24] Train loss=0.4241253137588501
[20/24] Train loss=0.47372645139694214
Test set avg_accuracy=80.48% avg_sensitivity=86.56%, avg_specificity=78.16% avg_auc=90.40%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.473295 Test loss=0.442090 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.48586180806159973
[5/24] Train loss=0.4739224314689636
[10/24] Train loss=0.5645487308502197
[15/24] Train loss=0.4288093149662018
[20/24] Train loss=0.40408632159233093
Test set avg_accuracy=83.16% avg_sensitivity=77.09%, avg_specificity=85.48% avg_auc=90.05%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.473085 Test loss=0.375069 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.44799375534057617
[5/24] Train loss=0.4031420648097992
[10/24] Train loss=0.4992137551307678
[15/24] Train loss=0.379812628030777
[20/24] Train loss=0.3986642360687256
Test set avg_accuracy=82.32% avg_sensitivity=80.72%, avg_specificity=82.93% avg_auc=90.05%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.441088 Test loss=0.400859 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.444138765335083
[5/24] Train loss=0.3954157829284668
[10/24] Train loss=0.4894866645336151
[15/24] Train loss=0.38323572278022766
[20/24] Train loss=0.4091525077819824
Test set avg_accuracy=82.12% avg_sensitivity=81.47%, avg_specificity=82.37% avg_auc=90.04%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.432283 Test loss=0.408956 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.42769762873649597
[5/24] Train loss=0.39257514476776123
[10/24] Train loss=0.4731657803058624
[15/24] Train loss=0.3726850748062134
[20/24] Train loss=0.4057895243167877
Test set avg_accuracy=82.40% avg_sensitivity=80.76%, avg_specificity=83.02% avg_auc=90.02%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.426259 Test loss=0.404239 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4225268065929413
[5/24] Train loss=0.36590686440467834
[10/24] Train loss=0.4684029519557953
[15/24] Train loss=0.37097102403640747
[20/24] Train loss=0.3881700038909912
Test set avg_accuracy=82.34% avg_sensitivity=79.77%, avg_specificity=83.32% avg_auc=89.91%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.423253 Test loss=0.401957 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.41251450777053833
[5/24] Train loss=0.3678068220615387
[10/24] Train loss=0.4615080952644348
[15/24] Train loss=0.3675668239593506
[20/24] Train loss=0.38317549228668213
Test set avg_accuracy=82.45% avg_sensitivity=79.26%, avg_specificity=83.67% avg_auc=89.86%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.414600 Test loss=0.401193 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.40647825598716736
[5/24] Train loss=0.3717760145664215
[10/24] Train loss=0.44747188687324524
[15/24] Train loss=0.3582571744918823
[20/24] Train loss=0.37242451310157776
Test set avg_accuracy=82.53% avg_sensitivity=79.63%, avg_specificity=83.63% avg_auc=89.90%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.409479 Test loss=0.402490 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.4209710359573364
[5/24] Train loss=0.372496634721756
[10/24] Train loss=0.44821444153785706
[15/24] Train loss=0.3614938259124756
[20/24] Train loss=0.3776266276836395
Test set avg_accuracy=82.76% avg_sensitivity=78.69%, avg_specificity=84.31% avg_auc=89.72%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.405187 Test loss=0.400278 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.410356342792511
[5/24] Train loss=0.36258479952812195
[10/24] Train loss=0.4612862169742584
[15/24] Train loss=0.35984766483306885
[20/24] Train loss=0.38051819801330566
Test set avg_accuracy=82.53% avg_sensitivity=78.64%, avg_specificity=84.01% avg_auc=89.70%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.406148 Test loss=0.401522 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.40476754307746887
[5/24] Train loss=0.35525691509246826
[10/24] Train loss=0.4451735317707062
[15/24] Train loss=0.3515808880329132
[20/24] Train loss=0.3682556450366974
Test set avg_accuracy=82.58% avg_sensitivity=78.88%, avg_specificity=83.99% avg_auc=89.72%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.398954 Test loss=0.404831 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.40837806463241577
[5/24] Train loss=0.366498202085495
[10/24] Train loss=0.44919443130493164
[15/24] Train loss=0.3462204039096832
[20/24] Train loss=0.36865803599357605
Test set avg_accuracy=82.50% avg_sensitivity=78.31%, avg_specificity=84.10% avg_auc=89.75%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.397778 Test loss=0.402927 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.396016001701355
[5/24] Train loss=0.3654334247112274
[10/24] Train loss=0.43808653950691223
[15/24] Train loss=0.3512045741081238
[20/24] Train loss=0.36621543765068054
Test set avg_accuracy=82.80% avg_sensitivity=76.38%, avg_specificity=85.25% avg_auc=89.60%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.396554 Test loss=0.396260 Current lr=[0.000224838296036774]

[0/24] Train loss=0.40502771735191345
[5/24] Train loss=0.35244861245155334
[10/24] Train loss=0.434190958738327
[15/24] Train loss=0.34299883246421814
[20/24] Train loss=0.3576784133911133
Test set avg_accuracy=82.68% avg_sensitivity=76.00%, avg_specificity=85.23% avg_auc=89.56%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.392746 Test loss=0.396326 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3886066675186157
[5/24] Train loss=0.35475194454193115
[10/24] Train loss=0.4416293203830719
[15/24] Train loss=0.3460521996021271
[20/24] Train loss=0.3568935692310333
Test set avg_accuracy=82.89% avg_sensitivity=76.90%, avg_specificity=85.18% avg_auc=89.66%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.390888 Test loss=0.397576 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3737107813358307
[5/24] Train loss=0.3518931269645691
[10/24] Train loss=0.42611536383628845
[15/24] Train loss=0.3441079258918762
[20/24] Train loss=0.3616248071193695
Test set avg_accuracy=83.01% avg_sensitivity=76.52%, avg_specificity=85.48% avg_auc=89.57%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.386684 Test loss=0.398065 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3774511516094208
[5/24] Train loss=0.34341326355934143
[10/24] Train loss=0.43152886629104614
[15/24] Train loss=0.3429880142211914
[20/24] Train loss=0.3526912331581116
Test set avg_accuracy=82.93% avg_sensitivity=77.42%, avg_specificity=85.03% avg_auc=89.69%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.385652 Test loss=0.400879 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.38713985681533813
[5/24] Train loss=0.34682339429855347
[10/24] Train loss=0.4243525266647339
[15/24] Train loss=0.3460499942302704
[20/24] Train loss=0.3651038110256195
Test set avg_accuracy=82.40% avg_sensitivity=78.69%, avg_specificity=83.81% avg_auc=89.64%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.382601 Test loss=0.410835 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3852733075618744
[5/24] Train loss=0.34541240334510803
[10/24] Train loss=0.41528069972991943
[15/24] Train loss=0.33701059222221375
[20/24] Train loss=0.3539031445980072
Test set avg_accuracy=82.70% avg_sensitivity=78.12%, avg_specificity=84.44% avg_auc=89.63%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.382225 Test loss=0.407065 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.37145134806632996
[5/24] Train loss=0.33878251910209656
[10/24] Train loss=0.40344882011413574
[15/24] Train loss=0.3278782069683075
[20/24] Train loss=0.3485097289085388
Test set avg_accuracy=82.06% avg_sensitivity=79.77%, avg_specificity=82.93% avg_auc=89.63%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.379455 Test loss=0.423025 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3886851370334625
[5/24] Train loss=0.3379572927951813
[10/24] Train loss=0.42403292655944824
[15/24] Train loss=0.3326025605201721
[20/24] Train loss=0.35127919912338257
Test set avg_accuracy=82.49% avg_sensitivity=79.54%, avg_specificity=83.61% avg_auc=89.75%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.379277 Test loss=0.415370 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.37860336899757385
[5/24] Train loss=0.34742438793182373
[10/24] Train loss=0.4346637427806854
[15/24] Train loss=0.32202965021133423
[20/24] Train loss=0.33650392293930054
Test set avg_accuracy=83.11% avg_sensitivity=75.95%, avg_specificity=85.84% avg_auc=89.56%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.380101 Test loss=0.397205 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.379220187664032
[5/24] Train loss=0.3618781864643097
[10/24] Train loss=0.4092661738395691
[15/24] Train loss=0.33396363258361816
[20/24] Train loss=0.3532443642616272
Test set avg_accuracy=82.76% avg_sensitivity=77.93%, avg_specificity=84.60% avg_auc=89.57%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.380484 Test loss=0.407391 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.37899911403656006
[5/24] Train loss=0.345974862575531
[10/24] Train loss=0.4031902551651001
[15/24] Train loss=0.3323313891887665
[20/24] Train loss=0.3630608320236206
Test set avg_accuracy=82.20% avg_sensitivity=79.82%, avg_specificity=83.11% avg_auc=89.73%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.374488 Test loss=0.422365 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3874499201774597
[5/24] Train loss=0.34113186597824097
[10/24] Train loss=0.41010782122612
[15/24] Train loss=0.3259485960006714
[20/24] Train loss=0.3526931405067444
Test set avg_accuracy=81.99% avg_sensitivity=79.77%, avg_specificity=82.84% avg_auc=89.54%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.371557 Test loss=0.426687 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3751213848590851
[5/24] Train loss=0.33990156650543213
[10/24] Train loss=0.395549476146698
[15/24] Train loss=0.33903247117996216
[20/24] Train loss=0.35600072145462036
Test set avg_accuracy=81.93% avg_sensitivity=80.20%, avg_specificity=82.59% avg_auc=89.58%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.371549 Test loss=0.431657 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3785291314125061
[5/24] Train loss=0.34474387764930725
[10/24] Train loss=0.40336519479751587
[15/24] Train loss=0.32284727692604065
[20/24] Train loss=0.35054826736450195
Test set avg_accuracy=81.58% avg_sensitivity=81.38%, avg_specificity=81.65% avg_auc=89.66%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.374650 Test loss=0.438703 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.38270220160484314
[5/24] Train loss=0.3331417441368103
[10/24] Train loss=0.4254281222820282
[15/24] Train loss=0.3161712884902954
[20/24] Train loss=0.35607796907424927
Test set avg_accuracy=82.32% avg_sensitivity=79.44%, avg_specificity=83.41% avg_auc=89.74%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.385219 Test loss=0.416299 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.36448124051094055
[5/24] Train loss=0.3588726818561554
[10/24] Train loss=0.47238320112228394
[15/24] Train loss=0.3585335910320282
[20/24] Train loss=0.3519635796546936
Test set avg_accuracy=83.59% avg_sensitivity=73.50%, avg_specificity=87.44% avg_auc=89.66%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.394951 Test loss=0.387077 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3901519775390625
[5/24] Train loss=0.31877535581588745
[10/24] Train loss=0.4003427028656006
[15/24] Train loss=0.3203442394733429
[20/24] Train loss=0.34747380018234253
Test set avg_accuracy=82.80% avg_sensitivity=78.45%, avg_specificity=84.46% avg_auc=89.72%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.378183 Test loss=0.411369 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3642292618751526
[5/24] Train loss=0.3182108998298645
[10/24] Train loss=0.39981499314308167
[15/24] Train loss=0.325914591550827
[20/24] Train loss=0.33429214358329773
Test set avg_accuracy=83.03% avg_sensitivity=76.94%, avg_specificity=85.36% avg_auc=89.67%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.370321 Test loss=0.406405 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.36724966764450073
[5/24] Train loss=0.32985952496528625
[10/24] Train loss=0.415681928396225
[15/24] Train loss=0.316675066947937
[20/24] Train loss=0.3389187157154083
Test set avg_accuracy=82.73% avg_sensitivity=77.98%, avg_specificity=84.55% avg_auc=89.68%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.373020 Test loss=0.414100 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3722578287124634
[5/24] Train loss=0.3291834592819214
[10/24] Train loss=0.4137990474700928
[15/24] Train loss=0.3174957036972046
[20/24] Train loss=0.34031131863594055
Test set avg_accuracy=82.47% avg_sensitivity=78.69%, avg_specificity=83.92% avg_auc=89.66%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.372807 Test loss=0.422386 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.37999510765075684
[5/24] Train loss=0.32780179381370544
[10/24] Train loss=0.41629865765571594
[15/24] Train loss=0.3394033908843994
[20/24] Train loss=0.3331335783004761
Test set avg_accuracy=82.41% avg_sensitivity=78.78%, avg_specificity=83.79% avg_auc=89.58%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.373796 Test loss=0.425583 Current lr=[0.000134135431043539]

[0/24] Train loss=0.38628435134887695
[5/24] Train loss=0.3333812952041626
[10/24] Train loss=0.40895000100135803
[15/24] Train loss=0.34395521879196167
[20/24] Train loss=0.3353038430213928
Test set avg_accuracy=82.20% avg_sensitivity=79.26%, avg_specificity=83.32% avg_auc=89.63%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.374682 Test loss=0.434002 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.37751853466033936
[5/24] Train loss=0.3260095715522766
[10/24] Train loss=0.4152774512767792
[15/24] Train loss=0.34257543087005615
[20/24] Train loss=0.34173718094825745
Test set avg_accuracy=82.20% avg_sensitivity=79.82%, avg_specificity=83.11% avg_auc=89.72%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.376043 Test loss=0.428114 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.36727073788642883
[5/24] Train loss=0.347370445728302
[10/24] Train loss=0.4176602363586426
[15/24] Train loss=0.3513188362121582
[20/24] Train loss=0.33800622820854187
Test set avg_accuracy=82.08% avg_sensitivity=80.43%, avg_specificity=82.71% avg_auc=89.77%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.379342 Test loss=0.428424 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.363543838262558
[5/24] Train loss=0.33743762969970703
[10/24] Train loss=0.4079798460006714
[15/24] Train loss=0.33364176750183105
[20/24] Train loss=0.36785265803337097
Test set avg_accuracy=81.72% avg_sensitivity=81.80%, avg_specificity=81.69% avg_auc=89.86%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.375949 Test loss=0.434279 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.38178032636642456
[5/24] Train loss=0.3398817479610443
[10/24] Train loss=0.42095062136650085
[15/24] Train loss=0.3415505290031433
[20/24] Train loss=0.39371174573898315
Test set avg_accuracy=82.01% avg_sensitivity=80.91%, avg_specificity=82.42% avg_auc=89.81%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.382229 Test loss=0.423418 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3773578107357025
[5/24] Train loss=0.32896938920021057
[10/24] Train loss=0.439809113740921
[15/24] Train loss=0.3561786711215973
[20/24] Train loss=0.3894977867603302
Test set avg_accuracy=83.26% avg_sensitivity=75.91%, avg_specificity=86.06% avg_auc=89.68%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.386177 Test loss=0.391602 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3802267909049988
[5/24] Train loss=0.3298812508583069
[10/24] Train loss=0.45626845955848694
[15/24] Train loss=0.3438475728034973
[20/24] Train loss=0.3398680090904236
Test set avg_accuracy=83.63% avg_sensitivity=70.25%, avg_specificity=88.74% avg_auc=89.40%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.382637 Test loss=0.383202 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.38406720757484436
[5/24] Train loss=0.32584869861602783
[10/24] Train loss=0.4097103476524353
[15/24] Train loss=0.3219362199306488
[20/24] Train loss=0.3308459222316742
Test set avg_accuracy=83.29% avg_sensitivity=74.16%, avg_specificity=86.78% avg_auc=89.46%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.363625 Test loss=0.392467 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3649695813655853
[5/24] Train loss=0.31139490008354187
[10/24] Train loss=0.3943786919116974
[15/24] Train loss=0.31773242354393005
[20/24] Train loss=0.33861079812049866
Test set avg_accuracy=83.22% avg_sensitivity=74.63%, avg_specificity=86.49% avg_auc=89.43%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.358058 Test loss=0.397012 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3555566668510437
[5/24] Train loss=0.3064005672931671
[10/24] Train loss=0.3928956985473633
[15/24] Train loss=0.3148431181907654
[20/24] Train loss=0.3380071520805359
Test set avg_accuracy=83.22% avg_sensitivity=74.78%, avg_specificity=86.44% avg_auc=89.42%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.353314 Test loss=0.398073 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3615320920944214
[5/24] Train loss=0.3091351091861725
[10/24] Train loss=0.3757424056529999
[15/24] Train loss=0.32550185918807983
[20/24] Train loss=0.33374762535095215
Test set avg_accuracy=83.29% avg_sensitivity=74.35%, avg_specificity=86.71% avg_auc=89.40%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.355103 Test loss=0.397278 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.35754552483558655
[5/24] Train loss=0.31363552808761597
[10/24] Train loss=0.388815313577652
[15/24] Train loss=0.30828431248664856
[20/24] Train loss=0.34232670068740845
Test set avg_accuracy=83.26% avg_sensitivity=74.73%, avg_specificity=86.51% avg_auc=89.30%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.352332 Test loss=0.400138 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.34766167402267456
[5/24] Train loss=0.3132506012916565
[10/24] Train loss=0.393359512090683
[15/24] Train loss=0.3166365325450897
[20/24] Train loss=0.33859783411026
Test set avg_accuracy=83.03% avg_sensitivity=74.78%, avg_specificity=86.18% avg_auc=89.30%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.352835 Test loss=0.401708 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3362301290035248
[5/24] Train loss=0.31698089838027954
[10/24] Train loss=0.3772832453250885
[15/24] Train loss=0.3123571574687958
[20/24] Train loss=0.3360932767391205
Test set avg_accuracy=82.89% avg_sensitivity=75.29%, avg_specificity=85.79% avg_auc=89.30%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.346513 Test loss=0.403759 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3381245732307434
[5/24] Train loss=0.30597689747810364
[10/24] Train loss=0.379584401845932
[15/24] Train loss=0.3108140528202057
[20/24] Train loss=0.3273230493068695
Test set avg_accuracy=83.18% avg_sensitivity=75.11%, avg_specificity=86.26% avg_auc=89.30%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.345765 Test loss=0.403008 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3564192056655884
[5/24] Train loss=0.30067315697669983
[10/24] Train loss=0.36524391174316406
[15/24] Train loss=0.3099779784679413
[20/24] Train loss=0.33939191699028015
Test set avg_accuracy=83.06% avg_sensitivity=75.25%, avg_specificity=86.04% avg_auc=89.29%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.344857 Test loss=0.405249 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3526405394077301
[5/24] Train loss=0.30600258708000183
[10/24] Train loss=0.38002392649650574
[15/24] Train loss=0.3068116307258606
[20/24] Train loss=0.3303619623184204
Test set avg_accuracy=82.98% avg_sensitivity=74.82%, avg_specificity=86.09% avg_auc=89.26%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.342224 Test loss=0.405176 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3426817059516907
[5/24] Train loss=0.31450721621513367
[10/24] Train loss=0.3782406151294708
[15/24] Train loss=0.29885274171829224
[20/24] Train loss=0.3335174024105072
Test set avg_accuracy=82.90% avg_sensitivity=75.06%, avg_specificity=85.90% avg_auc=89.20%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.342849 Test loss=0.406872 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3530023396015167
[5/24] Train loss=0.3069097697734833
[10/24] Train loss=0.3697725534439087
[15/24] Train loss=0.3102177381515503
[20/24] Train loss=0.31658244132995605
Test set avg_accuracy=83.05% avg_sensitivity=74.96%, avg_specificity=86.13% avg_auc=89.22%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.342136 Test loss=0.406119 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.33766818046569824
[5/24] Train loss=0.3087645471096039
[10/24] Train loss=0.3821226954460144
[15/24] Train loss=0.3129434883594513
[20/24] Train loss=0.3266192674636841
Test set avg_accuracy=82.88% avg_sensitivity=74.82%, avg_specificity=85.95% avg_auc=89.18%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.341641 Test loss=0.407646 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.327539324760437
[5/24] Train loss=0.3073147237300873
[10/24] Train loss=0.3745761811733246
[15/24] Train loss=0.30389875173568726
[20/24] Train loss=0.3223074674606323
Test set avg_accuracy=83.02% avg_sensitivity=74.59%, avg_specificity=86.24% avg_auc=89.16%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.342243 Test loss=0.406909 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3392010033130646
[5/24] Train loss=0.3007231056690216
[10/24] Train loss=0.365801066160202
[15/24] Train loss=0.31452155113220215
[20/24] Train loss=0.3245888352394104
Test set avg_accuracy=82.85% avg_sensitivity=74.92%, avg_specificity=85.88% avg_auc=89.13%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.340865 Test loss=0.409731 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.34088489413261414
[5/24] Train loss=0.3016188442707062
[10/24] Train loss=0.3731590807437897
[15/24] Train loss=0.3049127757549286
[20/24] Train loss=0.32331162691116333
Test set avg_accuracy=82.88% avg_sensitivity=75.11%, avg_specificity=85.84% avg_auc=89.17%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.340839 Test loss=0.409925 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.33150386810302734
[5/24] Train loss=0.30055487155914307
[10/24] Train loss=0.3660295009613037
[15/24] Train loss=0.30555981397628784
[20/24] Train loss=0.3244415819644928
Test set avg_accuracy=82.85% avg_sensitivity=75.06%, avg_specificity=85.82% avg_auc=89.17%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.339280 Test loss=0.410461 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.346912145614624
[5/24] Train loss=0.3008880019187927
[10/24] Train loss=0.3701697885990143
[15/24] Train loss=0.3055931329727173
[20/24] Train loss=0.31516754627227783
Test set avg_accuracy=82.83% avg_sensitivity=75.39%, avg_specificity=85.66% avg_auc=89.19%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.339874 Test loss=0.411580 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3411497175693512
[5/24] Train loss=0.30752691626548767
[10/24] Train loss=0.37264642119407654
[15/24] Train loss=0.30522292852401733
[20/24] Train loss=0.3255918323993683
Test set avg_accuracy=82.73% avg_sensitivity=75.81%, avg_specificity=85.38% avg_auc=89.22%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.341026 Test loss=0.413749 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3375706672668457
[5/24] Train loss=0.303477019071579
[10/24] Train loss=0.38358843326568604
[15/24] Train loss=0.30979907512664795
[20/24] Train loss=0.32309916615486145
Test set avg_accuracy=82.25% avg_sensitivity=76.90%, avg_specificity=84.30% avg_auc=89.24%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.341863 Test loss=0.420125 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3374103903770447
[5/24] Train loss=0.2992333769798279
[10/24] Train loss=0.37742388248443604
[15/24] Train loss=0.3038957118988037
[20/24] Train loss=0.32278934121131897
Test set avg_accuracy=82.20% avg_sensitivity=77.84%, avg_specificity=83.86% avg_auc=89.31%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.342972 Test loss=0.424678 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.33321115374565125
[5/24] Train loss=0.3118129074573517
[10/24] Train loss=0.3755226135253906
[15/24] Train loss=0.30173811316490173
[20/24] Train loss=0.3193395137786865
Test set avg_accuracy=81.64% avg_sensitivity=78.93%, avg_specificity=82.68% avg_auc=89.32%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.343364 Test loss=0.432796 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3439961373806
[5/24] Train loss=0.2992423176765442
[10/24] Train loss=0.3735649883747101
[15/24] Train loss=0.303665429353714
[20/24] Train loss=0.3295603096485138
Test set avg_accuracy=81.56% avg_sensitivity=79.30%, avg_specificity=82.42% avg_auc=89.36%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.343848 Test loss=0.434939 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.34505534172058105
[5/24] Train loss=0.3020375669002533
[10/24] Train loss=0.38214966654777527
[15/24] Train loss=0.30292773246765137
[20/24] Train loss=0.32416605949401855
Test set avg_accuracy=81.97% avg_sensitivity=78.55%, avg_specificity=83.27% avg_auc=89.35%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.342178 Test loss=0.428628 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3470440208911896
[5/24] Train loss=0.3053368926048279
[10/24] Train loss=0.35610565543174744
[15/24] Train loss=0.31520184874534607
[20/24] Train loss=0.3307070732116699
Test set avg_accuracy=82.40% avg_sensitivity=76.99%, avg_specificity=84.46% avg_auc=89.24%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.344087 Test loss=0.418552 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3293958306312561
[5/24] Train loss=0.3003106713294983
[10/24] Train loss=0.3655540645122528
[15/24] Train loss=0.2982332408428192
[20/24] Train loss=0.32670873403549194
Test set avg_accuracy=82.60% avg_sensitivity=75.67%, avg_specificity=85.25% avg_auc=89.19%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.339352 Test loss=0.414046 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.34123772382736206
[5/24] Train loss=0.3063496947288513
[10/24] Train loss=0.3602706789970398
[15/24] Train loss=0.30282092094421387
[20/24] Train loss=0.3348884880542755
Test set avg_accuracy=82.51% avg_sensitivity=76.14%, avg_specificity=84.94% avg_auc=89.19%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.338134 Test loss=0.416184 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.33876878023147583
[5/24] Train loss=0.3030140995979309
[10/24] Train loss=0.360860675573349
[15/24] Train loss=0.30531319975852966
[20/24] Train loss=0.33071380853652954
Test set avg_accuracy=82.54% avg_sensitivity=76.33%, avg_specificity=84.91% avg_auc=89.21%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.337400 Test loss=0.417024 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3405853509902954
[5/24] Train loss=0.30036160349845886
[10/24] Train loss=0.36635464429855347
[15/24] Train loss=0.29888224601745605
[20/24] Train loss=0.31895092129707336
Test set avg_accuracy=82.71% avg_sensitivity=75.72%, avg_specificity=85.38% avg_auc=89.16%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.336035 Test loss=0.413983 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3411051034927368
[5/24] Train loss=0.29888054728507996
[10/24] Train loss=0.3656548261642456
[15/24] Train loss=0.29995572566986084
[20/24] Train loss=0.33063700795173645
Test set avg_accuracy=82.54% avg_sensitivity=76.14%, avg_specificity=84.98% avg_auc=89.20%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.338616 Test loss=0.416717 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.34358134865760803
[5/24] Train loss=0.29203397035598755
[10/24] Train loss=0.36234238743782043
[15/24] Train loss=0.30162861943244934
[20/24] Train loss=0.3257902264595032
Test set avg_accuracy=82.60% avg_sensitivity=75.95%, avg_specificity=85.14% avg_auc=89.19%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.337586 Test loss=0.415700 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3409497141838074
[5/24] Train loss=0.29772597551345825
[10/24] Train loss=0.37192556262016296
[15/24] Train loss=0.2920962870121002
[20/24] Train loss=0.3180426359176636
Test set avg_accuracy=82.64% avg_sensitivity=75.81%, avg_specificity=85.25% avg_auc=89.18%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.337255 Test loss=0.415062 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.34151479601860046
[5/24] Train loss=0.2928446829319
[10/24] Train loss=0.3673197031021118
[15/24] Train loss=0.2981421947479248
[20/24] Train loss=0.32155629992485046
Test set avg_accuracy=82.64% avg_sensitivity=75.86%, avg_specificity=85.23% avg_auc=89.18%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.335077 Test loss=0.415430 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3503200113773346
[5/24] Train loss=0.3075866103172302
[10/24] Train loss=0.3655851483345032
[15/24] Train loss=0.289671391248703
[20/24] Train loss=0.31765997409820557
Test set avg_accuracy=82.64% avg_sensitivity=75.86%, avg_specificity=85.23% avg_auc=89.17%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.333874 Test loss=0.415613 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3390575349330902
[5/24] Train loss=0.30740466713905334
[10/24] Train loss=0.3648209571838379
[15/24] Train loss=0.3036420941352844
[20/24] Train loss=0.3274003267288208
Test set avg_accuracy=82.64% avg_sensitivity=75.91%, avg_specificity=85.21% avg_auc=89.17%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.338991 Test loss=0.415754 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.34331920742988586
[5/24] Train loss=0.30034640431404114
[10/24] Train loss=0.36093735694885254
[15/24] Train loss=0.2953712046146393
[20/24] Train loss=0.32670220732688904
Test set avg_accuracy=82.67% avg_sensitivity=75.72%, avg_specificity=85.32% avg_auc=89.16%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.333967 Test loss=0.415294 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3487311005592346
[5/24] Train loss=0.3030390441417694
[10/24] Train loss=0.3605819046497345
[15/24] Train loss=0.3061685860157013
[20/24] Train loss=0.3181406855583191
Test set avg_accuracy=82.63% avg_sensitivity=75.77%, avg_specificity=85.25% avg_auc=89.15%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.337303 Test loss=0.415396 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.33931830525398254
[5/24] Train loss=0.3018079400062561
[10/24] Train loss=0.37674379348754883
[15/24] Train loss=0.29997217655181885
[20/24] Train loss=0.331027090549469
Test set avg_accuracy=82.63% avg_sensitivity=75.81%, avg_specificity=85.23% avg_auc=89.15%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.337450 Test loss=0.415585 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3293382227420807
[5/24] Train loss=0.3104701340198517
[10/24] Train loss=0.3725060522556305
[15/24] Train loss=0.30204036831855774
[20/24] Train loss=0.3184993267059326
Test set avg_accuracy=82.63% avg_sensitivity=75.81%, avg_specificity=85.23% avg_auc=89.15%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.337454 Test loss=0.415664 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3376655876636505
[5/24] Train loss=0.28893721103668213
[10/24] Train loss=0.3625132441520691
[15/24] Train loss=0.3043971657752991
[20/24] Train loss=0.3191815912723541
Test set avg_accuracy=82.64% avg_sensitivity=75.81%, avg_specificity=85.25% avg_auc=89.15%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.335873 Test loss=0.415583 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.33415675163269043
[5/24] Train loss=0.2978622615337372
[10/24] Train loss=0.3692178726196289
[15/24] Train loss=0.2919296324253082
[20/24] Train loss=0.3204852044582367
Test set avg_accuracy=82.66% avg_sensitivity=75.81%, avg_specificity=85.27% avg_auc=89.15%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.335116 Test loss=0.415494 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3369124233722687
[5/24] Train loss=0.299249529838562
[10/24] Train loss=0.3717098832130432
[15/24] Train loss=0.2947266399860382
[20/24] Train loss=0.32156631350517273
Test set avg_accuracy=82.66% avg_sensitivity=75.81%, avg_specificity=85.27% avg_auc=89.15%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.333800 Test loss=0.415489 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=83.39% sen=81.75%, spe=84.01%, auc=91.29%!
Fold[7] Avg_jsc=0.63%(±0.23969348028018994)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=2.2626218795776367
[5/24] Train loss=2.0562167167663574
[10/24] Train loss=1.8834773302078247
[15/24] Train loss=1.7347766160964966
[20/24] Train loss=1.6864607334136963
Test set avg_accuracy=51.61% avg_sensitivity=44.64%, avg_specificity=53.96% avg_auc=48.59%
Best model saved!! Metric=48.58510957121401!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=1.878574 Test loss=0.808125 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.6358556747436523
[5/24] Train loss=1.5754797458648682
[10/24] Train loss=1.5677543878555298
[15/24] Train loss=1.570949912071228
[20/24] Train loss=1.5461355447769165
Test set avg_accuracy=53.78% avg_sensitivity=41.53%, avg_specificity=57.89% avg_auc=49.24%
Best model saved!! Metric=49.241941430563344!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=1.570137 Test loss=0.700026 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.5392194986343384
[5/24] Train loss=1.5221203565597534
[10/24] Train loss=1.5154541730880737
[15/24] Train loss=1.512954592704773
[20/24] Train loss=1.5335474014282227
Test set avg_accuracy=53.50% avg_sensitivity=40.65%, avg_specificity=57.82% avg_auc=49.19%
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=1.520596 Test loss=0.700531 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.521267294883728
[5/24] Train loss=1.4945793151855469
[10/24] Train loss=1.5071356296539307
[15/24] Train loss=1.469180941581726
[20/24] Train loss=1.4878193140029907
Test set avg_accuracy=47.89% avg_sensitivity=54.07%, avg_specificity=45.82% avg_auc=50.19%
Best model saved!! Metric=50.189621611630116!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=1.492438 Test loss=0.702473 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.488047480583191
[5/24] Train loss=1.4902143478393555
[10/24] Train loss=1.488438367843628
[15/24] Train loss=1.4960907697677612
[20/24] Train loss=1.4937182664871216
Test set avg_accuracy=51.37% avg_sensitivity=52.62%, avg_specificity=50.95% avg_auc=52.11%
Best model saved!! Metric=52.10569572858865!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=1.482104 Test loss=0.697099 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.4591854810714722
[5/24] Train loss=1.4667158126831055
[10/24] Train loss=1.4566023349761963
[15/24] Train loss=1.4732767343521118
[20/24] Train loss=1.4588351249694824
Test set avg_accuracy=52.30% avg_sensitivity=50.96%, avg_specificity=52.76% avg_auc=53.12%
Best model saved!! Metric=53.11804390090943!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=1.465586 Test loss=0.691164 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.4399529695510864
[5/24] Train loss=1.4836770296096802
[10/24] Train loss=1.443959355354309
[15/24] Train loss=1.434233546257019
[20/24] Train loss=1.4379044771194458
Test set avg_accuracy=52.67% avg_sensitivity=55.41%, avg_specificity=51.75% avg_auc=54.74%
Best model saved!! Metric=54.74366154147988!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=1.452599 Test loss=0.690231 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.4374752044677734
[5/24] Train loss=1.439809799194336
[10/24] Train loss=1.455237627029419
[15/24] Train loss=1.4405667781829834
[20/24] Train loss=1.445515751838684
Test set avg_accuracy=54.14% avg_sensitivity=55.20%, avg_specificity=53.78% avg_auc=56.25%
Best model saved!! Metric=56.252626377099865!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=1.443237 Test loss=0.687956 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.4384503364562988
[5/24] Train loss=1.425829291343689
[10/24] Train loss=1.432672142982483
[15/24] Train loss=1.4318245649337769
[20/24] Train loss=1.4261518716812134
Test set avg_accuracy=57.58% avg_sensitivity=51.79%, avg_specificity=59.52% avg_auc=57.77%
Best model saved!! Metric=57.76518538022374!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=1.432719 Test loss=0.680634 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.4311832189559937
[5/24] Train loss=1.4277381896972656
[10/24] Train loss=1.4185492992401123
[15/24] Train loss=1.4168025255203247
[20/24] Train loss=1.4064884185791016
Test set avg_accuracy=59.11% avg_sensitivity=53.08%, avg_specificity=61.14% avg_auc=59.59%
Best model saved!! Metric=59.5947697746547!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=1.421682 Test loss=0.678423 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.420264720916748
[5/24] Train loss=1.4132721424102783
[10/24] Train loss=1.425386667251587
[15/24] Train loss=1.4103279113769531
[20/24] Train loss=1.4009108543395996
Test set avg_accuracy=59.99% avg_sensitivity=54.89%, avg_specificity=61.70% avg_auc=61.66%
Best model saved!! Metric=61.65597529446726!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=1.412216 Test loss=0.675856 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.4055062532424927
[5/24] Train loss=1.4120845794677734
[10/24] Train loss=1.4179513454437256
[15/24] Train loss=1.3983373641967773
[20/24] Train loss=1.4036831855773926
Test set avg_accuracy=63.36% avg_sensitivity=53.18%, avg_specificity=66.78% avg_auc=64.10%
Best model saved!! Metric=64.10102709416782!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=1.404547 Test loss=0.667182 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.3869482278823853
[5/24] Train loss=1.3842443227767944
[10/24] Train loss=1.3872742652893066
[15/24] Train loss=1.3651323318481445
[20/24] Train loss=1.3636564016342163
Test set avg_accuracy=65.18% avg_sensitivity=54.17%, avg_specificity=68.88% avg_auc=66.33%
Best model saved!! Metric=66.33176652251862!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=1.383369 Test loss=0.657455 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.3777871131896973
[5/24] Train loss=1.3613345623016357
[10/24] Train loss=1.3641762733459473
[15/24] Train loss=1.3480637073516846
[20/24] Train loss=1.3362199068069458
Test set avg_accuracy=65.99% avg_sensitivity=58.98%, avg_specificity=68.34% avg_auc=69.02%
Best model saved!! Metric=69.01736631475954!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=1.361955 Test loss=0.647398 Current lr=[7.558439349929357e-05]

[0/24] Train loss=1.3429943323135376
[5/24] Train loss=1.3411271572113037
[10/24] Train loss=1.3377267122268677
[15/24] Train loss=1.2909761667251587
[20/24] Train loss=1.2747312784194946
Test set avg_accuracy=67.47% avg_sensitivity=64.73%, avg_specificity=68.39% avg_auc=72.47%
Best model saved!! Metric=72.46906426164314!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=1.318186 Test loss=0.628348 Current lr=[8.412106591444728e-05]

[0/24] Train loss=1.283776879310608
[5/24] Train loss=1.2798017263412476
[10/24] Train loss=1.3146826028823853
[15/24] Train loss=1.2138077020645142
[20/24] Train loss=1.1950684785842896
Test set avg_accuracy=69.10% avg_sensitivity=65.15%, avg_specificity=70.43% avg_auc=75.04%
Best model saved!! Metric=75.0355791055099!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=1.254948 Test loss=0.591829 Current lr=[9.300857440308985e-05]

[0/24] Train loss=1.2167397737503052
[5/24] Train loss=1.206538200378418
[10/24] Train loss=1.26079523563385
[15/24] Train loss=1.1415367126464844
[20/24] Train loss=1.0991382598876953
Test set avg_accuracy=71.71% avg_sensitivity=63.80%, avg_specificity=74.36% avg_auc=76.76%
Best model saved!! Metric=76.76362601597161!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=1.193800 Test loss=0.548146 Current lr=[0.00010220353965498347]

[0/24] Train loss=1.1427228450775146
[5/24] Train loss=1.1505223512649536
[10/24] Train loss=1.1864345073699951
[15/24] Train loss=1.0934128761291504
[20/24] Train loss=1.0479273796081543
Test set avg_accuracy=72.79% avg_sensitivity=67.12%, avg_specificity=74.69% avg_auc=77.98%
Best model saved!! Metric=77.98220193474309!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=1.148879 Test loss=0.533453 Current lr=[0.0001116610816848323]

[0/24] Train loss=1.1259748935699463
[5/24] Train loss=1.0869563817977905
[10/24] Train loss=1.1443445682525635
[15/24] Train loss=1.0470553636550903
[20/24] Train loss=0.995581865310669
Test set avg_accuracy=73.11% avg_sensitivity=69.65%, avg_specificity=74.27% avg_auc=79.02%
Best model saved!! Metric=79.01947507318725!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=1.110150 Test loss=0.524089 Current lr=[0.00012133503888836635]

[0/24] Train loss=1.1117204427719116
[5/24] Train loss=1.0940544605255127
[10/24] Train loss=1.1293833255767822
[15/24] Train loss=1.0102577209472656
[20/24] Train loss=0.9504953026771545
Test set avg_accuracy=74.48% avg_sensitivity=69.50%, avg_specificity=76.15% avg_auc=79.92%
Best model saved!! Metric=79.920273437778!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=1.080964 Test loss=0.507990 Current lr=[0.00013117819335391835]

[0/24] Train loss=1.081647515296936
[5/24] Train loss=1.0694541931152344
[10/24] Train loss=1.0767298936843872
[15/24] Train loss=0.9846798181533813
[20/24] Train loss=0.9248465895652771
Test set avg_accuracy=75.40% avg_sensitivity=70.53%, avg_specificity=77.04% avg_auc=80.85%
Best model saved!! Metric=80.84915405097358!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=1.051398 Test loss=0.494699 Current lr=[0.00014114250132976375]

[0/24] Train loss=1.066969394683838
[5/24] Train loss=1.0176670551300049
[10/24] Train loss=1.053419589996338
[15/24] Train loss=0.9571274518966675
[20/24] Train loss=0.8880849480628967
Test set avg_accuracy=75.08% avg_sensitivity=74.42%, avg_specificity=75.30% avg_auc=81.74%
Best model saved!! Metric=81.74106158015998!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=1.029214 Test loss=0.499401 Current lr=[0.00015117932772232805]

[0/24] Train loss=1.0290029048919678
[5/24] Train loss=1.00494384765625
[10/24] Train loss=1.022361159324646
[15/24] Train loss=0.9564588665962219
[20/24] Train loss=0.8410134315490723
Test set avg_accuracy=76.16% avg_sensitivity=72.71%, avg_specificity=77.32% avg_auc=82.23%
Best model saved!! Metric=82.22526530405983!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=1.003041 Test loss=0.484886 Current lr=[0.00016123968348069324]

[0/24] Train loss=1.013244390487671
[5/24] Train loss=1.0022180080413818
[10/24] Train loss=1.0311334133148193
[15/24] Train loss=0.9100543260574341
[20/24] Train loss=0.8365186452865601
Test set avg_accuracy=76.68% avg_sensitivity=73.69%, avg_specificity=77.68% avg_auc=82.95%
Best model saved!! Metric=82.95032329041261!!
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.985762 Test loss=0.477246 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.9853019118309021
[5/24] Train loss=1.0060418844223022
[10/24] Train loss=0.9929518699645996
[15/24] Train loss=0.9003142714500427
[20/24] Train loss=0.8093720078468323
Test set avg_accuracy=77.70% avg_sensitivity=71.93%, avg_specificity=79.63% avg_auc=83.38%
Best model saved!! Metric=83.38112795425481!!
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.971057 Test loss=0.463599 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.9848787188529968
[5/24] Train loss=0.9298064112663269
[10/24] Train loss=0.9891504049301147
[15/24] Train loss=0.873540997505188
[20/24] Train loss=0.819069504737854
Test set avg_accuracy=77.84% avg_sensitivity=73.12%, avg_specificity=79.42% avg_auc=83.97%
Best model saved!! Metric=83.97085967892643!!
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.956802 Test loss=0.458110 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.9657070636749268
[5/24] Train loss=0.8961986899375916
[10/24] Train loss=0.9920843243598938
[15/24] Train loss=0.860249400138855
[20/24] Train loss=0.7841185927391052
Test set avg_accuracy=77.60% avg_sensitivity=75.19%, avg_specificity=78.41% avg_auc=84.35%
Best model saved!! Metric=84.35077849758213!!
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.939718 Test loss=0.461566 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.9327183365821838
[5/24] Train loss=0.9009164571762085
[10/24] Train loss=0.9549646377563477
[15/24] Train loss=0.8487681150436401
[20/24] Train loss=0.7978158593177795
Test set avg_accuracy=78.24% avg_sensitivity=72.76%, avg_specificity=80.08% avg_auc=84.68%
Best model saved!! Metric=84.67909083596284!!
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.927501 Test loss=0.447880 Current lr=[0.000210185142098938]

[0/24] Train loss=0.9471254944801331
[5/24] Train loss=0.8981024026870728
[10/24] Train loss=0.9576717615127563
[15/24] Train loss=0.82395339012146
[20/24] Train loss=0.7655372023582458
Test set avg_accuracy=78.92% avg_sensitivity=71.78%, avg_specificity=81.32% avg_auc=84.80%
Best model saved!! Metric=84.79949094337348!!
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.920455 Test loss=0.440863 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.9408555626869202
[5/24] Train loss=0.8990052938461304
[10/24] Train loss=0.9557307958602905
[15/24] Train loss=0.8368198871612549
[20/24] Train loss=0.752508819103241
Test set avg_accuracy=79.05% avg_sensitivity=72.45%, avg_specificity=81.27% avg_auc=85.16%
Best model saved!! Metric=85.16270003591467!!
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.911328 Test loss=0.438396 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.9215520024299622
[5/24] Train loss=0.8903777003288269
[10/24] Train loss=0.9340500235557556
[15/24] Train loss=0.8039753437042236
[20/24] Train loss=0.7431460618972778
Test set avg_accuracy=79.58% avg_sensitivity=72.81%, avg_specificity=81.86% avg_auc=85.29%
Best model saved!! Metric=85.29404929270116!!
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.901456 Test loss=0.435298 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.9052201509475708
[5/24] Train loss=0.8764058947563171
[10/24] Train loss=0.9319182634353638
[15/24] Train loss=0.8044280409812927
[20/24] Train loss=0.7418649792671204
Test set avg_accuracy=79.62% avg_sensitivity=72.09%, avg_specificity=82.15% avg_auc=85.49%
Best model saved!! Metric=85.49226447776162!!
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.893231 Test loss=0.429897 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.8938804864883423
[5/24] Train loss=0.869598388671875
[10/24] Train loss=0.9172738790512085
[15/24] Train loss=0.7907534837722778
[20/24] Train loss=0.7150858640670776
Test set avg_accuracy=79.92% avg_sensitivity=71.26%, avg_specificity=82.83% avg_auc=85.57%
Best model saved!! Metric=85.56550802656872!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.886836 Test loss=0.426623 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.8923749923706055
[5/24] Train loss=0.8729371428489685
[10/24] Train loss=0.9071348309516907
[15/24] Train loss=0.7876487970352173
[20/24] Train loss=0.7247202396392822
Test set avg_accuracy=80.21% avg_sensitivity=70.95%, avg_specificity=83.32% avg_auc=85.79%
Best model saved!! Metric=85.79368811940274!!
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.879661 Test loss=0.421854 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.8930457234382629
[5/24] Train loss=0.8878391981124878
[10/24] Train loss=0.9118631482124329
[15/24] Train loss=0.782640814781189
[20/24] Train loss=0.71413654088974
Test set avg_accuracy=80.18% avg_sensitivity=71.41%, avg_specificity=83.13% avg_auc=85.88%
Best model saved!! Metric=85.87908337738965!!
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.874883 Test loss=0.422321 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.8964686393737793
[5/24] Train loss=0.916902482509613
[10/24] Train loss=0.8816543817520142
[15/24] Train loss=0.7600119113922119
[20/24] Train loss=0.7249743938446045
Test set avg_accuracy=80.66% avg_sensitivity=69.34%, avg_specificity=84.47% avg_auc=85.97%
Best model saved!! Metric=85.971766057709!!
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.864643 Test loss=0.415231 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.8848481774330139
[5/24] Train loss=0.8939762115478516
[10/24] Train loss=0.8724526166915894
[15/24] Train loss=0.7596474289894104
[20/24] Train loss=0.7043958306312561
Test set avg_accuracy=81.00% avg_sensitivity=68.93%, avg_specificity=85.06% avg_auc=86.01%
Best model saved!! Metric=86.01071638424227!!
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.859524 Test loss=0.411996 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.8774651288986206
[5/24] Train loss=0.86426842212677
[10/24] Train loss=0.8773005604743958
[15/24] Train loss=0.7667219042778015
[20/24] Train loss=0.7018481492996216
Test set avg_accuracy=80.95% avg_sensitivity=70.48%, avg_specificity=84.47% avg_auc=86.17%
Best model saved!! Metric=86.16696808730568!!
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.857964 Test loss=0.414410 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.8629958033561707
[5/24] Train loss=0.8565460443496704
[10/24] Train loss=0.8871461749076843
[15/24] Train loss=0.757554292678833
[20/24] Train loss=0.6956830620765686
Test set avg_accuracy=81.33% avg_sensitivity=69.14%, avg_specificity=85.42% avg_auc=86.29%
Best model saved!! Metric=86.29263783880096!!
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.848488 Test loss=0.408199 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.8609740138053894
[5/24] Train loss=0.8667321801185608
[10/24] Train loss=0.8945887684822083
[15/24] Train loss=0.7597752809524536
[20/24] Train loss=0.7054766416549683
Test set avg_accuracy=81.37% avg_sensitivity=70.02%, avg_specificity=85.18% avg_auc=86.39%
Best model saved!! Metric=86.38916240493585!!
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.847045 Test loss=0.409806 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.850913941860199
[5/24] Train loss=0.8889399766921997
[10/24] Train loss=0.8708100318908691
[15/24] Train loss=0.746476411819458
[20/24] Train loss=0.713181734085083
Test set avg_accuracy=81.45% avg_sensitivity=68.57%, avg_specificity=85.77% avg_auc=86.47%
Best model saved!! Metric=86.47295875382017!!
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.842351 Test loss=0.405100 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.8677785396575928
[5/24] Train loss=0.83177649974823
[10/24] Train loss=0.8703672289848328
[15/24] Train loss=0.7490386962890625
[20/24] Train loss=0.6930569410324097
Test set avg_accuracy=81.68% avg_sensitivity=68.62%, avg_specificity=86.07% avg_auc=86.54%
Best model saved!! Metric=86.5389869438037!!
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.837206 Test loss=0.403457 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.8419544100761414
[5/24] Train loss=0.8250340223312378
[10/24] Train loss=0.8804370164871216
[15/24] Train loss=0.7417920827865601
[20/24] Train loss=0.6955170631408691
Test set avg_accuracy=81.54% avg_sensitivity=69.96%, avg_specificity=85.42% avg_auc=86.59%
Best model saved!! Metric=86.59046731293823!!
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.835107 Test loss=0.406573 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.8502506017684937
[5/24] Train loss=0.8007650971412659
[10/24] Train loss=0.8716984987258911
[15/24] Train loss=0.7323938012123108
[20/24] Train loss=0.7027891278266907
Test set avg_accuracy=81.48% avg_sensitivity=70.84%, avg_specificity=85.06% avg_auc=86.65%
Best model saved!! Metric=86.64819468749614!!
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.829901 Test loss=0.407690 Current lr=[0.00029967723776099]

[0/24] Train loss=0.8519690632820129
[5/24] Train loss=0.7919976711273193
[10/24] Train loss=0.8665704131126404
[15/24] Train loss=0.7303250432014465
[20/24] Train loss=0.7047521471977234
Test set avg_accuracy=81.18% avg_sensitivity=73.12%, avg_specificity=83.89% avg_auc=86.74%
Best model saved!! Metric=86.74430488845515!!
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.827043 Test loss=0.414660 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.8273528218269348
[5/24] Train loss=0.7741732001304626
[10/24] Train loss=0.8733313083648682
[15/24] Train loss=0.7369563579559326
[20/24] Train loss=0.7038527131080627
Test set avg_accuracy=80.09% avg_sensitivity=75.76%, avg_specificity=81.54% avg_auc=86.83%
Best model saved!! Metric=86.82587177253441!!
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.824839 Test loss=0.425605 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.8073314428329468
[5/24] Train loss=0.7742111682891846
[10/24] Train loss=0.8822075128555298
[15/24] Train loss=0.741612434387207
[20/24] Train loss=0.697749137878418
Test set avg_accuracy=80.16% avg_sensitivity=76.02%, avg_specificity=81.54% avg_auc=86.74%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.819356 Test loss=0.428880 Current lr=[0.000299720220882401]

[0/24] Train loss=0.7882960438728333
[5/24] Train loss=0.7616202235221863
[10/24] Train loss=0.8625773787498474
[15/24] Train loss=0.7196437120437622
[20/24] Train loss=0.6860659718513489
Test set avg_accuracy=80.89% avg_sensitivity=74.21%, avg_specificity=83.13% avg_auc=86.89%
Best model saved!! Metric=86.89462035997705!!
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.810758 Test loss=0.416295 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.8119475245475769
[5/24] Train loss=0.769681453704834
[10/24] Train loss=0.8527964949607849
[15/24] Train loss=0.7166092395782471
[20/24] Train loss=0.6779111623764038
Test set avg_accuracy=80.77% avg_sensitivity=73.95%, avg_specificity=83.06% avg_auc=86.80%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.811500 Test loss=0.418042 Current lr=[0.000298904600941902]

[0/24] Train loss=0.8094147443771362
[5/24] Train loss=0.752021074295044
[10/24] Train loss=0.8351921439170837
[15/24] Train loss=0.7282398343086243
[20/24] Train loss=0.6762164235115051
Test set avg_accuracy=81.12% avg_sensitivity=73.59%, avg_specificity=83.65% avg_auc=86.92%
Best model saved!! Metric=86.91780679394944!!
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.804792 Test loss=0.414469 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.7965602278709412
[5/24] Train loss=0.7669498920440674
[10/24] Train loss=0.8477703332901001
[15/24] Train loss=0.7255845665931702
[20/24] Train loss=0.6750876903533936
Test set avg_accuracy=81.35% avg_sensitivity=73.33%, avg_specificity=84.05% avg_auc=86.99%
Best model saved!! Metric=86.98823536194213!!
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.804281 Test loss=0.412887 Current lr=[0.000297555943323901]

[0/24] Train loss=0.7905030250549316
[5/24] Train loss=0.7481813430786133
[10/24] Train loss=0.8409584760665894
[15/24] Train loss=0.7039386034011841
[20/24] Train loss=0.6590762734413147
Test set avg_accuracy=81.21% avg_sensitivity=73.85%, avg_specificity=83.68% avg_auc=86.97%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.798096 Test loss=0.415684 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.7885866165161133
[5/24] Train loss=0.7428552508354187
[10/24] Train loss=0.8356675505638123
[15/24] Train loss=0.7216427326202393
[20/24] Train loss=0.6675264239311218
Test set avg_accuracy=81.29% avg_sensitivity=74.47%, avg_specificity=83.58% avg_auc=86.98%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.795474 Test loss=0.416312 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.7869724631309509
[5/24] Train loss=0.743801474571228
[10/24] Train loss=0.8424758315086365
[15/24] Train loss=0.7133651375770569
[20/24] Train loss=0.6809177994728088
Test set avg_accuracy=80.79% avg_sensitivity=77.11%, avg_specificity=82.03% avg_auc=87.22%
Best model saved!! Metric=87.22309934522194!!
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.794423 Test loss=0.424718 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.7680703997612
[5/24] Train loss=0.7350196242332458
[10/24] Train loss=0.8377910852432251
[15/24] Train loss=0.7135388851165771
[20/24] Train loss=0.6501449346542358
Test set avg_accuracy=80.85% avg_sensitivity=76.75%, avg_specificity=82.22% avg_auc=87.15%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.790264 Test loss=0.424941 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.7685702443122864
[5/24] Train loss=0.7232425808906555
[10/24] Train loss=0.8207031488418579
[15/24] Train loss=0.698364794254303
[20/24] Train loss=0.6541892886161804
Test set avg_accuracy=81.18% avg_sensitivity=76.85%, avg_specificity=82.64% avg_auc=87.34%
Best model saved!! Metric=87.33548689124238!!
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.782673 Test loss=0.421289 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.7752204537391663
[5/24] Train loss=0.7202739715576172
[10/24] Train loss=0.8321144580841064
[15/24] Train loss=0.7073767781257629
[20/24] Train loss=0.6472660303115845
Test set avg_accuracy=81.38% avg_sensitivity=76.85%, avg_specificity=82.90% avg_auc=87.29%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.779309 Test loss=0.421137 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.7678205370903015
[5/24] Train loss=0.7201533317565918
[10/24] Train loss=0.8387371301651001
[15/24] Train loss=0.7043752670288086
[20/24] Train loss=0.6497604846954346
Test set avg_accuracy=81.34% avg_sensitivity=76.90%, avg_specificity=82.83% avg_auc=87.31%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.778999 Test loss=0.423271 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.754692554473877
[5/24] Train loss=0.7237961888313293
[10/24] Train loss=0.8287832140922546
[15/24] Train loss=0.7080438733100891
[20/24] Train loss=0.6642555594444275
Test set avg_accuracy=81.37% avg_sensitivity=76.33%, avg_specificity=83.06% avg_auc=87.30%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.775659 Test loss=0.419650 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.7703069448471069
[5/24] Train loss=0.7102890610694885
[10/24] Train loss=0.8208637833595276
[15/24] Train loss=0.6912195086479187
[20/24] Train loss=0.6635299324989319
Test set avg_accuracy=80.99% avg_sensitivity=77.89%, avg_specificity=82.03% avg_auc=87.38%
Best model saved!! Metric=87.37827459962189!!
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.776323 Test loss=0.427391 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.7703266739845276
[5/24] Train loss=0.7198529839515686
[10/24] Train loss=0.8103115558624268
[15/24] Train loss=0.6976667046546936
[20/24] Train loss=0.6596055626869202
Test set avg_accuracy=81.02% avg_sensitivity=77.47%, avg_specificity=82.21% avg_auc=87.38%
Best model saved!! Metric=87.38008519528175!!
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.771439 Test loss=0.425626 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.7518459558486938
[5/24] Train loss=0.7178272604942322
[10/24] Train loss=0.8256617188453674
[15/24] Train loss=0.6719844937324524
[20/24] Train loss=0.6523089408874512
Test set avg_accuracy=80.96% avg_sensitivity=77.78%, avg_specificity=82.03% avg_auc=87.27%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.767838 Test loss=0.430762 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.7498348355293274
[5/24] Train loss=0.7070371508598328
[10/24] Train loss=0.8149933815002441
[15/24] Train loss=0.6814349293708801
[20/24] Train loss=0.6384360790252686
Test set avg_accuracy=80.95% avg_sensitivity=77.52%, avg_specificity=82.10% avg_auc=87.22%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.763041 Test loss=0.431946 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.7584554553031921
[5/24] Train loss=0.6957168579101562
[10/24] Train loss=0.8032143115997314
[15/24] Train loss=0.685882568359375
[20/24] Train loss=0.6235591173171997
Test set avg_accuracy=81.20% avg_sensitivity=76.90%, avg_specificity=82.64% avg_auc=87.16%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.760250 Test loss=0.427946 Current lr=[0.000276307469034998]

[0/24] Train loss=0.7474465370178223
[5/24] Train loss=0.6906274557113647
[10/24] Train loss=0.808199405670166
[15/24] Train loss=0.6809134483337402
[20/24] Train loss=0.6267335414886475
Test set avg_accuracy=81.74% avg_sensitivity=75.09%, avg_specificity=83.98% avg_auc=87.21%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.754058 Test loss=0.418892 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.7533580660820007
[5/24] Train loss=0.6931136846542358
[10/24] Train loss=0.8106726408004761
[15/24] Train loss=0.6741523742675781
[20/24] Train loss=0.6190739870071411
Test set avg_accuracy=81.73% avg_sensitivity=76.49%, avg_specificity=83.49% avg_auc=87.25%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.757208 Test loss=0.423671 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.7508227229118347
[5/24] Train loss=0.6941691637039185
[10/24] Train loss=0.8058890104293823
[15/24] Train loss=0.6763656735420227
[20/24] Train loss=0.630470335483551
Test set avg_accuracy=81.37% avg_sensitivity=76.75%, avg_specificity=82.92% avg_auc=87.25%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.757656 Test loss=0.426220 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.7305061221122742
[5/24] Train loss=0.6742146611213684
[10/24] Train loss=0.7942060232162476
[15/24] Train loss=0.6763789057731628
[20/24] Train loss=0.6168028712272644
Test set avg_accuracy=81.20% avg_sensitivity=77.52%, avg_specificity=82.43% avg_auc=87.27%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.754070 Test loss=0.430965 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.7337360978126526
[5/24] Train loss=0.670923113822937
[10/24] Train loss=0.8025135397911072
[15/24] Train loss=0.6740691065788269
[20/24] Train loss=0.6383603811264038
Test set avg_accuracy=80.89% avg_sensitivity=78.56%, avg_specificity=81.67% avg_auc=87.29%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.749834 Test loss=0.438390 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.7248587012290955
[5/24] Train loss=0.6833083629608154
[10/24] Train loss=0.7888646721839905
[15/24] Train loss=0.6630761623382568
[20/24] Train loss=0.6127302646636963
Test set avg_accuracy=81.04% avg_sensitivity=77.21%, avg_specificity=82.33% avg_auc=87.18%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.749351 Test loss=0.433512 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.743335485458374
[5/24] Train loss=0.6724076867103577
[10/24] Train loss=0.7883731126785278
[15/24] Train loss=0.663190484046936
[20/24] Train loss=0.6115999817848206
Test set avg_accuracy=80.95% avg_sensitivity=77.94%, avg_specificity=81.96% avg_auc=87.22%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.748100 Test loss=0.436112 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.7370360493659973
[5/24] Train loss=0.6703380942344666
[10/24] Train loss=0.7892698049545288
[15/24] Train loss=0.6651609539985657
[20/24] Train loss=0.6007397174835205
Test set avg_accuracy=80.73% avg_sensitivity=78.04%, avg_specificity=81.63% avg_auc=87.23%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.743413 Test loss=0.439420 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.7198798656463623
[5/24] Train loss=0.6549671292304993
[10/24] Train loss=0.7939017415046692
[15/24] Train loss=0.650775671005249
[20/24] Train loss=0.6035611629486084
Test set avg_accuracy=80.81% avg_sensitivity=77.58%, avg_specificity=81.89% avg_auc=87.13%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.737777 Test loss=0.440278 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.7229549884796143
[5/24] Train loss=0.6727779507637024
[10/24] Train loss=0.7860410213470459
[15/24] Train loss=0.6542402505874634
[20/24] Train loss=0.60940021276474
Test set avg_accuracy=80.68% avg_sensitivity=77.84%, avg_specificity=81.63% avg_auc=87.20%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.740009 Test loss=0.441558 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.7112734913825989
[5/24] Train loss=0.640727162361145
[10/24] Train loss=0.7773966193199158
[15/24] Train loss=0.6543270349502563
[20/24] Train loss=0.5899278521537781
Test set avg_accuracy=80.65% avg_sensitivity=77.84%, avg_specificity=81.60% avg_auc=87.05%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.732931 Test loss=0.445000 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.7145860195159912
[5/24] Train loss=0.6631038784980774
[10/24] Train loss=0.7810289263725281
[15/24] Train loss=0.6417399644851685
[20/24] Train loss=0.6069836020469666
Test set avg_accuracy=80.60% avg_sensitivity=78.51%, avg_specificity=81.30% avg_auc=87.18%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.734605 Test loss=0.445606 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.723071813583374
[5/24] Train loss=0.6739750504493713
[10/24] Train loss=0.7923553586006165
[15/24] Train loss=0.6433781981468201
[20/24] Train loss=0.6188995838165283
Test set avg_accuracy=80.94% avg_sensitivity=76.80%, avg_specificity=82.33% avg_auc=86.99%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.736141 Test loss=0.440290 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.7207406163215637
[5/24] Train loss=0.6620931625366211
[10/24] Train loss=0.7917540073394775
[15/24] Train loss=0.6676192879676819
[20/24] Train loss=0.590803861618042
Test set avg_accuracy=80.56% avg_sensitivity=78.20%, avg_specificity=81.35% avg_auc=86.98%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.736219 Test loss=0.452198 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.7022414207458496
[5/24] Train loss=0.6569950580596924
[10/24] Train loss=0.8015597462654114
[15/24] Train loss=0.659706175327301
[20/24] Train loss=0.5962255597114563
Test set avg_accuracy=80.74% avg_sensitivity=77.32%, avg_specificity=81.89% avg_auc=86.85%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.733249 Test loss=0.451323 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.7014326453208923
[5/24] Train loss=0.6663919687271118
[10/24] Train loss=0.7983062267303467
[15/24] Train loss=0.657012939453125
[20/24] Train loss=0.595142126083374
Test set avg_accuracy=79.65% avg_sensitivity=81.05%, avg_specificity=79.18% avg_auc=87.21%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.741562 Test loss=0.466988 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6961450576782227
[5/24] Train loss=0.675955057144165
[10/24] Train loss=0.8402993679046631
[15/24] Train loss=0.695763885974884
[20/24] Train loss=0.6478860378265381
Test set avg_accuracy=74.52% avg_sensitivity=87.93%, avg_specificity=70.01% avg_auc=87.48%
Best model saved!! Metric=87.4819019253478!!
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.752959 Test loss=0.555612 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.7478345036506653
[5/24] Train loss=0.7256008386611938
[10/24] Train loss=0.7788751125335693
[15/24] Train loss=0.6598146557807922
[20/24] Train loss=0.6427968740463257
Test set avg_accuracy=75.87% avg_sensitivity=86.79%, avg_specificity=72.20% avg_auc=87.40%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.748104 Test loss=0.541875 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.7034484148025513
[5/24] Train loss=0.6957062482833862
[10/24] Train loss=0.7843301296234131
[15/24] Train loss=0.6658369302749634
[20/24] Train loss=0.6342536211013794
Test set avg_accuracy=75.22% avg_sensitivity=87.78%, avg_specificity=71.00% avg_auc=87.52%
Best model saved!! Metric=87.51910921576076!!
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.734145 Test loss=0.552654 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.7241322994232178
[5/24] Train loss=0.6941064596176147
[10/24] Train loss=0.7674844264984131
[15/24] Train loss=0.6486635208129883
[20/24] Train loss=0.6236409544944763
Test set avg_accuracy=75.66% avg_sensitivity=87.42%, avg_specificity=71.72% avg_auc=87.55%
Best model saved!! Metric=87.55095678270303!!
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.730601 Test loss=0.548201 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.6946297287940979
[5/24] Train loss=0.695450484752655
[10/24] Train loss=0.7611678242683411
[15/24] Train loss=0.6635586023330688
[20/24] Train loss=0.6263932585716248
Test set avg_accuracy=76.42% avg_sensitivity=86.64%, avg_specificity=72.99% avg_auc=87.45%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.723468 Test loss=0.536898 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.7015045285224915
[5/24] Train loss=0.661472499370575
[10/24] Train loss=0.7630676627159119
[15/24] Train loss=0.6456323266029358
[20/24] Train loss=0.6339027881622314
Test set avg_accuracy=75.39% avg_sensitivity=87.31%, avg_specificity=71.39% avg_auc=87.50%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.723708 Test loss=0.552159 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.7043734788894653
[5/24] Train loss=0.6716179251670837
[10/24] Train loss=0.7882601618766785
[15/24] Train loss=0.6703349947929382
[20/24] Train loss=0.627607524394989
Test set avg_accuracy=75.60% avg_sensitivity=87.31%, avg_specificity=71.66% avg_auc=87.43%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.723781 Test loss=0.554903 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6955729722976685
[5/24] Train loss=0.6705422401428223
[10/24] Train loss=0.752878725528717
[15/24] Train loss=0.6483815908432007
[20/24] Train loss=0.6361780762672424
Test set avg_accuracy=75.48% avg_sensitivity=87.62%, avg_specificity=71.40% avg_auc=87.44%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.717025 Test loss=0.559426 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.708111047744751
[5/24] Train loss=0.6709827184677124
[10/24] Train loss=0.7609239220619202
[15/24] Train loss=0.649387538433075
[20/24] Train loss=0.604287326335907
Test set avg_accuracy=76.41% avg_sensitivity=86.74%, avg_specificity=72.93% avg_auc=87.38%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.714966 Test loss=0.547059 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6956595182418823
[5/24] Train loss=0.6710863709449768
[10/24] Train loss=0.7678238153457642
[15/24] Train loss=0.6531997323036194
[20/24] Train loss=0.6111882925033569
Test set avg_accuracy=76.64% avg_sensitivity=86.48%, avg_specificity=73.33% avg_auc=87.41%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.714054 Test loss=0.537761 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6795569658279419
[5/24] Train loss=0.6454684138298035
[10/24] Train loss=0.7697671055793762
[15/24] Train loss=0.6445438265800476
[20/24] Train loss=0.6190981864929199
Test set avg_accuracy=75.52% avg_sensitivity=87.21%, avg_specificity=71.60% avg_auc=87.32%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.708623 Test loss=0.562319 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.702587902545929
[5/24] Train loss=0.657672643661499
[10/24] Train loss=0.7790977358818054
[15/24] Train loss=0.6514466404914856
[20/24] Train loss=0.6108868718147278
Test set avg_accuracy=75.70% avg_sensitivity=87.26%, avg_specificity=71.82% avg_auc=87.38%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.709480 Test loss=0.558670 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.701309859752655
[5/24] Train loss=0.6657671332359314
[10/24] Train loss=0.7652873992919922
[15/24] Train loss=0.6445479989051819
[20/24] Train loss=0.5926687121391296
Test set avg_accuracy=76.46% avg_sensitivity=86.28%, avg_specificity=73.16% avg_auc=87.26%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.706802 Test loss=0.542289 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6826351284980774
[5/24] Train loss=0.6550787687301636
[10/24] Train loss=0.7580392956733704
[15/24] Train loss=0.645793616771698
[20/24] Train loss=0.602207362651825
Test set avg_accuracy=76.84% avg_sensitivity=86.07%, avg_specificity=73.73% avg_auc=87.22%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.701739 Test loss=0.541887 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.6775285601615906
[5/24] Train loss=0.6486141085624695
[10/24] Train loss=0.7616217732429504
[15/24] Train loss=0.642670750617981
[20/24] Train loss=0.5982744693756104
Test set avg_accuracy=76.73% avg_sensitivity=86.02%, avg_specificity=73.61% avg_auc=87.24%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.700497 Test loss=0.544247 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.6824016571044922
[5/24] Train loss=0.6345272660255432
[10/24] Train loss=0.7559447288513184
[15/24] Train loss=0.6384758353233337
[20/24] Train loss=0.598901629447937
Test set avg_accuracy=76.18% avg_sensitivity=86.22%, avg_specificity=72.81% avg_auc=87.24%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.698530 Test loss=0.551152 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6832782030105591
[5/24] Train loss=0.6576454639434814
[10/24] Train loss=0.7591617703437805
[15/24] Train loss=0.6364503502845764
[20/24] Train loss=0.5978173017501831
Test set avg_accuracy=75.87% avg_sensitivity=86.85%, avg_specificity=72.19% avg_auc=87.31%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.699225 Test loss=0.554858 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.6746030449867249
[5/24] Train loss=0.6493456959724426
[10/24] Train loss=0.7420995235443115
[15/24] Train loss=0.6223909854888916
[20/24] Train loss=0.5818525552749634
Test set avg_accuracy=77.25% avg_sensitivity=85.34%, avg_specificity=74.53% avg_auc=87.08%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.692206 Test loss=0.534131 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.6612060070037842
[5/24] Train loss=0.6423181295394897
[10/24] Train loss=0.7441790103912354
[15/24] Train loss=0.6193194389343262
[20/24] Train loss=0.5879690647125244
Test set avg_accuracy=76.63% avg_sensitivity=85.91%, avg_specificity=73.51% avg_auc=87.09%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.688459 Test loss=0.547754 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6633335947990417
[5/24] Train loss=0.6327901482582092
[10/24] Train loss=0.7596909999847412
[15/24] Train loss=0.6278932690620422
[20/24] Train loss=0.5860192775726318
Test set avg_accuracy=76.85% avg_sensitivity=85.50%, avg_specificity=73.94% avg_auc=87.07%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.688639 Test loss=0.540422 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6674172282218933
[5/24] Train loss=0.6442034840583801
[10/24] Train loss=0.7545533776283264
[15/24] Train loss=0.6393846273422241
[20/24] Train loss=0.5969107151031494
Test set avg_accuracy=76.63% avg_sensitivity=85.86%, avg_specificity=73.53% avg_auc=87.06%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.688389 Test loss=0.547125 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6674885153770447
[5/24] Train loss=0.6312401294708252
[10/24] Train loss=0.7402894496917725
[15/24] Train loss=0.6372195482254028
[20/24] Train loss=0.5870405435562134
Test set avg_accuracy=77.07% avg_sensitivity=85.09%, avg_specificity=74.38% avg_auc=87.08%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.685173 Test loss=0.534522 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.6657998561859131
[5/24] Train loss=0.6317624449729919
[10/24] Train loss=0.7524158954620361
[15/24] Train loss=0.6124982237815857
[20/24] Train loss=0.5810461640357971
Test set avg_accuracy=77.27% avg_sensitivity=83.79%, avg_specificity=75.07% avg_auc=86.94%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.682369 Test loss=0.526233 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6510403156280518
[5/24] Train loss=0.6329121589660645
[10/24] Train loss=0.7442392110824585
[15/24] Train loss=0.6192479729652405
[20/24] Train loss=0.5716438889503479
Test set avg_accuracy=76.91% avg_sensitivity=84.98%, avg_specificity=74.20% avg_auc=86.94%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.680927 Test loss=0.538689 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6582506895065308
[5/24] Train loss=0.6352957487106323
[10/24] Train loss=0.7570887804031372
[15/24] Train loss=0.628250777721405
[20/24] Train loss=0.5821449160575867
Test set avg_accuracy=77.33% avg_sensitivity=84.00%, avg_specificity=75.09% avg_auc=86.90%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.679626 Test loss=0.528492 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6648931503295898
[5/24] Train loss=0.629413902759552
[10/24] Train loss=0.7478893399238586
[15/24] Train loss=0.6160427927970886
[20/24] Train loss=0.5778427720069885
Test set avg_accuracy=77.11% avg_sensitivity=84.21%, avg_specificity=74.73% avg_auc=86.88%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.680329 Test loss=0.535434 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.6678104400634766
[5/24] Train loss=0.6142115592956543
[10/24] Train loss=0.720733106136322
[15/24] Train loss=0.6153814196586609
[20/24] Train loss=0.5815185308456421
Test set avg_accuracy=77.07% avg_sensitivity=84.41%, avg_specificity=74.60% avg_auc=86.89%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.674854 Test loss=0.536571 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.6747967004776001
[5/24] Train loss=0.612962007522583
[10/24] Train loss=0.7380300760269165
[15/24] Train loss=0.6335078477859497
[20/24] Train loss=0.5645343065261841
Test set avg_accuracy=77.43% avg_sensitivity=83.69%, avg_specificity=75.33% avg_auc=86.88%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.674477 Test loss=0.524449 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.653471827507019
[5/24] Train loss=0.619248628616333
[10/24] Train loss=0.7491143941879272
[15/24] Train loss=0.6161379218101501
[20/24] Train loss=0.5655013918876648
Test set avg_accuracy=77.51% avg_sensitivity=84.41%, avg_specificity=75.20% avg_auc=87.00%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.671738 Test loss=0.526925 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.6701071858406067
[5/24] Train loss=0.621544599533081
[10/24] Train loss=0.749975860118866
[15/24] Train loss=0.6193041205406189
[20/24] Train loss=0.5640817880630493
Test set avg_accuracy=77.64% avg_sensitivity=83.95%, avg_specificity=75.53% avg_auc=87.03%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.675725 Test loss=0.522715 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.6594333648681641
[5/24] Train loss=0.6143041253089905
[10/24] Train loss=0.7463308572769165
[15/24] Train loss=0.6113426685333252
[20/24] Train loss=0.5783942937850952
Test set avg_accuracy=77.15% avg_sensitivity=85.09%, avg_specificity=74.48% avg_auc=87.18%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.673159 Test loss=0.527714 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.6505601406097412
[5/24] Train loss=0.6349247097969055
[10/24] Train loss=0.7588635683059692
[15/24] Train loss=0.6123326420783997
[20/24] Train loss=0.5688071250915527
Test set avg_accuracy=77.11% avg_sensitivity=85.91%, avg_specificity=74.15% avg_auc=87.28%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.672314 Test loss=0.531115 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.6476712226867676
[5/24] Train loss=0.6387621164321899
[10/24] Train loss=0.7564590573310852
[15/24] Train loss=0.5972784757614136
[20/24] Train loss=0.5696045756340027
Test set avg_accuracy=76.88% avg_sensitivity=85.86%, avg_specificity=73.86% avg_auc=87.26%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.671979 Test loss=0.533403 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.6645002961158752
[5/24] Train loss=0.6053174734115601
[10/24] Train loss=0.7523568272590637
[15/24] Train loss=0.6088870167732239
[20/24] Train loss=0.5769254565238953
Test set avg_accuracy=76.30% avg_sensitivity=86.90%, avg_specificity=72.74% avg_auc=87.36%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.667030 Test loss=0.547671 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.6533923149108887
[5/24] Train loss=0.618362307548523
[10/24] Train loss=0.733081579208374
[15/24] Train loss=0.6002881526947021
[20/24] Train loss=0.5935637354850769
Test set avg_accuracy=75.74% avg_sensitivity=87.52%, avg_specificity=71.79% avg_auc=87.33%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.667727 Test loss=0.560773 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.6617515683174133
[5/24] Train loss=0.6189533472061157
[10/24] Train loss=0.7452784776687622
[15/24] Train loss=0.6161433458328247
[20/24] Train loss=0.6118913292884827
Test set avg_accuracy=75.65% avg_sensitivity=87.57%, avg_specificity=71.65% avg_auc=87.34%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.669579 Test loss=0.562025 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.6625699996948242
[5/24] Train loss=0.5909520983695984
[10/24] Train loss=0.7300511002540588
[15/24] Train loss=0.5917050838470459
[20/24] Train loss=0.5964155793190002
Test set avg_accuracy=76.60% avg_sensitivity=86.22%, avg_specificity=73.37% avg_auc=87.25%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.666343 Test loss=0.539743 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6544240117073059
[5/24] Train loss=0.5873252153396606
[10/24] Train loss=0.7420489192008972
[15/24] Train loss=0.6146188378334045
[20/24] Train loss=0.5862732529640198
Test set avg_accuracy=77.66% avg_sensitivity=85.09%, avg_specificity=75.16% avg_auc=87.29%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.664050 Test loss=0.515611 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.650419294834137
[5/24] Train loss=0.5843427777290344
[10/24] Train loss=0.7454733848571777
[15/24] Train loss=0.600888192653656
[20/24] Train loss=0.5729019641876221
Test set avg_accuracy=77.83% avg_sensitivity=84.83%, avg_specificity=75.47% avg_auc=87.29%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.660785 Test loss=0.510730 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.6603999137878418
[5/24] Train loss=0.6042395234107971
[10/24] Train loss=0.7473338842391968
[15/24] Train loss=0.6191840171813965
[20/24] Train loss=0.558420717716217
Test set avg_accuracy=77.80% avg_sensitivity=84.83%, avg_specificity=75.44% avg_auc=87.29%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.662656 Test loss=0.512420 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.6548847556114197
[5/24] Train loss=0.5956293940544128
[10/24] Train loss=0.7365392446517944
[15/24] Train loss=0.59144127368927
[20/24] Train loss=0.5867708921432495
Test set avg_accuracy=77.28% avg_sensitivity=84.83%, avg_specificity=74.74% avg_auc=87.19%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.661104 Test loss=0.521488 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.6606411933898926
[5/24] Train loss=0.5942952632904053
[10/24] Train loss=0.733722448348999
[15/24] Train loss=0.5959306359291077
[20/24] Train loss=0.5624121427536011
Test set avg_accuracy=77.06% avg_sensitivity=84.83%, avg_specificity=74.45% avg_auc=87.12%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.660838 Test loss=0.524419 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.6659504175186157
[5/24] Train loss=0.5969720482826233
[10/24] Train loss=0.7390687465667725
[15/24] Train loss=0.6016280055046082
[20/24] Train loss=0.5489976406097412
Test set avg_accuracy=77.55% avg_sensitivity=84.57%, avg_specificity=75.20% avg_auc=87.22%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.658630 Test loss=0.515085 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.6408493518829346
[5/24] Train loss=0.5925018787384033
[10/24] Train loss=0.7204456925392151
[15/24] Train loss=0.596497654914856
[20/24] Train loss=0.5635896921157837
Test set avg_accuracy=77.27% avg_sensitivity=84.83%, avg_specificity=74.73% avg_auc=87.12%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.658043 Test loss=0.523168 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.6502219438552856
[5/24] Train loss=0.5920076966285706
[10/24] Train loss=0.7293226718902588
[15/24] Train loss=0.5885784029960632
[20/24] Train loss=0.5559242367744446
Test set avg_accuracy=77.54% avg_sensitivity=84.52%, avg_specificity=75.20% avg_auc=87.13%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.655613 Test loss=0.520439 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.6491568088531494
[5/24] Train loss=0.6042872071266174
[10/24] Train loss=0.7322048544883728
[15/24] Train loss=0.6128740906715393
[20/24] Train loss=0.5648587942123413
Test set avg_accuracy=77.58% avg_sensitivity=84.62%, avg_specificity=75.21% avg_auc=87.11%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.657076 Test loss=0.519814 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.6618780493736267
[5/24] Train loss=0.5916364192962646
[10/24] Train loss=0.7428222894668579
[15/24] Train loss=0.6095467209815979
[20/24] Train loss=0.5609012246131897
Test set avg_accuracy=77.02% avg_sensitivity=84.57%, avg_specificity=74.48% avg_auc=87.04%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.658706 Test loss=0.529384 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.6448975801467896
[5/24] Train loss=0.6077399849891663
[10/24] Train loss=0.7104935646057129
[15/24] Train loss=0.5910068154335022
[20/24] Train loss=0.5679364800453186
Test set avg_accuracy=76.84% avg_sensitivity=84.67%, avg_specificity=74.20% avg_auc=86.99%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.656660 Test loss=0.534726 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.6471341848373413
[5/24] Train loss=0.5707589387893677
[10/24] Train loss=0.7077674865722656
[15/24] Train loss=0.6012315154075623
[20/24] Train loss=0.5536184310913086
Test set avg_accuracy=76.76% avg_sensitivity=85.45%, avg_specificity=73.84% avg_auc=87.09%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.649986 Test loss=0.539811 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.6463583707809448
[5/24] Train loss=0.5942506194114685
[10/24] Train loss=0.7123990654945374
[15/24] Train loss=0.594038188457489
[20/24] Train loss=0.5420978665351868
Test set avg_accuracy=76.63% avg_sensitivity=85.40%, avg_specificity=73.68% avg_auc=87.01%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.653432 Test loss=0.542678 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.6603073477745056
[5/24] Train loss=0.5955421924591064
[10/24] Train loss=0.7339794635772705
[15/24] Train loss=0.5954388380050659
[20/24] Train loss=0.5406372547149658
Test set avg_accuracy=76.52% avg_sensitivity=85.29%, avg_specificity=73.58% avg_auc=87.02%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.656532 Test loss=0.541543 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.6331885457038879
[5/24] Train loss=0.6002811193466187
[10/24] Train loss=0.735410749912262
[15/24] Train loss=0.5997205376625061
[20/24] Train loss=0.5386092066764832
Test set avg_accuracy=76.21% avg_sensitivity=85.60%, avg_specificity=73.06% avg_auc=87.04%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.652963 Test loss=0.548961 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.6463763117790222
[5/24] Train loss=0.582207202911377
[10/24] Train loss=0.7337134480476379
[15/24] Train loss=0.5918332934379578
[20/24] Train loss=0.5527706146240234
Test set avg_accuracy=75.82% avg_sensitivity=86.64%, avg_specificity=72.19% avg_auc=87.04%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.654638 Test loss=0.564281 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.6435824632644653
[5/24] Train loss=0.5784146785736084
[10/24] Train loss=0.7103028893470764
[15/24] Train loss=0.590721845626831
[20/24] Train loss=0.5562679767608643
Test set avg_accuracy=75.36% avg_sensitivity=86.79%, avg_specificity=71.53% avg_auc=87.02%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.651932 Test loss=0.572733 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.6437220573425293
[5/24] Train loss=0.5765324831008911
[10/24] Train loss=0.7098503708839417
[15/24] Train loss=0.5981460213661194
[20/24] Train loss=0.5581377744674683
Test set avg_accuracy=75.99% avg_sensitivity=86.38%, avg_specificity=72.50% avg_auc=87.04%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.650872 Test loss=0.559921 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.6543470025062561
[5/24] Train loss=0.5864158272743225
[10/24] Train loss=0.7214078903198242
[15/24] Train loss=0.6048089265823364
[20/24] Train loss=0.5779311060905457
Test set avg_accuracy=76.71% avg_sensitivity=85.14%, avg_specificity=73.87% avg_auc=86.98%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.653263 Test loss=0.540146 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.6468383073806763
[5/24] Train loss=0.5733587145805359
[10/24] Train loss=0.7118362784385681
[15/24] Train loss=0.5939489006996155
[20/24] Train loss=0.5695402026176453
Test set avg_accuracy=76.84% avg_sensitivity=84.77%, avg_specificity=74.17% avg_auc=86.96%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.649048 Test loss=0.536055 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.6235415935516357
[5/24] Train loss=0.583445131778717
[10/24] Train loss=0.7287077903747559
[15/24] Train loss=0.591641366481781
[20/24] Train loss=0.5533798933029175
Test set avg_accuracy=76.71% avg_sensitivity=85.03%, avg_specificity=73.91% avg_auc=86.99%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.649395 Test loss=0.538828 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.6456717848777771
[5/24] Train loss=0.5855423808097839
[10/24] Train loss=0.7359688878059387
[15/24] Train loss=0.592732846736908
[20/24] Train loss=0.5616059899330139
Test set avg_accuracy=76.88% avg_sensitivity=84.62%, avg_specificity=74.27% avg_auc=86.98%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.651961 Test loss=0.534532 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.6385579705238342
[5/24] Train loss=0.5908645987510681
[10/24] Train loss=0.7206626534461975
[15/24] Train loss=0.6114205718040466
[20/24] Train loss=0.5526046752929688
Test set avg_accuracy=76.71% avg_sensitivity=84.93%, avg_specificity=73.94% avg_auc=86.96%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.653489 Test loss=0.538122 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.6392567157745361
[5/24] Train loss=0.5757190585136414
[10/24] Train loss=0.7203335165977478
[15/24] Train loss=0.593417763710022
[20/24] Train loss=0.5644232630729675
Test set avg_accuracy=76.80% avg_sensitivity=84.77%, avg_specificity=74.12% avg_auc=86.95%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.649551 Test loss=0.536241 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.6522876620292664
[5/24] Train loss=0.5949073433876038
[10/24] Train loss=0.7165368795394897
[15/24] Train loss=0.6086979508399963
[20/24] Train loss=0.5554364919662476
Test set avg_accuracy=76.86% avg_sensitivity=84.72%, avg_specificity=74.22% avg_auc=86.97%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.651638 Test loss=0.535197 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.6375898122787476
[5/24] Train loss=0.5940568447113037
[10/24] Train loss=0.7254297137260437
[15/24] Train loss=0.591122031211853
[20/24] Train loss=0.5606924891471863
Test set avg_accuracy=77.07% avg_sensitivity=84.46%, avg_specificity=74.59% avg_auc=86.95%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.651029 Test loss=0.531746 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.6434981226921082
[5/24] Train loss=0.5724659562110901
[10/24] Train loss=0.7077323198318481
[15/24] Train loss=0.587990403175354
[20/24] Train loss=0.561475396156311
Test set avg_accuracy=76.82% avg_sensitivity=84.62%, avg_specificity=74.20% avg_auc=86.95%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.649361 Test loss=0.535142 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.6502572894096375
[5/24] Train loss=0.5883826017379761
[10/24] Train loss=0.724461555480957
[15/24] Train loss=0.6015658378601074
[20/24] Train loss=0.5567590594291687
Test set avg_accuracy=76.80% avg_sensitivity=84.62%, avg_specificity=74.17% avg_auc=86.95%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.652095 Test loss=0.535544 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.6224476099014282
[5/24] Train loss=0.5920157432556152
[10/24] Train loss=0.7136319279670715
[15/24] Train loss=0.5770620107650757
[20/24] Train loss=0.5562350749969482
Test set avg_accuracy=77.02% avg_sensitivity=84.52%, avg_specificity=74.50% avg_auc=86.95%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.646957 Test loss=0.532757 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.6512978076934814
[5/24] Train loss=0.5850854516029358
[10/24] Train loss=0.728165328502655
[15/24] Train loss=0.6024287343025208
[20/24] Train loss=0.5595914721488953
Test set avg_accuracy=77.03% avg_sensitivity=84.52%, avg_specificity=74.52% avg_auc=86.95%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.651635 Test loss=0.532440 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.6478522419929504
[5/24] Train loss=0.5749351978302002
[10/24] Train loss=0.7187058925628662
[15/24] Train loss=0.605015218257904
[20/24] Train loss=0.5442774891853333
Test set avg_accuracy=76.99% avg_sensitivity=84.52%, avg_specificity=74.47% avg_auc=86.95%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.648631 Test loss=0.532912 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.6503388285636902
[5/24] Train loss=0.5755364298820496
[10/24] Train loss=0.7056488394737244
[15/24] Train loss=0.5892927646636963
[20/24] Train loss=0.5726204514503479
Test set avg_accuracy=76.99% avg_sensitivity=84.52%, avg_specificity=74.47% avg_auc=86.95%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.646951 Test loss=0.532949 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.6432541012763977
[5/24] Train loss=0.5699162483215332
[10/24] Train loss=0.7126436233520508
[15/24] Train loss=0.5758402943611145
[20/24] Train loss=0.5583577156066895
Test set avg_accuracy=76.99% avg_sensitivity=84.52%, avg_specificity=74.47% avg_auc=86.95%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.646133 Test loss=0.532924 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=75.66% sen=87.42%, spe=71.72%, auc=87.55%!
Fold[8] Avg_jsc=0.55%(±0.24379561515856216)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/23] Train loss=2.386704683303833
[5/23] Train loss=2.1786839962005615
[10/23] Train loss=2.0205979347229004
[15/23] Train loss=1.861080288887024
[20/23] Train loss=1.79386568069458
Test set avg_accuracy=51.55% avg_sensitivity=47.55%, avg_specificity=52.82% avg_auc=50.35%
Best model saved!! Metric=50.35342132966232!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=2.013595 Test loss=0.824546 Current lr=[1.23514552994466e-05]

[0/23] Train loss=1.7893422842025757
[5/23] Train loss=1.6981393098831177
[10/23] Train loss=1.6233322620391846
[15/23] Train loss=1.6633230447769165
[20/23] Train loss=1.5879223346710205
Test set avg_accuracy=55.92% avg_sensitivity=41.29%, avg_specificity=60.58% avg_auc=51.40%
Best model saved!! Metric=51.40066402137825!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=1.661935 Test loss=0.710268 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=1.6326735019683838
[5/23] Train loss=1.605908751487732
[10/23] Train loss=1.58476722240448
[15/23] Train loss=1.5789875984191895
[20/23] Train loss=1.5437978506088257
Test set avg_accuracy=52.46% avg_sensitivity=52.83%, avg_specificity=52.34% avg_auc=53.76%
Best model saved!! Metric=53.75689413833392!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=1.573877 Test loss=0.715805 Current lr=[1.515281266696464e-05]

[0/23] Train loss=1.5645811557769775
[5/23] Train loss=1.5347018241882324
[10/23] Train loss=1.5152689218521118
[15/23] Train loss=1.5026401281356812
[20/23] Train loss=1.4858309030532837
Test set avg_accuracy=52.54% avg_sensitivity=58.33%, avg_specificity=50.70% avg_auc=56.24%
Best model saved!! Metric=56.2441146188818!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=1.516275 Test loss=0.712861 Current lr=[1.758904040319645e-05]

[0/23] Train loss=1.4917265176773071
[5/23] Train loss=1.5032272338867188
[10/23] Train loss=1.5013105869293213
[15/23] Train loss=1.4908844232559204
[20/23] Train loss=1.4477901458740234
Test set avg_accuracy=56.73% avg_sensitivity=57.68%, avg_specificity=56.43% avg_auc=58.92%
Best model saved!! Metric=58.92214291498444!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=1.479219 Test loss=0.689271 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=1.47017502784729
[5/23] Train loss=1.431308388710022
[10/23] Train loss=1.47724187374115
[15/23] Train loss=1.4446173906326294
[20/23] Train loss=1.4434624910354614
Test set avg_accuracy=60.23% avg_sensitivity=55.90%, avg_specificity=61.61% avg_auc=61.40%
Best model saved!! Metric=61.395772937079926!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=1.450699 Test loss=0.670586 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=1.4196447134017944
[5/23] Train loss=1.4236321449279785
[10/23] Train loss=1.4246231317520142
[15/23] Train loss=1.407479166984558
[20/23] Train loss=1.4097020626068115
Test set avg_accuracy=59.39% avg_sensitivity=61.24%, avg_specificity=58.80% avg_auc=63.89%
Best model saved!! Metric=63.89148918940805!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=1.422614 Test loss=0.671956 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=1.4067869186401367
[5/23] Train loss=1.3942800760269165
[10/23] Train loss=1.421956181526184
[15/23] Train loss=1.3996025323867798
[20/23] Train loss=1.372981309890747
Test set avg_accuracy=61.85% avg_sensitivity=60.92%, avg_specificity=62.15% avg_auc=66.04%
Best model saved!! Metric=66.03534352116424!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=1.405115 Test loss=0.659329 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=1.3719453811645508
[5/23] Train loss=1.3811564445495605
[10/23] Train loss=1.3855376243591309
[15/23] Train loss=1.3521360158920288
[20/23] Train loss=1.3488283157348633
Test set avg_accuracy=63.75% avg_sensitivity=62.16%, avg_specificity=64.26% avg_auc=68.28%
Best model saved!! Metric=68.28354869682911!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=1.377638 Test loss=0.647510 Current lr=[3.955300715542903e-05]

[0/23] Train loss=1.3572075366973877
[5/23] Train loss=1.353291392326355
[10/23] Train loss=1.36630117893219
[15/23] Train loss=1.3112763166427612
[20/23] Train loss=1.319854497909546
Test set avg_accuracy=65.59% avg_sensitivity=64.31%, avg_specificity=65.99% avg_auc=70.30%
Best model saved!! Metric=70.29507536758327!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=1.349573 Test loss=0.635991 Current lr=[4.575212055041121e-05]

[0/23] Train loss=1.310573697090149
[5/23] Train loss=1.3242202997207642
[10/23] Train loss=1.349888801574707
[15/23] Train loss=1.2869902849197388
[20/23] Train loss=1.2858643531799316
Test set avg_accuracy=68.62% avg_sensitivity=63.50%, avg_specificity=70.25% avg_auc=72.32%
Best model saved!! Metric=72.31868861561954!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=1.317536 Test loss=0.614027 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=1.2830493450164795
[5/23] Train loss=1.2611631155014038
[10/23] Train loss=1.326019048690796
[15/23] Train loss=1.2384133338928223
[20/23] Train loss=1.2338863611221313
Test set avg_accuracy=70.74% avg_sensitivity=63.83%, avg_specificity=72.94% avg_auc=74.30%
Best model saved!! Metric=74.29640803766645!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=1.286152 Test loss=0.592196 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=1.203035831451416
[5/23] Train loss=1.2497929334640503
[10/23] Train loss=1.304656744003296
[15/23] Train loss=1.1931252479553223
[20/23] Train loss=1.2229009866714478
Test set avg_accuracy=69.96% avg_sensitivity=69.49%, avg_specificity=70.11% avg_auc=76.22%
Best model saved!! Metric=76.21722985088441!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=1.249683 Test loss=0.597287 Current lr=[6.744438065180833e-05]

[0/23] Train loss=1.1735758781433105
[5/23] Train loss=1.1801987886428833
[10/23] Train loss=1.2690545320510864
[15/23] Train loss=1.165635347366333
[20/23] Train loss=1.156212329864502
Test set avg_accuracy=69.92% avg_sensitivity=74.34%, avg_specificity=68.52% avg_auc=78.10%
Best model saved!! Metric=78.10380481936073!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=1.208306 Test loss=0.594694 Current lr=[7.558910265967854e-05]

[0/23] Train loss=1.1204702854156494
[5/23] Train loss=1.132043719291687
[10/23] Train loss=1.2304022312164307
[15/23] Train loss=1.1312899589538574
[20/23] Train loss=1.1132068634033203
Test set avg_accuracy=68.65% avg_sensitivity=80.38%, avg_specificity=64.91% avg_auc=80.06%
Best model saved!! Metric=80.06020614740349!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=1.164328 Test loss=0.604642 Current lr=[8.412633627870859e-05]

[0/23] Train loss=1.1066398620605469
[5/23] Train loss=1.0926454067230225
[10/23] Train loss=1.1952385902404785
[15/23] Train loss=1.1022491455078125
[20/23] Train loss=1.0724060535430908
Test set avg_accuracy=69.79% avg_sensitivity=81.35%, avg_specificity=66.11% avg_auc=81.67%
Best model saved!! Metric=81.6726305195331!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=1.122816 Test loss=0.583425 Current lr=[9.301440850892597e-05]

[0/23] Train loss=1.0446149110794067
[5/23] Train loss=1.029125690460205
[10/23] Train loss=1.1563090085983276
[15/23] Train loss=1.0712155103683472
[20/23] Train loss=1.0280413627624512
Test set avg_accuracy=72.16% avg_sensitivity=80.38%, avg_specificity=69.55% avg_auc=82.96%
Best model saved!! Metric=82.95787975891628!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=1.082363 Test loss=0.546469 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.9793651700019836
[5/23] Train loss=1.0015733242034912
[10/23] Train loss=1.1352195739746094
[15/23] Train loss=1.0461573600769043
[20/23] Train loss=0.9919358491897583
Test set avg_accuracy=71.52% avg_sensitivity=83.13%, avg_specificity=67.83% avg_auc=83.92%
Best model saved!! Metric=83.91933181402774!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=1.045739 Test loss=0.552436 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.9675953388214111
[5/23] Train loss=0.9667628407478333
[10/23] Train loss=1.088985800743103
[15/23] Train loss=1.0089387893676758
[20/23] Train loss=0.9683923721313477
Test set avg_accuracy=73.01% avg_sensitivity=81.94%, avg_specificity=70.16% avg_auc=84.57%
Best model saved!! Metric=84.56713441227167!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=1.023575 Test loss=0.528292 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.9475970268249512
[5/23] Train loss=0.9494982957839966
[10/23] Train loss=1.075650930404663
[15/23] Train loss=0.9929870963096619
[20/23] Train loss=0.9558782577514648
Test set avg_accuracy=74.38% avg_sensitivity=80.11%, avg_specificity=72.55% avg_auc=85.08%
Best model saved!! Metric=85.08171164813807!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=1.003829 Test loss=0.502297 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.9235106110572815
[5/23] Train loss=0.9362682104110718
[10/23] Train loss=1.0499727725982666
[15/23] Train loss=0.9678205847740173
[20/23] Train loss=0.9427623748779297
Test set avg_accuracy=75.39% avg_sensitivity=79.78%, avg_specificity=73.99% avg_auc=85.56%
Best model saved!! Metric=85.56291660400494!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.984937 Test loss=0.489391 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.9182388782501221
[5/23] Train loss=0.9335110187530518
[10/23] Train loss=1.053314208984375
[15/23] Train loss=0.9511801600456238
[20/23] Train loss=0.9160775542259216
Test set avg_accuracy=76.30% avg_sensitivity=79.03%, avg_specificity=75.43% avg_auc=85.93%
Best model saved!! Metric=85.92815612600208!!
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.971578 Test loss=0.475791 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.8862805962562561
[5/23] Train loss=0.9117540121078491
[10/23] Train loss=1.047062873840332
[15/23] Train loss=0.9340791702270508
[20/23] Train loss=0.8912431597709656
Test set avg_accuracy=77.02% avg_sensitivity=78.98%, avg_specificity=76.39% avg_auc=86.20%
Best model saved!! Metric=86.20335249817799!!
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.955870 Test loss=0.469585 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.8844072222709656
[5/23] Train loss=0.8947252631187439
[10/23] Train loss=1.0331484079360962
[15/23] Train loss=0.9221727252006531
[20/23] Train loss=0.902651846408844
Test set avg_accuracy=76.32% avg_sensitivity=80.97%, avg_specificity=74.83% avg_auc=86.53%
Best model saved!! Metric=86.53011117152343!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.942454 Test loss=0.480189 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.8951898217201233
[5/23] Train loss=0.8786536455154419
[10/23] Train loss=1.0210994482040405
[15/23] Train loss=0.8988432288169861
[20/23] Train loss=0.8883829116821289
Test set avg_accuracy=76.03% avg_sensitivity=83.61%, avg_specificity=73.61% avg_auc=86.80%
Best model saved!! Metric=86.80260518491954!!
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.925907 Test loss=0.492802 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.887645423412323
[5/23] Train loss=0.8776929974555969
[10/23] Train loss=1.022143006324768
[15/23] Train loss=0.8845723271369934
[20/23] Train loss=0.8841066360473633
Test set avg_accuracy=75.59% avg_sensitivity=84.53%, avg_specificity=72.74% avg_auc=86.96%
Best model saved!! Metric=86.95770392050252!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.918773 Test loss=0.503175 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.8787438273429871
[5/23] Train loss=0.8753023147583008
[10/23] Train loss=1.010601282119751
[15/23] Train loss=0.8790014982223511
[20/23] Train loss=0.8599799275398254
Test set avg_accuracy=75.99% avg_sensitivity=84.91%, avg_specificity=73.15% avg_auc=87.14%
Best model saved!! Metric=87.13966891477621!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.912763 Test loss=0.499077 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.8812762498855591
[5/23] Train loss=0.8429501056671143
[10/23] Train loss=1.0109201669692993
[15/23] Train loss=0.8636355996131897
[20/23] Train loss=0.8785570859909058
Test set avg_accuracy=75.83% avg_sensitivity=85.12%, avg_specificity=72.88% avg_auc=87.20%
Best model saved!! Metric=87.20357692352187!!
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.902691 Test loss=0.498949 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.872174859046936
[5/23] Train loss=0.8619555234909058
[10/23] Train loss=1.0005698204040527
[15/23] Train loss=0.8604760766029358
[20/23] Train loss=0.8541576862335205
Test set avg_accuracy=76.13% avg_sensitivity=85.01%, avg_specificity=73.30% avg_auc=87.36%
Best model saved!! Metric=87.35538562983699!!
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.895487 Test loss=0.494362 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.859744131565094
[5/23] Train loss=0.862308144569397
[10/23] Train loss=0.9787497520446777
[15/23] Train loss=0.8464938402175903
[20/23] Train loss=0.8486782312393188
Test set avg_accuracy=76.77% avg_sensitivity=85.01%, avg_specificity=74.15% avg_auc=87.46%
Best model saved!! Metric=87.46055551056766!!
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.887527 Test loss=0.494306 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.8481149673461914
[5/23] Train loss=0.8503746390342712
[10/23] Train loss=0.9829190969467163
[15/23] Train loss=0.8285582661628723
[20/23] Train loss=0.8472235798835754
Test set avg_accuracy=77.08% avg_sensitivity=84.91%, avg_specificity=74.59% avg_auc=87.59%
Best model saved!! Metric=87.59255463137559!!
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.880336 Test loss=0.488007 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.8337408900260925
[5/23] Train loss=0.8679633140563965
[10/23] Train loss=0.9887029528617859
[15/23] Train loss=0.823180079460144
[20/23] Train loss=0.8506509065628052
Test set avg_accuracy=76.72% avg_sensitivity=85.23%, avg_specificity=74.01% avg_auc=87.64%
Best model saved!! Metric=87.64423261571208!!
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.875991 Test loss=0.492980 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.8376601338386536
[5/23] Train loss=0.8552091121673584
[10/23] Train loss=0.9752911329269409
[15/23] Train loss=0.8167117238044739
[20/23] Train loss=0.8252110481262207
Test set avg_accuracy=77.14% avg_sensitivity=85.34%, avg_specificity=74.52% avg_auc=87.75%
Best model saved!! Metric=87.74925442198905!!
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.867408 Test loss=0.487847 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.8239917755126953
[5/23] Train loss=0.8259721398353577
[10/23] Train loss=0.967266321182251
[15/23] Train loss=0.8000484704971313
[20/23] Train loss=0.8281920552253723
Test set avg_accuracy=77.75% avg_sensitivity=84.85%, avg_specificity=75.48% avg_auc=87.80%
Best model saved!! Metric=87.7999884316833!!
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.859945 Test loss=0.479205 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.8289364576339722
[5/23] Train loss=0.8414304256439209
[10/23] Train loss=0.9822424054145813
[15/23] Train loss=0.7877526879310608
[20/23] Train loss=0.8280518651008606
Test set avg_accuracy=77.38% avg_sensitivity=85.01%, avg_specificity=74.95% avg_auc=87.87%
Best model saved!! Metric=87.86578438971344!!
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.855222 Test loss=0.484192 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.8118727803230286
[5/23] Train loss=0.8360314965248108
[10/23] Train loss=0.9746521711349487
[15/23] Train loss=0.7896285057067871
[20/23] Train loss=0.8218937516212463
Test set avg_accuracy=77.76% avg_sensitivity=85.23%, avg_specificity=75.38% avg_auc=87.90%
Best model saved!! Metric=87.90443644945225!!
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.849618 Test loss=0.481710 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.808540940284729
[5/23] Train loss=0.8325914144515991
[10/23] Train loss=0.9668775200843811
[15/23] Train loss=0.7806392908096313
[20/23] Train loss=0.8232218623161316
Test set avg_accuracy=77.88% avg_sensitivity=84.85%, avg_specificity=75.66% avg_auc=87.92%
Best model saved!! Metric=87.91980380134888!!
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.844606 Test loss=0.478837 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.8032180070877075
[5/23] Train loss=0.8334251046180725
[10/23] Train loss=0.9450386762619019
[15/23] Train loss=0.7740250825881958
[20/23] Train loss=0.8185551166534424
Test set avg_accuracy=77.81% avg_sensitivity=85.07%, avg_specificity=75.50% avg_auc=87.92%
Best model saved!! Metric=87.92396376803211!!
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.838026 Test loss=0.481171 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.8162299394607544
[5/23] Train loss=0.8126255869865417
[10/23] Train loss=0.9540959000587463
[15/23] Train loss=0.7762750387191772
[20/23] Train loss=0.8042442202568054
Test set avg_accuracy=78.01% avg_sensitivity=84.64%, avg_specificity=75.90% avg_auc=87.96%
Best model saved!! Metric=87.96386983330055!!
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.832250 Test loss=0.475679 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.7932973504066467
[5/23] Train loss=0.8088619709014893
[10/23] Train loss=0.9351314902305603
[15/23] Train loss=0.7621200084686279
[20/23] Train loss=0.8061580061912537
Test set avg_accuracy=78.48% avg_sensitivity=84.42%, avg_specificity=76.58% avg_auc=87.98%
Best model saved!! Metric=87.97951945212452!!
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.820925 Test loss=0.471412 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.790900468826294
[5/23] Train loss=0.7927795648574829
[10/23] Train loss=0.9342805743217468
[15/23] Train loss=0.7568426132202148
[20/23] Train loss=0.7863363027572632
Test set avg_accuracy=78.55% avg_sensitivity=83.40%, avg_specificity=77.01% avg_auc=87.98%
Best model saved!! Metric=87.98469280335019!!
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.816135 Test loss=0.462335 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.7782670855522156
[5/23] Train loss=0.7960529923439026
[10/23] Train loss=0.9324327707290649
[15/23] Train loss=0.7542774081230164
[20/23] Train loss=0.787436842918396
Test set avg_accuracy=78.84% avg_sensitivity=82.48%, avg_specificity=77.68% avg_auc=88.03%
Best model saved!! Metric=88.02574181830802!!
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.810773 Test loss=0.452326 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.7725282311439514
[5/23] Train loss=0.7850052118301392
[10/23] Train loss=0.928619921207428
[15/23] Train loss=0.747553288936615
[20/23] Train loss=0.7745469808578491
Test set avg_accuracy=78.61% avg_sensitivity=83.34%, avg_specificity=77.10% avg_auc=88.01%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.809089 Test loss=0.461554 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.7645968794822693
[5/23] Train loss=0.7816950678825378
[10/23] Train loss=0.9189499616622925
[15/23] Train loss=0.7394302487373352
[20/23] Train loss=0.7761029601097107
Test set avg_accuracy=78.85% avg_sensitivity=83.77%, avg_specificity=77.29% avg_auc=88.11%
Best model saved!! Metric=88.11111136818481!!
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.800948 Test loss=0.462394 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.7637896537780762
[5/23] Train loss=0.7728477716445923
[10/23] Train loss=0.908866822719574
[15/23] Train loss=0.7478492856025696
[20/23] Train loss=0.7816556692123413
Test set avg_accuracy=78.26% avg_sensitivity=84.58%, avg_specificity=76.24% avg_auc=88.09%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.796616 Test loss=0.474565 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.7740290760993958
[5/23] Train loss=0.778296172618866
[10/23] Train loss=0.8858499526977539
[15/23] Train loss=0.7516406178474426
[20/23] Train loss=0.7731266617774963
Test set avg_accuracy=77.93% avg_sensitivity=84.96%, avg_specificity=75.69% avg_auc=88.13%
Best model saved!! Metric=88.12642781948799!!
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.794459 Test loss=0.481630 Current lr=[0.000299926900870094]

[0/23] Train loss=0.7665789127349854
[5/23] Train loss=0.7792094349861145
[10/23] Train loss=0.8803330659866333
[15/23] Train loss=0.7234488725662231
[20/23] Train loss=0.7594426870346069
Test set avg_accuracy=78.62% avg_sensitivity=83.94%, avg_specificity=76.93% avg_auc=88.09%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.784988 Test loss=0.469178 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.7553585171699524
[5/23] Train loss=0.7612881064414978
[10/23] Train loss=0.8705635666847229
[15/23] Train loss=0.7161783576011658
[20/23] Train loss=0.7585323452949524
Test set avg_accuracy=78.55% avg_sensitivity=83.29%, avg_specificity=77.05% avg_auc=88.08%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.779569 Test loss=0.465338 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.7594308853149414
[5/23] Train loss=0.7620454430580139
[10/23] Train loss=0.8621890544891357
[15/23] Train loss=0.7112446427345276
[20/23] Train loss=0.742026686668396
Test set avg_accuracy=78.80% avg_sensitivity=83.29%, avg_specificity=77.37% avg_auc=88.11%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.774598 Test loss=0.466157 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.7646498680114746
[5/23] Train loss=0.7622166275978088
[10/23] Train loss=0.8492266535758972
[15/23] Train loss=0.7194017767906189
[20/23] Train loss=0.7298234105110168
Test set avg_accuracy=78.78% avg_sensitivity=82.64%, avg_specificity=77.55% avg_auc=88.08%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.771109 Test loss=0.458330 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.7431641221046448
[5/23] Train loss=0.7518696784973145
[10/23] Train loss=0.8510435819625854
[15/23] Train loss=0.7073405385017395
[20/23] Train loss=0.7381991744041443
Test set avg_accuracy=78.98% avg_sensitivity=81.99%, avg_specificity=78.03% avg_auc=87.99%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.760847 Test loss=0.454025 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.7491117715835571
[5/23] Train loss=0.7435071468353271
[10/23] Train loss=0.8574931025505066
[15/23] Train loss=0.6978522539138794
[20/23] Train loss=0.7448807954788208
Test set avg_accuracy=79.36% avg_sensitivity=81.56%, avg_specificity=78.66% avg_auc=88.03%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.760466 Test loss=0.447745 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.7482906579971313
[5/23] Train loss=0.7518563866615295
[10/23] Train loss=0.8556318283081055
[15/23] Train loss=0.7043125629425049
[20/23] Train loss=0.7351007461547852
Test set avg_accuracy=78.66% avg_sensitivity=84.04%, avg_specificity=76.94% avg_auc=88.19%
Best model saved!! Metric=88.18561132769571!!
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.758295 Test loss=0.473320 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.7406114339828491
[5/23] Train loss=0.7564150094985962
[10/23] Train loss=0.8281590938568115
[15/23] Train loss=0.7027738094329834
[20/23] Train loss=0.7362620830535889
Test set avg_accuracy=78.26% avg_sensitivity=83.99%, avg_specificity=76.43% avg_auc=88.14%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.755796 Test loss=0.473694 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.7325599193572998
[5/23] Train loss=0.7290986180305481
[10/23] Train loss=0.8256049752235413
[15/23] Train loss=0.7059164047241211
[20/23] Train loss=0.7316871285438538
Test set avg_accuracy=78.65% avg_sensitivity=83.61%, avg_specificity=77.06% avg_auc=88.12%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.746468 Test loss=0.469115 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.7295507192611694
[5/23] Train loss=0.7373137474060059
[10/23] Train loss=0.8088753819465637
[15/23] Train loss=0.6949715614318848
[20/23] Train loss=0.7192578911781311
Test set avg_accuracy=78.40% avg_sensitivity=83.83%, avg_specificity=76.67% avg_auc=88.17%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.739733 Test loss=0.472613 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.7205148339271545
[5/23] Train loss=0.7275579571723938
[10/23] Train loss=0.8108240962028503
[15/23] Train loss=0.681128978729248
[20/23] Train loss=0.712983250617981
Test set avg_accuracy=79.13% avg_sensitivity=82.70%, avg_specificity=77.99% avg_auc=88.13%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.733736 Test loss=0.460514 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.7192409038543701
[5/23] Train loss=0.7258502244949341
[10/23] Train loss=0.796798825263977
[15/23] Train loss=0.6823148727416992
[20/23] Train loss=0.6967918872833252
Test set avg_accuracy=79.54% avg_sensitivity=81.62%, avg_specificity=78.88% avg_auc=88.07%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.730773 Test loss=0.451977 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.7104504108428955
[5/23] Train loss=0.7191377282142639
[10/23] Train loss=0.7860060930252075
[15/23] Train loss=0.6717960834503174
[20/23] Train loss=0.7189041376113892
Test set avg_accuracy=79.40% avg_sensitivity=82.10%, avg_specificity=78.54% avg_auc=88.06%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.723360 Test loss=0.457521 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.7164694666862488
[5/23] Train loss=0.7175576090812683
[10/23] Train loss=0.7875324487686157
[15/23] Train loss=0.6686192750930786
[20/23] Train loss=0.7023075222969055
Test set avg_accuracy=79.18% avg_sensitivity=82.21%, avg_specificity=78.21% avg_auc=88.06%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.720678 Test loss=0.459916 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.6979925036430359
[5/23] Train loss=0.7042720913887024
[10/23] Train loss=0.7869715690612793
[15/23] Train loss=0.6698084473609924
[20/23] Train loss=0.7027975916862488
Test set avg_accuracy=78.78% avg_sensitivity=83.56%, avg_specificity=77.25% avg_auc=88.08%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.717123 Test loss=0.471689 Current lr=[0.000283047938381597]

[0/23] Train loss=0.703099250793457
[5/23] Train loss=0.6977882981300354
[10/23] Train loss=0.7788006067276001
[15/23] Train loss=0.6583607196807861
[20/23] Train loss=0.6951649188995361
Test set avg_accuracy=78.89% avg_sensitivity=83.18%, avg_specificity=77.53% avg_auc=88.01%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.714025 Test loss=0.469421 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.700886607170105
[5/23] Train loss=0.6968461275100708
[10/23] Train loss=0.7712585926055908
[15/23] Train loss=0.6782951354980469
[20/23] Train loss=0.6829264760017395
Test set avg_accuracy=78.71% avg_sensitivity=83.50%, avg_specificity=77.18% avg_auc=88.12%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.711053 Test loss=0.474277 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.6910609006881714
[5/23] Train loss=0.726133406162262
[10/23] Train loss=0.7632995843887329
[15/23] Train loss=0.6565549969673157
[20/23] Train loss=0.6924442052841187
Test set avg_accuracy=78.61% avg_sensitivity=83.61%, avg_specificity=77.01% avg_auc=88.11%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.708867 Test loss=0.475279 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.6827197074890137
[5/23] Train loss=0.6898261308670044
[10/23] Train loss=0.7519524097442627
[15/23] Train loss=0.6607106924057007
[20/23] Train loss=0.6932342052459717
Test set avg_accuracy=78.55% avg_sensitivity=83.40%, avg_specificity=77.01% avg_auc=88.08%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.701856 Test loss=0.475213 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.6906226277351379
[5/23] Train loss=0.6800071001052856
[10/23] Train loss=0.7468196153640747
[15/23] Train loss=0.64515221118927
[20/23] Train loss=0.6691697835922241
Test set avg_accuracy=79.27% avg_sensitivity=82.10%, avg_specificity=78.37% avg_auc=88.03%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.695538 Test loss=0.463202 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.6819517612457275
[5/23] Train loss=0.6521483659744263
[10/23] Train loss=0.7215468883514404
[15/23] Train loss=0.6601173877716064
[20/23] Train loss=0.666479766368866
Test set avg_accuracy=79.26% avg_sensitivity=82.26%, avg_specificity=78.30% avg_auc=88.02%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.689245 Test loss=0.464746 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.6697487831115723
[5/23] Train loss=0.6583572626113892
[10/23] Train loss=0.7248731255531311
[15/23] Train loss=0.6452791690826416
[20/23] Train loss=0.6476561427116394
Test set avg_accuracy=79.69% avg_sensitivity=81.08%, avg_specificity=79.24% avg_auc=88.07%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.681626 Test loss=0.454215 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.6717674732208252
[5/23] Train loss=0.6599252223968506
[10/23] Train loss=0.7507955431938171
[15/23] Train loss=0.6267868876457214
[20/23] Train loss=0.6525050401687622
Test set avg_accuracy=79.77% avg_sensitivity=79.89%, avg_specificity=79.73% avg_auc=88.05%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.678700 Test loss=0.445772 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.6538580060005188
[5/23] Train loss=0.6566776633262634
[10/23] Train loss=0.72878497838974
[15/23] Train loss=0.6260067820549011
[20/23] Train loss=0.6597751379013062
Test set avg_accuracy=80.34% avg_sensitivity=79.35%, avg_specificity=80.65% avg_auc=88.06%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.673340 Test loss=0.439095 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.6481177806854248
[5/23] Train loss=0.6603250503540039
[10/23] Train loss=0.7136028409004211
[15/23] Train loss=0.6194257140159607
[20/23] Train loss=0.6473643779754639
Test set avg_accuracy=80.23% avg_sensitivity=78.60%, avg_specificity=80.76% avg_auc=88.01%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.673730 Test loss=0.438603 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.6559079885482788
[5/23] Train loss=0.6392502784729004
[10/23] Train loss=0.7348514199256897
[15/23] Train loss=0.6231594681739807
[20/23] Train loss=0.6532917618751526
Test set avg_accuracy=80.16% avg_sensitivity=78.92%, avg_specificity=80.55% avg_auc=88.06%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.669543 Test loss=0.440443 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.6465416550636292
[5/23] Train loss=0.6616759896278381
[10/23] Train loss=0.7335916757583618
[15/23] Train loss=0.6236520409584045
[20/23] Train loss=0.6423943042755127
Test set avg_accuracy=80.42% avg_sensitivity=79.25%, avg_specificity=80.79% avg_auc=88.05%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.667413 Test loss=0.437942 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.6418222188949585
[5/23] Train loss=0.6445849537849426
[10/23] Train loss=0.7151201367378235
[15/23] Train loss=0.6100355386734009
[20/23] Train loss=0.6308630108833313
Test set avg_accuracy=79.65% avg_sensitivity=81.13%, avg_specificity=79.18% avg_auc=88.16%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.659544 Test loss=0.454648 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.6526449918746948
[5/23] Train loss=0.6518731713294983
[10/23] Train loss=0.7131645679473877
[15/23] Train loss=0.6119040250778198
[20/23] Train loss=0.6349597573280334
Test set avg_accuracy=79.93% avg_sensitivity=80.65%, avg_specificity=79.71% avg_auc=88.05%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.660881 Test loss=0.453060 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.6375479102134705
[5/23] Train loss=0.6489783525466919
[10/23] Train loss=0.7105275392532349
[15/23] Train loss=0.6067315936088562
[20/23] Train loss=0.6387235522270203
Test set avg_accuracy=79.30% avg_sensitivity=81.51%, avg_specificity=78.59% avg_auc=88.04%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.658554 Test loss=0.464180 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.6342291831970215
[5/23] Train loss=0.6461700797080994
[10/23] Train loss=0.696861982345581
[15/23] Train loss=0.6200774908065796
[20/23] Train loss=0.6567013263702393
Test set avg_accuracy=79.53% avg_sensitivity=81.40%, avg_specificity=78.94% avg_auc=88.14%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.658583 Test loss=0.457259 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.6348363757133484
[5/23] Train loss=0.636882483959198
[10/23] Train loss=0.7001259326934814
[15/23] Train loss=0.6291805505752563
[20/23] Train loss=0.6260403394699097
Test set avg_accuracy=78.78% avg_sensitivity=82.91%, avg_specificity=77.46% avg_auc=88.13%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.654543 Test loss=0.476799 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.635760486125946
[5/23] Train loss=0.6292580366134644
[10/23] Train loss=0.6880509853363037
[15/23] Train loss=0.6186798214912415
[20/23] Train loss=0.6272857785224915
Test set avg_accuracy=79.10% avg_sensitivity=81.94%, avg_specificity=78.20% avg_auc=88.07%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.651351 Test loss=0.464612 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.6270681619644165
[5/23] Train loss=0.6074868440628052
[10/23] Train loss=0.680682361125946
[15/23] Train loss=0.6058142781257629
[20/23] Train loss=0.6253785490989685
Test set avg_accuracy=79.87% avg_sensitivity=78.92%, avg_specificity=80.17% avg_auc=88.01%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.645872 Test loss=0.443442 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.620607852935791
[5/23] Train loss=0.6004007458686829
[10/23] Train loss=0.6854729652404785
[15/23] Train loss=0.6027066707611084
[20/23] Train loss=0.6102628111839294
Test set avg_accuracy=79.87% avg_sensitivity=79.41%, avg_specificity=80.02% avg_auc=88.02%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.639702 Test loss=0.449161 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.6268565058708191
[5/23] Train loss=0.6061480641365051
[10/23] Train loss=0.6728384494781494
[15/23] Train loss=0.5879651308059692
[20/23] Train loss=0.623389482498169
Test set avg_accuracy=80.38% avg_sensitivity=77.41%, avg_specificity=81.32% avg_auc=87.91%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.636474 Test loss=0.435145 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.6118554472923279
[5/23] Train loss=0.6174789667129517
[10/23] Train loss=0.6664057970046997
[15/23] Train loss=0.5692703723907471
[20/23] Train loss=0.6074435114860535
Test set avg_accuracy=80.98% avg_sensitivity=77.20%, avg_specificity=82.18% avg_auc=87.91%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.633124 Test loss=0.429658 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.629291296005249
[5/23] Train loss=0.5911155939102173
[10/23] Train loss=0.6668851971626282
[15/23] Train loss=0.5934232473373413
[20/23] Train loss=0.6087399125099182
Test set avg_accuracy=80.55% avg_sensitivity=77.63%, avg_specificity=81.48% avg_auc=87.89%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.628777 Test loss=0.434620 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.6104200482368469
[5/23] Train loss=0.6154619455337524
[10/23] Train loss=0.6724331378936768
[15/23] Train loss=0.5801869034767151
[20/23] Train loss=0.6065307855606079
Test set avg_accuracy=80.60% avg_sensitivity=77.84%, avg_specificity=81.48% avg_auc=87.92%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.629483 Test loss=0.434128 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.6140836477279663
[5/23] Train loss=0.6053954362869263
[10/23] Train loss=0.6856346726417542
[15/23] Train loss=0.5724928379058838
[20/23] Train loss=0.6098058223724365
Test set avg_accuracy=80.10% avg_sensitivity=77.90%, avg_specificity=80.81% avg_auc=87.93%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.632101 Test loss=0.438840 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.601575493812561
[5/23] Train loss=0.6216112375259399
[10/23] Train loss=0.6598686575889587
[15/23] Train loss=0.557523250579834
[20/23] Train loss=0.6127550005912781
Test set avg_accuracy=81.04% avg_sensitivity=76.01%, avg_specificity=82.64% avg_auc=87.76%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.623835 Test loss=0.427921 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.6038650870323181
[5/23] Train loss=0.6067189574241638
[10/23] Train loss=0.6438254117965698
[15/23] Train loss=0.5838952660560608
[20/23] Train loss=0.6206318140029907
Test set avg_accuracy=81.35% avg_sensitivity=74.23%, avg_specificity=83.62% avg_auc=87.75%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.622837 Test loss=0.420071 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.5953565835952759
[5/23] Train loss=0.604119598865509
[10/23] Train loss=0.6620838642120361
[15/23] Train loss=0.576270580291748
[20/23] Train loss=0.6340406537055969
Test set avg_accuracy=81.63% avg_sensitivity=73.42%, avg_specificity=84.24% avg_auc=87.71%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.626896 Test loss=0.414458 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.6046369671821594
[5/23] Train loss=0.6148979663848877
[10/23] Train loss=0.6595481038093567
[15/23] Train loss=0.561917781829834
[20/23] Train loss=0.663529098033905
Test set avg_accuracy=80.95% avg_sensitivity=74.56%, avg_specificity=82.99% avg_auc=87.80%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.637104 Test loss=0.421892 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.5947273969650269
[5/23] Train loss=0.6698519587516785
[10/23] Train loss=0.7555900812149048
[15/23] Train loss=0.6202092170715332
[20/23] Train loss=0.6228610277175903
Test set avg_accuracy=74.23% avg_sensitivity=88.52%, avg_specificity=69.68% avg_auc=88.28%
Best model saved!! Metric=88.28341913168214!!
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.668598 Test loss=0.568974 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.6933358907699585
[5/23] Train loss=0.6084616780281067
[10/23] Train loss=0.6694970726966858
[15/23] Train loss=0.5620077252388
[20/23] Train loss=0.6249262690544128
Test set avg_accuracy=76.41% avg_sensitivity=85.82%, avg_specificity=73.41% avg_auc=88.13%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.640220 Test loss=0.526575 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.6252633929252625
[5/23] Train loss=0.5915893912315369
[10/23] Train loss=0.654907763004303
[15/23] Train loss=0.583783745765686
[20/23] Train loss=0.6257854700088501
Test set avg_accuracy=76.26% avg_sensitivity=85.82%, avg_specificity=73.22% avg_auc=88.06%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.623838 Test loss=0.530533 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.6182650327682495
[5/23] Train loss=0.5927301049232483
[10/23] Train loss=0.6565139889717102
[15/23] Train loss=0.5760091543197632
[20/23] Train loss=0.6080765128135681
Test set avg_accuracy=76.25% avg_sensitivity=85.61%, avg_specificity=73.27% avg_auc=88.08%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.623303 Test loss=0.526468 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.6325340867042542
[5/23] Train loss=0.5587925314903259
[10/23] Train loss=0.6408355832099915
[15/23] Train loss=0.5756810903549194
[20/23] Train loss=0.6100943088531494
Test set avg_accuracy=76.42% avg_sensitivity=85.55%, avg_specificity=73.51% avg_auc=88.00%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.618615 Test loss=0.529022 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.6404623985290527
[5/23] Train loss=0.5675489902496338
[10/23] Train loss=0.6501083970069885
[15/23] Train loss=0.5718428492546082
[20/23] Train loss=0.5854195952415466
Test set avg_accuracy=76.89% avg_sensitivity=85.07%, avg_specificity=74.28% avg_auc=88.00%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.612728 Test loss=0.515486 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.626147985458374
[5/23] Train loss=0.5659480690956116
[10/23] Train loss=0.6535983085632324
[15/23] Train loss=0.5725034475326538
[20/23] Train loss=0.6116276979446411
Test set avg_accuracy=76.37% avg_sensitivity=85.71%, avg_specificity=73.39% avg_auc=88.05%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.613795 Test loss=0.531739 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.613959550857544
[5/23] Train loss=0.5612828731536865
[10/23] Train loss=0.6596247553825378
[15/23] Train loss=0.5735020637512207
[20/23] Train loss=0.5975550413131714
Test set avg_accuracy=76.76% avg_sensitivity=85.01%, avg_specificity=74.13% avg_auc=88.02%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.610164 Test loss=0.521225 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.6062876582145691
[5/23] Train loss=0.5590460300445557
[10/23] Train loss=0.6277652382850647
[15/23] Train loss=0.556937038898468
[20/23] Train loss=0.5675987601280212
Test set avg_accuracy=77.23% avg_sensitivity=84.58%, avg_specificity=74.88% avg_auc=87.96%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.604970 Test loss=0.514934 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.6018933653831482
[5/23] Train loss=0.5463848114013672
[10/23] Train loss=0.6432825326919556
[15/23] Train loss=0.5596966743469238
[20/23] Train loss=0.5779280066490173
Test set avg_accuracy=77.59% avg_sensitivity=84.64%, avg_specificity=75.35% avg_auc=87.99%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.600745 Test loss=0.508234 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.6064286828041077
[5/23] Train loss=0.5560843348503113
[10/23] Train loss=0.6491764783859253
[15/23] Train loss=0.5602980852127075
[20/23] Train loss=0.5770678520202637
Test set avg_accuracy=76.91% avg_sensitivity=85.88%, avg_specificity=74.06% avg_auc=88.10%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.597779 Test loss=0.533049 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.6212045550346375
[5/23] Train loss=0.5619460940361023
[10/23] Train loss=0.6210018396377563
[15/23] Train loss=0.5602290034294128
[20/23] Train loss=0.5860148668289185
Test set avg_accuracy=77.53% avg_sensitivity=85.01%, avg_specificity=75.14% avg_auc=88.12%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.601786 Test loss=0.512090 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.5938183069229126
[5/23] Train loss=0.5414790511131287
[10/23] Train loss=0.6218938231468201
[15/23] Train loss=0.5551760792732239
[20/23] Train loss=0.5825487971305847
Test set avg_accuracy=77.50% avg_sensitivity=85.07%, avg_specificity=75.09% avg_auc=88.12%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.596171 Test loss=0.517292 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.5955331325531006
[5/23] Train loss=0.562911331653595
[10/23] Train loss=0.6389002799987793
[15/23] Train loss=0.5482876300811768
[20/23] Train loss=0.5676484704017639
Test set avg_accuracy=78.01% avg_sensitivity=83.61%, avg_specificity=76.22% avg_auc=88.07%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.593827 Test loss=0.500837 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.5933160185813904
[5/23] Train loss=0.5617674589157104
[10/23] Train loss=0.6382717490196228
[15/23] Train loss=0.5540749430656433
[20/23] Train loss=0.5900283455848694
Test set avg_accuracy=76.99% avg_sensitivity=85.77%, avg_specificity=74.20% avg_auc=88.12%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.592441 Test loss=0.536592 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.6183096766471863
[5/23] Train loss=0.5373328328132629
[10/23] Train loss=0.628553032875061
[15/23] Train loss=0.5617771148681641
[20/23] Train loss=0.5494508147239685
Test set avg_accuracy=77.70% avg_sensitivity=85.01%, avg_specificity=75.36% avg_auc=88.05%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.590196 Test loss=0.519423 Current lr=[0.000112073915556435]

[0/23] Train loss=0.6054096817970276
[5/23] Train loss=0.5416278839111328
[10/23] Train loss=0.6334778070449829
[15/23] Train loss=0.5510249137878418
[20/23] Train loss=0.5803321003913879
Test set avg_accuracy=76.98% avg_sensitivity=85.93%, avg_specificity=74.13% avg_auc=88.13%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.591768 Test loss=0.539410 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.6220945119857788
[5/23] Train loss=0.5549925565719604
[10/23] Train loss=0.6394463181495667
[15/23] Train loss=0.5520309805870056
[20/23] Train loss=0.5557672381401062
Test set avg_accuracy=76.39% avg_sensitivity=85.98%, avg_specificity=73.34% avg_auc=88.09%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.593473 Test loss=0.553133 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.6074160933494568
[5/23] Train loss=0.5531789064407349
[10/23] Train loss=0.6383051872253418
[15/23] Train loss=0.5397948026657104
[20/23] Train loss=0.5726301074028015
Test set avg_accuracy=76.25% avg_sensitivity=85.98%, avg_specificity=73.15% avg_auc=88.09%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.589504 Test loss=0.556720 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.6291320323944092
[5/23] Train loss=0.5402020812034607
[10/23] Train loss=0.6198855638504028
[15/23] Train loss=0.5388426184654236
[20/23] Train loss=0.5888636708259583
Test set avg_accuracy=75.78% avg_sensitivity=86.47%, avg_specificity=72.38% avg_auc=88.16%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.591803 Test loss=0.567404 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.637093722820282
[5/23] Train loss=0.5509220957756042
[10/23] Train loss=0.6121148467063904
[15/23] Train loss=0.5564075112342834
[20/23] Train loss=0.6042129993438721
Test set avg_accuracy=77.45% avg_sensitivity=85.12%, avg_specificity=75.00% avg_auc=88.21%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.599528 Test loss=0.520600 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.6158963441848755
[5/23] Train loss=0.5320426821708679
[10/23] Train loss=0.6215040683746338
[15/23] Train loss=0.594510555267334
[20/23] Train loss=0.6096064448356628
Test set avg_accuracy=79.92% avg_sensitivity=80.32%, avg_specificity=79.79% avg_auc=88.17%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.601503 Test loss=0.454396 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.5628606677055359
[5/23] Train loss=0.561022937297821
[10/23] Train loss=0.6352604627609253
[15/23] Train loss=0.5636184811592102
[20/23] Train loss=0.5568006038665771
Test set avg_accuracy=80.22% avg_sensitivity=80.97%, avg_specificity=79.98% avg_auc=88.24%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.586779 Test loss=0.456047 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.5690727233886719
[5/23] Train loss=0.5518355369567871
[10/23] Train loss=0.6129629611968994
[15/23] Train loss=0.540531575679779
[20/23] Train loss=0.5653132200241089
Test set avg_accuracy=79.69% avg_sensitivity=83.02%, avg_specificity=78.63% avg_auc=88.25%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.579886 Test loss=0.473125 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.5734928250312805
[5/23] Train loss=0.5470676422119141
[10/23] Train loss=0.6243149638175964
[15/23] Train loss=0.5373610258102417
[20/23] Train loss=0.5555140972137451
Test set avg_accuracy=79.65% avg_sensitivity=82.16%, avg_specificity=78.85% avg_auc=88.20%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.577201 Test loss=0.470177 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.5602247714996338
[5/23] Train loss=0.5364339351654053
[10/23] Train loss=0.5928007364273071
[15/23] Train loss=0.5440184473991394
[20/23] Train loss=0.5503404140472412
Test set avg_accuracy=79.35% avg_sensitivity=82.75%, avg_specificity=78.27% avg_auc=88.20%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.575275 Test loss=0.476929 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.5698400735855103
[5/23] Train loss=0.5290306806564331
[10/23] Train loss=0.5992624163627625
[15/23] Train loss=0.5323655605316162
[20/23] Train loss=0.5656242370605469
Test set avg_accuracy=79.49% avg_sensitivity=82.26%, avg_specificity=78.61% avg_auc=88.17%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.572129 Test loss=0.473828 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.574182391166687
[5/23] Train loss=0.541270911693573
[10/23] Train loss=0.5831214189529419
[15/23] Train loss=0.5525155663490295
[20/23] Train loss=0.5535312294960022
Test set avg_accuracy=79.74% avg_sensitivity=82.10%, avg_specificity=78.99% avg_auc=88.19%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.572079 Test loss=0.472171 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.5528439879417419
[5/23] Train loss=0.5351222157478333
[10/23] Train loss=0.5948099493980408
[15/23] Train loss=0.5362467765808105
[20/23] Train loss=0.5529710054397583
Test set avg_accuracy=79.18% avg_sensitivity=81.94%, avg_specificity=78.30% avg_auc=88.12%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.567319 Test loss=0.478856 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.567119836807251
[5/23] Train loss=0.5320310592651367
[10/23] Train loss=0.5958552956581116
[15/23] Train loss=0.5276267528533936
[20/23] Train loss=0.5476071834564209
Test set avg_accuracy=78.91% avg_sensitivity=81.83%, avg_specificity=77.97% avg_auc=88.12%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.567218 Test loss=0.481912 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.5744062066078186
[5/23] Train loss=0.5309810638427734
[10/23] Train loss=0.5951529741287231
[15/23] Train loss=0.5206915736198425
[20/23] Train loss=0.5626444816589355
Test set avg_accuracy=78.48% avg_sensitivity=82.21%, avg_specificity=77.29% avg_auc=88.06%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.570477 Test loss=0.490387 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.5883156061172485
[5/23] Train loss=0.5297420024871826
[10/23] Train loss=0.6087121367454529
[15/23] Train loss=0.5365272164344788
[20/23] Train loss=0.5558101534843445
Test set avg_accuracy=78.71% avg_sensitivity=81.78%, avg_specificity=77.73% avg_auc=88.01%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.570599 Test loss=0.487809 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.5834541916847229
[5/23] Train loss=0.5276099443435669
[10/23] Train loss=0.5938435196876526
[15/23] Train loss=0.5361572504043579
[20/23] Train loss=0.5352829098701477
Test set avg_accuracy=79.32% avg_sensitivity=81.83%, avg_specificity=78.52% avg_auc=88.11%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.569680 Test loss=0.479352 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.5661160945892334
[5/23] Train loss=0.5415565371513367
[10/23] Train loss=0.5889755487442017
[15/23] Train loss=0.5315191745758057
[20/23] Train loss=0.5534061789512634
Test set avg_accuracy=79.43% avg_sensitivity=83.40%, avg_specificity=78.16% avg_auc=88.19%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.569766 Test loss=0.484984 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.5533608198165894
[5/23] Train loss=0.5209192633628845
[10/23] Train loss=0.5848246812820435
[15/23] Train loss=0.5264847874641418
[20/23] Train loss=0.5504104495048523
Test set avg_accuracy=79.35% avg_sensitivity=83.29%, avg_specificity=78.09% avg_auc=88.21%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.567292 Test loss=0.484349 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.5597965717315674
[5/23] Train loss=0.5434620976448059
[10/23] Train loss=0.5789570212364197
[15/23] Train loss=0.5347857475280762
[20/23] Train loss=0.5459880232810974
Test set avg_accuracy=79.19% avg_sensitivity=83.50%, avg_specificity=77.82% avg_auc=88.22%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.564274 Test loss=0.488766 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.5600229501724243
[5/23] Train loss=0.533552348613739
[10/23] Train loss=0.573045015335083
[15/23] Train loss=0.5256256461143494
[20/23] Train loss=0.5426002740859985
Test set avg_accuracy=79.09% avg_sensitivity=83.83%, avg_specificity=77.58% avg_auc=88.24%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.562252 Test loss=0.492168 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.5681959390640259
[5/23] Train loss=0.5330954790115356
[10/23] Train loss=0.5864520072937012
[15/23] Train loss=0.52129727602005
[20/23] Train loss=0.5464336276054382
Test set avg_accuracy=79.32% avg_sensitivity=83.40%, avg_specificity=78.03% avg_auc=88.22%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.561952 Test loss=0.488143 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.549613356590271
[5/23] Train loss=0.5246099233627319
[10/23] Train loss=0.5795377492904663
[15/23] Train loss=0.518168568611145
[20/23] Train loss=0.5525054931640625
Test set avg_accuracy=79.31% avg_sensitivity=83.23%, avg_specificity=78.06% avg_auc=88.20%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.562009 Test loss=0.487170 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.5625384449958801
[5/23] Train loss=0.5323538184165955
[10/23] Train loss=0.5629551410675049
[15/23] Train loss=0.5181353092193604
[20/23] Train loss=0.5577701330184937
Test set avg_accuracy=79.40% avg_sensitivity=82.75%, avg_specificity=78.33% avg_auc=88.19%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.563077 Test loss=0.484095 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.5522372126579285
[5/23] Train loss=0.5481708645820618
[10/23] Train loss=0.5850460529327393
[15/23] Train loss=0.5106072425842285
[20/23] Train loss=0.5488591194152832
Test set avg_accuracy=79.75% avg_sensitivity=82.16%, avg_specificity=78.99% avg_auc=88.18%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.564731 Test loss=0.474916 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.5563836693763733
[5/23] Train loss=0.5541990995407104
[10/23] Train loss=0.5984770059585571
[15/23] Train loss=0.5207158923149109
[20/23] Train loss=0.5687177181243896
Test set avg_accuracy=80.43% avg_sensitivity=80.65%, avg_specificity=80.36% avg_auc=88.13%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.565582 Test loss=0.458845 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.5513184070587158
[5/23] Train loss=0.535385251045227
[10/23] Train loss=0.5870834589004517
[15/23] Train loss=0.5189810991287231
[20/23] Train loss=0.553598165512085
Test set avg_accuracy=80.91% avg_sensitivity=79.41%, avg_specificity=81.39% avg_auc=88.07%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.562867 Test loss=0.449164 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.5665731430053711
[5/23] Train loss=0.5402741432189941
[10/23] Train loss=0.5940176844596863
[15/23] Train loss=0.5156239867210388
[20/23] Train loss=0.5594012141227722
Test set avg_accuracy=80.99% avg_sensitivity=79.35%, avg_specificity=81.51% avg_auc=88.07%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.564014 Test loss=0.447448 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.5497328639030457
[5/23] Train loss=0.5333194136619568
[10/23] Train loss=0.585019588470459
[15/23] Train loss=0.5304266214370728
[20/23] Train loss=0.5309032201766968
Test set avg_accuracy=80.40% avg_sensitivity=80.59%, avg_specificity=80.34% avg_auc=88.12%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.559795 Test loss=0.458908 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.5547787547111511
[5/23] Train loss=0.5362969636917114
[10/23] Train loss=0.5754460692405701
[15/23] Train loss=0.5209296941757202
[20/23] Train loss=0.5424401760101318
Test set avg_accuracy=80.14% avg_sensitivity=80.75%, avg_specificity=79.95% avg_auc=88.15%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.557933 Test loss=0.461901 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.5515422821044922
[5/23] Train loss=0.5281574130058289
[10/23] Train loss=0.5895012021064758
[15/23] Train loss=0.5299227833747864
[20/23] Train loss=0.5461843609809875
Test set avg_accuracy=80.70% avg_sensitivity=80.11%, avg_specificity=80.89% avg_auc=88.12%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.559704 Test loss=0.453910 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.5380253195762634
[5/23] Train loss=0.5257734656333923
[10/23] Train loss=0.5892587304115295
[15/23] Train loss=0.5174251794815063
[20/23] Train loss=0.534356415271759
Test set avg_accuracy=80.01% avg_sensitivity=81.02%, avg_specificity=79.69% avg_auc=88.16%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.560755 Test loss=0.466181 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.5663154125213623
[5/23] Train loss=0.5299184918403625
[10/23] Train loss=0.5908106565475464
[15/23] Train loss=0.5215304493904114
[20/23] Train loss=0.5311973094940186
Test set avg_accuracy=80.36% avg_sensitivity=80.32%, avg_specificity=80.38% avg_auc=88.13%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.559744 Test loss=0.458805 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.5540796518325806
[5/23] Train loss=0.5217230916023254
[10/23] Train loss=0.5774103403091431
[15/23] Train loss=0.531112015247345
[20/23] Train loss=0.5499019622802734
Test set avg_accuracy=80.08% avg_sensitivity=81.02%, avg_specificity=79.78% avg_auc=88.16%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.559122 Test loss=0.465345 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.5527118444442749
[5/23] Train loss=0.5401151776313782
[10/23] Train loss=0.5879968404769897
[15/23] Train loss=0.5155730843544006
[20/23] Train loss=0.5493857264518738
Test set avg_accuracy=80.20% avg_sensitivity=80.75%, avg_specificity=80.02% avg_auc=88.15%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.558331 Test loss=0.462315 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.5369274616241455
[5/23] Train loss=0.521096408367157
[10/23] Train loss=0.5821446776390076
[15/23] Train loss=0.5247578620910645
[20/23] Train loss=0.5455674529075623
Test set avg_accuracy=80.14% avg_sensitivity=80.81%, avg_specificity=79.93% avg_auc=88.16%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.558488 Test loss=0.463421 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.5361165404319763
[5/23] Train loss=0.5202000737190247
[10/23] Train loss=0.5777066946029663
[15/23] Train loss=0.5257890224456787
[20/23] Train loss=0.5307602286338806
Test set avg_accuracy=80.10% avg_sensitivity=80.86%, avg_specificity=79.86% avg_auc=88.16%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.556319 Test loss=0.464671 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.5531890392303467
[5/23] Train loss=0.5322080850601196
[10/23] Train loss=0.5903952121734619
[15/23] Train loss=0.5149990916252136
[20/23] Train loss=0.5328415036201477
Test set avg_accuracy=80.16% avg_sensitivity=80.81%, avg_specificity=79.95% avg_auc=88.16%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.556143 Test loss=0.463724 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.5532001852989197
[5/23] Train loss=0.5254166722297668
[10/23] Train loss=0.5755304098129272
[15/23] Train loss=0.5114638209342957
[20/23] Train loss=0.5590308308601379
Test set avg_accuracy=80.10% avg_sensitivity=80.86%, avg_specificity=79.86% avg_auc=88.16%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.558173 Test loss=0.464225 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.5509847402572632
[5/23] Train loss=0.5386622548103333
[10/23] Train loss=0.5698603391647339
[15/23] Train loss=0.531481146812439
[20/23] Train loss=0.5424416661262512
Test set avg_accuracy=80.10% avg_sensitivity=80.92%, avg_specificity=79.85% avg_auc=88.16%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.558309 Test loss=0.465255 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.5461763143539429
[5/23] Train loss=0.5320109724998474
[10/23] Train loss=0.5866113305091858
[15/23] Train loss=0.503018319606781
[20/23] Train loss=0.5365155935287476
Test set avg_accuracy=80.08% avg_sensitivity=80.92%, avg_specificity=79.81% avg_auc=88.16%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.556703 Test loss=0.465520 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.5600859522819519
[5/23] Train loss=0.5323665142059326
[10/23] Train loss=0.565790593624115
[15/23] Train loss=0.5148731470108032
[20/23] Train loss=0.5382525324821472
Test set avg_accuracy=80.09% avg_sensitivity=80.97%, avg_specificity=79.81% avg_auc=88.16%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.557461 Test loss=0.465533 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.543755292892456
[5/23] Train loss=0.5327682495117188
[10/23] Train loss=0.5761352777481079
[15/23] Train loss=0.5243636965751648
[20/23] Train loss=0.544533908367157
Test set avg_accuracy=80.08% avg_sensitivity=80.92%, avg_specificity=79.81% avg_auc=88.16%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.554313 Test loss=0.465542 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.5458380579948425
[5/23] Train loss=0.5391606688499451
[10/23] Train loss=0.5788590908050537
[15/23] Train loss=0.5161341428756714
[20/23] Train loss=0.5336392521858215
Test set avg_accuracy=80.08% avg_sensitivity=80.92%, avg_specificity=79.81% avg_auc=88.16%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.555141 Test loss=0.465543 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=74.23% sen=88.52%, spe=69.68%, auc=88.28%!
Fold[9] Avg_jsc=0.48%(±0.21572646870496867)
{'AudioSampleRate': 16000,
 'BatchSize': 256,
 'BinNum': 15,
 'Cuda': 0,
 'DisableGpu': False,
 'Epochs': 150,
 'GasSampleRate': 100,
 'HopDuration': 2,
 'ImuSampleRate': 1000,
 'LabelMeta': 'patient_meta.csv',
 'LearningRate': 0.0003,
 'LogInterval': 5,
 'Model': 'Transformer',
 'Momentum': 0.5,
 'NumWorkers': 2,
 'Seed': 0,
 'Splits': 10,
 'TestBatchSize': 512,
 'WinDuration': 3,
 'healthy_data_dir': 'healthy',
 'healthy_data_meta': 'healthy_meta.csv',
 'healthy_dir': 'data/healthy',
 'patient_data_dir': 'patient',
 'patient_data_meta': 'patient_meta.csv',
 'train_dir': 'data/patient'}
[0/24] Train loss=2.0107274055480957
[5/24] Train loss=1.8085012435913086
[10/24] Train loss=1.711181640625
[15/24] Train loss=1.6191617250442505
[20/24] Train loss=1.5752812623977661
Test set avg_accuracy=53.68% avg_sensitivity=42.58%, avg_specificity=56.90% avg_auc=50.01%
Best model saved!! Metric=50.00549792519007!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=1.701744 Test loss=0.700916 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.554591178894043
[5/24] Train loss=1.5690975189208984
[10/24] Train loss=1.5464609861373901
[15/24] Train loss=1.543465256690979
[20/24] Train loss=1.5234299898147583
Test set avg_accuracy=42.86% avg_sensitivity=62.46%, avg_specificity=37.19% avg_auc=50.29%
Best model saved!! Metric=50.29253827431708!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=1.539544 Test loss=0.732012 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.5426326990127563
[5/24] Train loss=1.5287765264511108
[10/24] Train loss=1.5082850456237793
[15/24] Train loss=1.5183508396148682
[20/24] Train loss=1.5013703107833862
Test set avg_accuracy=52.28% avg_sensitivity=50.41%, avg_specificity=52.82% avg_auc=52.72%
Best model saved!! Metric=52.71603342894209!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=1.510137 Test loss=0.691122 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.4938464164733887
[5/24] Train loss=1.493299126625061
[10/24] Train loss=1.4987660646438599
[15/24] Train loss=1.5078420639038086
[20/24] Train loss=1.4697881937026978
Test set avg_accuracy=52.15% avg_sensitivity=53.36%, avg_specificity=51.80% avg_auc=54.31%
Best model saved!! Metric=54.30635937708605!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=1.482647 Test loss=0.689879 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.478541374206543
[5/24] Train loss=1.4962718486785889
[10/24] Train loss=1.4865715503692627
[15/24] Train loss=1.4755423069000244
[20/24] Train loss=1.4650142192840576
Test set avg_accuracy=50.21% avg_sensitivity=57.82%, avg_specificity=48.00% avg_auc=55.24%
Best model saved!! Metric=55.236540203359006!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=1.468231 Test loss=0.691031 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.4454759359359741
[5/24] Train loss=1.467829942703247
[10/24] Train loss=1.4355120658874512
[15/24] Train loss=1.4555919170379639
[20/24] Train loss=1.4350454807281494
Test set avg_accuracy=51.82% avg_sensitivity=57.53%, avg_specificity=50.17% avg_auc=56.63%
Best model saved!! Metric=56.63174819230166!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=1.451567 Test loss=0.684754 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.457369327545166
[5/24] Train loss=1.4567651748657227
[10/24] Train loss=1.4562721252441406
[15/24] Train loss=1.4637962579727173
[20/24] Train loss=1.4378113746643066
Test set avg_accuracy=51.77% avg_sensitivity=59.62%, avg_specificity=49.50% avg_auc=57.57%
Best model saved!! Metric=57.57130468392088!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=1.444525 Test loss=0.683036 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=1.4400755167007446
[5/24] Train loss=1.4285558462142944
[10/24] Train loss=1.436762809753418
[15/24] Train loss=1.4288972616195679
[20/24] Train loss=1.4436511993408203
Test set avg_accuracy=50.14% avg_sensitivity=61.99%, avg_specificity=46.71% avg_auc=58.26%
Best model saved!! Metric=58.260039016780254!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=1.434727 Test loss=0.683072 Current lr=[3.392058878345813e-05]

[0/24] Train loss=1.423108458518982
[5/24] Train loss=1.4468885660171509
[10/24] Train loss=1.4194493293762207
[15/24] Train loss=1.4325344562530518
[20/24] Train loss=1.4108517169952393
Test set avg_accuracy=52.03% avg_sensitivity=59.44%, avg_specificity=49.88% avg_auc=58.84%
Best model saved!! Metric=58.83692706267557!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=1.423608 Test loss=0.675171 Current lr=[3.955086037805142e-05]

[0/24] Train loss=1.4309446811676025
[5/24] Train loss=1.4186129570007324
[10/24] Train loss=1.3980076313018799
[15/24] Train loss=1.4222981929779053
[20/24] Train loss=1.4079396724700928
Test set avg_accuracy=50.76% avg_sensitivity=62.86%, avg_specificity=47.25% avg_auc=59.82%
Best model saved!! Metric=59.819532795075105!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=1.410855 Test loss=0.673655 Current lr=[4.57495121166447e-05]

[0/24] Train loss=1.4172295331954956
[5/24] Train loss=1.4342354536056519
[10/24] Train loss=1.3802324533462524
[15/24] Train loss=1.407867193222046
[20/24] Train loss=1.4132424592971802
Test set avg_accuracy=48.57% avg_sensitivity=68.19%, avg_specificity=42.88% avg_auc=61.01%
Best model saved!! Metric=61.00799446976842!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=1.401676 Test loss=0.677708 Current lr=[5.2486288811615e-05]

[0/24] Train loss=1.4172022342681885
[5/24] Train loss=1.4053164720535278
[10/24] Train loss=1.3736125230789185
[15/24] Train loss=1.3846744298934937
[20/24] Train loss=1.388601541519165
Test set avg_accuracy=49.79% avg_sensitivity=68.89%, avg_specificity=44.26% avg_auc=62.32%
Best model saved!! Metric=62.32440210793372!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=1.387638 Test loss=0.672220 Current lr=[5.97283087248885e-05]

[0/24] Train loss=1.3887380361557007
[5/24] Train loss=1.3871409893035889
[10/24] Train loss=1.3652793169021606
[15/24] Train loss=1.3691288232803345
[20/24] Train loss=1.362771987915039
Test set avg_accuracy=50.81% avg_sensitivity=73.29%, avg_specificity=44.29% avg_auc=64.18%
Best model saved!! Metric=64.18053571004585!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=1.371744 Test loss=0.674977 Current lr=[6.744022406141468e-05]

[0/24] Train loss=1.3806923627853394
[5/24] Train loss=1.3687089681625366
[10/24] Train loss=1.331285834312439
[15/24] Train loss=1.356460690498352
[20/24] Train loss=1.3641746044158936
Test set avg_accuracy=54.47% avg_sensitivity=73.29%, avg_specificity=49.01% avg_auc=66.47%
Best model saved!! Metric=66.46814940032719!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=1.355267 Test loss=0.665048 Current lr=[7.558439349929357e-05]

[0/24] Train loss=1.3588017225265503
[5/24] Train loss=1.349011778831482
[10/24] Train loss=1.3405048847198486
[15/24] Train loss=1.3402042388916016
[20/24] Train loss=1.325751781463623
Test set avg_accuracy=64.47% avg_sensitivity=67.15%, avg_specificity=63.69% avg_auc=70.27%
Best model saved!! Metric=70.27395431409053!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=1.333668 Test loss=0.631942 Current lr=[8.412106591444728e-05]

[0/24] Train loss=1.3294646739959717
[5/24] Train loss=1.313636302947998
[10/24] Train loss=1.3035411834716797
[15/24] Train loss=1.3018907308578491
[20/24] Train loss=1.2851814031600952
Test set avg_accuracy=68.01% avg_sensitivity=65.93%, avg_specificity=68.61% avg_auc=73.81%
Best model saved!! Metric=73.81225840754398!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=1.302011 Test loss=0.607007 Current lr=[9.300857440308985e-05]

[0/24] Train loss=1.2868659496307373
[5/24] Train loss=1.2945996522903442
[10/24] Train loss=1.2790213823318481
[15/24] Train loss=1.2411409616470337
[20/24] Train loss=1.2241809368133545
Test set avg_accuracy=71.72% avg_sensitivity=65.53%, avg_specificity=73.51% avg_auc=76.53%
Best model saved!! Metric=76.52562558603991!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=1.259981 Test loss=0.566924 Current lr=[0.00010220353965498347]

[0/24] Train loss=1.2286450862884521
[5/24] Train loss=1.2564302682876587
[10/24] Train loss=1.2535624504089355
[15/24] Train loss=1.1792175769805908
[20/24] Train loss=1.198185682296753
Test set avg_accuracy=69.36% avg_sensitivity=74.16%, avg_specificity=67.97% avg_auc=78.47%
Best model saved!! Metric=78.4714580808991!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=1.222805 Test loss=0.575343 Current lr=[0.0001116610816848323]

[0/24] Train loss=1.1749595403671265
[5/24] Train loss=1.2154332399368286
[10/24] Train loss=1.196352481842041
[15/24] Train loss=1.1604981422424316
[20/24] Train loss=1.1430715322494507
Test set avg_accuracy=67.93% avg_sensitivity=80.07%, avg_specificity=64.41% avg_auc=79.67%
Best model saved!! Metric=79.67209790315945!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=1.176728 Test loss=0.588376 Current lr=[0.00012133503888836635]

[0/24] Train loss=1.132149338722229
[5/24] Train loss=1.177213191986084
[10/24] Train loss=1.1488431692123413
[15/24] Train loss=1.1306064128875732
[20/24] Train loss=1.1429932117462158
Test set avg_accuracy=72.29% avg_sensitivity=73.46%, avg_specificity=71.95% avg_auc=80.66%
Best model saved!! Metric=80.6619871700807!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=1.145920 Test loss=0.523512 Current lr=[0.00013117819335391835]

[0/24] Train loss=1.0855212211608887
[5/24] Train loss=1.1784234046936035
[10/24] Train loss=1.1251442432403564
[15/24] Train loss=1.1276530027389526
[20/24] Train loss=1.1073681116104126
Test set avg_accuracy=71.21% avg_sensitivity=79.32%, avg_specificity=68.86% avg_auc=81.84%
Best model saved!! Metric=81.84269336446165!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=1.120014 Test loss=0.537938 Current lr=[0.00014114250132976375]

[0/24] Train loss=1.0597057342529297
[5/24] Train loss=1.142067790031433
[10/24] Train loss=1.0853525400161743
[15/24] Train loss=1.0930646657943726
[20/24] Train loss=1.0579487085342407
Test set avg_accuracy=75.05% avg_sensitivity=74.39%, avg_specificity=75.24% avg_auc=82.80%
Best model saved!! Metric=82.79812085782424!!
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=1.085710 Test loss=0.485848 Current lr=[0.00015117932772232805]

[0/24] Train loss=1.0679495334625244
[5/24] Train loss=1.1398292779922485
[10/24] Train loss=1.055495262145996
[15/24] Train loss=1.0818475484848022
[20/24] Train loss=1.0330009460449219
Test set avg_accuracy=73.88% avg_sensitivity=80.71%, avg_specificity=71.90% avg_auc=83.98%
Best model saved!! Metric=83.98012611948461!!
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=1.066842 Test loss=0.504924 Current lr=[0.00016123968348069324]

[0/24] Train loss=1.031662940979004
[5/24] Train loss=1.116807222366333
[10/24] Train loss=1.0102537870407104
[15/24] Train loss=1.0685486793518066
[20/24] Train loss=1.0016005039215088
Test set avg_accuracy=75.55% avg_sensitivity=80.48%, avg_specificity=74.12% avg_auc=84.92%
Best model saved!! Metric=84.91602381487114!!
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=1.034034 Test loss=0.482471 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.9933179616928101
[5/24] Train loss=1.0804136991500854
[10/24] Train loss=0.9857237935066223
[15/24] Train loss=1.0293560028076172
[20/24] Train loss=0.9853388071060181
Test set avg_accuracy=76.26% avg_sensitivity=81.05%, avg_specificity=74.87% avg_auc=85.55%
Best model saved!! Metric=85.54511782296954!!
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=1.014324 Test loss=0.472276 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.9854133129119873
[5/24] Train loss=1.0743162631988525
[10/24] Train loss=0.9442877769470215
[15/24] Train loss=1.0078701972961426
[20/24] Train loss=0.9843282699584961
Test set avg_accuracy=77.20% avg_sensitivity=80.01%, avg_specificity=76.39% avg_auc=85.96%
Best model saved!! Metric=85.96429326263812!!
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.998854 Test loss=0.456440 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.9834482073783875
[5/24] Train loss=1.0440747737884521
[10/24] Train loss=0.9468032121658325
[15/24] Train loss=1.0390690565109253
[20/24] Train loss=0.946927547454834
Test set avg_accuracy=77.67% avg_sensitivity=79.14%, avg_specificity=77.24% avg_auc=86.33%
Best model saved!! Metric=86.32542423547702!!
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.986597 Test loss=0.444261 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.9595889449119568
[5/24] Train loss=1.0575370788574219
[10/24] Train loss=0.9159144759178162
[15/24] Train loss=1.0127575397491455
[20/24] Train loss=0.9647856950759888
Test set avg_accuracy=76.81% avg_sensitivity=82.16%, avg_specificity=75.26% avg_auc=86.53%
Best model saved!! Metric=86.532530590845!!
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.974706 Test loss=0.461645 Current lr=[0.000210185142098938]

[0/24] Train loss=0.9378321766853333
[5/24] Train loss=0.9923803210258484
[10/24] Train loss=0.9118914008140564
[15/24] Train loss=0.9818364381790161
[20/24] Train loss=0.9378465414047241
Test set avg_accuracy=77.90% avg_sensitivity=81.17%, avg_specificity=76.96% avg_auc=86.70%
Best model saved!! Metric=86.69643687739645!!
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.959188 Test loss=0.447252 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.9456117749214172
[5/24] Train loss=0.9952180981636047
[10/24] Train loss=0.9041427969932556
[15/24] Train loss=0.9788409471511841
[20/24] Train loss=0.943556010723114
Test set avg_accuracy=79.43% avg_sensitivity=77.81%, avg_specificity=79.90% avg_auc=86.76%
Best model saved!! Metric=86.759930615211!!
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.956456 Test loss=0.424141 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.9347596764564514
[5/24] Train loss=1.0358285903930664
[10/24] Train loss=0.8980228900909424
[15/24] Train loss=0.977888822555542
[20/24] Train loss=0.9214502573013306
Test set avg_accuracy=78.28% avg_sensitivity=81.05%, avg_specificity=77.48% avg_auc=86.87%
Best model saved!! Metric=86.86839056949162!!
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.947494 Test loss=0.443902 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.9280269742012024
[5/24] Train loss=0.9842149019241333
[10/24] Train loss=0.8975012302398682
[15/24] Train loss=0.9787654876708984
[20/24] Train loss=0.9165698289871216
Test set avg_accuracy=79.71% avg_sensitivity=76.36%, avg_specificity=80.69% avg_auc=86.85%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.940524 Test loss=0.413503 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.9171358942985535
[5/24] Train loss=1.0280574560165405
[10/24] Train loss=0.8767202496528625
[15/24] Train loss=0.9555841088294983
[20/24] Train loss=0.9239286184310913
Test set avg_accuracy=78.20% avg_sensitivity=83.37%, avg_specificity=76.70% avg_auc=87.18%
Best model saved!! Metric=87.18358224176002!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.938752 Test loss=0.450501 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.888333797454834
[5/24] Train loss=0.9599699974060059
[10/24] Train loss=0.8605607748031616
[15/24] Train loss=0.9585356712341309
[20/24] Train loss=0.9170446395874023
Test set avg_accuracy=80.07% avg_sensitivity=76.83%, avg_specificity=81.00% avg_auc=87.08%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.924772 Test loss=0.411198 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.9033550024032593
[5/24] Train loss=0.997170090675354
[10/24] Train loss=0.8791531920433044
[15/24] Train loss=0.9576283097267151
[20/24] Train loss=0.8933250904083252
Test set avg_accuracy=79.11% avg_sensitivity=81.29%, avg_specificity=78.49% avg_auc=87.34%
Best model saved!! Metric=87.34047745733902!!
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.924035 Test loss=0.430136 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.8782707452774048
[5/24] Train loss=0.9741535186767578
[10/24] Train loss=0.8528567552566528
[15/24] Train loss=0.9208741784095764
[20/24] Train loss=0.8790143132209778
Test set avg_accuracy=79.27% avg_sensitivity=80.42%, avg_specificity=78.94% avg_auc=87.27%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.910897 Test loss=0.427878 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.8691149950027466
[5/24] Train loss=0.9445300102233887
[10/24] Train loss=0.8506782054901123
[15/24] Train loss=0.9400304555892944
[20/24] Train loss=0.879714846611023
Test set avg_accuracy=80.03% avg_sensitivity=78.74%, avg_specificity=80.40% avg_auc=87.33%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.908895 Test loss=0.414952 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.8864653706550598
[5/24] Train loss=0.9600167870521545
[10/24] Train loss=0.8553488850593567
[15/24] Train loss=0.9411708116531372
[20/24] Train loss=0.88111412525177
Test set avg_accuracy=79.64% avg_sensitivity=80.42%, avg_specificity=79.41% avg_auc=87.41%
Best model saved!! Metric=87.40935235025113!!
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.903449 Test loss=0.425515 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.8762164115905762
[5/24] Train loss=0.9398928284645081
[10/24] Train loss=0.8551139831542969
[15/24] Train loss=0.9020749926567078
[20/24] Train loss=0.8594953417778015
Test set avg_accuracy=79.15% avg_sensitivity=81.69%, avg_specificity=78.42% avg_auc=87.51%
Best model saved!! Metric=87.51447462605351!!
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.893874 Test loss=0.433542 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.8620599508285522
[5/24] Train loss=0.937574028968811
[10/24] Train loss=0.8321022391319275
[15/24] Train loss=0.8963918685913086
[20/24] Train loss=0.8604242205619812
Test set avg_accuracy=79.87% avg_sensitivity=79.08%, avg_specificity=80.10% avg_auc=87.50%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.885929 Test loss=0.417070 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.8749825954437256
[5/24] Train loss=0.9327070116996765
[10/24] Train loss=0.8362006545066833
[15/24] Train loss=0.9023165702819824
[20/24] Train loss=0.8552996516227722
Test set avg_accuracy=80.23% avg_sensitivity=79.03%, avg_specificity=80.58% avg_auc=87.40%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.884216 Test loss=0.416066 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.8713359832763672
[5/24] Train loss=0.9242815971374512
[10/24] Train loss=0.8188217878341675
[15/24] Train loss=0.8972967863082886
[20/24] Train loss=0.8689045906066895
Test set avg_accuracy=80.30% avg_sensitivity=78.91%, avg_specificity=80.70% avg_auc=87.57%
Best model saved!! Metric=87.57489828351858!!
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.882593 Test loss=0.415224 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.8576673269271851
[5/24] Train loss=0.9187356233596802
[10/24] Train loss=0.8160302639007568
[15/24] Train loss=0.8916743397712708
[20/24] Train loss=0.8569523692131042
Test set avg_accuracy=79.32% avg_sensitivity=80.71%, avg_specificity=78.92% avg_auc=87.65%
Best model saved!! Metric=87.65245795206276!!
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.876336 Test loss=0.431515 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.8377963304519653
[5/24] Train loss=0.8905609250068665
[10/24] Train loss=0.8254923820495605
[15/24] Train loss=0.8944992423057556
[20/24] Train loss=0.8397715091705322
Test set avg_accuracy=79.34% avg_sensitivity=80.71%, avg_specificity=78.94% avg_auc=87.64%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.866960 Test loss=0.433998 Current lr=[0.00029967723776099]

[0/24] Train loss=0.8417670130729675
[5/24] Train loss=0.8951351046562195
[10/24] Train loss=0.8052786588668823
[15/24] Train loss=0.8724842667579651
[20/24] Train loss=0.8399957418441772
Test set avg_accuracy=80.39% avg_sensitivity=78.51%, avg_specificity=80.94% avg_auc=87.63%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.859227 Test loss=0.413778 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.8618848323822021
[5/24] Train loss=0.9161267280578613
[10/24] Train loss=0.811582624912262
[15/24] Train loss=0.8884100914001465
[20/24] Train loss=0.836957573890686
Test set avg_accuracy=79.38% avg_sensitivity=80.42%, avg_specificity=79.07% avg_auc=87.69%
Best model saved!! Metric=87.68648670319496!!
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.866016 Test loss=0.431913 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.8332081437110901
[5/24] Train loss=0.9081789255142212
[10/24] Train loss=0.8093563318252563
[15/24] Train loss=0.8794876337051392
[20/24] Train loss=0.8442040085792542
Test set avg_accuracy=78.88% avg_sensitivity=81.52%, avg_specificity=78.12% avg_auc=87.65%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.855808 Test loss=0.440238 Current lr=[0.000299720220882401]

[0/24] Train loss=0.8174644708633423
[5/24] Train loss=0.8690576553344727
[10/24] Train loss=0.7926744222640991
[15/24] Train loss=0.8558088541030884
[20/24] Train loss=0.812559962272644
Test set avg_accuracy=78.39% avg_sensitivity=82.62%, avg_specificity=77.16% avg_auc=87.71%
Best model saved!! Metric=87.70695066191128!!
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.843733 Test loss=0.454203 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.8071584701538086
[5/24] Train loss=0.8875183463096619
[10/24] Train loss=0.7818138599395752
[15/24] Train loss=0.8713837265968323
[20/24] Train loss=0.8095434904098511
Test set avg_accuracy=79.66% avg_sensitivity=79.72%, avg_specificity=79.64% avg_auc=87.45%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.838755 Test loss=0.431689 Current lr=[0.000298904600941902]

[0/24] Train loss=0.8067678213119507
[5/24] Train loss=0.8615538477897644
[10/24] Train loss=0.8043184280395508
[15/24] Train loss=0.8561525940895081
[20/24] Train loss=0.8303697109222412
Test set avg_accuracy=79.82% avg_sensitivity=79.49%, avg_specificity=79.91% avg_auc=87.38%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.836295 Test loss=0.430541 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.7918493151664734
[5/24] Train loss=0.8663797378540039
[10/24] Train loss=0.7818153500556946
[15/24] Train loss=0.8658539056777954
[20/24] Train loss=0.8296725749969482
Test set avg_accuracy=80.04% avg_sensitivity=79.14%, avg_specificity=80.30% avg_auc=87.55%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.834190 Test loss=0.423084 Current lr=[0.000297555943323901]

[0/24] Train loss=0.8182777762413025
[5/24] Train loss=0.8601410984992981
[10/24] Train loss=0.7721104621887207
[15/24] Train loss=0.8511486053466797
[20/24] Train loss=0.8204094767570496
Test set avg_accuracy=79.49% avg_sensitivity=80.19%, avg_specificity=79.29% avg_auc=87.39%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.826909 Test loss=0.436784 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.8044308423995972
[5/24] Train loss=0.8532791137695312
[10/24] Train loss=0.7755544781684875
[15/24] Train loss=0.8490420579910278
[20/24] Train loss=0.7832836508750916
Test set avg_accuracy=79.32% avg_sensitivity=81.17%, avg_specificity=78.79% avg_auc=87.50%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.821230 Test loss=0.445045 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.788046658039093
[5/24] Train loss=0.8334746956825256
[10/24] Train loss=0.7617841362953186
[15/24] Train loss=0.8344053030014038
[20/24] Train loss=0.7744512557983398
Test set avg_accuracy=79.24% avg_sensitivity=81.00%, avg_specificity=78.74% avg_auc=87.39%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.811716 Test loss=0.445033 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.7850977778434753
[5/24] Train loss=0.8380035758018494
[10/24] Train loss=0.7633225917816162
[15/24] Train loss=0.8275842666625977
[20/24] Train loss=0.7838430404663086
Test set avg_accuracy=80.00% avg_sensitivity=78.39%, avg_specificity=80.47% avg_auc=87.38%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.810388 Test loss=0.428367 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.7848790884017944
[5/24] Train loss=0.8540179133415222
[10/24] Train loss=0.7760120034217834
[15/24] Train loss=0.8221641778945923
[20/24] Train loss=0.7787284255027771
Test set avg_accuracy=79.58% avg_sensitivity=79.95%, avg_specificity=79.48% avg_auc=87.45%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.814177 Test loss=0.439266 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.7826105356216431
[5/24] Train loss=0.8349286913871765
[10/24] Train loss=0.7692862153053284
[15/24] Train loss=0.8138035535812378
[20/24] Train loss=0.7914864420890808
Test set avg_accuracy=78.65% avg_sensitivity=82.27%, avg_specificity=77.59% avg_auc=87.42%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.804366 Test loss=0.464413 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.7711699604988098
[5/24] Train loss=0.8267043232917786
[10/24] Train loss=0.7803632020950317
[15/24] Train loss=0.8098182678222656
[20/24] Train loss=0.762095034122467
Test set avg_accuracy=78.27% avg_sensitivity=82.85%, avg_specificity=76.94% avg_auc=87.40%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.802620 Test loss=0.472153 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.7639660835266113
[5/24] Train loss=0.8122065663337708
[10/24] Train loss=0.7583209276199341
[15/24] Train loss=0.8103713393211365
[20/24] Train loss=0.7728879451751709
Test set avg_accuracy=79.71% avg_sensitivity=79.55%, avg_specificity=79.76% avg_auc=87.31%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.792851 Test loss=0.440684 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.770249605178833
[5/24] Train loss=0.8242082595825195
[10/24] Train loss=0.7603375911712646
[15/24] Train loss=0.8176130652427673
[20/24] Train loss=0.7700191736221313
Test set avg_accuracy=79.18% avg_sensitivity=79.78%, avg_specificity=79.01% avg_auc=87.29%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.790622 Test loss=0.448653 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.7635859847068787
[5/24] Train loss=0.7954851984977722
[10/24] Train loss=0.7500045299530029
[15/24] Train loss=0.7825162410736084
[20/24] Train loss=0.7384534478187561
Test set avg_accuracy=79.26% avg_sensitivity=81.34%, avg_specificity=78.65% avg_auc=87.39%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.780745 Test loss=0.452951 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.7399206161499023
[5/24] Train loss=0.8136904239654541
[10/24] Train loss=0.7359774708747864
[15/24] Train loss=0.7873042821884155
[20/24] Train loss=0.7421194911003113
Test set avg_accuracy=78.71% avg_sensitivity=80.94%, avg_specificity=78.07% avg_auc=87.20%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.780422 Test loss=0.465163 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.7661860585212708
[5/24] Train loss=0.8079252243041992
[10/24] Train loss=0.7385110259056091
[15/24] Train loss=0.7988854050636292
[20/24] Train loss=0.7495391964912415
Test set avg_accuracy=79.67% avg_sensitivity=78.79%, avg_specificity=79.93% avg_auc=87.14%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.778856 Test loss=0.444107 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.765070915222168
[5/24] Train loss=0.7936790585517883
[10/24] Train loss=0.7371811270713806
[15/24] Train loss=0.7799990177154541
[20/24] Train loss=0.7344351410865784
Test set avg_accuracy=78.70% avg_sensitivity=81.29%, avg_specificity=77.95% avg_auc=87.27%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.774835 Test loss=0.464977 Current lr=[0.000276307469034998]

[0/24] Train loss=0.7357137203216553
[5/24] Train loss=0.8030440211296082
[10/24] Train loss=0.7301329970359802
[15/24] Train loss=0.7686638236045837
[20/24] Train loss=0.7307145595550537
Test set avg_accuracy=78.72% avg_sensitivity=81.17%, avg_specificity=78.01% avg_auc=87.29%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.767281 Test loss=0.465323 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.7372087240219116
[5/24] Train loss=0.7676238417625427
[10/24] Train loss=0.7167413830757141
[15/24] Train loss=0.7753946185112
[20/24] Train loss=0.7237669229507446
Test set avg_accuracy=79.40% avg_sensitivity=79.72%, avg_specificity=79.31% avg_auc=87.31%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.761267 Test loss=0.445626 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.7393175363540649
[5/24] Train loss=0.8106205463409424
[10/24] Train loss=0.7194742560386658
[15/24] Train loss=0.7958940863609314
[20/24] Train loss=0.731214702129364
Test set avg_accuracy=78.02% avg_sensitivity=82.56%, avg_specificity=76.70% avg_auc=87.26%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.763101 Test loss=0.478971 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.7182300686836243
[5/24] Train loss=0.7682235836982727
[10/24] Train loss=0.7065851092338562
[15/24] Train loss=0.7613980770111084
[20/24] Train loss=0.7180711030960083
Test set avg_accuracy=77.85% avg_sensitivity=83.55%, avg_specificity=76.20% avg_auc=87.22%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.750929 Test loss=0.490669 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.742419958114624
[5/24] Train loss=0.7822349071502686
[10/24] Train loss=0.7041347622871399
[15/24] Train loss=0.7454721927642822
[20/24] Train loss=0.7238142490386963
Test set avg_accuracy=77.86% avg_sensitivity=82.62%, avg_specificity=76.49% avg_auc=87.03%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.748053 Test loss=0.489210 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.7174601554870605
[5/24] Train loss=0.7679443955421448
[10/24] Train loss=0.6939102411270142
[15/24] Train loss=0.7626082301139832
[20/24] Train loss=0.7071936726570129
Test set avg_accuracy=78.75% avg_sensitivity=80.65%, avg_specificity=78.20% avg_auc=87.09%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.739098 Test loss=0.463513 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.7207607626914978
[5/24] Train loss=0.7997695207595825
[10/24] Train loss=0.7213260531425476
[15/24] Train loss=0.7647536396980286
[20/24] Train loss=0.6923115253448486
Test set avg_accuracy=78.37% avg_sensitivity=81.81%, avg_specificity=77.38% avg_auc=87.00%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.745237 Test loss=0.480002 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.7312654256820679
[5/24] Train loss=0.7733742594718933
[10/24] Train loss=0.7170804142951965
[15/24] Train loss=0.7363853454589844
[20/24] Train loss=0.7312155961990356
Test set avg_accuracy=79.61% avg_sensitivity=80.65%, avg_specificity=79.31% avg_auc=87.23%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.750551 Test loss=0.449003 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.7116696238517761
[5/24] Train loss=0.790961742401123
[10/24] Train loss=0.7020332217216492
[15/24] Train loss=0.7380216121673584
[20/24] Train loss=0.7386516332626343
Test set avg_accuracy=82.34% avg_sensitivity=69.87%, avg_specificity=85.96% avg_auc=87.12%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.751660 Test loss=0.388918 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.7650509476661682
[5/24] Train loss=0.7682408690452576
[10/24] Train loss=0.7634598016738892
[15/24] Train loss=0.7251081466674805
[20/24] Train loss=0.720630407333374
Test set avg_accuracy=80.86% avg_sensitivity=76.71%, avg_specificity=82.06% avg_auc=87.04%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.754128 Test loss=0.422781 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.7144127488136292
[5/24] Train loss=0.7163758277893066
[10/24] Train loss=0.7402734756469727
[15/24] Train loss=0.7330906987190247
[20/24] Train loss=0.7135439515113831
Test set avg_accuracy=80.78% avg_sensitivity=75.67%, avg_specificity=82.26% avg_auc=86.95%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.730748 Test loss=0.420144 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.7168595194816589
[5/24] Train loss=0.7451338171958923
[10/24] Train loss=0.7088798880577087
[15/24] Train loss=0.7390037775039673
[20/24] Train loss=0.6886188387870789
Test set avg_accuracy=81.25% avg_sensitivity=74.10%, avg_specificity=83.32% avg_auc=86.96%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.725311 Test loss=0.412205 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.7117801904678345
[5/24] Train loss=0.716195821762085
[10/24] Train loss=0.699531614780426
[15/24] Train loss=0.7310390472412109
[20/24] Train loss=0.6896507740020752
Test set avg_accuracy=80.51% avg_sensitivity=75.72%, avg_specificity=81.89% avg_auc=86.89%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.717758 Test loss=0.425561 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.683588981628418
[5/24] Train loss=0.7026092410087585
[10/24] Train loss=0.71485435962677
[15/24] Train loss=0.7319263815879822
[20/24] Train loss=0.6933765411376953
Test set avg_accuracy=81.16% avg_sensitivity=74.80%, avg_specificity=83.00% avg_auc=86.86%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.719212 Test loss=0.416858 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.7070782780647278
[5/24] Train loss=0.7256218194961548
[10/24] Train loss=0.7303088307380676
[15/24] Train loss=0.6982331275939941
[20/24] Train loss=0.6848787069320679
Test set avg_accuracy=80.42% avg_sensitivity=77.52%, avg_specificity=81.26% avg_auc=86.86%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.714616 Test loss=0.437101 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.6927386522293091
[5/24] Train loss=0.6878589987754822
[10/24] Train loss=0.6940779685974121
[15/24] Train loss=0.7030365467071533
[20/24] Train loss=0.6824274659156799
Test set avg_accuracy=80.16% avg_sensitivity=78.33%, avg_specificity=80.69% avg_auc=86.78%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.699874 Test loss=0.445292 Current lr=[0.000224838296036774]

[0/24] Train loss=0.6938799619674683
[5/24] Train loss=0.6965929269790649
[10/24] Train loss=0.7024780511856079
[15/24] Train loss=0.7072414755821228
[20/24] Train loss=0.6726341247558594
Test set avg_accuracy=80.49% avg_sensitivity=76.88%, avg_specificity=81.54% avg_auc=86.80%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.699346 Test loss=0.435172 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.6809345483779907
[5/24] Train loss=0.702631413936615
[10/24] Train loss=0.6844450235366821
[15/24] Train loss=0.716828465461731
[20/24] Train loss=0.6852194666862488
Test set avg_accuracy=80.30% avg_sensitivity=77.00%, avg_specificity=81.26% avg_auc=86.72%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.694069 Test loss=0.439389 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.6749258041381836
[5/24] Train loss=0.6886301040649414
[10/24] Train loss=0.6870319843292236
[15/24] Train loss=0.6971246004104614
[20/24] Train loss=0.6709743738174438
Test set avg_accuracy=80.03% avg_sensitivity=78.22%, avg_specificity=80.55% avg_auc=86.69%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.690843 Test loss=0.444281 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.7039188742637634
[5/24] Train loss=0.6605544686317444
[10/24] Train loss=0.6880858540534973
[15/24] Train loss=0.6776846647262573
[20/24] Train loss=0.6696692705154419
Test set avg_accuracy=80.21% avg_sensitivity=75.96%, avg_specificity=81.44% avg_auc=86.61%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.684976 Test loss=0.438207 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.699439525604248
[5/24] Train loss=0.6734908819198608
[10/24] Train loss=0.6696723699569702
[15/24] Train loss=0.6914693713188171
[20/24] Train loss=0.6682447195053101
Test set avg_accuracy=79.79% avg_sensitivity=77.35%, avg_specificity=80.50% avg_auc=86.61%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.680481 Test loss=0.448574 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.6703392863273621
[5/24] Train loss=0.6705819368362427
[10/24] Train loss=0.6796905994415283
[15/24] Train loss=0.6816293597221375
[20/24] Train loss=0.6362555623054504
Test set avg_accuracy=79.92% avg_sensitivity=76.94%, avg_specificity=80.79% avg_auc=86.57%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.680992 Test loss=0.445083 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.674699068069458
[5/24] Train loss=0.6720443964004517
[10/24] Train loss=0.6790470480918884
[15/24] Train loss=0.6568260788917542
[20/24] Train loss=0.674262523651123
Test set avg_accuracy=80.25% avg_sensitivity=75.43%, avg_specificity=81.64% avg_auc=86.53%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.676179 Test loss=0.437645 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.6874528527259827
[5/24] Train loss=0.6664843559265137
[10/24] Train loss=0.6651967167854309
[15/24] Train loss=0.6725174188613892
[20/24] Train loss=0.6545099020004272
Test set avg_accuracy=79.67% avg_sensitivity=78.04%, avg_specificity=80.15% avg_auc=86.60%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.672743 Test loss=0.452867 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.6571388840675354
[5/24] Train loss=0.6630587577819824
[10/24] Train loss=0.6619822382926941
[15/24] Train loss=0.6623316407203674
[20/24] Train loss=0.6476023197174072
Test set avg_accuracy=80.01% avg_sensitivity=77.06%, avg_specificity=80.87% avg_auc=86.53%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.666856 Test loss=0.448034 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.6755706071853638
[5/24] Train loss=0.6443954706192017
[10/24] Train loss=0.66753089427948
[15/24] Train loss=0.6530567407608032
[20/24] Train loss=0.6480888724327087
Test set avg_accuracy=79.77% avg_sensitivity=77.64%, avg_specificity=80.38% avg_auc=86.55%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.667929 Test loss=0.452872 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.6740773320198059
[5/24] Train loss=0.6295636296272278
[10/24] Train loss=0.6769405603408813
[15/24] Train loss=0.6672677993774414
[20/24] Train loss=0.6349060535430908
Test set avg_accuracy=79.47% avg_sensitivity=78.45%, avg_specificity=79.76% avg_auc=86.60%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.662707 Test loss=0.458566 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.6436734795570374
[5/24] Train loss=0.633510172367096
[10/24] Train loss=0.6756429672241211
[15/24] Train loss=0.6592001914978027
[20/24] Train loss=0.6307317614555359
Test set avg_accuracy=78.28% avg_sensitivity=81.34%, avg_specificity=77.39% avg_auc=86.63%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.654107 Test loss=0.489011 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.625840961933136
[5/24] Train loss=0.6412249803543091
[10/24] Train loss=0.6522802114486694
[15/24] Train loss=0.6509044766426086
[20/24] Train loss=0.6284882426261902
Test set avg_accuracy=77.67% avg_sensitivity=81.58%, avg_specificity=76.54% avg_auc=86.58%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.652323 Test loss=0.497080 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.6340553760528564
[5/24] Train loss=0.6169735193252563
[10/24] Train loss=0.6467832922935486
[15/24] Train loss=0.660077691078186
[20/24] Train loss=0.6193856596946716
Test set avg_accuracy=77.97% avg_sensitivity=81.00%, avg_specificity=77.09% avg_auc=86.53%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.645071 Test loss=0.489136 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.6428670287132263
[5/24] Train loss=0.617872416973114
[10/24] Train loss=0.6398525834083557
[15/24] Train loss=0.6680898666381836
[20/24] Train loss=0.6282767057418823
Test set avg_accuracy=77.45% avg_sensitivity=81.46%, avg_specificity=76.28% avg_auc=86.44%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.645828 Test loss=0.498115 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.6405258774757385
[5/24] Train loss=0.6276139616966248
[10/24] Train loss=0.6556299924850464
[15/24] Train loss=0.6445250511169434
[20/24] Train loss=0.6218675374984741
Test set avg_accuracy=76.97% avg_sensitivity=82.27%, avg_specificity=75.43% avg_auc=86.49%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.648656 Test loss=0.511775 Current lr=[0.000156543481933168]

[0/24] Train loss=0.6433432102203369
[5/24] Train loss=0.605251133441925
[10/24] Train loss=0.6333721876144409
[15/24] Train loss=0.6600185632705688
[20/24] Train loss=0.6201541423797607
Test set avg_accuracy=78.02% avg_sensitivity=81.46%, avg_specificity=77.02% avg_auc=86.40%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.641240 Test loss=0.495317 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.6323525309562683
[5/24] Train loss=0.6458768248558044
[10/24] Train loss=0.6139034628868103
[15/24] Train loss=0.6367120146751404
[20/24] Train loss=0.6194384694099426
Test set avg_accuracy=79.21% avg_sensitivity=77.75%, avg_specificity=79.63% avg_auc=86.25%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.639014 Test loss=0.464674 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.645038366317749
[5/24] Train loss=0.6238738894462585
[10/24] Train loss=0.6411288976669312
[15/24] Train loss=0.633228063583374
[20/24] Train loss=0.6105749011039734
Test set avg_accuracy=78.49% avg_sensitivity=79.14%, avg_specificity=78.30% avg_auc=86.16%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.639942 Test loss=0.482642 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.6329514384269714
[5/24] Train loss=0.6254382133483887
[10/24] Train loss=0.6509061455726624
[15/24] Train loss=0.6312546133995056
[20/24] Train loss=0.5994287133216858
Test set avg_accuracy=77.77% avg_sensitivity=80.59%, avg_specificity=76.96% avg_auc=86.26%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.630584 Test loss=0.497872 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.6174029111862183
[5/24] Train loss=0.5968684554100037
[10/24] Train loss=0.6084638237953186
[15/24] Train loss=0.6270846128463745
[20/24] Train loss=0.6088728308677673
Test set avg_accuracy=78.42% avg_sensitivity=79.37%, avg_specificity=78.15% avg_auc=86.19%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.628123 Test loss=0.483522 Current lr=[0.000134135431043539]

[0/24] Train loss=0.6351149678230286
[5/24] Train loss=0.6081035733222961
[10/24] Train loss=0.6079299449920654
[15/24] Train loss=0.6156245470046997
[20/24] Train loss=0.6059213876724243
Test set avg_accuracy=78.10% avg_sensitivity=79.49%, avg_specificity=77.70% avg_auc=86.07%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.627556 Test loss=0.489316 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.6151338219642639
[5/24] Train loss=0.5917243361473083
[10/24] Train loss=0.6158995628356934
[15/24] Train loss=0.6379492878913879
[20/24] Train loss=0.5989443063735962
Test set avg_accuracy=77.43% avg_sensitivity=80.94%, avg_specificity=76.42% avg_auc=86.11%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.626174 Test loss=0.507269 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.6248825788497925
[5/24] Train loss=0.6095513701438904
[10/24] Train loss=0.6280444860458374
[15/24] Train loss=0.6226632595062256
[20/24] Train loss=0.602318525314331
Test set avg_accuracy=78.42% avg_sensitivity=78.68%, avg_specificity=78.35% avg_auc=86.03%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.620643 Test loss=0.483244 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.6142002940177917
[5/24] Train loss=0.6182312369346619
[10/24] Train loss=0.5927601456642151
[15/24] Train loss=0.6246208548545837
[20/24] Train loss=0.6081371903419495
Test set avg_accuracy=78.36% avg_sensitivity=78.45%, avg_specificity=78.33% avg_auc=85.91%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.617745 Test loss=0.489245 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.6102868914604187
[5/24] Train loss=0.5846725702285767
[10/24] Train loss=0.6018845438957214
[15/24] Train loss=0.5917766094207764
[20/24] Train loss=0.6047785878181458
Test set avg_accuracy=77.70% avg_sensitivity=79.84%, avg_specificity=77.07% avg_auc=85.95%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.613217 Test loss=0.503567 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.6171622276306152
[5/24] Train loss=0.587489902973175
[10/24] Train loss=0.5795152187347412
[15/24] Train loss=0.6134782433509827
[20/24] Train loss=0.5761348009109497
Test set avg_accuracy=79.05% avg_sensitivity=77.11%, avg_specificity=79.61% avg_auc=85.80%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.617700 Test loss=0.477119 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.618305504322052
[5/24] Train loss=0.6013518571853638
[10/24] Train loss=0.6097201108932495
[15/24] Train loss=0.6122758388519287
[20/24] Train loss=0.5910334587097168
Test set avg_accuracy=77.77% avg_sensitivity=79.78%, avg_specificity=77.19% avg_auc=85.99%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.616782 Test loss=0.501838 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.6084585785865784
[5/24] Train loss=0.5777240991592407
[10/24] Train loss=0.5876269340515137
[15/24] Train loss=0.6118515729904175
[20/24] Train loss=0.6003382802009583
Test set avg_accuracy=76.43% avg_sensitivity=82.73%, avg_specificity=74.61% avg_auc=86.06%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.618993 Test loss=0.537641 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.5912784934043884
[5/24] Train loss=0.6107041835784912
[10/24] Train loss=0.6094639897346497
[15/24] Train loss=0.6061415076255798
[20/24] Train loss=0.6081930994987488
Test set avg_accuracy=74.41% avg_sensitivity=84.82%, avg_specificity=71.40% avg_auc=86.07%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.618817 Test loss=0.584669 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.6267207264900208
[5/24] Train loss=0.6234046220779419
[10/24] Train loss=0.6178406476974487
[15/24] Train loss=0.5948442220687866
[20/24] Train loss=0.6017969250679016
Test set avg_accuracy=75.51% avg_sensitivity=83.78%, avg_specificity=73.11% avg_auc=86.08%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.619448 Test loss=0.562290 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.605594277381897
[5/24] Train loss=0.6167489886283875
[10/24] Train loss=0.6255459189414978
[15/24] Train loss=0.6094318628311157
[20/24] Train loss=0.5996556282043457
Test set avg_accuracy=76.33% avg_sensitivity=82.33%, avg_specificity=74.59% avg_auc=85.97%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.609377 Test loss=0.540349 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.6083317995071411
[5/24] Train loss=0.576904833316803
[10/24] Train loss=0.6093336939811707
[15/24] Train loss=0.6131329536437988
[20/24] Train loss=0.585706353187561
Test set avg_accuracy=75.66% avg_sensitivity=83.20%, avg_specificity=73.48% avg_auc=85.86%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.604947 Test loss=0.555855 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.6228231191635132
[5/24] Train loss=0.5919278860092163
[10/24] Train loss=0.6260759234428406
[15/24] Train loss=0.6042038202285767
[20/24] Train loss=0.5934834480285645
Test set avg_accuracy=75.18% avg_sensitivity=83.26%, avg_specificity=72.84% avg_auc=85.73%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.608722 Test loss=0.572123 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.6357681751251221
[5/24] Train loss=0.6013038158416748
[10/24] Train loss=0.6343565583229065
[15/24] Train loss=0.605265200138092
[20/24] Train loss=0.5944539904594421
Test set avg_accuracy=74.65% avg_sensitivity=84.13%, avg_specificity=71.90% avg_auc=85.67%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.610805 Test loss=0.583454 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.6160448789596558
[5/24] Train loss=0.6141393780708313
[10/24] Train loss=0.6179476380348206
[15/24] Train loss=0.6164777278900146
[20/24] Train loss=0.6043808460235596
Test set avg_accuracy=72.77% avg_sensitivity=86.15%, avg_specificity=68.89% avg_auc=85.58%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.615416 Test loss=0.635332 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.6460441946983337
[5/24] Train loss=0.6153286695480347
[10/24] Train loss=0.6045628190040588
[15/24] Train loss=0.6236011981964111
[20/24] Train loss=0.5993478298187256
Test set avg_accuracy=72.10% avg_sensitivity=87.25%, avg_specificity=67.70% avg_auc=85.79%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.620286 Test loss=0.648244 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.6576508283615112
[5/24] Train loss=0.6057097911834717
[10/24] Train loss=0.5855465531349182
[15/24] Train loss=0.6556269526481628
[20/24] Train loss=0.6755699515342712
Test set avg_accuracy=75.38% avg_sensitivity=83.72%, avg_specificity=72.96% avg_auc=86.07%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.631718 Test loss=0.556403 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.6031895279884338
[5/24] Train loss=0.5693111419677734
[10/24] Train loss=0.6452434659004211
[15/24] Train loss=0.6432433128356934
[20/24] Train loss=0.5943530201911926
Test set avg_accuracy=78.50% avg_sensitivity=78.45%, avg_specificity=78.52% avg_auc=86.10%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.629791 Test loss=0.483912 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.5887460112571716
[5/24] Train loss=0.5648326873779297
[10/24] Train loss=0.586746096611023
[15/24] Train loss=0.611587643623352
[20/24] Train loss=0.6086078882217407
Test set avg_accuracy=76.84% avg_sensitivity=82.27%, avg_specificity=75.26% avg_auc=86.03%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.600945 Test loss=0.531569 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.5997410416603088
[5/24] Train loss=0.5643652081489563
[10/24] Train loss=0.5921589136123657
[15/24] Train loss=0.6121480464935303
[20/24] Train loss=0.568398654460907
Test set avg_accuracy=77.70% avg_sensitivity=80.36%, avg_specificity=76.92% avg_auc=85.88%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.598225 Test loss=0.512192 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.6212096810340881
[5/24] Train loss=0.5726351737976074
[10/24] Train loss=0.5851577520370483
[15/24] Train loss=0.5980040431022644
[20/24] Train loss=0.5932146906852722
Test set avg_accuracy=76.65% avg_sensitivity=81.69%, avg_specificity=75.19% avg_auc=85.79%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.597571 Test loss=0.535527 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.6096540093421936
[5/24] Train loss=0.5766574740409851
[10/24] Train loss=0.5789036154747009
[15/24] Train loss=0.5966393351554871
[20/24] Train loss=0.5841373205184937
Test set avg_accuracy=77.01% avg_sensitivity=81.29%, avg_specificity=75.76% avg_auc=85.80%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.598710 Test loss=0.528351 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.6031396389007568
[5/24] Train loss=0.5677152276039124
[10/24] Train loss=0.5714043974876404
[15/24] Train loss=0.5990583300590515
[20/24] Train loss=0.5895028710365295
Test set avg_accuracy=76.29% avg_sensitivity=82.27%, avg_specificity=74.55% avg_auc=85.75%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.595907 Test loss=0.545237 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.5970579981803894
[5/24] Train loss=0.5555824637413025
[10/24] Train loss=0.573566198348999
[15/24] Train loss=0.5945371985435486
[20/24] Train loss=0.5905605554580688
Test set avg_accuracy=76.45% avg_sensitivity=81.11%, avg_specificity=75.09% avg_auc=85.73%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.595705 Test loss=0.534978 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.5939967632293701
[5/24] Train loss=0.5687285661697388
[10/24] Train loss=0.5849358439445496
[15/24] Train loss=0.5957905650138855
[20/24] Train loss=0.5665321350097656
Test set avg_accuracy=76.08% avg_sensitivity=81.34%, avg_specificity=74.55% avg_auc=85.70%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.590338 Test loss=0.544200 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.5948285460472107
[5/24] Train loss=0.5448985695838928
[10/24] Train loss=0.5683538317680359
[15/24] Train loss=0.5982329845428467
[20/24] Train loss=0.5748355388641357
Test set avg_accuracy=75.65% avg_sensitivity=81.81%, avg_specificity=73.87% avg_auc=85.71%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.593454 Test loss=0.552767 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.6101351380348206
[5/24] Train loss=0.5735054612159729
[10/24] Train loss=0.5814883708953857
[15/24] Train loss=0.6076725721359253
[20/24] Train loss=0.5621190071105957
Test set avg_accuracy=75.52% avg_sensitivity=83.02%, avg_specificity=73.35% avg_auc=85.73%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.596121 Test loss=0.563830 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.5883926749229431
[5/24] Train loss=0.5476436614990234
[10/24] Train loss=0.5755344033241272
[15/24] Train loss=0.5755905508995056
[20/24] Train loss=0.576833963394165
Test set avg_accuracy=74.64% avg_sensitivity=84.01%, avg_specificity=71.92% avg_auc=85.75%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.591204 Test loss=0.583800 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.6040955185890198
[5/24] Train loss=0.5354096293449402
[10/24] Train loss=0.5807039737701416
[15/24] Train loss=0.5966355800628662
[20/24] Train loss=0.5757019519805908
Test set avg_accuracy=73.93% avg_sensitivity=84.76%, avg_specificity=70.79% avg_auc=85.78%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.590461 Test loss=0.599562 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.617570161819458
[5/24] Train loss=0.5552447438240051
[10/24] Train loss=0.5764132738113403
[15/24] Train loss=0.5902010202407837
[20/24] Train loss=0.5768560171127319
Test set avg_accuracy=73.54% avg_sensitivity=85.34%, avg_specificity=70.12% avg_auc=85.81%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.594017 Test loss=0.611576 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.6272682547569275
[5/24] Train loss=0.5372449159622192
[10/24] Train loss=0.5849740505218506
[15/24] Train loss=0.6214161515235901
[20/24] Train loss=0.599839448928833
Test set avg_accuracy=73.79% avg_sensitivity=85.17%, avg_specificity=70.49% avg_auc=85.82%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.600000 Test loss=0.604653 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.6306895613670349
[5/24] Train loss=0.5662469267845154
[10/24] Train loss=0.5582178831100464
[15/24] Train loss=0.6246309876441956
[20/24] Train loss=0.5939149260520935
Test set avg_accuracy=75.73% avg_sensitivity=82.79%, avg_specificity=73.68% avg_auc=85.83%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.605924 Test loss=0.553954 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.5895830392837524
[5/24] Train loss=0.58497154712677
[10/24] Train loss=0.5628051161766052
[15/24] Train loss=0.5981014966964722
[20/24] Train loss=0.6102670431137085
Test set avg_accuracy=77.85% avg_sensitivity=79.08%, avg_specificity=77.49% avg_auc=85.77%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.599658 Test loss=0.503091 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.6046604514122009
[5/24] Train loss=0.5560430288314819
[10/24] Train loss=0.5819639563560486
[15/24] Train loss=0.5923227667808533
[20/24] Train loss=0.5893054008483887
Test set avg_accuracy=78.23% avg_sensitivity=78.45%, avg_specificity=78.17% avg_auc=85.75%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.593107 Test loss=0.496368 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.574594259262085
[5/24] Train loss=0.5758225917816162
[10/24] Train loss=0.5643974542617798
[15/24] Train loss=0.5906497240066528
[20/24] Train loss=0.5706813335418701
Test set avg_accuracy=77.77% avg_sensitivity=79.26%, avg_specificity=77.34% avg_auc=85.73%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.583857 Test loss=0.509935 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.5760647654533386
[5/24] Train loss=0.5492038130760193
[10/24] Train loss=0.5658618211746216
[15/24] Train loss=0.5818426609039307
[20/24] Train loss=0.6141740679740906
Test set avg_accuracy=77.46% avg_sensitivity=79.61%, avg_specificity=76.84% avg_auc=85.72%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.584785 Test loss=0.517792 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.5862321257591248
[5/24] Train loss=0.554950475692749
[10/24] Train loss=0.5621964335441589
[15/24] Train loss=0.5863446593284607
[20/24] Train loss=0.5889618396759033
Test set avg_accuracy=77.68% avg_sensitivity=79.08%, avg_specificity=77.28% avg_auc=85.68%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.586074 Test loss=0.510386 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.5941305756568909
[5/24] Train loss=0.5479615926742554
[10/24] Train loss=0.5736794471740723
[15/24] Train loss=0.5980576276779175
[20/24] Train loss=0.6131213903427124
Test set avg_accuracy=77.43% avg_sensitivity=79.32%, avg_specificity=76.89% avg_auc=85.67%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.585175 Test loss=0.516891 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.5896905660629272
[5/24] Train loss=0.5541423559188843
[10/24] Train loss=0.5580329298973083
[15/24] Train loss=0.5792876482009888
[20/24] Train loss=0.570884108543396
Test set avg_accuracy=77.64% avg_sensitivity=79.03%, avg_specificity=77.24% avg_auc=85.65%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.580479 Test loss=0.513260 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.5937058329582214
[5/24] Train loss=0.5365996956825256
[10/24] Train loss=0.5487854480743408
[15/24] Train loss=0.6014073491096497
[20/24] Train loss=0.5693463683128357
Test set avg_accuracy=77.46% avg_sensitivity=79.32%, avg_specificity=76.92% avg_auc=85.65%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.578945 Test loss=0.517760 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.5769888758659363
[5/24] Train loss=0.5433782339096069
[10/24] Train loss=0.5545733571052551
[15/24] Train loss=0.5889413952827454
[20/24] Train loss=0.5871660113334656
Test set avg_accuracy=77.53% avg_sensitivity=79.26%, avg_specificity=77.02% avg_auc=85.64%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.584727 Test loss=0.516843 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.57731032371521
[5/24] Train loss=0.5447766184806824
[10/24] Train loss=0.5725799798965454
[15/24] Train loss=0.5639384388923645
[20/24] Train loss=0.5907958745956421
Test set avg_accuracy=77.54% avg_sensitivity=78.97%, avg_specificity=77.12% avg_auc=85.63%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.581484 Test loss=0.515903 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.6105243563652039
[5/24] Train loss=0.5619027614593506
[10/24] Train loss=0.5606254935264587
[15/24] Train loss=0.6062609553337097
[20/24] Train loss=0.5867960453033447
Test set avg_accuracy=77.45% avg_sensitivity=79.20%, avg_specificity=76.94% avg_auc=85.63%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.586692 Test loss=0.518119 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.5681453347206116
[5/24] Train loss=0.5409764051437378
[10/24] Train loss=0.5619829893112183
[15/24] Train loss=0.604219913482666
[20/24] Train loss=0.5703889727592468
Test set avg_accuracy=77.41% avg_sensitivity=79.14%, avg_specificity=76.91% avg_auc=85.63%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.577648 Test loss=0.518014 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.595151424407959
[5/24] Train loss=0.5399286150932312
[10/24] Train loss=0.5660176873207092
[15/24] Train loss=0.5835906267166138
[20/24] Train loss=0.5949251055717468
Test set avg_accuracy=77.45% avg_sensitivity=79.08%, avg_specificity=76.97% avg_auc=85.62%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.579583 Test loss=0.517458 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.5867478251457214
[5/24] Train loss=0.541701078414917
[10/24] Train loss=0.5675166249275208
[15/24] Train loss=0.5916173458099365
[20/24] Train loss=0.5679975748062134
Test set avg_accuracy=77.43% avg_sensitivity=79.08%, avg_specificity=76.96% avg_auc=85.62%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.578725 Test loss=0.517736 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.5915704965591431
[5/24] Train loss=0.5409964919090271
[10/24] Train loss=0.5628411769866943
[15/24] Train loss=0.5743324160575867
[20/24] Train loss=0.5714684128761292
Test set avg_accuracy=77.41% avg_sensitivity=79.08%, avg_specificity=76.92% avg_auc=85.62%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.579879 Test loss=0.517828 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.5775004029273987
[5/24] Train loss=0.558243453502655
[10/24] Train loss=0.5536467432975769
[15/24] Train loss=0.5980374217033386
[20/24] Train loss=0.5920869708061218
Test set avg_accuracy=77.41% avg_sensitivity=79.08%, avg_specificity=76.92% avg_auc=85.62%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.583341 Test loss=0.518004 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.5795663595199585
[5/24] Train loss=0.5563617944717407
[10/24] Train loss=0.5602660775184631
[15/24] Train loss=0.5801685452461243
[20/24] Train loss=0.5724232196807861
Test set avg_accuracy=77.41% avg_sensitivity=79.08%, avg_specificity=76.92% avg_auc=85.62%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.583403 Test loss=0.518055 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=78.39% sen=82.62%, spe=77.16%, auc=87.71%!
Fold[10] Avg_jsc=0.52%(±0.24433498450500848)
Final Avg Result: avg_acc=79.60%(±3.318317926237936) avg_sen=82.15% (±3.7395014489738303) avg_spe=78.80% (±5.22872729477844) avg_auc=88.68% (±1.7274675757559976) avg_jsc=0.57% (±0.04764357707790514)
