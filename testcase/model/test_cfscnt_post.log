/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=0.7289053797721863
[5/24] Train loss=0.7179231643676758
[10/24] Train loss=0.7064223289489746
[15/24] Train loss=0.6974090933799744
[20/24] Train loss=0.6972878575325012
Test set avg_accuracy=71.58% avg_sensitivity=28.10%, avg_specificity=87.10% avg_auc=58.80%
Best model saved!! Metric=-80.42143951558825!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.706070 Test loss=0.684885 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6909138560295105
[5/24] Train loss=0.6877927780151367
[10/24] Train loss=0.6863766312599182
[15/24] Train loss=0.6705337762832642
[20/24] Train loss=0.6627071499824524
Test set avg_accuracy=73.98% avg_sensitivity=72.34%, avg_specificity=74.57% avg_auc=70.51%
Best model saved!! Metric=-34.59183771052254!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.679172 Test loss=0.637588 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6637361645698547
[5/24] Train loss=0.6577678918838501
[10/24] Train loss=0.6581093668937683
[15/24] Train loss=0.6384019255638123
[20/24] Train loss=0.6416698098182678
Test set avg_accuracy=74.10% avg_sensitivity=76.94%, avg_specificity=73.09% avg_auc=75.67%
Best model saved!! Metric=-26.196366324564195!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.651577 Test loss=0.605459 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6309375166893005
[5/24] Train loss=0.6255307793617249
[10/24] Train loss=0.6293982863426208
[15/24] Train loss=0.6115221381187439
[20/24] Train loss=0.5984169244766235
Test set avg_accuracy=74.73% avg_sensitivity=79.71%, avg_specificity=72.95% avg_auc=79.41%
Best model saved!! Metric=-19.2060279649003!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.623343 Test loss=0.573839 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5987401604652405
[5/24] Train loss=0.5944554209709167
[10/24] Train loss=0.603531539440155
[15/24] Train loss=0.5772316455841064
[20/24] Train loss=0.5706890225410461
Test set avg_accuracy=75.60% avg_sensitivity=80.80%, avg_specificity=73.74% avg_auc=81.57%
Best model saved!! Metric=-14.285223301120041!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.594782 Test loss=0.552177 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5642592310905457
[5/24] Train loss=0.5676893591880798
[10/24] Train loss=0.5766689777374268
[15/24] Train loss=0.5471729636192322
[20/24] Train loss=0.5439901351928711
Test set avg_accuracy=76.48% avg_sensitivity=82.19%, avg_specificity=74.45% avg_auc=83.54%
Best model saved!! Metric=-9.339589471301906!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.567020 Test loss=0.533689 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5379754304885864
[5/24] Train loss=0.5360018610954285
[10/24] Train loss=0.5538284778594971
[15/24] Train loss=0.5197405219078064
[20/24] Train loss=0.5157729983329773
Test set avg_accuracy=78.03% avg_sensitivity=80.01%, avg_specificity=77.33% avg_auc=85.13%
Best model saved!! Metric=-5.495337247149678!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.537670 Test loss=0.497904 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5079935193061829
[5/24] Train loss=0.5055869221687317
[10/24] Train loss=0.5212334394454956
[15/24] Train loss=0.4922274649143219
[20/24] Train loss=0.48361361026763916
Test set avg_accuracy=79.73% avg_sensitivity=79.17%, avg_specificity=79.93% avg_auc=86.85%
Best model saved!! Metric=-0.3313113583274543!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.507181 Test loss=0.470186 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.47519609332084656
[5/24] Train loss=0.47676029801368713
[10/24] Train loss=0.4861164391040802
[15/24] Train loss=0.46334198117256165
[20/24] Train loss=0.4551200568675995
Test set avg_accuracy=81.43% avg_sensitivity=78.48%, avg_specificity=82.49% avg_auc=88.43%
Best model saved!! Metric=4.8243658228211785!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.476750 Test loss=0.439729 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4409312605857849
[5/24] Train loss=0.44377270340919495
[10/24] Train loss=0.4648686349391937
[15/24] Train loss=0.43523460626602173
[20/24] Train loss=0.4290018379688263
Test set avg_accuracy=83.06% avg_sensitivity=78.97%, avg_specificity=84.52% avg_auc=89.46%
Best model saved!! Metric=10.01531909320434!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.448138 Test loss=0.419424 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4144926369190216
[5/24] Train loss=0.41249385476112366
[10/24] Train loss=0.43600812554359436
[15/24] Train loss=0.4116034507751465
[20/24] Train loss=0.39196842908859253
Test set avg_accuracy=84.48% avg_sensitivity=79.42%, avg_specificity=86.29% avg_auc=90.40%
Best model saved!! Metric=14.583947891618777!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.420587 Test loss=0.394883 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.3898151218891144
[5/24] Train loss=0.3915248215198517
[10/24] Train loss=0.4126887619495392
[15/24] Train loss=0.3892527222633362
[20/24] Train loss=0.3598141670227051
Test set avg_accuracy=85.09% avg_sensitivity=79.86%, avg_specificity=86.96% avg_auc=91.07%
Best model saved!! Metric=16.98155156519684!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.396227 Test loss=0.377055 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3706091344356537
[5/24] Train loss=0.36816173791885376
[10/24] Train loss=0.3904244005680084
[15/24] Train loss=0.3717136085033417
[20/24] Train loss=0.34996989369392395
Test set avg_accuracy=86.16% avg_sensitivity=74.96%, avg_specificity=90.16% avg_auc=91.23%
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.375745 Test loss=0.350822 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.34948092699050903
[5/24] Train loss=0.34747880697250366
[10/24] Train loss=0.3733123242855072
[15/24] Train loss=0.3557477593421936
[20/24] Train loss=0.3377577066421509
Test set avg_accuracy=86.58% avg_sensitivity=70.06%, avg_specificity=92.47% avg_auc=91.28%
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.358353 Test loss=0.338208 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.330390602350235
[5/24] Train loss=0.32678425312042236
[10/24] Train loss=0.35542285442352295
[15/24] Train loss=0.345470666885376
[20/24] Train loss=0.3216967284679413
Test set avg_accuracy=87.01% avg_sensitivity=70.36%, avg_specificity=92.95% avg_auc=91.80%
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.342935 Test loss=0.328647 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3166174292564392
[5/24] Train loss=0.3162917196750641
[10/24] Train loss=0.3545118570327759
[15/24] Train loss=0.3338288366794586
[20/24] Train loss=0.3106062710285187
Test set avg_accuracy=86.94% avg_sensitivity=72.29%, avg_specificity=92.17% avg_auc=92.34%
Best model saved!! Metric=17.743150882634254!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.330288 Test loss=0.320957 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.30050554871559143
[5/24] Train loss=0.301151305437088
[10/24] Train loss=0.33828699588775635
[15/24] Train loss=0.31989818811416626
[20/24] Train loss=0.29302647709846497
Test set avg_accuracy=86.98% avg_sensitivity=69.52%, avg_specificity=93.21% avg_auc=92.39%
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.317952 Test loss=0.315911 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.29460814595222473
[5/24] Train loss=0.2909225821495056
[10/24] Train loss=0.3352855145931244
[15/24] Train loss=0.3111477792263031
[20/24] Train loss=0.2917529344558716
Test set avg_accuracy=87.19% avg_sensitivity=75.26%, avg_specificity=91.45% avg_auc=92.86%
Best model saved!! Metric=20.75798534127307!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.309763 Test loss=0.311745 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.2760547697544098
[5/24] Train loss=0.2846641540527344
[10/24] Train loss=0.3179529905319214
[15/24] Train loss=0.3087467551231384
[20/24] Train loss=0.28653958439826965
Test set avg_accuracy=87.68% avg_sensitivity=76.99%, avg_specificity=91.50% avg_auc=93.21%
Best model saved!! Metric=23.386788862089304!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.300224 Test loss=0.306708 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2753027081489563
[5/24] Train loss=0.2768561840057373
[10/24] Train loss=0.3141234219074249
[15/24] Train loss=0.2927081286907196
[20/24] Train loss=0.2716289758682251
Test set avg_accuracy=87.73% avg_sensitivity=75.95%, avg_specificity=91.94% avg_auc=93.19%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.293531 Test loss=0.302482 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.26766595244407654
[5/24] Train loss=0.268560528755188
[10/24] Train loss=0.3090915083885193
[15/24] Train loss=0.29042404890060425
[20/24] Train loss=0.26452457904815674
Test set avg_accuracy=88.19% avg_sensitivity=77.44%, avg_specificity=92.03% avg_auc=93.56%
Best model saved!! Metric=25.21298137950494!!
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.286465 Test loss=0.296124 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2597409188747406
[5/24] Train loss=0.2623797357082367
[10/24] Train loss=0.3036452829837799
[15/24] Train loss=0.2821837365627289
[20/24] Train loss=0.25778985023498535
Test set avg_accuracy=88.44% avg_sensitivity=75.85%, avg_specificity=92.93% avg_auc=93.60%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.280877 Test loss=0.293294 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2537018060684204
[5/24] Train loss=0.2505754828453064
[10/24] Train loss=0.3048185110092163
[15/24] Train loss=0.2787627875804901
[20/24] Train loss=0.25442007184028625
Test set avg_accuracy=88.32% avg_sensitivity=75.36%, avg_specificity=92.95% avg_auc=93.72%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.273725 Test loss=0.288247 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2528185546398163
[5/24] Train loss=0.23907379806041718
[10/24] Train loss=0.29004496335983276
[15/24] Train loss=0.27187809348106384
[20/24] Train loss=0.2445080578327179
Test set avg_accuracy=88.46% avg_sensitivity=77.68%, avg_specificity=92.31% avg_auc=93.84%
Best model saved!! Metric=26.30120695162873!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.268783 Test loss=0.288491 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.24757269024848938
[5/24] Train loss=0.24123984575271606
[10/24] Train loss=0.28499260544776917
[15/24] Train loss=0.2720649242401123
[20/24] Train loss=0.239557147026062
Test set avg_accuracy=87.68% avg_sensitivity=67.64%, avg_specificity=94.84% avg_auc=93.68%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.262879 Test loss=0.287609 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.24064357578754425
[5/24] Train loss=0.22767096757888794
[10/24] Train loss=0.2849133610725403
[15/24] Train loss=0.26864564418792725
[20/24] Train loss=0.23875628411769867
Test set avg_accuracy=88.36% avg_sensitivity=78.72%, avg_specificity=91.80% avg_auc=93.75%
Best model saved!! Metric=26.634328944879343!!
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.258458 Test loss=0.290829 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.23951482772827148
[5/24] Train loss=0.22517216205596924
[10/24] Train loss=0.2752833068370819
[15/24] Train loss=0.26296260952949524
[20/24] Train loss=0.24042974412441254
Test set avg_accuracy=87.81% avg_sensitivity=68.13%, avg_specificity=94.84% avg_auc=93.40%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.254862 Test loss=0.291325 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2371116429567337
[5/24] Train loss=0.22432789206504822
[10/24] Train loss=0.2737172842025757
[15/24] Train loss=0.25049886107444763
[20/24] Train loss=0.2291717678308487
Test set avg_accuracy=87.42% avg_sensitivity=62.64%, avg_specificity=96.27% avg_auc=93.12%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.250620 Test loss=0.297109 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2370397299528122
[5/24] Train loss=0.21463976800441742
[10/24] Train loss=0.2713002562522888
[15/24] Train loss=0.2478850930929184
[20/24] Train loss=0.22615060210227966
Test set avg_accuracy=87.15% avg_sensitivity=61.75%, avg_specificity=96.22% avg_auc=93.14%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.246015 Test loss=0.298445 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.22913622856140137
[5/24] Train loss=0.2130577564239502
[10/24] Train loss=0.2660536468029022
[15/24] Train loss=0.2495841383934021
[20/24] Train loss=0.22848498821258545
Test set avg_accuracy=88.27% avg_sensitivity=72.88%, avg_specificity=93.76% avg_auc=93.74%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.242610 Test loss=0.284841 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.22588002681732178
[5/24] Train loss=0.20994657278060913
[10/24] Train loss=0.2670697867870331
[15/24] Train loss=0.24946309626102448
[20/24] Train loss=0.22911490499973297
Test set avg_accuracy=87.41% avg_sensitivity=70.16%, avg_specificity=93.57% avg_auc=92.36%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.239271 Test loss=0.307112 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22321419417858124
[5/24] Train loss=0.20272652804851532
[10/24] Train loss=0.25064322352409363
[15/24] Train loss=0.23945879936218262
[20/24] Train loss=0.2217455953359604
Test set avg_accuracy=84.93% avg_sensitivity=82.38%, avg_specificity=85.85% avg_auc=91.15%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.232708 Test loss=0.369593 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22394700348377228
[5/24] Train loss=0.2049631029367447
[10/24] Train loss=0.26102375984191895
[15/24] Train loss=0.24304160475730896
[20/24] Train loss=0.21597270667552948
Test set avg_accuracy=87.64% avg_sensitivity=75.16%, avg_specificity=92.10% avg_auc=93.64%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.231915 Test loss=0.287114 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.21472087502479553
[5/24] Train loss=0.19992901384830475
[10/24] Train loss=0.26393961906433105
[15/24] Train loss=0.2436753362417221
[20/24] Train loss=0.20879203081130981
Test set avg_accuracy=86.09% avg_sensitivity=81.54%, avg_specificity=87.72% avg_auc=91.23%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.229469 Test loss=0.349956 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.20832130312919617
[5/24] Train loss=0.1892479509115219
[10/24] Train loss=0.26005107164382935
[15/24] Train loss=0.24215780198574066
[20/24] Train loss=0.21078602969646454
Test set avg_accuracy=84.48% avg_sensitivity=81.94%, avg_specificity=85.39% avg_auc=89.36%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.228031 Test loss=0.400339 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21252159774303436
[5/24] Train loss=0.2017870992422104
[10/24] Train loss=0.253422349691391
[15/24] Train loss=0.23645056784152985
[20/24] Train loss=0.21709579229354858
Test set avg_accuracy=83.07% avg_sensitivity=41.46%, avg_specificity=97.93% avg_auc=87.95%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.224804 Test loss=0.419830 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.24102939665317535
[5/24] Train loss=0.2089761197566986
[10/24] Train loss=0.25165796279907227
[15/24] Train loss=0.2341083586215973
[20/24] Train loss=0.2218913584947586
Test set avg_accuracy=87.16% avg_sensitivity=63.43%, avg_specificity=95.64% avg_auc=91.91%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.226745 Test loss=0.310039 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21169650554656982
[5/24] Train loss=0.18734011054039001
[10/24] Train loss=0.24664206802845
[15/24] Train loss=0.22373457252979279
[20/24] Train loss=0.1992105096578598
Test set avg_accuracy=82.41% avg_sensitivity=37.21%, avg_specificity=98.55% avg_auc=86.64%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.218095 Test loss=0.461842 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.22984881699085236
[5/24] Train loss=0.20956027507781982
[10/24] Train loss=0.26170679926872253
[15/24] Train loss=0.2336176335811615
[20/24] Train loss=0.20676100254058838
Test set avg_accuracy=85.60% avg_sensitivity=53.44%, avg_specificity=97.08% avg_auc=90.54%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.225857 Test loss=0.347207 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22382852435112
[5/24] Train loss=0.19772078096866608
[10/24] Train loss=0.2511533200740814
[15/24] Train loss=0.23734547197818756
[20/24] Train loss=0.2089189887046814
Test set avg_accuracy=87.36% avg_sensitivity=62.69%, avg_specificity=96.17% avg_auc=92.42%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.223086 Test loss=0.302927 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.19697658717632294
[5/24] Train loss=0.18753927946090698
[10/24] Train loss=0.25152361392974854
[15/24] Train loss=0.22876127064228058
[20/24] Train loss=0.2132028043270111
Test set avg_accuracy=87.24% avg_sensitivity=71.85%, avg_specificity=92.74% avg_auc=92.26%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.221624 Test loss=0.315481 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2088412493467331
[5/24] Train loss=0.18924933671951294
[10/24] Train loss=0.25064149498939514
[15/24] Train loss=0.22740380465984344
[20/24] Train loss=0.19718562066555023
Test set avg_accuracy=87.29% avg_sensitivity=72.59%, avg_specificity=92.54% avg_auc=90.72%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.217199 Test loss=0.331520 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.20173385739326477
[5/24] Train loss=0.17970100045204163
[10/24] Train loss=0.2422570139169693
[15/24] Train loss=0.2249142825603485
[20/24] Train loss=0.19909313321113586
Test set avg_accuracy=86.24% avg_sensitivity=62.49%, avg_specificity=94.72% avg_auc=91.60%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.214807 Test loss=0.321000 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.19780932366847992
[5/24] Train loss=0.18016070127487183
[10/24] Train loss=0.2422238439321518
[15/24] Train loss=0.2146265208721161
[20/24] Train loss=0.19893454015254974
Test set avg_accuracy=82.33% avg_sensitivity=86.15%, avg_specificity=80.97% avg_auc=90.59%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.213980 Test loss=0.419468 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19301867485046387
[5/24] Train loss=0.18087013065814972
[10/24] Train loss=0.23833341896533966
[15/24] Train loss=0.22387081384658813
[20/24] Train loss=0.21072344481945038
Test set avg_accuracy=87.06% avg_sensitivity=76.94%, avg_specificity=90.67% avg_auc=93.21%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.214038 Test loss=0.299745 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20206697285175323
[5/24] Train loss=0.17918454110622406
[10/24] Train loss=0.23372982442378998
[15/24] Train loss=0.2234262228012085
[20/24] Train loss=0.1985410451889038
Test set avg_accuracy=86.52% avg_sensitivity=77.59%, avg_specificity=89.72% avg_auc=92.38%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.211690 Test loss=0.321386 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2013062685728073
[5/24] Train loss=0.16528333723545074
[10/24] Train loss=0.231531023979187
[15/24] Train loss=0.225045308470726
[20/24] Train loss=0.20468783378601074
Test set avg_accuracy=83.84% avg_sensitivity=85.75%, avg_specificity=83.16% avg_auc=91.77%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.208121 Test loss=0.373870 Current lr=[0.000299720220882401]

[0/24] Train loss=0.1923840343952179
[5/24] Train loss=0.17551171779632568
[10/24] Train loss=0.21960484981536865
[15/24] Train loss=0.21488523483276367
[20/24] Train loss=0.19474981725215912
Test set avg_accuracy=84.92% avg_sensitivity=75.90%, avg_specificity=88.14% avg_auc=91.38%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.207853 Test loss=0.340187 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20227311551570892
[5/24] Train loss=0.19250109791755676
[10/24] Train loss=0.23612534999847412
[15/24] Train loss=0.2380715310573578
[20/24] Train loss=0.19254247844219208
Test set avg_accuracy=87.68% avg_sensitivity=71.10%, avg_specificity=93.60% avg_auc=93.28%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.209426 Test loss=0.291978 Current lr=[0.000298904600941902]

[0/24] Train loss=0.1919666975736618
[5/24] Train loss=0.18155865371227264
[10/24] Train loss=0.2409546673297882
[15/24] Train loss=0.22611501812934875
[20/24] Train loss=0.18963837623596191
Test set avg_accuracy=85.47% avg_sensitivity=62.64%, avg_specificity=93.62% avg_auc=90.62%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.207307 Test loss=0.336699 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19777536392211914
[5/24] Train loss=0.16797810792922974
[10/24] Train loss=0.2225983738899231
[15/24] Train loss=0.22487889230251312
[20/24] Train loss=0.18764004111289978
Test set avg_accuracy=87.07% avg_sensitivity=68.73%, avg_specificity=93.62% avg_auc=92.56%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.204078 Test loss=0.305607 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19289830327033997
[5/24] Train loss=0.1829424351453781
[10/24] Train loss=0.22531183063983917
[15/24] Train loss=0.2108852118253708
[20/24] Train loss=0.1903984397649765
Test set avg_accuracy=84.40% avg_sensitivity=83.13%, avg_specificity=84.86% avg_auc=91.76%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.201379 Test loss=0.353107 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19227464497089386
[5/24] Train loss=0.16863466799259186
[10/24] Train loss=0.2169211506843567
[15/24] Train loss=0.2196793407201767
[20/24] Train loss=0.17856433987617493
Test set avg_accuracy=83.50% avg_sensitivity=85.35%, avg_specificity=82.84% avg_auc=91.63%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.197927 Test loss=0.377440 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.1912260502576828
[5/24] Train loss=0.1610831916332245
[10/24] Train loss=0.21610169112682343
[15/24] Train loss=0.2155272662639618
[20/24] Train loss=0.18217521905899048
Test set avg_accuracy=86.58% avg_sensitivity=68.43%, avg_specificity=93.06% avg_auc=91.49%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.194475 Test loss=0.320473 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.17830140888690948
[5/24] Train loss=0.17123080790042877
[10/24] Train loss=0.22847187519073486
[15/24] Train loss=0.21692703664302826
[20/24] Train loss=0.18103133141994476
Test set avg_accuracy=87.23% avg_sensitivity=75.56%, avg_specificity=91.39% avg_auc=92.74%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.198619 Test loss=0.306057 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18528001010417938
[5/24] Train loss=0.17080585658550262
[10/24] Train loss=0.2168309986591339
[15/24] Train loss=0.2129092812538147
[20/24] Train loss=0.1831323653459549
Test set avg_accuracy=83.36% avg_sensitivity=83.72%, avg_specificity=83.23% avg_auc=91.88%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.190190 Test loss=0.371588 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18786457180976868
[5/24] Train loss=0.16081373393535614
[10/24] Train loss=0.21336700022220612
[15/24] Train loss=0.20919053256511688
[20/24] Train loss=0.18403290212154388
Test set avg_accuracy=86.30% avg_sensitivity=65.22%, avg_specificity=93.83% avg_auc=90.77%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.190339 Test loss=0.336784 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19037865102291107
[5/24] Train loss=0.1572972983121872
[10/24] Train loss=0.2193981558084488
[15/24] Train loss=0.21874253451824188
[20/24] Train loss=0.18341539800167084
Test set avg_accuracy=85.48% avg_sensitivity=77.49%, avg_specificity=88.34% avg_auc=90.27%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.191997 Test loss=0.365089 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1853226125240326
[5/24] Train loss=0.15831556916236877
[10/24] Train loss=0.20209673047065735
[15/24] Train loss=0.2108311504125595
[20/24] Train loss=0.17372708022594452
Test set avg_accuracy=86.89% avg_sensitivity=68.28%, avg_specificity=93.53% avg_auc=92.47%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.187437 Test loss=0.303255 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18381662666797638
[5/24] Train loss=0.16088107228279114
[10/24] Train loss=0.21499837934970856
[15/24] Train loss=0.20550300180912018
[20/24] Train loss=0.18136434257030487
Test set avg_accuracy=85.69% avg_sensitivity=81.64%, avg_specificity=87.14% avg_auc=92.81%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.192791 Test loss=0.325528 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.17735865712165833
[5/24] Train loss=0.1598958671092987
[10/24] Train loss=0.2096310704946518
[15/24] Train loss=0.20043551921844482
[20/24] Train loss=0.18603414297103882
Test set avg_accuracy=87.29% avg_sensitivity=67.59%, avg_specificity=94.33% avg_auc=91.47%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.188327 Test loss=0.317296 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.17969441413879395
[5/24] Train loss=0.1615821272134781
[10/24] Train loss=0.2240135669708252
[15/24] Train loss=0.22137583792209625
[20/24] Train loss=0.17471644282341003
Test set avg_accuracy=87.49% avg_sensitivity=68.33%, avg_specificity=94.33% avg_auc=92.77%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.189358 Test loss=0.300674 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17143818736076355
[5/24] Train loss=0.15954597294330597
[10/24] Train loss=0.1975599080324173
[15/24] Train loss=0.1973642259836197
[20/24] Train loss=0.16823703050613403
Test set avg_accuracy=86.63% avg_sensitivity=68.88%, avg_specificity=92.97% avg_auc=91.96%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.184131 Test loss=0.319603 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1760447770357132
[5/24] Train loss=0.15503531694412231
[10/24] Train loss=0.20198588073253632
[15/24] Train loss=0.19527970254421234
[20/24] Train loss=0.17157526314258575
Test set avg_accuracy=87.27% avg_sensitivity=67.05%, avg_specificity=94.49% avg_auc=91.21%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.184252 Test loss=0.323069 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17719878256320953
[5/24] Train loss=0.15643836557865143
[10/24] Train loss=0.20062577724456787
[15/24] Train loss=0.19667136669158936
[20/24] Train loss=0.17980924248695374
Test set avg_accuracy=87.90% avg_sensitivity=74.17%, avg_specificity=92.81% avg_auc=92.70%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.182371 Test loss=0.301560 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1677943766117096
[5/24] Train loss=0.14818055927753448
[10/24] Train loss=0.20993487536907196
[15/24] Train loss=0.18640439212322235
[20/24] Train loss=0.17522314190864563
Test set avg_accuracy=86.26% avg_sensitivity=78.62%, avg_specificity=88.99% avg_auc=92.60%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.180030 Test loss=0.320965 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.18077698349952698
[5/24] Train loss=0.15819980204105377
[10/24] Train loss=0.20697301626205444
[15/24] Train loss=0.19510503113269806
[20/24] Train loss=0.16860921680927277
Test set avg_accuracy=85.65% avg_sensitivity=85.11%, avg_specificity=85.85% avg_auc=92.23%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.184758 Test loss=0.360912 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18236291408538818
[5/24] Train loss=0.15274052321910858
[10/24] Train loss=0.2034105509519577
[15/24] Train loss=0.20791473984718323
[20/24] Train loss=0.17442217469215393
Test set avg_accuracy=83.63% avg_sensitivity=83.03%, avg_specificity=83.85% avg_auc=91.34%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.179133 Test loss=0.385442 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17317886650562286
[5/24] Train loss=0.1695815771818161
[10/24] Train loss=0.20853933691978455
[15/24] Train loss=0.19934703409671783
[20/24] Train loss=0.16352057456970215
Test set avg_accuracy=86.55% avg_sensitivity=82.83%, avg_specificity=87.88% avg_auc=91.65%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.184360 Test loss=0.357538 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17339497804641724
[5/24] Train loss=0.15242598950862885
[10/24] Train loss=0.19503946602344513
[15/24] Train loss=0.19345904886722565
[20/24] Train loss=0.17532344162464142
Test set avg_accuracy=84.11% avg_sensitivity=85.25%, avg_specificity=83.71% avg_auc=91.31%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.182182 Test loss=0.388191 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1722576916217804
[5/24] Train loss=0.1634155958890915
[10/24] Train loss=0.2063027173280716
[15/24] Train loss=0.19732873141765594
[20/24] Train loss=0.17922408878803253
Test set avg_accuracy=82.30% avg_sensitivity=84.81%, avg_specificity=81.41% avg_auc=90.58%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.182362 Test loss=0.392938 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1714933216571808
[5/24] Train loss=0.16455551981925964
[10/24] Train loss=0.19945652782917023
[15/24] Train loss=0.19879773259162903
[20/24] Train loss=0.1652429699897766
Test set avg_accuracy=87.75% avg_sensitivity=77.04%, avg_specificity=91.57% avg_auc=92.89%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.181088 Test loss=0.306744 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1694176346063614
[5/24] Train loss=0.15311798453330994
[10/24] Train loss=0.20446619391441345
[15/24] Train loss=0.1913534551858902
[20/24] Train loss=0.16580718755722046
Test set avg_accuracy=86.80% avg_sensitivity=70.46%, avg_specificity=92.63% avg_auc=91.45%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.176289 Test loss=0.324704 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16408193111419678
[5/24] Train loss=0.15299378335475922
[10/24] Train loss=0.1960170865058899
[15/24] Train loss=0.20200927555561066
[20/24] Train loss=0.176591694355011
Test set avg_accuracy=86.32% avg_sensitivity=75.61%, avg_specificity=90.14% avg_auc=90.74%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.177612 Test loss=0.346995 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1777653992176056
[5/24] Train loss=0.1546037793159485
[10/24] Train loss=0.19255518913269043
[15/24] Train loss=0.1924688071012497
[20/24] Train loss=0.1733541190624237
Test set avg_accuracy=87.59% avg_sensitivity=76.40%, avg_specificity=91.59% avg_auc=92.62%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.175897 Test loss=0.305463 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16806751489639282
[5/24] Train loss=0.14324700832366943
[10/24] Train loss=0.18310998380184174
[15/24] Train loss=0.1843993216753006
[20/24] Train loss=0.16814428567886353
Test set avg_accuracy=85.59% avg_sensitivity=80.46%, avg_specificity=87.42% avg_auc=91.33%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.171475 Test loss=0.353070 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16523203253746033
[5/24] Train loss=0.15229125320911407
[10/24] Train loss=0.17694610357284546
[15/24] Train loss=0.18942375481128693
[20/24] Train loss=0.16308386623859406
Test set avg_accuracy=87.70% avg_sensitivity=67.44%, avg_specificity=94.93% avg_auc=90.18%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.172653 Test loss=0.329067 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17432436347007751
[5/24] Train loss=0.14019328355789185
[10/24] Train loss=0.1733759641647339
[15/24] Train loss=0.18160782754421234
[20/24] Train loss=0.1599859893321991
Test set avg_accuracy=86.71% avg_sensitivity=79.42%, avg_specificity=89.31% avg_auc=90.76%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.171197 Test loss=0.363077 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16623461246490479
[5/24] Train loss=0.149818554520607
[10/24] Train loss=0.18484120070934296
[15/24] Train loss=0.1886259764432907
[20/24] Train loss=0.16432401537895203
Test set avg_accuracy=86.07% avg_sensitivity=81.10%, avg_specificity=87.84% avg_auc=92.29%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.170893 Test loss=0.343128 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.1608595997095108
[5/24] Train loss=0.14265526831150055
[10/24] Train loss=0.1795705407857895
[15/24] Train loss=0.1774793416261673
[20/24] Train loss=0.1616043746471405
Test set avg_accuracy=87.75% avg_sensitivity=73.28%, avg_specificity=92.91% avg_auc=91.18%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.169253 Test loss=0.324057 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16104073822498322
[5/24] Train loss=0.14796355366706848
[10/24] Train loss=0.16169284284114838
[15/24] Train loss=0.192759171128273
[20/24] Train loss=0.1638382375240326
Test set avg_accuracy=86.95% avg_sensitivity=68.48%, avg_specificity=93.55% avg_auc=90.20%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.167023 Test loss=0.343170 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16235505044460297
[5/24] Train loss=0.13818080723285675
[10/24] Train loss=0.1707461178302765
[15/24] Train loss=0.1882685124874115
[20/24] Train loss=0.15967480838298798
Test set avg_accuracy=87.01% avg_sensitivity=65.71%, avg_specificity=94.61% avg_auc=90.50%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.169454 Test loss=0.327632 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15934604406356812
[5/24] Train loss=0.15451349318027496
[10/24] Train loss=0.17155393958091736
[15/24] Train loss=0.19204315543174744
[20/24] Train loss=0.16580858826637268
Test set avg_accuracy=84.83% avg_sensitivity=51.51%, avg_specificity=96.73% avg_auc=86.51%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.170209 Test loss=0.402068 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.15875890851020813
[5/24] Train loss=0.14907154440879822
[10/24] Train loss=0.1776876598596573
[15/24] Train loss=0.18406610190868378
[20/24] Train loss=0.162865549325943
Test set avg_accuracy=87.64% avg_sensitivity=66.60%, avg_specificity=95.16% avg_auc=90.90%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.170188 Test loss=0.328077 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1643158197402954
[5/24] Train loss=0.1478567272424698
[10/24] Train loss=0.16890157759189606
[15/24] Train loss=0.1867782324552536
[20/24] Train loss=0.17000940442085266
Test set avg_accuracy=86.20% avg_sensitivity=58.63%, avg_specificity=96.04% avg_auc=89.37%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.170541 Test loss=0.353390 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.16041071712970734
[5/24] Train loss=0.14703023433685303
[10/24] Train loss=0.16532030701637268
[15/24] Train loss=0.18962685763835907
[20/24] Train loss=0.17073456943035126
Test set avg_accuracy=85.62% avg_sensitivity=82.24%, avg_specificity=86.84% avg_auc=92.40%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.170345 Test loss=0.343609 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1672336310148239
[5/24] Train loss=0.14992812275886536
[10/24] Train loss=0.1590520292520523
[15/24] Train loss=0.18513663113117218
[20/24] Train loss=0.16534575819969177
Test set avg_accuracy=86.61% avg_sensitivity=71.40%, avg_specificity=92.05% avg_auc=90.88%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.166729 Test loss=0.339866 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16377580165863037
[5/24] Train loss=0.1509641855955124
[10/24] Train loss=0.17071408033370972
[15/24] Train loss=0.17331711947917938
[20/24] Train loss=0.15942712128162384
Test set avg_accuracy=86.69% avg_sensitivity=62.69%, avg_specificity=95.26% avg_auc=89.28%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.166588 Test loss=0.351769 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1622525304555893
[5/24] Train loss=0.14027196168899536
[10/24] Train loss=0.17094165086746216
[15/24] Train loss=0.1776229590177536
[20/24] Train loss=0.15260083973407745
Test set avg_accuracy=86.95% avg_sensitivity=75.31%, avg_specificity=91.11% avg_auc=91.33%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.165068 Test loss=0.344572 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1563175916671753
[5/24] Train loss=0.13998690247535706
[10/24] Train loss=0.15578772127628326
[15/24] Train loss=0.18043115735054016
[20/24] Train loss=0.14804494380950928
Test set avg_accuracy=85.69% avg_sensitivity=56.90%, avg_specificity=95.97% avg_auc=87.83%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.160609 Test loss=0.360302 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1617325246334076
[5/24] Train loss=0.14230042695999146
[10/24] Train loss=0.16799396276474
[15/24] Train loss=0.17307093739509583
[20/24] Train loss=0.15445522964000702
Test set avg_accuracy=84.18% avg_sensitivity=46.76%, avg_specificity=97.54% avg_auc=86.19%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.158713 Test loss=0.395306 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15611936151981354
[5/24] Train loss=0.13707764446735382
[10/24] Train loss=0.15651048719882965
[15/24] Train loss=0.1755969077348709
[20/24] Train loss=0.1603267788887024
Test set avg_accuracy=86.22% avg_sensitivity=62.05%, avg_specificity=94.86% avg_auc=90.35%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.161942 Test loss=0.335565 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15599116683006287
[5/24] Train loss=0.14051158726215363
[10/24] Train loss=0.15973211824893951
[15/24] Train loss=0.18031896650791168
[20/24] Train loss=0.155198872089386
Test set avg_accuracy=86.24% avg_sensitivity=59.92%, avg_specificity=95.64% avg_auc=88.33%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.159681 Test loss=0.351863 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15409348905086517
[5/24] Train loss=0.13672062754631042
[10/24] Train loss=0.16403630375862122
[15/24] Train loss=0.17031383514404297
[20/24] Train loss=0.15904657542705536
Test set avg_accuracy=86.24% avg_sensitivity=65.41%, avg_specificity=93.67% avg_auc=90.08%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.161275 Test loss=0.335536 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15957604348659515
[5/24] Train loss=0.1406765878200531
[10/24] Train loss=0.16208986937999725
[15/24] Train loss=0.17387638986110687
[20/24] Train loss=0.15320821106433868
Test set avg_accuracy=86.90% avg_sensitivity=67.39%, avg_specificity=93.87% avg_auc=90.62%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.159717 Test loss=0.326959 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15504592657089233
[5/24] Train loss=0.13843175768852234
[10/24] Train loss=0.15337315201759338
[15/24] Train loss=0.17014771699905396
[20/24] Train loss=0.15021447837352753
Test set avg_accuracy=87.76% avg_sensitivity=70.86%, avg_specificity=93.80% avg_auc=91.59%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.156397 Test loss=0.312709 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15335582196712494
[5/24] Train loss=0.1360502988100052
[10/24] Train loss=0.15965954959392548
[15/24] Train loss=0.16518624126911163
[20/24] Train loss=0.15090204775333405
Test set avg_accuracy=87.25% avg_sensitivity=66.40%, avg_specificity=94.70% avg_auc=91.34%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.155417 Test loss=0.321490 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.15408548712730408
[5/24] Train loss=0.14537495374679565
[10/24] Train loss=0.1474989652633667
[15/24] Train loss=0.1665094494819641
[20/24] Train loss=0.14674489200115204
Test set avg_accuracy=87.51% avg_sensitivity=65.26%, avg_specificity=95.46% avg_auc=91.87%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.156719 Test loss=0.314774 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15324389934539795
[5/24] Train loss=0.13931679725646973
[10/24] Train loss=0.15738332271575928
[15/24] Train loss=0.16584470868110657
[20/24] Train loss=0.150694340467453
Test set avg_accuracy=85.21% avg_sensitivity=50.67%, avg_specificity=97.54% avg_auc=88.02%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.157468 Test loss=0.371526 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15764857828617096
[5/24] Train loss=0.1422877311706543
[10/24] Train loss=0.15651839971542358
[15/24] Train loss=0.1737716645002365
[20/24] Train loss=0.15443845093250275
Test set avg_accuracy=87.02% avg_sensitivity=64.37%, avg_specificity=95.11% avg_auc=90.90%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.156263 Test loss=0.317899 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14653855562210083
[5/24] Train loss=0.14333535730838776
[10/24] Train loss=0.15083938837051392
[15/24] Train loss=0.15812937915325165
[20/24] Train loss=0.1485808789730072
Test set avg_accuracy=87.17% avg_sensitivity=65.26%, avg_specificity=95.00% avg_auc=91.20%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.152678 Test loss=0.312045 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15072724223136902
[5/24] Train loss=0.13865534961223602
[10/24] Train loss=0.15058375895023346
[15/24] Train loss=0.1725466251373291
[20/24] Train loss=0.1515028029680252
Test set avg_accuracy=87.11% avg_sensitivity=62.00%, avg_specificity=96.08% avg_auc=90.96%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.153753 Test loss=0.319432 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15239347517490387
[5/24] Train loss=0.13629251718521118
[10/24] Train loss=0.15098321437835693
[15/24] Train loss=0.16928331553936005
[20/24] Train loss=0.15159544348716736
Test set avg_accuracy=86.64% avg_sensitivity=67.10%, avg_specificity=93.62% avg_auc=90.71%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.153689 Test loss=0.324831 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15202414989471436
[5/24] Train loss=0.13069425523281097
[10/24] Train loss=0.14927540719509125
[15/24] Train loss=0.1663942039012909
[20/24] Train loss=0.15126903355121613
Test set avg_accuracy=85.68% avg_sensitivity=51.95%, avg_specificity=97.72% avg_auc=89.01%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.152145 Test loss=0.368265 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14801344275474548
[5/24] Train loss=0.13963162899017334
[10/24] Train loss=0.14260534942150116
[15/24] Train loss=0.16212186217308044
[20/24] Train loss=0.14901123940944672
Test set avg_accuracy=84.69% avg_sensitivity=48.89%, avg_specificity=97.47% avg_auc=84.76%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.152307 Test loss=0.420521 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14457125961780548
[5/24] Train loss=0.13807810842990875
[10/24] Train loss=0.14378678798675537
[15/24] Train loss=0.1612032800912857
[20/24] Train loss=0.1493998020887375
Test set avg_accuracy=87.73% avg_sensitivity=71.70%, avg_specificity=93.46% avg_auc=92.28%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.151047 Test loss=0.306038 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14354771375656128
[5/24] Train loss=0.13508756458759308
[10/24] Train loss=0.15583175420761108
[15/24] Train loss=0.16708603501319885
[20/24] Train loss=0.1442716270685196
Test set avg_accuracy=87.23% avg_sensitivity=71.65%, avg_specificity=92.79% avg_auc=91.90%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.149407 Test loss=0.316670 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1457555741071701
[5/24] Train loss=0.1341647207736969
[10/24] Train loss=0.1462046056985855
[15/24] Train loss=0.16019795835018158
[20/24] Train loss=0.15134380757808685
Test set avg_accuracy=88.06% avg_sensitivity=72.88%, avg_specificity=93.48% avg_auc=92.68%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.148238 Test loss=0.303178 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13909445703029633
[5/24] Train loss=0.13635104894638062
[10/24] Train loss=0.14326198399066925
[15/24] Train loss=0.15556634962558746
[20/24] Train loss=0.1495913863182068
Test set avg_accuracy=87.85% avg_sensitivity=70.41%, avg_specificity=94.08% avg_auc=92.12%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.146669 Test loss=0.306933 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1391766369342804
[5/24] Train loss=0.1351664662361145
[10/24] Train loss=0.13903434574604034
[15/24] Train loss=0.1601504236459732
[20/24] Train loss=0.14115217328071594
Test set avg_accuracy=87.41% avg_sensitivity=68.98%, avg_specificity=93.99% avg_auc=92.16%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.144519 Test loss=0.309634 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13718093931674957
[5/24] Train loss=0.1279594600200653
[10/24] Train loss=0.14542058110237122
[15/24] Train loss=0.15494900941848755
[20/24] Train loss=0.14432965219020844
Test set avg_accuracy=87.28% avg_sensitivity=75.31%, avg_specificity=91.55% avg_auc=92.50%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.141856 Test loss=0.315264 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14045046269893646
[5/24] Train loss=0.13032208383083344
[10/24] Train loss=0.13537687063217163
[15/24] Train loss=0.15194734930992126
[20/24] Train loss=0.1367083340883255
Test set avg_accuracy=87.34% avg_sensitivity=65.56%, avg_specificity=95.12% avg_auc=91.62%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.140630 Test loss=0.309162 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13501675426959991
[5/24] Train loss=0.12629877030849457
[10/24] Train loss=0.1359715759754181
[15/24] Train loss=0.1517706960439682
[20/24] Train loss=0.13975492119789124
Test set avg_accuracy=87.72% avg_sensitivity=72.84%, avg_specificity=93.04% avg_auc=92.25%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.140312 Test loss=0.311307 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13733330368995667
[5/24] Train loss=0.1291467547416687
[10/24] Train loss=0.13823717832565308
[15/24] Train loss=0.15024201571941376
[20/24] Train loss=0.1453360915184021
Test set avg_accuracy=88.09% avg_sensitivity=72.39%, avg_specificity=93.69% avg_auc=92.88%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.141528 Test loss=0.298697 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13790057599544525
[5/24] Train loss=0.12459180504083633
[10/24] Train loss=0.13685140013694763
[15/24] Train loss=0.14875657856464386
[20/24] Train loss=0.13845238089561462
Test set avg_accuracy=86.93% avg_sensitivity=62.10%, avg_specificity=95.79% avg_auc=90.71%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.139658 Test loss=0.326694 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13269414007663727
[5/24] Train loss=0.12523946166038513
[10/24] Train loss=0.1360761970281601
[15/24] Train loss=0.1427091360092163
[20/24] Train loss=0.13630232214927673
Test set avg_accuracy=86.81% avg_sensitivity=59.43%, avg_specificity=96.59% avg_auc=90.61%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.137436 Test loss=0.334168 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13711929321289062
[5/24] Train loss=0.12411212921142578
[10/24] Train loss=0.13650205731391907
[15/24] Train loss=0.13946934044361115
[20/24] Train loss=0.139286071062088
Test set avg_accuracy=86.69% avg_sensitivity=60.56%, avg_specificity=96.02% avg_auc=90.83%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.136993 Test loss=0.327020 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1303921937942505
[5/24] Train loss=0.12042716890573502
[10/24] Train loss=0.13006705045700073
[15/24] Train loss=0.1434904783964157
[20/24] Train loss=0.13380564749240875
Test set avg_accuracy=86.48% avg_sensitivity=59.08%, avg_specificity=96.27% avg_auc=90.71%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.135282 Test loss=0.333967 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13427312672138214
[5/24] Train loss=0.11963099241256714
[10/24] Train loss=0.13165335357189178
[15/24] Train loss=0.1416822224855423
[20/24] Train loss=0.13274379074573517
Test set avg_accuracy=86.85% avg_sensitivity=64.62%, avg_specificity=94.79% avg_auc=91.25%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.134920 Test loss=0.315060 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13126122951507568
[5/24] Train loss=0.12027216702699661
[10/24] Train loss=0.13136351108551025
[15/24] Train loss=0.14014829695224762
[20/24] Train loss=0.13495922088623047
Test set avg_accuracy=87.47% avg_sensitivity=71.30%, avg_specificity=93.25% avg_auc=91.77%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.133887 Test loss=0.313012 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13000009953975677
[5/24] Train loss=0.12316440045833588
[10/24] Train loss=0.13159769773483276
[15/24] Train loss=0.14563363790512085
[20/24] Train loss=0.13316388428211212
Test set avg_accuracy=87.55% avg_sensitivity=68.13%, avg_specificity=94.49% avg_auc=92.16%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.133614 Test loss=0.309184 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.12967541813850403
[5/24] Train loss=0.11862693727016449
[10/24] Train loss=0.1273469775915146
[15/24] Train loss=0.1347598284482956
[20/24] Train loss=0.1318901777267456
Test set avg_accuracy=86.99% avg_sensitivity=66.60%, avg_specificity=94.27% avg_auc=91.48%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.131751 Test loss=0.315814 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13083019852638245
[5/24] Train loss=0.12080660462379456
[10/24] Train loss=0.12730097770690918
[15/24] Train loss=0.1386549174785614
[20/24] Train loss=0.1335388869047165
Test set avg_accuracy=87.07% avg_sensitivity=67.89%, avg_specificity=93.92% avg_auc=91.73%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.132142 Test loss=0.316037 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12794159352779388
[5/24] Train loss=0.1198202595114708
[10/24] Train loss=0.12249715626239777
[15/24] Train loss=0.13941913843154907
[20/24] Train loss=0.12937992811203003
Test set avg_accuracy=87.28% avg_sensitivity=71.15%, avg_specificity=93.04% avg_auc=92.12%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.130382 Test loss=0.309521 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12862151861190796
[5/24] Train loss=0.11891411244869232
[10/24] Train loss=0.12668836116790771
[15/24] Train loss=0.13630050420761108
[20/24] Train loss=0.13122954964637756
Test set avg_accuracy=87.46% avg_sensitivity=72.44%, avg_specificity=92.83% avg_auc=92.16%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.130108 Test loss=0.316900 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12869878113269806
[5/24] Train loss=0.11824245750904083
[10/24] Train loss=0.1258375346660614
[15/24] Train loss=0.13645289838314056
[20/24] Train loss=0.12833787500858307
Test set avg_accuracy=87.11% avg_sensitivity=70.76%, avg_specificity=92.95% avg_auc=91.60%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.129917 Test loss=0.314909 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12599538266658783
[5/24] Train loss=0.12010218948125839
[10/24] Train loss=0.12505097687244415
[15/24] Train loss=0.13716551661491394
[20/24] Train loss=0.13239899277687073
Test set avg_accuracy=86.47% avg_sensitivity=73.68%, avg_specificity=91.04% avg_auc=91.61%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.130473 Test loss=0.331866 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12670396268367767
[5/24] Train loss=0.11824499815702438
[10/24] Train loss=0.1250874102115631
[15/24] Train loss=0.13447174429893494
[20/24] Train loss=0.13073642551898956
Test set avg_accuracy=87.04% avg_sensitivity=75.90%, avg_specificity=91.02% avg_auc=92.35%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.130109 Test loss=0.319226 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1288996934890747
[5/24] Train loss=0.1197129413485527
[10/24] Train loss=0.12497130036354065
[15/24] Train loss=0.13624067604541779
[20/24] Train loss=0.1300981491804123
Test set avg_accuracy=86.95% avg_sensitivity=71.15%, avg_specificity=92.60% avg_auc=91.46%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.129505 Test loss=0.321043 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1267988085746765
[5/24] Train loss=0.11870204657316208
[10/24] Train loss=0.12319600582122803
[15/24] Train loss=0.1351759433746338
[20/24] Train loss=0.1327379047870636
Test set avg_accuracy=87.38% avg_sensitivity=72.64%, avg_specificity=92.65% avg_auc=92.02%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.129494 Test loss=0.315139 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12553545832633972
[5/24] Train loss=0.11707510054111481
[10/24] Train loss=0.12299942970275879
[15/24] Train loss=0.13293321430683136
[20/24] Train loss=0.12919765710830688
Test set avg_accuracy=87.25% avg_sensitivity=74.37%, avg_specificity=91.85% avg_auc=92.49%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.128736 Test loss=0.312202 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12717610597610474
[5/24] Train loss=0.11519570648670197
[10/24] Train loss=0.12050753831863403
[15/24] Train loss=0.1293971985578537
[20/24] Train loss=0.12850399315357208
Test set avg_accuracy=87.55% avg_sensitivity=72.44%, avg_specificity=92.95% avg_auc=92.28%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.127101 Test loss=0.306397 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12360908836126328
[5/24] Train loss=0.11573345959186554
[10/24] Train loss=0.12051701545715332
[15/24] Train loss=0.13260416686534882
[20/24] Train loss=0.12629005312919617
Test set avg_accuracy=87.15% avg_sensitivity=72.24%, avg_specificity=92.47% avg_auc=92.00%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.126498 Test loss=0.314369 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12334423512220383
[5/24] Train loss=0.11616408079862595
[10/24] Train loss=0.11907486617565155
[15/24] Train loss=0.1306782066822052
[20/24] Train loss=0.12525171041488647
Test set avg_accuracy=87.41% avg_sensitivity=71.94%, avg_specificity=92.93% avg_auc=91.92%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.125324 Test loss=0.311426 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1214800551533699
[5/24] Train loss=0.11556067317724228
[10/24] Train loss=0.12132135033607483
[15/24] Train loss=0.1264173984527588
[20/24] Train loss=0.12671403586864471
Test set avg_accuracy=87.37% avg_sensitivity=74.96%, avg_specificity=91.80% avg_auc=92.52%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.124637 Test loss=0.312052 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.11991908401250839
[5/24] Train loss=0.116572305560112
[10/24] Train loss=0.11750722676515579
[15/24] Train loss=0.12888933718204498
[20/24] Train loss=0.12496724724769592
Test set avg_accuracy=87.24% avg_sensitivity=71.94%, avg_specificity=92.70% avg_auc=92.15%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.124025 Test loss=0.310735 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12087541818618774
[5/24] Train loss=0.11284750699996948
[10/24] Train loss=0.12053604423999786
[15/24] Train loss=0.1289689689874649
[20/24] Train loss=0.12492060661315918
Test set avg_accuracy=87.28% avg_sensitivity=72.34%, avg_specificity=92.61% avg_auc=92.03%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.123743 Test loss=0.313076 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1191924512386322
[5/24] Train loss=0.11344654113054276
[10/24] Train loss=0.11613962799310684
[15/24] Train loss=0.12802287936210632
[20/24] Train loss=0.1260826587677002
Test set avg_accuracy=87.21% avg_sensitivity=72.59%, avg_specificity=92.44% avg_auc=92.15%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.123193 Test loss=0.311476 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11915304511785507
[5/24] Train loss=0.11315429210662842
[10/24] Train loss=0.11686933785676956
[15/24] Train loss=0.1304887980222702
[20/24] Train loss=0.12772147357463837
Test set avg_accuracy=87.10% avg_sensitivity=71.99%, avg_specificity=92.49% avg_auc=92.09%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.122461 Test loss=0.312459 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1215377226471901
[5/24] Train loss=0.1142081618309021
[10/24] Train loss=0.11640222370624542
[15/24] Train loss=0.12694130837917328
[20/24] Train loss=0.12349320203065872
Test set avg_accuracy=86.97% avg_sensitivity=71.80%, avg_specificity=92.38% avg_auc=92.10%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.122898 Test loss=0.312951 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11972562968730927
[5/24] Train loss=0.11297596246004105
[10/24] Train loss=0.1165977194905281
[15/24] Train loss=0.12617135047912598
[20/24] Train loss=0.12399176508188248
Test set avg_accuracy=87.17% avg_sensitivity=71.35%, avg_specificity=92.83% avg_auc=92.03%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.122422 Test loss=0.312572 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11938732117414474
[5/24] Train loss=0.11518602818250656
[10/24] Train loss=0.11519016325473785
[15/24] Train loss=0.12612681090831757
[20/24] Train loss=0.12255222350358963
Test set avg_accuracy=87.04% avg_sensitivity=71.15%, avg_specificity=92.72% avg_auc=92.13%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.122213 Test loss=0.311423 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11793642491102219
[5/24] Train loss=0.11182235181331635
[10/24] Train loss=0.11571329832077026
[15/24] Train loss=0.12636156380176544
[20/24] Train loss=0.1272784024477005
Test set avg_accuracy=87.20% avg_sensitivity=71.94%, avg_specificity=92.65% avg_auc=92.12%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.122118 Test loss=0.312012 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.11974634230136871
[5/24] Train loss=0.11156247556209564
[10/24] Train loss=0.11604117602109909
[15/24] Train loss=0.12927137315273285
[20/24] Train loss=0.12352897971868515
Test set avg_accuracy=87.19% avg_sensitivity=71.50%, avg_specificity=92.79% avg_auc=92.00%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.122076 Test loss=0.313417 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11799927055835724
[5/24] Train loss=0.11111455410718918
[10/24] Train loss=0.11640410870313644
[15/24] Train loss=0.12687496840953827
[20/24] Train loss=0.12341471016407013
Test set avg_accuracy=87.28% avg_sensitivity=71.80%, avg_specificity=92.81% avg_auc=91.98%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.121823 Test loss=0.313348 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12102343887090683
[5/24] Train loss=0.11137276142835617
[10/24] Train loss=0.11625924706459045
[15/24] Train loss=0.12651407718658447
[20/24] Train loss=0.12352287024259567
Test set avg_accuracy=87.25% avg_sensitivity=71.75%, avg_specificity=92.79% avg_auc=92.02%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.121760 Test loss=0.312982 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12117426097393036
[5/24] Train loss=0.11250221729278564
[10/24] Train loss=0.116424061357975
[15/24] Train loss=0.12763242423534393
[20/24] Train loss=0.12714405357837677
Test set avg_accuracy=87.28% avg_sensitivity=71.85%, avg_specificity=92.79% avg_auc=92.00%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.122306 Test loss=0.312975 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11751675605773926
[5/24] Train loss=0.11168046295642853
[10/24] Train loss=0.11636108160018921
[15/24] Train loss=0.126108318567276
[20/24] Train loss=0.12663456797599792
Test set avg_accuracy=87.23% avg_sensitivity=71.75%, avg_specificity=92.75% avg_auc=92.00%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.121724 Test loss=0.313169 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11976534128189087
[5/24] Train loss=0.11115523427724838
[10/24] Train loss=0.1180238351225853
[15/24] Train loss=0.12791258096694946
[20/24] Train loss=0.12352067977190018
Test set avg_accuracy=87.23% avg_sensitivity=71.75%, avg_specificity=92.75% avg_auc=91.99%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.121812 Test loss=0.313159 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11883512139320374
[5/24] Train loss=0.1127704530954361
[10/24] Train loss=0.11626680940389633
[15/24] Train loss=0.12673038244247437
[20/24] Train loss=0.12473709136247635
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.27% avg_sensitivity=71.80%, avg_specificity=92.79% avg_auc=91.99%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.121446 Test loss=0.313070 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=88.36% sen=78.72%, spe=91.80%, auc=93.75%!
Fold[1] Avg_overlap=0.71%(0.23110326739561168)
[0/24] Train loss=0.7188782691955566
[5/24] Train loss=0.7172922492027283
[10/24] Train loss=0.7061182856559753
[15/24] Train loss=0.7016282677650452
[20/24] Train loss=0.682798445224762
Test set avg_accuracy=58.23% avg_sensitivity=56.13%, avg_specificity=58.93% avg_auc=55.96%
Best model saved!! Metric=-96.75512785115524!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.705270 Test loss=0.702677 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6873477697372437
[5/24] Train loss=0.6834654808044434
[10/24] Train loss=0.6737601161003113
[15/24] Train loss=0.668297290802002
[20/24] Train loss=0.6706359386444092
Test set avg_accuracy=73.71% avg_sensitivity=72.72%, avg_specificity=74.04% avg_auc=70.66%
Best model saved!! Metric=-34.87007889703064!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.677042 Test loss=0.627247 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6578036546707153
[5/24] Train loss=0.6538477540016174
[10/24] Train loss=0.642806351184845
[15/24] Train loss=0.6367056965827942
[20/24] Train loss=0.63575279712677
Test set avg_accuracy=74.31% avg_sensitivity=75.69%, avg_specificity=73.85% avg_auc=76.41%
Best model saved!! Metric=-25.736968885936463!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.649250 Test loss=0.591637 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6285496354103088
[5/24] Train loss=0.6165605187416077
[10/24] Train loss=0.6184257864952087
[15/24] Train loss=0.6043400764465332
[20/24] Train loss=0.6083519458770752
Test set avg_accuracy=74.49% avg_sensitivity=77.73%, avg_specificity=73.42% avg_auc=78.98%
Best model saved!! Metric=-21.382449425737562!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.621131 Test loss=0.568877 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6016392707824707
[5/24] Train loss=0.5877052545547485
[10/24] Train loss=0.5893285274505615
[15/24] Train loss=0.5834611058235168
[20/24] Train loss=0.5775500535964966
Test set avg_accuracy=75.10% avg_sensitivity=76.42%, avg_specificity=74.67% avg_auc=81.10%
Best model saved!! Metric=-18.711900629327232!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.594118 Test loss=0.542715 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5712036490440369
[5/24] Train loss=0.5558250546455383
[10/24] Train loss=0.55718994140625
[15/24] Train loss=0.5515722036361694
[20/24] Train loss=0.5451163053512573
Test set avg_accuracy=76.74% avg_sensitivity=76.00%, avg_specificity=76.99% avg_auc=82.98%
Best model saved!! Metric=-13.28058073987944!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.563572 Test loss=0.511217 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5341796278953552
[5/24] Train loss=0.5232824683189392
[10/24] Train loss=0.52401202917099
[15/24] Train loss=0.5138432383537292
[20/24] Train loss=0.5202285647392273
Test set avg_accuracy=78.50% avg_sensitivity=76.89%, avg_specificity=79.04% avg_auc=84.44%
Best model saved!! Metric=-7.1230852659748365!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.534851 Test loss=0.488518 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5093712210655212
[5/24] Train loss=0.49045997858047485
[10/24] Train loss=0.4939122200012207
[15/24] Train loss=0.4857920706272125
[20/24] Train loss=0.4853903353214264
Test set avg_accuracy=81.12% avg_sensitivity=76.42%, avg_specificity=82.68% avg_auc=85.67%
Best model saved!! Metric=-0.10217321624847386!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.504755 Test loss=0.460685 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4771428108215332
[5/24] Train loss=0.46449604630470276
[10/24] Train loss=0.4620414674282074
[15/24] Train loss=0.4549609124660492
[20/24] Train loss=0.4497312009334564
Test set avg_accuracy=82.42% avg_sensitivity=77.05%, avg_specificity=84.21% avg_auc=87.13%
Best model saved!! Metric=4.810259302899695!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.475178 Test loss=0.436328 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.44881290197372437
[5/24] Train loss=0.4275423288345337
[10/24] Train loss=0.43129706382751465
[15/24] Train loss=0.42997026443481445
[20/24] Train loss=0.4191230237483978
Test set avg_accuracy=84.06% avg_sensitivity=77.15%, avg_specificity=86.36% avg_auc=88.11%
Best model saved!! Metric=9.68653007837581!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.446022 Test loss=0.413850 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.41914746165275574
[5/24] Train loss=0.40230947732925415
[10/24] Train loss=0.41352877020835876
[15/24] Train loss=0.400371789932251
[20/24] Train loss=0.3920712471008301
Test set avg_accuracy=84.71% avg_sensitivity=76.94%, avg_specificity=87.30% avg_auc=88.98%
Best model saved!! Metric=11.932129548221056!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.418845 Test loss=0.400028 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.3916492760181427
[5/24] Train loss=0.3778017461299896
[10/24] Train loss=0.3837101459503174
[15/24] Train loss=0.37990060448646545
[20/24] Train loss=0.36307603120803833
Test set avg_accuracy=85.61% avg_sensitivity=74.39%, avg_specificity=89.35% avg_auc=89.71%
Best model saved!! Metric=13.055542067842822!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.395309 Test loss=0.373218 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.37105482816696167
[5/24] Train loss=0.357731431722641
[10/24] Train loss=0.3704635202884674
[15/24] Train loss=0.35706037282943726
[20/24] Train loss=0.3434103727340698
Test set avg_accuracy=85.79% avg_sensitivity=76.00%, avg_specificity=89.05% avg_auc=90.20%
Best model saved!! Metric=15.050758829762643!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.375015 Test loss=0.366937 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3481028378009796
[5/24] Train loss=0.3371869921684265
[10/24] Train loss=0.3511165678501129
[15/24] Train loss=0.3403427302837372
[20/24] Train loss=0.32982784509658813
Test set avg_accuracy=86.17% avg_sensitivity=75.48%, avg_specificity=89.73% avg_auc=90.75%
Best model saved!! Metric=16.132837269785213!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.357125 Test loss=0.354447 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.33569446206092834
[5/24] Train loss=0.32429054379463196
[10/24] Train loss=0.34041810035705566
[15/24] Train loss=0.3291899859905243
[20/24] Train loss=0.3137771785259247
Test set avg_accuracy=86.26% avg_sensitivity=75.07%, avg_specificity=89.99% avg_auc=91.16%
Best model saved!! Metric=16.478534492275585!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.343526 Test loss=0.341356 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3129471242427826
[5/24] Train loss=0.3191676735877991
[10/24] Train loss=0.3265605568885803
[15/24] Train loss=0.31510233879089355
[20/24] Train loss=0.29787737131118774
Test set avg_accuracy=86.84% avg_sensitivity=75.17%, avg_specificity=90.72% avg_auc=91.37%
Best model saved!! Metric=18.09106846832809!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.331427 Test loss=0.333532 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.30460819602012634
[5/24] Train loss=0.30254295468330383
[10/24] Train loss=0.31367242336273193
[15/24] Train loss=0.2997038662433624
[20/24] Train loss=0.2840045988559723
Test set avg_accuracy=86.67% avg_sensitivity=76.42%, avg_specificity=90.07% avg_auc=91.64%
Best model saved!! Metric=18.805268911429394!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.319149 Test loss=0.328835 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.29373425245285034
[5/24] Train loss=0.28584668040275574
[10/24] Train loss=0.30346235632896423
[15/24] Train loss=0.29601791501045227
[20/24] Train loss=0.27212443947792053
Test set avg_accuracy=87.29% avg_sensitivity=76.47%, avg_specificity=90.89% avg_auc=91.78%
Best model saved!! Metric=20.437291115475844!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.309654 Test loss=0.325205 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.2839392423629761
[5/24] Train loss=0.29079705476760864
[10/24] Train loss=0.30233263969421387
[15/24] Train loss=0.28694799542427063
[20/24] Train loss=0.2638348937034607
Test set avg_accuracy=87.10% avg_sensitivity=78.87%, avg_specificity=89.83% avg_auc=91.80%
Best model saved!! Metric=21.604890309714378!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.302772 Test loss=0.326300 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.27404290437698364
[5/24] Train loss=0.27448102831840515
[10/24] Train loss=0.29315289855003357
[15/24] Train loss=0.280519962310791
[20/24] Train loss=0.2575528919696808
Test set avg_accuracy=87.64% avg_sensitivity=77.20%, avg_specificity=91.12% avg_auc=92.21%
Best model saved!! Metric=22.16989130206153!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.293924 Test loss=0.313659 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2680227756500244
[5/24] Train loss=0.2632075846195221
[10/24] Train loss=0.2878752648830414
[15/24] Train loss=0.268759548664093
[20/24] Train loss=0.2496354877948761
Test set avg_accuracy=88.24% avg_sensitivity=73.60%, avg_specificity=93.11% avg_auc=92.34%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.287343 Test loss=0.305844 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2573249936103821
[5/24] Train loss=0.25855523347854614
[10/24] Train loss=0.2814942002296448
[15/24] Train loss=0.2630971372127533
[20/24] Train loss=0.24488520622253418
Test set avg_accuracy=88.22% avg_sensitivity=74.39%, avg_specificity=92.82% avg_auc=92.44%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.279937 Test loss=0.300059 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.256388783454895
[5/24] Train loss=0.2551640570163727
[10/24] Train loss=0.27582788467407227
[15/24] Train loss=0.25299280881881714
[20/24] Train loss=0.23599648475646973
Test set avg_accuracy=88.49% avg_sensitivity=74.49%, avg_specificity=93.15% avg_auc=92.79%
Best model saved!! Metric=22.918301748282488!!
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.274807 Test loss=0.296796 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.24977311491966248
[5/24] Train loss=0.25000250339508057
[10/24] Train loss=0.2690407931804657
[15/24] Train loss=0.24921205639839172
[20/24] Train loss=0.23649674654006958
Test set avg_accuracy=88.58% avg_sensitivity=70.79%, avg_specificity=94.50% avg_auc=92.86%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.267871 Test loss=0.290850 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.24726642668247223
[5/24] Train loss=0.24656151235103607
[10/24] Train loss=0.26174312829971313
[15/24] Train loss=0.24096181988716125
[20/24] Train loss=0.22658611834049225
Test set avg_accuracy=88.05% avg_sensitivity=76.53%, avg_specificity=91.88% avg_auc=92.58%
Best model saved!! Metric=23.03385587587873!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.262697 Test loss=0.307777 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.24037738144397736
[5/24] Train loss=0.24247053265571594
[10/24] Train loss=0.25488120317459106
[15/24] Train loss=0.2432633489370346
[20/24] Train loss=0.23253068327903748
Test set avg_accuracy=88.70% avg_sensitivity=76.58%, avg_specificity=92.73% avg_auc=92.33%
Best model saved!! Metric=24.331640190837504!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.259115 Test loss=0.305495 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.23975493013858795
[5/24] Train loss=0.2395942509174347
[10/24] Train loss=0.25547027587890625
[15/24] Train loss=0.23719386756420135
[20/24] Train loss=0.2280525416135788
Test set avg_accuracy=87.97% avg_sensitivity=66.15%, avg_specificity=95.23% avg_auc=92.09%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.255914 Test loss=0.303386 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.23935170471668243
[5/24] Train loss=0.24276278913021088
[10/24] Train loss=0.2524493932723999
[15/24] Train loss=0.2369413524866104
[20/24] Train loss=0.22385849058628082
Test set avg_accuracy=86.88% avg_sensitivity=54.46%, avg_specificity=97.66% avg_auc=92.11%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.251886 Test loss=0.310832 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23163117468357086
[5/24] Train loss=0.23156408965587616
[10/24] Train loss=0.2439012974500656
[15/24] Train loss=0.23815612494945526
[20/24] Train loss=0.21724963188171387
Test set avg_accuracy=88.97% avg_sensitivity=72.25%, avg_specificity=94.53% avg_auc=92.84%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.247634 Test loss=0.288965 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2269221991300583
[5/24] Train loss=0.2246779203414917
[10/24] Train loss=0.24387602508068085
[15/24] Train loss=0.23549196124076843
[20/24] Train loss=0.21488727629184723
Test set avg_accuracy=87.40% avg_sensitivity=58.48%, avg_specificity=97.02% avg_auc=91.51%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.242763 Test loss=0.311105 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.22150260210037231
[5/24] Train loss=0.22224800288677216
[10/24] Train loss=0.2385311871767044
[15/24] Train loss=0.22569973766803741
[20/24] Train loss=0.22459068894386292
Test set avg_accuracy=88.27% avg_sensitivity=64.11%, avg_specificity=96.30% avg_auc=91.83%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.240968 Test loss=0.304372 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2280401885509491
[5/24] Train loss=0.21390603482723236
[10/24] Train loss=0.24166330695152283
[15/24] Train loss=0.23526816070079803
[20/24] Train loss=0.21294938027858734
Test set avg_accuracy=88.48% avg_sensitivity=73.29%, avg_specificity=93.53% avg_auc=91.87%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.240243 Test loss=0.305021 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22158624231815338
[5/24] Train loss=0.21548277139663696
[10/24] Train loss=0.24582329392433167
[15/24] Train loss=0.22431281208992004
[20/24] Train loss=0.2084779143333435
Test set avg_accuracy=88.20% avg_sensitivity=72.04%, avg_specificity=93.58% avg_auc=91.93%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.237067 Test loss=0.306172 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22609873116016388
[5/24] Train loss=0.20857875049114227
[10/24] Train loss=0.22666724026203156
[15/24] Train loss=0.22293610870838165
[20/24] Train loss=0.2073703557252884
Test set avg_accuracy=87.96% avg_sensitivity=73.92%, avg_specificity=92.63% avg_auc=91.61%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.231952 Test loss=0.309880 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2167472243309021
[5/24] Train loss=0.2084982544183731
[10/24] Train loss=0.23430897295475006
[15/24] Train loss=0.21829503774642944
[20/24] Train loss=0.20130202174186707
Test set avg_accuracy=87.12% avg_sensitivity=73.34%, avg_specificity=91.71% avg_auc=91.68%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.228961 Test loss=0.313179 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21117176115512848
[5/24] Train loss=0.20421506464481354
[10/24] Train loss=0.22307756543159485
[15/24] Train loss=0.22054658830165863
[20/24] Train loss=0.20113787055015564
Test set avg_accuracy=86.35% avg_sensitivity=82.89%, avg_specificity=87.51% avg_auc=91.11%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.225516 Test loss=0.351315 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.19664506614208221
[5/24] Train loss=0.20720474421977997
[10/24] Train loss=0.225676491856575
[15/24] Train loss=0.22057458758354187
[20/24] Train loss=0.2004169523715973
Test set avg_accuracy=87.40% avg_sensitivity=67.19%, avg_specificity=94.12% avg_auc=90.88%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.221978 Test loss=0.319075 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.20829987525939941
[5/24] Train loss=0.19813275337219238
[10/24] Train loss=0.2265697568655014
[15/24] Train loss=0.21464940905570984
[20/24] Train loss=0.19339816272258759
Test set avg_accuracy=84.78% avg_sensitivity=46.53%, avg_specificity=97.50% avg_auc=88.54%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.224729 Test loss=0.394275 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.20551614463329315
[5/24] Train loss=0.1946912258863449
[10/24] Train loss=0.2156142294406891
[15/24] Train loss=0.21294178068637848
[20/24] Train loss=0.19337013363838196
Test set avg_accuracy=88.32% avg_sensitivity=73.66%, avg_specificity=93.20% avg_auc=92.10%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.219352 Test loss=0.305350 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.19476954638957977
[5/24] Train loss=0.19416175782680511
[10/24] Train loss=0.21254627406597137
[15/24] Train loss=0.22296935319900513
[20/24] Train loss=0.17938309907913208
Test set avg_accuracy=81.73% avg_sensitivity=30.88%, avg_specificity=98.65% avg_auc=85.00%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.217032 Test loss=0.464975 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20532682538032532
[5/24] Train loss=0.1991148442029953
[10/24] Train loss=0.22265282273292542
[15/24] Train loss=0.20738297700881958
[20/24] Train loss=0.20430949330329895
Test set avg_accuracy=86.82% avg_sensitivity=58.16%, avg_specificity=96.36% avg_auc=90.22%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.218595 Test loss=0.340267 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.20986300706863403
[5/24] Train loss=0.2218773365020752
[10/24] Train loss=0.23641107976436615
[15/24] Train loss=0.21217381954193115
[20/24] Train loss=0.18998481333255768
Test set avg_accuracy=85.26% avg_sensitivity=47.99%, avg_specificity=97.66% avg_auc=86.54%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.219110 Test loss=0.403875 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.1997368186712265
[5/24] Train loss=0.19314037263393402
[10/24] Train loss=0.21839582920074463
[15/24] Train loss=0.22191669046878815
[20/24] Train loss=0.18276388943195343
Test set avg_accuracy=86.35% avg_sensitivity=79.66%, avg_specificity=88.58% avg_auc=90.69%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.214805 Test loss=0.344388 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.19097773730754852
[5/24] Train loss=0.188629150390625
[10/24] Train loss=0.25252777338027954
[15/24] Train loss=0.2143753468990326
[20/24] Train loss=0.18209704756736755
Test set avg_accuracy=87.96% avg_sensitivity=73.24%, avg_specificity=92.85% avg_auc=92.07%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.215369 Test loss=0.306284 Current lr=[0.00029967723776099]

[0/24] Train loss=0.18664145469665527
[5/24] Train loss=0.19074136018753052
[10/24] Train loss=0.21821877360343933
[15/24] Train loss=0.2046215534210205
[20/24] Train loss=0.19222404062747955
Test set avg_accuracy=86.52% avg_sensitivity=79.34%, avg_specificity=88.91% avg_auc=89.82%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.206883 Test loss=0.348676 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2040744423866272
[5/24] Train loss=0.18753595650196075
[10/24] Train loss=0.20202027261257172
[15/24] Train loss=0.2063559889793396
[20/24] Train loss=0.1784399449825287
Test set avg_accuracy=87.29% avg_sensitivity=61.45%, avg_specificity=95.89% avg_auc=89.64%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.204552 Test loss=0.344647 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.1949949711561203
[5/24] Train loss=0.18841786682605743
[10/24] Train loss=0.21096274256706238
[15/24] Train loss=0.19358082115650177
[20/24] Train loss=0.17786578834056854
Test set avg_accuracy=86.09% avg_sensitivity=53.10%, avg_specificity=97.07% avg_auc=89.20%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.202731 Test loss=0.376202 Current lr=[0.000299720220882401]

[0/24] Train loss=0.18828275799751282
[5/24] Train loss=0.19331081211566925
[10/24] Train loss=0.20015692710876465
[15/24] Train loss=0.19937898218631744
[20/24] Train loss=0.18725918233394623
Test set avg_accuracy=81.09% avg_sensitivity=86.80%, avg_specificity=79.19% avg_auc=89.40%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.203276 Test loss=0.437626 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19468115270137787
[5/24] Train loss=0.19311051070690155
[10/24] Train loss=0.1959436684846878
[15/24] Train loss=0.20175722241401672
[20/24] Train loss=0.17637400329113007
Test set avg_accuracy=77.19% avg_sensitivity=89.93%, avg_specificity=72.95% avg_auc=86.75%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.205140 Test loss=0.529997 Current lr=[0.000298904600941902]

[0/24] Train loss=0.1887541264295578
[5/24] Train loss=0.19167083501815796
[10/24] Train loss=0.19954198598861694
[15/24] Train loss=0.2087673395872116
[20/24] Train loss=0.17099785804748535
Test set avg_accuracy=83.35% avg_sensitivity=82.58%, avg_specificity=83.60% avg_auc=88.33%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.200343 Test loss=0.415342 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20391100645065308
[5/24] Train loss=0.20489248633384705
[10/24] Train loss=0.20905034244060516
[15/24] Train loss=0.20478227734565735
[20/24] Train loss=0.17935830354690552
Test set avg_accuracy=87.45% avg_sensitivity=67.50%, avg_specificity=94.08% avg_auc=90.82%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.209167 Test loss=0.327563 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19645127654075623
[5/24] Train loss=0.1866437792778015
[10/24] Train loss=0.19242079555988312
[15/24] Train loss=0.20104482769966125
[20/24] Train loss=0.18498791754245758
Test set avg_accuracy=86.67% avg_sensitivity=57.90%, avg_specificity=96.23% avg_auc=87.08%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.198783 Test loss=0.388264 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.17888416349887848
[5/24] Train loss=0.18689750134944916
[10/24] Train loss=0.20348896086215973
[15/24] Train loss=0.1930587887763977
[20/24] Train loss=0.1703576296567917
Test set avg_accuracy=86.28% avg_sensitivity=57.33%, avg_specificity=95.90% avg_auc=88.38%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.197565 Test loss=0.375915 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18464912474155426
[5/24] Train loss=0.20396527647972107
[10/24] Train loss=0.19834832847118378
[15/24] Train loss=0.19624097645282745
[20/24] Train loss=0.1658608466386795
Test set avg_accuracy=86.20% avg_sensitivity=56.81%, avg_specificity=95.97% avg_auc=88.86%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.199226 Test loss=0.374319 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1780948042869568
[5/24] Train loss=0.19461162388324738
[10/24] Train loss=0.20658451318740845
[15/24] Train loss=0.189358651638031
[20/24] Train loss=0.1856776922941208
Test set avg_accuracy=86.74% avg_sensitivity=58.95%, avg_specificity=95.99% avg_auc=88.66%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.196457 Test loss=0.371461 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18539442121982574
[5/24] Train loss=0.18915772438049316
[10/24] Train loss=0.20155535638332367
[15/24] Train loss=0.19149790704250336
[20/24] Train loss=0.18314795196056366
Test set avg_accuracy=88.02% avg_sensitivity=68.44%, avg_specificity=94.53% avg_auc=90.12%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.196478 Test loss=0.337481 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.17183513939380646
[5/24] Train loss=0.19137248396873474
[10/24] Train loss=0.1939384937286377
[15/24] Train loss=0.1889186054468155
[20/24] Train loss=0.17682473361492157
Test set avg_accuracy=87.15% avg_sensitivity=75.38%, avg_specificity=91.06% avg_auc=88.50%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.192347 Test loss=0.364527 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1698475033044815
[5/24] Train loss=0.1838051825761795
[10/24] Train loss=0.19224078953266144
[15/24] Train loss=0.1861853003501892
[20/24] Train loss=0.17368222773075104
Test set avg_accuracy=87.01% avg_sensitivity=72.93%, avg_specificity=91.69% avg_auc=90.06%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.188704 Test loss=0.344703 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.17739714682102203
[5/24] Train loss=0.1855764240026474
[10/24] Train loss=0.20261900126934052
[15/24] Train loss=0.19418682157993317
[20/24] Train loss=0.16891935467720032
Test set avg_accuracy=78.76% avg_sensitivity=15.60%, avg_specificity=99.77% avg_auc=70.28%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.196434 Test loss=0.637961 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18995828926563263
[5/24] Train loss=0.17730818688869476
[10/24] Train loss=0.1946699172258377
[15/24] Train loss=0.18059787154197693
[20/24] Train loss=0.17319785058498383
Test set avg_accuracy=84.15% avg_sensitivity=83.93%, avg_specificity=84.23% avg_auc=89.59%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.197255 Test loss=0.382453 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.17316362261772156
[5/24] Train loss=0.183725044131279
[10/24] Train loss=0.19270449876785278
[15/24] Train loss=0.18196745216846466
[20/24] Train loss=0.17283447086811066
Test set avg_accuracy=87.17% avg_sensitivity=75.38%, avg_specificity=91.10% avg_auc=89.92%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.192409 Test loss=0.349396 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1834431141614914
[5/24] Train loss=0.1811715066432953
[10/24] Train loss=0.18289802968502045
[15/24] Train loss=0.1876784712076187
[20/24] Train loss=0.17854717373847961
Test set avg_accuracy=83.19% avg_sensitivity=83.83%, avg_specificity=82.98% avg_auc=89.67%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.187787 Test loss=0.403350 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17313547432422638
[5/24] Train loss=0.18056313693523407
[10/24] Train loss=0.1951299011707306
[15/24] Train loss=0.18172433972358704
[20/24] Train loss=0.16786256432533264
Test set avg_accuracy=87.24% avg_sensitivity=77.62%, avg_specificity=90.44% avg_auc=90.96%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.187800 Test loss=0.334507 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17119547724723816
[5/24] Train loss=0.18287909030914307
[10/24] Train loss=0.20737503468990326
[15/24] Train loss=0.18466752767562866
[20/24] Train loss=0.16386662423610687
Test set avg_accuracy=87.71% avg_sensitivity=77.93%, avg_specificity=90.96% avg_auc=91.38%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.195846 Test loss=0.331951 Current lr=[0.000276307469034998]

[0/24] Train loss=0.18462812900543213
[5/24] Train loss=0.1967422515153885
[10/24] Train loss=0.1916445791721344
[15/24] Train loss=0.19072426855564117
[20/24] Train loss=0.1573205143213272
Test set avg_accuracy=87.81% avg_sensitivity=74.54%, avg_specificity=92.23% avg_auc=90.89%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.188481 Test loss=0.333030 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17037402093410492
[5/24] Train loss=0.19370627403259277
[10/24] Train loss=0.1919824630022049
[15/24] Train loss=0.18564215302467346
[20/24] Train loss=0.16039441525936127
Test set avg_accuracy=83.96% avg_sensitivity=76.47%, avg_specificity=86.45% avg_auc=88.15%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.187194 Test loss=0.406691 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17866697907447815
[5/24] Train loss=0.20301692187786102
[10/24] Train loss=0.19167332351207733
[15/24] Train loss=0.18215762078762054
[20/24] Train loss=0.17048655450344086
Test set avg_accuracy=87.98% avg_sensitivity=74.65%, avg_specificity=92.42% avg_auc=90.71%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.191367 Test loss=0.342766 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.16992737352848053
[5/24] Train loss=0.1698203831911087
[10/24] Train loss=0.1937442570924759
[15/24] Train loss=0.18235237896442413
[20/24] Train loss=0.16453081369400024
Test set avg_accuracy=87.29% avg_sensitivity=66.61%, avg_specificity=94.17% avg_auc=90.55%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.184714 Test loss=0.341338 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1746513843536377
[5/24] Train loss=0.1716562956571579
[10/24] Train loss=0.18157915771007538
[15/24] Train loss=0.18089956045150757
[20/24] Train loss=0.15833814442157745
Test set avg_accuracy=86.35% avg_sensitivity=80.75%, avg_specificity=88.22% avg_auc=91.25%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.182832 Test loss=0.342176 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1673218309879303
[5/24] Train loss=0.1742851883172989
[10/24] Train loss=0.19023889303207397
[15/24] Train loss=0.18253767490386963
[20/24] Train loss=0.15651382505893707
Test set avg_accuracy=86.46% avg_sensitivity=77.93%, avg_specificity=89.29% avg_auc=90.19%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.183711 Test loss=0.354057 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1648176908493042
[5/24] Train loss=0.1722145527601242
[10/24] Train loss=0.1874895840883255
[15/24] Train loss=0.17807917296886444
[20/24] Train loss=0.15579400956630707
Test set avg_accuracy=87.51% avg_sensitivity=71.05%, avg_specificity=92.99% avg_auc=90.45%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.183461 Test loss=0.332166 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1743524968624115
[5/24] Train loss=0.18384598195552826
[10/24] Train loss=0.18788819015026093
[15/24] Train loss=0.17654213309288025
[20/24] Train loss=0.14876630902290344
Test set avg_accuracy=87.67% avg_sensitivity=72.98%, avg_specificity=92.56% avg_auc=91.29%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.178449 Test loss=0.324237 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16591839492321014
[5/24] Train loss=0.1761823445558548
[10/24] Train loss=0.17354562878608704
[15/24] Train loss=0.1754990518093109
[20/24] Train loss=0.15415330231189728
Test set avg_accuracy=87.50% avg_sensitivity=61.24%, avg_specificity=96.23% avg_auc=89.72%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.179669 Test loss=0.348555 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.15527603030204773
[5/24] Train loss=0.17769527435302734
[10/24] Train loss=0.18097680807113647
[15/24] Train loss=0.180416077375412
[20/24] Train loss=0.15437988936901093
Test set avg_accuracy=83.82% avg_sensitivity=82.94%, avg_specificity=84.11% avg_auc=90.33%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.180539 Test loss=0.403664 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.18033607304096222
[5/24] Train loss=0.1782388836145401
[10/24] Train loss=0.1917298436164856
[15/24] Train loss=0.17961780726909637
[20/24] Train loss=0.15916495025157928
Test set avg_accuracy=84.31% avg_sensitivity=81.53%, avg_specificity=85.23% avg_auc=89.88%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.180705 Test loss=0.396133 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16952462494373322
[5/24] Train loss=0.17498637735843658
[10/24] Train loss=0.19103987514972687
[15/24] Train loss=0.16950955986976624
[20/24] Train loss=0.16037346422672272
Test set avg_accuracy=83.68% avg_sensitivity=84.77%, avg_specificity=83.32% avg_auc=90.51%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.180162 Test loss=0.388999 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1755644530057907
[5/24] Train loss=0.1845398098230362
[10/24] Train loss=0.1866782009601593
[15/24] Train loss=0.16944150626659393
[20/24] Train loss=0.1548765003681183
Test set avg_accuracy=85.98% avg_sensitivity=78.82%, avg_specificity=88.36% avg_auc=90.82%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.182376 Test loss=0.343153 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17150436341762543
[5/24] Train loss=0.18293501436710358
[10/24] Train loss=0.17590415477752686
[15/24] Train loss=0.1718718260526657
[20/24] Train loss=0.1593932807445526
Test set avg_accuracy=87.47% avg_sensitivity=75.22%, avg_specificity=91.55% avg_auc=91.13%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.176297 Test loss=0.331615 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1669381558895111
[5/24] Train loss=0.1665971279144287
[10/24] Train loss=0.17934484779834747
[15/24] Train loss=0.1634223461151123
[20/24] Train loss=0.15146228671073914
Test set avg_accuracy=86.55% avg_sensitivity=73.40%, avg_specificity=90.92% avg_auc=90.44%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.173502 Test loss=0.346671 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16809190809726715
[5/24] Train loss=0.16762258112430573
[10/24] Train loss=0.17437084019184113
[15/24] Train loss=0.15833242237567902
[20/24] Train loss=0.14942800998687744
Test set avg_accuracy=87.50% avg_sensitivity=69.69%, avg_specificity=93.42% avg_auc=90.36%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.168424 Test loss=0.338355 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1578279286623001
[5/24] Train loss=0.1670776903629303
[10/24] Train loss=0.16657622158527374
[15/24] Train loss=0.16557161509990692
[20/24] Train loss=0.1467713713645935
Test set avg_accuracy=85.20% avg_sensitivity=80.07%, avg_specificity=86.90% avg_auc=91.03%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.169293 Test loss=0.360633 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.162793830037117
[5/24] Train loss=0.16846142709255219
[10/24] Train loss=0.17758077383041382
[15/24] Train loss=0.15120276808738708
[20/24] Train loss=0.1453416645526886
Test set avg_accuracy=84.34% avg_sensitivity=84.09%, avg_specificity=84.42% avg_auc=90.85%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.169645 Test loss=0.395409 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.15756790339946747
[5/24] Train loss=0.16849474608898163
[10/24] Train loss=0.17467808723449707
[15/24] Train loss=0.15893182158470154
[20/24] Train loss=0.15095154941082
Test set avg_accuracy=88.24% avg_sensitivity=66.98%, avg_specificity=95.31% avg_auc=89.37%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.167135 Test loss=0.345227 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1548886001110077
[5/24] Train loss=0.16550767421722412
[10/24] Train loss=0.1683269888162613
[15/24] Train loss=0.15644994378089905
[20/24] Train loss=0.13844379782676697
Test set avg_accuracy=85.99% avg_sensitivity=51.17%, avg_specificity=97.57% avg_auc=88.74%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.163827 Test loss=0.364990 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.15033307671546936
[5/24] Train loss=0.16678540408611298
[10/24] Train loss=0.16393747925758362
[15/24] Train loss=0.1554107517004013
[20/24] Train loss=0.14295318722724915
Test set avg_accuracy=87.36% avg_sensitivity=74.70%, avg_specificity=91.57% avg_auc=91.68%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.165077 Test loss=0.325949 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15738917887210846
[5/24] Train loss=0.1648940145969391
[10/24] Train loss=0.17083348333835602
[15/24] Train loss=0.1620102971792221
[20/24] Train loss=0.14785179495811462
Test set avg_accuracy=87.38% avg_sensitivity=58.32%, avg_specificity=97.05% avg_auc=88.94%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.167818 Test loss=0.351747 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.14814479649066925
[5/24] Train loss=0.17193779349327087
[10/24] Train loss=0.16493193805217743
[15/24] Train loss=0.15789099037647247
[20/24] Train loss=0.14627301692962646
Test set avg_accuracy=87.29% avg_sensitivity=69.01%, avg_specificity=93.37% avg_auc=89.94%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.163927 Test loss=0.340263 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1592825949192047
[5/24] Train loss=0.16947650909423828
[10/24] Train loss=0.17223867774009705
[15/24] Train loss=0.1514398455619812
[20/24] Train loss=0.1410001516342163
Test set avg_accuracy=87.32% avg_sensitivity=57.90%, avg_specificity=97.10% avg_auc=85.49%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.163864 Test loss=0.383808 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.14826525747776031
[5/24] Train loss=0.16428066790103912
[10/24] Train loss=0.1677238643169403
[15/24] Train loss=0.16305704414844513
[20/24] Train loss=0.14207446575164795
Test set avg_accuracy=85.86% avg_sensitivity=48.93%, avg_specificity=98.14% avg_auc=86.92%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.162290 Test loss=0.386021 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16445417702198029
[5/24] Train loss=0.1591661423444748
[10/24] Train loss=0.15469618141651154
[15/24] Train loss=0.1479872763156891
[20/24] Train loss=0.13728736340999603
Test set avg_accuracy=87.77% avg_sensitivity=64.27%, avg_specificity=95.59% avg_auc=89.53%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.159618 Test loss=0.348223 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.14373376965522766
[5/24] Train loss=0.16671229898929596
[10/24] Train loss=0.16934175789356232
[15/24] Train loss=0.15003953874111176
[20/24] Train loss=0.14693686366081238
Test set avg_accuracy=87.79% avg_sensitivity=65.21%, avg_specificity=95.30% avg_auc=89.53%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.161468 Test loss=0.334532 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15090061724185944
[5/24] Train loss=0.16446593403816223
[10/24] Train loss=0.16677160561084747
[15/24] Train loss=0.15395191311836243
[20/24] Train loss=0.1369725912809372
Test set avg_accuracy=87.36% avg_sensitivity=64.21%, avg_specificity=95.05% avg_auc=90.30%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.161077 Test loss=0.340478 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15288212895393372
[5/24] Train loss=0.16427719593048096
[10/24] Train loss=0.1588037610054016
[15/24] Train loss=0.14892667531967163
[20/24] Train loss=0.14323334395885468
Test set avg_accuracy=86.16% avg_sensitivity=76.47%, avg_specificity=89.38% avg_auc=89.47%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.159064 Test loss=0.398224 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15616671741008759
[5/24] Train loss=0.1656932234764099
[10/24] Train loss=0.1541065275669098
[15/24] Train loss=0.1586035192012787
[20/24] Train loss=0.14042015373706818
Test set avg_accuracy=87.49% avg_sensitivity=66.46%, avg_specificity=94.48% avg_auc=89.63%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.163389 Test loss=0.348984 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15820471942424774
[5/24] Train loss=0.1695544272661209
[10/24] Train loss=0.16393204033374786
[15/24] Train loss=0.15202338993549347
[20/24] Train loss=0.14406968653202057
Test set avg_accuracy=86.56% avg_sensitivity=75.74%, avg_specificity=90.16% avg_auc=90.44%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.162232 Test loss=0.361381 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15004070103168488
[5/24] Train loss=0.15762150287628174
[10/24] Train loss=0.16157203912734985
[15/24] Train loss=0.1662968099117279
[20/24] Train loss=0.1466790735721588
Test set avg_accuracy=87.01% avg_sensitivity=64.21%, avg_specificity=94.59% avg_auc=89.71%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.160327 Test loss=0.359691 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15077368915081024
[5/24] Train loss=0.1606604903936386
[10/24] Train loss=0.15531592071056366
[15/24] Train loss=0.15634970366954803
[20/24] Train loss=0.1478997766971588
Test set avg_accuracy=87.08% avg_sensitivity=66.82%, avg_specificity=93.82% avg_auc=90.99%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.159355 Test loss=0.328428 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.14925263822078705
[5/24] Train loss=0.16435229778289795
[10/24] Train loss=0.1611199975013733
[15/24] Train loss=0.15349827706813812
[20/24] Train loss=0.1376785933971405
Test set avg_accuracy=87.21% avg_sensitivity=58.69%, avg_specificity=96.70% avg_auc=88.82%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.157786 Test loss=0.350215 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.14421698451042175
[5/24] Train loss=0.15953944623470306
[10/24] Train loss=0.1575123816728592
[15/24] Train loss=0.15040713548660278
[20/24] Train loss=0.1414961814880371
Test set avg_accuracy=86.38% avg_sensitivity=59.57%, avg_specificity=95.30% avg_auc=88.82%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.159100 Test loss=0.362998 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15009567141532898
[5/24] Train loss=0.16903048753738403
[10/24] Train loss=0.1539229154586792
[15/24] Train loss=0.14553652703762054
[20/24] Train loss=0.13626201450824738
Test set avg_accuracy=87.15% avg_sensitivity=62.65%, avg_specificity=95.30% avg_auc=91.33%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.158099 Test loss=0.328018 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.14339318871498108
[5/24] Train loss=0.15215855836868286
[10/24] Train loss=0.15163353085517883
[15/24] Train loss=0.15148968994617462
[20/24] Train loss=0.14213332533836365
Test set avg_accuracy=85.95% avg_sensitivity=47.68%, avg_specificity=98.68% avg_auc=88.75%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.155393 Test loss=0.368756 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14216652512550354
[5/24] Train loss=0.15993903577327728
[10/24] Train loss=0.15379540622234344
[15/24] Train loss=0.15878693759441376
[20/24] Train loss=0.13705791532993317
Test set avg_accuracy=81.67% avg_sensitivity=28.90%, avg_specificity=99.22% avg_auc=78.88%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.155348 Test loss=0.539713 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14596422016620636
[5/24] Train loss=0.15625227987766266
[10/24] Train loss=0.1548304408788681
[15/24] Train loss=0.15203091502189636
[20/24] Train loss=0.1401195228099823
Test set avg_accuracy=87.54% avg_sensitivity=60.93%, avg_specificity=96.39% avg_auc=88.34%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.155417 Test loss=0.350385 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1418033093214035
[5/24] Train loss=0.15708808600902557
[10/24] Train loss=0.15431125462055206
[15/24] Train loss=0.1474577635526657
[20/24] Train loss=0.13238489627838135
Test set avg_accuracy=88.33% avg_sensitivity=67.34%, avg_specificity=95.31% avg_auc=90.12%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.152453 Test loss=0.334706 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14521735906600952
[5/24] Train loss=0.1514350026845932
[10/24] Train loss=0.1496312916278839
[15/24] Train loss=0.14975759387016296
[20/24] Train loss=0.12943115830421448
Test set avg_accuracy=87.79% avg_sensitivity=63.95%, avg_specificity=95.71% avg_auc=90.74%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.151038 Test loss=0.337770 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1410660445690155
[5/24] Train loss=0.15479785203933716
[10/24] Train loss=0.1456512212753296
[15/24] Train loss=0.14452718198299408
[20/24] Train loss=0.13121140003204346
Test set avg_accuracy=86.02% avg_sensitivity=50.44%, avg_specificity=97.85% avg_auc=87.69%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.147717 Test loss=0.376216 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14277300238609314
[5/24] Train loss=0.14921920001506805
[10/24] Train loss=0.14148756861686707
[15/24] Train loss=0.15050937235355377
[20/24] Train loss=0.13083931803703308
Test set avg_accuracy=87.04% avg_sensitivity=56.49%, avg_specificity=97.21% avg_auc=89.28%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.147529 Test loss=0.351490 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.13873593509197235
[5/24] Train loss=0.15087370574474335
[10/24] Train loss=0.14547498524188995
[15/24] Train loss=0.14547470211982727
[20/24] Train loss=0.12976519763469696
Test set avg_accuracy=87.47% avg_sensitivity=62.49%, avg_specificity=95.78% avg_auc=90.19%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.147367 Test loss=0.340080 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13640493154525757
[5/24] Train loss=0.1584867388010025
[10/24] Train loss=0.15059220790863037
[15/24] Train loss=0.14489327371120453
[20/24] Train loss=0.13209809362888336
Test set avg_accuracy=87.21% avg_sensitivity=58.95%, avg_specificity=96.62% avg_auc=89.36%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.148781 Test loss=0.354050 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14091984927654266
[5/24] Train loss=0.15015847980976105
[10/24] Train loss=0.145296111702919
[15/24] Train loss=0.13986864686012268
[20/24] Train loss=0.12598970532417297
Test set avg_accuracy=87.59% avg_sensitivity=63.85%, avg_specificity=95.49% avg_auc=89.83%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.146567 Test loss=0.350276 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13992123305797577
[5/24] Train loss=0.14632998406887054
[10/24] Train loss=0.14422261714935303
[15/24] Train loss=0.13804835081100464
[20/24] Train loss=0.1285688728094101
Test set avg_accuracy=87.79% avg_sensitivity=63.43%, avg_specificity=95.89% avg_auc=90.73%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.145163 Test loss=0.328355 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1356593519449234
[5/24] Train loss=0.14873331785202026
[10/24] Train loss=0.1397753655910492
[15/24] Train loss=0.1386762261390686
[20/24] Train loss=0.13038890063762665
Test set avg_accuracy=87.81% avg_sensitivity=71.83%, avg_specificity=93.13% avg_auc=91.66%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.143188 Test loss=0.328674 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1358589380979538
[5/24] Train loss=0.14370658993721008
[10/24] Train loss=0.14007557928562164
[15/24] Train loss=0.1374550610780716
[20/24] Train loss=0.12759080529212952
Test set avg_accuracy=86.97% avg_sensitivity=61.61%, avg_specificity=95.40% avg_auc=90.94%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.142103 Test loss=0.341541 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1341230422258377
[5/24] Train loss=0.14723455905914307
[10/24] Train loss=0.14175470173358917
[15/24] Train loss=0.13575351238250732
[20/24] Train loss=0.13180579245090485
Test set avg_accuracy=87.34% avg_sensitivity=62.28%, avg_specificity=95.68% avg_auc=90.21%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.142562 Test loss=0.345579 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13169321417808533
[5/24] Train loss=0.15147927403450012
[10/24] Train loss=0.13939298689365387
[15/24] Train loss=0.13523916900157928
[20/24] Train loss=0.12313840538263321
Test set avg_accuracy=87.41% avg_sensitivity=58.63%, avg_specificity=96.98% avg_auc=90.00%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.141448 Test loss=0.352320 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13326743245124817
[5/24] Train loss=0.14297665655612946
[10/24] Train loss=0.13747447729110718
[15/24] Train loss=0.13876670598983765
[20/24] Train loss=0.1218380331993103
Test set avg_accuracy=87.76% avg_sensitivity=63.69%, avg_specificity=95.77% avg_auc=91.34%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.140172 Test loss=0.322648 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.14051254093647003
[5/24] Train loss=0.14638632535934448
[10/24] Train loss=0.13472560048103333
[15/24] Train loss=0.13164523243904114
[20/24] Train loss=0.12556743621826172
Test set avg_accuracy=87.73% avg_sensitivity=66.09%, avg_specificity=94.93% avg_auc=91.29%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.139280 Test loss=0.327822 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13182194530963898
[5/24] Train loss=0.14210361242294312
[10/24] Train loss=0.13998092710971832
[15/24] Train loss=0.12925897538661957
[20/24] Train loss=0.11872453987598419
Test set avg_accuracy=87.66% avg_sensitivity=68.86%, avg_specificity=93.91% avg_auc=91.14%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.137703 Test loss=0.329845 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1338319629430771
[5/24] Train loss=0.14265042543411255
[10/24] Train loss=0.13447801768779755
[15/24] Train loss=0.12820222973823547
[20/24] Train loss=0.12139207124710083
Test set avg_accuracy=87.68% avg_sensitivity=69.38%, avg_specificity=93.77% avg_auc=91.56%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.137047 Test loss=0.327081 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.12832780182361603
[5/24] Train loss=0.14115652441978455
[10/24] Train loss=0.1387237012386322
[15/24] Train loss=0.13127462565898895
[20/24] Train loss=0.12146279215812683
Test set avg_accuracy=88.03% avg_sensitivity=71.83%, avg_specificity=93.42% avg_auc=91.48%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.136738 Test loss=0.321864 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13185857236385345
[5/24] Train loss=0.1406942456960678
[10/24] Train loss=0.1339765042066574
[15/24] Train loss=0.1265273243188858
[20/24] Train loss=0.11965089291334152
Test set avg_accuracy=88.23% avg_sensitivity=69.27%, avg_specificity=94.53% avg_auc=91.54%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.135720 Test loss=0.323010 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1279643476009369
[5/24] Train loss=0.1406521201133728
[10/24] Train loss=0.13322840631008148
[15/24] Train loss=0.12540724873542786
[20/24] Train loss=0.11868428438901901
Test set avg_accuracy=87.68% avg_sensitivity=72.67%, avg_specificity=92.68% avg_auc=91.52%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.134903 Test loss=0.332658 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1293354034423828
[5/24] Train loss=0.1381300836801529
[10/24] Train loss=0.13373598456382751
[15/24] Train loss=0.1255721002817154
[20/24] Train loss=0.11942586302757263
Test set avg_accuracy=88.02% avg_sensitivity=71.78%, avg_specificity=93.42% avg_auc=91.40%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.133766 Test loss=0.334460 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12711067497730255
[5/24] Train loss=0.13879509270191193
[10/24] Train loss=0.13392728567123413
[15/24] Train loss=0.12332640588283539
[20/24] Train loss=0.11955350637435913
Test set avg_accuracy=87.84% avg_sensitivity=71.88%, avg_specificity=93.15% avg_auc=90.94%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.133003 Test loss=0.343639 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12800931930541992
[5/24] Train loss=0.13516652584075928
[10/24] Train loss=0.13457702100276947
[15/24] Train loss=0.12780553102493286
[20/24] Train loss=0.1174696609377861
Test set avg_accuracy=87.73% avg_sensitivity=70.94%, avg_specificity=93.32% avg_auc=91.65%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.132478 Test loss=0.329847 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12580174207687378
[5/24] Train loss=0.1320999562740326
[10/24] Train loss=0.12942492961883545
[15/24] Train loss=0.12457550317049026
[20/24] Train loss=0.11819954216480255
Test set avg_accuracy=88.19% avg_sensitivity=69.59%, avg_specificity=94.38% avg_auc=91.14%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.131299 Test loss=0.333388 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12529592216014862
[5/24] Train loss=0.13545334339141846
[10/24] Train loss=0.1334768682718277
[15/24] Train loss=0.12433385103940964
[20/24] Train loss=0.11868798732757568
Test set avg_accuracy=88.41% avg_sensitivity=69.85%, avg_specificity=94.59% avg_auc=91.40%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.131656 Test loss=0.331649 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12400124222040176
[5/24] Train loss=0.13607439398765564
[10/24] Train loss=0.13122521340847015
[15/24] Train loss=0.12349062412977219
[20/24] Train loss=0.11699467152357101
Test set avg_accuracy=87.94% avg_sensitivity=66.09%, avg_specificity=95.21% avg_auc=91.27%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.131423 Test loss=0.333027 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12614020705223083
[5/24] Train loss=0.13945475220680237
[10/24] Train loss=0.12844836711883545
[15/24] Train loss=0.13002538681030273
[20/24] Train loss=0.11959033459424973
Test set avg_accuracy=88.23% avg_sensitivity=67.97%, avg_specificity=94.97% avg_auc=91.57%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.132480 Test loss=0.325536 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1239493116736412
[5/24] Train loss=0.13947264850139618
[10/24] Train loss=0.12705548107624054
[15/24] Train loss=0.12511904537677765
[20/24] Train loss=0.11889619380235672
Test set avg_accuracy=88.20% avg_sensitivity=69.48%, avg_specificity=94.43% avg_auc=91.63%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.131650 Test loss=0.324796 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12124507874250412
[5/24] Train loss=0.13792072236537933
[10/24] Train loss=0.12749852240085602
[15/24] Train loss=0.12370002269744873
[20/24] Train loss=0.11840898543596268
Test set avg_accuracy=88.10% avg_sensitivity=73.03%, avg_specificity=93.11% avg_auc=91.83%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.130905 Test loss=0.323127 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12544749677181244
[5/24] Train loss=0.13345640897750854
[10/24] Train loss=0.12614944577217102
[15/24] Train loss=0.12231463938951492
[20/24] Train loss=0.11472248286008835
Test set avg_accuracy=87.92% avg_sensitivity=71.57%, avg_specificity=93.35% avg_auc=91.82%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.129277 Test loss=0.321863 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12432307004928589
[5/24] Train loss=0.13092690706253052
[10/24] Train loss=0.12454943358898163
[15/24] Train loss=0.12022795528173447
[20/24] Train loss=0.11439982801675797
Test set avg_accuracy=88.20% avg_sensitivity=71.67%, avg_specificity=93.70% avg_auc=91.68%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.127764 Test loss=0.322832 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.11903275549411774
[5/24] Train loss=0.1305302083492279
[10/24] Train loss=0.12560410797595978
[15/24] Train loss=0.11963776499032974
[20/24] Train loss=0.11298897862434387
Test set avg_accuracy=88.09% avg_sensitivity=70.94%, avg_specificity=93.79% avg_auc=91.61%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.126209 Test loss=0.323051 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12068091332912445
[5/24] Train loss=0.1314183622598648
[10/24] Train loss=0.1243237555027008
[15/24] Train loss=0.11830314248800278
[20/24] Train loss=0.11263936012983322
Test set avg_accuracy=88.19% avg_sensitivity=74.07%, avg_specificity=92.89% avg_auc=91.66%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.126495 Test loss=0.326148 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.11969045549631119
[5/24] Train loss=0.13249661028385162
[10/24] Train loss=0.12500105798244476
[15/24] Train loss=0.11824339628219604
[20/24] Train loss=0.11328379064798355
Test set avg_accuracy=88.33% avg_sensitivity=71.36%, avg_specificity=93.98% avg_auc=91.56%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.126445 Test loss=0.322940 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.11754903942346573
[5/24] Train loss=0.1300547868013382
[10/24] Train loss=0.12621521949768066
[15/24] Train loss=0.1215914785861969
[20/24] Train loss=0.11192737519741058
Test set avg_accuracy=88.36% avg_sensitivity=75.22%, avg_specificity=92.73% avg_auc=91.60%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.125770 Test loss=0.326293 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1172562688589096
[5/24] Train loss=0.1300039291381836
[10/24] Train loss=0.12275581806898117
[15/24] Train loss=0.11695588380098343
[20/24] Train loss=0.11345319449901581
Test set avg_accuracy=88.18% avg_sensitivity=71.52%, avg_specificity=93.72% avg_auc=91.58%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.125132 Test loss=0.323066 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1162610724568367
[5/24] Train loss=0.13054588437080383
[10/24] Train loss=0.12420731037855148
[15/24] Train loss=0.11999697238206863
[20/24] Train loss=0.1130177229642868
Test set avg_accuracy=88.18% avg_sensitivity=71.15%, avg_specificity=93.84% avg_auc=91.44%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.124819 Test loss=0.326076 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11462235450744629
[5/24] Train loss=0.129245325922966
[10/24] Train loss=0.12378844618797302
[15/24] Train loss=0.11768500506877899
[20/24] Train loss=0.11171494424343109
Test set avg_accuracy=88.42% avg_sensitivity=73.97%, avg_specificity=93.23% avg_auc=91.65%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.124705 Test loss=0.327078 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11663799732923508
[5/24] Train loss=0.12888303399085999
[10/24] Train loss=0.11893025785684586
[15/24] Train loss=0.11651752144098282
[20/24] Train loss=0.11319590359926224
Test set avg_accuracy=88.16% avg_sensitivity=71.52%, avg_specificity=93.70% avg_auc=91.61%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.124274 Test loss=0.324945 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11839483678340912
[5/24] Train loss=0.12828843295574188
[10/24] Train loss=0.12131085246801376
[15/24] Train loss=0.1171698123216629
[20/24] Train loss=0.11368508636951447
Test set avg_accuracy=87.96% avg_sensitivity=70.37%, avg_specificity=93.81% avg_auc=91.53%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.124039 Test loss=0.326559 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11962055414915085
[5/24] Train loss=0.1301099807024002
[10/24] Train loss=0.11971491575241089
[15/24] Train loss=0.11816192418336868
[20/24] Train loss=0.11201737076044083
Test set avg_accuracy=88.09% avg_sensitivity=71.21%, avg_specificity=93.70% avg_auc=91.58%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.124121 Test loss=0.325572 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1169477328658104
[5/24] Train loss=0.13113804161548615
[10/24] Train loss=0.12038646638393402
[15/24] Train loss=0.1150633692741394
[20/24] Train loss=0.11261360347270966
Test set avg_accuracy=88.16% avg_sensitivity=71.88%, avg_specificity=93.58% avg_auc=91.62%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.123959 Test loss=0.324709 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11768786609172821
[5/24] Train loss=0.1268535852432251
[10/24] Train loss=0.1185755655169487
[15/24] Train loss=0.11587623506784439
[20/24] Train loss=0.11362569034099579
Test set avg_accuracy=88.27% avg_sensitivity=72.20%, avg_specificity=93.61% avg_auc=91.55%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.123625 Test loss=0.325706 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11882882565259933
[5/24] Train loss=0.127669557929039
[10/24] Train loss=0.1196627989411354
[15/24] Train loss=0.11781946569681168
[20/24] Train loss=0.11113705486059189
Test set avg_accuracy=88.26% avg_sensitivity=72.14%, avg_specificity=93.61% avg_auc=91.54%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.123592 Test loss=0.325483 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11467670649290085
[5/24] Train loss=0.12948407232761383
[10/24] Train loss=0.1212579607963562
[15/24] Train loss=0.11621148139238358
[20/24] Train loss=0.11285583674907684
Test set avg_accuracy=88.28% avg_sensitivity=72.14%, avg_specificity=93.65% avg_auc=91.56%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.123339 Test loss=0.325512 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11407056450843811
[5/24] Train loss=0.12764118611812592
[10/24] Train loss=0.12237363308668137
[15/24] Train loss=0.11745692044496536
[20/24] Train loss=0.11316780745983124
Test set avg_accuracy=88.28% avg_sensitivity=72.04%, avg_specificity=93.68% avg_auc=91.56%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.123538 Test loss=0.325296 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11686910688877106
[5/24] Train loss=0.1298125982284546
[10/24] Train loss=0.12080461531877518
[15/24] Train loss=0.11617482453584671
[20/24] Train loss=0.11173848062753677
Test set avg_accuracy=88.26% avg_sensitivity=71.88%, avg_specificity=93.70% avg_auc=91.55%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.123838 Test loss=0.325314 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.115646593272686
[5/24] Train loss=0.12960587441921234
[10/24] Train loss=0.12227491289377213
[15/24] Train loss=0.11625166982412338
[20/24] Train loss=0.1121947392821312
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.27% avg_sensitivity=71.99%, avg_specificity=93.68% avg_auc=91.56%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.123715 Test loss=0.325355 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=88.70% sen=76.58%, spe=92.73%, auc=92.33%!
Fold[2] Avg_overlap=0.72%(0.2215637167772609)
[0/24] Train loss=0.7648150324821472
[5/24] Train loss=0.7508748769760132
[10/24] Train loss=0.7516482472419739
[15/24] Train loss=0.7340384125709534
[20/24] Train loss=0.7284963130950928
Test set avg_accuracy=58.02% avg_sensitivity=42.18%, avg_specificity=64.02% avg_auc=56.72%
Best model saved!! Metric=-105.0554299933916!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.741957 Test loss=0.675622 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.728731095790863
[5/24] Train loss=0.7159446477890015
[10/24] Train loss=0.7142363786697388
[15/24] Train loss=0.6933851838111877
[20/24] Train loss=0.6972161531448364
Test set avg_accuracy=71.64% avg_sensitivity=51.04%, avg_specificity=79.44% avg_auc=67.48%
Best model saved!! Metric=-56.39051678018667!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.711113 Test loss=0.625938 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6990024447441101
[5/24] Train loss=0.69118732213974
[10/24] Train loss=0.6901978254318237
[15/24] Train loss=0.6681981682777405
[20/24] Train loss=0.662898063659668
Test set avg_accuracy=75.10% avg_sensitivity=70.09%, avg_specificity=77.00% avg_auc=74.38%
Best model saved!! Metric=-29.420355358059567!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.684797 Test loss=0.598988 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6607999801635742
[5/24] Train loss=0.666433572769165
[10/24] Train loss=0.6688233017921448
[15/24] Train loss=0.64764803647995
[20/24] Train loss=0.6300406455993652
Test set avg_accuracy=76.71% avg_sensitivity=74.83%, avg_specificity=77.41% avg_auc=78.40%
Best model saved!! Metric=-18.64140383255905!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.656402 Test loss=0.572854 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6279471516609192
[5/24] Train loss=0.6416456699371338
[10/24] Train loss=0.6403138041496277
[15/24] Train loss=0.6152496933937073
[20/24] Train loss=0.6037322282791138
Test set avg_accuracy=77.83% avg_sensitivity=78.96%, avg_specificity=77.40% avg_auc=81.36%
Best model saved!! Metric=-10.462949050182772!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.628618 Test loss=0.544894 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5989230871200562
[5/24] Train loss=0.609925389289856
[10/24] Train loss=0.6143085956573486
[15/24] Train loss=0.5839707851409912
[20/24] Train loss=0.5734444260597229
Test set avg_accuracy=78.16% avg_sensitivity=80.19%, avg_specificity=77.40% avg_auc=83.43%
Best model saved!! Metric=-6.821013269823112!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.600096 Test loss=0.521538 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5718799829483032
[5/24] Train loss=0.576191246509552
[10/24] Train loss=0.5880312919616699
[15/24] Train loss=0.5553421378135681
[20/24] Train loss=0.5366670489311218
Test set avg_accuracy=79.75% avg_sensitivity=80.43%, avg_specificity=79.50% avg_auc=85.12%
Best model saved!! Metric=-1.2049289959257834!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.569968 Test loss=0.490417 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5414510369300842
[5/24] Train loss=0.5547255873680115
[10/24] Train loss=0.5648655891418457
[15/24] Train loss=0.5320951342582703
[20/24] Train loss=0.5073485374450684
Test set avg_accuracy=81.04% avg_sensitivity=79.91%, avg_specificity=81.47% avg_auc=86.37%
Best model saved!! Metric=2.786648670801867!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.541070 Test loss=0.465472 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.514506459236145
[5/24] Train loss=0.5215713977813721
[10/24] Train loss=0.5161190032958984
[15/24] Train loss=0.4942953884601593
[20/24] Train loss=0.4765778183937073
Test set avg_accuracy=83.01% avg_sensitivity=77.25%, avg_specificity=85.19% avg_auc=87.31%
Best model saved!! Metric=6.756670209292309!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.508102 Test loss=0.437733 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4830918312072754
[5/24] Train loss=0.48657792806625366
[10/24] Train loss=0.49300333857536316
[15/24] Train loss=0.4649922847747803
[20/24] Train loss=0.43890827894210815
Test set avg_accuracy=84.66% avg_sensitivity=77.16%, avg_specificity=87.50% avg_auc=88.60%
Best model saved!! Metric=11.920990185588565!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.477649 Test loss=0.416871 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.45052042603492737
[5/24] Train loss=0.458434522151947
[10/24] Train loss=0.45974498987197876
[15/24] Train loss=0.44000107049942017
[20/24] Train loss=0.4146159589290619
Test set avg_accuracy=85.57% avg_sensitivity=78.63%, avg_specificity=88.20% avg_auc=89.56%
Best model saved!! Metric=15.96102322941394!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.448152 Test loss=0.400436 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.42240628600120544
[5/24] Train loss=0.43316203355789185
[10/24] Train loss=0.43721240758895874
[15/24] Train loss=0.4120544195175171
[20/24] Train loss=0.3856198787689209
Test set avg_accuracy=85.98% avg_sensitivity=75.12%, avg_specificity=90.09% avg_auc=90.18%
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.421076 Test loss=0.381240 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3923962414264679
[5/24] Train loss=0.41083237528800964
[10/24] Train loss=0.4193826913833618
[15/24] Train loss=0.39493706822395325
[20/24] Train loss=0.3610624670982361
Test set avg_accuracy=86.64% avg_sensitivity=74.50%, avg_specificity=91.24% avg_auc=90.76%
Best model saved!! Metric=17.14078241063757!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.396296 Test loss=0.365409 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3757554590702057
[5/24] Train loss=0.39155688881874084
[10/24] Train loss=0.4098021388053894
[15/24] Train loss=0.37176835536956787
[20/24] Train loss=0.339114785194397
Test set avg_accuracy=86.82% avg_sensitivity=72.37%, avg_specificity=92.30% avg_auc=91.08%
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.376006 Test loss=0.349059 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3504016101360321
[5/24] Train loss=0.36696794629096985
[10/24] Train loss=0.38372182846069336
[15/24] Train loss=0.35679274797439575
[20/24] Train loss=0.3240605294704437
Test set avg_accuracy=87.43% avg_sensitivity=76.45%, avg_specificity=91.60% avg_auc=91.62%
Best model saved!! Metric=21.101423524842502!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.357230 Test loss=0.343705 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.33492758870124817
[5/24] Train loss=0.3490120768547058
[10/24] Train loss=0.37481775879859924
[15/24] Train loss=0.34314095973968506
[20/24] Train loss=0.31204721331596375
Test set avg_accuracy=87.25% avg_sensitivity=74.31%, avg_specificity=92.15% avg_auc=91.84%
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.343112 Test loss=0.331310 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3204004764556885
[5/24] Train loss=0.33279499411582947
[10/24] Train loss=0.3577783703804016
[15/24] Train loss=0.3380114436149597
[20/24] Train loss=0.29734566807746887
Test set avg_accuracy=87.12% avg_sensitivity=74.45%, avg_specificity=91.92% avg_auc=92.11%
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.328914 Test loss=0.326553 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.31086939573287964
[5/24] Train loss=0.324150025844574
[10/24] Train loss=0.3549574613571167
[15/24] Train loss=0.32770681381225586
[20/24] Train loss=0.28636348247528076
Test set avg_accuracy=87.15% avg_sensitivity=76.54%, avg_specificity=91.17% avg_auc=92.39%
Best model saved!! Metric=21.247248836969376!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.319864 Test loss=0.323678 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3010951578617096
[5/24] Train loss=0.31223419308662415
[10/24] Train loss=0.34227922558784485
[15/24] Train loss=0.3148704767227173
[20/24] Train loss=0.2763865888118744
Test set avg_accuracy=87.62% avg_sensitivity=73.03%, avg_specificity=93.14% avg_auc=92.68%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.308794 Test loss=0.307918 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2885200083255768
[5/24] Train loss=0.29787829518318176
[10/24] Train loss=0.3324081003665924
[15/24] Train loss=0.30516940355300903
[20/24] Train loss=0.26737335324287415
Test set avg_accuracy=87.86% avg_sensitivity=72.18%, avg_specificity=93.81% avg_auc=92.81%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.298810 Test loss=0.303226 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28301191329956055
[5/24] Train loss=0.28672388195991516
[10/24] Train loss=0.3277193605899811
[15/24] Train loss=0.30861467123031616
[20/24] Train loss=0.2587159276008606
Test set avg_accuracy=88.10% avg_sensitivity=69.38%, avg_specificity=95.19% avg_auc=93.01%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.291608 Test loss=0.299015 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.27719780802726746
[5/24] Train loss=0.2842901051044464
[10/24] Train loss=0.32711005210876465
[15/24] Train loss=0.29962772130966187
[20/24] Train loss=0.24959398806095123
Test set avg_accuracy=87.36% avg_sensitivity=62.70%, avg_specificity=96.70% avg_auc=92.66%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.284752 Test loss=0.311235 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2655154764652252
[5/24] Train loss=0.2659062445163727
[10/24] Train loss=0.31896841526031494
[15/24] Train loss=0.28963354229927063
[20/24] Train loss=0.2468786984682083
Test set avg_accuracy=87.41% avg_sensitivity=63.18%, avg_specificity=96.59% avg_auc=93.12%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.277791 Test loss=0.302741 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2617887258529663
[5/24] Train loss=0.26562178134918213
[10/24] Train loss=0.3056017756462097
[15/24] Train loss=0.2822340726852417
[20/24] Train loss=0.24242283403873444
Test set avg_accuracy=87.83% avg_sensitivity=65.12%, avg_specificity=96.43% avg_auc=93.08%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.272610 Test loss=0.301533 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2524718642234802
[5/24] Train loss=0.25448790192604065
[10/24] Train loss=0.30653566122055054
[15/24] Train loss=0.2795328199863434
[20/24] Train loss=0.23820626735687256
Test set avg_accuracy=88.33% avg_sensitivity=70.33%, avg_specificity=95.15% avg_auc=93.45%
Best model saved!! Metric=21.26366423601951!!
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.266879 Test loss=0.290415 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.25428998470306396
[5/24] Train loss=0.2545032203197479
[10/24] Train loss=0.30187809467315674
[15/24] Train loss=0.2715587019920349
[20/24] Train loss=0.23303355276584625
Test set avg_accuracy=87.07% avg_sensitivity=60.09%, avg_specificity=97.29% avg_auc=92.99%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.261879 Test loss=0.313040 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.25522273778915405
[5/24] Train loss=0.2420521378517151
[10/24] Train loss=0.3038557767868042
[15/24] Train loss=0.2708376348018646
[20/24] Train loss=0.23090651631355286
Test set avg_accuracy=88.11% avg_sensitivity=67.25%, avg_specificity=96.01% avg_auc=93.29%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.256035 Test loss=0.294803 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.23803485929965973
[5/24] Train loss=0.2382154017686844
[10/24] Train loss=0.2907353341579437
[15/24] Train loss=0.26028791069984436
[20/24] Train loss=0.22958430647850037
Test set avg_accuracy=88.54% avg_sensitivity=68.01%, avg_specificity=96.32% avg_auc=92.97%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.251666 Test loss=0.300168 Current lr=[0.000210185142098938]

[0/24] Train loss=0.24384045600891113
[5/24] Train loss=0.22689788043498993
[10/24] Train loss=0.27834436297416687
[15/24] Train loss=0.2652778625488281
[20/24] Train loss=0.2264631688594818
Test set avg_accuracy=86.09% avg_sensitivity=55.02%, avg_specificity=97.86% avg_auc=92.24%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.249697 Test loss=0.341662 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.23844538629055023
[5/24] Train loss=0.23799924552440643
[10/24] Train loss=0.28518733382225037
[15/24] Train loss=0.25505444407463074
[20/24] Train loss=0.21354924142360687
Test set avg_accuracy=88.09% avg_sensitivity=70.43%, avg_specificity=94.78% avg_auc=93.38%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.246636 Test loss=0.292477 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2367495745420456
[5/24] Train loss=0.21765606105327606
[10/24] Train loss=0.28120914101600647
[15/24] Train loss=0.2535790503025055
[20/24] Train loss=0.21724608540534973
Test set avg_accuracy=87.49% avg_sensitivity=63.08%, avg_specificity=96.73% avg_auc=93.52%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.241377 Test loss=0.302777 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22079262137413025
[5/24] Train loss=0.22545678913593292
[10/24] Train loss=0.270236074924469
[15/24] Train loss=0.2548602819442749
[20/24] Train loss=0.21264973282814026
Test set avg_accuracy=88.32% avg_sensitivity=68.01%, avg_specificity=96.01% avg_auc=93.24%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.235793 Test loss=0.291233 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.2378779798746109
[5/24] Train loss=0.22017470002174377
[10/24] Train loss=0.26417237520217896
[15/24] Train loss=0.2602105736732483
[20/24] Train loss=0.21433980762958527
Test set avg_accuracy=86.12% avg_sensitivity=57.39%, avg_specificity=97.00% avg_auc=92.44%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.236063 Test loss=0.324053 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.21688586473464966
[5/24] Train loss=0.21960318088531494
[10/24] Train loss=0.26436275243759155
[15/24] Train loss=0.2519893944263458
[20/24] Train loss=0.2042899876832962
Test set avg_accuracy=85.95% avg_sensitivity=56.30%, avg_specificity=97.18% avg_auc=92.26%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.230543 Test loss=0.332339 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21383127570152283
[5/24] Train loss=0.20955964922904968
[10/24] Train loss=0.25708475708961487
[15/24] Train loss=0.24235273897647858
[20/24] Train loss=0.20519833266735077
Test set avg_accuracy=86.43% avg_sensitivity=60.76%, avg_specificity=96.16% avg_auc=91.51%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.230449 Test loss=0.334501 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22187936305999756
[5/24] Train loss=0.20636025071144104
[10/24] Train loss=0.2812759280204773
[15/24] Train loss=0.23860864341259003
[20/24] Train loss=0.20192892849445343
Test set avg_accuracy=86.78% avg_sensitivity=62.89%, avg_specificity=95.83% avg_auc=91.17%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.228298 Test loss=0.338445 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.20514768362045288
[5/24] Train loss=0.20551055669784546
[10/24] Train loss=0.26236242055892944
[15/24] Train loss=0.2320016622543335
[20/24] Train loss=0.1995221972465515
Test set avg_accuracy=85.78% avg_sensitivity=55.55%, avg_specificity=97.24% avg_auc=89.93%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.223352 Test loss=0.371457 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.22662703692913055
[5/24] Train loss=0.20815303921699524
[10/24] Train loss=0.26057156920433044
[15/24] Train loss=0.2299644947052002
[20/24] Train loss=0.20101132988929749
Test set avg_accuracy=86.03% avg_sensitivity=57.96%, avg_specificity=96.66% avg_auc=91.92%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.226150 Test loss=0.337450 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2093437761068344
[5/24] Train loss=0.2004242092370987
[10/24] Train loss=0.26413843035697937
[15/24] Train loss=0.234741672873497
[20/24] Train loss=0.19859877228736877
Test set avg_accuracy=88.09% avg_sensitivity=81.42%, avg_specificity=90.61% avg_auc=93.32%
Best model saved!! Metric=27.439822139274384!!
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.223229 Test loss=0.301858 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.200493723154068
[5/24] Train loss=0.20212917029857635
[10/24] Train loss=0.25739017128944397
[15/24] Train loss=0.22580930590629578
[20/24] Train loss=0.205208882689476
Test set avg_accuracy=86.12% avg_sensitivity=57.06%, avg_specificity=97.13% avg_auc=91.29%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.216391 Test loss=0.350594 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.20205995440483093
[5/24] Train loss=0.18703509867191315
[10/24] Train loss=0.2497771978378296
[15/24] Train loss=0.23073966801166534
[20/24] Train loss=0.20230364799499512
Test set avg_accuracy=84.53% avg_sensitivity=50.81%, avg_specificity=97.31% avg_auc=89.23%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.214736 Test loss=0.399968 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.1939898431301117
[5/24] Train loss=0.19387924671173096
[10/24] Train loss=0.24982142448425293
[15/24] Train loss=0.2249222844839096
[20/24] Train loss=0.20292441546916962
Test set avg_accuracy=86.65% avg_sensitivity=60.85%, avg_specificity=96.43% avg_auc=91.42%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.211727 Test loss=0.342437 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2099030613899231
[5/24] Train loss=0.181222066283226
[10/24] Train loss=0.24340321123600006
[15/24] Train loss=0.22853359580039978
[20/24] Train loss=0.19214853644371033
Test set avg_accuracy=85.62% avg_sensitivity=55.83%, avg_specificity=96.91% avg_auc=89.45%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.211638 Test loss=0.391683 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.1908728927373886
[5/24] Train loss=0.1862206757068634
[10/24] Train loss=0.2420220673084259
[15/24] Train loss=0.223393514752388
[20/24] Train loss=0.20154985785484314
Test set avg_accuracy=84.04% avg_sensitivity=48.77%, avg_specificity=97.40% avg_auc=89.31%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.214106 Test loss=0.410173 Current lr=[0.00029967723776099]

[0/24] Train loss=0.1895807385444641
[5/24] Train loss=0.184121772646904
[10/24] Train loss=0.23539477586746216
[15/24] Train loss=0.2226797491312027
[20/24] Train loss=0.19571734964847565
Test set avg_accuracy=87.75% avg_sensitivity=68.72%, avg_specificity=94.96% avg_auc=87.56%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.208258 Test loss=0.378112 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2232166826725006
[5/24] Train loss=0.1766793131828308
[10/24] Train loss=0.24636124074459076
[15/24] Train loss=0.21317200362682343
[20/24] Train loss=0.19903217256069183
Test set avg_accuracy=88.57% avg_sensitivity=77.11%, avg_specificity=92.91% avg_auc=93.24%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.207807 Test loss=0.294963 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.18768645823001862
[5/24] Train loss=0.20292602479457855
[10/24] Train loss=0.23832176625728607
[15/24] Train loss=0.21026413142681122
[20/24] Train loss=0.19339235126972198
Test set avg_accuracy=87.07% avg_sensitivity=65.73%, avg_specificity=95.15% avg_auc=90.96%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.207554 Test loss=0.336892 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20580631494522095
[5/24] Train loss=0.20327451825141907
[10/24] Train loss=0.25004276633262634
[15/24] Train loss=0.22475269436836243
[20/24] Train loss=0.19267266988754272
Test set avg_accuracy=87.72% avg_sensitivity=70.09%, avg_specificity=94.40% avg_auc=91.64%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.211802 Test loss=0.329591 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19504065811634064
[5/24] Train loss=0.17510917782783508
[10/24] Train loss=0.24273079633712769
[15/24] Train loss=0.2113143503665924
[20/24] Train loss=0.181802898645401
Test set avg_accuracy=87.76% avg_sensitivity=68.86%, avg_specificity=94.92% avg_auc=93.09%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.202054 Test loss=0.294933 Current lr=[0.000298904600941902]

[0/24] Train loss=0.1871570348739624
[5/24] Train loss=0.17327754199504852
[10/24] Train loss=0.2320067137479782
[15/24] Train loss=0.21159526705741882
[20/24] Train loss=0.1798722892999649
Test set avg_accuracy=88.20% avg_sensitivity=71.28%, avg_specificity=94.61% avg_auc=93.19%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.196300 Test loss=0.296063 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.18093577027320862
[5/24] Train loss=0.17097878456115723
[10/24] Train loss=0.2204982191324234
[15/24] Train loss=0.2210516631603241
[20/24] Train loss=0.1837468296289444
Test set avg_accuracy=85.51% avg_sensitivity=55.50%, avg_specificity=96.88% avg_auc=91.29%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.198716 Test loss=0.350811 Current lr=[0.000297555943323901]

[0/24] Train loss=0.18137812614440918
[5/24] Train loss=0.1946539431810379
[10/24] Train loss=0.2365739643573761
[15/24] Train loss=0.21206270158290863
[20/24] Train loss=0.19053654372692108
Test set avg_accuracy=86.07% avg_sensitivity=59.95%, avg_specificity=95.96% avg_auc=91.22%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.197981 Test loss=0.345070 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18500223755836487
[5/24] Train loss=0.1662299931049347
[10/24] Train loss=0.2289123684167862
[15/24] Train loss=0.20798909664154053
[20/24] Train loss=0.18652896583080292
Test set avg_accuracy=85.27% avg_sensitivity=54.22%, avg_specificity=97.04% avg_auc=90.02%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.195447 Test loss=0.377561 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.18231049180030823
[5/24] Train loss=0.19577448070049286
[10/24] Train loss=0.22078847885131836
[15/24] Train loss=0.21492204070091248
[20/24] Train loss=0.17892663180828094
Test set avg_accuracy=87.57% avg_sensitivity=78.82%, avg_specificity=90.88% avg_auc=92.86%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.198654 Test loss=0.305719 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1821340024471283
[5/24] Train loss=0.15623803436756134
[10/24] Train loss=0.22013893723487854
[15/24] Train loss=0.2178497463464737
[20/24] Train loss=0.1754336953163147
Test set avg_accuracy=88.40% avg_sensitivity=75.92%, avg_specificity=93.12% avg_auc=93.75%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.190514 Test loss=0.285877 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1840444654226303
[5/24] Train loss=0.16198773682117462
[10/24] Train loss=0.2121044546365738
[15/24] Train loss=0.20318417251110077
[20/24] Train loss=0.181855246424675
Test set avg_accuracy=86.89% avg_sensitivity=77.87%, avg_specificity=90.31% avg_auc=92.19%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.189327 Test loss=0.324633 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18355081975460052
[5/24] Train loss=0.17550523579120636
[10/24] Train loss=0.21851696074008942
[15/24] Train loss=0.21091380715370178
[20/24] Train loss=0.17588673532009125
Test set avg_accuracy=87.99% avg_sensitivity=71.66%, avg_specificity=94.18% avg_auc=92.97%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.191710 Test loss=0.300151 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1836165487766266
[5/24] Train loss=0.1634555608034134
[10/24] Train loss=0.22371184825897217
[15/24] Train loss=0.20995783805847168
[20/24] Train loss=0.18688732385635376
Test set avg_accuracy=86.21% avg_sensitivity=60.85%, avg_specificity=95.82% avg_auc=91.50%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.189896 Test loss=0.351146 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18528321385383606
[5/24] Train loss=0.15532253682613373
[10/24] Train loss=0.22081677615642548
[15/24] Train loss=0.20226943492889404
[20/24] Train loss=0.17815101146697998
Test set avg_accuracy=86.08% avg_sensitivity=81.09%, avg_specificity=87.97% avg_auc=92.35%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.189043 Test loss=0.336115 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18808458745479584
[5/24] Train loss=0.16704127192497253
[10/24] Train loss=0.21865025162696838
[15/24] Train loss=0.2036048024892807
[20/24] Train loss=0.1773708462715149
Test set avg_accuracy=86.95% avg_sensitivity=70.24%, avg_specificity=93.29% avg_auc=92.70%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.186934 Test loss=0.309051 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18414241075515747
[5/24] Train loss=0.16601376235485077
[10/24] Train loss=0.2065163403749466
[15/24] Train loss=0.1934051513671875
[20/24] Train loss=0.17411887645721436
Test set avg_accuracy=87.54% avg_sensitivity=72.99%, avg_specificity=93.05% avg_auc=92.36%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.188219 Test loss=0.310822 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.1771032065153122
[5/24] Train loss=0.15677021443843842
[10/24] Train loss=0.20571187138557434
[15/24] Train loss=0.20488415658473969
[20/24] Train loss=0.17369025945663452
Test set avg_accuracy=87.23% avg_sensitivity=74.08%, avg_specificity=92.21% avg_auc=91.50%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.186792 Test loss=0.331642 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.17138129472732544
[5/24] Train loss=0.16214852035045624
[10/24] Train loss=0.21465912461280823
[15/24] Train loss=0.19529248774051666
[20/24] Train loss=0.17303425073623657
Test set avg_accuracy=84.54% avg_sensitivity=52.84%, avg_specificity=96.55% avg_auc=88.85%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.184168 Test loss=0.388977 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.16741397976875305
[5/24] Train loss=0.15641216933727264
[10/24] Train loss=0.2232021987438202
[15/24] Train loss=0.2023160457611084
[20/24] Train loss=0.17259933054447174
Test set avg_accuracy=85.51% avg_sensitivity=60.05%, avg_specificity=95.15% avg_auc=90.20%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.185993 Test loss=0.365908 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1684674322605133
[5/24] Train loss=0.15365159511566162
[10/24] Train loss=0.21682438254356384
[15/24] Train loss=0.2025374472141266
[20/24] Train loss=0.16865012049674988
Test set avg_accuracy=80.05% avg_sensitivity=31.37%, avg_specificity=98.49% avg_auc=82.57%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.180121 Test loss=0.545576 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1710144728422165
[5/24] Train loss=0.15694791078567505
[10/24] Train loss=0.20916025340557098
[15/24] Train loss=0.19524440169334412
[20/24] Train loss=0.16580359637737274
Test set avg_accuracy=87.97% avg_sensitivity=79.57%, avg_specificity=91.15% avg_auc=92.50%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.176373 Test loss=0.311599 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17103399336338043
[5/24] Train loss=0.15087418258190155
[10/24] Train loss=0.23100171983242035
[15/24] Train loss=0.1942978948354721
[20/24] Train loss=0.17258742451667786
Test set avg_accuracy=87.25% avg_sensitivity=66.49%, avg_specificity=95.12% avg_auc=92.27%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.179363 Test loss=0.319844 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.16971150040626526
[5/24] Train loss=0.14833703637123108
[10/24] Train loss=0.21476691961288452
[15/24] Train loss=0.19504638016223907
[20/24] Train loss=0.1704777032136917
Test set avg_accuracy=84.00% avg_sensitivity=50.57%, avg_specificity=96.66% avg_auc=89.11%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.178782 Test loss=0.390695 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.16673442721366882
[5/24] Train loss=0.17127394676208496
[10/24] Train loss=0.21274635195732117
[15/24] Train loss=0.19476443529129028
[20/24] Train loss=0.16397309303283691
Test set avg_accuracy=86.47% avg_sensitivity=61.18%, avg_specificity=96.05% avg_auc=88.46%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.180951 Test loss=0.369689 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17190739512443542
[5/24] Train loss=0.151130810379982
[10/24] Train loss=0.22257469594478607
[15/24] Train loss=0.1919855922460556
[20/24] Train loss=0.1606028974056244
Test set avg_accuracy=85.10% avg_sensitivity=55.26%, avg_specificity=96.41% avg_auc=88.66%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.175123 Test loss=0.395447 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17469722032546997
[5/24] Train loss=0.14575159549713135
[10/24] Train loss=0.21891728043556213
[15/24] Train loss=0.20316249132156372
[20/24] Train loss=0.16540661454200745
Test set avg_accuracy=86.85% avg_sensitivity=65.17%, avg_specificity=95.06% avg_auc=91.34%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.176273 Test loss=0.337031 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1652745008468628
[5/24] Train loss=0.1549834907054901
[10/24] Train loss=0.21737591922283173
[15/24] Train loss=0.19659265875816345
[20/24] Train loss=0.1763918101787567
Test set avg_accuracy=83.78% avg_sensitivity=48.25%, avg_specificity=97.24% avg_auc=87.26%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.176788 Test loss=0.422639 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.16607193648815155
[5/24] Train loss=0.16218745708465576
[10/24] Train loss=0.21115770936012268
[15/24] Train loss=0.19899550080299377
[20/24] Train loss=0.1637217253446579
Test set avg_accuracy=87.45% avg_sensitivity=72.75%, avg_specificity=93.02% avg_auc=92.49%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.177082 Test loss=0.311375 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1696275770664215
[5/24] Train loss=0.15477702021598816
[10/24] Train loss=0.1891486942768097
[15/24] Train loss=0.19052092730998993
[20/24] Train loss=0.15892857313156128
Test set avg_accuracy=87.36% avg_sensitivity=75.69%, avg_specificity=91.78% avg_auc=92.73%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.172166 Test loss=0.306064 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17013520002365112
[5/24] Train loss=0.14369717240333557
[10/24] Train loss=0.20175549387931824
[15/24] Train loss=0.18569178879261017
[20/24] Train loss=0.15910108387470245
Test set avg_accuracy=86.59% avg_sensitivity=70.14%, avg_specificity=92.82% avg_auc=91.46%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.171682 Test loss=0.327807 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1657709777355194
[5/24] Train loss=0.15995995700359344
[10/24] Train loss=0.2078016996383667
[15/24] Train loss=0.18659119307994843
[20/24] Train loss=0.18622739613056183
Test set avg_accuracy=87.83% avg_sensitivity=73.08%, avg_specificity=93.41% avg_auc=90.13%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.175601 Test loss=0.352112 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.162210151553154
[5/24] Train loss=0.14700986444950104
[10/24] Train loss=0.19029074907302856
[15/24] Train loss=0.19169045984745026
[20/24] Train loss=0.16260775923728943
Test set avg_accuracy=85.55% avg_sensitivity=84.27%, avg_specificity=86.03% avg_auc=90.15%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.170308 Test loss=0.386104 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16372430324554443
[5/24] Train loss=0.15956062078475952
[10/24] Train loss=0.18222126364707947
[15/24] Train loss=0.19480912387371063
[20/24] Train loss=0.16675233840942383
Test set avg_accuracy=86.51% avg_sensitivity=62.18%, avg_specificity=95.73% avg_auc=89.39%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.171513 Test loss=0.369048 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.1609613001346588
[5/24] Train loss=0.15167616307735443
[10/24] Train loss=0.19628040492534637
[15/24] Train loss=0.20791254937648773
[20/24] Train loss=0.16859334707260132
Test set avg_accuracy=85.82% avg_sensitivity=76.16%, avg_specificity=89.48% avg_auc=91.40%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.172995 Test loss=0.334599 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17220532894134521
[5/24] Train loss=0.15445956587791443
[10/24] Train loss=0.20075201988220215
[15/24] Train loss=0.1947242021560669
[20/24] Train loss=0.16764938831329346
Test set avg_accuracy=85.65% avg_sensitivity=82.80%, avg_specificity=86.73% avg_auc=91.22%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.172974 Test loss=0.362645 Current lr=[0.000224838296036774]

[0/24] Train loss=0.15656806528568268
[5/24] Train loss=0.154423788189888
[10/24] Train loss=0.19222944974899292
[15/24] Train loss=0.20500905811786652
[20/24] Train loss=0.16596519947052002
Test set avg_accuracy=84.45% avg_sensitivity=51.99%, avg_specificity=96.75% avg_auc=86.37%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.172234 Test loss=0.423586 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16974332928657532
[5/24] Train loss=0.14552271366119385
[10/24] Train loss=0.19247370958328247
[15/24] Train loss=0.18416853249073029
[20/24] Train loss=0.16823318600654602
Test set avg_accuracy=86.82% avg_sensitivity=69.67%, avg_specificity=93.32% avg_auc=91.49%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.171440 Test loss=0.323891 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17076203227043152
[5/24] Train loss=0.15757980942726135
[10/24] Train loss=0.2024206966161728
[15/24] Train loss=0.18855297565460205
[20/24] Train loss=0.16126805543899536
Test set avg_accuracy=87.34% avg_sensitivity=70.00%, avg_specificity=93.91% avg_auc=91.79%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.172870 Test loss=0.321623 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1658431440591812
[5/24] Train loss=0.15336459875106812
[10/24] Train loss=0.19797058403491974
[15/24] Train loss=0.18637816607952118
[20/24] Train loss=0.17075641453266144
Test set avg_accuracy=87.62% avg_sensitivity=78.77%, avg_specificity=90.97% avg_auc=91.50%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.173231 Test loss=0.327897 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1641015261411667
[5/24] Train loss=0.14726099371910095
[10/24] Train loss=0.1920200139284134
[15/24] Train loss=0.1836584210395813
[20/24] Train loss=0.16246549785137177
Test set avg_accuracy=86.15% avg_sensitivity=77.35%, avg_specificity=89.48% avg_auc=92.47%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.171127 Test loss=0.327768 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.15574058890342712
[5/24] Train loss=0.1474665105342865
[10/24] Train loss=0.19091394543647766
[15/24] Train loss=0.18361258506774902
[20/24] Train loss=0.16396689414978027
Test set avg_accuracy=85.20% avg_sensitivity=61.47%, avg_specificity=94.18% avg_auc=90.68%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.166312 Test loss=0.345612 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16403183341026306
[5/24] Train loss=0.15130455791950226
[10/24] Train loss=0.19166505336761475
[15/24] Train loss=0.17930877208709717
[20/24] Train loss=0.1578589528799057
Test set avg_accuracy=85.92% avg_sensitivity=65.31%, avg_specificity=93.73% avg_auc=91.41%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.170636 Test loss=0.334781 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1600639373064041
[5/24] Train loss=0.1523798704147339
[10/24] Train loss=0.20109419524669647
[15/24] Train loss=0.17696860432624817
[20/24] Train loss=0.1537453681230545
Test set avg_accuracy=86.58% avg_sensitivity=80.71%, avg_specificity=88.80% avg_auc=92.35%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.166974 Test loss=0.332450 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.15909701585769653
[5/24] Train loss=0.1487620323896408
[10/24] Train loss=0.192156583070755
[15/24] Train loss=0.17826679348945618
[20/24] Train loss=0.1628834754228592
Test set avg_accuracy=86.46% avg_sensitivity=66.16%, avg_specificity=94.15% avg_auc=91.30%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.164406 Test loss=0.331468 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1607401967048645
[5/24] Train loss=0.1416996419429779
[10/24] Train loss=0.186237171292305
[15/24] Train loss=0.1832071840763092
[20/24] Train loss=0.16248658299446106
Test set avg_accuracy=87.70% avg_sensitivity=80.76%, avg_specificity=90.32% avg_auc=92.10%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.168334 Test loss=0.322008 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.16073039174079895
[5/24] Train loss=0.1438170224428177
[10/24] Train loss=0.18487940728664398
[15/24] Train loss=0.17965304851531982
[20/24] Train loss=0.170557901263237
Test set avg_accuracy=85.66% avg_sensitivity=64.08%, avg_specificity=93.84% avg_auc=90.58%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.166065 Test loss=0.351513 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15579316020011902
[5/24] Train loss=0.14448182284832
[10/24] Train loss=0.18115702271461487
[15/24] Train loss=0.17749544978141785
[20/24] Train loss=0.16883763670921326
Test set avg_accuracy=86.99% avg_sensitivity=74.27%, avg_specificity=91.81% avg_auc=92.02%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.163537 Test loss=0.325842 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15481039881706238
[5/24] Train loss=0.1477118283510208
[10/24] Train loss=0.17998363077640533
[15/24] Train loss=0.1836601346731186
[20/24] Train loss=0.15948821604251862
Test set avg_accuracy=87.40% avg_sensitivity=72.89%, avg_specificity=92.89% avg_auc=92.12%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.163897 Test loss=0.311382 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.1502627730369568
[5/24] Train loss=0.14647217094898224
[10/24] Train loss=0.18562401831150055
[15/24] Train loss=0.17511658370494843
[20/24] Train loss=0.153468519449234
Test set avg_accuracy=85.38% avg_sensitivity=59.91%, avg_specificity=95.03% avg_auc=89.74%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.160746 Test loss=0.356537 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15673504769802094
[5/24] Train loss=0.14064249396324158
[10/24] Train loss=0.17825251817703247
[15/24] Train loss=0.1758645474910736
[20/24] Train loss=0.1550067961215973
Test set avg_accuracy=83.53% avg_sensitivity=48.91%, avg_specificity=96.64% avg_auc=88.46%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.158356 Test loss=0.391545 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15146076679229736
[5/24] Train loss=0.14299575984477997
[10/24] Train loss=0.1754039227962494
[15/24] Train loss=0.17549312114715576
[20/24] Train loss=0.15741075575351715
Test set avg_accuracy=81.80% avg_sensitivity=38.48%, avg_specificity=98.20% avg_auc=84.33%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.157739 Test loss=0.473795 Current lr=[0.000156543481933168]

[0/24] Train loss=0.15449129045009613
[5/24] Train loss=0.13997311890125275
[10/24] Train loss=0.17555591464042664
[15/24] Train loss=0.1788245141506195
[20/24] Train loss=0.15511789917945862
Test set avg_accuracy=84.62% avg_sensitivity=55.40%, avg_specificity=95.69% avg_auc=88.37%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.157471 Test loss=0.376241 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1589386761188507
[5/24] Train loss=0.13792937994003296
[10/24] Train loss=0.17779408395290375
[15/24] Train loss=0.17427778244018555
[20/24] Train loss=0.14859209954738617
Test set avg_accuracy=85.29% avg_sensitivity=56.54%, avg_specificity=96.18% avg_auc=90.30%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.156161 Test loss=0.353409 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15332147479057312
[5/24] Train loss=0.13927806913852692
[10/24] Train loss=0.17094096541404724
[15/24] Train loss=0.17665860056877136
[20/24] Train loss=0.15187355875968933
Test set avg_accuracy=85.66% avg_sensitivity=58.29%, avg_specificity=96.03% avg_auc=90.12%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.155640 Test loss=0.352901 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14230531454086304
[5/24] Train loss=0.13614216446876526
[10/24] Train loss=0.16718535125255585
[15/24] Train loss=0.17080096900463104
[20/24] Train loss=0.14852891862392426
Test set avg_accuracy=85.26% avg_sensitivity=53.93%, avg_specificity=97.13% avg_auc=88.68%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.154396 Test loss=0.373626 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15271390974521637
[5/24] Train loss=0.13037307560443878
[10/24] Train loss=0.16129492223262787
[15/24] Train loss=0.16887205839157104
[20/24] Train loss=0.14911402761936188
Test set avg_accuracy=84.90% avg_sensitivity=54.45%, avg_specificity=96.43% avg_auc=89.08%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.153153 Test loss=0.370556 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15600675344467163
[5/24] Train loss=0.1362362951040268
[10/24] Train loss=0.16294071078300476
[15/24] Train loss=0.16860166192054749
[20/24] Train loss=0.1472829133272171
Test set avg_accuracy=82.50% avg_sensitivity=41.18%, avg_specificity=98.15% avg_auc=81.64%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.152823 Test loss=0.501210 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15111802518367767
[5/24] Train loss=0.1403372585773468
[10/24] Train loss=0.16282585263252258
[15/24] Train loss=0.1688554286956787
[20/24] Train loss=0.15369361639022827
Test set avg_accuracy=82.93% avg_sensitivity=43.84%, avg_specificity=97.74% avg_auc=87.18%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.153921 Test loss=0.438461 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14976921677589417
[5/24] Train loss=0.13568098843097687
[10/24] Train loss=0.16994929313659668
[15/24] Train loss=0.16207164525985718
[20/24] Train loss=0.15139631927013397
Test set avg_accuracy=84.31% avg_sensitivity=48.48%, avg_specificity=97.88% avg_auc=88.47%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.153590 Test loss=0.410128 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14467163383960724
[5/24] Train loss=0.13436120748519897
[10/24] Train loss=0.1654135286808014
[15/24] Train loss=0.16668012738227844
[20/24] Train loss=0.14665989577770233
Test set avg_accuracy=87.45% avg_sensitivity=68.01%, avg_specificity=94.81% avg_auc=92.23%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.150313 Test loss=0.317588 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1445196568965912
[5/24] Train loss=0.13438813388347626
[10/24] Train loss=0.16397099196910858
[15/24] Train loss=0.16303078830242157
[20/24] Train loss=0.15147095918655396
Test set avg_accuracy=87.60% avg_sensitivity=75.02%, avg_specificity=92.37% avg_auc=92.83%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.150292 Test loss=0.305974 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14476408064365387
[5/24] Train loss=0.13402636349201202
[10/24] Train loss=0.16091473400592804
[15/24] Train loss=0.16112525761127472
[20/24] Train loss=0.14612813293933868
Test set avg_accuracy=87.49% avg_sensitivity=76.73%, avg_specificity=91.56% avg_auc=92.91%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.149375 Test loss=0.309344 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14552895724773407
[5/24] Train loss=0.1289367377758026
[10/24] Train loss=0.1654832661151886
[15/24] Train loss=0.16632957756519318
[20/24] Train loss=0.1457996815443039
Test set avg_accuracy=87.62% avg_sensitivity=77.44%, avg_specificity=91.47% avg_auc=93.01%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.148330 Test loss=0.307407 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14895354211330414
[5/24] Train loss=0.13148148357868195
[10/24] Train loss=0.15957888960838318
[15/24] Train loss=0.15292823314666748
[20/24] Train loss=0.14324964582920074
Test set avg_accuracy=87.32% avg_sensitivity=72.46%, avg_specificity=92.94% avg_auc=92.60%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.145866 Test loss=0.307928 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1397048383951187
[5/24] Train loss=0.13039012253284454
[10/24] Train loss=0.15698210895061493
[15/24] Train loss=0.16090098023414612
[20/24] Train loss=0.14076834917068481
Test set avg_accuracy=87.99% avg_sensitivity=75.45%, avg_specificity=92.75% avg_auc=92.50%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.144464 Test loss=0.309506 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.1456938236951828
[5/24] Train loss=0.13267295062541962
[10/24] Train loss=0.16090025007724762
[15/24] Train loss=0.17211085557937622
[20/24] Train loss=0.14685383439064026
Test set avg_accuracy=88.10% avg_sensitivity=73.36%, avg_specificity=93.68% avg_auc=92.94%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.147380 Test loss=0.301882 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1449914276599884
[5/24] Train loss=0.12827877700328827
[10/24] Train loss=0.1570560485124588
[15/24] Train loss=0.15799812972545624
[20/24] Train loss=0.13819755613803864
Test set avg_accuracy=87.99% avg_sensitivity=77.11%, avg_specificity=92.12% avg_auc=92.98%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.145602 Test loss=0.301412 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1372649222612381
[5/24] Train loss=0.1330268234014511
[10/24] Train loss=0.15318883955478668
[15/24] Train loss=0.15798872709274292
[20/24] Train loss=0.14051774144172668
Test set avg_accuracy=87.47% avg_sensitivity=68.67%, avg_specificity=94.60% avg_auc=92.32%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.142513 Test loss=0.308262 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13545380532741547
[5/24] Train loss=0.1424054056406021
[10/24] Train loss=0.15453065931797028
[15/24] Train loss=0.15819388628005981
[20/24] Train loss=0.14278081059455872
Test set avg_accuracy=87.70% avg_sensitivity=66.78%, avg_specificity=95.62% avg_auc=92.24%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.142396 Test loss=0.312045 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.13506382703781128
[5/24] Train loss=0.12700890004634857
[10/24] Train loss=0.15436497330665588
[15/24] Train loss=0.15747371315956116
[20/24] Train loss=0.14037050306797028
Test set avg_accuracy=87.42% avg_sensitivity=69.43%, avg_specificity=94.24% avg_auc=92.56%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.141672 Test loss=0.307098 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1390533447265625
[5/24] Train loss=0.12363491952419281
[10/24] Train loss=0.15422433614730835
[15/24] Train loss=0.1521673947572708
[20/24] Train loss=0.1367691159248352
Test set avg_accuracy=87.60% avg_sensitivity=80.66%, avg_specificity=90.23% avg_auc=92.81%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.138707 Test loss=0.312164 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13605111837387085
[5/24] Train loss=0.12514729797840118
[10/24] Train loss=0.1489432156085968
[15/24] Train loss=0.14658120274543762
[20/24] Train loss=0.13683250546455383
Test set avg_accuracy=87.23% avg_sensitivity=69.67%, avg_specificity=93.88% avg_auc=92.28%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.137076 Test loss=0.313118 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1339002251625061
[5/24] Train loss=0.12391451746225357
[10/24] Train loss=0.1420193463563919
[15/24] Train loss=0.14510364830493927
[20/24] Train loss=0.13859184086322784
Test set avg_accuracy=87.97% avg_sensitivity=75.83%, avg_specificity=92.57% avg_auc=92.55%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.136435 Test loss=0.311251 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13425643742084503
[5/24] Train loss=0.12083353102207184
[10/24] Train loss=0.1451844424009323
[15/24] Train loss=0.14562350511550903
[20/24] Train loss=0.13442356884479523
Test set avg_accuracy=87.79% avg_sensitivity=72.04%, avg_specificity=93.75% avg_auc=92.81%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.135326 Test loss=0.299706 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.13288402557373047
[5/24] Train loss=0.12137727439403534
[10/24] Train loss=0.14357329905033112
[15/24] Train loss=0.14351123571395874
[20/24] Train loss=0.13326652348041534
Test set avg_accuracy=88.06% avg_sensitivity=69.91%, avg_specificity=94.94% avg_auc=92.54%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.133930 Test loss=0.306755 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13102638721466064
[5/24] Train loss=0.11797712743282318
[10/24] Train loss=0.14241120219230652
[15/24] Train loss=0.14434503018856049
[20/24] Train loss=0.13414859771728516
Test set avg_accuracy=88.12% avg_sensitivity=72.75%, avg_specificity=93.95% avg_auc=92.78%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.133747 Test loss=0.303728 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.128987655043602
[5/24] Train loss=0.12213267385959625
[10/24] Train loss=0.1452670842409134
[15/24] Train loss=0.14541247487068176
[20/24] Train loss=0.13396282494068146
Test set avg_accuracy=87.62% avg_sensitivity=68.96%, avg_specificity=94.69% avg_auc=92.22%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.133323 Test loss=0.313553 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1314527839422226
[5/24] Train loss=0.1210777536034584
[10/24] Train loss=0.14194196462631226
[15/24] Train loss=0.1464456021785736
[20/24] Train loss=0.13449035584926605
Test set avg_accuracy=88.07% avg_sensitivity=77.01%, avg_specificity=92.26% avg_auc=92.75%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.133157 Test loss=0.310325 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12982556223869324
[5/24] Train loss=0.11903981119394302
[10/24] Train loss=0.1430244892835617
[15/24] Train loss=0.14531858265399933
[20/24] Train loss=0.13749125599861145
Test set avg_accuracy=88.19% avg_sensitivity=72.65%, avg_specificity=94.08% avg_auc=92.44%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.132486 Test loss=0.308057 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.12542526423931122
[5/24] Train loss=0.11862005293369293
[10/24] Train loss=0.14281509816646576
[15/24] Train loss=0.14215266704559326
[20/24] Train loss=0.13179172575473785
Test set avg_accuracy=87.81% avg_sensitivity=68.72%, avg_specificity=95.04% avg_auc=92.71%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.131705 Test loss=0.305088 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12930934131145477
[5/24] Train loss=0.11717348545789719
[10/24] Train loss=0.13920319080352783
[15/24] Train loss=0.14182578027248383
[20/24] Train loss=0.13437114655971527
Test set avg_accuracy=87.83% avg_sensitivity=74.31%, avg_specificity=92.94% avg_auc=92.57%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.130865 Test loss=0.308730 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.12656812369823456
[5/24] Train loss=0.11843162029981613
[10/24] Train loss=0.13925321400165558
[15/24] Train loss=0.14055770635604858
[20/24] Train loss=0.13042208552360535
Test set avg_accuracy=87.57% avg_sensitivity=69.53%, avg_specificity=94.40% avg_auc=92.68%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.130038 Test loss=0.306729 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1256731003522873
[5/24] Train loss=0.11851174384355545
[10/24] Train loss=0.13780534267425537
[15/24] Train loss=0.13673144578933716
[20/24] Train loss=0.13049937784671783
Test set avg_accuracy=88.05% avg_sensitivity=75.92%, avg_specificity=92.64% avg_auc=92.90%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.129632 Test loss=0.302831 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.12438908219337463
[5/24] Train loss=0.11716335266828537
[10/24] Train loss=0.14020207524299622
[15/24] Train loss=0.14052356779575348
[20/24] Train loss=0.12717777490615845
Test set avg_accuracy=87.90% avg_sensitivity=71.66%, avg_specificity=94.06% avg_auc=92.88%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.128647 Test loss=0.303405 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12355519086122513
[5/24] Train loss=0.11447814106941223
[10/24] Train loss=0.13517872989177704
[15/24] Train loss=0.13566739857196808
[20/24] Train loss=0.13155020773410797
Test set avg_accuracy=88.78% avg_sensitivity=75.40%, avg_specificity=93.84% avg_auc=92.66%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.128238 Test loss=0.302074 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1259632557630539
[5/24] Train loss=0.11486167460680008
[10/24] Train loss=0.1385374516248703
[15/24] Train loss=0.13901911675930023
[20/24] Train loss=0.13042552769184113
Test set avg_accuracy=88.39% avg_sensitivity=73.79%, avg_specificity=93.91% avg_auc=92.63%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.128193 Test loss=0.305635 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12648534774780273
[5/24] Train loss=0.11385630816221237
[10/24] Train loss=0.13583612442016602
[15/24] Train loss=0.13992340862751007
[20/24] Train loss=0.13141214847564697
Test set avg_accuracy=88.45% avg_sensitivity=73.46%, avg_specificity=94.13% avg_auc=92.78%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.128004 Test loss=0.305508 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12278690189123154
[5/24] Train loss=0.11500518023967743
[10/24] Train loss=0.13248248398303986
[15/24] Train loss=0.13946644961833954
[20/24] Train loss=0.127967968583107
Test set avg_accuracy=88.40% avg_sensitivity=73.46%, avg_specificity=94.06% avg_auc=92.76%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.128035 Test loss=0.304834 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12089566141366959
[5/24] Train loss=0.11675503104925156
[10/24] Train loss=0.13540831208229065
[15/24] Train loss=0.13730952143669128
[20/24] Train loss=0.12861211597919464
Test set avg_accuracy=87.99% avg_sensitivity=75.73%, avg_specificity=92.64% avg_auc=92.84%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.127645 Test loss=0.304613 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12041591852903366
[5/24] Train loss=0.11288560926914215
[10/24] Train loss=0.13497084379196167
[15/24] Train loss=0.13516302406787872
[20/24] Train loss=0.12707163393497467
Test set avg_accuracy=88.26% avg_sensitivity=76.92%, avg_specificity=92.55% avg_auc=93.04%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.126150 Test loss=0.299547 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12133919447660446
[5/24] Train loss=0.11540516465902328
[10/24] Train loss=0.13186417520046234
[15/24] Train loss=0.13345977663993835
[20/24] Train loss=0.1275535225868225
Test set avg_accuracy=88.20% avg_sensitivity=74.45%, avg_specificity=93.41% avg_auc=93.01%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.124971 Test loss=0.300284 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12158310413360596
[5/24] Train loss=0.11596910655498505
[10/24] Train loss=0.1323217898607254
[15/24] Train loss=0.13289996981620789
[20/24] Train loss=0.12678852677345276
Test set avg_accuracy=88.10% avg_sensitivity=74.69%, avg_specificity=93.18% avg_auc=92.98%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.125186 Test loss=0.300831 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12200123816728592
[5/24] Train loss=0.11330985277891159
[10/24] Train loss=0.13250389695167542
[15/24] Train loss=0.1348111927509308
[20/24] Train loss=0.12763959169387817
Test set avg_accuracy=88.27% avg_sensitivity=75.45%, avg_specificity=93.12% avg_auc=93.00%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.124413 Test loss=0.300508 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12212295830249786
[5/24] Train loss=0.11212851852178574
[10/24] Train loss=0.1311497837305069
[15/24] Train loss=0.13332398235797882
[20/24] Train loss=0.12601405382156372
Test set avg_accuracy=88.24% avg_sensitivity=75.31%, avg_specificity=93.14% avg_auc=92.93%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.124067 Test loss=0.302486 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11906077712774277
[5/24] Train loss=0.11368070542812347
[10/24] Train loss=0.12918388843536377
[15/24] Train loss=0.1353277564048767
[20/24] Train loss=0.1271284818649292
Test set avg_accuracy=88.07% avg_sensitivity=74.88%, avg_specificity=93.07% avg_auc=92.91%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.123693 Test loss=0.303529 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11956582963466644
[5/24] Train loss=0.1113910973072052
[10/24] Train loss=0.1296004056930542
[15/24] Train loss=0.13360904157161713
[20/24] Train loss=0.12526769936084747
Test set avg_accuracy=87.79% avg_sensitivity=73.46%, avg_specificity=93.21% avg_auc=92.90%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.123124 Test loss=0.303889 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11813949793577194
[5/24] Train loss=0.11215954273939133
[10/24] Train loss=0.13002647459506989
[15/24] Train loss=0.1331833302974701
[20/24] Train loss=0.12474941462278366
Test set avg_accuracy=87.73% avg_sensitivity=73.08%, avg_specificity=93.29% avg_auc=92.87%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.122879 Test loss=0.304073 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12104642391204834
[5/24] Train loss=0.11172959953546524
[10/24] Train loss=0.13120095431804657
[15/24] Train loss=0.1324738711118698
[20/24] Train loss=0.12486067414283752
Test set avg_accuracy=88.31% avg_sensitivity=75.26%, avg_specificity=93.25% avg_auc=92.92%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.123171 Test loss=0.302154 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12007474154233932
[5/24] Train loss=0.11256244033575058
[10/24] Train loss=0.13086409866809845
[15/24] Train loss=0.1337377279996872
[20/24] Train loss=0.12522412836551666
Test set avg_accuracy=87.90% avg_sensitivity=73.89%, avg_specificity=93.21% avg_auc=92.92%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.123241 Test loss=0.302370 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11830396950244904
[5/24] Train loss=0.10944433510303497
[10/24] Train loss=0.13066011667251587
[15/24] Train loss=0.13215617835521698
[20/24] Train loss=0.1251521110534668
Test set avg_accuracy=88.03% avg_sensitivity=74.64%, avg_specificity=93.11% avg_auc=92.93%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.122645 Test loss=0.302241 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11992014944553375
[5/24] Train loss=0.11209945380687714
[10/24] Train loss=0.13007423281669617
[15/24] Train loss=0.13079510629177094
[20/24] Train loss=0.12349927425384521
Test set avg_accuracy=87.97% avg_sensitivity=74.17%, avg_specificity=93.20% avg_auc=92.93%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.122447 Test loss=0.302271 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11854813247919083
[5/24] Train loss=0.11022097617387772
[10/24] Train loss=0.12927694618701935
[15/24] Train loss=0.1303221881389618
[20/24] Train loss=0.1261173039674759
Test set avg_accuracy=87.88% avg_sensitivity=73.60%, avg_specificity=93.29% avg_auc=92.92%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.122372 Test loss=0.302748 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11899357289075851
[5/24] Train loss=0.11151257157325745
[10/24] Train loss=0.13092488050460815
[15/24] Train loss=0.13075418770313263
[20/24] Train loss=0.12559306621551514
Test set avg_accuracy=87.85% avg_sensitivity=73.74%, avg_specificity=93.20% avg_auc=92.92%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.122345 Test loss=0.302761 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11791888624429703
[5/24] Train loss=0.11344122141599655
[10/24] Train loss=0.12780998647212982
[15/24] Train loss=0.13252727687358856
[20/24] Train loss=0.12386094778776169
Test set avg_accuracy=87.84% avg_sensitivity=73.65%, avg_specificity=93.21% avg_auc=92.93%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.122514 Test loss=0.302882 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11811234802007675
[5/24] Train loss=0.11200274527072906
[10/24] Train loss=0.12907950580120087
[15/24] Train loss=0.13141581416130066
[20/24] Train loss=0.12507443130016327
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.81% avg_sensitivity=73.55%, avg_specificity=93.21% avg_auc=92.93%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.122654 Test loss=0.302866 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=88.09% sen=81.42%, spe=90.61%, auc=93.32%!
Fold[3] Avg_overlap=0.68%(0.23164435432716593)
[0/24] Train loss=0.7456067204475403
[5/24] Train loss=0.7445688247680664
[10/24] Train loss=0.740368664264679
[15/24] Train loss=0.731514036655426
[20/24] Train loss=0.7154800891876221
Test set avg_accuracy=63.62% avg_sensitivity=67.22%, avg_specificity=62.35% avg_auc=59.85%
Best model saved!! Metric=-72.96114343366483!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.736767 Test loss=0.686995 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7179952263832092
[5/24] Train loss=0.7195978760719299
[10/24] Train loss=0.7098578214645386
[15/24] Train loss=0.6973995566368103
[20/24] Train loss=0.693757176399231
Test set avg_accuracy=69.32% avg_sensitivity=74.41%, avg_specificity=67.53% avg_auc=70.48%
Best model saved!! Metric=-44.25713553297747!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.707714 Test loss=0.637703 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6840515732765198
[5/24] Train loss=0.6905309557914734
[10/24] Train loss=0.6890993118286133
[15/24] Train loss=0.6710899472236633
[20/24] Train loss=0.6688592433929443
Test set avg_accuracy=71.68% avg_sensitivity=75.66%, avg_specificity=70.28% avg_auc=76.88%
Best model saved!! Metric=-31.50016332119975!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.681029 Test loss=0.597559 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6571416854858398
[5/24] Train loss=0.6679644584655762
[10/24] Train loss=0.6714051961898804
[15/24] Train loss=0.6421619653701782
[20/24] Train loss=0.6338145136833191
Test set avg_accuracy=72.41% avg_sensitivity=78.91%, avg_specificity=70.12% avg_auc=80.55%
Best model saved!! Metric=-24.015319201834856!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.654552 Test loss=0.568947 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6334471106529236
[5/24] Train loss=0.6395522356033325
[10/24] Train loss=0.6418143510818481
[15/24] Train loss=0.6182788610458374
[20/24] Train loss=0.5999916195869446
Test set avg_accuracy=74.43% avg_sensitivity=79.71%, avg_specificity=72.57% avg_auc=82.69%
Best model saved!! Metric=-16.603264672800933!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.625019 Test loss=0.542628 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5955922603607178
[5/24] Train loss=0.6062667965888977
[10/24] Train loss=0.6171473860740662
[15/24] Train loss=0.5909157395362854
[20/24] Train loss=0.572044849395752
Test set avg_accuracy=75.89% avg_sensitivity=82.71%, avg_specificity=73.48% avg_auc=84.49%
Best model saved!! Metric=-9.431279977087542!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.596224 Test loss=0.520495 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5652524828910828
[5/24] Train loss=0.5779093503952026
[10/24] Train loss=0.5949670672416687
[15/24] Train loss=0.5619505643844604
[20/24] Train loss=0.5396302938461304
Test set avg_accuracy=79.05% avg_sensitivity=82.46%, avg_specificity=77.85% avg_auc=85.80%
Best model saved!! Metric=-0.8401546394272827!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.566351 Test loss=0.491205 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5352465510368347
[5/24] Train loss=0.5376425981521606
[10/24] Train loss=0.5563340187072754
[15/24] Train loss=0.5244033932685852
[20/24] Train loss=0.514126181602478
Test set avg_accuracy=80.30% avg_sensitivity=83.41%, avg_specificity=79.20% avg_auc=86.98%
Best model saved!! Metric=3.8961678798906263!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.533874 Test loss=0.469415 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4995870888233185
[5/24] Train loss=0.5059294700622559
[10/24] Train loss=0.5326016545295715
[15/24] Train loss=0.4872702658176422
[20/24] Train loss=0.48163580894470215
Test set avg_accuracy=82.64% avg_sensitivity=80.66%, avg_specificity=83.34% avg_auc=87.97%
Best model saved!! Metric=8.614637369943097!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.502974 Test loss=0.438830 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4663339853286743
[5/24] Train loss=0.467549592256546
[10/24] Train loss=0.49913346767425537
[15/24] Train loss=0.4661140739917755
[20/24] Train loss=0.44654059410095215
Test set avg_accuracy=83.16% avg_sensitivity=80.91%, avg_specificity=83.96% avg_auc=88.90%
Best model saved!! Metric=10.934148754636368!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.471873 Test loss=0.421185 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.44597989320755005
[5/24] Train loss=0.4379713833332062
[10/24] Train loss=0.46267324686050415
[15/24] Train loss=0.4349724352359772
[20/24] Train loss=0.4224209487438202
Test set avg_accuracy=84.58% avg_sensitivity=76.41%, avg_specificity=87.46% avg_auc=89.45%
Best model saved!! Metric=11.912673241650012!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.443565 Test loss=0.396442 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.41358232498168945
[5/24] Train loss=0.40879055857658386
[10/24] Train loss=0.43827706575393677
[15/24] Train loss=0.4124242961406708
[20/24] Train loss=0.3936704695224762
Test set avg_accuracy=85.05% avg_sensitivity=76.86%, avg_specificity=87.94% avg_auc=90.11%
Best model saved!! Metric=13.961774112173515!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.417444 Test loss=0.381462 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3963840901851654
[5/24] Train loss=0.3851270377635956
[10/24] Train loss=0.42198002338409424
[15/24] Train loss=0.39212796092033386
[20/24] Train loss=0.3767373859882355
Test set avg_accuracy=85.95% avg_sensitivity=76.06%, avg_specificity=89.43% avg_auc=90.55%
Best model saved!! Metric=15.99448775636941!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.394933 Test loss=0.364205 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37284794449806213
[5/24] Train loss=0.35579943656921387
[10/24] Train loss=0.39750316739082336
[15/24] Train loss=0.37138259410858154
[20/24] Train loss=0.3541823923587799
Test set avg_accuracy=86.93% avg_sensitivity=74.51%, avg_specificity=91.30% avg_auc=90.72%
Best model saved!! Metric=17.459567223453774!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.373542 Test loss=0.349939 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3537112772464752
[5/24] Train loss=0.3356144428253174
[10/24] Train loss=0.3835006058216095
[15/24] Train loss=0.3537786602973938
[20/24] Train loss=0.33958786725997925
Test set avg_accuracy=87.33% avg_sensitivity=75.76%, avg_specificity=91.41% avg_auc=91.18%
Best model saved!! Metric=19.684656622730856!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.356818 Test loss=0.340078 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.33631062507629395
[5/24] Train loss=0.31854352355003357
[10/24] Train loss=0.36801812052726746
[15/24] Train loss=0.33912500739097595
[20/24] Train loss=0.32371222972869873
Test set avg_accuracy=87.64% avg_sensitivity=73.86%, avg_specificity=92.50% avg_auc=91.49%
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.340859 Test loss=0.329284 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3248831629753113
[5/24] Train loss=0.31153327226638794
[10/24] Train loss=0.35231709480285645
[15/24] Train loss=0.3306317627429962
[20/24] Train loss=0.31265199184417725
Test set avg_accuracy=87.42% avg_sensitivity=75.36%, avg_specificity=91.67% avg_auc=91.76%
Best model saved!! Metric=20.217024000600972!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.328760 Test loss=0.322865 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.30809155106544495
[5/24] Train loss=0.2968870997428894
[10/24] Train loss=0.34943753480911255
[15/24] Train loss=0.32607659697532654
[20/24] Train loss=0.2986893355846405
Test set avg_accuracy=87.90% avg_sensitivity=75.36%, avg_specificity=92.32% avg_auc=92.25%
Best model saved!! Metric=21.84071814943799!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.317570 Test loss=0.314323 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3011578321456909
[5/24] Train loss=0.28968119621276855
[10/24] Train loss=0.3294440805912018
[15/24] Train loss=0.31609007716178894
[20/24] Train loss=0.2981409728527069
Test set avg_accuracy=88.24% avg_sensitivity=76.11%, avg_specificity=92.52% avg_auc=92.14%
Best model saved!! Metric=23.011490293575918!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.308153 Test loss=0.311221 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.2865322232246399
[5/24] Train loss=0.28229039907455444
[10/24] Train loss=0.3208087682723999
[15/24] Train loss=0.3035733699798584
[20/24] Train loss=0.2864799201488495
Test set avg_accuracy=88.20% avg_sensitivity=75.01%, avg_specificity=92.85% avg_auc=92.38%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.297170 Test loss=0.304220 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2858853042125702
[5/24] Train loss=0.2680623531341553
[10/24] Train loss=0.3241562843322754
[15/24] Train loss=0.29140886664390564
[20/24] Train loss=0.2731528878211975
Test set avg_accuracy=86.78% avg_sensitivity=80.21%, avg_specificity=89.10% avg_auc=92.72%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.290958 Test loss=0.319246 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.27274438738822937
[5/24] Train loss=0.26489853858947754
[10/24] Train loss=0.3025752007961273
[15/24] Train loss=0.28905990719795227
[20/24] Train loss=0.2668551206588745
Test set avg_accuracy=88.15% avg_sensitivity=79.26%, avg_specificity=91.28% avg_auc=92.99%
Best model saved!! Metric=25.682473696733695!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.282984 Test loss=0.303538 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2703905701637268
[5/24] Train loss=0.2563794255256653
[10/24] Train loss=0.3024757206439972
[15/24] Train loss=0.282634973526001
[20/24] Train loss=0.26206904649734497
Test set avg_accuracy=88.40% avg_sensitivity=79.26%, avg_specificity=91.62% avg_auc=93.16%
Best model saved!! Metric=26.436087630736722!!
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.276219 Test loss=0.298171 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.263857364654541
[5/24] Train loss=0.2451528012752533
[10/24] Train loss=0.29082611203193665
[15/24] Train loss=0.2809511721134186
[20/24] Train loss=0.2556105852127075
Test set avg_accuracy=88.74% avg_sensitivity=71.36%, avg_specificity=94.86% avg_auc=92.97%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.269707 Test loss=0.290336 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26073727011680603
[5/24] Train loss=0.2390613704919815
[10/24] Train loss=0.28465887904167175
[15/24] Train loss=0.26561349630355835
[20/24] Train loss=0.25059399008750916
Test set avg_accuracy=88.92% avg_sensitivity=77.56%, avg_specificity=92.92% avg_auc=93.16%
Best model saved!! Metric=26.56603523067328!!
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.263050 Test loss=0.291091 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.25856631994247437
[5/24] Train loss=0.22999760508537292
[10/24] Train loss=0.28036001324653625
[15/24] Train loss=0.2649213373661041
[20/24] Train loss=0.2474217563867569
Test set avg_accuracy=88.46% avg_sensitivity=76.41%, avg_specificity=92.71% avg_auc=93.18%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.258778 Test loss=0.288594 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2497813105583191
[5/24] Train loss=0.21972113847732544
[10/24] Train loss=0.2810358703136444
[15/24] Train loss=0.26256802678108215
[20/24] Train loss=0.241276815533638
Test set avg_accuracy=88.46% avg_sensitivity=67.62%, avg_specificity=95.81% avg_auc=92.95%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.253917 Test loss=0.289561 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.24396665394306183
[5/24] Train loss=0.2304706573486328
[10/24] Train loss=0.27692466974258423
[15/24] Train loss=0.2551484704017639
[20/24] Train loss=0.24132519960403442
Test set avg_accuracy=88.01% avg_sensitivity=76.36%, avg_specificity=92.11% avg_auc=93.41%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.249557 Test loss=0.288078 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23928667604923248
[5/24] Train loss=0.21604712307453156
[10/24] Train loss=0.2732866108417511
[15/24] Train loss=0.24663850665092468
[20/24] Train loss=0.23374144732952118
Test set avg_accuracy=88.10% avg_sensitivity=70.21%, avg_specificity=94.40% avg_auc=92.44%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.244611 Test loss=0.297392 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2329677790403366
[5/24] Train loss=0.21187733113765717
[10/24] Train loss=0.2703448534011841
[15/24] Train loss=0.24142469465732574
[20/24] Train loss=0.24361670017242432
Test set avg_accuracy=88.75% avg_sensitivity=68.67%, avg_specificity=95.83% avg_auc=92.73%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.240487 Test loss=0.296623 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.23733501136302948
[5/24] Train loss=0.20542150735855103
[10/24] Train loss=0.26348185539245605
[15/24] Train loss=0.2534749209880829
[20/24] Train loss=0.22257739305496216
Test set avg_accuracy=87.16% avg_sensitivity=80.76%, avg_specificity=89.42% avg_auc=93.33%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.238623 Test loss=0.301954 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.22927315533161163
[5/24] Train loss=0.22205834090709686
[10/24] Train loss=0.2689456343650818
[15/24] Train loss=0.24384267628192902
[20/24] Train loss=0.2281324565410614
Test set avg_accuracy=88.82% avg_sensitivity=71.41%, avg_specificity=94.95% avg_auc=93.02%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.237023 Test loss=0.285645 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22468149662017822
[5/24] Train loss=0.19746264815330505
[10/24] Train loss=0.2562757730484009
[15/24] Train loss=0.24023060500621796
[20/24] Train loss=0.22328230738639832
Test set avg_accuracy=88.98% avg_sensitivity=75.56%, avg_specificity=93.71% avg_auc=92.92%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.230166 Test loss=0.296561 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.22637076675891876
[5/24] Train loss=0.19066916406154633
[10/24] Train loss=0.2548179030418396
[15/24] Train loss=0.2358015775680542
[20/24] Train loss=0.2223251461982727
Test set avg_accuracy=88.12% avg_sensitivity=67.72%, avg_specificity=95.32% avg_auc=92.54%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.228731 Test loss=0.295631 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.21763579547405243
[5/24] Train loss=0.18414950370788574
[10/24] Train loss=0.24945206940174103
[15/24] Train loss=0.22900378704071045
[20/24] Train loss=0.2122139185667038
Test set avg_accuracy=88.84% avg_sensitivity=72.11%, avg_specificity=94.73% avg_auc=92.69%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.222104 Test loss=0.296507 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21686092019081116
[5/24] Train loss=0.1785239726305008
[10/24] Train loss=0.2423456311225891
[15/24] Train loss=0.2347790151834488
[20/24] Train loss=0.20990794897079468
Test set avg_accuracy=87.71% avg_sensitivity=62.67%, avg_specificity=96.53% avg_auc=91.56%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.219331 Test loss=0.317488 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2164967954158783
[5/24] Train loss=0.20295368134975433
[10/24] Train loss=0.25320157408714294
[15/24] Train loss=0.2367420643568039
[20/24] Train loss=0.22620977461338043
Test set avg_accuracy=88.40% avg_sensitivity=83.26%, avg_specificity=90.21% avg_auc=92.82%
Best model saved!! Metric=28.688166380937247!!
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.224784 Test loss=0.310574 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.20523923635482788
[5/24] Train loss=0.1920791119337082
[10/24] Train loss=0.24426478147506714
[15/24] Train loss=0.23315691947937012
[20/24] Train loss=0.21841633319854736
Test set avg_accuracy=88.10% avg_sensitivity=77.16%, avg_specificity=91.95% avg_auc=91.30%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.221379 Test loss=0.328713 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21914589405059814
[5/24] Train loss=0.18157535791397095
[10/24] Train loss=0.2581401765346527
[15/24] Train loss=0.23342028260231018
[20/24] Train loss=0.22510363161563873
Test set avg_accuracy=87.89% avg_sensitivity=67.62%, avg_specificity=95.03% avg_auc=87.94%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.219316 Test loss=0.371862 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22126202285289764
[5/24] Train loss=0.18714460730552673
[10/24] Train loss=0.24407251179218292
[15/24] Train loss=0.22684940695762634
[20/24] Train loss=0.20910166203975677
Test set avg_accuracy=87.10% avg_sensitivity=61.82%, avg_specificity=96.00% avg_auc=89.52%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.218259 Test loss=0.349125 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21535035967826843
[5/24] Train loss=0.19098623096942902
[10/24] Train loss=0.24356599152088165
[15/24] Train loss=0.21992839872837067
[20/24] Train loss=0.20716455578804016
Test set avg_accuracy=87.92% avg_sensitivity=69.37%, avg_specificity=94.45% avg_auc=92.21%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.214731 Test loss=0.300677 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.19673150777816772
[5/24] Train loss=0.1904871016740799
[10/24] Train loss=0.23312993347644806
[15/24] Train loss=0.2208467274904251
[20/24] Train loss=0.21343089640140533
Test set avg_accuracy=88.46% avg_sensitivity=73.21%, avg_specificity=93.84% avg_auc=92.32%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.211094 Test loss=0.296167 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21931670606136322
[5/24] Train loss=0.17525579035282135
[10/24] Train loss=0.24914751946926117
[15/24] Train loss=0.22576262056827545
[20/24] Train loss=0.20703667402267456
Test set avg_accuracy=88.75% avg_sensitivity=78.21%, avg_specificity=92.46% avg_auc=93.30%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.215689 Test loss=0.289499 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.19541534781455994
[5/24] Train loss=0.18466253578662872
[10/24] Train loss=0.24521246552467346
[15/24] Train loss=0.2195156216621399
[20/24] Train loss=0.21106591820716858
Test set avg_accuracy=87.84% avg_sensitivity=73.56%, avg_specificity=92.87% avg_auc=92.54%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.209837 Test loss=0.296465 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20037953555583954
[5/24] Train loss=0.17085473239421844
[10/24] Train loss=0.23655478656291962
[15/24] Train loss=0.21452596783638
[20/24] Train loss=0.20631906390190125
Test set avg_accuracy=89.21% avg_sensitivity=78.41%, avg_specificity=93.01% avg_auc=93.38%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.207884 Test loss=0.287241 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.19899259507656097
[5/24] Train loss=0.16787679493427277
[10/24] Train loss=0.2500119209289551
[15/24] Train loss=0.2258516401052475
[20/24] Train loss=0.20022867619991302
Test set avg_accuracy=86.28% avg_sensitivity=85.41%, avg_specificity=86.58% avg_auc=91.23%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.207077 Test loss=0.358211 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.19503435492515564
[5/24] Train loss=0.1797691136598587
[10/24] Train loss=0.23201334476470947
[15/24] Train loss=0.21585418283939362
[20/24] Train loss=0.1990991085767746
Test set avg_accuracy=87.45% avg_sensitivity=61.12%, avg_specificity=96.72% avg_auc=91.82%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.206676 Test loss=0.316772 Current lr=[0.000299720220882401]

[0/24] Train loss=0.21102510392665863
[5/24] Train loss=0.1755618155002594
[10/24] Train loss=0.23678673803806305
[15/24] Train loss=0.21913281083106995
[20/24] Train loss=0.2081025093793869
Test set avg_accuracy=82.12% avg_sensitivity=88.46%, avg_specificity=79.89% avg_auc=90.88%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.208113 Test loss=0.407329 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20931854844093323
[5/24] Train loss=0.1674329787492752
[10/24] Train loss=0.27129313349723816
[15/24] Train loss=0.20804433524608612
[20/24] Train loss=0.20550334453582764
Test set avg_accuracy=88.06% avg_sensitivity=79.76%, avg_specificity=90.98% avg_auc=91.85%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.204631 Test loss=0.319472 Current lr=[0.000298904600941902]

[0/24] Train loss=0.18967397511005402
[5/24] Train loss=0.16475994884967804
[10/24] Train loss=0.2279462367296219
[15/24] Train loss=0.21500833332538605
[20/24] Train loss=0.21264775097370148
Test set avg_accuracy=83.48% avg_sensitivity=87.51%, avg_specificity=82.06% avg_auc=92.07%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.200171 Test loss=0.365867 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19381530582904816
[5/24] Train loss=0.16530025005340576
[10/24] Train loss=0.22238682210445404
[15/24] Train loss=0.21253380179405212
[20/24] Train loss=0.19437432289123535
Test set avg_accuracy=86.61% avg_sensitivity=59.77%, avg_specificity=96.07% avg_auc=90.92%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.200601 Test loss=0.336519 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19767020642757416
[5/24] Train loss=0.16406753659248352
[10/24] Train loss=0.22008219361305237
[15/24] Train loss=0.22986581921577454
[20/24] Train loss=0.19753971695899963
Test set avg_accuracy=87.93% avg_sensitivity=82.46%, avg_specificity=89.86% avg_auc=92.53%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.198614 Test loss=0.312810 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.19338180124759674
[5/24] Train loss=0.17796793580055237
[10/24] Train loss=0.22191941738128662
[15/24] Train loss=0.2181636244058609
[20/24] Train loss=0.19461725652217865
Test set avg_accuracy=84.87% avg_sensitivity=51.62%, avg_specificity=96.58% avg_auc=88.84%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.197888 Test loss=0.369491 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19900983572006226
[5/24] Train loss=0.16513916850090027
[10/24] Train loss=0.1988116353750229
[15/24] Train loss=0.2157832533121109
[20/24] Train loss=0.19547073543071747
Test set avg_accuracy=86.72% avg_sensitivity=58.82%, avg_specificity=96.55% avg_auc=89.87%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.192345 Test loss=0.345275 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18631188571453094
[5/24] Train loss=0.16537421941757202
[10/24] Train loss=0.20965851843357086
[15/24] Train loss=0.19927509129047394
[20/24] Train loss=0.18933407962322235
Test set avg_accuracy=88.78% avg_sensitivity=71.56%, avg_specificity=94.84% avg_auc=93.04%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.191326 Test loss=0.288769 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18904536962509155
[5/24] Train loss=0.15969547629356384
[10/24] Train loss=0.20606523752212524
[15/24] Train loss=0.20956449210643768
[20/24] Train loss=0.18506759405136108
Test set avg_accuracy=87.84% avg_sensitivity=66.32%, avg_specificity=95.42% avg_auc=91.67%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.186938 Test loss=0.307224 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18865831196308136
[5/24] Train loss=0.16342288255691528
[10/24] Train loss=0.2103520631790161
[15/24] Train loss=0.21614965796470642
[20/24] Train loss=0.17731957137584686
Test set avg_accuracy=88.82% avg_sensitivity=76.11%, avg_specificity=93.29% avg_auc=92.71%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.188866 Test loss=0.295438 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.1811431646347046
[5/24] Train loss=0.15835918486118317
[10/24] Train loss=0.19659747183322906
[15/24] Train loss=0.20623116195201874
[20/24] Train loss=0.18183329701423645
Test set avg_accuracy=88.58% avg_sensitivity=70.26%, avg_specificity=95.03% avg_auc=91.11%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.184463 Test loss=0.314243 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18798933923244476
[5/24] Train loss=0.15565592050552368
[10/24] Train loss=0.20535403490066528
[15/24] Train loss=0.22402237355709076
[20/24] Train loss=0.18326081335544586
Test set avg_accuracy=88.67% avg_sensitivity=73.76%, avg_specificity=93.92% avg_auc=91.95%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.187898 Test loss=0.305767 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19121921062469482
[5/24] Train loss=0.15494629740715027
[10/24] Train loss=0.20145241916179657
[15/24] Train loss=0.19871391355991364
[20/24] Train loss=0.1738966703414917
Test set avg_accuracy=86.73% avg_sensitivity=56.37%, avg_specificity=97.43% avg_auc=88.59%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.185200 Test loss=0.349832 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18739525973796844
[5/24] Train loss=0.17053204774856567
[10/24] Train loss=0.21346840262413025
[15/24] Train loss=0.19669106602668762
[20/24] Train loss=0.1884448528289795
Test set avg_accuracy=86.25% avg_sensitivity=55.17%, avg_specificity=97.20% avg_auc=89.74%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.189865 Test loss=0.354464 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18496447801589966
[5/24] Train loss=0.1562294065952301
[10/24] Train loss=0.1995374709367752
[15/24] Train loss=0.2021823525428772
[20/24] Train loss=0.19165149331092834
Test set avg_accuracy=88.11% avg_sensitivity=71.46%, avg_specificity=93.98% avg_auc=91.62%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.187967 Test loss=0.309436 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18243199586868286
[5/24] Train loss=0.16904594004154205
[10/24] Train loss=0.2067909985780716
[15/24] Train loss=0.20054301619529724
[20/24] Train loss=0.18084771931171417
Test set avg_accuracy=87.51% avg_sensitivity=63.07%, avg_specificity=96.13% avg_auc=90.34%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.186098 Test loss=0.321788 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17842867970466614
[5/24] Train loss=0.15606720745563507
[10/24] Train loss=0.2249676138162613
[15/24] Train loss=0.21626487374305725
[20/24] Train loss=0.17816676199436188
Test set avg_accuracy=88.39% avg_sensitivity=68.47%, avg_specificity=95.40% avg_auc=92.59%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.189704 Test loss=0.295817 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17899352312088013
[5/24] Train loss=0.15508906543254852
[10/24] Train loss=0.1868477463722229
[15/24] Train loss=0.19661125540733337
[20/24] Train loss=0.1813458949327469
Test set avg_accuracy=88.93% avg_sensitivity=70.26%, avg_specificity=95.51% avg_auc=91.65%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.180372 Test loss=0.309076 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1699002981185913
[5/24] Train loss=0.15773382782936096
[10/24] Train loss=0.19749417901039124
[15/24] Train loss=0.20266956090927124
[20/24] Train loss=0.18340754508972168
Test set avg_accuracy=85.74% avg_sensitivity=56.52%, avg_specificity=96.04% avg_auc=89.72%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.185384 Test loss=0.356012 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.18232549726963043
[5/24] Train loss=0.16787287592887878
[10/24] Train loss=0.1971738338470459
[15/24] Train loss=0.19304879009723663
[20/24] Train loss=0.1741228997707367
Test set avg_accuracy=86.60% avg_sensitivity=58.62%, avg_specificity=96.46% avg_auc=88.58%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.180960 Test loss=0.359661 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17409153282642365
[5/24] Train loss=0.14822706580162048
[10/24] Train loss=0.19783733785152435
[15/24] Train loss=0.1897515058517456
[20/24] Train loss=0.17132070660591125
Test set avg_accuracy=88.98% avg_sensitivity=78.16%, avg_specificity=92.80% avg_auc=93.08%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.178052 Test loss=0.288951 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.17646802961826324
[5/24] Train loss=0.1481369137763977
[10/24] Train loss=0.1907835155725479
[15/24] Train loss=0.1934460997581482
[20/24] Train loss=0.17892834544181824
Test set avg_accuracy=88.65% avg_sensitivity=71.36%, avg_specificity=94.73% avg_auc=92.11%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.178087 Test loss=0.301505 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17140646278858185
[5/24] Train loss=0.15341044962406158
[10/24] Train loss=0.1966603696346283
[15/24] Train loss=0.18049202859401703
[20/24] Train loss=0.17164476215839386
Test set avg_accuracy=87.88% avg_sensitivity=69.37%, avg_specificity=94.40% avg_auc=90.79%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.178122 Test loss=0.320554 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1770295649766922
[5/24] Train loss=0.14923639595508575
[10/24] Train loss=0.19630013406276703
[15/24] Train loss=0.19648228585720062
[20/24] Train loss=0.1720072627067566
Test set avg_accuracy=84.02% avg_sensitivity=82.16%, avg_specificity=84.68% avg_auc=90.85%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.179291 Test loss=0.366788 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17231342196464539
[5/24] Train loss=0.16064180433750153
[10/24] Train loss=0.18775077164173126
[15/24] Train loss=0.17915776371955872
[20/24] Train loss=0.17163637280464172
Test set avg_accuracy=87.47% avg_sensitivity=64.82%, avg_specificity=95.46% avg_auc=90.67%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.176097 Test loss=0.321831 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1669081598520279
[5/24] Train loss=0.153285950422287
[10/24] Train loss=0.1932506561279297
[15/24] Train loss=0.19547665119171143
[20/24] Train loss=0.18413203954696655
Test set avg_accuracy=81.77% avg_sensitivity=35.88%, avg_specificity=97.94% avg_auc=84.20%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.178106 Test loss=0.448075 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17889556288719177
[5/24] Train loss=0.1515013426542282
[10/24] Train loss=0.19204768538475037
[15/24] Train loss=0.18255965411663055
[20/24] Train loss=0.17755462229251862
Test set avg_accuracy=87.06% avg_sensitivity=64.47%, avg_specificity=95.02% avg_auc=90.73%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.174944 Test loss=0.325789 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16933073103427887
[5/24] Train loss=0.15621834993362427
[10/24] Train loss=0.1809096485376358
[15/24] Train loss=0.17903439700603485
[20/24] Train loss=0.17001642286777496
Test set avg_accuracy=88.19% avg_sensitivity=71.76%, avg_specificity=93.98% avg_auc=92.32%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.174544 Test loss=0.306134 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1747972071170807
[5/24] Train loss=0.14782461524009705
[10/24] Train loss=0.18880592286586761
[15/24] Train loss=0.1751329004764557
[20/24] Train loss=0.1766090989112854
Test set avg_accuracy=88.53% avg_sensitivity=72.91%, avg_specificity=94.03% avg_auc=91.82%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.174558 Test loss=0.307033 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.16546571254730225
[5/24] Train loss=0.15125857293605804
[10/24] Train loss=0.17959319055080414
[15/24] Train loss=0.18055325746536255
[20/24] Train loss=0.17547525465488434
Test set avg_accuracy=87.97% avg_sensitivity=64.17%, avg_specificity=96.35% avg_auc=91.55%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.171841 Test loss=0.314357 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16294313967227936
[5/24] Train loss=0.14508101344108582
[10/24] Train loss=0.18003204464912415
[15/24] Train loss=0.17826685309410095
[20/24] Train loss=0.17613252997398376
Test set avg_accuracy=85.79% avg_sensitivity=79.11%, avg_specificity=88.15% avg_auc=91.61%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.169132 Test loss=0.346063 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.17103302478790283
[5/24] Train loss=0.14173708856105804
[10/24] Train loss=0.17777740955352783
[15/24] Train loss=0.18078424036502838
[20/24] Train loss=0.16680188477039337
Test set avg_accuracy=85.51% avg_sensitivity=51.37%, avg_specificity=97.53% avg_auc=87.58%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.166819 Test loss=0.388121 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.16771408915519714
[5/24] Train loss=0.1417345255613327
[10/24] Train loss=0.18157678842544556
[15/24] Train loss=0.18146152794361115
[20/24] Train loss=0.16879260540008545
Test set avg_accuracy=86.64% avg_sensitivity=57.57%, avg_specificity=96.88% avg_auc=89.49%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.168723 Test loss=0.354620 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1618546098470688
[5/24] Train loss=0.13958798348903656
[10/24] Train loss=0.17913350462913513
[15/24] Train loss=0.1826189160346985
[20/24] Train loss=0.16553321480751038
Test set avg_accuracy=88.59% avg_sensitivity=75.51%, avg_specificity=93.20% avg_auc=92.22%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.169761 Test loss=0.305127 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.16849763691425323
[5/24] Train loss=0.15248817205429077
[10/24] Train loss=0.17210382223129272
[15/24] Train loss=0.18425457179546356
[20/24] Train loss=0.1624770313501358
Test set avg_accuracy=89.05% avg_sensitivity=76.91%, avg_specificity=93.33% avg_auc=92.76%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.168427 Test loss=0.299357 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.16111625730991364
[5/24] Train loss=0.14927838742733002
[10/24] Train loss=0.18916663527488708
[15/24] Train loss=0.18000085651874542
[20/24] Train loss=0.16798287630081177
Test set avg_accuracy=87.15% avg_sensitivity=78.01%, avg_specificity=90.37% avg_auc=90.72%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.170166 Test loss=0.362412 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18091310560703278
[5/24] Train loss=0.14366334676742554
[10/24] Train loss=0.19646890461444855
[15/24] Train loss=0.18186287581920624
[20/24] Train loss=0.16259321570396423
Test set avg_accuracy=89.24% avg_sensitivity=77.21%, avg_specificity=93.48% avg_auc=92.18%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.173049 Test loss=0.304194 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16910943388938904
[5/24] Train loss=0.1485699862241745
[10/24] Train loss=0.1745467483997345
[15/24] Train loss=0.17099973559379578
[20/24] Train loss=0.16051414608955383
Test set avg_accuracy=87.42% avg_sensitivity=79.71%, avg_specificity=90.14% avg_auc=92.04%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.165243 Test loss=0.325601 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1752043515443802
[5/24] Train loss=0.13516756892204285
[10/24] Train loss=0.17089635133743286
[15/24] Train loss=0.17253288626670837
[20/24] Train loss=0.16137349605560303
Test set avg_accuracy=88.97% avg_sensitivity=79.81%, avg_specificity=92.20% avg_auc=92.16%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.165748 Test loss=0.312932 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1650882214307785
[5/24] Train loss=0.14390745759010315
[10/24] Train loss=0.17143554985523224
[15/24] Train loss=0.16856884956359863
[20/24] Train loss=0.18317675590515137
Test set avg_accuracy=81.97% avg_sensitivity=86.51%, avg_specificity=80.37% avg_auc=90.98%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.169104 Test loss=0.401532 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16278879344463348
[5/24] Train loss=0.1487094610929489
[10/24] Train loss=0.18161974847316742
[15/24] Train loss=0.16822297871112823
[20/24] Train loss=0.16325904428958893
Test set avg_accuracy=88.92% avg_sensitivity=75.96%, avg_specificity=93.48% avg_auc=92.33%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.167883 Test loss=0.305383 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1637362539768219
[5/24] Train loss=0.14549167454242706
[10/24] Train loss=0.16847480833530426
[15/24] Train loss=0.17455370724201202
[20/24] Train loss=0.1654863953590393
Test set avg_accuracy=88.03% avg_sensitivity=62.37%, avg_specificity=97.08% avg_auc=90.42%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.163932 Test loss=0.327706 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.15772506594657898
[5/24] Train loss=0.15129773318767548
[10/24] Train loss=0.18372772634029388
[15/24] Train loss=0.16844893991947174
[20/24] Train loss=0.15902112424373627
Test set avg_accuracy=89.11% avg_sensitivity=71.26%, avg_specificity=95.40% avg_auc=91.45%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.162910 Test loss=0.312271 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1541328877210617
[5/24] Train loss=0.14281578361988068
[10/24] Train loss=0.16627207398414612
[15/24] Train loss=0.16357550024986267
[20/24] Train loss=0.15852929651737213
Test set avg_accuracy=88.66% avg_sensitivity=71.71%, avg_specificity=94.63% avg_auc=92.07%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.160030 Test loss=0.308232 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.15792526304721832
[5/24] Train loss=0.1397925466299057
[10/24] Train loss=0.16701266169548035
[15/24] Train loss=0.16650408506393433
[20/24] Train loss=0.15758247673511505
Test set avg_accuracy=88.40% avg_sensitivity=72.06%, avg_specificity=94.15% avg_auc=92.22%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.159014 Test loss=0.308880 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1564600020647049
[5/24] Train loss=0.14470313489437103
[10/24] Train loss=0.1667109876871109
[15/24] Train loss=0.15926888585090637
[20/24] Train loss=0.15278400480747223
Test set avg_accuracy=88.20% avg_sensitivity=69.57%, avg_specificity=94.77% avg_auc=92.00%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.158612 Test loss=0.312665 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16123493015766144
[5/24] Train loss=0.1409853994846344
[10/24] Train loss=0.16548243165016174
[15/24] Train loss=0.16812805831432343
[20/24] Train loss=0.1610075831413269
Test set avg_accuracy=88.82% avg_sensitivity=77.26%, avg_specificity=92.89% avg_auc=91.73%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.157595 Test loss=0.312129 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.15612895786762238
[5/24] Train loss=0.13558082282543182
[10/24] Train loss=0.1636236011981964
[15/24] Train loss=0.16533806920051575
[20/24] Train loss=0.1518370658159256
Test set avg_accuracy=88.59% avg_sensitivity=71.01%, avg_specificity=94.79% avg_auc=91.63%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.155378 Test loss=0.307937 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1513528972864151
[5/24] Train loss=0.14553797245025635
[10/24] Train loss=0.1595872938632965
[15/24] Train loss=0.16622206568717957
[20/24] Train loss=0.1500445157289505
Test set avg_accuracy=88.31% avg_sensitivity=69.57%, avg_specificity=94.91% avg_auc=91.05%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.155568 Test loss=0.316772 Current lr=[0.000156543481933168]

[0/24] Train loss=0.14744846522808075
[5/24] Train loss=0.13669824600219727
[10/24] Train loss=0.16481655836105347
[15/24] Train loss=0.1673281490802765
[20/24] Train loss=0.1551576852798462
Test set avg_accuracy=86.60% avg_sensitivity=59.27%, avg_specificity=96.23% avg_auc=89.91%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.157835 Test loss=0.341879 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1542673259973526
[5/24] Train loss=0.13210801780223846
[10/24] Train loss=0.17010009288787842
[15/24] Train loss=0.17149032652378082
[20/24] Train loss=0.15969684720039368
Test set avg_accuracy=84.11% avg_sensitivity=46.78%, avg_specificity=97.27% avg_auc=86.76%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.158972 Test loss=0.422489 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15662987530231476
[5/24] Train loss=0.13731053471565247
[10/24] Train loss=0.16760489344596863
[15/24] Train loss=0.16685324907302856
[20/24] Train loss=0.16206605732440948
Test set avg_accuracy=87.42% avg_sensitivity=68.62%, avg_specificity=94.05% avg_auc=90.62%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.158005 Test loss=0.337881 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.16049392521381378
[5/24] Train loss=0.13654576241970062
[10/24] Train loss=0.17202892899513245
[15/24] Train loss=0.16024701297283173
[20/24] Train loss=0.15316076576709747
Test set avg_accuracy=86.77% avg_sensitivity=64.22%, avg_specificity=94.72% avg_auc=88.80%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.156552 Test loss=0.366003 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15647034347057343
[5/24] Train loss=0.13735882937908173
[10/24] Train loss=0.1611495465040207
[15/24] Train loss=0.16278858482837677
[20/24] Train loss=0.15236833691596985
Test set avg_accuracy=86.95% avg_sensitivity=63.57%, avg_specificity=95.19% avg_auc=90.31%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.153972 Test loss=0.336245 Current lr=[0.000134135431043539]

[0/24] Train loss=0.1508340984582901
[5/24] Train loss=0.12986095249652863
[10/24] Train loss=0.16440162062644958
[15/24] Train loss=0.1567474901676178
[20/24] Train loss=0.1523612141609192
Test set avg_accuracy=87.36% avg_sensitivity=69.77%, avg_specificity=93.56% avg_auc=90.52%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.152053 Test loss=0.341058 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15579935908317566
[5/24] Train loss=0.13569873571395874
[10/24] Train loss=0.15541157126426697
[15/24] Train loss=0.16291876137256622
[20/24] Train loss=0.1485760658979416
Test set avg_accuracy=87.16% avg_sensitivity=60.97%, avg_specificity=96.39% avg_auc=90.20%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.153374 Test loss=0.338341 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1549171507358551
[5/24] Train loss=0.13227194547653198
[10/24] Train loss=0.16003569960594177
[15/24] Train loss=0.16248373687267303
[20/24] Train loss=0.1482723355293274
Test set avg_accuracy=87.89% avg_sensitivity=67.57%, avg_specificity=95.05% avg_auc=91.47%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.153526 Test loss=0.314142 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14822342991828918
[5/24] Train loss=0.13058257102966309
[10/24] Train loss=0.1539328545331955
[15/24] Train loss=0.16041581332683563
[20/24] Train loss=0.15006478130817413
Test set avg_accuracy=86.84% avg_sensitivity=60.32%, avg_specificity=96.18% avg_auc=89.13%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.150522 Test loss=0.353360 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14694242179393768
[5/24] Train loss=0.12840107083320618
[10/24] Train loss=0.159115731716156
[15/24] Train loss=0.1591489166021347
[20/24] Train loss=0.15135130286216736
Test set avg_accuracy=86.35% avg_sensitivity=58.27%, avg_specificity=96.25% avg_auc=88.80%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.151283 Test loss=0.362601 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1469075083732605
[5/24] Train loss=0.1407216638326645
[10/24] Train loss=0.15729787945747375
[15/24] Train loss=0.15410062670707703
[20/24] Train loss=0.14734256267547607
Test set avg_accuracy=87.93% avg_sensitivity=67.22%, avg_specificity=95.23% avg_auc=91.08%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.152351 Test loss=0.319839 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1443125158548355
[5/24] Train loss=0.1273682415485382
[10/24] Train loss=0.15539796650409698
[15/24] Train loss=0.15565454959869385
[20/24] Train loss=0.1491064876317978
Test set avg_accuracy=88.12% avg_sensitivity=79.66%, avg_specificity=91.11% avg_auc=92.17%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.148635 Test loss=0.322429 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14817796647548676
[5/24] Train loss=0.13089925050735474
[10/24] Train loss=0.1554211527109146
[15/24] Train loss=0.14880162477493286
[20/24] Train loss=0.14451375603675842
Test set avg_accuracy=88.88% avg_sensitivity=74.86%, avg_specificity=93.82% avg_auc=92.37%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.146255 Test loss=0.302349 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14284460246562958
[5/24] Train loss=0.1245248094201088
[10/24] Train loss=0.1545749306678772
[15/24] Train loss=0.14717306196689606
[20/24] Train loss=0.1474856734275818
Test set avg_accuracy=88.44% avg_sensitivity=79.91%, avg_specificity=91.44% avg_auc=92.43%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.144011 Test loss=0.311723 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14062415063381195
[5/24] Train loss=0.1240701749920845
[10/24] Train loss=0.14991341531276703
[15/24] Train loss=0.1454818844795227
[20/24] Train loss=0.14173518121242523
Test set avg_accuracy=88.83% avg_sensitivity=75.36%, avg_specificity=93.57% avg_auc=92.17%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.142255 Test loss=0.308374 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1408025473356247
[5/24] Train loss=0.12488692998886108
[10/24] Train loss=0.1475592851638794
[15/24] Train loss=0.14619237184524536
[20/24] Train loss=0.137751504778862
Test set avg_accuracy=87.12% avg_sensitivity=81.51%, avg_specificity=89.10% avg_auc=91.89%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.141455 Test loss=0.340958 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13853271305561066
[5/24] Train loss=0.12422989308834076
[10/24] Train loss=0.14821183681488037
[15/24] Train loss=0.14789149165153503
[20/24] Train loss=0.13559426367282867
Test set avg_accuracy=88.80% avg_sensitivity=76.31%, avg_specificity=93.20% avg_auc=92.37%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.139365 Test loss=0.313143 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.13653260469436646
[5/24] Train loss=0.12089723348617554
[10/24] Train loss=0.1479821652173996
[15/24] Train loss=0.14368446171283722
[20/24] Train loss=0.13940401375293732
Test set avg_accuracy=88.83% avg_sensitivity=75.31%, avg_specificity=93.59% avg_auc=91.73%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.137764 Test loss=0.311627 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1329796463251114
[5/24] Train loss=0.12018038332462311
[10/24] Train loss=0.13979092240333557
[15/24] Train loss=0.14075250923633575
[20/24] Train loss=0.13747456669807434
Test set avg_accuracy=89.32% avg_sensitivity=77.56%, avg_specificity=93.47% avg_auc=92.42%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.135837 Test loss=0.301080 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.13554613292217255
[5/24] Train loss=0.1173541471362114
[10/24] Train loss=0.1376248449087143
[15/24] Train loss=0.1375560164451599
[20/24] Train loss=0.13900570571422577
Test set avg_accuracy=88.29% avg_sensitivity=72.41%, avg_specificity=93.89% avg_auc=91.90%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.135725 Test loss=0.311487 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13667291402816772
[5/24] Train loss=0.11846747994422913
[10/24] Train loss=0.14152634143829346
[15/24] Train loss=0.14252953231334686
[20/24] Train loss=0.13729313015937805
Test set avg_accuracy=88.49% avg_sensitivity=76.66%, avg_specificity=92.66% avg_auc=91.92%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.135693 Test loss=0.316522 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13182637095451355
[5/24] Train loss=0.11733537167310715
[10/24] Train loss=0.13769757747650146
[15/24] Train loss=0.13621409237384796
[20/24] Train loss=0.1391095519065857
Test set avg_accuracy=88.49% avg_sensitivity=68.62%, avg_specificity=95.49% avg_auc=91.70%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.134579 Test loss=0.311324 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13409151136875153
[5/24] Train loss=0.11598768830299377
[10/24] Train loss=0.14021822810173035
[15/24] Train loss=0.13729651272296906
[20/24] Train loss=0.13493064045906067
Test set avg_accuracy=88.58% avg_sensitivity=71.61%, avg_specificity=94.56% avg_auc=91.52%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.133806 Test loss=0.316406 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.12999102473258972
[5/24] Train loss=0.11599026620388031
[10/24] Train loss=0.13921871781349182
[15/24] Train loss=0.14007963240146637
[20/24] Train loss=0.1323174089193344
Test set avg_accuracy=88.54% avg_sensitivity=71.11%, avg_specificity=94.68% avg_auc=91.83%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.132952 Test loss=0.311431 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1315772831439972
[5/24] Train loss=0.11794768273830414
[10/24] Train loss=0.13502907752990723
[15/24] Train loss=0.13983646035194397
[20/24] Train loss=0.1322207897901535
Test set avg_accuracy=88.41% avg_sensitivity=72.51%, avg_specificity=94.01% avg_auc=91.92%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.133067 Test loss=0.306633 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1306433379650116
[5/24] Train loss=0.11333529651165009
[10/24] Train loss=0.13958793878555298
[15/24] Train loss=0.137281134724617
[20/24] Train loss=0.13170652091503143
Test set avg_accuracy=88.27% avg_sensitivity=69.52%, avg_specificity=94.88% avg_auc=91.54%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.131482 Test loss=0.315354 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1299590766429901
[5/24] Train loss=0.11528590321540833
[10/24] Train loss=0.13697682321071625
[15/24] Train loss=0.13658657670021057
[20/24] Train loss=0.1300787329673767
Test set avg_accuracy=88.19% avg_sensitivity=67.82%, avg_specificity=95.37% avg_auc=91.54%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.130844 Test loss=0.313308 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12763984501361847
[5/24] Train loss=0.1129380613565445
[10/24] Train loss=0.13595394790172577
[15/24] Train loss=0.1333603709936142
[20/24] Train loss=0.13125739991664886
Test set avg_accuracy=88.83% avg_sensitivity=78.61%, avg_specificity=92.43% avg_auc=92.61%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.129546 Test loss=0.307557 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1274605095386505
[5/24] Train loss=0.11391223967075348
[10/24] Train loss=0.13605456054210663
[15/24] Train loss=0.13906142115592957
[20/24] Train loss=0.12944281101226807
Test set avg_accuracy=88.87% avg_sensitivity=78.31%, avg_specificity=92.59% avg_auc=92.28%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.129180 Test loss=0.306234 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12549501657485962
[5/24] Train loss=0.1100199744105339
[10/24] Train loss=0.13250850141048431
[15/24] Train loss=0.13482718169689178
[20/24] Train loss=0.13279590010643005
Test set avg_accuracy=88.96% avg_sensitivity=75.36%, avg_specificity=93.75% avg_auc=92.22%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.128329 Test loss=0.305406 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1296391785144806
[5/24] Train loss=0.11143766343593597
[10/24] Train loss=0.13498462736606598
[15/24] Train loss=0.13401156663894653
[20/24] Train loss=0.13106314837932587
Test set avg_accuracy=88.27% avg_sensitivity=75.21%, avg_specificity=92.87% avg_auc=91.92%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.128546 Test loss=0.310495 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1266080141067505
[5/24] Train loss=0.11148480325937271
[10/24] Train loss=0.13098746538162231
[15/24] Train loss=0.13269302248954773
[20/24] Train loss=0.12864342331886292
Test set avg_accuracy=88.44% avg_sensitivity=71.96%, avg_specificity=94.24% avg_auc=91.59%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.128477 Test loss=0.311953 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1252197027206421
[5/24] Train loss=0.11457483470439911
[10/24] Train loss=0.13241243362426758
[15/24] Train loss=0.13172362744808197
[20/24] Train loss=0.12896446883678436
Test set avg_accuracy=88.45% avg_sensitivity=74.76%, avg_specificity=93.27% avg_auc=91.81%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.127335 Test loss=0.310838 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12687788903713226
[5/24] Train loss=0.11106991022825241
[10/24] Train loss=0.1288299262523651
[15/24] Train loss=0.13050833344459534
[20/24] Train loss=0.12723055481910706
Test set avg_accuracy=87.97% avg_sensitivity=73.81%, avg_specificity=92.96% avg_auc=91.15%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.126600 Test loss=0.322468 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1240668073296547
[5/24] Train loss=0.11111772060394287
[10/24] Train loss=0.13078321516513824
[15/24] Train loss=0.13193251192569733
[20/24] Train loss=0.13071812689304352
Test set avg_accuracy=88.23% avg_sensitivity=74.86%, avg_specificity=92.94% avg_auc=91.75%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.127403 Test loss=0.313790 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12356659770011902
[5/24] Train loss=0.11360614001750946
[10/24] Train loss=0.13067775964736938
[15/24] Train loss=0.13345535099506378
[20/24] Train loss=0.12685108184814453
Test set avg_accuracy=87.89% avg_sensitivity=78.91%, avg_specificity=91.05% avg_auc=92.00%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.126211 Test loss=0.318746 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12064211070537567
[5/24] Train loss=0.11003847420215607
[10/24] Train loss=0.1293676346540451
[15/24] Train loss=0.1302749067544937
[20/24] Train loss=0.12652164697647095
Test set avg_accuracy=88.72% avg_sensitivity=76.86%, avg_specificity=92.90% avg_auc=92.10%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.125045 Test loss=0.305912 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12367329001426697
[5/24] Train loss=0.10949999839067459
[10/24] Train loss=0.12609092891216278
[15/24] Train loss=0.13051682710647583
[20/24] Train loss=0.12911945581436157
Test set avg_accuracy=88.57% avg_sensitivity=77.16%, avg_specificity=92.59% avg_auc=92.14%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.125066 Test loss=0.306120 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12131553888320923
[5/24] Train loss=0.10884031653404236
[10/24] Train loss=0.13037680089473724
[15/24] Train loss=0.12848593294620514
[20/24] Train loss=0.12655454874038696
Test set avg_accuracy=88.31% avg_sensitivity=74.66%, avg_specificity=93.11% avg_auc=92.11%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.124436 Test loss=0.304568 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12359573692083359
[5/24] Train loss=0.10882019996643066
[10/24] Train loss=0.1269778460264206
[15/24] Train loss=0.13207469880580902
[20/24] Train loss=0.12546594440937042
Test set avg_accuracy=88.33% avg_sensitivity=74.51%, avg_specificity=93.20% avg_auc=92.18%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.123966 Test loss=0.305175 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12288559228181839
[5/24] Train loss=0.10868804156780243
[10/24] Train loss=0.1259000301361084
[15/24] Train loss=0.12859012186527252
[20/24] Train loss=0.12527114152908325
Test set avg_accuracy=88.78% avg_sensitivity=76.86%, avg_specificity=92.97% avg_auc=92.20%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.123313 Test loss=0.304844 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12219587713479996
[5/24] Train loss=0.10833856463432312
[10/24] Train loss=0.12720708549022675
[15/24] Train loss=0.1291615515947342
[20/24] Train loss=0.12377871572971344
Test set avg_accuracy=88.68% avg_sensitivity=76.01%, avg_specificity=93.15% avg_auc=92.15%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.122784 Test loss=0.304319 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11985200643539429
[5/24] Train loss=0.10778886079788208
[10/24] Train loss=0.12696614861488342
[15/24] Train loss=0.12778162956237793
[20/24] Train loss=0.12287046760320663
Test set avg_accuracy=88.46% avg_sensitivity=75.61%, avg_specificity=92.99% avg_auc=91.93%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.122651 Test loss=0.307470 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12104684859514236
[5/24] Train loss=0.10737836360931396
[10/24] Train loss=0.12295840680599213
[15/24] Train loss=0.12957589328289032
[20/24] Train loss=0.12338302284479141
Test set avg_accuracy=88.65% avg_sensitivity=76.21%, avg_specificity=93.03% avg_auc=91.99%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.122094 Test loss=0.306471 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11891023814678192
[5/24] Train loss=0.10788312554359436
[10/24] Train loss=0.12556087970733643
[15/24] Train loss=0.1267576664686203
[20/24] Train loss=0.1253189891576767
Test set avg_accuracy=88.76% avg_sensitivity=76.46%, avg_specificity=93.10% avg_auc=92.09%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.121389 Test loss=0.304368 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1198071837425232
[5/24] Train loss=0.10664141178131104
[10/24] Train loss=0.12291181087493896
[15/24] Train loss=0.12644022703170776
[20/24] Train loss=0.1252419650554657
Test set avg_accuracy=88.58% avg_sensitivity=75.66%, avg_specificity=93.13% avg_auc=92.00%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.121698 Test loss=0.306217 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11909417062997818
[5/24] Train loss=0.10539977252483368
[10/24] Train loss=0.1242503896355629
[15/24] Train loss=0.1277717500925064
[20/24] Train loss=0.1281975358724594
Test set avg_accuracy=88.39% avg_sensitivity=75.81%, avg_specificity=92.82% avg_auc=92.05%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.121674 Test loss=0.307322 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1205744594335556
[5/24] Train loss=0.10583832114934921
[10/24] Train loss=0.1259295493364334
[15/24] Train loss=0.1279495805501938
[20/24] Train loss=0.12428616732358932
Test set avg_accuracy=88.80% avg_sensitivity=76.81%, avg_specificity=93.03% avg_auc=92.05%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.121373 Test loss=0.305932 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12138179689645767
[5/24] Train loss=0.10950278490781784
[10/24] Train loss=0.1261322796344757
[15/24] Train loss=0.12484563887119293
[20/24] Train loss=0.12606868147850037
Test set avg_accuracy=88.84% avg_sensitivity=76.46%, avg_specificity=93.20% avg_auc=92.09%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.121480 Test loss=0.304730 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11988683044910431
[5/24] Train loss=0.10830546915531158
[10/24] Train loss=0.12325756996870041
[15/24] Train loss=0.1268950253725052
[20/24] Train loss=0.12425736337900162
Test set avg_accuracy=88.66% avg_sensitivity=75.96%, avg_specificity=93.13% avg_auc=92.09%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.121615 Test loss=0.305057 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12036456912755966
[5/24] Train loss=0.10569150000810623
[10/24] Train loss=0.12515348196029663
[15/24] Train loss=0.12643450498580933
[20/24] Train loss=0.1230931505560875
Test set avg_accuracy=88.62% avg_sensitivity=76.06%, avg_specificity=93.04% avg_auc=92.06%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.121049 Test loss=0.305504 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.11963485926389694
[5/24] Train loss=0.10886508226394653
[10/24] Train loss=0.12519316375255585
[15/24] Train loss=0.1265934705734253
[20/24] Train loss=0.12246934324502945
Test set avg_accuracy=88.61% avg_sensitivity=75.96%, avg_specificity=93.06% avg_auc=92.07%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.121273 Test loss=0.305214 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11910855770111084
[5/24] Train loss=0.10803115367889404
[10/24] Train loss=0.12499753385782242
[15/24] Train loss=0.12854322791099548
[20/24] Train loss=0.1267240047454834
Test set avg_accuracy=88.62% avg_sensitivity=76.06%, avg_specificity=93.04% avg_auc=92.06%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.122287 Test loss=0.305474 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.11882587522268295
[5/24] Train loss=0.10735514014959335
[10/24] Train loss=0.12433270364999771
[15/24] Train loss=0.12681089341640472
[20/24] Train loss=0.12143222987651825
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.61% avg_sensitivity=75.96%, avg_specificity=93.06% avg_auc=92.06%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.120896 Test loss=0.305413 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=88.40% sen=83.26%, spe=90.21%, auc=92.82%!
Fold[4] Avg_overlap=0.70%(0.20943696216725938)
[0/24] Train loss=0.7329081892967224
[5/24] Train loss=0.7195228934288025
[10/24] Train loss=0.7141667604446411
[15/24] Train loss=0.7107535600662231
[20/24] Train loss=0.7018433809280396
Test set avg_accuracy=68.45% avg_sensitivity=40.71%, avg_specificity=77.91% avg_auc=60.68%
Best model saved!! Metric=-78.2547003720653!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.717135 Test loss=0.653767 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6982970237731934
[5/24] Train loss=0.6957200169563293
[10/24] Train loss=0.6942479610443115
[15/24] Train loss=0.6840326189994812
[20/24] Train loss=0.6760169267654419
Test set avg_accuracy=75.05% avg_sensitivity=64.36%, avg_specificity=78.70% avg_auc=73.22%
Best model saved!! Metric=-34.66605688711344!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.688594 Test loss=0.599355 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6712238192558289
[5/24] Train loss=0.6668581962585449
[10/24] Train loss=0.6747356653213501
[15/24] Train loss=0.6485314965248108
[20/24] Train loss=0.6434723138809204
Test set avg_accuracy=75.90% avg_sensitivity=71.17%, avg_specificity=77.51% avg_auc=77.40%
Best model saved!! Metric=-24.022840344966994!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.661179 Test loss=0.564639 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6418671011924744
[5/24] Train loss=0.6324780583381653
[10/24] Train loss=0.637418270111084
[15/24] Train loss=0.6158028244972229
[20/24] Train loss=0.6035802364349365
Test set avg_accuracy=75.89% avg_sensitivity=75.99%, avg_specificity=75.85% avg_auc=80.66%
Best model saved!! Metric=-17.616340847595282!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.630295 Test loss=0.538562 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6124270558357239
[5/24] Train loss=0.6074280142784119
[10/24] Train loss=0.6136044859886169
[15/24] Train loss=0.5833584070205688
[20/24] Train loss=0.5800561308860779
Test set avg_accuracy=77.10% avg_sensitivity=78.44%, avg_specificity=76.64% avg_auc=83.15%
Best model saved!! Metric=-10.675871090916559!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.602112 Test loss=0.514769 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5833489894866943
[5/24] Train loss=0.5732287764549255
[10/24] Train loss=0.5878708362579346
[15/24] Train loss=0.5538294911384583
[20/24] Train loss=0.553870677947998
Test set avg_accuracy=77.36% avg_sensitivity=80.49%, avg_specificity=76.29% avg_auc=85.17%
Best model saved!! Metric=-6.696927072339065!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.574076 Test loss=0.492759 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5548149347305298
[5/24] Train loss=0.5470179319381714
[10/24] Train loss=0.5643439292907715
[15/24] Train loss=0.5188913345336914
[20/24] Train loss=0.5281564593315125
Test set avg_accuracy=78.93% avg_sensitivity=80.03%, avg_specificity=78.56% avg_auc=86.71%
Best model saved!! Metric=-1.7697507692002574!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.546734 Test loss=0.468869 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5236571431159973
[5/24] Train loss=0.515421450138092
[10/24] Train loss=0.5323120355606079
[15/24] Train loss=0.4941941201686859
[20/24] Train loss=0.4953754246234894
Test set avg_accuracy=81.34% avg_sensitivity=79.57%, avg_specificity=81.95% avg_auc=87.96%
Best model saved!! Metric=4.815465114509763!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.518316 Test loss=0.443038 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.5032965540885925
[5/24] Train loss=0.4870714545249939
[10/24] Train loss=0.5039137601852417
[15/24] Train loss=0.4631362557411194
[20/24] Train loss=0.46780964732170105
Test set avg_accuracy=82.27% avg_sensitivity=77.78%, avg_specificity=83.80% avg_auc=89.27%
Best model saved!! Metric=7.106008730429181!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.490617 Test loss=0.416672 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.47135281562805176
[5/24] Train loss=0.4568500816822052
[10/24] Train loss=0.48112449049949646
[15/24] Train loss=0.4325849711894989
[20/24] Train loss=0.44064709544181824
Test set avg_accuracy=83.79% avg_sensitivity=77.47%, avg_specificity=85.94% avg_auc=90.43%
Best model saved!! Metric=11.636375883635381!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.463402 Test loss=0.396025 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.44597190618515015
[5/24] Train loss=0.43062761425971985
[10/24] Train loss=0.4486843943595886
[15/24] Train loss=0.4119895398616791
[20/24] Train loss=0.40871143341064453
Test set avg_accuracy=84.78% avg_sensitivity=77.42%, avg_specificity=87.29% avg_auc=91.36%
Best model saved!! Metric=14.850552507649653!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.436440 Test loss=0.376090 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4208739697933197
[5/24] Train loss=0.4089899957180023
[10/24] Train loss=0.43208009004592896
[15/24] Train loss=0.38495975732803345
[20/24] Train loss=0.3826215863227844
Test set avg_accuracy=85.40% avg_sensitivity=75.06%, avg_specificity=88.93% avg_auc=91.86%
Best model saved!! Metric=15.253206725223436!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.412967 Test loss=0.354789 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.39691677689552307
[5/24] Train loss=0.3803596794605255
[10/24] Train loss=0.40922096371650696
[15/24] Train loss=0.36299172043800354
[20/24] Train loss=0.3656196892261505
Test set avg_accuracy=86.77% avg_sensitivity=71.58%, avg_specificity=91.95% avg_auc=92.07%
Best model saved!! Metric=16.37138733365751!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.390081 Test loss=0.337755 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3765012323856354
[5/24] Train loss=0.3567672073841095
[10/24] Train loss=0.3860815167427063
[15/24] Train loss=0.34394270181655884
[20/24] Train loss=0.3424774408340454
Test set avg_accuracy=86.69% avg_sensitivity=71.99%, avg_specificity=91.71% avg_auc=92.28%
Best model saved!! Metric=16.673411126249903!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.369124 Test loss=0.328411 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3622732162475586
[5/24] Train loss=0.337474524974823
[10/24] Train loss=0.37709474563598633
[15/24] Train loss=0.3229576349258423
[20/24] Train loss=0.3270476162433624
Test set avg_accuracy=86.63% avg_sensitivity=73.78%, avg_specificity=91.01% avg_auc=92.84%
Best model saved!! Metric=18.263803587113884!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.352899 Test loss=0.318573 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.34147563576698303
[5/24] Train loss=0.32322928309440613
[10/24] Train loss=0.3629957437515259
[15/24] Train loss=0.312765896320343
[20/24] Train loss=0.3122670650482178
Test set avg_accuracy=86.90% avg_sensitivity=73.89%, avg_specificity=91.34% avg_auc=93.15%
Best model saved!! Metric=19.279339917216888!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.337678 Test loss=0.308648 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3298780620098114
[5/24] Train loss=0.3120785653591156
[10/24] Train loss=0.35841381549835205
[15/24] Train loss=0.3038859963417053
[20/24] Train loss=0.30746835470199585
Test set avg_accuracy=86.93% avg_sensitivity=72.09%, avg_specificity=91.99% avg_auc=93.27%
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.326269 Test loss=0.299909 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.32046452164649963
[5/24] Train loss=0.30098241567611694
[10/24] Train loss=0.34382688999176025
[15/24] Train loss=0.2860671877861023
[20/24] Train loss=0.2977663278579712
Test set avg_accuracy=86.74% avg_sensitivity=77.21%, avg_specificity=89.99% avg_auc=93.84%
Best model saved!! Metric=21.79607621446182!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.316245 Test loss=0.298146 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3092445135116577
[5/24] Train loss=0.2944727838039398
[10/24] Train loss=0.33475756645202637
[15/24] Train loss=0.28121355175971985
[20/24] Train loss=0.28454431891441345
Test set avg_accuracy=86.78% avg_sensitivity=77.68%, avg_specificity=89.89% avg_auc=93.87%
Best model saved!! Metric=22.22085755098243!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.306867 Test loss=0.296612 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3022282123565674
[5/24] Train loss=0.2775495648384094
[10/24] Train loss=0.3242296278476715
[15/24] Train loss=0.27049732208251953
[20/24] Train loss=0.27138203382492065
Test set avg_accuracy=88.14% avg_sensitivity=74.04%, avg_specificity=92.95% avg_auc=93.75%
Best model saved!! Metric=22.87579148002436!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.298305 Test loss=0.285572 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.292476087808609
[5/24] Train loss=0.27404505014419556
[10/24] Train loss=0.32097217440605164
[15/24] Train loss=0.26759207248687744
[20/24] Train loss=0.2689363658428192
Test set avg_accuracy=88.37% avg_sensitivity=73.53%, avg_specificity=93.43% avg_auc=93.87%
Best model saved!! Metric=23.20520591334258!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.290970 Test loss=0.281016 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.28257906436920166
[5/24] Train loss=0.26301538944244385
[10/24] Train loss=0.30835312604904175
[15/24] Train loss=0.256125271320343
[20/24] Train loss=0.2622097134590149
Test set avg_accuracy=88.72% avg_sensitivity=70.81%, avg_specificity=94.83% avg_auc=93.75%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.282185 Test loss=0.279041 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2795749306678772
[5/24] Train loss=0.26267343759536743
[10/24] Train loss=0.31184014678001404
[15/24] Train loss=0.25098276138305664
[20/24] Train loss=0.259858101606369
Test set avg_accuracy=87.84% avg_sensitivity=70.92%, avg_specificity=93.61% avg_auc=93.76%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.278431 Test loss=0.276936 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27681058645248413
[5/24] Train loss=0.2603498697280884
[10/24] Train loss=0.3078221082687378
[15/24] Train loss=0.24917501211166382
[20/24] Train loss=0.2504686415195465
Test set avg_accuracy=89.11% avg_sensitivity=71.53%, avg_specificity=95.11% avg_auc=93.97%
Best model saved!! Metric=23.72435025784027!!
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.273486 Test loss=0.271167 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2645135521888733
[5/24] Train loss=0.24818797409534454
[10/24] Train loss=0.2978403866291046
[15/24] Train loss=0.2396354228258133
[20/24] Train loss=0.24778945744037628
Test set avg_accuracy=88.27% avg_sensitivity=66.56%, avg_specificity=95.67% avg_auc=93.38%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.266506 Test loss=0.278557 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.26229774951934814
[5/24] Train loss=0.2400117665529251
[10/24] Train loss=0.2961156964302063
[15/24] Train loss=0.23567473888397217
[20/24] Train loss=0.24366170167922974
Test set avg_accuracy=88.79% avg_sensitivity=68.31%, avg_specificity=95.77% avg_auc=93.94%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.261366 Test loss=0.271726 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2517891824245453
[5/24] Train loss=0.24132904410362244
[10/24] Train loss=0.28947684168815613
[15/24] Train loss=0.2303779274225235
[20/24] Train loss=0.24213752150535583
Test set avg_accuracy=87.86% avg_sensitivity=70.20%, avg_specificity=93.89% avg_auc=93.86%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.256065 Test loss=0.273028 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2502827048301697
[5/24] Train loss=0.23928649723529816
[10/24] Train loss=0.28431376814842224
[15/24] Train loss=0.22862693667411804
[20/24] Train loss=0.24409523606300354
Test set avg_accuracy=87.93% avg_sensitivity=63.75%, avg_specificity=96.18% avg_auc=93.20%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.253023 Test loss=0.284991 Current lr=[0.000210185142098938]

[0/24] Train loss=0.25507795810699463
[5/24] Train loss=0.23371995985507965
[10/24] Train loss=0.278349369764328
[15/24] Train loss=0.22536709904670715
[20/24] Train loss=0.24055393040180206
Test set avg_accuracy=84.99% avg_sensitivity=45.93%, avg_specificity=98.31% avg_auc=91.21%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.249480 Test loss=0.338699 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2548067271709442
[5/24] Train loss=0.2257678508758545
[10/24] Train loss=0.27309370040893555
[15/24] Train loss=0.21342577040195465
[20/24] Train loss=0.2347002774477005
Test set avg_accuracy=87.89% avg_sensitivity=61.03%, avg_specificity=97.05% avg_auc=91.79%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.245231 Test loss=0.300809 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2498491406440735
[5/24] Train loss=0.21644756197929382
[10/24] Train loss=0.28256163001060486
[15/24] Train loss=0.21619747579097748
[20/24] Train loss=0.22398412227630615
Test set avg_accuracy=86.52% avg_sensitivity=55.97%, avg_specificity=96.94% avg_auc=90.53%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.240167 Test loss=0.330728 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2387371063232422
[5/24] Train loss=0.21686036884784698
[10/24] Train loss=0.27679941058158875
[15/24] Train loss=0.21306967735290527
[20/24] Train loss=0.22260558605194092
Test set avg_accuracy=87.64% avg_sensitivity=61.85%, avg_specificity=96.44% avg_auc=93.08%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.238104 Test loss=0.293235 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23338493704795837
[5/24] Train loss=0.22127072513103485
[10/24] Train loss=0.2754414975643158
[15/24] Train loss=0.21207965910434723
[20/24] Train loss=0.23131851851940155
Test set avg_accuracy=87.33% avg_sensitivity=61.19%, avg_specificity=96.25% avg_auc=91.20%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.234228 Test loss=0.316565 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23347756266593933
[5/24] Train loss=0.2084013819694519
[10/24] Train loss=0.26362699270248413
[15/24] Train loss=0.208333820104599
[20/24] Train loss=0.2257857471704483
Test set avg_accuracy=83.93% avg_sensitivity=41.37%, avg_specificity=98.45% avg_auc=88.34%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.233044 Test loss=0.401239 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2632104754447937
[5/24] Train loss=0.1966530829668045
[10/24] Train loss=0.25464439392089844
[15/24] Train loss=0.1997012495994568
[20/24] Train loss=0.21069353818893433
Test set avg_accuracy=86.16% avg_sensitivity=55.30%, avg_specificity=96.68% avg_auc=92.22%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.228668 Test loss=0.316638 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.21944056451320648
[5/24] Train loss=0.19454585015773773
[10/24] Train loss=0.26270827651023865
[15/24] Train loss=0.20753668248653412
[20/24] Train loss=0.21503733098506927
Test set avg_accuracy=86.61% avg_sensitivity=56.94%, avg_specificity=96.73% avg_auc=91.79%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.227152 Test loss=0.313392 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22730478644371033
[5/24] Train loss=0.20962309837341309
[10/24] Train loss=0.2559155225753784
[15/24] Train loss=0.2104567289352417
[20/24] Train loss=0.20468948781490326
Test set avg_accuracy=82.57% avg_sensitivity=36.66%, avg_specificity=98.22% avg_auc=87.12%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.224851 Test loss=0.425083 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.22833888232707977
[5/24] Train loss=0.1962197721004486
[10/24] Train loss=0.24776087701320648
[15/24] Train loss=0.21437214314937592
[20/24] Train loss=0.21523578464984894
Test set avg_accuracy=88.78% avg_sensitivity=71.68%, avg_specificity=94.60% avg_auc=93.96%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.223341 Test loss=0.269012 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21225129067897797
[5/24] Train loss=0.1956273466348648
[10/24] Train loss=0.2527271509170532
[15/24] Train loss=0.1993933469057083
[20/24] Train loss=0.21816369891166687
Test set avg_accuracy=86.86% avg_sensitivity=56.07%, avg_specificity=97.36% avg_auc=89.85%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.218993 Test loss=0.343949 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2308979332447052
[5/24] Train loss=0.1885986477136612
[10/24] Train loss=0.24313382804393768
[15/24] Train loss=0.20098073780536652
[20/24] Train loss=0.20631985366344452
Test set avg_accuracy=87.68% avg_sensitivity=70.51%, avg_specificity=93.54% avg_auc=92.71%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.219287 Test loss=0.287372 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.22084058821201324
[5/24] Train loss=0.19283640384674072
[10/24] Train loss=0.23924385011196136
[15/24] Train loss=0.18889158964157104
[20/24] Train loss=0.20214281976222992
Test set avg_accuracy=87.10% avg_sensitivity=62.26%, avg_specificity=95.56% avg_auc=90.65%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.216693 Test loss=0.336695 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21142879128456116
[5/24] Train loss=0.21811489760875702
[10/24] Train loss=0.2593146562576294
[15/24] Train loss=0.19893182814121246
[20/24] Train loss=0.21156710386276245
Test set avg_accuracy=88.68% avg_sensitivity=69.33%, avg_specificity=95.29% avg_auc=92.98%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.225413 Test loss=0.291413 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2138260304927826
[5/24] Train loss=0.19375117123126984
[10/24] Train loss=0.24533936381340027
[15/24] Train loss=0.20202723145484924
[20/24] Train loss=0.20619618892669678
Test set avg_accuracy=88.54% avg_sensitivity=76.96%, avg_specificity=92.49% avg_auc=93.20%
Best model saved!! Metric=25.1883888209844!!
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.215880 Test loss=0.283768 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.22042730450630188
[5/24] Train loss=0.17775613069534302
[10/24] Train loss=0.24447877705097198
[15/24] Train loss=0.19914942979812622
[20/24] Train loss=0.20828978717327118
Test set avg_accuracy=85.96% avg_sensitivity=87.25%, avg_specificity=85.52% avg_auc=94.37%
Best model saved!! Metric=27.10573630510153!!
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.218591 Test loss=0.307190 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20744965970516205
[5/24] Train loss=0.1786486655473709
[10/24] Train loss=0.22290371358394623
[15/24] Train loss=0.19414778053760529
[20/24] Train loss=0.20412620902061462
Test set avg_accuracy=88.16% avg_sensitivity=77.78%, avg_specificity=91.71% avg_auc=94.71%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.208710 Test loss=0.260056 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.20888341963291168
[5/24] Train loss=0.19071008265018463
[10/24] Train loss=0.22406135499477386
[15/24] Train loss=0.18599647283554077
[20/24] Train loss=0.18912315368652344
Test set avg_accuracy=88.14% avg_sensitivity=72.91%, avg_specificity=93.33% avg_auc=93.79%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.207263 Test loss=0.276118 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.201028510928154
[5/24] Train loss=0.1844056397676468
[10/24] Train loss=0.22424225509166718
[15/24] Train loss=0.1910756528377533
[20/24] Train loss=0.19148051738739014
Test set avg_accuracy=89.56% avg_sensitivity=76.75%, avg_specificity=93.92% avg_auc=93.80%
Best model saved!! Metric=28.037890434766084!!
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.209108 Test loss=0.287381 Current lr=[0.000299720220882401]

[0/24] Train loss=0.20578055083751678
[5/24] Train loss=0.17772071063518524
[10/24] Train loss=0.23440121114253998
[15/24] Train loss=0.18753592669963837
[20/24] Train loss=0.18879926204681396
Test set avg_accuracy=88.31% avg_sensitivity=80.65%, avg_specificity=90.92% avg_auc=94.02%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.207806 Test loss=0.279348 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19669872522354126
[5/24] Train loss=0.192208930850029
[10/24] Train loss=0.2220490425825119
[15/24] Train loss=0.19787131249904633
[20/24] Train loss=0.18748462200164795
Test set avg_accuracy=86.85% avg_sensitivity=82.44%, avg_specificity=88.35% avg_auc=94.26%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.204403 Test loss=0.287792 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2021588683128357
[5/24] Train loss=0.1855483204126358
[10/24] Train loss=0.22639040648937225
[15/24] Train loss=0.19578617811203003
[20/24] Train loss=0.18499517440795898
Test set avg_accuracy=87.14% avg_sensitivity=83.51%, avg_specificity=88.37% avg_auc=94.09%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.203179 Test loss=0.295640 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.20341871678829193
[5/24] Train loss=0.17592674493789673
[10/24] Train loss=0.23244696855545044
[15/24] Train loss=0.1935916692018509
[20/24] Train loss=0.18899722397327423
Test set avg_accuracy=87.88% avg_sensitivity=71.22%, avg_specificity=93.56% avg_auc=93.69%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.206703 Test loss=0.275545 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19858522713184357
[5/24] Train loss=0.19573906064033508
[10/24] Train loss=0.21770554780960083
[15/24] Train loss=0.1923079639673233
[20/24] Train loss=0.18544669449329376
Test set avg_accuracy=87.62% avg_sensitivity=82.64%, avg_specificity=89.31% avg_auc=94.20%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.200919 Test loss=0.280403 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20070478320121765
[5/24] Train loss=0.1611672192811966
[10/24] Train loss=0.21757128834724426
[15/24] Train loss=0.18565663695335388
[20/24] Train loss=0.18518595397472382
Test set avg_accuracy=87.04% avg_sensitivity=76.45%, avg_specificity=90.66% avg_auc=93.65%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.198347 Test loss=0.287698 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19600141048431396
[5/24] Train loss=0.17347128689289093
[10/24] Train loss=0.218377023935318
[15/24] Train loss=0.19249452650547028
[20/24] Train loss=0.19164563715457916
Test set avg_accuracy=87.34% avg_sensitivity=79.37%, avg_specificity=90.06% avg_auc=93.97%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.202654 Test loss=0.280972 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.19628643989562988
[5/24] Train loss=0.16022339463233948
[10/24] Train loss=0.22881023585796356
[15/24] Train loss=0.19770048558712006
[20/24] Train loss=0.18725267052650452
Test set avg_accuracy=88.27% avg_sensitivity=74.91%, avg_specificity=92.82% avg_auc=94.31%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.200263 Test loss=0.263654 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.2061319351196289
[5/24] Train loss=0.1805252730846405
[10/24] Train loss=0.21330809593200684
[15/24] Train loss=0.20013365149497986
[20/24] Train loss=0.19189682602882385
Test set avg_accuracy=87.59% avg_sensitivity=76.14%, avg_specificity=91.50% avg_auc=93.95%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.201018 Test loss=0.274323 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.20635986328125
[5/24] Train loss=0.16626718640327454
[10/24] Train loss=0.2233792394399643
[15/24] Train loss=0.1825658529996872
[20/24] Train loss=0.18561118841171265
Test set avg_accuracy=87.98% avg_sensitivity=77.42%, avg_specificity=91.58% avg_auc=93.76%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.199660 Test loss=0.279961 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.20805461704730988
[5/24] Train loss=0.17341728508472443
[10/24] Train loss=0.22489100694656372
[15/24] Train loss=0.1877748817205429
[20/24] Train loss=0.1932956725358963
Test set avg_accuracy=86.52% avg_sensitivity=81.77%, avg_specificity=88.14% avg_auc=93.95%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.199690 Test loss=0.293611 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19877177476882935
[5/24] Train loss=0.17166170477867126
[10/24] Train loss=0.21322639286518097
[15/24] Train loss=0.18292967975139618
[20/24] Train loss=0.1873115748167038
Test set avg_accuracy=86.45% avg_sensitivity=84.43%, avg_specificity=87.13% avg_auc=94.08%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.199818 Test loss=0.301112 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19467061758041382
[5/24] Train loss=0.16362470388412476
[10/24] Train loss=0.20245851576328278
[15/24] Train loss=0.18009711802005768
[20/24] Train loss=0.18137167394161224
Test set avg_accuracy=88.44% avg_sensitivity=73.84%, avg_specificity=93.42% avg_auc=92.95%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.191264 Test loss=0.290640 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.19417136907577515
[5/24] Train loss=0.15949369966983795
[10/24] Train loss=0.21559995412826538
[15/24] Train loss=0.17358773946762085
[20/24] Train loss=0.1828216314315796
Test set avg_accuracy=87.24% avg_sensitivity=60.27%, avg_specificity=96.44% avg_auc=91.62%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.189234 Test loss=0.309057 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.20331908762454987
[5/24] Train loss=0.16561105847358704
[10/24] Train loss=0.18678182363510132
[15/24] Train loss=0.17153435945510864
[20/24] Train loss=0.18695737421512604
Test set avg_accuracy=88.02% avg_sensitivity=61.44%, avg_specificity=97.08% avg_auc=92.39%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.189910 Test loss=0.300172 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.1946849226951599
[5/24] Train loss=0.16016598045825958
[10/24] Train loss=0.2056315839290619
[15/24] Train loss=0.17211516201496124
[20/24] Train loss=0.1801667958498001
Test set avg_accuracy=83.01% avg_sensitivity=39.27%, avg_specificity=97.92% avg_auc=87.54%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.186083 Test loss=0.412384 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19438685476779938
[5/24] Train loss=0.16654664278030396
[10/24] Train loss=0.21138454973697662
[15/24] Train loss=0.17251142859458923
[20/24] Train loss=0.18334241211414337
Test set avg_accuracy=87.24% avg_sensitivity=77.47%, avg_specificity=90.57% avg_auc=93.25%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.185593 Test loss=0.289762 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1900584101676941
[5/24] Train loss=0.17033088207244873
[10/24] Train loss=0.19355152547359467
[15/24] Train loss=0.17406973242759705
[20/24] Train loss=0.17366065084934235
Test set avg_accuracy=87.83% avg_sensitivity=61.24%, avg_specificity=96.89% avg_auc=91.40%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.182802 Test loss=0.303994 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18189917504787445
[5/24] Train loss=0.16847385466098785
[10/24] Train loss=0.199563130736351
[15/24] Train loss=0.17479415237903595
[20/24] Train loss=0.17527823150157928
Test set avg_accuracy=88.05% avg_sensitivity=62.62%, avg_specificity=96.72% avg_auc=91.84%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.182664 Test loss=0.310007 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.179977148771286
[5/24] Train loss=0.1561008244752884
[10/24] Train loss=0.19432765245437622
[15/24] Train loss=0.17311221361160278
[20/24] Train loss=0.18572141230106354
Test set avg_accuracy=86.38% avg_sensitivity=75.52%, avg_specificity=90.08% avg_auc=91.52%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.186330 Test loss=0.324617 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18674126267433167
[5/24] Train loss=0.1696319580078125
[10/24] Train loss=0.20355254411697388
[15/24] Train loss=0.18540838360786438
[20/24] Train loss=0.17057856917381287
Test set avg_accuracy=88.79% avg_sensitivity=74.14%, avg_specificity=93.78% avg_auc=93.40%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.185308 Test loss=0.279898 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1853114515542984
[5/24] Train loss=0.1732686161994934
[10/24] Train loss=0.186386376619339
[15/24] Train loss=0.18342693150043488
[20/24] Train loss=0.1698032170534134
Test set avg_accuracy=85.72% avg_sensitivity=82.33%, avg_specificity=86.87% avg_auc=93.53%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.183640 Test loss=0.304881 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.18707460165023804
[5/24] Train loss=0.16338692605495453
[10/24] Train loss=0.1882050335407257
[15/24] Train loss=0.18005864322185516
[20/24] Train loss=0.17939502000808716
Test set avg_accuracy=87.03% avg_sensitivity=61.14%, avg_specificity=95.86% avg_auc=91.18%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.184524 Test loss=0.317791 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1877097189426422
[5/24] Train loss=0.16197991371154785
[10/24] Train loss=0.20133884251117706
[15/24] Train loss=0.16784875094890594
[20/24] Train loss=0.17267543077468872
Test set avg_accuracy=83.95% avg_sensitivity=84.84%, avg_specificity=83.64% avg_auc=92.07%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.182272 Test loss=0.357694 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.18932843208312988
[5/24] Train loss=0.17073360085487366
[10/24] Train loss=0.19713838398456573
[15/24] Train loss=0.17903681099414825
[20/24] Train loss=0.17473311722278595
Test set avg_accuracy=87.42% avg_sensitivity=79.67%, avg_specificity=90.06% avg_auc=93.78%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.185503 Test loss=0.293760 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18658556044101715
[5/24] Train loss=0.15818698704242706
[10/24] Train loss=0.19575932621955872
[15/24] Train loss=0.169516921043396
[20/24] Train loss=0.17201738059520721
Test set avg_accuracy=82.51% avg_sensitivity=88.38%, avg_specificity=80.51% avg_auc=91.97%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.185270 Test loss=0.409179 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17830967903137207
[5/24] Train loss=0.16526934504508972
[10/24] Train loss=0.19174401462078094
[15/24] Train loss=0.1658414602279663
[20/24] Train loss=0.17221558094024658
Test set avg_accuracy=88.44% avg_sensitivity=65.08%, avg_specificity=96.40% avg_auc=91.86%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.181956 Test loss=0.299065 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.1857888251543045
[5/24] Train loss=0.16357064247131348
[10/24] Train loss=0.18414199352264404
[15/24] Train loss=0.1681220531463623
[20/24] Train loss=0.17960593104362488
Test set avg_accuracy=88.10% avg_sensitivity=64.06%, avg_specificity=96.30% avg_auc=89.40%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.179608 Test loss=0.351011 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.1987796127796173
[5/24] Train loss=0.16759590804576874
[10/24] Train loss=0.1845775991678238
[15/24] Train loss=0.16598038375377655
[20/24] Train loss=0.17388029396533966
Test set avg_accuracy=88.26% avg_sensitivity=75.42%, avg_specificity=92.63% avg_auc=92.47%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.180997 Test loss=0.315448 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.18058231472969055
[5/24] Train loss=0.1541907638311386
[10/24] Train loss=0.18716095387935638
[15/24] Train loss=0.1689876914024353
[20/24] Train loss=0.17761008441448212
Test set avg_accuracy=86.80% avg_sensitivity=81.16%, avg_specificity=88.72% avg_auc=93.25%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.177016 Test loss=0.310709 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18356375396251678
[5/24] Train loss=0.15451575815677643
[10/24] Train loss=0.17189301550388336
[15/24] Train loss=0.15715284645557404
[20/24] Train loss=0.17500261962413788
Test set avg_accuracy=86.22% avg_sensitivity=54.94%, avg_specificity=96.89% avg_auc=90.89%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.171907 Test loss=0.327348 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.18657195568084717
[5/24] Train loss=0.14990635216236115
[10/24] Train loss=0.17327404022216797
[15/24] Train loss=0.162108913064003
[20/24] Train loss=0.16463615000247955
Test set avg_accuracy=88.70% avg_sensitivity=73.58%, avg_specificity=93.85% avg_auc=93.03%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.168422 Test loss=0.287403 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17432080209255219
[5/24] Train loss=0.1461779922246933
[10/24] Train loss=0.1802409440279007
[15/24] Train loss=0.15982408821582794
[20/24] Train loss=0.1603253334760666
Test set avg_accuracy=86.11% avg_sensitivity=53.46%, avg_specificity=97.24% avg_auc=88.49%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.169350 Test loss=0.343971 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1793220341205597
[5/24] Train loss=0.156283900141716
[10/24] Train loss=0.17870619893074036
[15/24] Train loss=0.15706384181976318
[20/24] Train loss=0.1643517166376114
Test set avg_accuracy=87.83% avg_sensitivity=63.75%, avg_specificity=96.04% avg_auc=89.43%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.170648 Test loss=0.324873 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1963241994380951
[5/24] Train loss=0.1575181782245636
[10/24] Train loss=0.17342625558376312
[15/24] Train loss=0.1597105711698532
[20/24] Train loss=0.16595618426799774
Test set avg_accuracy=85.74% avg_sensitivity=49.16%, avg_specificity=98.22% avg_auc=87.61%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.174076 Test loss=0.376512 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.18855124711990356
[5/24] Train loss=0.15836097300052643
[10/24] Train loss=0.17626486718654633
[15/24] Train loss=0.16000887751579285
[20/24] Train loss=0.16932086646556854
Test set avg_accuracy=87.43% avg_sensitivity=73.53%, avg_specificity=92.18% avg_auc=91.85%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.174247 Test loss=0.316622 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18080171942710876
[5/24] Train loss=0.1520690619945526
[10/24] Train loss=0.1712336242198944
[15/24] Train loss=0.15909230709075928
[20/24] Train loss=0.15838228166103363
Test set avg_accuracy=88.39% avg_sensitivity=64.93%, avg_specificity=96.39% avg_auc=91.81%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.167959 Test loss=0.304396 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17968523502349854
[5/24] Train loss=0.15628878772258759
[10/24] Train loss=0.17763520777225494
[15/24] Train loss=0.16256901621818542
[20/24] Train loss=0.15834824740886688
Test set avg_accuracy=88.35% avg_sensitivity=68.61%, avg_specificity=95.08% avg_auc=92.21%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.171569 Test loss=0.297322 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1810050755739212
[5/24] Train loss=0.14779235422611237
[10/24] Train loss=0.1738046407699585
[15/24] Train loss=0.1543080359697342
[20/24] Train loss=0.1618562787771225
Test set avg_accuracy=88.33% avg_sensitivity=79.26%, avg_specificity=91.43% avg_auc=93.97%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.167510 Test loss=0.285308 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1654381901025772
[5/24] Train loss=0.15314671397209167
[10/24] Train loss=0.16841816902160645
[15/24] Train loss=0.1585766226053238
[20/24] Train loss=0.1628362536430359
Test set avg_accuracy=88.72% avg_sensitivity=69.02%, avg_specificity=95.44% avg_auc=93.01%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.165446 Test loss=0.283560 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16567187011241913
[5/24] Train loss=0.14635786414146423
[10/24] Train loss=0.17972977459430695
[15/24] Train loss=0.1579689234495163
[20/24] Train loss=0.15736383199691772
Test set avg_accuracy=88.52% avg_sensitivity=69.07%, avg_specificity=95.15% avg_auc=92.64%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.168041 Test loss=0.293311 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1756027638912201
[5/24] Train loss=0.15194067358970642
[10/24] Train loss=0.16945041716098785
[15/24] Train loss=0.15202359855175018
[20/24] Train loss=0.16201986372470856
Test set avg_accuracy=87.99% avg_sensitivity=63.34%, avg_specificity=96.40% avg_auc=89.99%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.167784 Test loss=0.323709 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17837338149547577
[5/24] Train loss=0.14405792951583862
[10/24] Train loss=0.1686837077140808
[15/24] Train loss=0.1542276293039322
[20/24] Train loss=0.15933266282081604
Test set avg_accuracy=88.24% avg_sensitivity=65.13%, avg_specificity=96.12% avg_auc=90.48%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.165165 Test loss=0.319668 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17260092496871948
[5/24] Train loss=0.14370635151863098
[10/24] Train loss=0.17446185648441315
[15/24] Train loss=0.15805815160274506
[20/24] Train loss=0.16670043766498566
Test set avg_accuracy=87.73% avg_sensitivity=75.01%, avg_specificity=92.07% avg_auc=92.47%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.165142 Test loss=0.306037 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16893887519836426
[5/24] Train loss=0.1517251431941986
[10/24] Train loss=0.16589286923408508
[15/24] Train loss=0.15623508393764496
[20/24] Train loss=0.16287997364997864
Test set avg_accuracy=87.51% avg_sensitivity=70.51%, avg_specificity=93.31% avg_auc=90.74%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.166901 Test loss=0.320420 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17697453498840332
[5/24] Train loss=0.16106753051280975
[10/24] Train loss=0.1711401343345642
[15/24] Train loss=0.1626530885696411
[20/24] Train loss=0.15624892711639404
Test set avg_accuracy=82.43% avg_sensitivity=34.05%, avg_specificity=98.93% avg_auc=85.41%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.164139 Test loss=0.458222 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.18182262778282166
[5/24] Train loss=0.15959449112415314
[10/24] Train loss=0.17214785516262054
[15/24] Train loss=0.15264369547367096
[20/24] Train loss=0.16133087873458862
Test set avg_accuracy=88.40% avg_sensitivity=67.90%, avg_specificity=95.39% avg_auc=92.41%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.165774 Test loss=0.289767 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16423948109149933
[5/24] Train loss=0.14725549519062042
[10/24] Train loss=0.173955500125885
[15/24] Train loss=0.1537429839372635
[20/24] Train loss=0.16593892872333527
Test set avg_accuracy=89.10% avg_sensitivity=67.90%, avg_specificity=96.33% avg_auc=92.20%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.164695 Test loss=0.290350 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16412758827209473
[5/24] Train loss=0.15111936628818512
[10/24] Train loss=0.1666167676448822
[15/24] Train loss=0.15392211079597473
[20/24] Train loss=0.15321335196495056
Test set avg_accuracy=88.70% avg_sensitivity=70.71%, avg_specificity=94.83% avg_auc=92.42%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.160609 Test loss=0.292482 Current lr=[0.000156543481933168]

[0/24] Train loss=0.1718081831932068
[5/24] Train loss=0.15111176669597626
[10/24] Train loss=0.15679937601089478
[15/24] Train loss=0.1486358791589737
[20/24] Train loss=0.14804358780384064
Test set avg_accuracy=88.40% avg_sensitivity=62.52%, avg_specificity=97.22% avg_auc=91.68%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.157613 Test loss=0.302586 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1629471480846405
[5/24] Train loss=0.14580415189266205
[10/24] Train loss=0.15628059208393097
[15/24] Train loss=0.1423933207988739
[20/24] Train loss=0.14887359738349915
Test set avg_accuracy=88.10% avg_sensitivity=65.95%, avg_specificity=95.65% avg_auc=91.26%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.154820 Test loss=0.304361 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15837277472019196
[5/24] Train loss=0.14486005902290344
[10/24] Train loss=0.15503108501434326
[15/24] Train loss=0.14123468101024628
[20/24] Train loss=0.1522674262523651
Test set avg_accuracy=88.14% avg_sensitivity=61.34%, avg_specificity=97.28% avg_auc=91.19%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.154374 Test loss=0.312202 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.15565475821495056
[5/24] Train loss=0.14137691259384155
[10/24] Train loss=0.15905101597309113
[15/24] Train loss=0.14579375088214874
[20/24] Train loss=0.15065203607082367
Test set avg_accuracy=88.19% avg_sensitivity=74.40%, avg_specificity=92.89% avg_auc=92.78%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.155073 Test loss=0.293483 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15239447355270386
[5/24] Train loss=0.1441102772951126
[10/24] Train loss=0.15408073365688324
[15/24] Train loss=0.14460071921348572
[20/24] Train loss=0.14997899532318115
Test set avg_accuracy=88.70% avg_sensitivity=65.44%, avg_specificity=96.63% avg_auc=90.33%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.155397 Test loss=0.322879 Current lr=[0.000134135431043539]

[0/24] Train loss=0.16029927134513855
[5/24] Train loss=0.14344066381454468
[10/24] Train loss=0.14987358450889587
[15/24] Train loss=0.1457497924566269
[20/24] Train loss=0.14781317114830017
Test set avg_accuracy=88.36% avg_sensitivity=65.08%, avg_specificity=96.30% avg_auc=92.53%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.154926 Test loss=0.297662 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15681539475917816
[5/24] Train loss=0.1445547640323639
[10/24] Train loss=0.15116606652736664
[15/24] Train loss=0.14342178404331207
[20/24] Train loss=0.14319826662540436
Test set avg_accuracy=88.85% avg_sensitivity=65.34%, avg_specificity=96.87% avg_auc=91.81%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.152793 Test loss=0.294901 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1548788994550705
[5/24] Train loss=0.13611410558223724
[10/24] Train loss=0.15045449137687683
[15/24] Train loss=0.1426386684179306
[20/24] Train loss=0.14641223847866058
Test set avg_accuracy=88.95% avg_sensitivity=66.92%, avg_specificity=96.46% avg_auc=92.24%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.150160 Test loss=0.291932 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.1516764611005783
[5/24] Train loss=0.1391601264476776
[10/24] Train loss=0.1466788649559021
[15/24] Train loss=0.1413082778453827
[20/24] Train loss=0.1483784168958664
Test set avg_accuracy=88.07% avg_sensitivity=72.45%, avg_specificity=93.40% avg_auc=93.37%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.149222 Test loss=0.283853 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1561453640460968
[5/24] Train loss=0.13713786005973816
[10/24] Train loss=0.1571865826845169
[15/24] Train loss=0.1378600150346756
[20/24] Train loss=0.143817737698555
Test set avg_accuracy=88.49% avg_sensitivity=69.94%, avg_specificity=94.81% avg_auc=92.28%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.149220 Test loss=0.296355 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15828081965446472
[5/24] Train loss=0.13388806581497192
[10/24] Train loss=0.14356102049350739
[15/24] Train loss=0.1411200612783432
[20/24] Train loss=0.14033754169940948
Test set avg_accuracy=87.54% avg_sensitivity=68.82%, avg_specificity=93.92% avg_auc=91.91%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.147972 Test loss=0.301575 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.15620042383670807
[5/24] Train loss=0.1342882364988327
[10/24] Train loss=0.14739319682121277
[15/24] Train loss=0.1454365998506546
[20/24] Train loss=0.13772660493850708
Test set avg_accuracy=88.11% avg_sensitivity=68.25%, avg_specificity=94.88% avg_auc=92.40%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.146629 Test loss=0.296777 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15293343365192413
[5/24] Train loss=0.13254240155220032
[10/24] Train loss=0.14477941393852234
[15/24] Train loss=0.14051461219787598
[20/24] Train loss=0.1421770453453064
Test set avg_accuracy=87.93% avg_sensitivity=68.56%, avg_specificity=94.53% avg_auc=92.71%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.147087 Test loss=0.292901 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1569986492395401
[5/24] Train loss=0.13190524280071259
[10/24] Train loss=0.13932165503501892
[15/24] Train loss=0.140469029545784
[20/24] Train loss=0.14016570150852203
Test set avg_accuracy=87.34% avg_sensitivity=72.56%, avg_specificity=92.39% avg_auc=92.66%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.146528 Test loss=0.299164 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15151581168174744
[5/24] Train loss=0.13517716526985168
[10/24] Train loss=0.14191927015781403
[15/24] Train loss=0.1366683542728424
[20/24] Train loss=0.1371738761663437
Test set avg_accuracy=87.80% avg_sensitivity=71.79%, avg_specificity=93.26% avg_auc=93.47%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.143861 Test loss=0.283623 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15184582769870758
[5/24] Train loss=0.1334998458623886
[10/24] Train loss=0.13733161985874176
[15/24] Train loss=0.13661541044712067
[20/24] Train loss=0.14181473851203918
Test set avg_accuracy=88.39% avg_sensitivity=73.32%, avg_specificity=93.52% avg_auc=93.58%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.143629 Test loss=0.282522 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14782322943210602
[5/24] Train loss=0.13260887563228607
[10/24] Train loss=0.1362971067428589
[15/24] Train loss=0.13649149239063263
[20/24] Train loss=0.13842859864234924
Test set avg_accuracy=87.45% avg_sensitivity=67.43%, avg_specificity=94.27% avg_auc=92.40%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.143781 Test loss=0.296901 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14739565551280975
[5/24] Train loss=0.13708677887916565
[10/24] Train loss=0.1398715227842331
[15/24] Train loss=0.12932941317558289
[20/24] Train loss=0.14758092164993286
Test set avg_accuracy=88.46% avg_sensitivity=70.76%, avg_specificity=94.50% avg_auc=92.91%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.142191 Test loss=0.285452 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14634333550930023
[5/24] Train loss=0.12886355817317963
[10/24] Train loss=0.13376322388648987
[15/24] Train loss=0.13801991939544678
[20/24] Train loss=0.13570179045200348
Test set avg_accuracy=88.11% avg_sensitivity=73.68%, avg_specificity=93.03% avg_auc=93.30%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.141466 Test loss=0.290897 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14707879722118378
[5/24] Train loss=0.12740160524845123
[10/24] Train loss=0.13472530245780945
[15/24] Train loss=0.13481591641902924
[20/24] Train loss=0.13795475661754608
Test set avg_accuracy=88.15% avg_sensitivity=73.48%, avg_specificity=93.16% avg_auc=92.81%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.139738 Test loss=0.296711 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1495780646800995
[5/24] Train loss=0.12588009238243103
[10/24] Train loss=0.1351012885570526
[15/24] Train loss=0.12807083129882812
[20/24] Train loss=0.13319233059883118
Test set avg_accuracy=88.19% avg_sensitivity=66.51%, avg_specificity=95.58% avg_auc=91.97%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.137811 Test loss=0.297706 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1455283761024475
[5/24] Train loss=0.1251400262117386
[10/24] Train loss=0.13009631633758545
[15/24] Train loss=0.13002869486808777
[20/24] Train loss=0.13134314119815826
Test set avg_accuracy=87.77% avg_sensitivity=72.35%, avg_specificity=93.03% avg_auc=93.13%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.136978 Test loss=0.288598 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14350755512714386
[5/24] Train loss=0.12500108778476715
[10/24] Train loss=0.12942545115947723
[15/24] Train loss=0.1291254609823227
[20/24] Train loss=0.13020551204681396
Test set avg_accuracy=88.15% avg_sensitivity=73.84%, avg_specificity=93.03% avg_auc=93.21%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.136492 Test loss=0.292086 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14496587216854095
[5/24] Train loss=0.1255992352962494
[10/24] Train loss=0.12922722101211548
[15/24] Train loss=0.12843187153339386
[20/24] Train loss=0.132475346326828
Test set avg_accuracy=88.22% avg_sensitivity=71.84%, avg_specificity=93.80% avg_auc=92.56%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.134755 Test loss=0.296952 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14042162895202637
[5/24] Train loss=0.12320871651172638
[10/24] Train loss=0.12414656579494476
[15/24] Train loss=0.1260097771883011
[20/24] Train loss=0.12773583829402924
Test set avg_accuracy=88.05% avg_sensitivity=72.15%, avg_specificity=93.47% avg_auc=92.80%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.133118 Test loss=0.296872 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13971050083637238
[5/24] Train loss=0.12335711717605591
[10/24] Train loss=0.1295376867055893
[15/24] Train loss=0.1283341497182846
[20/24] Train loss=0.13367138803005219
Test set avg_accuracy=88.12% avg_sensitivity=69.59%, avg_specificity=94.45% avg_auc=92.90%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.133655 Test loss=0.294279 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.14511066675186157
[5/24] Train loss=0.12483938038349152
[10/24] Train loss=0.12604469060897827
[15/24] Train loss=0.13154670596122742
[20/24] Train loss=0.13218097388744354
Test set avg_accuracy=88.19% avg_sensitivity=70.46%, avg_specificity=94.24% avg_auc=92.98%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.133323 Test loss=0.291981 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13906244933605194
[5/24] Train loss=0.12588386237621307
[10/24] Train loss=0.1307550072669983
[15/24] Train loss=0.1243661642074585
[20/24] Train loss=0.12782640755176544
Test set avg_accuracy=87.76% avg_sensitivity=65.28%, avg_specificity=95.43% avg_auc=91.66%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.132557 Test loss=0.306525 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1378195881843567
[5/24] Train loss=0.12343097478151321
[10/24] Train loss=0.12818732857704163
[15/24] Train loss=0.12947922945022583
[20/24] Train loss=0.1293967366218567
Test set avg_accuracy=88.28% avg_sensitivity=69.38%, avg_specificity=94.73% avg_auc=93.29%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.132110 Test loss=0.286120 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13802604377269745
[5/24] Train loss=0.12165657430887222
[10/24] Train loss=0.12510934472084045
[15/24] Train loss=0.12465790659189224
[20/24] Train loss=0.1279284656047821
Test set avg_accuracy=88.35% avg_sensitivity=66.56%, avg_specificity=95.77% avg_auc=92.68%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.130873 Test loss=0.295852 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13722282648086548
[5/24] Train loss=0.12280421704053879
[10/24] Train loss=0.12470640242099762
[15/24] Train loss=0.12557680904865265
[20/24] Train loss=0.12399214506149292
Test set avg_accuracy=88.35% avg_sensitivity=67.49%, avg_specificity=95.46% avg_auc=92.32%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.130623 Test loss=0.297786 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13684210181236267
[5/24] Train loss=0.12395668774843216
[10/24] Train loss=0.12404675781726837
[15/24] Train loss=0.12585611641407013
[20/24] Train loss=0.12527437508106232
Test set avg_accuracy=88.27% avg_sensitivity=66.97%, avg_specificity=95.53% avg_auc=92.85%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.130038 Test loss=0.292262 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1353415846824646
[5/24] Train loss=0.12463534623384476
[10/24] Train loss=0.12277849018573761
[15/24] Train loss=0.12309228628873825
[20/24] Train loss=0.12477874010801315
Test set avg_accuracy=88.28% avg_sensitivity=69.69%, avg_specificity=94.62% avg_auc=92.74%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.130465 Test loss=0.291169 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13324053585529327
[5/24] Train loss=0.1228918582201004
[10/24] Train loss=0.12438765168190002
[15/24] Train loss=0.12301351130008698
[20/24] Train loss=0.12690500915050507
Test set avg_accuracy=87.94% avg_sensitivity=72.76%, avg_specificity=93.12% avg_auc=92.72%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.129719 Test loss=0.294180 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1383807361125946
[5/24] Train loss=0.12048685550689697
[10/24] Train loss=0.12454533576965332
[15/24] Train loss=0.12427352368831635
[20/24] Train loss=0.12672194838523865
Test set avg_accuracy=88.35% avg_sensitivity=73.43%, avg_specificity=93.43% avg_auc=92.55%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.129071 Test loss=0.298579 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13341456651687622
[5/24] Train loss=0.12014924734830856
[10/24] Train loss=0.11996103078126907
[15/24] Train loss=0.12284379452466965
[20/24] Train loss=0.12277401983737946
Test set avg_accuracy=88.32% avg_sensitivity=70.46%, avg_specificity=94.41% avg_auc=92.54%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.127845 Test loss=0.294094 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13521847128868103
[5/24] Train loss=0.12328848242759705
[10/24] Train loss=0.121468186378479
[15/24] Train loss=0.12576337158679962
[20/24] Train loss=0.12371720373630524
Test set avg_accuracy=88.16% avg_sensitivity=71.07%, avg_specificity=93.99% avg_auc=92.51%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.128120 Test loss=0.295319 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.13333240151405334
[5/24] Train loss=0.1231769323348999
[10/24] Train loss=0.12054404616355896
[15/24] Train loss=0.1229458823800087
[20/24] Train loss=0.12744639813899994
Test set avg_accuracy=87.97% avg_sensitivity=72.04%, avg_specificity=93.40% avg_auc=92.72%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.128483 Test loss=0.295281 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13326460123062134
[5/24] Train loss=0.12397503107786179
[10/24] Train loss=0.12449991703033447
[15/24] Train loss=0.11988674849271774
[20/24] Train loss=0.12152964621782303
Test set avg_accuracy=87.54% avg_sensitivity=72.20%, avg_specificity=92.77% avg_auc=92.69%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.127416 Test loss=0.297175 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1327686607837677
[5/24] Train loss=0.12049251049757004
[10/24] Train loss=0.117158442735672
[15/24] Train loss=0.1204184740781784
[20/24] Train loss=0.12068486958742142
Test set avg_accuracy=87.40% avg_sensitivity=71.68%, avg_specificity=92.75% avg_auc=92.64%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.126269 Test loss=0.297918 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1321939378976822
[5/24] Train loss=0.11732546985149384
[10/24] Train loss=0.1180810034275055
[15/24] Train loss=0.11951499432325363
[20/24] Train loss=0.12204193323850632
Test set avg_accuracy=87.49% avg_sensitivity=70.92%, avg_specificity=93.14% avg_auc=92.70%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.125044 Test loss=0.297697 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12981252372264862
[5/24] Train loss=0.1209552064538002
[10/24] Train loss=0.12023494392633438
[15/24] Train loss=0.11884346604347229
[20/24] Train loss=0.11772584915161133
Test set avg_accuracy=87.49% avg_sensitivity=71.79%, avg_specificity=92.84% avg_auc=92.66%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.124445 Test loss=0.297682 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.13265521824359894
[5/24] Train loss=0.11759457737207413
[10/24] Train loss=0.11642002314329147
[15/24] Train loss=0.11571871489286423
[20/24] Train loss=0.11945704370737076
Test set avg_accuracy=87.43% avg_sensitivity=72.61%, avg_specificity=92.49% avg_auc=92.84%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.124092 Test loss=0.297301 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13019965589046478
[5/24] Train loss=0.11656799912452698
[10/24] Train loss=0.11779462546110153
[15/24] Train loss=0.11672592163085938
[20/24] Train loss=0.1204170435667038
Test set avg_accuracy=87.54% avg_sensitivity=70.87%, avg_specificity=93.23% avg_auc=92.83%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.123796 Test loss=0.295439 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13058890402317047
[5/24] Train loss=0.11888973414897919
[10/24] Train loss=0.11777695268392563
[15/24] Train loss=0.11632247269153595
[20/24] Train loss=0.11898688226938248
Test set avg_accuracy=87.45% avg_sensitivity=71.84%, avg_specificity=92.77% avg_auc=92.70%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.123612 Test loss=0.295972 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.13101467490196228
[5/24] Train loss=0.11976215243339539
[10/24] Train loss=0.11894547939300537
[15/24] Train loss=0.11677543818950653
[20/24] Train loss=0.12061674147844315
Test set avg_accuracy=87.71% avg_sensitivity=70.97%, avg_specificity=93.42% avg_auc=92.76%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.122924 Test loss=0.294018 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12956950068473816
[5/24] Train loss=0.11659269034862518
[10/24] Train loss=0.11956465989351273
[15/24] Train loss=0.11432424187660217
[20/24] Train loss=0.11982414871454239
Test set avg_accuracy=87.53% avg_sensitivity=71.68%, avg_specificity=92.93% avg_auc=92.77%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.123115 Test loss=0.294886 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.13181498646736145
[5/24] Train loss=0.11767840385437012
[10/24] Train loss=0.11593183130025864
[15/24] Train loss=0.11954265087842941
[20/24] Train loss=0.12034129351377487
Test set avg_accuracy=87.36% avg_sensitivity=71.22%, avg_specificity=92.86% avg_auc=92.74%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.123143 Test loss=0.295595 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12916134297847748
[5/24] Train loss=0.11671160161495209
[10/24] Train loss=0.1175093725323677
[15/24] Train loss=0.11681849509477615
[20/24] Train loss=0.120026595890522
Test set avg_accuracy=87.42% avg_sensitivity=71.48%, avg_specificity=92.86% avg_auc=92.84%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.122899 Test loss=0.295254 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1284284144639969
[5/24] Train loss=0.11543408036231995
[10/24] Train loss=0.11862917244434357
[15/24] Train loss=0.11885053664445877
[20/24] Train loss=0.12121681869029999
Test set avg_accuracy=87.50% avg_sensitivity=71.48%, avg_specificity=92.96% avg_auc=92.81%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.123125 Test loss=0.295126 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12824825942516327
[5/24] Train loss=0.11618106812238693
[10/24] Train loss=0.11768225580453873
[15/24] Train loss=0.11489611864089966
[20/24] Train loss=0.12013917416334152
Test set avg_accuracy=87.43% avg_sensitivity=71.27%, avg_specificity=92.95% avg_auc=92.81%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.123211 Test loss=0.295275 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1295052319765091
[5/24] Train loss=0.11740482598543167
[10/24] Train loss=0.11913730204105377
[15/24] Train loss=0.11691280454397202
[20/24] Train loss=0.11931076645851135
Test set avg_accuracy=87.45% avg_sensitivity=71.38%, avg_specificity=92.93% avg_auc=92.83%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.122553 Test loss=0.295350 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1289818286895752
[5/24] Train loss=0.11664208024740219
[10/24] Train loss=0.11730803549289703
[15/24] Train loss=0.11711310595273972
[20/24] Train loss=0.12069225311279297
Test set avg_accuracy=87.46% avg_sensitivity=71.43%, avg_specificity=92.93% avg_auc=92.79%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.122794 Test loss=0.295482 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12958396971225739
[5/24] Train loss=0.1158260777592659
[10/24] Train loss=0.11509031802415848
[15/24] Train loss=0.1197514533996582
[20/24] Train loss=0.12201201170682907
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.47% avg_sensitivity=71.38%, avg_specificity=92.96% avg_auc=92.80%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.122887 Test loss=0.295433 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=89.56% sen=76.75%, spe=93.92%, auc=93.80%!
Fold[5] Avg_overlap=0.71%(0.20404274027562197)
[0/24] Train loss=0.7328906059265137
[5/24] Train loss=0.7392417192459106
[10/24] Train loss=0.7215343117713928
[15/24] Train loss=0.7209357023239136
[20/24] Train loss=0.7051436305046082
Test set avg_accuracy=60.87% avg_sensitivity=63.72%, avg_specificity=59.81% avg_auc=57.04%
Best model saved!! Metric=-84.55616329650852!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.722954 Test loss=0.677687 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7015998959541321
[5/24] Train loss=0.693489134311676
[10/24] Train loss=0.6959695816040039
[15/24] Train loss=0.6811368465423584
[20/24] Train loss=0.6702426075935364
Test set avg_accuracy=71.94% avg_sensitivity=65.83%, avg_specificity=74.21% avg_auc=70.49%
Best model saved!! Metric=-43.517581025251346!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.691741 Test loss=0.608261 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6615171432495117
[5/24] Train loss=0.6727910041809082
[10/24] Train loss=0.6717163920402527
[15/24] Train loss=0.6438948512077332
[20/24] Train loss=0.6460887789726257
Test set avg_accuracy=75.39% avg_sensitivity=71.59%, avg_specificity=76.80% avg_auc=76.99%
Best model saved!! Metric=-25.22547640366234!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.662020 Test loss=0.572368 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6383137106895447
[5/24] Train loss=0.6475882530212402
[10/24] Train loss=0.6383367776870728
[15/24] Train loss=0.6247055530548096
[20/24] Train loss=0.6135662198066711
Test set avg_accuracy=76.22% avg_sensitivity=75.53%, avg_specificity=76.48% avg_auc=80.74%
Best model saved!! Metric=-17.026247119149176!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.635539 Test loss=0.543291 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6057906150817871
[5/24] Train loss=0.6092330813407898
[10/24] Train loss=0.6088014245033264
[15/24] Train loss=0.5897055864334106
[20/24] Train loss=0.5867537260055542
Test set avg_accuracy=78.10% avg_sensitivity=75.24%, avg_specificity=79.16% avg_auc=83.28%
Best model saved!! Metric=-10.21956435698975!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.604452 Test loss=0.512174 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5721490383148193
[5/24] Train loss=0.5664137005805969
[10/24] Train loss=0.583081066608429
[15/24] Train loss=0.5559401512145996
[20/24] Train loss=0.5463969111442566
Test set avg_accuracy=80.13% avg_sensitivity=77.26%, avg_specificity=81.20% avg_auc=85.52%
Best model saved!! Metric=-1.8969323168980594!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.574325 Test loss=0.482171 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.547643780708313
[5/24] Train loss=0.5410842895507812
[10/24] Train loss=0.5514647364616394
[15/24] Train loss=0.5263227224349976
[20/24] Train loss=0.5202229022979736
Test set avg_accuracy=80.98% avg_sensitivity=77.16%, avg_specificity=82.40% avg_auc=87.23%
Best model saved!! Metric=1.7598849033069968!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.544027 Test loss=0.455952 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5162867307662964
[5/24] Train loss=0.5121574997901917
[10/24] Train loss=0.526400089263916
[15/24] Train loss=0.4983103275299072
[20/24] Train loss=0.4810153543949127
Test set avg_accuracy=83.33% avg_sensitivity=76.78%, avg_specificity=85.78% avg_auc=88.72%
Best model saved!! Metric=8.604060367587294!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.513308 Test loss=0.427383 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.48092132806777954
[5/24] Train loss=0.48740389943122864
[10/24] Train loss=0.4911005198955536
[15/24] Train loss=0.47115451097488403
[20/24] Train loss=0.454546183347702
Test set avg_accuracy=84.31% avg_sensitivity=79.94%, avg_specificity=85.94% avg_auc=89.90%
Best model saved!! Metric=14.091779726270303!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.483553 Test loss=0.410689 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4620991051197052
[5/24] Train loss=0.4572884440422058
[10/24] Train loss=0.46404626965522766
[15/24] Train loss=0.4396088123321533
[20/24] Train loss=0.42671114206314087
Test set avg_accuracy=85.53% avg_sensitivity=80.23%, avg_specificity=87.51% avg_auc=90.85%
Best model saved!! Metric=18.126912822492955!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.456969 Test loss=0.389221 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4416789710521698
[5/24] Train loss=0.42994245886802673
[10/24] Train loss=0.4401083290576935
[15/24] Train loss=0.418857216835022
[20/24] Train loss=0.4038921892642975
Test set avg_accuracy=86.22% avg_sensitivity=78.45%, avg_specificity=89.12% avg_auc=91.52%
Best model saved!! Metric=19.31549650359203!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.432004 Test loss=0.368982 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4110344648361206
[5/24] Train loss=0.4049990475177765
[10/24] Train loss=0.4119536876678467
[15/24] Train loss=0.39250171184539795
[20/24] Train loss=0.3752862513065338
Test set avg_accuracy=87.57% avg_sensitivity=77.16%, avg_specificity=91.44% avg_auc=92.17%
Best model saved!! Metric=22.332619248045035!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.408690 Test loss=0.348002 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3842741847038269
[5/24] Train loss=0.38992393016815186
[10/24] Train loss=0.3898053765296936
[15/24] Train loss=0.3760816156864166
[20/24] Train loss=0.35846763849258423
Test set avg_accuracy=87.94% avg_sensitivity=74.81%, avg_specificity=92.83% avg_auc=92.53%
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.388617 Test loss=0.331405 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.3643074035644531
[5/24] Train loss=0.3673590421676636
[10/24] Train loss=0.3747517466545105
[15/24] Train loss=0.360143780708313
[20/24] Train loss=0.3386985659599304
Test set avg_accuracy=87.86% avg_sensitivity=76.39%, avg_specificity=92.14% avg_auc=92.98%
Best model saved!! Metric=23.370591189232584!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.371083 Test loss=0.321410 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3509857654571533
[5/24] Train loss=0.35177674889564514
[10/24] Train loss=0.3575449585914612
[15/24] Train loss=0.3474295437335968
[20/24] Train loss=0.3268449902534485
Test set avg_accuracy=88.45% avg_sensitivity=79.37%, avg_specificity=91.83% avg_auc=93.36%
Best model saved!! Metric=27.0091358435065!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.354895 Test loss=0.315263 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.3401627540588379
[5/24] Train loss=0.3347805142402649
[10/24] Train loss=0.3400411009788513
[15/24] Train loss=0.33164331316947937
[20/24] Train loss=0.3097207546234131
Test set avg_accuracy=88.79% avg_sensitivity=75.62%, avg_specificity=93.69% avg_auc=93.55%
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.340131 Test loss=0.299143 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3242036700248718
[5/24] Train loss=0.3276672661304474
[10/24] Train loss=0.33055758476257324
[15/24] Train loss=0.3195708096027374
[20/24] Train loss=0.2946847379207611
Test set avg_accuracy=88.93% avg_sensitivity=76.54%, avg_specificity=93.55% avg_auc=93.76%
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.328806 Test loss=0.294900 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3134291470050812
[5/24] Train loss=0.3150217831134796
[10/24] Train loss=0.32685503363609314
[15/24] Train loss=0.3042653203010559
[20/24] Train loss=0.28401440382003784
Test set avg_accuracy=88.93% avg_sensitivity=79.17%, avg_specificity=92.57% avg_auc=93.84%
Best model saved!! Metric=28.513684463001837!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.318790 Test loss=0.292529 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3043460249900818
[5/24] Train loss=0.3130320906639099
[10/24] Train loss=0.3157729506492615
[15/24] Train loss=0.3020003139972687
[20/24] Train loss=0.2778262197971344
Test set avg_accuracy=89.36% avg_sensitivity=76.73%, avg_specificity=94.07% avg_auc=94.06%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.309860 Test loss=0.284370 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29570338129997253
[5/24] Train loss=0.29559510946273804
[10/24] Train loss=0.30290478467941284
[15/24] Train loss=0.2902657389640808
[20/24] Train loss=0.2666172385215759
Test set avg_accuracy=89.48% avg_sensitivity=78.55%, avg_specificity=93.55% avg_auc=94.02%
Best model saved!! Metric=29.594564421300845!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.300888 Test loss=0.284405 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28230753540992737
[5/24] Train loss=0.29199543595314026
[10/24] Train loss=0.29956814646720886
[15/24] Train loss=0.2892892062664032
[20/24] Train loss=0.262472003698349
Test set avg_accuracy=89.74% avg_sensitivity=75.62%, avg_specificity=95.00% avg_auc=94.14%
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.292827 Test loss=0.275492 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.28158247470855713
[5/24] Train loss=0.28319403529167175
[10/24] Train loss=0.2914641499519348
[15/24] Train loss=0.2798779308795929
[20/24] Train loss=0.25168994069099426
Test set avg_accuracy=89.69% avg_sensitivity=75.05%, avg_specificity=95.14% avg_auc=94.06%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.285099 Test loss=0.270688 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2736061215400696
[5/24] Train loss=0.27427953481674194
[10/24] Train loss=0.28520289063453674
[15/24] Train loss=0.27809250354766846
[20/24] Train loss=0.24308088421821594
Test set avg_accuracy=88.71% avg_sensitivity=65.02%, avg_specificity=97.53% avg_auc=93.53%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.277899 Test loss=0.288101 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.27114734053611755
[5/24] Train loss=0.2727755308151245
[10/24] Train loss=0.27990642189979553
[15/24] Train loss=0.27018213272094727
[20/24] Train loss=0.23492491245269775
Test set avg_accuracy=89.11% avg_sensitivity=68.14%, avg_specificity=96.93% avg_auc=93.89%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.274134 Test loss=0.276054 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2624179422855377
[5/24] Train loss=0.27362260222435
[10/24] Train loss=0.2800837457180023
[15/24] Train loss=0.26491183042526245
[20/24] Train loss=0.2322017252445221
Test set avg_accuracy=89.57% avg_sensitivity=71.93%, avg_specificity=96.14% avg_auc=94.09%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.268657 Test loss=0.267181 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.252580463886261
[5/24] Train loss=0.26227691769599915
[10/24] Train loss=0.2796764373779297
[15/24] Train loss=0.25867074728012085
[20/24] Train loss=0.22646859288215637
Test set avg_accuracy=87.73% avg_sensitivity=60.75%, avg_specificity=97.78% avg_auc=93.07%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.262837 Test loss=0.298770 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2547391355037689
[5/24] Train loss=0.2573338747024536
[10/24] Train loss=0.27034664154052734
[15/24] Train loss=0.25457632541656494
[20/24] Train loss=0.2205561101436615
Test set avg_accuracy=90.08% avg_sensitivity=74.04%, avg_specificity=96.05% avg_auc=94.19%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.258778 Test loss=0.267627 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.24069097638130188
[5/24] Train loss=0.2477014660835266
[10/24] Train loss=0.2609465718269348
[15/24] Train loss=0.25068822503089905
[20/24] Train loss=0.22068120539188385
Test set avg_accuracy=88.45% avg_sensitivity=65.79%, avg_specificity=96.89% avg_auc=93.59%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.251737 Test loss=0.283414 Current lr=[0.000210185142098938]

[0/24] Train loss=0.23456192016601562
[5/24] Train loss=0.23930734395980835
[10/24] Train loss=0.26298922300338745
[15/24] Train loss=0.25547751784324646
[20/24] Train loss=0.2187952846288681
Test set avg_accuracy=81.59% avg_sensitivity=34.84%, avg_specificity=99.00% avg_auc=90.35%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.246603 Test loss=0.412926 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.25223320722579956
[5/24] Train loss=0.2383306622505188
[10/24] Train loss=0.25676897168159485
[15/24] Train loss=0.24844412505626678
[20/24] Train loss=0.20757938921451569
Test set avg_accuracy=87.08% avg_sensitivity=57.77%, avg_specificity=98.00% avg_auc=92.47%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.243107 Test loss=0.314359 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.24066857993602753
[5/24] Train loss=0.24429954588413239
[10/24] Train loss=0.2550314962863922
[15/24] Train loss=0.24070866405963898
[20/24] Train loss=0.2074802815914154
Test set avg_accuracy=84.44% avg_sensitivity=46.45%, avg_specificity=98.59% avg_auc=90.93%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.239225 Test loss=0.368943 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.23795008659362793
[5/24] Train loss=0.23678387701511383
[10/24] Train loss=0.24721302092075348
[15/24] Train loss=0.24930457770824432
[20/24] Train loss=0.20407667756080627
Test set avg_accuracy=85.22% avg_sensitivity=49.76%, avg_specificity=98.43% avg_auc=91.46%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.238887 Test loss=0.367645 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.22073057293891907
[5/24] Train loss=0.2294030338525772
[10/24] Train loss=0.25078085064888
[15/24] Train loss=0.24293413758277893
[20/24] Train loss=0.20337016880512238
Test set avg_accuracy=89.23% avg_sensitivity=67.61%, avg_specificity=97.28% avg_auc=93.95%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.235485 Test loss=0.271043 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2193126380443573
[5/24] Train loss=0.2244543582201004
[10/24] Train loss=0.23978549242019653
[15/24] Train loss=0.2299509197473526
[20/24] Train loss=0.2090240865945816
Test set avg_accuracy=89.51% avg_sensitivity=70.06%, avg_specificity=96.75% avg_auc=94.22%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.231323 Test loss=0.266595 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.2253796011209488
[5/24] Train loss=0.2188383787870407
[10/24] Train loss=0.23736856877803802
[15/24] Train loss=0.2287190854549408
[20/24] Train loss=0.20409941673278809
Test set avg_accuracy=89.23% avg_sensitivity=73.80%, avg_specificity=94.98% avg_auc=93.72%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.226544 Test loss=0.270282 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2167494148015976
[5/24] Train loss=0.20498716831207275
[10/24] Train loss=0.2375764399766922
[15/24] Train loss=0.23362135887145996
[20/24] Train loss=0.19809705018997192
Test set avg_accuracy=90.03% avg_sensitivity=77.69%, avg_specificity=94.62% avg_auc=94.39%
Best model saved!! Metric=30.722760189219798!!
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.226707 Test loss=0.258318 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.21644285321235657
[5/24] Train loss=0.22121675312519073
[10/24] Train loss=0.2308751791715622
[15/24] Train loss=0.22087788581848145
[20/24] Train loss=0.20096473395824432
Test set avg_accuracy=88.29% avg_sensitivity=64.40%, avg_specificity=97.19% avg_auc=92.66%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.221198 Test loss=0.299738 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.21285554766654968
[5/24] Train loss=0.22046811878681183
[10/24] Train loss=0.23294517397880554
[15/24] Train loss=0.23172707855701447
[20/24] Train loss=0.19638143479824066
Test set avg_accuracy=83.26% avg_sensitivity=42.90%, avg_specificity=98.28% avg_auc=91.40%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.221315 Test loss=0.374460 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.21372637152671814
[5/24] Train loss=0.20000958442687988
[10/24] Train loss=0.24467259645462036
[15/24] Train loss=0.2275622934103012
[20/24] Train loss=0.19361083209514618
Test set avg_accuracy=79.75% avg_sensitivity=28.89%, avg_specificity=98.70% avg_auc=83.10%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.221972 Test loss=0.490901 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.22857709228992462
[5/24] Train loss=0.20836590230464935
[10/24] Train loss=0.23832868039608002
[15/24] Train loss=0.20579886436462402
[20/24] Train loss=0.19088202714920044
Test set avg_accuracy=81.41% avg_sensitivity=35.46%, avg_specificity=98.52% avg_auc=88.91%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.219942 Test loss=0.445412 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21733330190181732
[5/24] Train loss=0.20198971033096313
[10/24] Train loss=0.21239669620990753
[15/24] Train loss=0.2050498127937317
[20/24] Train loss=0.18923376500606537
Test set avg_accuracy=88.07% avg_sensitivity=63.15%, avg_specificity=97.36% avg_auc=92.21%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.209087 Test loss=0.311113 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.21277950704097748
[5/24] Train loss=0.2025993913412094
[10/24] Train loss=0.22462686896324158
[15/24] Train loss=0.205853670835495
[20/24] Train loss=0.19070139527320862
Test set avg_accuracy=75.49% avg_sensitivity=10.08%, avg_specificity=99.86% avg_auc=83.87%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.213286 Test loss=0.645194 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21077357232570648
[5/24] Train loss=0.20104368031024933
[10/24] Train loss=0.20770852267742157
[15/24] Train loss=0.2022274285554886
[20/24] Train loss=0.18548060953617096
Test set avg_accuracy=88.72% avg_sensitivity=68.71%, avg_specificity=96.18% avg_auc=92.34%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.206581 Test loss=0.300116 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.20140811800956726
[5/24] Train loss=0.2066858857870102
[10/24] Train loss=0.2211022824048996
[15/24] Train loss=0.2002379149198532
[20/24] Train loss=0.19155669212341309
Test set avg_accuracy=89.65% avg_sensitivity=74.18%, avg_specificity=95.41% avg_auc=93.06%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.211183 Test loss=0.279100 Current lr=[0.00029967723776099]

[0/24] Train loss=0.20508471131324768
[5/24] Train loss=0.1898113191127777
[10/24] Train loss=0.2100393921136856
[15/24] Train loss=0.20883172750473022
[20/24] Train loss=0.18414002656936646
Test set avg_accuracy=83.45% avg_sensitivity=43.04%, avg_specificity=98.50% avg_auc=88.39%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.208354 Test loss=0.461544 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.19923259317874908
[5/24] Train loss=0.19855232536792755
[10/24] Train loss=0.20330533385276794
[15/24] Train loss=0.20301851630210876
[20/24] Train loss=0.171113982796669
Test set avg_accuracy=88.66% avg_sensitivity=80.18%, avg_specificity=91.82% avg_auc=93.61%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.205249 Test loss=0.277905 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2025420069694519
[5/24] Train loss=0.18944363296031952
[10/24] Train loss=0.21790403127670288
[15/24] Train loss=0.20990662276744843
[20/24] Train loss=0.17444032430648804
Test set avg_accuracy=89.02% avg_sensitivity=75.05%, avg_specificity=94.23% avg_auc=92.87%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.212176 Test loss=0.287741 Current lr=[0.000299720220882401]

[0/24] Train loss=0.2110276222229004
[5/24] Train loss=0.18288330733776093
[10/24] Train loss=0.21298748254776
[15/24] Train loss=0.2061060070991516
[20/24] Train loss=0.17575685679912567
Test set avg_accuracy=87.83% avg_sensitivity=81.33%, avg_specificity=90.24% avg_auc=93.10%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.202247 Test loss=0.304672 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.19816622138023376
[5/24] Train loss=0.1918262541294098
[10/24] Train loss=0.2078532576560974
[15/24] Train loss=0.20843850076198578
[20/24] Train loss=0.18076415359973907
Test set avg_accuracy=88.89% avg_sensitivity=80.76%, avg_specificity=91.92% avg_auc=93.59%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.203663 Test loss=0.289771 Current lr=[0.000298904600941902]

[0/24] Train loss=0.2090217024087906
[5/24] Train loss=0.1834820806980133
[10/24] Train loss=0.20964621007442474
[15/24] Train loss=0.21958327293395996
[20/24] Train loss=0.17390240728855133
Test set avg_accuracy=86.33% avg_sensitivity=82.97%, avg_specificity=87.58% avg_auc=92.77%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.203348 Test loss=0.324804 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.19642356038093567
[5/24] Train loss=0.1872745156288147
[10/24] Train loss=0.21138903498649597
[15/24] Train loss=0.20361296832561493
[20/24] Train loss=0.1803165078163147
Test set avg_accuracy=87.34% avg_sensitivity=82.77%, avg_specificity=89.05% avg_auc=93.12%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.200081 Test loss=0.309132 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19698862731456757
[5/24] Train loss=0.19142217934131622
[10/24] Train loss=0.21646548807621002
[15/24] Train loss=0.19573235511779785
[20/24] Train loss=0.17494826018810272
Test set avg_accuracy=86.98% avg_sensitivity=57.25%, avg_specificity=98.05% avg_auc=90.77%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.197913 Test loss=0.337219 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2093140333890915
[5/24] Train loss=0.18204545974731445
[10/24] Train loss=0.19708111882209778
[15/24] Train loss=0.18892160058021545
[20/24] Train loss=0.1883670538663864
Test set avg_accuracy=88.76% avg_sensitivity=66.79%, avg_specificity=96.94% avg_auc=92.74%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.196308 Test loss=0.289482 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.2020660936832428
[5/24] Train loss=0.17622309923171997
[10/24] Train loss=0.19911828637123108
[15/24] Train loss=0.19927054643630981
[20/24] Train loss=0.16985026001930237
Test set avg_accuracy=88.82% avg_sensitivity=69.05%, avg_specificity=96.18% avg_auc=92.11%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.195000 Test loss=0.302016 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18119625747203827
[5/24] Train loss=0.17683179676532745
[10/24] Train loss=0.19460201263427734
[15/24] Train loss=0.1788678616285324
[20/24] Train loss=0.1661003828048706
Test set avg_accuracy=89.23% avg_sensitivity=79.46%, avg_specificity=92.87% avg_auc=93.48%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.189613 Test loss=0.278523 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.1908554583787918
[5/24] Train loss=0.17985178530216217
[10/24] Train loss=0.1846071034669876
[15/24] Train loss=0.18530024588108063
[20/24] Train loss=0.16933052241802216
Test set avg_accuracy=87.80% avg_sensitivity=80.90%, avg_specificity=90.37% avg_auc=93.59%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.191172 Test loss=0.297686 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.19731175899505615
[5/24] Train loss=0.18567855656147003
[10/24] Train loss=0.20081709325313568
[15/24] Train loss=0.18194876611232758
[20/24] Train loss=0.1600269377231598
Test set avg_accuracy=87.50% avg_sensitivity=81.77%, avg_specificity=89.64% avg_auc=93.18%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.192170 Test loss=0.302170 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18942885100841522
[5/24] Train loss=0.1880611777305603
[10/24] Train loss=0.19079400599002838
[15/24] Train loss=0.18849696218967438
[20/24] Train loss=0.17066584527492523
Test set avg_accuracy=88.55% avg_sensitivity=79.65%, avg_specificity=91.87% avg_auc=93.56%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.189533 Test loss=0.284284 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18365143239498138
[5/24] Train loss=0.1709253191947937
[10/24] Train loss=0.20164963603019714
[15/24] Train loss=0.18865154683589935
[20/24] Train loss=0.1797695904970169
Test set avg_accuracy=89.09% avg_sensitivity=72.98%, avg_specificity=95.09% avg_auc=92.64%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.189344 Test loss=0.287503 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.18691809475421906
[5/24] Train loss=0.1790841519832611
[10/24] Train loss=0.19633470475673676
[15/24] Train loss=0.17857494950294495
[20/24] Train loss=0.16323630511760712
Test set avg_accuracy=89.21% avg_sensitivity=78.69%, avg_specificity=93.12% avg_auc=93.47%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.185748 Test loss=0.279035 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18303336203098297
[5/24] Train loss=0.17371690273284912
[10/24] Train loss=0.17904981970787048
[15/24] Train loss=0.184801384806633
[20/24] Train loss=0.164882630109787
Test set avg_accuracy=85.99% avg_sensitivity=83.01%, avg_specificity=87.10% avg_auc=92.73%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.183167 Test loss=0.331856 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18339747190475464
[5/24] Train loss=0.17379365861415863
[10/24] Train loss=0.1776183545589447
[15/24] Train loss=0.1802583783864975
[20/24] Train loss=0.17905859649181366
Test set avg_accuracy=87.66% avg_sensitivity=82.20%, avg_specificity=89.69% avg_auc=93.44%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.182948 Test loss=0.296372 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18602514266967773
[5/24] Train loss=0.17277255654335022
[10/24] Train loss=0.19128179550170898
[15/24] Train loss=0.17459721863269806
[20/24] Train loss=0.16370424628257751
Test set avg_accuracy=88.23% avg_sensitivity=79.65%, avg_specificity=91.42% avg_auc=93.23%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.184540 Test loss=0.289366 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.1802375614643097
[5/24] Train loss=0.1753714680671692
[10/24] Train loss=0.19184574484825134
[15/24] Train loss=0.17818300426006317
[20/24] Train loss=0.16033624112606049
Test set avg_accuracy=87.94% avg_sensitivity=83.25%, avg_specificity=89.69% avg_auc=93.15%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.184254 Test loss=0.304564 Current lr=[0.000276307469034998]

[0/24] Train loss=0.1829342097043991
[5/24] Train loss=0.17870324850082397
[10/24] Train loss=0.19208043813705444
[15/24] Train loss=0.18455681204795837
[20/24] Train loss=0.15904437005519867
Test set avg_accuracy=88.54% avg_sensitivity=82.39%, avg_specificity=90.83% avg_auc=93.31%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.181089 Test loss=0.288601 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18045128881931305
[5/24] Train loss=0.1666482836008072
[10/24] Train loss=0.18470025062561035
[15/24] Train loss=0.1689438372850418
[20/24] Train loss=0.15604715049266815
Test set avg_accuracy=88.70% avg_sensitivity=69.00%, avg_specificity=96.03% avg_auc=92.37%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.174285 Test loss=0.292311 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.17370301485061646
[5/24] Train loss=0.16324543952941895
[10/24] Train loss=0.1717144101858139
[15/24] Train loss=0.1768326461315155
[20/24] Train loss=0.16266345977783203
Test set avg_accuracy=86.12% avg_sensitivity=81.91%, avg_specificity=87.69% avg_auc=91.24%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.177327 Test loss=0.345801 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17924322187900543
[5/24] Train loss=0.16215649247169495
[10/24] Train loss=0.17527271807193756
[15/24] Train loss=0.17013734579086304
[20/24] Train loss=0.15648239850997925
Test set avg_accuracy=89.02% avg_sensitivity=78.74%, avg_specificity=92.85% avg_auc=92.98%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.176066 Test loss=0.289213 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1747979372739792
[5/24] Train loss=0.17070406675338745
[10/24] Train loss=0.18050739169120789
[15/24] Train loss=0.16845287382602692
[20/24] Train loss=0.15839676558971405
Test set avg_accuracy=88.91% avg_sensitivity=72.79%, avg_specificity=94.91% avg_auc=91.53%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.175473 Test loss=0.297490 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17780561745166779
[5/24] Train loss=0.17156188189983368
[10/24] Train loss=0.17800240218639374
[15/24] Train loss=0.17124933004379272
[20/24] Train loss=0.15653309226036072
Test set avg_accuracy=88.93% avg_sensitivity=77.64%, avg_specificity=93.14% avg_auc=92.17%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.173507 Test loss=0.303178 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.18712539970874786
[5/24] Train loss=0.17788030207157135
[10/24] Train loss=0.16033414006233215
[15/24] Train loss=0.16960585117340088
[20/24] Train loss=0.14887696504592896
Test set avg_accuracy=86.46% avg_sensitivity=55.95%, avg_specificity=97.82% avg_auc=87.55%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.175017 Test loss=0.379922 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1777290254831314
[5/24] Train loss=0.1650441288948059
[10/24] Train loss=0.17861256003379822
[15/24] Train loss=0.17886270582675934
[20/24] Train loss=0.15470381081104279
Test set avg_accuracy=89.65% avg_sensitivity=76.82%, avg_specificity=94.42% avg_auc=93.42%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.171179 Test loss=0.280270 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1628624051809311
[5/24] Train loss=0.1596112698316574
[10/24] Train loss=0.15647593140602112
[15/24] Train loss=0.16573414206504822
[20/24] Train loss=0.15390892326831818
Test set avg_accuracy=89.57% avg_sensitivity=73.13%, avg_specificity=95.69% avg_auc=91.29%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.167913 Test loss=0.298033 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.17192360758781433
[5/24] Train loss=0.15887810289859772
[10/24] Train loss=0.15945622324943542
[15/24] Train loss=0.1688385158777237
[20/24] Train loss=0.15600010752677917
Test set avg_accuracy=89.21% avg_sensitivity=77.88%, avg_specificity=93.42% avg_auc=93.62%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.166885 Test loss=0.281724 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16840913891792297
[5/24] Train loss=0.15922589600086212
[10/24] Train loss=0.17399120330810547
[15/24] Train loss=0.1631549447774887
[20/24] Train loss=0.14255061745643616
Test set avg_accuracy=88.70% avg_sensitivity=69.72%, avg_specificity=95.76% avg_auc=91.24%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.167749 Test loss=0.312180 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17100660502910614
[5/24] Train loss=0.15841162204742432
[10/24] Train loss=0.16443657875061035
[15/24] Train loss=0.1699119359254837
[20/24] Train loss=0.15422245860099792
Test set avg_accuracy=88.72% avg_sensitivity=76.78%, avg_specificity=93.17% avg_auc=92.10%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.171187 Test loss=0.294335 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.19531217217445374
[5/24] Train loss=0.1662888526916504
[10/24] Train loss=0.18625958263874054
[15/24] Train loss=0.17662176489830017
[20/24] Train loss=0.15230974555015564
Test set avg_accuracy=89.09% avg_sensitivity=70.15%, avg_specificity=96.14% avg_auc=92.10%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.173573 Test loss=0.293522 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.16928435862064362
[5/24] Train loss=0.1629861295223236
[10/24] Train loss=0.1713433861732483
[15/24] Train loss=0.16802451014518738
[20/24] Train loss=0.1422475278377533
Test set avg_accuracy=89.61% avg_sensitivity=70.78%, avg_specificity=96.62% avg_auc=92.49%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.166496 Test loss=0.287514 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16620615124702454
[5/24] Train loss=0.16032086312770844
[10/24] Train loss=0.1835823953151703
[15/24] Train loss=0.17164389789104462
[20/24] Train loss=0.15319062769412994
Test set avg_accuracy=88.65% avg_sensitivity=76.97%, avg_specificity=92.99% avg_auc=91.73%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.167627 Test loss=0.311800 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17234213650226593
[5/24] Train loss=0.15552929043769836
[10/24] Train loss=0.1584886759519577
[15/24] Train loss=0.16384942829608917
[20/24] Train loss=0.1554144322872162
Test set avg_accuracy=88.57% avg_sensitivity=79.80%, avg_specificity=91.83% avg_auc=93.33%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.164979 Test loss=0.288567 Current lr=[0.000224838296036774]

[0/24] Train loss=0.16275310516357422
[5/24] Train loss=0.1555856317281723
[10/24] Train loss=0.1602238118648529
[15/24] Train loss=0.16390524804592133
[20/24] Train loss=0.14897601306438446
Test set avg_accuracy=88.93% avg_sensitivity=72.26%, avg_specificity=95.14% avg_auc=92.45%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.165847 Test loss=0.289142 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.1683163195848465
[5/24] Train loss=0.16297495365142822
[10/24] Train loss=0.16790461540222168
[15/24] Train loss=0.16301029920578003
[20/24] Train loss=0.14724035561084747
Test set avg_accuracy=88.29% avg_sensitivity=78.69%, avg_specificity=91.87% avg_auc=92.65%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.167225 Test loss=0.305180 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.16849976778030396
[5/24] Train loss=0.1558832973241806
[10/24] Train loss=0.16180065274238586
[15/24] Train loss=0.1613617092370987
[20/24] Train loss=0.14687922596931458
Test set avg_accuracy=88.79% avg_sensitivity=70.83%, avg_specificity=95.48% avg_auc=91.87%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.165004 Test loss=0.300048 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1655186265707016
[5/24] Train loss=0.15662187337875366
[10/24] Train loss=0.15917356312274933
[15/24] Train loss=0.16056697070598602
[20/24] Train loss=0.14922474324703217
Test set avg_accuracy=88.55% avg_sensitivity=77.40%, avg_specificity=92.71% avg_auc=93.07%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.166654 Test loss=0.295031 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.1659146547317505
[5/24] Train loss=0.16486144065856934
[10/24] Train loss=0.17642080783843994
[15/24] Train loss=0.1588178128004074
[20/24] Train loss=0.14711622893810272
Test set avg_accuracy=88.46% avg_sensitivity=78.45%, avg_specificity=92.19% avg_auc=92.74%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.163736 Test loss=0.294049 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.1658201366662979
[5/24] Train loss=0.15913993120193481
[10/24] Train loss=0.1617811918258667
[15/24] Train loss=0.15763382613658905
[20/24] Train loss=0.15179508924484253
Test set avg_accuracy=85.17% avg_sensitivity=84.84%, avg_specificity=85.29% avg_auc=91.21%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.162731 Test loss=0.375389 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.16263264417648315
[5/24] Train loss=0.15834158658981323
[10/24] Train loss=0.15914736688137054
[15/24] Train loss=0.1637057065963745
[20/24] Train loss=0.14964111149311066
Test set avg_accuracy=88.92% avg_sensitivity=76.87%, avg_specificity=93.41% avg_auc=92.79%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.165416 Test loss=0.291274 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.16491584479808807
[5/24] Train loss=0.15398822724819183
[10/24] Train loss=0.1632956564426422
[15/24] Train loss=0.15342094004154205
[20/24] Train loss=0.14592556655406952
Test set avg_accuracy=89.45% avg_sensitivity=74.14%, avg_specificity=95.16% avg_auc=91.37%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.161049 Test loss=0.298388 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.159652978181839
[5/24] Train loss=0.15375599265098572
[10/24] Train loss=0.1568780392408371
[15/24] Train loss=0.1647937297821045
[20/24] Train loss=0.1430835872888565
Test set avg_accuracy=89.21% avg_sensitivity=74.09%, avg_specificity=94.84% avg_auc=92.27%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.163694 Test loss=0.292172 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.1625269055366516
[5/24] Train loss=0.15465329587459564
[10/24] Train loss=0.1574186384677887
[15/24] Train loss=0.152398020029068
[20/24] Train loss=0.15765593945980072
Test set avg_accuracy=84.61% avg_sensitivity=85.08%, avg_specificity=84.44% avg_auc=91.49%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.165006 Test loss=0.383814 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1627117246389389
[5/24] Train loss=0.15494923293590546
[10/24] Train loss=0.15544752776622772
[15/24] Train loss=0.15768328309059143
[20/24] Train loss=0.1519274115562439
Test set avg_accuracy=88.33% avg_sensitivity=83.25%, avg_specificity=90.23% avg_auc=92.81%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.161815 Test loss=0.302310 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16261887550354004
[5/24] Train loss=0.15371090173721313
[10/24] Train loss=0.15494388341903687
[15/24] Train loss=0.17475943267345428
[20/24] Train loss=0.14840644598007202
Test set avg_accuracy=89.09% avg_sensitivity=69.05%, avg_specificity=96.55% avg_auc=92.44%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.162468 Test loss=0.289431 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.16475847363471985
[5/24] Train loss=0.1556931436061859
[10/24] Train loss=0.16090089082717896
[15/24] Train loss=0.1626274138689041
[20/24] Train loss=0.1409461349248886
Test set avg_accuracy=86.88% avg_sensitivity=58.73%, avg_specificity=97.36% avg_auc=89.57%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.160606 Test loss=0.339794 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16383197903633118
[5/24] Train loss=0.1546412855386734
[10/24] Train loss=0.16086414456367493
[15/24] Train loss=0.16182883083820343
[20/24] Train loss=0.1487216353416443
Test set avg_accuracy=81.54% avg_sensitivity=35.56%, avg_specificity=98.66% avg_auc=85.87%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.163876 Test loss=0.473187 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16463862359523773
[5/24] Train loss=0.15317541360855103
[10/24] Train loss=0.16601713001728058
[15/24] Train loss=0.15550556778907776
[20/24] Train loss=0.14687427878379822
Test set avg_accuracy=86.29% avg_sensitivity=54.94%, avg_specificity=97.96% avg_auc=89.98%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.162658 Test loss=0.357113 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16301485896110535
[5/24] Train loss=0.1541166752576828
[10/24] Train loss=0.1507357954978943
[15/24] Train loss=0.15508824586868286
[20/24] Train loss=0.14819857478141785
Test set avg_accuracy=86.45% avg_sensitivity=55.71%, avg_specificity=97.89% avg_auc=90.11%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.160912 Test loss=0.335401 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16277292370796204
[5/24] Train loss=0.15548881888389587
[10/24] Train loss=0.15504421293735504
[15/24] Train loss=0.1462484449148178
[20/24] Train loss=0.14456263184547424
Test set avg_accuracy=89.73% avg_sensitivity=72.94%, avg_specificity=95.98% avg_auc=93.40%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.158563 Test loss=0.277068 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1648901253938675
[5/24] Train loss=0.1458543986082077
[10/24] Train loss=0.15371686220169067
[15/24] Train loss=0.14554835855960846
[20/24] Train loss=0.14704091846942902
Test set avg_accuracy=89.04% avg_sensitivity=70.97%, avg_specificity=95.76% avg_auc=91.69%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.159754 Test loss=0.294104 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1585148274898529
[5/24] Train loss=0.15235227346420288
[10/24] Train loss=0.15060950815677643
[15/24] Train loss=0.16203105449676514
[20/24] Train loss=0.15160565078258514
Test set avg_accuracy=89.58% avg_sensitivity=78.41%, avg_specificity=93.75% avg_auc=93.57%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.157542 Test loss=0.275359 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1580154448747635
[5/24] Train loss=0.14336369931697845
[10/24] Train loss=0.1556187868118286
[15/24] Train loss=0.1496751606464386
[20/24] Train loss=0.15117554366588593
Test set avg_accuracy=89.04% avg_sensitivity=72.22%, avg_specificity=95.30% avg_auc=91.84%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.158179 Test loss=0.292423 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.16462866961956024
[5/24] Train loss=0.1493280529975891
[10/24] Train loss=0.15265969932079315
[15/24] Train loss=0.15066780149936676
[20/24] Train loss=0.13966523110866547
Test set avg_accuracy=87.99% avg_sensitivity=64.83%, avg_specificity=96.62% avg_auc=90.73%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.155817 Test loss=0.310053 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15653365850448608
[5/24] Train loss=0.14715053141117096
[10/24] Train loss=0.15045315027236938
[15/24] Train loss=0.13963893055915833
[20/24] Train loss=0.13531216979026794
Test set avg_accuracy=89.28% avg_sensitivity=74.18%, avg_specificity=94.91% avg_auc=92.89%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.153004 Test loss=0.280285 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15394656360149384
[5/24] Train loss=0.1497148871421814
[10/24] Train loss=0.14256338775157928
[15/24] Train loss=0.14311470091342926
[20/24] Train loss=0.14058783650398254
Test set avg_accuracy=89.67% avg_sensitivity=73.85%, avg_specificity=95.57% avg_auc=92.55%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.150944 Test loss=0.281157 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.1507430225610733
[5/24] Train loss=0.14871864020824432
[10/24] Train loss=0.14288698136806488
[15/24] Train loss=0.15785004198551178
[20/24] Train loss=0.13911323249340057
Test set avg_accuracy=87.84% avg_sensitivity=64.54%, avg_specificity=96.52% avg_auc=91.77%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.150685 Test loss=0.315979 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15217188000679016
[5/24] Train loss=0.15064959228038788
[10/24] Train loss=0.14505229890346527
[15/24] Train loss=0.14512547850608826
[20/24] Train loss=0.13663096725940704
Test set avg_accuracy=89.10% avg_sensitivity=70.54%, avg_specificity=96.02% avg_auc=92.49%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.150989 Test loss=0.292267 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14871357381343842
[5/24] Train loss=0.13923782110214233
[10/24] Train loss=0.13941006362438202
[15/24] Train loss=0.14026008546352386
[20/24] Train loss=0.13680338859558105
Test set avg_accuracy=89.02% avg_sensitivity=72.26%, avg_specificity=95.26% avg_auc=93.10%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.147391 Test loss=0.279138 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.15041972696781158
[5/24] Train loss=0.13938777148723602
[10/24] Train loss=0.1417468935251236
[15/24] Train loss=0.1469002366065979
[20/24] Train loss=0.13931939005851746
Test set avg_accuracy=87.53% avg_sensitivity=61.18%, avg_specificity=97.34% avg_auc=91.39%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.148777 Test loss=0.321630 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14983516931533813
[5/24] Train loss=0.14396820962429047
[10/24] Train loss=0.13965705037117004
[15/24] Train loss=0.14948788285255432
[20/24] Train loss=0.13702930510044098
Test set avg_accuracy=88.71% avg_sensitivity=68.28%, avg_specificity=96.32% avg_auc=92.49%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.147792 Test loss=0.293559 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.153215229511261
[5/24] Train loss=0.13967429101467133
[10/24] Train loss=0.1434483677148819
[15/24] Train loss=0.14024372398853302
[20/24] Train loss=0.13808420300483704
Test set avg_accuracy=89.77% avg_sensitivity=70.97%, avg_specificity=96.77% avg_auc=92.94%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.147868 Test loss=0.284564 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14671018719673157
[5/24] Train loss=0.14114300906658173
[10/24] Train loss=0.13692708313465118
[15/24] Train loss=0.13719183206558228
[20/24] Train loss=0.131321519613266
Test set avg_accuracy=89.40% avg_sensitivity=72.94%, avg_specificity=95.53% avg_auc=93.27%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.145451 Test loss=0.284676 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14392675459384918
[5/24] Train loss=0.13972239196300507
[10/24] Train loss=0.13430379331111908
[15/24] Train loss=0.1375974863767624
[20/24] Train loss=0.1292169988155365
Test set avg_accuracy=89.34% avg_sensitivity=76.73%, avg_specificity=94.03% avg_auc=93.23%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.143897 Test loss=0.285086 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14654245972633362
[5/24] Train loss=0.13883475959300995
[10/24] Train loss=0.13411974906921387
[15/24] Train loss=0.1319473832845688
[20/24] Train loss=0.13176469504833221
Test set avg_accuracy=89.74% avg_sensitivity=77.59%, avg_specificity=94.26% avg_auc=93.32%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.141258 Test loss=0.275732 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14366300404071808
[5/24] Train loss=0.13750478625297546
[10/24] Train loss=0.13431961834430695
[15/24] Train loss=0.13297505676746368
[20/24] Train loss=0.1267390251159668
Test set avg_accuracy=90.00% avg_sensitivity=76.25%, avg_specificity=95.12% avg_auc=92.63%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.139541 Test loss=0.283000 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14034101366996765
[5/24] Train loss=0.13170766830444336
[10/24] Train loss=0.13466262817382812
[15/24] Train loss=0.13195745646953583
[20/24] Train loss=0.12947270274162292
Test set avg_accuracy=89.82% avg_sensitivity=78.31%, avg_specificity=94.10% avg_auc=92.94%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.138083 Test loss=0.281068 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.14144304394721985
[5/24] Train loss=0.12732575833797455
[10/24] Train loss=0.13006214797496796
[15/24] Train loss=0.13215193152427673
[20/24] Train loss=0.1261672079563141
Test set avg_accuracy=89.90% avg_sensitivity=75.67%, avg_specificity=95.19% avg_auc=93.09%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.137167 Test loss=0.279033 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14105476438999176
[5/24] Train loss=0.12851673364639282
[10/24] Train loss=0.12886013090610504
[15/24] Train loss=0.12672582268714905
[20/24] Train loss=0.1279733031988144
Test set avg_accuracy=89.67% avg_sensitivity=76.15%, avg_specificity=94.71% avg_auc=92.70%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.135694 Test loss=0.284920 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13756532967090607
[5/24] Train loss=0.13204093277454376
[10/24] Train loss=0.12713630497455597
[15/24] Train loss=0.12755754590034485
[20/24] Train loss=0.12474806606769562
Test set avg_accuracy=89.92% avg_sensitivity=74.42%, avg_specificity=95.69% avg_auc=92.36%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.134678 Test loss=0.283897 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13518688082695007
[5/24] Train loss=0.12905971705913544
[10/24] Train loss=0.1249123066663742
[15/24] Train loss=0.12634527683258057
[20/24] Train loss=0.1238640546798706
Test set avg_accuracy=90.04% avg_sensitivity=78.89%, avg_specificity=94.19% avg_auc=92.79%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.134284 Test loss=0.280901 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13842855393886566
[5/24] Train loss=0.12943165004253387
[10/24] Train loss=0.12779811024665833
[15/24] Train loss=0.12649840116500854
[20/24] Train loss=0.1271369308233261
Test set avg_accuracy=89.70% avg_sensitivity=77.50%, avg_specificity=94.25% avg_auc=92.93%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.133449 Test loss=0.283572 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1329515427350998
[5/24] Train loss=0.12703442573547363
[10/24] Train loss=0.1262744516134262
[15/24] Train loss=0.12752728164196014
[20/24] Train loss=0.12526175379753113
Test set avg_accuracy=89.80% avg_sensitivity=75.91%, avg_specificity=94.98% avg_auc=92.68%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.133086 Test loss=0.286465 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13587604463100433
[5/24] Train loss=0.12495902925729752
[10/24] Train loss=0.12608414888381958
[15/24] Train loss=0.12729284167289734
[20/24] Train loss=0.12621454894542694
Test set avg_accuracy=89.39% avg_sensitivity=77.93%, avg_specificity=93.66% avg_auc=92.88%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.132420 Test loss=0.285776 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1320611536502838
[5/24] Train loss=0.1254510134458542
[10/24] Train loss=0.12372029572725296
[15/24] Train loss=0.12520156800746918
[20/24] Train loss=0.12498023360967636
Test set avg_accuracy=89.53% avg_sensitivity=75.67%, avg_specificity=94.69% avg_auc=92.16%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.132087 Test loss=0.294803 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13490667939186096
[5/24] Train loss=0.12659214437007904
[10/24] Train loss=0.12428867071866989
[15/24] Train loss=0.12346921861171722
[20/24] Train loss=0.12092941999435425
Test set avg_accuracy=89.53% avg_sensitivity=74.09%, avg_specificity=95.28% avg_auc=92.06%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.130897 Test loss=0.295760 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1292182207107544
[5/24] Train loss=0.12406856566667557
[10/24] Train loss=0.1227487176656723
[15/24] Train loss=0.12035726010799408
[20/24] Train loss=0.12441752105951309
Test set avg_accuracy=89.73% avg_sensitivity=75.62%, avg_specificity=94.98% avg_auc=92.35%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.129526 Test loss=0.290133 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13167637586593628
[5/24] Train loss=0.1270834058523178
[10/24] Train loss=0.1255144476890564
[15/24] Train loss=0.12332615256309509
[20/24] Train loss=0.12274531275033951
Test set avg_accuracy=89.52% avg_sensitivity=75.91%, avg_specificity=94.59% avg_auc=92.24%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.129401 Test loss=0.292484 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.12955886125564575
[5/24] Train loss=0.12370679527521133
[10/24] Train loss=0.12403835356235504
[15/24] Train loss=0.12282836437225342
[20/24] Train loss=0.12035076320171356
Test set avg_accuracy=89.39% avg_sensitivity=76.20%, avg_specificity=94.30% avg_auc=92.35%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.128896 Test loss=0.287081 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13036330044269562
[5/24] Train loss=0.122349813580513
[10/24] Train loss=0.12083179503679276
[15/24] Train loss=0.11995024979114532
[20/24] Train loss=0.12098965793848038
Test set avg_accuracy=89.60% avg_sensitivity=78.79%, avg_specificity=93.62% avg_auc=92.73%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.127888 Test loss=0.288436 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13164739310741425
[5/24] Train loss=0.1211019977927208
[10/24] Train loss=0.12024524062871933
[15/24] Train loss=0.12207843363285065
[20/24] Train loss=0.11967630684375763
Test set avg_accuracy=89.95% avg_sensitivity=77.59%, avg_specificity=94.55% avg_auc=92.36%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.127483 Test loss=0.291614 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13150076568126678
[5/24] Train loss=0.12233208864927292
[10/24] Train loss=0.12314646691083908
[15/24] Train loss=0.12191406637430191
[20/24] Train loss=0.12092792987823486
Test set avg_accuracy=89.06% avg_sensitivity=81.05%, avg_specificity=92.05% avg_auc=92.99%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.127999 Test loss=0.293671 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13069450855255127
[5/24] Train loss=0.12088917195796967
[10/24] Train loss=0.11990546435117722
[15/24] Train loss=0.12145068496465683
[20/24] Train loss=0.12150683254003525
Test set avg_accuracy=89.74% avg_sensitivity=77.78%, avg_specificity=94.19% avg_auc=92.43%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.125952 Test loss=0.290445 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12640121579170227
[5/24] Train loss=0.12207471579313278
[10/24] Train loss=0.11837327480316162
[15/24] Train loss=0.12001317739486694
[20/24] Train loss=0.11755258589982986
Test set avg_accuracy=89.32% avg_sensitivity=78.89%, avg_specificity=93.21% avg_auc=92.63%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.125367 Test loss=0.291505 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1265682727098465
[5/24] Train loss=0.12226855754852295
[10/24] Train loss=0.11867846548557281
[15/24] Train loss=0.12059721350669861
[20/24] Train loss=0.11928486824035645
Test set avg_accuracy=89.78% avg_sensitivity=78.21%, avg_specificity=94.09% avg_auc=92.45%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.125487 Test loss=0.289859 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12873399257659912
[5/24] Train loss=0.12230440974235535
[10/24] Train loss=0.11964254826307297
[15/24] Train loss=0.11755675077438354
[20/24] Train loss=0.11924758553504944
Test set avg_accuracy=89.79% avg_sensitivity=75.82%, avg_specificity=95.00% avg_auc=92.23%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.125335 Test loss=0.287671 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12339918315410614
[5/24] Train loss=0.11903756856918335
[10/24] Train loss=0.11866770684719086
[15/24] Train loss=0.11908967047929764
[20/24] Train loss=0.11964819580316544
Test set avg_accuracy=89.62% avg_sensitivity=77.50%, avg_specificity=94.14% avg_auc=92.50%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.124952 Test loss=0.285669 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12500600516796112
[5/24] Train loss=0.11808037012815475
[10/24] Train loss=0.12067319452762604
[15/24] Train loss=0.11703462153673172
[20/24] Train loss=0.11674176156520844
Test set avg_accuracy=89.27% avg_sensitivity=76.82%, avg_specificity=93.91% avg_auc=92.43%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.124250 Test loss=0.287886 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12825873494148254
[5/24] Train loss=0.11779157817363739
[10/24] Train loss=0.11845279484987259
[15/24] Train loss=0.11772358417510986
[20/24] Train loss=0.11613369733095169
Test set avg_accuracy=89.22% avg_sensitivity=75.91%, avg_specificity=94.17% avg_auc=92.20%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.123111 Test loss=0.289436 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12517736852169037
[5/24] Train loss=0.11765193194150925
[10/24] Train loss=0.11541866511106491
[15/24] Train loss=0.11518758535385132
[20/24] Train loss=0.11742416024208069
Test set avg_accuracy=89.43% avg_sensitivity=76.44%, avg_specificity=94.26% avg_auc=92.40%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.122470 Test loss=0.286818 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.12481240928173065
[5/24] Train loss=0.11807044595479965
[10/24] Train loss=0.11636007577180862
[15/24] Train loss=0.11652009934186935
[20/24] Train loss=0.11367731541395187
Test set avg_accuracy=89.88% avg_sensitivity=77.02%, avg_specificity=94.67% avg_auc=92.25%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.121966 Test loss=0.285952 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.125330850481987
[5/24] Train loss=0.11749178171157837
[10/24] Train loss=0.11609499901533127
[15/24] Train loss=0.1150083839893341
[20/24] Train loss=0.1162092462182045
Test set avg_accuracy=89.75% avg_sensitivity=76.06%, avg_specificity=94.85% avg_auc=92.41%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.121747 Test loss=0.284506 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12091260403394699
[5/24] Train loss=0.11694860458374023
[10/24] Train loss=0.11409980058670044
[15/24] Train loss=0.11601828783750534
[20/24] Train loss=0.11428717523813248
Test set avg_accuracy=89.78% avg_sensitivity=76.39%, avg_specificity=94.76% avg_auc=92.24%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.120996 Test loss=0.287227 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12246572971343994
[5/24] Train loss=0.11684472113847733
[10/24] Train loss=0.11556558310985565
[15/24] Train loss=0.1167808324098587
[20/24] Train loss=0.11553934961557388
Test set avg_accuracy=89.92% avg_sensitivity=77.45%, avg_specificity=94.57% avg_auc=92.57%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.121068 Test loss=0.284319 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12183725833892822
[5/24] Train loss=0.11628525704145432
[10/24] Train loss=0.11543775349855423
[15/24] Train loss=0.11470731347799301
[20/24] Train loss=0.11552349478006363
Test set avg_accuracy=89.69% avg_sensitivity=76.49%, avg_specificity=94.60% avg_auc=92.35%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.120682 Test loss=0.286238 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12375438213348389
[5/24] Train loss=0.11517076194286346
[10/24] Train loss=0.11629527062177658
[15/24] Train loss=0.11530318856239319
[20/24] Train loss=0.11742671579122543
Test set avg_accuracy=89.82% avg_sensitivity=76.54%, avg_specificity=94.76% avg_auc=92.29%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.120554 Test loss=0.286236 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12014544010162354
[5/24] Train loss=0.11433969438076019
[10/24] Train loss=0.1117837205529213
[15/24] Train loss=0.11234947293996811
[20/24] Train loss=0.11517761647701263
Test set avg_accuracy=89.80% avg_sensitivity=77.26%, avg_specificity=94.48% avg_auc=92.40%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.119954 Test loss=0.285518 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12124966084957123
[5/24] Train loss=0.11697287857532501
[10/24] Train loss=0.11429397761821747
[15/24] Train loss=0.11596618592739105
[20/24] Train loss=0.11479619890451431
Test set avg_accuracy=89.78% avg_sensitivity=76.92%, avg_specificity=94.57% avg_auc=92.40%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.120578 Test loss=0.285038 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12100846320390701
[5/24] Train loss=0.1157824769616127
[10/24] Train loss=0.11411476880311966
[15/24] Train loss=0.11340060085058212
[20/24] Train loss=0.11553780734539032
Test set avg_accuracy=89.84% avg_sensitivity=76.58%, avg_specificity=94.78% avg_auc=92.37%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.120423 Test loss=0.284952 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.11847414076328278
[5/24] Train loss=0.11469455063343048
[10/24] Train loss=0.11283770203590393
[15/24] Train loss=0.11172955483198166
[20/24] Train loss=0.11668296903371811
Test set avg_accuracy=89.83% avg_sensitivity=76.58%, avg_specificity=94.76% avg_auc=92.37%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.119887 Test loss=0.285029 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12214779108762741
[5/24] Train loss=0.11674240976572037
[10/24] Train loss=0.11401300132274628
[15/24] Train loss=0.11308303475379944
[20/24] Train loss=0.11528376489877701
Test set avg_accuracy=89.88% avg_sensitivity=76.97%, avg_specificity=94.69% avg_auc=92.38%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.119810 Test loss=0.285069 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12233293801546097
[5/24] Train loss=0.11572820693254471
[10/24] Train loss=0.11269973963499069
[15/24] Train loss=0.11421050876379013
[20/24] Train loss=0.11397899687290192
Test set avg_accuracy=89.83% avg_sensitivity=76.58%, avg_specificity=94.76% avg_auc=92.34%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.119846 Test loss=0.285153 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12123075127601624
[5/24] Train loss=0.11623189598321915
[10/24] Train loss=0.11483456194400787
[15/24] Train loss=0.1149481013417244
[20/24] Train loss=0.11398420482873917
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.88% avg_sensitivity=76.78%, avg_specificity=94.76% avg_auc=92.37%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.119320 Test loss=0.285039 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=90.03% sen=77.69%, spe=94.62%, auc=94.39%!
Fold[6] Avg_overlap=0.74%(0.22605658026108819)
[0/24] Train loss=0.730572521686554
[5/24] Train loss=0.722609281539917
[10/24] Train loss=0.7173212766647339
[15/24] Train loss=0.70394366979599
[20/24] Train loss=0.6980835199356079
Test set avg_accuracy=66.33% avg_sensitivity=38.85%, avg_specificity=76.81% avg_auc=56.13%
Best model saved!! Metric=-87.88247495136821!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.715720 Test loss=0.674613 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7054113745689392
[5/24] Train loss=0.6940832734107971
[10/24] Train loss=0.6898609399795532
[15/24] Train loss=0.6772893667221069
[20/24] Train loss=0.6697003841400146
Test set avg_accuracy=70.86% avg_sensitivity=63.65%, avg_specificity=73.61% avg_auc=68.75%
Best model saved!! Metric=-49.13276995499354!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.687805 Test loss=0.623457 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6662889122962952
[5/24] Train loss=0.6662948727607727
[10/24] Train loss=0.6661883592605591
[15/24] Train loss=0.6499903798103333
[20/24] Train loss=0.6411157846450806
Test set avg_accuracy=74.66% avg_sensitivity=70.77%, avg_specificity=76.15% avg_auc=75.17%
Best model saved!! Metric=-29.256125268369686!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.660873 Test loss=0.590060 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6489071846008301
[5/24] Train loss=0.6391852498054504
[10/24] Train loss=0.6374589204788208
[15/24] Train loss=0.6226764917373657
[20/24] Train loss=0.6107306480407715
Test set avg_accuracy=76.88% avg_sensitivity=74.54%, avg_specificity=77.77% avg_auc=78.92%
Best model saved!! Metric=-17.89942350664795!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.634328 Test loss=0.560311 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6141144037246704
[5/24] Train loss=0.6171222925186157
[10/24] Train loss=0.6163912415504456
[15/24] Train loss=0.5926608443260193
[20/24] Train loss=0.5847039818763733
Test set avg_accuracy=78.53% avg_sensitivity=74.68%, avg_specificity=80.00% avg_auc=81.60%
Best model saved!! Metric=-11.19447383812809!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.607088 Test loss=0.530659 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5850769281387329
[5/24] Train loss=0.5819145441055298
[10/24] Train loss=0.5934901237487793
[15/24] Train loss=0.5557613372802734
[20/24] Train loss=0.5482936501502991
Test set avg_accuracy=79.86% avg_sensitivity=75.67%, avg_specificity=81.45% avg_auc=83.91%
Best model saved!! Metric=-5.112539481400248!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.578269 Test loss=0.501499 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5507115721702576
[5/24] Train loss=0.5497975945472717
[10/24] Train loss=0.559592604637146
[15/24] Train loss=0.5279003977775574
[20/24] Train loss=0.5152248740196228
Test set avg_accuracy=81.45% avg_sensitivity=75.44%, avg_specificity=83.74% avg_auc=86.12%
Best model saved!! Metric=0.7375099797124989!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.549396 Test loss=0.470603 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5239351391792297
[5/24] Train loss=0.5205293893814087
[10/24] Train loss=0.5333925485610962
[15/24] Train loss=0.49913930892944336
[20/24] Train loss=0.4882980287075043
Test set avg_accuracy=82.77% avg_sensitivity=77.75%, avg_specificity=84.69% avg_auc=88.08%
Best model saved!! Metric=7.292658722870129!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.519502 Test loss=0.441799 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4971260130405426
[5/24] Train loss=0.4886910915374756
[10/24] Train loss=0.5009540319442749
[15/24] Train loss=0.46531736850738525
[20/24] Train loss=0.45697158575057983
Test set avg_accuracy=84.28% avg_sensitivity=76.14%, avg_specificity=87.39% avg_auc=89.70%
Best model saved!! Metric=11.515964826657196!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.490272 Test loss=0.409986 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4709053933620453
[5/24] Train loss=0.45707347989082336
[10/24] Train loss=0.4695170819759369
[15/24] Train loss=0.438406765460968
[20/24] Train loss=0.4258204996585846
Test set avg_accuracy=85.83% avg_sensitivity=75.67%, avg_specificity=89.71% avg_auc=91.00%
Best model saved!! Metric=16.21753778569591!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.460823 Test loss=0.385905 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.43816715478897095
[5/24] Train loss=0.42902523279190063
[10/24] Train loss=0.4426780641078949
[15/24] Train loss=0.4111554026603699
[20/24] Train loss=0.39428845047950745
Test set avg_accuracy=87.01% avg_sensitivity=75.77%, avg_specificity=91.29% avg_auc=91.99%
Best model saved!! Metric=20.053114897176044!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.432918 Test loss=0.365206 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4117346704006195
[5/24] Train loss=0.39919307827949524
[10/24] Train loss=0.4136209487915039
[15/24] Train loss=0.38517528772354126
[20/24] Train loss=0.3694927990436554
Test set avg_accuracy=87.50% avg_sensitivity=71.05%, avg_specificity=93.78% avg_auc=92.38%
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.406908 Test loss=0.344149 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3903142511844635
[5/24] Train loss=0.3731271028518677
[10/24] Train loss=0.3953688442707062
[15/24] Train loss=0.3621176481246948
[20/24] Train loss=0.3488638699054718
Test set avg_accuracy=87.70% avg_sensitivity=69.68%, avg_specificity=94.57% avg_auc=92.84%
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.385125 Test loss=0.330243 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37083473801612854
[5/24] Train loss=0.3498059809207916
[10/24] Train loss=0.37970778346061707
[15/24] Train loss=0.3502533733844757
[20/24] Train loss=0.3309696614742279
Test set avg_accuracy=88.01% avg_sensitivity=68.27%, avg_specificity=95.54% avg_auc=93.07%
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.366632 Test loss=0.319599 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.3546569049358368
[5/24] Train loss=0.3406491279602051
[10/24] Train loss=0.3657894432544708
[15/24] Train loss=0.33314719796180725
[20/24] Train loss=0.32226797938346863
Test set avg_accuracy=88.33% avg_sensitivity=69.97%, avg_specificity=95.34% avg_auc=93.82%
Best model saved!! Metric=21.460819977611052!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.351271 Test loss=0.306602 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.33295783400535583
[5/24] Train loss=0.3187772333621979
[10/24] Train loss=0.3540845811367035
[15/24] Train loss=0.3203671872615814
[20/24] Train loss=0.30743178725242615
Test set avg_accuracy=88.31% avg_sensitivity=68.98%, avg_specificity=95.68% avg_auc=94.12%
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.336558 Test loss=0.300597 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3250843286514282
[5/24] Train loss=0.30665716528892517
[10/24] Train loss=0.332607626914978
[15/24] Train loss=0.30701252818107605
[20/24] Train loss=0.2899405360221863
Test set avg_accuracy=88.37% avg_sensitivity=68.74%, avg_specificity=95.86% avg_auc=94.28%
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.325299 Test loss=0.291744 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3088948428630829
[5/24] Train loss=0.29291555285453796
[10/24] Train loss=0.3347313702106476
[15/24] Train loss=0.3027671277523041
[20/24] Train loss=0.28334951400756836
Test set avg_accuracy=89.26% avg_sensitivity=76.57%, avg_specificity=94.10% avg_auc=94.75%
Best model saved!! Metric=28.679415179888693!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.315096 Test loss=0.283645 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3050468862056732
[5/24] Train loss=0.28601354360580444
[10/24] Train loss=0.3168587386608124
[15/24] Train loss=0.2936359643936157
[20/24] Train loss=0.2750598192214966
Test set avg_accuracy=88.91% avg_sensitivity=72.42%, avg_specificity=95.20% avg_auc=94.89%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.307040 Test loss=0.278283 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29496708512306213
[5/24] Train loss=0.27128955721855164
[10/24] Train loss=0.31923091411590576
[15/24] Train loss=0.2811969220638275
[20/24] Train loss=0.2693425714969635
Test set avg_accuracy=88.68% avg_sensitivity=70.63%, avg_specificity=95.57% avg_auc=94.59%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.296528 Test loss=0.279789 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.2877035439014435
[5/24] Train loss=0.2702426314353943
[10/24] Train loss=0.30258485674858093
[15/24] Train loss=0.2778925597667694
[20/24] Train loss=0.25547218322753906
Test set avg_accuracy=88.41% avg_sensitivity=70.39%, avg_specificity=95.29% avg_auc=94.93%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.291006 Test loss=0.272197 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.28385552763938904
[5/24] Train loss=0.25939321517944336
[10/24] Train loss=0.30207720398902893
[15/24] Train loss=0.2732810378074646
[20/24] Train loss=0.25384360551834106
Test set avg_accuracy=88.70% avg_sensitivity=70.63%, avg_specificity=95.59% avg_auc=94.89%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.284804 Test loss=0.269194 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2796584665775299
[5/24] Train loss=0.24828819930553436
[10/24] Train loss=0.2977948784828186
[15/24] Train loss=0.2666662931442261
[20/24] Train loss=0.2466384768486023
Test set avg_accuracy=88.70% avg_sensitivity=69.40%, avg_specificity=96.06% avg_auc=94.86%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.277717 Test loss=0.272644 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2682218551635742
[5/24] Train loss=0.24025650322437286
[10/24] Train loss=0.2858116626739502
[15/24] Train loss=0.259047269821167
[20/24] Train loss=0.24470165371894836
Test set avg_accuracy=89.05% avg_sensitivity=70.39%, avg_specificity=96.17% avg_auc=95.12%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.271296 Test loss=0.265013 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2649824023246765
[5/24] Train loss=0.24071380496025085
[10/24] Train loss=0.280991792678833
[15/24] Train loss=0.250732421875
[20/24] Train loss=0.23827862739562988
Test set avg_accuracy=86.16% avg_sensitivity=54.03%, avg_specificity=98.42% avg_auc=93.27%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.265818 Test loss=0.326356 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2631289064884186
[5/24] Train loss=0.2339567244052887
[10/24] Train loss=0.27635127305984497
[15/24] Train loss=0.24335604906082153
[20/24] Train loss=0.2305692434310913
Test set avg_accuracy=89.10% avg_sensitivity=68.27%, avg_specificity=97.05% avg_auc=94.66%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.262084 Test loss=0.276220 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2558906078338623
[5/24] Train loss=0.230828657746315
[10/24] Train loss=0.2731073498725891
[15/24] Train loss=0.24324680864810944
[20/24] Train loss=0.23078617453575134
Test set avg_accuracy=88.82% avg_sensitivity=68.27%, avg_specificity=96.65% avg_auc=93.76%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.258083 Test loss=0.287113 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.2564626932144165
[5/24] Train loss=0.22831609845161438
[10/24] Train loss=0.27234145998954773
[15/24] Train loss=0.245290607213974
[20/24] Train loss=0.23290641605854034
Test set avg_accuracy=87.96% avg_sensitivity=62.09%, avg_specificity=97.82% avg_auc=94.03%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.254071 Test loss=0.296567 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2445390820503235
[5/24] Train loss=0.225723534822464
[10/24] Train loss=0.27127882838249207
[15/24] Train loss=0.2383352667093277
[20/24] Train loss=0.2250099629163742
Test set avg_accuracy=88.33% avg_sensitivity=63.70%, avg_specificity=97.73% avg_auc=94.10%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.249416 Test loss=0.287687 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.24862226843833923
[5/24] Train loss=0.21713846921920776
[10/24] Train loss=0.2560679614543915
[15/24] Train loss=0.23941181600093842
[20/24] Train loss=0.21921108663082123
Test set avg_accuracy=88.89% avg_sensitivity=67.37%, avg_specificity=97.10% avg_auc=94.37%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.245077 Test loss=0.277519 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2446112334728241
[5/24] Train loss=0.21255578100681305
[10/24] Train loss=0.261063814163208
[15/24] Train loss=0.23618747293949127
[20/24] Train loss=0.21859405934810638
Test set avg_accuracy=83.72% avg_sensitivity=42.24%, avg_specificity=99.55% avg_auc=90.56%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.241716 Test loss=0.415175 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.250377357006073
[5/24] Train loss=0.20873130857944489
[10/24] Train loss=0.2578611373901367
[15/24] Train loss=0.2329709529876709
[20/24] Train loss=0.21779680252075195
Test set avg_accuracy=87.63% avg_sensitivity=61.34%, avg_specificity=97.66% avg_auc=93.65%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.239755 Test loss=0.304465 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23834629356861115
[5/24] Train loss=0.20146453380584717
[10/24] Train loss=0.2567388415336609
[15/24] Train loss=0.23271727561950684
[20/24] Train loss=0.21778005361557007
Test set avg_accuracy=84.86% avg_sensitivity=47.34%, avg_specificity=99.17% avg_auc=89.92%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.234160 Test loss=0.370029 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.23282195627689362
[5/24] Train loss=0.20701949298381805
[10/24] Train loss=0.254739373922348
[15/24] Train loss=0.23283794522285461
[20/24] Train loss=0.22275950014591217
Test set avg_accuracy=87.86% avg_sensitivity=62.66%, avg_specificity=97.48% avg_auc=93.49%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.231895 Test loss=0.300203 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22642908990383148
[5/24] Train loss=0.18729570508003235
[10/24] Train loss=0.25143519043922424
[15/24] Train loss=0.23014000058174133
[20/24] Train loss=0.2259725034236908
Test set avg_accuracy=88.61% avg_sensitivity=64.40%, avg_specificity=97.84% avg_auc=92.57%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.230440 Test loss=0.308769 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.22827576100826263
[5/24] Train loss=0.19319799542427063
[10/24] Train loss=0.23699748516082764
[15/24] Train loss=0.22086668014526367
[20/24] Train loss=0.21049714088439941
Test set avg_accuracy=81.95% avg_sensitivity=36.35%, avg_specificity=99.35% avg_auc=89.01%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.226653 Test loss=0.445271 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2259545773267746
[5/24] Train loss=0.19821509718894958
[10/24] Train loss=0.2423250377178192
[15/24] Train loss=0.21791090071201324
[20/24] Train loss=0.21271616220474243
Test set avg_accuracy=88.50% avg_sensitivity=72.47%, avg_specificity=94.62% avg_auc=93.58%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.223087 Test loss=0.291217 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2247573584318161
[5/24] Train loss=0.18550734221935272
[10/24] Train loss=0.2475326955318451
[15/24] Train loss=0.21175669133663177
[20/24] Train loss=0.2068193256855011
Test set avg_accuracy=84.34% avg_sensitivity=47.10%, avg_specificity=98.54% avg_auc=92.24%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.224486 Test loss=0.350853 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.2215723842382431
[5/24] Train loss=0.18341796100139618
[10/24] Train loss=0.23021918535232544
[15/24] Train loss=0.22922326624393463
[20/24] Train loss=0.20111313462257385
Test set avg_accuracy=89.02% avg_sensitivity=73.22%, avg_specificity=95.05% avg_auc=94.42%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.219222 Test loss=0.265862 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21837575733661652
[5/24] Train loss=0.18148350715637207
[10/24] Train loss=0.22403870522975922
[15/24] Train loss=0.22045211493968964
[20/24] Train loss=0.20468676090240479
Test set avg_accuracy=81.89% avg_sensitivity=36.21%, avg_specificity=99.32% avg_auc=88.25%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.216889 Test loss=0.440617 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21187160909175873
[5/24] Train loss=0.1735023558139801
[10/24] Train loss=0.22741945087909698
[15/24] Train loss=0.2371746152639389
[20/24] Train loss=0.20659327507019043
Test set avg_accuracy=89.35% avg_sensitivity=79.73%, avg_specificity=93.02% avg_auc=94.64%
Best model saved!! Metric=30.732083200441878!!
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.216166 Test loss=0.269610 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.19980381429195404
[5/24] Train loss=0.17697478830814362
[10/24] Train loss=0.2187986671924591
[15/24] Train loss=0.22703899443149567
[20/24] Train loss=0.1948975920677185
Test set avg_accuracy=88.50% avg_sensitivity=69.73%, avg_specificity=95.66% avg_auc=92.31%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.214086 Test loss=0.311318 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2037997543811798
[5/24] Train loss=0.17594672739505768
[10/24] Train loss=0.2378215491771698
[15/24] Train loss=0.21986395120620728
[20/24] Train loss=0.19764627516269684
Test set avg_accuracy=87.07% avg_sensitivity=59.78%, avg_specificity=97.48% avg_auc=91.34%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.218295 Test loss=0.355358 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2030584067106247
[5/24] Train loss=0.18423794209957123
[10/24] Train loss=0.22524411976337433
[15/24] Train loss=0.20932109653949738
[20/24] Train loss=0.1994219720363617
Test set avg_accuracy=88.05% avg_sensitivity=63.46%, avg_specificity=97.43% avg_auc=94.11%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.210282 Test loss=0.278480 Current lr=[0.00029967723776099]

[0/24] Train loss=0.19831812381744385
[5/24] Train loss=0.18730175495147705
[10/24] Train loss=0.2196415662765503
[15/24] Train loss=0.2129514366388321
[20/24] Train loss=0.19302919507026672
Test set avg_accuracy=89.51% avg_sensitivity=74.07%, avg_specificity=95.39% avg_auc=94.81%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.208737 Test loss=0.259810 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2024727612733841
[5/24] Train loss=0.18627652525901794
[10/24] Train loss=0.21878695487976074
[15/24] Train loss=0.2146134227514267
[20/24] Train loss=0.19839900732040405
Test set avg_accuracy=88.79% avg_sensitivity=67.70%, avg_specificity=96.83% avg_auc=91.75%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.208696 Test loss=0.308208 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.20789790153503418
[5/24] Train loss=0.16436319053173065
[10/24] Train loss=0.20643381774425507
[15/24] Train loss=0.2101830244064331
[20/24] Train loss=0.18368804454803467
Test set avg_accuracy=89.71% avg_sensitivity=73.83%, avg_specificity=95.77% avg_auc=94.34%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.202507 Test loss=0.267203 Current lr=[0.000299720220882401]

[0/24] Train loss=0.18788622319698334
[5/24] Train loss=0.16843242943286896
[10/24] Train loss=0.2243826687335968
[15/24] Train loss=0.21510258316993713
[20/24] Train loss=0.1860002875328064
Test set avg_accuracy=89.26% avg_sensitivity=72.14%, avg_specificity=95.79% avg_auc=94.78%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.201488 Test loss=0.261663 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.1995653361082077
[5/24] Train loss=0.16836075484752655
[10/24] Train loss=0.2105393409729004
[15/24] Train loss=0.19991189241409302
[20/24] Train loss=0.1915295571088791
Test set avg_accuracy=86.99% avg_sensitivity=59.22%, avg_specificity=97.59% avg_auc=90.38%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.200080 Test loss=0.367465 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19996774196624756
[5/24] Train loss=0.17942702770233154
[10/24] Train loss=0.20704156160354614
[15/24] Train loss=0.20059749484062195
[20/24] Train loss=0.19875307381153107
Test set avg_accuracy=86.65% avg_sensitivity=57.14%, avg_specificity=97.91% avg_auc=92.49%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.201995 Test loss=0.323956 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.18534556031227112
[5/24] Train loss=0.1651242971420288
[10/24] Train loss=0.20966634154319763
[15/24] Train loss=0.19633974134922028
[20/24] Train loss=0.1900642067193985
Test set avg_accuracy=88.55% avg_sensitivity=67.56%, avg_specificity=96.56% avg_auc=93.23%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.195317 Test loss=0.285278 Current lr=[0.000297555943323901]

[0/24] Train loss=0.18257802724838257
[5/24] Train loss=0.15621422231197357
[10/24] Train loss=0.1951960325241089
[15/24] Train loss=0.20470274984836578
[20/24] Train loss=0.1781855970621109
Test set avg_accuracy=89.21% avg_sensitivity=72.65%, avg_specificity=95.52% avg_auc=94.26%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.190567 Test loss=0.263777 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.18205469846725464
[5/24] Train loss=0.171366348862648
[10/24] Train loss=0.20187172293663025
[15/24] Train loss=0.20512224733829498
[20/24] Train loss=0.1944817304611206
Test set avg_accuracy=87.92% avg_sensitivity=84.49%, avg_specificity=89.22% avg_auc=94.45%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.194006 Test loss=0.301891 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19340191781520844
[5/24] Train loss=0.15861183404922485
[10/24] Train loss=0.19669979810714722
[15/24] Train loss=0.183099627494812
[20/24] Train loss=0.17893128097057343
Test set avg_accuracy=87.77% avg_sensitivity=85.43%, avg_specificity=88.67% avg_auc=95.40%
Best model saved!! Metric=31.273258502067833!!
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.192079 Test loss=0.275897 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.1875801533460617
[5/24] Train loss=0.1731521636247635
[10/24] Train loss=0.20016193389892578
[15/24] Train loss=0.19406111538410187
[20/24] Train loss=0.18502363562583923
Test set avg_accuracy=88.75% avg_sensitivity=72.32%, avg_specificity=95.02% avg_auc=94.07%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.189556 Test loss=0.281671 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.18467605113983154
[5/24] Train loss=0.1561744511127472
[10/24] Train loss=0.21329784393310547
[15/24] Train loss=0.20331384241580963
[20/24] Train loss=0.18219977617263794
Test set avg_accuracy=88.24% avg_sensitivity=80.29%, avg_specificity=91.28% avg_auc=94.34%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.190702 Test loss=0.291449 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18153826892375946
[5/24] Train loss=0.16299909353256226
[10/24] Train loss=0.19444207847118378
[15/24] Train loss=0.1988856941461563
[20/24] Train loss=0.1808219999074936
Test set avg_accuracy=86.88% avg_sensitivity=60.91%, avg_specificity=96.78% avg_auc=91.72%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.187950 Test loss=0.319910 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.18350210785865784
[5/24] Train loss=0.16003403067588806
[10/24] Train loss=0.2028583288192749
[15/24] Train loss=0.1861668974161148
[20/24] Train loss=0.17612436413764954
Test set avg_accuracy=88.89% avg_sensitivity=72.37%, avg_specificity=95.20% avg_auc=93.84%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.189368 Test loss=0.277125 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.18341884016990662
[5/24] Train loss=0.15535980463027954
[10/24] Train loss=0.19243834912776947
[15/24] Train loss=0.1860613226890564
[20/24] Train loss=0.1819792538881302
Test set avg_accuracy=87.77% avg_sensitivity=65.68%, avg_specificity=96.20% avg_auc=93.42%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.186989 Test loss=0.289462 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.17635352909564972
[5/24] Train loss=0.1516122668981552
[10/24] Train loss=0.2096470594406128
[15/24] Train loss=0.1985413283109665
[20/24] Train loss=0.16912907361984253
Test set avg_accuracy=81.38% avg_sensitivity=35.27%, avg_specificity=98.97% avg_auc=86.94%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.187994 Test loss=0.453633 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.18521848320960999
[5/24] Train loss=0.15301579236984253
[10/24] Train loss=0.17770639061927795
[15/24] Train loss=0.19629408419132233
[20/24] Train loss=0.1730046272277832
Test set avg_accuracy=89.13% avg_sensitivity=71.57%, avg_specificity=95.83% avg_auc=94.37%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.181848 Test loss=0.265785 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18107354640960693
[5/24] Train loss=0.15698394179344177
[10/24] Train loss=0.18760307133197784
[15/24] Train loss=0.1909172683954239
[20/24] Train loss=0.17623774707317352
Test set avg_accuracy=88.45% avg_sensitivity=66.81%, avg_specificity=96.71% avg_auc=93.08%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.181161 Test loss=0.299332 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18587736785411835
[5/24] Train loss=0.16543757915496826
[10/24] Train loss=0.19471226632595062
[15/24] Train loss=0.18561536073684692
[20/24] Train loss=0.1766999214887619
Test set avg_accuracy=85.44% avg_sensitivity=51.86%, avg_specificity=98.26% avg_auc=88.66%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.183398 Test loss=0.411986 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.17720958590507507
[5/24] Train loss=0.15403111279010773
[10/24] Train loss=0.19284017384052277
[15/24] Train loss=0.18936170637607574
[20/24] Train loss=0.18308742344379425
Test set avg_accuracy=87.88% avg_sensitivity=63.55%, avg_specificity=97.16% avg_auc=92.84%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.183666 Test loss=0.300010 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17198576033115387
[5/24] Train loss=0.1498221457004547
[10/24] Train loss=0.19401368498802185
[15/24] Train loss=0.17750579118728638
[20/24] Train loss=0.17451250553131104
Test set avg_accuracy=82.33% avg_sensitivity=38.61%, avg_specificity=99.01% avg_auc=87.29%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.180981 Test loss=0.439744 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.17794084548950195
[5/24] Train loss=0.17053818702697754
[10/24] Train loss=0.1871248036623001
[15/24] Train loss=0.17909467220306396
[20/24] Train loss=0.17088718712329865
Test set avg_accuracy=87.83% avg_sensitivity=64.07%, avg_specificity=96.89% avg_auc=92.34%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.179432 Test loss=0.298877 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.1770746111869812
[5/24] Train loss=0.15702645480632782
[10/24] Train loss=0.20296810567378998
[15/24] Train loss=0.1772274672985077
[20/24] Train loss=0.16657789051532745
Test set avg_accuracy=82.77% avg_sensitivity=39.84%, avg_specificity=99.15% avg_auc=84.53%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.180652 Test loss=0.499272 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.17367686331272125
[5/24] Train loss=0.17011338472366333
[10/24] Train loss=0.18907490372657776
[15/24] Train loss=0.17790666222572327
[20/24] Train loss=0.17920249700546265
Test set avg_accuracy=78.42% avg_sensitivity=23.43%, avg_specificity=99.41% avg_auc=85.51%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.182132 Test loss=0.544858 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.1769639402627945
[5/24] Train loss=0.15019378066062927
[10/24] Train loss=0.17776454985141754
[15/24] Train loss=0.17710746824741364
[20/24] Train loss=0.181265726685524
Test set avg_accuracy=87.94% avg_sensitivity=61.95%, avg_specificity=97.86% avg_auc=91.63%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.178827 Test loss=0.323261 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.17170792818069458
[5/24] Train loss=0.15407787263393402
[10/24] Train loss=0.19051028788089752
[15/24] Train loss=0.17117513716220856
[20/24] Train loss=0.17309968173503876
Test set avg_accuracy=84.40% avg_sensitivity=49.60%, avg_specificity=97.68% avg_auc=89.99%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.175270 Test loss=0.378916 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.1742010861635208
[5/24] Train loss=0.1459827870130539
[10/24] Train loss=0.18191637098789215
[15/24] Train loss=0.16804590821266174
[20/24] Train loss=0.1621847301721573
Test set avg_accuracy=86.81% avg_sensitivity=58.13%, avg_specificity=97.75% avg_auc=90.29%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.174688 Test loss=0.344938 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.17513017356395721
[5/24] Train loss=0.1542617529630661
[10/24] Train loss=0.17609865963459015
[15/24] Train loss=0.17911063134670258
[20/24] Train loss=0.162729412317276
Test set avg_accuracy=87.40% avg_sensitivity=60.21%, avg_specificity=97.77% avg_auc=92.07%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.173496 Test loss=0.326557 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.17355242371559143
[5/24] Train loss=0.15491348505020142
[10/24] Train loss=0.17757710814476013
[15/24] Train loss=0.1697467416524887
[20/24] Train loss=0.16137288510799408
Test set avg_accuracy=88.32% avg_sensitivity=62.66%, avg_specificity=98.11% avg_auc=93.05%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.170124 Test loss=0.300808 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.16182206571102142
[5/24] Train loss=0.14644484221935272
[10/24] Train loss=0.19324977695941925
[15/24] Train loss=0.17571580410003662
[20/24] Train loss=0.16958943009376526
Test set avg_accuracy=86.61% avg_sensitivity=56.86%, avg_specificity=97.97% avg_auc=91.25%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.178147 Test loss=0.329399 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.16698899865150452
[5/24] Train loss=0.13895569741725922
[10/24] Train loss=0.18019582331180573
[15/24] Train loss=0.16859257221221924
[20/24] Train loss=0.15811479091644287
Test set avg_accuracy=88.87% avg_sensitivity=67.00%, avg_specificity=97.21% avg_auc=92.34%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.170272 Test loss=0.298162 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.16288793087005615
[5/24] Train loss=0.14099347591400146
[10/24] Train loss=0.17997834086418152
[15/24] Train loss=0.16670361161231995
[20/24] Train loss=0.16135761141777039
Test set avg_accuracy=87.40% avg_sensitivity=61.10%, avg_specificity=97.43% avg_auc=90.77%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.170756 Test loss=0.326918 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.1665269285440445
[5/24] Train loss=0.1431514024734497
[10/24] Train loss=0.17258286476135254
[15/24] Train loss=0.16662676632404327
[20/24] Train loss=0.16441047191619873
Test set avg_accuracy=88.75% avg_sensitivity=71.05%, avg_specificity=95.50% avg_auc=91.38%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.168276 Test loss=0.319814 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17313213646411896
[5/24] Train loss=0.14079628884792328
[10/24] Train loss=0.16135966777801514
[15/24] Train loss=0.15915624797344208
[20/24] Train loss=0.16316097974777222
Test set avg_accuracy=86.32% avg_sensitivity=54.22%, avg_specificity=98.56% avg_auc=89.55%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.165981 Test loss=0.374198 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.16148808598518372
[5/24] Train loss=0.13573892414569855
[10/24] Train loss=0.1766601949930191
[15/24] Train loss=0.16423384845256805
[20/24] Train loss=0.16132985055446625
Test set avg_accuracy=82.16% avg_sensitivity=37.39%, avg_specificity=99.24% avg_auc=85.82%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.168265 Test loss=0.463480 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17271408438682556
[5/24] Train loss=0.14190630614757538
[10/24] Train loss=0.17224320769309998
[15/24] Train loss=0.17683841288089752
[20/24] Train loss=0.16969865560531616
Test set avg_accuracy=87.60% avg_sensitivity=61.62%, avg_specificity=97.52% avg_auc=90.77%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.168335 Test loss=0.327212 Current lr=[0.000224838296036774]

[0/24] Train loss=0.18044568598270416
[5/24] Train loss=0.14533215761184692
[10/24] Train loss=0.1713959127664566
[15/24] Train loss=0.16402091085910797
[20/24] Train loss=0.15918318927288055
Test set avg_accuracy=87.16% avg_sensitivity=62.33%, avg_specificity=96.64% avg_auc=87.88%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.169597 Test loss=0.360160 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17587585747241974
[5/24] Train loss=0.1420060098171234
[10/24] Train loss=0.17532950639724731
[15/24] Train loss=0.16716811060905457
[20/24] Train loss=0.15661783516407013
Test set avg_accuracy=83.88% avg_sensitivity=44.51%, avg_specificity=98.90% avg_auc=87.46%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.169292 Test loss=0.443666 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.1641141027212143
[5/24] Train loss=0.13713309168815613
[10/24] Train loss=0.17340241372585297
[15/24] Train loss=0.16615013778209686
[20/24] Train loss=0.16022616624832153
Test set avg_accuracy=87.50% avg_sensitivity=76.57%, avg_specificity=91.67% avg_auc=92.49%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.166083 Test loss=0.314302 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18072621524333954
[5/24] Train loss=0.14650332927703857
[10/24] Train loss=0.1791420429944992
[15/24] Train loss=0.1674436330795288
[20/24] Train loss=0.16977576911449432
Test set avg_accuracy=88.35% avg_sensitivity=65.16%, avg_specificity=97.19% avg_auc=88.84%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.171611 Test loss=0.353555 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.16749660670757294
[5/24] Train loss=0.14087748527526855
[10/24] Train loss=0.18725425004959106
[15/24] Train loss=0.17094822227954865
[20/24] Train loss=0.16524182260036469
Test set avg_accuracy=88.72% avg_sensitivity=68.69%, avg_specificity=96.37% avg_auc=89.98%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.169832 Test loss=0.344525 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.17826250195503235
[5/24] Train loss=0.150461345911026
[10/24] Train loss=0.17818918824195862
[15/24] Train loss=0.15605418384075165
[20/24] Train loss=0.16004392504692078
Test set avg_accuracy=87.96% avg_sensitivity=65.72%, avg_specificity=96.44% avg_auc=89.89%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.167317 Test loss=0.332165 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1654573231935501
[5/24] Train loss=0.13698816299438477
[10/24] Train loss=0.17365920543670654
[15/24] Train loss=0.17041628062725067
[20/24] Train loss=0.16884949803352356
Test set avg_accuracy=87.19% avg_sensitivity=60.35%, avg_specificity=97.43% avg_auc=91.01%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.167343 Test loss=0.323840 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.15777523815631866
[5/24] Train loss=0.14119409024715424
[10/24] Train loss=0.16874203085899353
[15/24] Train loss=0.1628977507352829
[20/24] Train loss=0.15440315008163452
Test set avg_accuracy=87.30% avg_sensitivity=61.15%, avg_specificity=97.28% avg_auc=91.44%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.163028 Test loss=0.325452 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.1635427474975586
[5/24] Train loss=0.13640372455120087
[10/24] Train loss=0.16326454281806946
[15/24] Train loss=0.15668217837810516
[20/24] Train loss=0.1513419896364212
Test set avg_accuracy=89.34% avg_sensitivity=74.59%, avg_specificity=94.96% avg_auc=93.75%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.160033 Test loss=0.277167 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.15530380606651306
[5/24] Train loss=0.14324764907360077
[10/24] Train loss=0.16229112446308136
[15/24] Train loss=0.15009036660194397
[20/24] Train loss=0.15731260180473328
Test set avg_accuracy=88.53% avg_sensitivity=73.74%, avg_specificity=94.17% avg_auc=93.24%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.159676 Test loss=0.292345 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.1547604501247406
[5/24] Train loss=0.13328798115253448
[10/24] Train loss=0.15667544305324554
[15/24] Train loss=0.15597376227378845
[20/24] Train loss=0.1537332832813263
Test set avg_accuracy=88.89% avg_sensitivity=72.14%, avg_specificity=95.29% avg_auc=92.71%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.157661 Test loss=0.286021 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16396090388298035
[5/24] Train loss=0.13805364072322845
[10/24] Train loss=0.15297092497348785
[15/24] Train loss=0.15747515857219696
[20/24] Train loss=0.15011665225028992
Test set avg_accuracy=88.20% avg_sensitivity=64.26%, avg_specificity=97.34% avg_auc=92.17%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.156490 Test loss=0.302889 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.15487173199653625
[5/24] Train loss=0.1404683142900467
[10/24] Train loss=0.1651817113161087
[15/24] Train loss=0.15543526411056519
[20/24] Train loss=0.15004700422286987
Test set avg_accuracy=88.72% avg_sensitivity=69.45%, avg_specificity=96.08% avg_auc=91.94%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.155863 Test loss=0.293388 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.15319857001304626
[5/24] Train loss=0.13066473603248596
[10/24] Train loss=0.16221587359905243
[15/24] Train loss=0.14790020883083344
[20/24] Train loss=0.14965802431106567
Test set avg_accuracy=88.28% avg_sensitivity=81.05%, avg_specificity=91.04% avg_auc=94.22%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.155601 Test loss=0.292169 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.14945471286773682
[5/24] Train loss=0.14029988646507263
[10/24] Train loss=0.14930421113967896
[15/24] Train loss=0.1540815383195877
[20/24] Train loss=0.15280896425247192
Test set avg_accuracy=85.57% avg_sensitivity=53.75%, avg_specificity=97.72% avg_auc=88.49%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.154669 Test loss=0.376773 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.15190733969211578
[5/24] Train loss=0.1347046196460724
[10/24] Train loss=0.14962585270404816
[15/24] Train loss=0.14918431639671326
[20/24] Train loss=0.1466173380613327
Test set avg_accuracy=88.52% avg_sensitivity=67.14%, avg_specificity=96.67% avg_auc=91.84%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.152672 Test loss=0.305774 Current lr=[0.000156543481933168]

[0/24] Train loss=0.14900515973567963
[5/24] Train loss=0.12899205088615417
[10/24] Train loss=0.15320448577404022
[15/24] Train loss=0.14956790208816528
[20/24] Train loss=0.14994297921657562
Test set avg_accuracy=88.95% avg_sensitivity=73.27%, avg_specificity=94.93% avg_auc=93.17%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.150202 Test loss=0.285230 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.14325715601444244
[5/24] Train loss=0.1265256404876709
[10/24] Train loss=0.1494210660457611
[15/24] Train loss=0.14615510404109955
[20/24] Train loss=0.14612363278865814
Test set avg_accuracy=88.06% avg_sensitivity=64.73%, avg_specificity=96.96% avg_auc=92.59%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.149375 Test loss=0.300421 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.1488221287727356
[5/24] Train loss=0.1289399266242981
[10/24] Train loss=0.15302017331123352
[15/24] Train loss=0.15120954811573029
[20/24] Train loss=0.14926595985889435
Test set avg_accuracy=88.07% avg_sensitivity=66.20%, avg_specificity=96.42% avg_auc=92.25%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.150583 Test loss=0.295360 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.14600761234760284
[5/24] Train loss=0.1303618848323822
[10/24] Train loss=0.14891083538532257
[15/24] Train loss=0.1558467596769333
[20/24] Train loss=0.14044149219989777
Test set avg_accuracy=87.34% avg_sensitivity=59.74%, avg_specificity=97.88% avg_auc=91.15%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.148623 Test loss=0.344163 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.1502889096736908
[5/24] Train loss=0.12954245507717133
[10/24] Train loss=0.14920394122600555
[15/24] Train loss=0.1420859843492508
[20/24] Train loss=0.14346425235271454
Test set avg_accuracy=88.93% avg_sensitivity=72.28%, avg_specificity=95.29% avg_auc=93.76%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.147536 Test loss=0.282682 Current lr=[0.000134135431043539]

[0/24] Train loss=0.14723746478557587
[5/24] Train loss=0.12713715434074402
[10/24] Train loss=0.14487852156162262
[15/24] Train loss=0.14418718218803406
[20/24] Train loss=0.14237281680107117
Test set avg_accuracy=88.55% avg_sensitivity=66.62%, avg_specificity=96.92% avg_auc=91.15%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.145665 Test loss=0.319011 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.14143531024456024
[5/24] Train loss=0.12810289859771729
[10/24] Train loss=0.14253263175487518
[15/24] Train loss=0.13651524484157562
[20/24] Train loss=0.1450316160917282
Test set avg_accuracy=88.42% avg_sensitivity=65.96%, avg_specificity=97.00% avg_auc=92.36%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.144163 Test loss=0.295185 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.14513203501701355
[5/24] Train loss=0.12770698964595795
[10/24] Train loss=0.14089258015155792
[15/24] Train loss=0.14030790328979492
[20/24] Train loss=0.1423075795173645
Test set avg_accuracy=88.92% avg_sensitivity=69.45%, avg_specificity=96.35% avg_auc=92.53%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.144174 Test loss=0.296597 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.14886081218719482
[5/24] Train loss=0.12487234175205231
[10/24] Train loss=0.1415131539106369
[15/24] Train loss=0.13835392892360687
[20/24] Train loss=0.14082498848438263
Test set avg_accuracy=89.32% avg_sensitivity=72.42%, avg_specificity=95.77% avg_auc=93.59%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.143291 Test loss=0.276411 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1360786259174347
[5/24] Train loss=0.12445027381181717
[10/24] Train loss=0.14315727353096008
[15/24] Train loss=0.1387956142425537
[20/24] Train loss=0.1400974690914154
Test set avg_accuracy=88.45% avg_sensitivity=65.96%, avg_specificity=97.03% avg_auc=90.87%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.142262 Test loss=0.322616 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1463301032781601
[5/24] Train loss=0.12206081300973892
[10/24] Train loss=0.13737182319164276
[15/24] Train loss=0.14145338535308838
[20/24] Train loss=0.1389983743429184
Test set avg_accuracy=88.59% avg_sensitivity=68.36%, avg_specificity=96.31% avg_auc=92.43%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.142841 Test loss=0.289257 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14108498394489288
[5/24] Train loss=0.1265067607164383
[10/24] Train loss=0.13300037384033203
[15/24] Train loss=0.13898560404777527
[20/24] Train loss=0.13689489662647247
Test set avg_accuracy=89.26% avg_sensitivity=72.42%, avg_specificity=95.68% avg_auc=93.33%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.141042 Test loss=0.279508 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.13694605231285095
[5/24] Train loss=0.12490196526050568
[10/24] Train loss=0.13148723542690277
[15/24] Train loss=0.13512854278087616
[20/24] Train loss=0.1381501853466034
Test set avg_accuracy=88.42% avg_sensitivity=68.88%, avg_specificity=95.88% avg_auc=92.46%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.139987 Test loss=0.289284 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14268766343593597
[5/24] Train loss=0.12105561047792435
[10/24] Train loss=0.1396130472421646
[15/24] Train loss=0.13800664246082306
[20/24] Train loss=0.13614553213119507
Test set avg_accuracy=87.06% avg_sensitivity=59.55%, avg_specificity=97.55% avg_auc=91.12%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.140922 Test loss=0.329909 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.13884633779525757
[5/24] Train loss=0.12761862576007843
[10/24] Train loss=0.13865013420581818
[15/24] Train loss=0.13790343701839447
[20/24] Train loss=0.13602547347545624
Test set avg_accuracy=88.82% avg_sensitivity=70.63%, avg_specificity=95.75% avg_auc=92.76%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.141844 Test loss=0.288777 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.14017096161842346
[5/24] Train loss=0.12906843423843384
[10/24] Train loss=0.13361553847789764
[15/24] Train loss=0.13668686151504517
[20/24] Train loss=0.13370241224765778
Test set avg_accuracy=88.36% avg_sensitivity=66.01%, avg_specificity=96.89% avg_auc=92.03%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.141283 Test loss=0.302595 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.13897646963596344
[5/24] Train loss=0.12093600630760193
[10/24] Train loss=0.13525143265724182
[15/24] Train loss=0.13674679398536682
[20/24] Train loss=0.13872401416301727
Test set avg_accuracy=88.67% avg_sensitivity=68.93%, avg_specificity=96.20% avg_auc=92.67%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.141097 Test loss=0.286518 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14228376746177673
[5/24] Train loss=0.12439922243356705
[10/24] Train loss=0.1355581283569336
[15/24] Train loss=0.13536354899406433
[20/24] Train loss=0.1343725025653839
Test set avg_accuracy=88.75% avg_sensitivity=69.54%, avg_specificity=96.08% avg_auc=93.35%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.139131 Test loss=0.285121 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1401514708995819
[5/24] Train loss=0.1187155470252037
[10/24] Train loss=0.13377904891967773
[15/24] Train loss=0.1298273354768753
[20/24] Train loss=0.13429613411426544
Test set avg_accuracy=89.08% avg_sensitivity=72.75%, avg_specificity=95.30% avg_auc=93.81%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.135814 Test loss=0.279634 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1391117423772812
[5/24] Train loss=0.11605889350175858
[10/24] Train loss=0.13182654976844788
[15/24] Train loss=0.12673121690750122
[20/24] Train loss=0.1322326809167862
Test set avg_accuracy=88.58% avg_sensitivity=70.53%, avg_specificity=95.47% avg_auc=93.25%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.134475 Test loss=0.287237 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.13710837066173553
[5/24] Train loss=0.11730924248695374
[10/24] Train loss=0.12866532802581787
[15/24] Train loss=0.1277972012758255
[20/24] Train loss=0.12935680150985718
Test set avg_accuracy=88.72% avg_sensitivity=71.29%, avg_specificity=95.38% avg_auc=93.35%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.132987 Test loss=0.284643 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1340239942073822
[5/24] Train loss=0.11654683202505112
[10/24] Train loss=0.1309913694858551
[15/24] Train loss=0.12386682629585266
[20/24] Train loss=0.12697970867156982
Test set avg_accuracy=88.53% avg_sensitivity=70.67%, avg_specificity=95.34% avg_auc=93.71%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.132712 Test loss=0.282543 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13440760970115662
[5/24] Train loss=0.11599023640155792
[10/24] Train loss=0.12796775996685028
[15/24] Train loss=0.12426254153251648
[20/24] Train loss=0.1275121420621872
Test set avg_accuracy=88.61% avg_sensitivity=68.18%, avg_specificity=96.40% avg_auc=92.33%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.131167 Test loss=0.297545 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1355418860912323
[5/24] Train loss=0.11513403058052063
[10/24] Train loss=0.13143064081668854
[15/24] Train loss=0.12120483070611954
[20/24] Train loss=0.1307709813117981
Test set avg_accuracy=88.02% avg_sensitivity=66.10%, avg_specificity=96.38% avg_auc=92.54%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.130522 Test loss=0.299048 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.12807424366474152
[5/24] Train loss=0.11471299082040787
[10/24] Train loss=0.12428587675094604
[15/24] Train loss=0.11926856637001038
[20/24] Train loss=0.13098591566085815
Test set avg_accuracy=89.23% avg_sensitivity=72.80%, avg_specificity=95.50% avg_auc=93.82%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.129568 Test loss=0.276534 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1289655715227127
[5/24] Train loss=0.11355842649936676
[10/24] Train loss=0.12154979258775711
[15/24] Train loss=0.11864887177944183
[20/24] Train loss=0.13066893815994263
Test set avg_accuracy=88.48% avg_sensitivity=70.06%, avg_specificity=95.50% avg_auc=92.93%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.129587 Test loss=0.290584 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1307096928358078
[5/24] Train loss=0.11461289972066879
[10/24] Train loss=0.12327821552753448
[15/24] Train loss=0.12216358631849289
[20/24] Train loss=0.12705111503601074
Test set avg_accuracy=88.29% avg_sensitivity=68.74%, avg_specificity=95.75% avg_auc=92.86%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.128729 Test loss=0.290460 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.12718145549297333
[5/24] Train loss=0.1151575818657875
[10/24] Train loss=0.12627176940441132
[15/24] Train loss=0.11928911507129669
[20/24] Train loss=0.12650218605995178
Test set avg_accuracy=88.67% avg_sensitivity=69.73%, avg_specificity=95.90% avg_auc=92.86%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.127747 Test loss=0.290701 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13014204800128937
[5/24] Train loss=0.11282554268836975
[10/24] Train loss=0.12445889413356781
[15/24] Train loss=0.1161629930138588
[20/24] Train loss=0.1250045895576477
Test set avg_accuracy=88.66% avg_sensitivity=70.72%, avg_specificity=95.50% avg_auc=93.11%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.126821 Test loss=0.287448 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.125919908285141
[5/24] Train loss=0.11188389360904694
[10/24] Train loss=0.121558777987957
[15/24] Train loss=0.12026116997003555
[20/24] Train loss=0.1261119842529297
Test set avg_accuracy=88.83% avg_sensitivity=70.86%, avg_specificity=95.68% avg_auc=92.79%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.125771 Test loss=0.288703 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1246403306722641
[5/24] Train loss=0.11319803446531296
[10/24] Train loss=0.12382376194000244
[15/24] Train loss=0.11853443086147308
[20/24] Train loss=0.12937647104263306
Test set avg_accuracy=88.92% avg_sensitivity=70.34%, avg_specificity=96.01% avg_auc=93.00%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.126315 Test loss=0.288094 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.12526880204677582
[5/24] Train loss=0.11071494966745377
[10/24] Train loss=0.12056313455104828
[15/24] Train loss=0.12034609913825989
[20/24] Train loss=0.1249467059969902
Test set avg_accuracy=88.78% avg_sensitivity=69.78%, avg_specificity=96.02% avg_auc=92.84%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.124985 Test loss=0.292645 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13030023872852325
[5/24] Train loss=0.11227258294820786
[10/24] Train loss=0.12143116444349289
[15/24] Train loss=0.11791660636663437
[20/24] Train loss=0.12315683811903
Test set avg_accuracy=88.66% avg_sensitivity=69.97%, avg_specificity=95.79% avg_auc=93.07%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.125322 Test loss=0.288782 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1228356882929802
[5/24] Train loss=0.11188334226608276
[10/24] Train loss=0.12139057368040085
[15/24] Train loss=0.11835458129644394
[20/24] Train loss=0.12480492889881134
Test set avg_accuracy=88.62% avg_sensitivity=70.01%, avg_specificity=95.72% avg_auc=92.24%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.124742 Test loss=0.295505 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.123234823346138
[5/24] Train loss=0.11298976838588715
[10/24] Train loss=0.12127581238746643
[15/24] Train loss=0.12219986319541931
[20/24] Train loss=0.12419954687356949
Test set avg_accuracy=88.78% avg_sensitivity=72.32%, avg_specificity=95.05% avg_auc=93.09%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.124917 Test loss=0.286844 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12337693572044373
[5/24] Train loss=0.11350764334201813
[10/24] Train loss=0.12051510065793991
[15/24] Train loss=0.11672573536634445
[20/24] Train loss=0.12526392936706543
Test set avg_accuracy=88.82% avg_sensitivity=73.03%, avg_specificity=94.84% avg_auc=93.27%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.124785 Test loss=0.282439 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12293066829442978
[5/24] Train loss=0.11245463043451309
[10/24] Train loss=0.12248191982507706
[15/24] Train loss=0.11636758595705032
[20/24] Train loss=0.1257629245519638
Test set avg_accuracy=88.88% avg_sensitivity=73.36%, avg_specificity=94.80% avg_auc=93.26%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.124478 Test loss=0.281260 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12373398244380951
[5/24] Train loss=0.11128030717372894
[10/24] Train loss=0.12024654448032379
[15/24] Train loss=0.11850831657648087
[20/24] Train loss=0.12383309006690979
Test set avg_accuracy=88.96% avg_sensitivity=73.46%, avg_specificity=94.87% avg_auc=93.45%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.123722 Test loss=0.279655 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12323892116546631
[5/24] Train loss=0.1112939864397049
[10/24] Train loss=0.11829008162021637
[15/24] Train loss=0.11356617510318756
[20/24] Train loss=0.12135554850101471
Test set avg_accuracy=88.95% avg_sensitivity=71.66%, avg_specificity=95.54% avg_auc=93.09%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.122764 Test loss=0.284788 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12554015219211578
[5/24] Train loss=0.11227702349424362
[10/24] Train loss=0.11741625517606735
[15/24] Train loss=0.11556868255138397
[20/24] Train loss=0.12200090289115906
Test set avg_accuracy=89.01% avg_sensitivity=71.76%, avg_specificity=95.59% avg_auc=93.19%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.122739 Test loss=0.284765 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12315892428159714
[5/24] Train loss=0.10749318450689316
[10/24] Train loss=0.11682251840829849
[15/24] Train loss=0.11350329965353012
[20/24] Train loss=0.12053975462913513
Test set avg_accuracy=88.79% avg_sensitivity=71.85%, avg_specificity=95.25% avg_auc=93.25%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.121226 Test loss=0.282395 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.11989457160234451
[5/24] Train loss=0.10840947180986404
[10/24] Train loss=0.11648281663656235
[15/24] Train loss=0.11472336947917938
[20/24] Train loss=0.11929600685834885
Test set avg_accuracy=88.91% avg_sensitivity=72.28%, avg_specificity=95.25% avg_auc=93.18%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.120878 Test loss=0.282766 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.11909014731645584
[5/24] Train loss=0.10752764344215393
[10/24] Train loss=0.11705906689167023
[15/24] Train loss=0.11378437280654907
[20/24] Train loss=0.12068289518356323
Test set avg_accuracy=88.79% avg_sensitivity=70.96%, avg_specificity=95.59% avg_auc=92.83%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.120947 Test loss=0.288356 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.11879827082157135
[5/24] Train loss=0.10762213915586472
[10/24] Train loss=0.11658566445112228
[15/24] Train loss=0.11465200036764145
[20/24] Train loss=0.1218242198228836
Test set avg_accuracy=88.92% avg_sensitivity=71.52%, avg_specificity=95.56% avg_auc=92.83%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.120273 Test loss=0.287145 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.11868568509817123
[5/24] Train loss=0.10751138627529144
[10/24] Train loss=0.11728827655315399
[15/24] Train loss=0.11028151959180832
[20/24] Train loss=0.12163913995027542
Test set avg_accuracy=88.83% avg_sensitivity=71.62%, avg_specificity=95.39% avg_auc=93.15%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.119780 Test loss=0.284034 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.11928168684244156
[5/24] Train loss=0.1076294332742691
[10/24] Train loss=0.1168968677520752
[15/24] Train loss=0.11263741552829742
[20/24] Train loss=0.12165708094835281
Test set avg_accuracy=88.95% avg_sensitivity=71.85%, avg_specificity=95.47% avg_auc=93.29%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.120133 Test loss=0.282581 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.11829876154661179
[5/24] Train loss=0.10717721283435822
[10/24] Train loss=0.11445988714694977
[15/24] Train loss=0.11305450648069382
[20/24] Train loss=0.12018434703350067
Test set avg_accuracy=88.91% avg_sensitivity=71.57%, avg_specificity=95.52% avg_auc=93.11%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.119992 Test loss=0.285076 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12040819972753525
[5/24] Train loss=0.10726568102836609
[10/24] Train loss=0.11503536254167557
[15/24] Train loss=0.11174144595861435
[20/24] Train loss=0.1203627660870552
Test set avg_accuracy=88.92% avg_sensitivity=71.33%, avg_specificity=95.63% avg_auc=93.11%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.119872 Test loss=0.284963 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.11870251595973969
[5/24] Train loss=0.10911597311496735
[10/24] Train loss=0.11491771787405014
[15/24] Train loss=0.11236900091171265
[20/24] Train loss=0.12301421910524368
Test set avg_accuracy=88.95% avg_sensitivity=71.48%, avg_specificity=95.61% avg_auc=93.13%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.119575 Test loss=0.284933 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.11821231991052628
[5/24] Train loss=0.10857265442609787
[10/24] Train loss=0.11579953134059906
[15/24] Train loss=0.11096130311489105
[20/24] Train loss=0.11817603558301926
Test set avg_accuracy=88.92% avg_sensitivity=71.71%, avg_specificity=95.48% avg_auc=93.16%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.119282 Test loss=0.284076 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12085603922605515
[5/24] Train loss=0.10997795313596725
[10/24] Train loss=0.11676210910081863
[15/24] Train loss=0.11168375611305237
[20/24] Train loss=0.11879929155111313
Test set avg_accuracy=88.97% avg_sensitivity=71.71%, avg_specificity=95.56% avg_auc=93.17%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.119425 Test loss=0.284085 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12050462514162064
[5/24] Train loss=0.10875736176967621
[10/24] Train loss=0.11574933677911758
[15/24] Train loss=0.11116091907024384
[20/24] Train loss=0.12037172168493271
Test set avg_accuracy=88.97% avg_sensitivity=71.76%, avg_specificity=95.54% avg_auc=93.19%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.119788 Test loss=0.283744 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.11699138581752777
[5/24] Train loss=0.10678941756486893
[10/24] Train loss=0.11672917008399963
[15/24] Train loss=0.1124657690525055
[20/24] Train loss=0.11916172504425049
Test set avg_accuracy=88.97% avg_sensitivity=71.71%, avg_specificity=95.56% avg_auc=93.18%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.119313 Test loss=0.283943 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1187097579240799
[5/24] Train loss=0.1103217676281929
[10/24] Train loss=0.11524375528097153
[15/24] Train loss=0.11009334027767181
[20/24] Train loss=0.11841411888599396
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.97% avg_sensitivity=71.71%, avg_specificity=95.56% avg_auc=93.17%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.119402 Test loss=0.284054 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=87.77% sen=85.43%, spe=88.67%, auc=95.40%!
Fold[7] Avg_overlap=0.70%(0.22490994422502755)
[0/24] Train loss=0.7576534748077393
[5/24] Train loss=0.7538559436798096
[10/24] Train loss=0.7544112205505371
[15/24] Train loss=0.7335894703865051
[20/24] Train loss=0.7356903553009033
Test set avg_accuracy=56.95% avg_sensitivity=59.45%, avg_specificity=56.11% avg_auc=55.43%
Best model saved!! Metric=-98.04692445358295!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.743812 Test loss=0.686174 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7150197625160217
[5/24] Train loss=0.7167230248451233
[10/24] Train loss=0.7148669362068176
[15/24] Train loss=0.713768720626831
[20/24] Train loss=0.6954885721206665
Test set avg_accuracy=64.97% avg_sensitivity=79.60%, avg_specificity=60.06% avg_auc=66.73%
Best model saved!! Metric=-54.63609827345366!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.712734 Test loss=0.656793 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.695221483707428
[5/24] Train loss=0.6896110773086548
[10/24] Train loss=0.6852363348007202
[15/24] Train loss=0.6713751554489136
[20/24] Train loss=0.6783574819564819
Test set avg_accuracy=70.55% avg_sensitivity=84.31%, avg_specificity=65.92% avg_auc=74.72%
Best model saved!! Metric=-30.49905422696844!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.684335 Test loss=0.620168 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6589827537536621
[5/24] Train loss=0.6619076132774353
[10/24] Train loss=0.6624355912208557
[15/24] Train loss=0.6412215232849121
[20/24] Train loss=0.633743166923523
Test set avg_accuracy=70.99% avg_sensitivity=84.41%, avg_specificity=66.48% avg_auc=79.23%
Best model saved!! Metric=-24.889950801304195!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.653476 Test loss=0.594194 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6191722750663757
[5/24] Train loss=0.6270865201950073
[10/24] Train loss=0.6251508593559265
[15/24] Train loss=0.5986927151679993
[20/24] Train loss=0.6015141606330872
Test set avg_accuracy=73.57% avg_sensitivity=85.24%, avg_specificity=69.65% avg_auc=82.09%
Best model saved!! Metric=-15.453591207739194!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.620735 Test loss=0.565623 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5883012413978577
[5/24] Train loss=0.5942698121070862
[10/24] Train loss=0.596683919429779
[15/24] Train loss=0.5720293521881104
[20/24] Train loss=0.5620202422142029
Test set avg_accuracy=75.51% avg_sensitivity=86.59%, avg_specificity=71.79% avg_auc=84.54%
Best model saved!! Metric=-7.5761520270980895!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.588808 Test loss=0.535838 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5575737357139587
[5/24] Train loss=0.5607774257659912
[10/24] Train loss=0.5691041350364685
[15/24] Train loss=0.5439015626907349
[20/24] Train loss=0.5282797813415527
Test set avg_accuracy=77.68% avg_sensitivity=87.00%, avg_specificity=74.55% avg_auc=86.46%
Best model saved!! Metric=-0.3061252052383736!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.558608 Test loss=0.502481 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5259566903114319
[5/24] Train loss=0.5256560444831848
[10/24] Train loss=0.5364450216293335
[15/24] Train loss=0.5101121664047241
[20/24] Train loss=0.5018141269683838
Test set avg_accuracy=80.73% avg_sensitivity=84.72%, avg_specificity=79.39% avg_auc=88.15%
Best model saved!! Metric=6.992469793078953!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.528092 Test loss=0.464150 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.49069204926490784
[5/24] Train loss=0.5042004585266113
[10/24] Train loss=0.5089523792266846
[15/24] Train loss=0.4835164546966553
[20/24] Train loss=0.4633418917655945
Test set avg_accuracy=82.67% avg_sensitivity=84.83%, avg_specificity=81.94% avg_auc=89.80%
Best model saved!! Metric=13.239359486762709!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.499056 Test loss=0.440135 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.4704510569572449
[5/24] Train loss=0.4690372049808502
[10/24] Train loss=0.4814612865447998
[15/24] Train loss=0.4579451084136963
[20/24] Train loss=0.43222856521606445
Test set avg_accuracy=84.77% avg_sensitivity=83.43%, avg_specificity=85.21% avg_auc=90.96%
Best model saved!! Metric=18.364263684286087!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.469455 Test loss=0.408043 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4443204700946808
[5/24] Train loss=0.44296330213546753
[10/24] Train loss=0.44541290402412415
[15/24] Train loss=0.431730717420578
[20/24] Train loss=0.4027140438556671
Test set avg_accuracy=86.97% avg_sensitivity=80.68%, avg_specificity=89.08% avg_auc=92.14%
Best model saved!! Metric=22.86403832700907!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.441475 Test loss=0.371616 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.41815832257270813
[5/24] Train loss=0.41093456745147705
[10/24] Train loss=0.4327666163444519
[15/24] Train loss=0.4077446460723877
[20/24] Train loss=0.3785090446472168
Test set avg_accuracy=87.81% avg_sensitivity=78.82%, avg_specificity=90.83% avg_auc=92.71%
Best model saved!! Metric=24.17886385279982!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.416778 Test loss=0.348734 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3967188596725464
[5/24] Train loss=0.39162424206733704
[10/24] Train loss=0.41243138909339905
[15/24] Train loss=0.3890523612499237
[20/24] Train loss=0.35706812143325806
Test set avg_accuracy=88.74% avg_sensitivity=76.75%, avg_specificity=92.76% avg_auc=93.10%
Best model saved!! Metric=25.345557480648978!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.394859 Test loss=0.328118 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37236449122428894
[5/24] Train loss=0.3742596507072449
[10/24] Train loss=0.3861265182495117
[15/24] Train loss=0.3728485703468323
[20/24] Train loss=0.3409750461578369
Test set avg_accuracy=89.00% avg_sensitivity=74.52%, avg_specificity=93.86% avg_auc=93.22%
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.375582 Test loss=0.312492 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35542604327201843
[5/24] Train loss=0.34891051054000854
[10/24] Train loss=0.3712385892868042
[15/24] Train loss=0.3522473871707916
[20/24] Train loss=0.3152153193950653
Test set avg_accuracy=89.21% avg_sensitivity=71.57%, avg_specificity=95.13% avg_auc=93.51%
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.358184 Test loss=0.301471 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.34211233258247375
[5/24] Train loss=0.3395894467830658
[10/24] Train loss=0.3566203713417053
[15/24] Train loss=0.3387552499771118
[20/24] Train loss=0.30425307154655457
Test set avg_accuracy=89.45% avg_sensitivity=76.49%, avg_specificity=93.81% avg_auc=93.90%
Best model saved!! Metric=27.652703446489127!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.343849 Test loss=0.290050 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.3255508542060852
[5/24] Train loss=0.31956642866134644
[10/24] Train loss=0.3379398584365845
[15/24] Train loss=0.3287346065044403
[20/24] Train loss=0.28973856568336487
Test set avg_accuracy=89.14% avg_sensitivity=78.66%, avg_specificity=92.66% avg_auc=94.15%
Best model saved!! Metric=28.61889834751844!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.331732 Test loss=0.290194 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.3138015866279602
[5/24] Train loss=0.30829793214797974
[10/24] Train loss=0.32507777214050293
[15/24] Train loss=0.3188573122024536
[20/24] Train loss=0.27393120527267456
Test set avg_accuracy=89.38% avg_sensitivity=75.82%, avg_specificity=93.93% avg_auc=94.09%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.319216 Test loss=0.279132 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.3032727837562561
[5/24] Train loss=0.2974902093410492
[10/24] Train loss=0.31844764947891235
[15/24] Train loss=0.3123423755168915
[20/24] Train loss=0.2631380259990692
Test set avg_accuracy=89.41% avg_sensitivity=79.75%, avg_specificity=92.66% avg_auc=94.32%
Best model saved!! Metric=30.140241614391726!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.309062 Test loss=0.278853 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.29604384303092957
[5/24] Train loss=0.29300883412361145
[10/24] Train loss=0.3089495003223419
[15/24] Train loss=0.3011426031589508
[20/24] Train loss=0.260532021522522
Test set avg_accuracy=90.21% avg_sensitivity=76.39%, avg_specificity=94.85% avg_auc=94.63%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.302110 Test loss=0.264176 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28395208716392517
[5/24] Train loss=0.27852046489715576
[10/24] Train loss=0.29735124111175537
[15/24] Train loss=0.3026726543903351
[20/24] Train loss=0.2459801435470581
Test set avg_accuracy=89.15% avg_sensitivity=70.79%, avg_specificity=95.32% avg_auc=94.68%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.293160 Test loss=0.262363 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.2793492078781128
[5/24] Train loss=0.27364039421081543
[10/24] Train loss=0.29485729336738586
[15/24] Train loss=0.29022982716560364
[20/24] Train loss=0.2402757704257965
Test set avg_accuracy=89.44% avg_sensitivity=72.40%, avg_specificity=95.16% avg_auc=94.88%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.286320 Test loss=0.257630 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.27687594294548035
[5/24] Train loss=0.26747292280197144
[10/24] Train loss=0.29095327854156494
[15/24] Train loss=0.28060877323150635
[20/24] Train loss=0.23491322994232178
Test set avg_accuracy=90.14% avg_sensitivity=76.64%, avg_specificity=94.68% avg_auc=94.95%
Best model saved!! Metric=30.415547798353586!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.278664 Test loss=0.256767 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.26720741391181946
[5/24] Train loss=0.2547830045223236
[10/24] Train loss=0.2825396955013275
[15/24] Train loss=0.2819068431854248
[20/24] Train loss=0.22897407412528992
Test set avg_accuracy=90.04% avg_sensitivity=80.68%, avg_specificity=93.18% avg_auc=94.74%
Best model saved!! Metric=32.64498221098211!!
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.273458 Test loss=0.265048 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.26404327154159546
[5/24] Train loss=0.2508781850337982
[10/24] Train loss=0.2718549370765686
[15/24] Train loss=0.26921337842941284
[20/24] Train loss=0.22680379450321198
Test set avg_accuracy=90.16% avg_sensitivity=81.62%, avg_specificity=93.02% avg_auc=94.83%
Best model saved!! Metric=33.62471586428151!!
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.266668 Test loss=0.264980 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.25931188464164734
[5/24] Train loss=0.24801550805568695
[10/24] Train loss=0.27213746309280396
[15/24] Train loss=0.27249205112457275
[20/24] Train loss=0.2189345806837082
Test set avg_accuracy=90.47% avg_sensitivity=77.37%, avg_specificity=94.87% avg_auc=94.12%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.261224 Test loss=0.264135 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.2548244893550873
[5/24] Train loss=0.2387300282716751
[10/24] Train loss=0.2666712701320648
[15/24] Train loss=0.26254215836524963
[20/24] Train loss=0.21555596590042114
Test set avg_accuracy=90.36% avg_sensitivity=79.80%, avg_specificity=93.91% avg_auc=95.04%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.256028 Test loss=0.257283 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.25636470317840576
[5/24] Train loss=0.23520585894584656
[10/24] Train loss=0.2620694637298584
[15/24] Train loss=0.25568336248397827
[20/24] Train loss=0.2101147174835205
Test set avg_accuracy=90.31% avg_sensitivity=81.15%, avg_specificity=93.39% avg_auc=94.66%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.250228 Test loss=0.263004 Current lr=[0.000210185142098938]

[0/24] Train loss=0.2483101338148117
[5/24] Train loss=0.22551964223384857
[10/24] Train loss=0.26539894938468933
[15/24] Train loss=0.26057615876197815
[20/24] Train loss=0.20778527855873108
Test set avg_accuracy=90.36% avg_sensitivity=77.27%, avg_specificity=94.76% avg_auc=94.09%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.246516 Test loss=0.260544 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.2432982325553894
[5/24] Train loss=0.2200903743505478
[10/24] Train loss=0.2581638991832733
[15/24] Train loss=0.248057022690773
[20/24] Train loss=0.20094045996665955
Test set avg_accuracy=90.08% avg_sensitivity=74.68%, avg_specificity=95.25% avg_auc=94.35%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.241234 Test loss=0.256245 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.2369118183851242
[5/24] Train loss=0.21722033619880676
[10/24] Train loss=0.2510606348514557
[15/24] Train loss=0.24817070364952087
[20/24] Train loss=0.1982945203781128
Test set avg_accuracy=87.75% avg_sensitivity=84.77%, avg_specificity=88.75% avg_auc=94.33%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.240359 Test loss=0.300768 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2268560230731964
[5/24] Train loss=0.2067355066537857
[10/24] Train loss=0.2543491721153259
[15/24] Train loss=0.23660627007484436
[20/24] Train loss=0.20598940551280975
Test set avg_accuracy=90.44% avg_sensitivity=82.65%, avg_specificity=93.06% avg_auc=94.85%
Best model saved!! Metric=34.99964845909675!!
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.234786 Test loss=0.266215 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.23847343027591705
[5/24] Train loss=0.20568180084228516
[10/24] Train loss=0.2534908950328827
[15/24] Train loss=0.2423126995563507
[20/24] Train loss=0.20030410587787628
Test set avg_accuracy=90.17% avg_sensitivity=76.80%, avg_specificity=94.66% avg_auc=94.74%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.235061 Test loss=0.252013 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.2251501828432083
[5/24] Train loss=0.20108921825885773
[10/24] Train loss=0.2444394826889038
[15/24] Train loss=0.24148522317409515
[20/24] Train loss=0.20447218418121338
Test set avg_accuracy=90.13% avg_sensitivity=78.97%, avg_specificity=93.88% avg_auc=94.73%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.229420 Test loss=0.266994 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.22224856913089752
[5/24] Train loss=0.20211856067180634
[10/24] Train loss=0.23303067684173584
[15/24] Train loss=0.23160786926746368
[20/24] Train loss=0.19519081711769104
Test set avg_accuracy=90.61% avg_sensitivity=77.78%, avg_specificity=94.92% avg_auc=94.33%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.226075 Test loss=0.256125 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.2247437983751297
[5/24] Train loss=0.19888116419315338
[10/24] Train loss=0.24158310890197754
[15/24] Train loss=0.2270418256521225
[20/24] Train loss=0.190623477101326
Test set avg_accuracy=90.40% avg_sensitivity=75.35%, avg_specificity=95.46% avg_auc=94.56%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.222698 Test loss=0.250851 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.22231505811214447
[5/24] Train loss=0.2030942291021347
[10/24] Train loss=0.24926279485225677
[15/24] Train loss=0.2311377227306366
[20/24] Train loss=0.19211454689502716
Test set avg_accuracy=90.00% avg_sensitivity=81.10%, avg_specificity=92.99% avg_auc=94.09%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.224140 Test loss=0.267317 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2136954367160797
[5/24] Train loss=0.18957678973674774
[10/24] Train loss=0.2359037846326828
[15/24] Train loss=0.22463475167751312
[20/24] Train loss=0.18451333045959473
Test set avg_accuracy=89.43% avg_sensitivity=70.90%, avg_specificity=95.65% avg_auc=92.15%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.217637 Test loss=0.287899 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.210229754447937
[5/24] Train loss=0.20317915081977844
[10/24] Train loss=0.2437598705291748
[15/24] Train loss=0.2233344167470932
[20/24] Train loss=0.18580907583236694
Test set avg_accuracy=89.96% avg_sensitivity=76.44%, avg_specificity=94.50% avg_auc=93.88%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.219988 Test loss=0.272656 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.21485945582389832
[5/24] Train loss=0.1824064403772354
[10/24] Train loss=0.24417825043201447
[15/24] Train loss=0.22712527215480804
[20/24] Train loss=0.18947795033454895
Test set avg_accuracy=86.74% avg_sensitivity=84.57%, avg_specificity=87.48% avg_auc=92.69%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.219837 Test loss=0.354394 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.21651695668697357
[5/24] Train loss=0.1875634789466858
[10/24] Train loss=0.23562690615653992
[15/24] Train loss=0.23000088334083557
[20/24] Train loss=0.18321910500526428
Test set avg_accuracy=89.04% avg_sensitivity=81.56%, avg_specificity=91.55% avg_auc=93.62%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.221057 Test loss=0.282088 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2083953320980072
[5/24] Train loss=0.18594780564308167
[10/24] Train loss=0.22824187576770782
[15/24] Train loss=0.21377794444561005
[20/24] Train loss=0.1864737570285797
Test set avg_accuracy=88.92% avg_sensitivity=81.15%, avg_specificity=91.53% avg_auc=93.94%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.213809 Test loss=0.274839 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.21098265051841736
[5/24] Train loss=0.18142686784267426
[10/24] Train loss=0.22585956752300262
[15/24] Train loss=0.22909125685691833
[20/24] Train loss=0.17686547338962555
Test set avg_accuracy=68.29% avg_sensitivity=92.49%, avg_specificity=60.17% avg_auc=87.24%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.209916 Test loss=0.611998 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.21121162176132202
[5/24] Train loss=0.20638705790042877
[10/24] Train loss=0.22048060595989227
[15/24] Train loss=0.20602887868881226
[20/24] Train loss=0.1773659735918045
Test set avg_accuracy=89.45% avg_sensitivity=69.86%, avg_specificity=96.03% avg_auc=92.25%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.208199 Test loss=0.296628 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2068268358707428
[5/24] Train loss=0.16613493859767914
[10/24] Train loss=0.21097591519355774
[15/24] Train loss=0.22288425266742706
[20/24] Train loss=0.1737363636493683
Test set avg_accuracy=90.17% avg_sensitivity=72.86%, avg_specificity=95.98% avg_auc=93.91%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.206696 Test loss=0.264447 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.19555246829986572
[5/24] Train loss=0.17643125355243683
[10/24] Train loss=0.22511766850948334
[15/24] Train loss=0.21391671895980835
[20/24] Train loss=0.1799536794424057
Test set avg_accuracy=89.24% avg_sensitivity=70.48%, avg_specificity=95.55% avg_auc=91.42%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.203150 Test loss=0.300307 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.19788193702697754
[5/24] Train loss=0.19157394766807556
[10/24] Train loss=0.2078515738248825
[15/24] Train loss=0.21905875205993652
[20/24] Train loss=0.17560496926307678
Test set avg_accuracy=88.66% avg_sensitivity=79.23%, avg_specificity=91.82% avg_auc=91.98%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.202494 Test loss=0.305259 Current lr=[0.000299720220882401]

[0/24] Train loss=0.19746148586273193
[5/24] Train loss=0.17417961359024048
[10/24] Train loss=0.21198929846286774
[15/24] Train loss=0.21044863760471344
[20/24] Train loss=0.1697801649570465
Test set avg_accuracy=88.39% avg_sensitivity=63.44%, avg_specificity=96.76% avg_auc=88.81%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.201095 Test loss=0.344359 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.20081059634685516
[5/24] Train loss=0.17508119344711304
[10/24] Train loss=0.20784293115139008
[15/24] Train loss=0.20756228268146515
[20/24] Train loss=0.1647067815065384
Test set avg_accuracy=87.03% avg_sensitivity=82.76%, avg_specificity=88.47% avg_auc=92.95%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.197601 Test loss=0.316600 Current lr=[0.000298904600941902]

[0/24] Train loss=0.19614334404468536
[5/24] Train loss=0.17407402396202087
[10/24] Train loss=0.20329974591732025
[15/24] Train loss=0.20330992341041565
[20/24] Train loss=0.1724776029586792
Test set avg_accuracy=86.97% avg_sensitivity=55.77%, avg_specificity=97.44% avg_auc=88.79%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.198285 Test loss=0.356353 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2020314633846283
[5/24] Train loss=0.1750270277261734
[10/24] Train loss=0.19093622267246246
[15/24] Train loss=0.2089104801416397
[20/24] Train loss=0.17406880855560303
Test set avg_accuracy=88.87% avg_sensitivity=75.40%, avg_specificity=93.39% avg_auc=92.52%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.198717 Test loss=0.295990 Current lr=[0.000297555943323901]

[0/24] Train loss=0.19545616209506989
[5/24] Train loss=0.1783522367477417
[10/24] Train loss=0.21941381692886353
[15/24] Train loss=0.2213054597377777
[20/24] Train loss=0.17211899161338806
Test set avg_accuracy=87.75% avg_sensitivity=58.73%, avg_specificity=97.50% avg_auc=86.88%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.202381 Test loss=0.392787 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.20661891996860504
[5/24] Train loss=0.18178406357765198
[10/24] Train loss=0.2054089903831482
[15/24] Train loss=0.20722596347332
[20/24] Train loss=0.17731651663780212
Test set avg_accuracy=89.01% avg_sensitivity=75.97%, avg_specificity=93.39% avg_auc=91.55%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.202193 Test loss=0.306361 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19200459122657776
[5/24] Train loss=0.1820959448814392
[10/24] Train loss=0.1996455192565918
[15/24] Train loss=0.20087967813014984
[20/24] Train loss=0.16176186501979828
Test set avg_accuracy=89.11% avg_sensitivity=78.40%, avg_specificity=92.71% avg_auc=92.96%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.193337 Test loss=0.292351 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.18859565258026123
[5/24] Train loss=0.16986405849456787
[10/24] Train loss=0.19098667800426483
[15/24] Train loss=0.1894155591726303
[20/24] Train loss=0.16755975782871246
Test set avg_accuracy=89.15% avg_sensitivity=65.67%, avg_specificity=97.04% avg_auc=92.08%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.189440 Test loss=0.289677 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.19769860804080963
[5/24] Train loss=0.1679452806711197
[10/24] Train loss=0.2039983570575714
[15/24] Train loss=0.20338889956474304
[20/24] Train loss=0.1623087376356125
Test set avg_accuracy=88.95% avg_sensitivity=76.49%, avg_specificity=93.13% avg_auc=92.49%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.194168 Test loss=0.291195 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.18713605403900146
[5/24] Train loss=0.15577353537082672
[10/24] Train loss=0.1880853772163391
[15/24] Train loss=0.19357432425022125
[20/24] Train loss=0.16297966241836548
Test set avg_accuracy=89.36% avg_sensitivity=76.33%, avg_specificity=93.74% avg_auc=93.36%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.189572 Test loss=0.274875 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.19131460785865784
[5/24] Train loss=0.1668434590101242
[10/24] Train loss=0.20684075355529785
[15/24] Train loss=0.21426977217197418
[20/24] Train loss=0.15650874376296997
Test set avg_accuracy=88.53% avg_sensitivity=64.89%, avg_specificity=96.47% avg_auc=92.58%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.193375 Test loss=0.286478 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.1883848011493683
[5/24] Train loss=0.16253745555877686
[10/24] Train loss=0.18062490224838257
[15/24] Train loss=0.18662400543689728
[20/24] Train loss=0.16782140731811523
Test set avg_accuracy=84.08% avg_sensitivity=85.40%, avg_specificity=83.63% avg_auc=92.48%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.187315 Test loss=0.357609 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19292035698890686
[5/24] Train loss=0.16175255179405212
[10/24] Train loss=0.19762402772903442
[15/24] Train loss=0.19045569002628326
[20/24] Train loss=0.1674579381942749
Test set avg_accuracy=89.49% avg_sensitivity=75.30%, avg_specificity=94.26% avg_auc=93.20%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.189433 Test loss=0.280362 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2062648981809616
[5/24] Train loss=0.1599840372800827
[10/24] Train loss=0.18684950470924377
[15/24] Train loss=0.19443732500076294
[20/24] Train loss=0.15812000632286072
Test set avg_accuracy=88.44% avg_sensitivity=67.12%, avg_specificity=95.60% avg_auc=92.03%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.184483 Test loss=0.297316 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.18821501731872559
[5/24] Train loss=0.1648401916027069
[10/24] Train loss=0.17603060603141785
[15/24] Train loss=0.1880693882703781
[20/24] Train loss=0.1540595144033432
Test set avg_accuracy=88.58% avg_sensitivity=66.18%, avg_specificity=96.10% avg_auc=91.47%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.181885 Test loss=0.301172 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.18502217531204224
[5/24] Train loss=0.15252359211444855
[10/24] Train loss=0.18742384016513824
[15/24] Train loss=0.19201363623142242
[20/24] Train loss=0.1490883231163025
Test set avg_accuracy=89.87% avg_sensitivity=78.92%, avg_specificity=93.55% avg_auc=93.23%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.178613 Test loss=0.276745 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.18467389047145844
[5/24] Train loss=0.16065512597560883
[10/24] Train loss=0.18819421529769897
[15/24] Train loss=0.1886439174413681
[20/24] Train loss=0.15612539649009705
Test set avg_accuracy=85.52% avg_sensitivity=85.14%, avg_specificity=85.65% avg_auc=92.45%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.180954 Test loss=0.344195 Current lr=[0.000276307469034998]

[0/24] Train loss=0.17822802066802979
[5/24] Train loss=0.16126102209091187
[10/24] Train loss=0.17813199758529663
[15/24] Train loss=0.19428066909313202
[20/24] Train loss=0.15449674427509308
Test set avg_accuracy=88.32% avg_sensitivity=65.35%, avg_specificity=96.03% avg_auc=89.34%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.181671 Test loss=0.342189 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.18546441197395325
[5/24] Train loss=0.1541822850704193
[10/24] Train loss=0.1826920360326767
[15/24] Train loss=0.18858866393566132
[20/24] Train loss=0.14951781928539276
Test set avg_accuracy=89.35% avg_sensitivity=75.14%, avg_specificity=94.12% avg_auc=92.93%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.183906 Test loss=0.288320 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.19801007211208344
[5/24] Train loss=0.15900173783302307
[10/24] Train loss=0.1801934540271759
[15/24] Train loss=0.19799701869487762
[20/24] Train loss=0.14963935315608978
Test set avg_accuracy=88.97% avg_sensitivity=79.39%, avg_specificity=92.19% avg_auc=93.34%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.180812 Test loss=0.284043 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.18144504725933075
[5/24] Train loss=0.15972357988357544
[10/24] Train loss=0.18396376073360443
[15/24] Train loss=0.1864483654499054
[20/24] Train loss=0.15408854186534882
Test set avg_accuracy=89.02% avg_sensitivity=76.54%, avg_specificity=93.22% avg_auc=93.10%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.180051 Test loss=0.282222 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18517670035362244
[5/24] Train loss=0.1539471596479416
[10/24] Train loss=0.18701982498168945
[15/24] Train loss=0.1914689540863037
[20/24] Train loss=0.15390098094940186
Test set avg_accuracy=89.13% avg_sensitivity=81.25%, avg_specificity=91.77% avg_auc=93.57%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.180072 Test loss=0.283062 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.1792370080947876
[5/24] Train loss=0.14929156005382538
[10/24] Train loss=0.18204762041568756
[15/24] Train loss=0.1837836354970932
[20/24] Train loss=0.15566353499889374
Test set avg_accuracy=89.65% avg_sensitivity=73.85%, avg_specificity=94.96% avg_auc=92.92%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.176506 Test loss=0.276004 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.17630940675735474
[5/24] Train loss=0.15663248300552368
[10/24] Train loss=0.18181146681308746
[15/24] Train loss=0.18083448708057404
[20/24] Train loss=0.14657361805438995
Test set avg_accuracy=85.29% avg_sensitivity=85.19%, avg_specificity=85.32% avg_auc=92.07%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.173433 Test loss=0.361146 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1729419231414795
[5/24] Train loss=0.16796131432056427
[10/24] Train loss=0.1747814267873764
[15/24] Train loss=0.18512094020843506
[20/24] Train loss=0.1496659815311432
Test set avg_accuracy=85.59% avg_sensitivity=47.07%, avg_specificity=98.52% avg_auc=88.17%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.180947 Test loss=0.367026 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.1910598874092102
[5/24] Train loss=0.14954663813114166
[10/24] Train loss=0.17575375735759735
[15/24] Train loss=0.17985878884792328
[20/24] Train loss=0.14323855936527252
Test set avg_accuracy=88.53% avg_sensitivity=81.20%, avg_specificity=90.99% avg_auc=93.74%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.174213 Test loss=0.283337 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1714867651462555
[5/24] Train loss=0.15762139856815338
[10/24] Train loss=0.17544321715831757
[15/24] Train loss=0.18072275817394257
[20/24] Train loss=0.14734061062335968
Test set avg_accuracy=89.22% avg_sensitivity=79.49%, avg_specificity=92.49% avg_auc=93.81%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.170603 Test loss=0.270035 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.17146509885787964
[5/24] Train loss=0.15482430160045624
[10/24] Train loss=0.17544783651828766
[15/24] Train loss=0.17707717418670654
[20/24] Train loss=0.14193105697631836
Test set avg_accuracy=89.08% avg_sensitivity=81.72%, avg_specificity=91.55% avg_auc=94.11%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.174902 Test loss=0.276203 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17875322699546814
[5/24] Train loss=0.1529560536146164
[10/24] Train loss=0.18158118426799774
[15/24] Train loss=0.17858083546161652
[20/24] Train loss=0.15275415778160095
Test set avg_accuracy=87.34% avg_sensitivity=73.64%, avg_specificity=91.95% avg_auc=90.86%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.171454 Test loss=0.335270 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.17249660193920135
[5/24] Train loss=0.1497357189655304
[10/24] Train loss=0.18027131259441376
[15/24] Train loss=0.18500521779060364
[20/24] Train loss=0.14561273157596588
Test set avg_accuracy=87.54% avg_sensitivity=58.78%, avg_specificity=97.20% avg_auc=91.96%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.170829 Test loss=0.306428 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.17295345664024353
[5/24] Train loss=0.14744406938552856
[10/24] Train loss=0.16827841103076935
[15/24] Train loss=0.18806004524230957
[20/24] Train loss=0.14285504817962646
Test set avg_accuracy=88.46% avg_sensitivity=69.50%, avg_specificity=94.83% avg_auc=92.39%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.171311 Test loss=0.299476 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.18339641392230988
[5/24] Train loss=0.1581444889307022
[10/24] Train loss=0.17644743621349335
[15/24] Train loss=0.1731138527393341
[20/24] Train loss=0.14464229345321655
Test set avg_accuracy=88.70% avg_sensitivity=63.75%, avg_specificity=97.08% avg_auc=89.85%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.171497 Test loss=0.335117 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.17068105936050415
[5/24] Train loss=0.1474279761314392
[10/24] Train loss=0.17397178709506989
[15/24] Train loss=0.17538245022296906
[20/24] Train loss=0.16364996135234833
Test set avg_accuracy=86.37% avg_sensitivity=52.93%, avg_specificity=97.60% avg_auc=87.69%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.170896 Test loss=0.356382 Current lr=[0.000224838296036774]

[0/24] Train loss=0.1812332570552826
[5/24] Train loss=0.1523830145597458
[10/24] Train loss=0.17007166147232056
[15/24] Train loss=0.17437025904655457
[20/24] Train loss=0.13635258376598358
Test set avg_accuracy=89.62% avg_sensitivity=76.13%, avg_specificity=94.16% avg_auc=93.46%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.169509 Test loss=0.271801 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17759336531162262
[5/24] Train loss=0.14283709228038788
[10/24] Train loss=0.16381630301475525
[15/24] Train loss=0.16855774819850922
[20/24] Train loss=0.13504594564437866
Test set avg_accuracy=90.00% avg_sensitivity=78.61%, avg_specificity=93.83% avg_auc=93.20%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.164695 Test loss=0.274770 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.17277753353118896
[5/24] Train loss=0.1471690982580185
[10/24] Train loss=0.17124933004379272
[15/24] Train loss=0.1711347997188568
[20/24] Train loss=0.1491725742816925
Test set avg_accuracy=88.50% avg_sensitivity=71.15%, avg_specificity=94.33% avg_auc=90.41%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.165350 Test loss=0.307237 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.1670592576265335
[5/24] Train loss=0.1445809155702591
[10/24] Train loss=0.16732169687747955
[15/24] Train loss=0.16888213157653809
[20/24] Train loss=0.14409595727920532
Test set avg_accuracy=89.52% avg_sensitivity=74.31%, avg_specificity=94.63% avg_auc=92.72%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.165886 Test loss=0.283947 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17492708563804626
[5/24] Train loss=0.14469186961650848
[10/24] Train loss=0.16635406017303467
[15/24] Train loss=0.16516298055648804
[20/24] Train loss=0.15239152312278748
Test set avg_accuracy=88.33% avg_sensitivity=70.02%, avg_specificity=94.49% avg_auc=90.90%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.164983 Test loss=0.312359 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.173502579331398
[5/24] Train loss=0.15126025676727295
[10/24] Train loss=0.16135823726654053
[15/24] Train loss=0.17132160067558289
[20/24] Train loss=0.13981501758098602
Test set avg_accuracy=88.92% avg_sensitivity=72.71%, avg_specificity=94.36% avg_auc=93.11%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.165583 Test loss=0.280772 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1642967015504837
[5/24] Train loss=0.14831356704235077
[10/24] Train loss=0.1663879007101059
[15/24] Train loss=0.17198693752288818
[20/24] Train loss=0.1409084051847458
Test set avg_accuracy=85.86% avg_sensitivity=48.21%, avg_specificity=98.50% avg_auc=88.80%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.164804 Test loss=0.350399 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.1662949025630951
[5/24] Train loss=0.15002746880054474
[10/24] Train loss=0.15959131717681885
[15/24] Train loss=0.16520914435386658
[20/24] Train loss=0.13688933849334717
Test set avg_accuracy=87.60% avg_sensitivity=60.33%, avg_specificity=96.76% avg_auc=87.56%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.162196 Test loss=0.348949 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17162089049816132
[5/24] Train loss=0.14433430135250092
[10/24] Train loss=0.16141463816165924
[15/24] Train loss=0.16628709435462952
[20/24] Train loss=0.13686145842075348
Test set avg_accuracy=89.17% avg_sensitivity=73.95%, avg_specificity=94.28% avg_auc=91.12%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.163640 Test loss=0.300621 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.16556382179260254
[5/24] Train loss=0.13795465230941772
[10/24] Train loss=0.16525699198246002
[15/24] Train loss=0.16694189608097076
[20/24] Train loss=0.13314445316791534
Test set avg_accuracy=88.78% avg_sensitivity=73.74%, avg_specificity=93.83% avg_auc=91.27%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.157974 Test loss=0.310500 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.15905174612998962
[5/24] Train loss=0.143797367811203
[10/24] Train loss=0.1663832813501358
[15/24] Train loss=0.16758158802986145
[20/24] Train loss=0.13632100820541382
Test set avg_accuracy=86.67% avg_sensitivity=58.00%, avg_specificity=96.30% avg_auc=89.61%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.161297 Test loss=0.337472 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16998212039470673
[5/24] Train loss=0.14447711408138275
[10/24] Train loss=0.1638302356004715
[15/24] Train loss=0.17105945944786072
[20/24] Train loss=0.15087589621543884
Test set avg_accuracy=88.40% avg_sensitivity=63.23%, avg_specificity=96.85% avg_auc=90.75%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.165645 Test loss=0.302751 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.17656771838665009
[5/24] Train loss=0.14280684292316437
[10/24] Train loss=0.160696879029274
[15/24] Train loss=0.17372046411037445
[20/24] Train loss=0.14264710247516632
Test set avg_accuracy=88.79% avg_sensitivity=68.10%, avg_specificity=95.74% avg_auc=91.76%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.160477 Test loss=0.288998 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.16544973850250244
[5/24] Train loss=0.1436224728822708
[10/24] Train loss=0.15483435988426208
[15/24] Train loss=0.16947321593761444
[20/24] Train loss=0.13549011945724487
Test set avg_accuracy=89.70% avg_sensitivity=73.54%, avg_specificity=95.13% avg_auc=92.34%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.161168 Test loss=0.278419 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.16115538775920868
[5/24] Train loss=0.14993061125278473
[10/24] Train loss=0.15250903367996216
[15/24] Train loss=0.16365988552570343
[20/24] Train loss=0.13118724524974823
Test set avg_accuracy=88.76% avg_sensitivity=68.88%, avg_specificity=95.44% avg_auc=90.97%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.157109 Test loss=0.306227 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.1611693650484085
[5/24] Train loss=0.14071926474571228
[10/24] Train loss=0.1568952351808548
[15/24] Train loss=0.1564061939716339
[20/24] Train loss=0.13157059252262115
Test set avg_accuracy=88.42% avg_sensitivity=68.00%, avg_specificity=95.29% avg_auc=91.79%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.157658 Test loss=0.297534 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16341587901115417
[5/24] Train loss=0.13932672142982483
[10/24] Train loss=0.15535448491573334
[15/24] Train loss=0.1645687073469162
[20/24] Train loss=0.13625656068325043
Test set avg_accuracy=89.69% avg_sensitivity=79.39%, avg_specificity=93.15% avg_auc=93.70%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.157182 Test loss=0.274789 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.1625591516494751
[5/24] Train loss=0.1370287835597992
[10/24] Train loss=0.15352195501327515
[15/24] Train loss=0.15776924788951874
[20/24] Train loss=0.13348203897476196
Test set avg_accuracy=88.91% avg_sensitivity=65.87%, avg_specificity=96.64% avg_auc=91.18%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.153690 Test loss=0.298287 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.15795248746871948
[5/24] Train loss=0.13397851586341858
[10/24] Train loss=0.15669800341129303
[15/24] Train loss=0.15095902979373932
[20/24] Train loss=0.13632866740226746
Test set avg_accuracy=89.64% avg_sensitivity=73.17%, avg_specificity=95.16% avg_auc=93.28%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.152829 Test loss=0.271440 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1636938750743866
[5/24] Train loss=0.1408560574054718
[10/24] Train loss=0.1561405062675476
[15/24] Train loss=0.15652869641780853
[20/24] Train loss=0.12958180904388428
Test set avg_accuracy=89.40% avg_sensitivity=74.57%, avg_specificity=94.38% avg_auc=93.18%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.152556 Test loss=0.273437 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15398752689361572
[5/24] Train loss=0.14013977348804474
[10/24] Train loss=0.15409556031227112
[15/24] Train loss=0.16397725045681
[20/24] Train loss=0.13025657832622528
Test set avg_accuracy=89.38% avg_sensitivity=71.47%, avg_specificity=95.39% avg_auc=92.79%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.152506 Test loss=0.279165 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15526439249515533
[5/24] Train loss=0.14138689637184143
[10/24] Train loss=0.15260088443756104
[15/24] Train loss=0.1494055539369583
[20/24] Train loss=0.12958674132823944
Test set avg_accuracy=88.41% avg_sensitivity=63.34%, avg_specificity=96.83% avg_auc=91.57%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.151644 Test loss=0.296622 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15539470314979553
[5/24] Train loss=0.14166255295276642
[10/24] Train loss=0.1495995968580246
[15/24] Train loss=0.152155801653862
[20/24] Train loss=0.12749163806438446
Test set avg_accuracy=89.52% avg_sensitivity=75.30%, avg_specificity=94.29% avg_auc=92.82%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.148127 Test loss=0.274968 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15121406316757202
[5/24] Train loss=0.1359393447637558
[10/24] Train loss=0.150424525141716
[15/24] Train loss=0.149658665060997
[20/24] Train loss=0.1284504234790802
Test set avg_accuracy=89.65% avg_sensitivity=75.56%, avg_specificity=94.38% avg_auc=93.35%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.145988 Test loss=0.270752 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15144385397434235
[5/24] Train loss=0.13347163796424866
[10/24] Train loss=0.14723947644233704
[15/24] Train loss=0.14774076640605927
[20/24] Train loss=0.130989208817482
Test set avg_accuracy=88.76% avg_sensitivity=78.35%, avg_specificity=92.26% avg_auc=93.24%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.145539 Test loss=0.284788 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1503772884607315
[5/24] Train loss=0.13553714752197266
[10/24] Train loss=0.14906994998455048
[15/24] Train loss=0.1478649228811264
[20/24] Train loss=0.13047364354133606
Test set avg_accuracy=89.22% avg_sensitivity=76.33%, avg_specificity=93.55% avg_auc=93.69%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.145606 Test loss=0.271523 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.14984017610549927
[5/24] Train loss=0.13637562096118927
[10/24] Train loss=0.1417962908744812
[15/24] Train loss=0.14805802702903748
[20/24] Train loss=0.12431060522794724
Test set avg_accuracy=89.26% avg_sensitivity=72.24%, avg_specificity=94.97% avg_auc=92.59%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.144214 Test loss=0.282182 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.1523086130619049
[5/24] Train loss=0.13123077154159546
[10/24] Train loss=0.1393960416316986
[15/24] Train loss=0.14731799066066742
[20/24] Train loss=0.12867024540901184
Test set avg_accuracy=89.60% avg_sensitivity=75.50%, avg_specificity=94.33% avg_auc=92.95%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.144379 Test loss=0.274943 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.14071887731552124
[5/24] Train loss=0.12784597277641296
[10/24] Train loss=0.1441788524389267
[15/24] Train loss=0.13720908761024475
[20/24] Train loss=0.13090179860591888
Test set avg_accuracy=90.17% avg_sensitivity=77.63%, avg_specificity=94.38% avg_auc=93.16%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.144012 Test loss=0.269067 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.14682576060295105
[5/24] Train loss=0.1328846961259842
[10/24] Train loss=0.14275775849819183
[15/24] Train loss=0.14138218760490417
[20/24] Train loss=0.12293652445077896
Test set avg_accuracy=89.40% avg_sensitivity=74.78%, avg_specificity=94.31% avg_auc=93.18%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.142231 Test loss=0.275051 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.14473001658916473
[5/24] Train loss=0.1307488977909088
[10/24] Train loss=0.14408960938453674
[15/24] Train loss=0.1438339650630951
[20/24] Train loss=0.12604300677776337
Test set avg_accuracy=89.15% avg_sensitivity=72.97%, avg_specificity=94.59% avg_auc=92.88%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.140956 Test loss=0.278048 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1415318250656128
[5/24] Train loss=0.13476336002349854
[10/24] Train loss=0.1400497853755951
[15/24] Train loss=0.1433328241109848
[20/24] Train loss=0.12079010158777237
Test set avg_accuracy=88.39% avg_sensitivity=75.45%, avg_specificity=92.73% avg_auc=92.85%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.141744 Test loss=0.284695 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14284856617450714
[5/24] Train loss=0.12836961448192596
[10/24] Train loss=0.13904111087322235
[15/24] Train loss=0.14212170243263245
[20/24] Train loss=0.12347347289323807
Test set avg_accuracy=88.87% avg_sensitivity=66.08%, avg_specificity=96.52% avg_auc=91.86%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.141909 Test loss=0.296100 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14692677557468414
[5/24] Train loss=0.13383617997169495
[10/24] Train loss=0.13673414289951324
[15/24] Train loss=0.14159995317459106
[20/24] Train loss=0.12384697794914246
Test set avg_accuracy=90.00% avg_sensitivity=73.80%, avg_specificity=95.44% avg_auc=92.90%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.141934 Test loss=0.272086 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1437017172574997
[5/24] Train loss=0.126323863863945
[10/24] Train loss=0.13836632668972015
[15/24] Train loss=0.14370086789131165
[20/24] Train loss=0.1216292753815651
Test set avg_accuracy=88.57% avg_sensitivity=77.52%, avg_specificity=92.28% avg_auc=92.17%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.139361 Test loss=0.300918 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.14053180813789368
[5/24] Train loss=0.125125452876091
[10/24] Train loss=0.1347775161266327
[15/24] Train loss=0.13385289907455444
[20/24] Train loss=0.11762680113315582
Test set avg_accuracy=89.26% avg_sensitivity=70.12%, avg_specificity=95.69% avg_auc=91.93%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.136341 Test loss=0.290737 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1367432028055191
[5/24] Train loss=0.12746009230613708
[10/24] Train loss=0.1301327347755432
[15/24] Train loss=0.14008185267448425
[20/24] Train loss=0.12183848023414612
Test set avg_accuracy=89.23% avg_sensitivity=75.35%, avg_specificity=93.89% avg_auc=92.70%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.135948 Test loss=0.282890 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.13763625919818878
[5/24] Train loss=0.12704619765281677
[10/24] Train loss=0.13220913708209991
[15/24] Train loss=0.13014554977416992
[20/24] Train loss=0.11906427145004272
Test set avg_accuracy=89.43% avg_sensitivity=77.01%, avg_specificity=93.60% avg_auc=92.73%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.134926 Test loss=0.284013 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.13536131381988525
[5/24] Train loss=0.12396596372127533
[10/24] Train loss=0.13143838942050934
[15/24] Train loss=0.1322164535522461
[20/24] Train loss=0.11875013262033463
Test set avg_accuracy=89.49% avg_sensitivity=72.50%, avg_specificity=95.20% avg_auc=92.88%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.133432 Test loss=0.278744 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1368006467819214
[5/24] Train loss=0.12245399504899979
[10/24] Train loss=0.13052590191364288
[15/24] Train loss=0.12999439239501953
[20/24] Train loss=0.11742794513702393
Test set avg_accuracy=89.92% avg_sensitivity=80.42%, avg_specificity=93.11% avg_auc=93.20%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.132700 Test loss=0.289513 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.13688404858112335
[5/24] Train loss=0.12187356501817703
[10/24] Train loss=0.12593576312065125
[15/24] Train loss=0.1311381757259369
[20/24] Train loss=0.11628900468349457
Test set avg_accuracy=89.23% avg_sensitivity=78.25%, avg_specificity=92.92% avg_auc=92.81%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.130924 Test loss=0.287249 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.13176295161247253
[5/24] Train loss=0.12351468950510025
[10/24] Train loss=0.12875431776046753
[15/24] Train loss=0.12971942126750946
[20/24] Train loss=0.11424939334392548
Test set avg_accuracy=89.90% avg_sensitivity=76.39%, avg_specificity=94.43% avg_auc=92.85%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.130090 Test loss=0.279641 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.13109783828258514
[5/24] Train loss=0.12267404049634933
[10/24] Train loss=0.12766367197036743
[15/24] Train loss=0.12769001722335815
[20/24] Train loss=0.11684038490056992
Test set avg_accuracy=89.51% avg_sensitivity=76.39%, avg_specificity=93.91% avg_auc=93.04%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.130180 Test loss=0.278206 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13082021474838257
[5/24] Train loss=0.12136761844158173
[10/24] Train loss=0.12677344679832458
[15/24] Train loss=0.12840400636196136
[20/24] Train loss=0.11540406942367554
Test set avg_accuracy=89.57% avg_sensitivity=73.85%, avg_specificity=94.85% avg_auc=92.75%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.129609 Test loss=0.278271 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.13187633454799652
[5/24] Train loss=0.12202431261539459
[10/24] Train loss=0.13121318817138672
[15/24] Train loss=0.12863905727863312
[20/24] Train loss=0.11628679186105728
Test set avg_accuracy=89.40% avg_sensitivity=73.43%, avg_specificity=94.76% avg_auc=92.57%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.129248 Test loss=0.282436 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.13192588090896606
[5/24] Train loss=0.11770595610141754
[10/24] Train loss=0.12395317852497101
[15/24] Train loss=0.1299620419740677
[20/24] Train loss=0.11184056848287582
Test set avg_accuracy=88.88% avg_sensitivity=68.20%, avg_specificity=95.83% avg_auc=91.94%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.128091 Test loss=0.288553 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1301881968975067
[5/24] Train loss=0.11933708935976028
[10/24] Train loss=0.12329506874084473
[15/24] Train loss=0.12576916813850403
[20/24] Train loss=0.11440474539995193
Test set avg_accuracy=89.36% avg_sensitivity=70.84%, avg_specificity=95.58% avg_auc=92.51%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.127706 Test loss=0.281441 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13113033771514893
[5/24] Train loss=0.1172260195016861
[10/24] Train loss=0.12229771912097931
[15/24] Train loss=0.12624390423297882
[20/24] Train loss=0.11304278671741486
Test set avg_accuracy=89.52% avg_sensitivity=70.95%, avg_specificity=95.76% avg_auc=92.98%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.127765 Test loss=0.275263 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13040995597839355
[5/24] Train loss=0.11881666630506516
[10/24] Train loss=0.1231757253408432
[15/24] Train loss=0.12429873645305634
[20/24] Train loss=0.11302412301301956
Test set avg_accuracy=89.48% avg_sensitivity=75.45%, avg_specificity=94.19% avg_auc=92.83%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.127544 Test loss=0.282401 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.12994897365570068
[5/24] Train loss=0.11842941492795944
[10/24] Train loss=0.1231062188744545
[15/24] Train loss=0.1255909949541092
[20/24] Train loss=0.11329449713230133
Test set avg_accuracy=89.57% avg_sensitivity=73.33%, avg_specificity=95.03% avg_auc=92.51%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.127253 Test loss=0.282885 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.12840628623962402
[5/24] Train loss=0.11811114102602005
[10/24] Train loss=0.12034590542316437
[15/24] Train loss=0.1252797394990921
[20/24] Train loss=0.11109741777181625
Test set avg_accuracy=89.11% avg_sensitivity=79.65%, avg_specificity=92.29% avg_auc=92.56%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.126228 Test loss=0.293321 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.12741416692733765
[5/24] Train loss=0.11843979358673096
[10/24] Train loss=0.12263548374176025
[15/24] Train loss=0.12268470972776413
[20/24] Train loss=0.11148659139871597
Test set avg_accuracy=89.44% avg_sensitivity=76.07%, avg_specificity=93.93% avg_auc=92.63%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.125804 Test loss=0.284079 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.12783415615558624
[5/24] Train loss=0.1162971630692482
[10/24] Train loss=0.12380891293287277
[15/24] Train loss=0.12364855408668518
[20/24] Train loss=0.11217288672924042
Test set avg_accuracy=89.18% avg_sensitivity=76.64%, avg_specificity=93.39% avg_auc=92.81%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.125898 Test loss=0.282784 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.12803417444229126
[5/24] Train loss=0.1186198741197586
[10/24] Train loss=0.12159086018800735
[15/24] Train loss=0.1219756007194519
[20/24] Train loss=0.11211783438920975
Test set avg_accuracy=89.44% avg_sensitivity=74.99%, avg_specificity=94.29% avg_auc=92.59%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.125511 Test loss=0.282134 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.12847182154655457
[5/24] Train loss=0.11622655391693115
[10/24] Train loss=0.1186419352889061
[15/24] Train loss=0.12062598019838333
[20/24] Train loss=0.10825880616903305
Test set avg_accuracy=89.34% avg_sensitivity=75.66%, avg_specificity=93.93% avg_auc=92.61%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.123788 Test loss=0.282783 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.12573714554309845
[5/24] Train loss=0.11395178735256195
[10/24] Train loss=0.11964918673038483
[15/24] Train loss=0.12117383629083633
[20/24] Train loss=0.11043906956911087
Test set avg_accuracy=89.61% avg_sensitivity=75.61%, avg_specificity=94.31% avg_auc=92.90%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.123347 Test loss=0.277262 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.12677642703056335
[5/24] Train loss=0.1150176152586937
[10/24] Train loss=0.11742689460515976
[15/24] Train loss=0.12116658687591553
[20/24] Train loss=0.10845917463302612
Test set avg_accuracy=89.84% avg_sensitivity=78.04%, avg_specificity=93.81% avg_auc=92.88%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.122759 Test loss=0.278928 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1245003342628479
[5/24] Train loss=0.1129615381360054
[10/24] Train loss=0.11615236848592758
[15/24] Train loss=0.11969832330942154
[20/24] Train loss=0.11032364517450333
Test set avg_accuracy=89.65% avg_sensitivity=75.50%, avg_specificity=94.40% avg_auc=92.56%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.121709 Test loss=0.282742 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1252584159374237
[5/24] Train loss=0.11195771396160126
[10/24] Train loss=0.1186748594045639
[15/24] Train loss=0.11761882901191711
[20/24] Train loss=0.11047112196683884
Test set avg_accuracy=89.66% avg_sensitivity=76.49%, avg_specificity=94.09% avg_auc=92.79%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.121794 Test loss=0.278930 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.12349076569080353
[5/24] Train loss=0.11282055824995041
[10/24] Train loss=0.11631440371274948
[15/24] Train loss=0.11871392279863358
[20/24] Train loss=0.1083705797791481
Test set avg_accuracy=89.69% avg_sensitivity=75.56%, avg_specificity=94.43% avg_auc=92.60%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.121371 Test loss=0.280724 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.12621168792247772
[5/24] Train loss=0.11276323348283768
[10/24] Train loss=0.11696765571832657
[15/24] Train loss=0.11993914842605591
[20/24] Train loss=0.10802341252565384
Test set avg_accuracy=89.70% avg_sensitivity=76.28%, avg_specificity=94.21% avg_auc=92.80%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.121484 Test loss=0.278573 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12400612235069275
[5/24] Train loss=0.11305659264326096
[10/24] Train loss=0.11671946942806244
[15/24] Train loss=0.11987462639808655
[20/24] Train loss=0.11124808341264725
Test set avg_accuracy=89.86% avg_sensitivity=76.28%, avg_specificity=94.42% avg_auc=92.97%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.121144 Test loss=0.276354 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12499852478504181
[5/24] Train loss=0.11226090043783188
[10/24] Train loss=0.11703003942966461
[15/24] Train loss=0.11983729153871536
[20/24] Train loss=0.10887379199266434
Test set avg_accuracy=89.87% avg_sensitivity=76.23%, avg_specificity=94.45% avg_auc=92.74%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.121363 Test loss=0.278772 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12205933034420013
[5/24] Train loss=0.11424774676561356
[10/24] Train loss=0.11571948975324631
[15/24] Train loss=0.12052139639854431
[20/24] Train loss=0.10856591165065765
Test set avg_accuracy=89.67% avg_sensitivity=76.44%, avg_specificity=94.12% avg_auc=92.70%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.120568 Test loss=0.280281 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1228037029504776
[5/24] Train loss=0.11302905529737473
[10/24] Train loss=0.11631719768047333
[15/24] Train loss=0.1188671663403511
[20/24] Train loss=0.10793271660804749
Test set avg_accuracy=89.78% avg_sensitivity=75.92%, avg_specificity=94.43% avg_auc=92.73%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.120159 Test loss=0.279294 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.12177390605211258
[5/24] Train loss=0.11201532185077667
[10/24] Train loss=0.11552359163761139
[15/24] Train loss=0.11752764135599136
[20/24] Train loss=0.10705017298460007
Test set avg_accuracy=89.74% avg_sensitivity=75.82%, avg_specificity=94.42% avg_auc=92.75%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.120205 Test loss=0.279340 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.12353341281414032
[5/24] Train loss=0.11229372024536133
[10/24] Train loss=0.11580748856067657
[15/24] Train loss=0.11990484595298767
[20/24] Train loss=0.10652317106723785
Test set avg_accuracy=89.84% avg_sensitivity=75.97%, avg_specificity=94.50% avg_auc=92.72%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.120311 Test loss=0.279264 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1247430369257927
[5/24] Train loss=0.11264245957136154
[10/24] Train loss=0.1157948449254036
[15/24] Train loss=0.1187133863568306
[20/24] Train loss=0.10921181738376617
Test set avg_accuracy=89.82% avg_sensitivity=76.07%, avg_specificity=94.43% avg_auc=92.75%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.120327 Test loss=0.279030 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12290102988481522
[5/24] Train loss=0.11135067045688629
[10/24] Train loss=0.1153254434466362
[15/24] Train loss=0.12040601670742035
[20/24] Train loss=0.10584273934364319
Test set avg_accuracy=89.71% avg_sensitivity=76.28%, avg_specificity=94.23% avg_auc=92.76%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.119886 Test loss=0.278946 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1236252561211586
[5/24] Train loss=0.11244547367095947
[10/24] Train loss=0.1154816672205925
[15/24] Train loss=0.11847453564405441
[20/24] Train loss=0.10964484512805939
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.66% avg_sensitivity=76.07%, avg_specificity=94.23% avg_auc=92.74%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.120211 Test loss=0.279096 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=90.44% sen=82.65%, spe=93.06%, auc=94.85%!
Fold[8] Avg_overlap=0.71%(0.21665026025995765)
[0/23] Train loss=0.727591335773468
[5/23] Train loss=0.7242640852928162
[10/23] Train loss=0.7273297309875488
[15/23] Train loss=0.7120733261108398
[20/23] Train loss=0.702450156211853
Test set avg_accuracy=66.98% avg_sensitivity=51.37%, avg_specificity=71.95% avg_auc=58.19%
Best model saved!! Metric=-77.50845639130216!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.719163 Test loss=0.673252 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7006103992462158
[5/23] Train loss=0.6902744770050049
[10/23] Train loss=0.6985092759132385
[15/23] Train loss=0.6857460737228394
[20/23] Train loss=0.6745007038116455
Test set avg_accuracy=71.42% avg_sensitivity=67.22%, avg_specificity=72.76% avg_auc=67.15%
Best model saved!! Metric=-47.45243422086422!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.691683 Test loss=0.641650 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6676826477050781
[5/23] Train loss=0.674677312374115
[10/23] Train loss=0.670059084892273
[15/23] Train loss=0.6534252762794495
[20/23] Train loss=0.6516607999801636
Test set avg_accuracy=73.23% avg_sensitivity=71.81%, avg_specificity=73.68% avg_auc=72.48%
Best model saved!! Metric=-34.80244722919534!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.665790 Test loss=0.608258 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6488752961158752
[5/23] Train loss=0.6479764580726624
[10/23] Train loss=0.6496894955635071
[15/23] Train loss=0.6346615552902222
[20/23] Train loss=0.619178056716919
Test set avg_accuracy=74.01% avg_sensitivity=77.30%, avg_specificity=72.96% avg_auc=76.56%
Best model saved!! Metric=-25.162661546722504!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.641524 Test loss=0.584279 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6227582097053528
[5/23] Train loss=0.6148259043693542
[10/23] Train loss=0.6257577538490295
[15/23] Train loss=0.6018933653831482
[20/23] Train loss=0.597299337387085
Test set avg_accuracy=75.07% avg_sensitivity=79.95%, avg_specificity=73.51% avg_auc=79.69%
Best model saved!! Metric=-17.784792296898928!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.614078 Test loss=0.558379 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.5903586149215698
[5/23] Train loss=0.5887526273727417
[10/23] Train loss=0.6010134816169739
[15/23] Train loss=0.5700883269309998
[20/23] Train loss=0.5693826079368591
Test set avg_accuracy=75.47% avg_sensitivity=82.05%, avg_specificity=73.37% avg_auc=81.92%
Best model saved!! Metric=-13.193721223812219!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.586469 Test loss=0.536620 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.5630184412002563
[5/23] Train loss=0.5597273111343384
[10/23] Train loss=0.5675022602081299
[15/23] Train loss=0.5417045950889587
[20/23] Train loss=0.5401341915130615
Test set avg_accuracy=77.14% avg_sensitivity=81.02%, avg_specificity=75.90% avg_auc=84.22%
Best model saved!! Metric=-7.72251283601139!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.556601 Test loss=0.503684 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.5350544452667236
[5/23] Train loss=0.5227869749069214
[10/23] Train loss=0.5372786521911621
[15/23] Train loss=0.514281690120697
[20/23] Train loss=0.5076326727867126
Test set avg_accuracy=78.91% avg_sensitivity=79.68%, avg_specificity=78.66% avg_auc=86.23%
Best model saved!! Metric=-2.5299009896694855!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.528787 Test loss=0.475466 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.5055279731750488
[5/23] Train loss=0.4985656142234802
[10/23] Train loss=0.5065021514892578
[15/23] Train loss=0.48630020022392273
[20/23] Train loss=0.4808855652809143
Test set avg_accuracy=81.71% avg_sensitivity=77.52%, avg_specificity=83.04% avg_auc=88.28%
Best model saved!! Metric=4.541961134553006!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.499054 Test loss=0.444644 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.46909260749816895
[5/23] Train loss=0.4768825173377991
[10/23] Train loss=0.4753657877445221
[15/23] Train loss=0.4597627818584442
[20/23] Train loss=0.448413223028183
Test set avg_accuracy=84.96% avg_sensitivity=74.12%, avg_specificity=88.41% avg_auc=89.53%
Best model saved!! Metric=11.023702559056261!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.468707 Test loss=0.410489 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.44420909881591797
[5/23] Train loss=0.43515217304229736
[10/23] Train loss=0.45180508494377136
[15/23] Train loss=0.4291994869709015
[20/23] Train loss=0.4186028242111206
Test set avg_accuracy=86.93% avg_sensitivity=73.58%, avg_specificity=91.18% avg_auc=90.55%
Best model saved!! Metric=16.234983336803808!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.439875 Test loss=0.384178 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.41556239128112793
[5/23] Train loss=0.4076319634914398
[10/23] Train loss=0.42459115386009216
[15/23] Train loss=0.40741774439811707
[20/23] Train loss=0.39182260632514954
Test set avg_accuracy=87.80% avg_sensitivity=70.73%, avg_specificity=93.24% avg_auc=91.55%
Best model saved!! Metric=17.314415020350623!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.414299 Test loss=0.355894 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.3948070704936981
[5/23] Train loss=0.3902650475502014
[10/23] Train loss=0.4074341058731079
[15/23] Train loss=0.38403087854385376
[20/23] Train loss=0.36939412355422974
Test set avg_accuracy=88.19% avg_sensitivity=67.12%, avg_specificity=94.90% avg_auc=91.92%
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.391390 Test loss=0.337874 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.3673085868358612
[5/23] Train loss=0.36786162853240967
[10/23] Train loss=0.3896031975746155
[15/23] Train loss=0.3591599464416504
[20/23] Train loss=0.34600162506103516
Test set avg_accuracy=88.80% avg_sensitivity=68.25%, avg_specificity=95.35% avg_auc=92.19%
Best model saved!! Metric=18.584747053935374!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.372322 Test loss=0.325373 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.3502708971500397
[5/23] Train loss=0.3406406342983246
[10/23] Train loss=0.369243323802948
[15/23] Train loss=0.34217098355293274
[20/23] Train loss=0.33271098136901855
Test set avg_accuracy=89.14% avg_sensitivity=70.30%, avg_specificity=95.14% avg_auc=92.60%
Best model saved!! Metric=21.18370078404267!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.354833 Test loss=0.317244 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.33882084488868713
[5/23] Train loss=0.32551226019859314
[10/23] Train loss=0.3578994870185852
[15/23] Train loss=0.3277113735675812
[20/23] Train loss=0.308704137802124
Test set avg_accuracy=89.18% avg_sensitivity=67.49%, avg_specificity=96.09% avg_auc=92.86%
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.338773 Test loss=0.302021 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.32041317224502563
[5/23] Train loss=0.3148745894432068
[10/23] Train loss=0.34759625792503357
[15/23] Train loss=0.31511014699935913
[20/23] Train loss=0.2927265465259552
Test set avg_accuracy=89.39% avg_sensitivity=67.87%, avg_specificity=96.24% avg_auc=92.74%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.327725 Test loss=0.296842 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.31241661310195923
[5/23] Train loss=0.29655227065086365
[10/23] Train loss=0.33406561613082886
[15/23] Train loss=0.30475667119026184
[20/23] Train loss=0.28894349932670593
Test set avg_accuracy=89.92% avg_sensitivity=68.03%, avg_specificity=96.89% avg_auc=92.85%
Best model saved!! Metric=21.70178546122881!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.317577 Test loss=0.292382 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.3013538420200348
[5/23] Train loss=0.28808698058128357
[10/23] Train loss=0.32871299982070923
[15/23] Train loss=0.29587695002555847
[20/23] Train loss=0.2749332785606384
Test set avg_accuracy=89.38% avg_sensitivity=75.20%, avg_specificity=93.89% avg_auc=93.66%
Best model saved!! Metric=26.127731857987342!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.308614 Test loss=0.288559 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.29153960943222046
[5/23] Train loss=0.2790735065937042
[10/23] Train loss=0.3181583285331726
[15/23] Train loss=0.28062695264816284
[20/23] Train loss=0.2652274966239929
Test set avg_accuracy=90.01% avg_sensitivity=69.60%, avg_specificity=96.52% avg_auc=93.54%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.298080 Test loss=0.278408 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.2782377302646637
[5/23] Train loss=0.26983240246772766
[10/23] Train loss=0.3137693703174591
[15/23] Train loss=0.2772168219089508
[20/23] Train loss=0.260873019695282
Test set avg_accuracy=90.34% avg_sensitivity=68.89%, avg_specificity=97.17% avg_auc=93.73%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.291677 Test loss=0.272644 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.2787349820137024
[5/23] Train loss=0.26797088980674744
[10/23] Train loss=0.3186248540878296
[15/23] Train loss=0.2717863619327545
[20/23] Train loss=0.2592223286628723
Test set avg_accuracy=89.83% avg_sensitivity=64.37%, avg_specificity=97.94% avg_auc=93.80%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.286223 Test loss=0.269561 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.2682865858078003
[5/23] Train loss=0.2521553933620453
[10/23] Train loss=0.2981501519680023
[15/23] Train loss=0.26018282771110535
[20/23] Train loss=0.24327276647090912
Test set avg_accuracy=90.27% avg_sensitivity=70.08%, avg_specificity=96.70% avg_auc=93.94%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.277845 Test loss=0.266334 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.2651078999042511
[5/23] Train loss=0.24972443282604218
[10/23] Train loss=0.2994006872177124
[15/23] Train loss=0.2612021863460541
[20/23] Train loss=0.24096231162548065
Test set avg_accuracy=90.16% avg_sensitivity=67.87%, avg_specificity=97.25% avg_auc=93.96%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.274268 Test loss=0.263651 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.26508980989456177
[5/23] Train loss=0.2476998120546341
[10/23] Train loss=0.2851635217666626
[15/23] Train loss=0.25202077627182007
[20/23] Train loss=0.2433934062719345
Test set avg_accuracy=89.40% avg_sensitivity=61.35%, avg_specificity=98.33% avg_auc=93.48%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.269254 Test loss=0.275128 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.25285273790359497
[5/23] Train loss=0.2373095601797104
[10/23] Train loss=0.28478875756263733
[15/23] Train loss=0.248779758810997
[20/23] Train loss=0.2312624454498291
Test set avg_accuracy=89.64% avg_sensitivity=61.51%, avg_specificity=98.59% avg_auc=93.95%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.263078 Test loss=0.269025 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.2559409737586975
[5/23] Train loss=0.2343742549419403
[10/23] Train loss=0.278401643037796
[15/23] Train loss=0.23999978601932526
[20/23] Train loss=0.22892513871192932
Test set avg_accuracy=89.70% avg_sensitivity=62.64%, avg_specificity=98.32% avg_auc=93.51%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.257767 Test loss=0.273912 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.24366949498653412
[5/23] Train loss=0.2211674451828003
[10/23] Train loss=0.2752591073513031
[15/23] Train loss=0.23727786540985107
[20/23] Train loss=0.21976526081562042
Test set avg_accuracy=89.17% avg_sensitivity=60.16%, avg_specificity=98.40% avg_auc=93.13%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.252226 Test loss=0.281292 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.2381758838891983
[5/23] Train loss=0.23692303895950317
[10/23] Train loss=0.2664123475551605
[15/23] Train loss=0.24305576086044312
[20/23] Train loss=0.21310624480247498
Test set avg_accuracy=89.21% avg_sensitivity=78.98%, avg_specificity=92.46% avg_auc=94.17%
Best model saved!! Metric=28.81042127591786!!
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.250241 Test loss=0.268954 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.23455440998077393
[5/23] Train loss=0.21388386189937592
[10/23] Train loss=0.26098474860191345
[15/23] Train loss=0.2322128266096115
[20/23] Train loss=0.2095457762479782
Test set avg_accuracy=88.07% avg_sensitivity=82.80%, avg_specificity=89.75% avg_auc=93.98%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.245703 Test loss=0.293559 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.23089152574539185
[5/23] Train loss=0.21923518180847168
[10/23] Train loss=0.2594881057739258
[15/23] Train loss=0.22975951433181763
[20/23] Train loss=0.2093973010778427
Test set avg_accuracy=90.68% avg_sensitivity=68.57%, avg_specificity=97.72% avg_auc=94.15%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.241830 Test loss=0.257264 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.22831323742866516
[5/23] Train loss=0.20315779745578766
[10/23] Train loss=0.2554249167442322
[15/23] Train loss=0.22642076015472412
[20/23] Train loss=0.21057817339897156
Test set avg_accuracy=87.33% avg_sensitivity=80.97%, avg_specificity=89.36% avg_auc=93.41%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.234753 Test loss=0.296530 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.22419819235801697
[5/23] Train loss=0.21055664122104645
[10/23] Train loss=0.24842041730880737
[15/23] Train loss=0.22835764288902283
[20/23] Train loss=0.20710647106170654
Test set avg_accuracy=90.21% avg_sensitivity=69.92%, avg_specificity=96.67% avg_auc=93.89%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.233025 Test loss=0.256258 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.22135885059833527
[5/23] Train loss=0.20046859979629517
[10/23] Train loss=0.24429532885551453
[15/23] Train loss=0.23494432866573334
[20/23] Train loss=0.2101375311613083
Test set avg_accuracy=87.71% avg_sensitivity=82.48%, avg_specificity=89.37% avg_auc=93.71%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.234327 Test loss=0.293777 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.2268773764371872
[5/23] Train loss=0.19830940663814545
[10/23] Train loss=0.23770472407341003
[15/23] Train loss=0.2184334099292755
[20/23] Train loss=0.2101062536239624
Test set avg_accuracy=87.59% avg_sensitivity=83.40%, avg_specificity=88.93% avg_auc=93.93%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.231182 Test loss=0.299565 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.22876371443271637
[5/23] Train loss=0.18912386894226074
[10/23] Train loss=0.21956096589565277
[15/23] Train loss=0.21886423230171204
[20/23] Train loss=0.2043883502483368
Test set avg_accuracy=85.09% avg_sensitivity=82.75%, avg_specificity=85.84% avg_auc=92.54%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.224049 Test loss=0.326370 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.21997840702533722
[5/23] Train loss=0.19459660351276398
[10/23] Train loss=0.24507774412631989
[15/23] Train loss=0.22255690395832062
[20/23] Train loss=0.19675543904304504
Test set avg_accuracy=82.16% avg_sensitivity=86.42%, avg_specificity=80.81% avg_auc=91.50%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.224427 Test loss=0.402200 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.2149355113506317
[5/23] Train loss=0.18477857112884521
[10/23] Train loss=0.2332172691822052
[15/23] Train loss=0.22282083332538605
[20/23] Train loss=0.1967100203037262
Test set avg_accuracy=90.35% avg_sensitivity=71.27%, avg_specificity=96.43% avg_auc=93.68%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.221098 Test loss=0.259631 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.21812330186367035
[5/23] Train loss=0.1971239298582077
[10/23] Train loss=0.23850160837173462
[15/23] Train loss=0.22191976010799408
[20/23] Train loss=0.19387729465961456
Test set avg_accuracy=90.04% avg_sensitivity=79.08%, avg_specificity=93.53% avg_auc=93.91%
Best model saved!! Metric=30.56138125339818!!
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.225572 Test loss=0.264402 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.21261680126190186
[5/23] Train loss=0.19329093396663666
[10/23] Train loss=0.21482917666435242
[15/23] Train loss=0.22353483736515045
[20/23] Train loss=0.20010587573051453
Test set avg_accuracy=88.80% avg_sensitivity=81.02%, avg_specificity=91.28% avg_auc=94.46%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.216641 Test loss=0.268406 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.2069515585899353
[5/23] Train loss=0.17077864706516266
[10/23] Train loss=0.21055689454078674
[15/23] Train loss=0.21113771200180054
[20/23] Train loss=0.1966342329978943
Test set avg_accuracy=88.62% avg_sensitivity=81.19%, avg_specificity=90.99% avg_auc=94.05%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.211127 Test loss=0.276646 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.19767633080482483
[5/23] Train loss=0.17537356913089752
[10/23] Train loss=0.20617876946926117
[15/23] Train loss=0.21379072964191437
[20/23] Train loss=0.18750666081905365
Test set avg_accuracy=87.14% avg_sensitivity=84.20%, avg_specificity=88.07% avg_auc=94.24%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.214115 Test loss=0.300544 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.2101708948612213
[5/23] Train loss=0.18490448594093323
[10/23] Train loss=0.21386367082595825
[15/23] Train loss=0.2126728743314743
[20/23] Train loss=0.18702955543994904
Test set avg_accuracy=90.16% avg_sensitivity=69.60%, avg_specificity=96.70% avg_auc=93.94%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.211703 Test loss=0.255897 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.2070188969373703
[5/23] Train loss=0.16758227348327637
[10/23] Train loss=0.22050748765468597
[15/23] Train loss=0.2127785086631775
[20/23] Train loss=0.18906792998313904
Test set avg_accuracy=90.14% avg_sensitivity=72.51%, avg_specificity=95.76% avg_auc=93.89%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.213219 Test loss=0.256211 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.19531549513339996
[5/23] Train loss=0.17351481318473816
[10/23] Train loss=0.19625654816627502
[15/23] Train loss=0.21187560260295868
[20/23] Train loss=0.18994887173175812
Test set avg_accuracy=90.03% avg_sensitivity=74.18%, avg_specificity=95.07% avg_auc=94.12%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.208761 Test loss=0.259275 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.2056381106376648
[5/23] Train loss=0.17521703243255615
[10/23] Train loss=0.19651204347610474
[15/23] Train loss=0.21009598672389984
[20/23] Train loss=0.18443165719509125
Test set avg_accuracy=88.18% avg_sensitivity=56.28%, avg_specificity=98.33% avg_auc=91.02%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.207648 Test loss=0.323222 Current lr=[0.000299926900870094]

[0/23] Train loss=0.2126874029636383
[5/23] Train loss=0.16379980742931366
[10/23] Train loss=0.20115815103054047
[15/23] Train loss=0.22130408883094788
[20/23] Train loss=0.17854492366313934
Test set avg_accuracy=90.14% avg_sensitivity=68.79%, avg_specificity=96.94% avg_auc=93.43%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.208394 Test loss=0.267346 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.18951678276062012
[5/23] Train loss=0.17071478068828583
[10/23] Train loss=0.1937268227338791
[15/23] Train loss=0.20745918154716492
[20/23] Train loss=0.17378449440002441
Test set avg_accuracy=77.41% avg_sensitivity=88.57%, avg_specificity=73.85% avg_auc=89.38%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.201228 Test loss=0.479499 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.20819710195064545
[5/23] Train loss=0.167072132229805
[10/23] Train loss=0.196980819106102
[15/23] Train loss=0.2129555493593216
[20/23] Train loss=0.18710465729236603
Test set avg_accuracy=88.72% avg_sensitivity=76.17%, avg_specificity=92.72% avg_auc=91.70%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.203099 Test loss=0.307221 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.19587768614292145
[5/23] Train loss=0.1577165275812149
[10/23] Train loss=0.194978266954422
[15/23] Train loss=0.20686769485473633
[20/23] Train loss=0.18047526478767395
Test set avg_accuracy=90.09% avg_sensitivity=75.80%, avg_specificity=94.64% avg_auc=93.86%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.200164 Test loss=0.255084 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.18814927339553833
[5/23] Train loss=0.1654156744480133
[10/23] Train loss=0.19569993019104004
[15/23] Train loss=0.20331008732318878
[20/23] Train loss=0.1839480698108673
Test set avg_accuracy=83.98% avg_sensitivity=84.37%, avg_specificity=83.86% avg_auc=92.09%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.195290 Test loss=0.357080 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.20057302713394165
[5/23] Train loss=0.17278917133808136
[10/23] Train loss=0.19691212475299835
[15/23] Train loss=0.20057016611099243
[20/23] Train loss=0.18413487076759338
Test set avg_accuracy=86.88% avg_sensitivity=82.21%, avg_specificity=88.36% avg_auc=93.08%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.199147 Test loss=0.312771 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.1907261610031128
[5/23] Train loss=0.1643010824918747
[10/23] Train loss=0.19195707142353058
[15/23] Train loss=0.20211055874824524
[20/23] Train loss=0.17388293147087097
Test set avg_accuracy=89.28% avg_sensitivity=64.47%, avg_specificity=97.18% avg_auc=91.36%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.198910 Test loss=0.289467 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.1921851634979248
[5/23] Train loss=0.1640431433916092
[10/23] Train loss=0.20682984590530396
[15/23] Train loss=0.19294434785842896
[20/23] Train loss=0.1772441565990448
Test set avg_accuracy=89.95% avg_sensitivity=68.09%, avg_specificity=96.91% avg_auc=93.81%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.198648 Test loss=0.260139 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.19278275966644287
[5/23] Train loss=0.16613470017910004
[10/23] Train loss=0.18074758350849152
[15/23] Train loss=0.19331488013267517
[20/23] Train loss=0.17661000788211823
Test set avg_accuracy=88.44% avg_sensitivity=56.71%, avg_specificity=98.54% avg_auc=89.96%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.194448 Test loss=0.324175 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.1856628805398941
[5/23] Train loss=0.15714874863624573
[10/23] Train loss=0.20653003454208374
[15/23] Train loss=0.21290338039398193
[20/23] Train loss=0.17058825492858887
Test set avg_accuracy=89.95% avg_sensitivity=72.78%, avg_specificity=95.42% avg_auc=93.13%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.193398 Test loss=0.269130 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.1877584606409073
[5/23] Train loss=0.1633646935224533
[10/23] Train loss=0.18581700325012207
[15/23] Train loss=0.19299465417861938
[20/23] Train loss=0.17264297604560852
Test set avg_accuracy=87.54% avg_sensitivity=80.11%, avg_specificity=89.91% avg_auc=93.16%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.191367 Test loss=0.298279 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.1733582764863968
[5/23] Train loss=0.15759703516960144
[10/23] Train loss=0.17799581587314606
[15/23] Train loss=0.19958451390266418
[20/23] Train loss=0.17087247967720032
Test set avg_accuracy=85.22% avg_sensitivity=81.08%, avg_specificity=86.54% avg_auc=89.39%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.187161 Test loss=0.398308 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.1837579756975174
[5/23] Train loss=0.14869897067546844
[10/23] Train loss=0.19955483078956604
[15/23] Train loss=0.1971174031496048
[20/23] Train loss=0.16695024073123932
Test set avg_accuracy=86.84% avg_sensitivity=83.45%, avg_specificity=87.91% avg_auc=93.41%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.187862 Test loss=0.312146 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.18139636516571045
[5/23] Train loss=0.15335825085639954
[10/23] Train loss=0.1845124214887619
[15/23] Train loss=0.18659105896949768
[20/23] Train loss=0.17987284064292908
Test set avg_accuracy=89.32% avg_sensitivity=70.73%, avg_specificity=95.24% avg_auc=92.94%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.183813 Test loss=0.273228 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.17447268962860107
[5/23] Train loss=0.15493279695510864
[10/23] Train loss=0.17225371301174164
[15/23] Train loss=0.17963683605194092
[20/23] Train loss=0.15904176235198975
Test set avg_accuracy=88.74% avg_sensitivity=77.04%, avg_specificity=92.46% avg_auc=93.39%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.182384 Test loss=0.273287 Current lr=[0.000283047938381597]

[0/23] Train loss=0.17335745692253113
[5/23] Train loss=0.15931585431098938
[10/23] Train loss=0.16966399550437927
[15/23] Train loss=0.17687222361564636
[20/23] Train loss=0.16891728341579437
Test set avg_accuracy=85.59% avg_sensitivity=82.75%, avg_specificity=86.49% avg_auc=92.17%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.182567 Test loss=0.362418 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.17894630134105682
[5/23] Train loss=0.16150440275669098
[10/23] Train loss=0.17900925874710083
[15/23] Train loss=0.18937818706035614
[20/23] Train loss=0.1684238463640213
Test set avg_accuracy=88.78% avg_sensitivity=73.21%, avg_specificity=93.73% avg_auc=91.36%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.185657 Test loss=0.306986 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.16650432348251343
[5/23] Train loss=0.15645495057106018
[10/23] Train loss=0.17841900885105133
[15/23] Train loss=0.18448178470134735
[20/23] Train loss=0.1655205339193344
Test set avg_accuracy=87.14% avg_sensitivity=79.62%, avg_specificity=89.53% avg_auc=92.54%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.185748 Test loss=0.319320 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.17598268389701843
[5/23] Train loss=0.16436362266540527
[10/23] Train loss=0.1859297752380371
[15/23] Train loss=0.17676031589508057
[20/23] Train loss=0.1608886569738388
Test set avg_accuracy=87.94% avg_sensitivity=78.98%, avg_specificity=90.80% avg_auc=93.39%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.180929 Test loss=0.293188 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.16862131655216217
[5/23] Train loss=0.16310590505599976
[10/23] Train loss=0.1838160902261734
[15/23] Train loss=0.17819464206695557
[20/23] Train loss=0.16474290192127228
Test set avg_accuracy=89.04% avg_sensitivity=62.86%, avg_specificity=97.37% avg_auc=89.60%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.176850 Test loss=0.310128 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.18624641001224518
[5/23] Train loss=0.15141142904758453
[10/23] Train loss=0.1680935025215149
[15/23] Train loss=0.17595326900482178
[20/23] Train loss=0.16253767907619476
Test set avg_accuracy=88.89% avg_sensitivity=67.39%, avg_specificity=95.74% avg_auc=91.50%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.178584 Test loss=0.296651 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.17461778223514557
[5/23] Train loss=0.15658442676067352
[10/23] Train loss=0.17467495799064636
[15/23] Train loss=0.17022810876369476
[20/23] Train loss=0.15636904537677765
Test set avg_accuracy=82.29% avg_sensitivity=27.49%, avg_specificity=99.74% avg_auc=82.21%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.174580 Test loss=0.505752 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.17336736619472504
[5/23] Train loss=0.1605692058801651
[10/23] Train loss=0.17809000611305237
[15/23] Train loss=0.17317743599414825
[20/23] Train loss=0.15616080164909363
Test set avg_accuracy=88.95% avg_sensitivity=74.82%, avg_specificity=93.44% avg_auc=92.71%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.180280 Test loss=0.286511 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.17199166119098663
[5/23] Train loss=0.1587909758090973
[10/23] Train loss=0.17369595170021057
[15/23] Train loss=0.16923727095127106
[20/23] Train loss=0.17411187291145325
Test set avg_accuracy=89.51% avg_sensitivity=64.85%, avg_specificity=97.36% avg_auc=91.04%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.179457 Test loss=0.296819 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.17226238548755646
[5/23] Train loss=0.15334895253181458
[10/23] Train loss=0.1773184984922409
[15/23] Train loss=0.16665911674499512
[20/23] Train loss=0.16325341165065765
Test set avg_accuracy=88.27% avg_sensitivity=58.92%, avg_specificity=97.61% avg_auc=87.46%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.176284 Test loss=0.346842 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.16948452591896057
[5/23] Train loss=0.14334355294704437
[10/23] Train loss=0.16129450500011444
[15/23] Train loss=0.17439648509025574
[20/23] Train loss=0.15734994411468506
Test set avg_accuracy=89.23% avg_sensitivity=68.68%, avg_specificity=95.78% avg_auc=91.43%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.172988 Test loss=0.307827 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.16866888105869293
[5/23] Train loss=0.14561082422733307
[10/23] Train loss=0.16637364029884338
[15/23] Train loss=0.1727554053068161
[20/23] Train loss=0.1666005253791809
Test set avg_accuracy=89.04% avg_sensitivity=67.82%, avg_specificity=95.79% avg_auc=90.98%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.173795 Test loss=0.310609 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.16592586040496826
[5/23] Train loss=0.14067450165748596
[10/23] Train loss=0.17452186346054077
[15/23] Train loss=0.17341531813144684
[20/23] Train loss=0.1676514595746994
Test set avg_accuracy=87.42% avg_sensitivity=52.02%, avg_specificity=98.70% avg_auc=90.12%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.172528 Test loss=0.320603 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.16419768333435059
[5/23] Train loss=0.14293375611305237
[10/23] Train loss=0.16312460601329803
[15/23] Train loss=0.16893669962882996
[20/23] Train loss=0.15548305213451385
Test set avg_accuracy=88.88% avg_sensitivity=62.70%, avg_specificity=97.22% avg_auc=89.19%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.171936 Test loss=0.331023 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.16025985777378082
[5/23] Train loss=0.1429339200258255
[10/23] Train loss=0.17686015367507935
[15/23] Train loss=0.16894954442977905
[20/23] Train loss=0.16114689409732819
Test set avg_accuracy=87.99% avg_sensitivity=57.14%, avg_specificity=97.82% avg_auc=90.46%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.172363 Test loss=0.318423 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.16835956275463104
[5/23] Train loss=0.1491098701953888
[10/23] Train loss=0.17636261880397797
[15/23] Train loss=0.16469016671180725
[20/23] Train loss=0.1632681041955948
Test set avg_accuracy=89.97% avg_sensitivity=71.05%, avg_specificity=96.00% avg_auc=91.73%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.172901 Test loss=0.292408 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.16420422494411469
[5/23] Train loss=0.15546271204948425
[10/23] Train loss=0.181705504655838
[15/23] Train loss=0.1690000593662262
[20/23] Train loss=0.15325747430324554
Test set avg_accuracy=85.10% avg_sensitivity=84.74%, avg_specificity=85.22% avg_auc=92.29%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.172602 Test loss=0.366046 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.17929455637931824
[5/23] Train loss=0.14705432951450348
[10/23] Train loss=0.16863520443439484
[15/23] Train loss=0.15392866730690002
[20/23] Train loss=0.15261510014533997
Test set avg_accuracy=85.60% avg_sensitivity=82.96%, avg_specificity=86.44% avg_auc=92.78%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.169113 Test loss=0.346174 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.17059917747974396
[5/23] Train loss=0.14349623024463654
[10/23] Train loss=0.16864058375358582
[15/23] Train loss=0.15953433513641357
[20/23] Train loss=0.15205368399620056
Test set avg_accuracy=85.27% avg_sensitivity=82.26%, avg_specificity=86.23% avg_auc=91.45%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.168598 Test loss=0.357701 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.16502001881599426
[5/23] Train loss=0.15263989567756653
[10/23] Train loss=0.1715438812971115
[15/23] Train loss=0.1595480591058731
[20/23] Train loss=0.1509750783443451
Test set avg_accuracy=89.14% avg_sensitivity=71.70%, avg_specificity=94.70% avg_auc=92.11%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.170285 Test loss=0.293028 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.16288301348686218
[5/23] Train loss=0.14401915669441223
[10/23] Train loss=0.1732521653175354
[15/23] Train loss=0.16980165243148804
[20/23] Train loss=0.1488877832889557
Test set avg_accuracy=89.70% avg_sensitivity=70.40%, avg_specificity=95.85% avg_auc=90.75%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.167237 Test loss=0.296609 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.16190014779567719
[5/23] Train loss=0.1399671882390976
[10/23] Train loss=0.1517176479101181
[15/23] Train loss=0.15480411052703857
[20/23] Train loss=0.14442384243011475
Test set avg_accuracy=88.40% avg_sensitivity=72.02%, avg_specificity=93.61% avg_auc=91.39%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.164919 Test loss=0.301993 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.16024871170520782
[5/23] Train loss=0.14279399812221527
[10/23] Train loss=0.1563827395439148
[15/23] Train loss=0.15254849195480347
[20/23] Train loss=0.14341072738170624
Test set avg_accuracy=87.58% avg_sensitivity=78.44%, avg_specificity=90.49% avg_auc=91.32%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.162940 Test loss=0.330360 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.16145077347755432
[5/23] Train loss=0.1359955221414566
[10/23] Train loss=0.15573108196258545
[15/23] Train loss=0.1517484039068222
[20/23] Train loss=0.1406923532485962
Test set avg_accuracy=89.36% avg_sensitivity=69.11%, avg_specificity=95.81% avg_auc=91.60%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.162336 Test loss=0.300680 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.1583087295293808
[5/23] Train loss=0.1402953863143921
[10/23] Train loss=0.15774689614772797
[15/23] Train loss=0.15690219402313232
[20/23] Train loss=0.14995454251766205
Test set avg_accuracy=88.54% avg_sensitivity=59.62%, avg_specificity=97.75% avg_auc=90.34%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.161523 Test loss=0.314999 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.16426494717597961
[5/23] Train loss=0.14174185693264008
[10/23] Train loss=0.15092259645462036
[15/23] Train loss=0.1572558432817459
[20/23] Train loss=0.14215154945850372
Test set avg_accuracy=89.30% avg_sensitivity=74.93%, avg_specificity=93.87% avg_auc=92.47%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.161694 Test loss=0.284848 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.16476798057556152
[5/23] Train loss=0.1440712809562683
[10/23] Train loss=0.1576879322528839
[15/23] Train loss=0.15822164714336395
[20/23] Train loss=0.13978438079357147
Test set avg_accuracy=84.54% avg_sensitivity=83.99%, avg_specificity=84.72% avg_auc=91.88%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.161037 Test loss=0.365456 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.1625698208808899
[5/23] Train loss=0.15544313192367554
[10/23] Train loss=0.14894121885299683
[15/23] Train loss=0.150009423494339
[20/23] Train loss=0.14800922572612762
Test set avg_accuracy=89.66% avg_sensitivity=65.77%, avg_specificity=97.27% avg_auc=90.70%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.160495 Test loss=0.296065 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.15801580250263214
[5/23] Train loss=0.13459603488445282
[10/23] Train loss=0.15174052119255066
[15/23] Train loss=0.15159381926059723
[20/23] Train loss=0.13862761855125427
Test set avg_accuracy=87.49% avg_sensitivity=55.69%, avg_specificity=97.61% avg_auc=88.35%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.157075 Test loss=0.344228 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.14405600726604462
[5/23] Train loss=0.1385425478219986
[10/23] Train loss=0.1539812833070755
[15/23] Train loss=0.15466448664665222
[20/23] Train loss=0.14271602034568787
Test set avg_accuracy=89.45% avg_sensitivity=75.96%, avg_specificity=93.75% avg_auc=91.81%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.159039 Test loss=0.295155 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.1482200026512146
[5/23] Train loss=0.14068450033664703
[10/23] Train loss=0.1435011923313141
[15/23] Train loss=0.15087547898292542
[20/23] Train loss=0.1379343718290329
Test set avg_accuracy=89.28% avg_sensitivity=71.54%, avg_specificity=94.94% avg_auc=91.24%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.155643 Test loss=0.293744 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.1533842235803604
[5/23] Train loss=0.1387604922056198
[10/23] Train loss=0.15791019797325134
[15/23] Train loss=0.15718993544578552
[20/23] Train loss=0.14012210071086884
Test set avg_accuracy=86.69% avg_sensitivity=49.11%, avg_specificity=98.66% avg_auc=88.79%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.157229 Test loss=0.345638 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.15500353276729584
[5/23] Train loss=0.1378551870584488
[10/23] Train loss=0.14768697321414948
[15/23] Train loss=0.14378240704536438
[20/23] Train loss=0.14344422519207
Test set avg_accuracy=89.13% avg_sensitivity=64.26%, avg_specificity=97.05% avg_auc=91.45%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.154015 Test loss=0.295392 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.15327809751033783
[5/23] Train loss=0.13988755643367767
[10/23] Train loss=0.14731916785240173
[15/23] Train loss=0.1510942578315735
[20/23] Train loss=0.13751620054244995
Test set avg_accuracy=87.99% avg_sensitivity=56.71%, avg_specificity=97.96% avg_auc=89.54%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.155426 Test loss=0.322439 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.15437699854373932
[5/23] Train loss=0.15126675367355347
[10/23] Train loss=0.14814606308937073
[15/23] Train loss=0.15227703750133514
[20/23] Train loss=0.13661342859268188
Test set avg_accuracy=89.05% avg_sensitivity=62.26%, avg_specificity=97.58% avg_auc=89.99%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.157615 Test loss=0.296712 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.15124359726905823
[5/23] Train loss=0.13634377717971802
[10/23] Train loss=0.1540425568819046
[15/23] Train loss=0.1451430469751358
[20/23] Train loss=0.13745935261249542
Test set avg_accuracy=89.95% avg_sensitivity=72.08%, avg_specificity=95.64% avg_auc=91.85%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.154744 Test loss=0.284112 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.15298789739608765
[5/23] Train loss=0.13701699674129486
[10/23] Train loss=0.14853723347187042
[15/23] Train loss=0.1456327587366104
[20/23] Train loss=0.133108988404274
Test set avg_accuracy=89.15% avg_sensitivity=62.75%, avg_specificity=97.56% avg_auc=90.52%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.152704 Test loss=0.300695 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.15345849096775055
[5/23] Train loss=0.13429702818393707
[10/23] Train loss=0.14692570269107819
[15/23] Train loss=0.14320756494998932
[20/23] Train loss=0.13584689795970917
Test set avg_accuracy=88.72% avg_sensitivity=76.98%, avg_specificity=92.46% avg_auc=92.64%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.153776 Test loss=0.291302 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.15249603986740112
[5/23] Train loss=0.13100562989711761
[10/23] Train loss=0.1475827544927597
[15/23] Train loss=0.14979061484336853
[20/23] Train loss=0.13874197006225586
Test set avg_accuracy=88.97% avg_sensitivity=61.46%, avg_specificity=97.73% avg_auc=90.55%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.153287 Test loss=0.302054 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.15100562572479248
[5/23] Train loss=0.1348838061094284
[10/23] Train loss=0.14474107325077057
[15/23] Train loss=0.1515175998210907
[20/23] Train loss=0.13955144584178925
Test set avg_accuracy=89.35% avg_sensitivity=63.83%, avg_specificity=97.48% avg_auc=90.90%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.153309 Test loss=0.304535 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.14710544049739838
[5/23] Train loss=0.14039306342601776
[10/23] Train loss=0.13950912654399872
[15/23] Train loss=0.14687246084213257
[20/23] Train loss=0.13025209307670593
Test set avg_accuracy=89.27% avg_sensitivity=63.29%, avg_specificity=97.55% avg_auc=89.98%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.153198 Test loss=0.317352 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.14069660007953644
[5/23] Train loss=0.13201306760311127
[10/23] Train loss=0.140928253531456
[15/23] Train loss=0.14916469156742096
[20/23] Train loss=0.1314149647951126
Test set avg_accuracy=89.91% avg_sensitivity=68.14%, avg_specificity=96.84% avg_auc=91.53%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.148614 Test loss=0.285815 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.14520397782325745
[5/23] Train loss=0.13196350634098053
[10/23] Train loss=0.1375555396080017
[15/23] Train loss=0.13986825942993164
[20/23] Train loss=0.12958107888698578
Test set avg_accuracy=88.26% avg_sensitivity=58.92%, avg_specificity=97.60% avg_auc=90.79%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.149272 Test loss=0.306144 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.14417175948619843
[5/23] Train loss=0.12961052358150482
[10/23] Train loss=0.14758333563804626
[15/23] Train loss=0.14723704755306244
[20/23] Train loss=0.1301710456609726
Test set avg_accuracy=90.25% avg_sensitivity=73.21%, avg_specificity=95.67% avg_auc=92.44%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.151709 Test loss=0.278342 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.14746838808059692
[5/23] Train loss=0.13299120962619781
[10/23] Train loss=0.13658732175827026
[15/23] Train loss=0.1414002925157547
[20/23] Train loss=0.12778881192207336
Test set avg_accuracy=88.75% avg_sensitivity=64.69%, avg_specificity=96.41% avg_auc=91.59%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.145085 Test loss=0.294202 Current lr=[0.000112073915556435]

[0/23] Train loss=0.1436728835105896
[5/23] Train loss=0.13016581535339355
[10/23] Train loss=0.13255195319652557
[15/23] Train loss=0.1362142413854599
[20/23] Train loss=0.1317332535982132
Test set avg_accuracy=89.35% avg_sensitivity=68.25%, avg_specificity=96.07% avg_auc=91.09%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.144832 Test loss=0.288580 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.1407782882452011
[5/23] Train loss=0.1339365392923355
[10/23] Train loss=0.14796264469623566
[15/23] Train loss=0.14142902195453644
[20/23] Train loss=0.1291966289281845
Test set avg_accuracy=89.28% avg_sensitivity=73.48%, avg_specificity=94.32% avg_auc=91.64%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.144038 Test loss=0.294501 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.1403639018535614
[5/23] Train loss=0.1283906102180481
[10/23] Train loss=0.13770069181919098
[15/23] Train loss=0.13605859875679016
[20/23] Train loss=0.125480517745018
Test set avg_accuracy=89.00% avg_sensitivity=63.94%, avg_specificity=96.98% avg_auc=91.06%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.143849 Test loss=0.305874 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.13916727900505066
[5/23] Train loss=0.1263812929391861
[10/23] Train loss=0.13477596640586853
[15/23] Train loss=0.14051468670368195
[20/23] Train loss=0.12293300777673721
Test set avg_accuracy=89.28% avg_sensitivity=64.42%, avg_specificity=97.20% avg_auc=90.60%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.141370 Test loss=0.303617 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.13637541234493256
[5/23] Train loss=0.12171565741300583
[10/23] Train loss=0.13393338024616241
[15/23] Train loss=0.13079147040843964
[20/23] Train loss=0.12335222959518433
Test set avg_accuracy=89.47% avg_sensitivity=72.88%, avg_specificity=94.75% avg_auc=91.34%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.138832 Test loss=0.294285 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.13664968311786652
[5/23] Train loss=0.11988568305969238
[10/23] Train loss=0.13341973721981049
[15/23] Train loss=0.12851540744304657
[20/23] Train loss=0.12343963980674744
Test set avg_accuracy=89.97% avg_sensitivity=69.81%, avg_specificity=96.39% avg_auc=91.13%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.136202 Test loss=0.296738 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.13571277260780334
[5/23] Train loss=0.12255387008190155
[10/23] Train loss=0.1307184398174286
[15/23] Train loss=0.13071760535240173
[20/23] Train loss=0.12249928712844849
Test set avg_accuracy=90.16% avg_sensitivity=71.75%, avg_specificity=96.02% avg_auc=91.74%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.135732 Test loss=0.286610 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.13003571331501007
[5/23] Train loss=0.12057290971279144
[10/23] Train loss=0.13212822377681732
[15/23] Train loss=0.13022156059741974
[20/23] Train loss=0.11841375380754471
Test set avg_accuracy=89.93% avg_sensitivity=69.87%, avg_specificity=96.33% avg_auc=91.65%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.134472 Test loss=0.290616 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.13198626041412354
[5/23] Train loss=0.12066996097564697
[10/23] Train loss=0.12596704065799713
[15/23] Train loss=0.1249314546585083
[20/23] Train loss=0.12164118140935898
Test set avg_accuracy=89.04% avg_sensitivity=72.61%, avg_specificity=94.27% avg_auc=91.28%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.132334 Test loss=0.295587 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.1303807944059372
[5/23] Train loss=0.12241529673337936
[10/23] Train loss=0.12566277384757996
[15/23] Train loss=0.12814410030841827
[20/23] Train loss=0.12000081688165665
Test set avg_accuracy=89.15% avg_sensitivity=69.00%, avg_specificity=95.57% avg_auc=91.05%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.133314 Test loss=0.299338 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.13211211562156677
[5/23] Train loss=0.12005137652158737
[10/23] Train loss=0.12714213132858276
[15/23] Train loss=0.12778739631175995
[20/23] Train loss=0.11580253392457962
Test set avg_accuracy=89.18% avg_sensitivity=63.83%, avg_specificity=97.25% avg_auc=89.72%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.132781 Test loss=0.309179 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.1348220407962799
[5/23] Train loss=0.11639901250600815
[10/23] Train loss=0.13595934212207794
[15/23] Train loss=0.1258002519607544
[20/23] Train loss=0.11828790605068207
Test set avg_accuracy=88.95% avg_sensitivity=63.56%, avg_specificity=97.03% avg_auc=90.54%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.132279 Test loss=0.308226 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.13229523599147797
[5/23] Train loss=0.11790239810943604
[10/23] Train loss=0.1252121478319168
[15/23] Train loss=0.12607182562351227
[20/23] Train loss=0.11794637143611908
Test set avg_accuracy=88.87% avg_sensitivity=63.29%, avg_specificity=97.01% avg_auc=89.76%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.132168 Test loss=0.319515 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.12962499260902405
[5/23] Train loss=0.1195666566491127
[10/23] Train loss=0.12800924479961395
[15/23] Train loss=0.1254834234714508
[20/23] Train loss=0.11832481622695923
Test set avg_accuracy=89.40% avg_sensitivity=68.19%, avg_specificity=96.15% avg_auc=91.12%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.131397 Test loss=0.302494 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.1269216686487198
[5/23] Train loss=0.11916377395391464
[10/23] Train loss=0.12468362599611282
[15/23] Train loss=0.12502460181713104
[20/23] Train loss=0.11697451770305634
Test set avg_accuracy=88.79% avg_sensitivity=63.56%, avg_specificity=96.82% avg_auc=90.47%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.130304 Test loss=0.311192 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.12589985132217407
[5/23] Train loss=0.11703715473413467
[10/23] Train loss=0.12149863690137863
[15/23] Train loss=0.1275724321603775
[20/23] Train loss=0.11969081312417984
Test set avg_accuracy=88.66% avg_sensitivity=61.89%, avg_specificity=97.18% avg_auc=91.40%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.129824 Test loss=0.303887 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.13202475011348724
[5/23] Train loss=0.11650856584310532
[10/23] Train loss=0.11927729099988937
[15/23] Train loss=0.12492531538009644
[20/23] Train loss=0.1170426532626152
Test set avg_accuracy=89.65% avg_sensitivity=72.24%, avg_specificity=95.19% avg_auc=91.92%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.128935 Test loss=0.291727 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.12285798788070679
[5/23] Train loss=0.11543820053339005
[10/23] Train loss=0.11882684379816055
[15/23] Train loss=0.12254485487937927
[20/23] Train loss=0.1156185045838356
Test set avg_accuracy=89.58% avg_sensitivity=72.94%, avg_specificity=94.88% avg_auc=92.11%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.127519 Test loss=0.289863 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.12088741362094879
[5/23] Train loss=0.1175992414355278
[10/23] Train loss=0.11934960633516312
[15/23] Train loss=0.12066338211297989
[20/23] Train loss=0.11205675452947617
Test set avg_accuracy=89.15% avg_sensitivity=71.59%, avg_specificity=94.75% avg_auc=91.50%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.127477 Test loss=0.299994 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.12330665439367294
[5/23] Train loss=0.11458807438611984
[10/23] Train loss=0.11964043974876404
[15/23] Train loss=0.12192101776599884
[20/23] Train loss=0.1136505976319313
Test set avg_accuracy=88.71% avg_sensitivity=76.06%, avg_specificity=92.74% avg_auc=91.86%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.126269 Test loss=0.306891 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.12162227928638458
[5/23] Train loss=0.11436115205287933
[10/23] Train loss=0.11829522997140884
[15/23] Train loss=0.1194029375910759
[20/23] Train loss=0.11340925842523575
Test set avg_accuracy=89.43% avg_sensitivity=72.94%, avg_specificity=94.68% avg_auc=91.55%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.124641 Test loss=0.299786 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.12087520956993103
[5/23] Train loss=0.11362912505865097
[10/23] Train loss=0.1203722432255745
[15/23] Train loss=0.1191183552145958
[20/23] Train loss=0.11557424068450928
Test set avg_accuracy=89.48% avg_sensitivity=73.96%, avg_specificity=94.42% avg_auc=91.71%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.124460 Test loss=0.296976 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.11965806782245636
[5/23] Train loss=0.11410831660032272
[10/23] Train loss=0.116765595972538
[15/23] Train loss=0.1176677867770195
[20/23] Train loss=0.1119629517197609
Test set avg_accuracy=89.58% avg_sensitivity=71.59%, avg_specificity=95.31% avg_auc=91.38%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.123769 Test loss=0.295043 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.11876358836889267
[5/23] Train loss=0.11503759771585464
[10/23] Train loss=0.1189047172665596
[15/23] Train loss=0.12288167327642441
[20/23] Train loss=0.11007581651210785
Test set avg_accuracy=89.15% avg_sensitivity=73.91%, avg_specificity=94.01% avg_auc=91.85%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.123346 Test loss=0.299963 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.11757530272006989
[5/23] Train loss=0.11277754604816437
[10/23] Train loss=0.11767120659351349
[15/23] Train loss=0.11878497153520584
[20/23] Train loss=0.11324740201234818
Test set avg_accuracy=89.56% avg_sensitivity=72.35%, avg_specificity=95.04% avg_auc=91.80%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.123210 Test loss=0.291741 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.11833906918764114
[5/23] Train loss=0.1143331527709961
[10/23] Train loss=0.11557231843471527
[15/23] Train loss=0.11896943300962448
[20/23] Train loss=0.11100079864263535
Test set avg_accuracy=89.10% avg_sensitivity=70.84%, avg_specificity=94.92% avg_auc=91.62%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.123219 Test loss=0.293830 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.11780543625354767
[5/23] Train loss=0.11326389759778976
[10/23] Train loss=0.11756998300552368
[15/23] Train loss=0.11524992436170578
[20/23] Train loss=0.11273690313100815
Test set avg_accuracy=89.35% avg_sensitivity=72.88%, avg_specificity=94.59% avg_auc=91.55%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.122564 Test loss=0.294793 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.11651084572076797
[5/23] Train loss=0.10924690961837769
[10/23] Train loss=0.11485839635133743
[15/23] Train loss=0.11586989462375641
[20/23] Train loss=0.10885121673345566
Test set avg_accuracy=89.23% avg_sensitivity=71.37%, avg_specificity=94.92% avg_auc=91.46%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.121503 Test loss=0.294229 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.11755121499300003
[5/23] Train loss=0.11357252299785614
[10/23] Train loss=0.11333242058753967
[15/23] Train loss=0.1138509139418602
[20/23] Train loss=0.11270812898874283
Test set avg_accuracy=89.19% avg_sensitivity=72.56%, avg_specificity=94.49% avg_auc=91.72%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.120785 Test loss=0.294762 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.11671865731477737
[5/23] Train loss=0.11053554713726044
[10/23] Train loss=0.11498480290174484
[15/23] Train loss=0.11434213817119598
[20/23] Train loss=0.11059661209583282
Test set avg_accuracy=89.09% avg_sensitivity=72.02%, avg_specificity=94.52% avg_auc=91.58%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.120069 Test loss=0.297291 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.11456044763326645
[5/23] Train loss=0.10904724150896072
[10/23] Train loss=0.1115306094288826
[15/23] Train loss=0.11415767669677734
[20/23] Train loss=0.10930152237415314
Test set avg_accuracy=89.40% avg_sensitivity=71.86%, avg_specificity=94.99% avg_auc=91.47%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.118921 Test loss=0.297190 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.11309648305177689
[5/23] Train loss=0.11053098738193512
[10/23] Train loss=0.1135263592004776
[15/23] Train loss=0.11295215785503387
[20/23] Train loss=0.10846056044101715
Test set avg_accuracy=89.09% avg_sensitivity=72.29%, avg_specificity=94.44% avg_auc=91.48%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.118992 Test loss=0.297199 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.11501910537481308
[5/23] Train loss=0.11054746806621552
[10/23] Train loss=0.11173544824123383
[15/23] Train loss=0.11197138577699661
[20/23] Train loss=0.10866262018680573
Test set avg_accuracy=89.06% avg_sensitivity=71.59%, avg_specificity=94.63% avg_auc=91.60%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.119012 Test loss=0.295245 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.11320415139198303
[5/23] Train loss=0.10917877405881882
[10/23] Train loss=0.11622502654790878
[15/23] Train loss=0.1143031194806099
[20/23] Train loss=0.11074518412351608
Test set avg_accuracy=89.30% avg_sensitivity=71.54%, avg_specificity=94.95% avg_auc=91.52%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.118412 Test loss=0.294300 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.11209511011838913
[5/23] Train loss=0.11031497269868851
[10/23] Train loss=0.1122857928276062
[15/23] Train loss=0.11341271549463272
[20/23] Train loss=0.10964294523000717
Test set avg_accuracy=89.34% avg_sensitivity=71.81%, avg_specificity=94.92% avg_auc=91.35%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.118611 Test loss=0.296711 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.11453603208065033
[5/23] Train loss=0.11083825677633286
[10/23] Train loss=0.11049060523509979
[15/23] Train loss=0.11238130182027817
[20/23] Train loss=0.10851623862981796
Test set avg_accuracy=89.01% avg_sensitivity=71.64%, avg_specificity=94.54% avg_auc=91.41%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.118502 Test loss=0.295777 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.11355215311050415
[5/23] Train loss=0.10873718559741974
[10/23] Train loss=0.11266028881072998
[15/23] Train loss=0.10978201776742935
[20/23] Train loss=0.10833948850631714
Test set avg_accuracy=89.10% avg_sensitivity=72.02%, avg_specificity=94.54% avg_auc=91.53%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.117746 Test loss=0.294915 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.11221718043088913
[5/23] Train loss=0.11034586280584335
[10/23] Train loss=0.11433660984039307
[15/23] Train loss=0.11118954420089722
[20/23] Train loss=0.10740800946950912
Test set avg_accuracy=89.26% avg_sensitivity=72.24%, avg_specificity=94.68% avg_auc=91.53%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.117833 Test loss=0.294914 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.11460161954164505
[5/23] Train loss=0.10826531052589417
[10/23] Train loss=0.11201053112745285
[15/23] Train loss=0.1109781414270401
[20/23] Train loss=0.10729993879795074
Test set avg_accuracy=89.11% avg_sensitivity=71.75%, avg_specificity=94.64% avg_auc=91.47%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.117903 Test loss=0.295120 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.11336315423250198
[5/23] Train loss=0.10921549052000046
[10/23] Train loss=0.1114208847284317
[15/23] Train loss=0.11116105318069458
[20/23] Train loss=0.10749542713165283
Test set avg_accuracy=89.10% avg_sensitivity=71.70%, avg_specificity=94.64% avg_auc=91.48%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.117297 Test loss=0.295984 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.110930435359478
[5/23] Train loss=0.10930146276950836
[10/23] Train loss=0.11180329322814941
[15/23] Train loss=0.11138547956943512
[20/23] Train loss=0.10651317983865738
Test set avg_accuracy=89.06% avg_sensitivity=71.59%, avg_specificity=94.63% avg_auc=91.47%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.117144 Test loss=0.296208 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.11162031441926956
[5/23] Train loss=0.10940594971179962
[10/23] Train loss=0.11138330399990082
[15/23] Train loss=0.11321365833282471
[20/23] Train loss=0.10666608065366745
Test set avg_accuracy=89.09% avg_sensitivity=71.70%, avg_specificity=94.63% avg_auc=91.47%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.117585 Test loss=0.296216 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.11418398469686508
[5/23] Train loss=0.10861431062221527
[10/23] Train loss=0.11418800055980682
[15/23] Train loss=0.1095602884888649
[20/23] Train loss=0.10758379846811295
Test set avg_accuracy=89.13% avg_sensitivity=71.86%, avg_specificity=94.63% avg_auc=91.46%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.117187 Test loss=0.296123 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.11048853397369385
[5/23] Train loss=0.10687293857336044
[10/23] Train loss=0.1108601912856102
[15/23] Train loss=0.11518660932779312
[20/23] Train loss=0.10695792734622955
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.09% avg_sensitivity=71.70%, avg_specificity=94.63% avg_auc=91.47%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.117209 Test loss=0.296270 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=90.04% sen=79.08%, spe=93.53%, auc=93.91%!
Fold[9] Avg_overlap=0.68%(0.24961351945447402)
[0/24] Train loss=0.7300283908843994
[5/24] Train loss=0.7213866114616394
[10/24] Train loss=0.7138741612434387
[15/24] Train loss=0.7095904350280762
[20/24] Train loss=0.7000179290771484
Test set avg_accuracy=69.34% avg_sensitivity=24.91%, avg_specificity=82.21% avg_auc=57.24%
Best model saved!! Metric=-92.30132165681873!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.712765 Test loss=0.661783 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6920477747917175
[5/24] Train loss=0.6881654262542725
[10/24] Train loss=0.6842473745346069
[15/24] Train loss=0.672281801700592
[20/24] Train loss=0.6619311571121216
Test set avg_accuracy=75.05% avg_sensitivity=49.13%, avg_specificity=82.57% avg_auc=69.74%
Best model saved!! Metric=-49.5094842818049!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.681373 Test loss=0.591430 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6622565388679504
[5/24] Train loss=0.652796745300293
[10/24] Train loss=0.6578705310821533
[15/24] Train loss=0.646666407585144
[20/24] Train loss=0.6399586200714111
Test set avg_accuracy=79.19% avg_sensitivity=58.00%, avg_specificity=85.34% avg_auc=76.89%
Best model saved!! Metric=-26.588783684846987!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.653838 Test loss=0.544917 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6326838731765747
[5/24] Train loss=0.6276859641075134
[10/24] Train loss=0.6293094754219055
[15/24] Train loss=0.6205331683158875
[20/24] Train loss=0.6121747493743896
Test set avg_accuracy=80.73% avg_sensitivity=64.60%, avg_specificity=85.40% avg_auc=80.06%
Best model saved!! Metric=-15.209793713630162!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.626049 Test loss=0.513217 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.5958163142204285
[5/24] Train loss=0.5970861315727234
[10/24] Train loss=0.6104446649551392
[15/24] Train loss=0.5944274067878723
[20/24] Train loss=0.585960865020752
Test set avg_accuracy=82.04% avg_sensitivity=69.18%, avg_specificity=85.77% avg_auc=82.77%
Best model saved!! Metric=-6.233004811422475!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.600883 Test loss=0.485544 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.5732714533805847
[5/24] Train loss=0.5742635130882263
[10/24] Train loss=0.5842155814170837
[15/24] Train loss=0.5677348375320435
[20/24] Train loss=0.5588333606719971
Test set avg_accuracy=83.40% avg_sensitivity=71.26%, avg_specificity=86.92% avg_auc=84.66%
Best model saved!! Metric=0.23601302592277307!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.574071 Test loss=0.457919 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.5445675253868103
[5/24] Train loss=0.547867476940155
[10/24] Train loss=0.5632809996604919
[15/24] Train loss=0.5361337065696716
[20/24] Train loss=0.533186137676239
Test set avg_accuracy=84.75% avg_sensitivity=71.44%, avg_specificity=88.61% avg_auc=86.47%
Best model saved!! Metric=5.273293297044745!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.547666 Test loss=0.432501 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.5160792469978333
[5/24] Train loss=0.5227184295654297
[10/24] Train loss=0.5343992114067078
[15/24] Train loss=0.507381021976471
[20/24] Train loss=0.5009837746620178
Test set avg_accuracy=85.78% avg_sensitivity=72.31%, avg_specificity=89.69% avg_auc=88.12%
Best model saved!! Metric=9.891831277628285!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.519328 Test loss=0.403606 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.4907948076725006
[5/24] Train loss=0.4923326075077057
[10/24] Train loss=0.4967690408229828
[15/24] Train loss=0.474396675825119
[20/24] Train loss=0.4747188985347748
Test set avg_accuracy=87.04% avg_sensitivity=70.80%, avg_specificity=91.75% avg_auc=89.01%
Best model saved!! Metric=12.605691318154982!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.489919 Test loss=0.378939 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.46685999631881714
[5/24] Train loss=0.4624854326248169
[10/24] Train loss=0.47502824664115906
[15/24] Train loss=0.44624170660972595
[20/24] Train loss=0.44199684262275696
Test set avg_accuracy=87.92% avg_sensitivity=69.87%, avg_specificity=93.15% avg_auc=89.99%
Best model saved!! Metric=14.92773433065372!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.462008 Test loss=0.361162 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.4401019215583801
[5/24] Train loss=0.42933180928230286
[10/24] Train loss=0.4379090666770935
[15/24] Train loss=0.4218226969242096
[20/24] Train loss=0.41268834471702576
Test set avg_accuracy=88.45% avg_sensitivity=67.96%, avg_specificity=94.39% avg_auc=90.74%
Best model saved!! Metric=15.539109242500402!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.435562 Test loss=0.342084 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.4161105751991272
[5/24] Train loss=0.40991905331611633
[10/24] Train loss=0.41140952706336975
[15/24] Train loss=0.3955634832382202
[20/24] Train loss=0.39110827445983887
Test set avg_accuracy=89.17% avg_sensitivity=72.42%, avg_specificity=94.02% avg_auc=91.61%
Best model saved!! Metric=21.223297047675814!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.410212 Test loss=0.329201 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.3987983167171478
[5/24] Train loss=0.38308724761009216
[10/24] Train loss=0.38989701867103577
[15/24] Train loss=0.3748643696308136
[20/24] Train loss=0.36342230439186096
Test set avg_accuracy=89.13% avg_sensitivity=73.06%, avg_specificity=93.79% avg_auc=92.30%
Best model saved!! Metric=22.27257073344299!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.388781 Test loss=0.313738 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.37356987595558167
[5/24] Train loss=0.36605268716812134
[10/24] Train loss=0.36757317185401917
[15/24] Train loss=0.3543316721916199
[20/24] Train loss=0.34419435262680054
Test set avg_accuracy=89.54% avg_sensitivity=68.48%, avg_specificity=95.65% avg_auc=92.22%
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.369738 Test loss=0.297138 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.35952335596084595
[5/24] Train loss=0.34829452633857727
[10/24] Train loss=0.3576553463935852
[15/24] Train loss=0.33682191371917725
[20/24] Train loss=0.332065612077713
Test set avg_accuracy=89.88% avg_sensitivity=68.19%, avg_specificity=96.17% avg_auc=92.55%
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.352278 Test loss=0.287467 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.347578763961792
[5/24] Train loss=0.3327394127845764
[10/24] Train loss=0.34066617488861084
[15/24] Train loss=0.3286278545856476
[20/24] Train loss=0.31650468707084656
Test set avg_accuracy=89.67% avg_sensitivity=66.40%, avg_specificity=96.42% avg_auc=92.85%
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.339812 Test loss=0.280704 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.32788342237472534
[5/24] Train loss=0.3189789950847626
[10/24] Train loss=0.3311978280544281
[15/24] Train loss=0.312236487865448
[20/24] Train loss=0.3065170347690582
Test set avg_accuracy=90.09% avg_sensitivity=69.64%, avg_specificity=96.02% avg_auc=93.52%
Best model saved!! Metric=23.26670616435318!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.327502 Test loss=0.271030 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.318591833114624
[5/24] Train loss=0.31250548362731934
[10/24] Train loss=0.3169115483760834
[15/24] Train loss=0.30635732412338257
[20/24] Train loss=0.29626262187957764
Test set avg_accuracy=90.05% avg_sensitivity=67.56%, avg_specificity=96.57% avg_auc=93.14%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.316707 Test loss=0.269037 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.31164464354515076
[5/24] Train loss=0.30254065990448
[10/24] Train loss=0.3082410991191864
[15/24] Train loss=0.2937195301055908
[20/24] Train loss=0.2833530604839325
Test set avg_accuracy=90.07% avg_sensitivity=67.32%, avg_specificity=96.66% avg_auc=93.43%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.306131 Test loss=0.263419 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.30525946617126465
[5/24] Train loss=0.293610155582428
[10/24] Train loss=0.3060190975666046
[15/24] Train loss=0.2880081236362457
[20/24] Train loss=0.2761226296424866
Test set avg_accuracy=90.65% avg_sensitivity=72.31%, avg_specificity=95.97% avg_auc=93.89%
Best model saved!! Metric=26.816568332868854!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.299121 Test loss=0.255333 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.28933975100517273
[5/24] Train loss=0.28531208634376526
[10/24] Train loss=0.29888230562210083
[15/24] Train loss=0.2855871915817261
[20/24] Train loss=0.2741474211215973
Test set avg_accuracy=90.73% avg_sensitivity=73.46%, avg_specificity=95.73% avg_auc=94.17%
Best model saved!! Metric=28.10030561490288!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.291616 Test loss=0.254583 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.29442504048347473
[5/24] Train loss=0.27978333830833435
[10/24] Train loss=0.28518930077552795
[15/24] Train loss=0.2700234353542328
[20/24] Train loss=0.2642577886581421
Test set avg_accuracy=90.56% avg_sensitivity=72.36%, avg_specificity=95.83% avg_auc=94.29%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.283087 Test loss=0.247885 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.2820121943950653
[5/24] Train loss=0.26680684089660645
[10/24] Train loss=0.2803076207637787
[15/24] Train loss=0.26625677943229675
[20/24] Train loss=0.2651318907737732
Test set avg_accuracy=90.87% avg_sensitivity=74.45%, avg_specificity=95.63% avg_auc=94.24%
Best model saved!! Metric=29.1943498562771!!
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.277867 Test loss=0.246774 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.2835705876350403
[5/24] Train loss=0.25826236605644226
[10/24] Train loss=0.2735142409801483
[15/24] Train loss=0.2669854164123535
[20/24] Train loss=0.25993475317955017
Test set avg_accuracy=90.78% avg_sensitivity=72.60%, avg_specificity=96.05% avg_auc=94.00%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.272707 Test loss=0.249060 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.2796478867530823
[5/24] Train loss=0.2591984272003174
[10/24] Train loss=0.2652604877948761
[15/24] Train loss=0.2581949830055237
[20/24] Train loss=0.2489231526851654
Test set avg_accuracy=90.16% avg_sensitivity=63.85%, avg_specificity=97.78% avg_auc=93.52%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.266721 Test loss=0.257310 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.2746581733226776
[5/24] Train loss=0.24531938135623932
[10/24] Train loss=0.2594119608402252
[15/24] Train loss=0.25114765763282776
[20/24] Train loss=0.24476772546768188
Test set avg_accuracy=90.43% avg_sensitivity=69.99%, avg_specificity=96.36% avg_auc=94.10%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.260839 Test loss=0.249331 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.27088749408721924
[5/24] Train loss=0.23676112294197083
[10/24] Train loss=0.2554572522640228
[15/24] Train loss=0.24985283613204956
[20/24] Train loss=0.23715366423130035
Test set avg_accuracy=90.14% avg_sensitivity=66.22%, avg_specificity=97.08% avg_auc=93.36%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.256957 Test loss=0.260184 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.27868419885635376
[5/24] Train loss=0.23821739852428436
[10/24] Train loss=0.2571127712726593
[15/24] Train loss=0.2398737668991089
[20/24] Train loss=0.23865045607089996
Test set avg_accuracy=89.83% avg_sensitivity=62.57%, avg_specificity=97.73% avg_auc=93.61%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.253209 Test loss=0.258614 Current lr=[0.000210185142098938]

[0/24] Train loss=0.26685935258865356
[5/24] Train loss=0.22748880088329315
[10/24] Train loss=0.24578948318958282
[15/24] Train loss=0.2427368015050888
[20/24] Train loss=0.23650866746902466
Test set avg_accuracy=85.16% avg_sensitivity=36.33%, avg_specificity=99.31% avg_auc=89.64%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.248092 Test loss=0.373657 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.27066826820373535
[5/24] Train loss=0.2355407476425171
[10/24] Train loss=0.25435057282447815
[15/24] Train loss=0.2382100373506546
[20/24] Train loss=0.22947263717651367
Test set avg_accuracy=88.31% avg_sensitivity=51.74%, avg_specificity=98.91% avg_auc=91.81%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.247057 Test loss=0.306314 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.25957900285720825
[5/24] Train loss=0.21613375842571259
[10/24] Train loss=0.25497832894325256
[15/24] Train loss=0.237666517496109
[20/24] Train loss=0.23327958583831787
Test set avg_accuracy=85.30% avg_sensitivity=36.96%, avg_specificity=99.31% avg_auc=89.22%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.242032 Test loss=0.374688 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.2613423764705658
[5/24] Train loss=0.22052504122257233
[10/24] Train loss=0.23885944485664368
[15/24] Train loss=0.23181849718093872
[20/24] Train loss=0.22764906287193298
Test set avg_accuracy=85.74% avg_sensitivity=39.17%, avg_specificity=99.24% avg_auc=90.26%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.239470 Test loss=0.357392 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.25001105666160583
[5/24] Train loss=0.21416127681732178
[10/24] Train loss=0.23082956671714783
[15/24] Train loss=0.24186840653419495
[20/24] Train loss=0.2253054678440094
Test set avg_accuracy=90.21% avg_sensitivity=66.05%, avg_specificity=97.21% avg_auc=94.05%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.237255 Test loss=0.252946 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.24567390978336334
[5/24] Train loss=0.22170692682266235
[10/24] Train loss=0.23150064051151276
[15/24] Train loss=0.23232890665531158
[20/24] Train loss=0.22110530734062195
Test set avg_accuracy=90.26% avg_sensitivity=64.02%, avg_specificity=97.87% avg_auc=91.73%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.233907 Test loss=0.275371 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.23989112675189972
[5/24] Train loss=0.2263823002576828
[10/24] Train loss=0.2487906813621521
[15/24] Train loss=0.22909533977508545
[20/24] Train loss=0.2148381620645523
Test set avg_accuracy=90.22% avg_sensitivity=64.66%, avg_specificity=97.63% avg_auc=93.84%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.233336 Test loss=0.259176 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.24294708669185638
[5/24] Train loss=0.19324880838394165
[10/24] Train loss=0.22856168448925018
[15/24] Train loss=0.2412629872560501
[20/24] Train loss=0.2160729169845581
Test set avg_accuracy=87.55% avg_sensitivity=49.77%, avg_specificity=98.51% avg_auc=88.06%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.228217 Test loss=0.339549 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.2485513538122177
[5/24] Train loss=0.21279177069664001
[10/24] Train loss=0.2356172353029251
[15/24] Train loss=0.2247682511806488
[20/24] Train loss=0.21862564980983734
Test set avg_accuracy=90.26% avg_sensitivity=67.67%, avg_specificity=96.81% avg_auc=91.87%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.228533 Test loss=0.271644 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.2548685669898987
[5/24] Train loss=0.2069229930639267
[10/24] Train loss=0.2294914573431015
[15/24] Train loss=0.2396784871816635
[20/24] Train loss=0.21561525762081146
Test set avg_accuracy=90.39% avg_sensitivity=65.06%, avg_specificity=97.73% avg_auc=93.48%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.228867 Test loss=0.265463 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.23984071612358093
[5/24] Train loss=0.20724624395370483
[10/24] Train loss=0.22656185925006866
[15/24] Train loss=0.2327873259782791
[20/24] Train loss=0.2088063657283783
Test set avg_accuracy=89.47% avg_sensitivity=59.10%, avg_specificity=98.27% avg_auc=92.73%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.222980 Test loss=0.275877 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.2364596277475357
[5/24] Train loss=0.20701946318149567
[10/24] Train loss=0.2279713749885559
[15/24] Train loss=0.22781185805797577
[20/24] Train loss=0.21151310205459595
Test set avg_accuracy=89.79% avg_sensitivity=61.94%, avg_specificity=97.87% avg_auc=91.41%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.225147 Test loss=0.290939 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.23570096492767334
[5/24] Train loss=0.2057960331439972
[10/24] Train loss=0.24274896085262299
[15/24] Train loss=0.22806593775749207
[20/24] Train loss=0.21464933454990387
Test set avg_accuracy=86.80% avg_sensitivity=44.67%, avg_specificity=99.01% avg_auc=90.97%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.230136 Test loss=0.325884 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.24160157144069672
[5/24] Train loss=0.18552052974700928
[10/24] Train loss=0.2210545688867569
[15/24] Train loss=0.21819846332073212
[20/24] Train loss=0.20921580493450165
Test set avg_accuracy=90.12% avg_sensitivity=65.01%, avg_specificity=97.40% avg_auc=92.80%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.221185 Test loss=0.262926 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.22942200303077698
[5/24] Train loss=0.1830092817544937
[10/24] Train loss=0.21641115844249725
[15/24] Train loss=0.22994977235794067
[20/24] Train loss=0.19836248457431793
Test set avg_accuracy=90.16% avg_sensitivity=63.56%, avg_specificity=97.87% avg_auc=92.18%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.213942 Test loss=0.273731 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.2240501195192337
[5/24] Train loss=0.18715223670005798
[10/24] Train loss=0.2081611305475235
[15/24] Train loss=0.2195129245519638
[20/24] Train loss=0.19839982688426971
Test set avg_accuracy=90.10% avg_sensitivity=68.95%, avg_specificity=96.24% avg_auc=92.60%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.210952 Test loss=0.268047 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2288210242986679
[5/24] Train loss=0.18595169484615326
[10/24] Train loss=0.2201942652463913
[15/24] Train loss=0.2204921841621399
[20/24] Train loss=0.20169955492019653
Test set avg_accuracy=90.47% avg_sensitivity=74.80%, avg_specificity=95.01% avg_auc=93.82%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.213275 Test loss=0.254423 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.2270280122756958
[5/24] Train loss=0.18989072740077972
[10/24] Train loss=0.21253377199172974
[15/24] Train loss=0.22531111538410187
[20/24] Train loss=0.20969925820827484
Test set avg_accuracy=86.42% avg_sensitivity=84.41%, avg_specificity=87.00% avg_auc=92.59%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.215453 Test loss=0.336425 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2123556286096573
[5/24] Train loss=0.18068021535873413
[10/24] Train loss=0.20746469497680664
[15/24] Train loss=0.21952944993972778
[20/24] Train loss=0.19840489327907562
Test set avg_accuracy=88.50% avg_sensitivity=79.43%, avg_specificity=91.13% avg_auc=92.82%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.212136 Test loss=0.297265 Current lr=[0.000299720220882401]

[0/24] Train loss=0.22167858481407166
[5/24] Train loss=0.18157294392585754
[10/24] Train loss=0.20421503484249115
[15/24] Train loss=0.21441800892353058
[20/24] Train loss=0.20095807313919067
Test set avg_accuracy=90.47% avg_sensitivity=75.55%, avg_specificity=94.79% avg_auc=93.81%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.208492 Test loss=0.257346 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.21438905596733093
[5/24] Train loss=0.18303515017032623
[10/24] Train loss=0.20049509406089783
[15/24] Train loss=0.21414825320243835
[20/24] Train loss=0.20637014508247375
Test set avg_accuracy=87.96% avg_sensitivity=50.00%, avg_specificity=98.96% avg_auc=89.78%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.210152 Test loss=0.321817 Current lr=[0.000298904600941902]

[0/24] Train loss=0.21760404109954834
[5/24] Train loss=0.18540532886981964
[10/24] Train loss=0.20737111568450928
[15/24] Train loss=0.2133713811635971
[20/24] Train loss=0.20140084624290466
Test set avg_accuracy=89.78% avg_sensitivity=67.56%, avg_specificity=96.22% avg_auc=91.25%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.208752 Test loss=0.283504 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.2062651365995407
[5/24] Train loss=0.17055407166481018
[10/24] Train loss=0.20325598120689392
[15/24] Train loss=0.20659862458705902
[20/24] Train loss=0.1921049803495407
Test set avg_accuracy=87.11% avg_sensitivity=77.81%, avg_specificity=89.81% avg_auc=91.61%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.202261 Test loss=0.322861 Current lr=[0.000297555943323901]

[0/24] Train loss=0.21689119935035706
[5/24] Train loss=0.17829063534736633
[10/24] Train loss=0.19872713088989258
[15/24] Train loss=0.2136540561914444
[20/24] Train loss=0.21261513233184814
Test set avg_accuracy=89.54% avg_sensitivity=72.54%, avg_specificity=94.47% avg_auc=92.98%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.207179 Test loss=0.271067 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.21343831717967987
[5/24] Train loss=0.1751570999622345
[10/24] Train loss=0.20019657909870148
[15/24] Train loss=0.2060118019580841
[20/24] Train loss=0.19467006623744965
Test set avg_accuracy=87.06% avg_sensitivity=83.43%, avg_specificity=88.11% avg_auc=93.41%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.200462 Test loss=0.307344 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.19565819203853607
[5/24] Train loss=0.18468303978443146
[10/24] Train loss=0.2001437097787857
[15/24] Train loss=0.20428070425987244
[20/24] Train loss=0.19175294041633606
Test set avg_accuracy=89.75% avg_sensitivity=74.51%, avg_specificity=94.17% avg_auc=92.83%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.198701 Test loss=0.272482 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.20450527966022491
[5/24] Train loss=0.17039228975772858
[10/24] Train loss=0.19610758125782013
[15/24] Train loss=0.21221806108951569
[20/24] Train loss=0.1943945735692978
Test set avg_accuracy=88.85% avg_sensitivity=77.69%, avg_specificity=92.09% avg_auc=93.41%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.198266 Test loss=0.272210 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.20246721804141998
[5/24] Train loss=0.16863124072551727
[10/24] Train loss=0.2045319378376007
[15/24] Train loss=0.20228637754917145
[20/24] Train loss=0.2008904367685318
Test set avg_accuracy=88.23% avg_sensitivity=75.55%, avg_specificity=91.90% avg_auc=92.45%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.197699 Test loss=0.296676 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.20499056577682495
[5/24] Train loss=0.1873425990343094
[10/24] Train loss=0.18306685984134674
[15/24] Train loss=0.21634173393249512
[20/24] Train loss=0.19692058861255646
Test set avg_accuracy=90.10% avg_sensitivity=66.98%, avg_specificity=96.81% avg_auc=92.51%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.197823 Test loss=0.263403 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.20494936406612396
[5/24] Train loss=0.169777050614357
[10/24] Train loss=0.2209746092557907
[15/24] Train loss=0.21834634244441986
[20/24] Train loss=0.18741612136363983
Test set avg_accuracy=89.36% avg_sensitivity=71.78%, avg_specificity=94.46% avg_auc=92.62%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.196637 Test loss=0.278411 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.19612331688404083
[5/24] Train loss=0.1671665459871292
[10/24] Train loss=0.19562633335590363
[15/24] Train loss=0.20247861742973328
[20/24] Train loss=0.18810276687145233
Test set avg_accuracy=89.75% avg_sensitivity=75.26%, avg_specificity=93.95% avg_auc=93.14%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.196258 Test loss=0.264866 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.19952745735645294
[5/24] Train loss=0.16755898296833038
[10/24] Train loss=0.18758973479270935
[15/24] Train loss=0.20608438551425934
[20/24] Train loss=0.18976707756519318
Test set avg_accuracy=90.03% avg_sensitivity=76.13%, avg_specificity=94.05% avg_auc=93.57%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.192975 Test loss=0.264665 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.20931664109230042
[5/24] Train loss=0.18846537172794342
[10/24] Train loss=0.18791049718856812
[15/24] Train loss=0.21150630712509155
[20/24] Train loss=0.1866883635520935
Test set avg_accuracy=89.35% avg_sensitivity=71.84%, avg_specificity=94.42% avg_auc=92.21%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.192605 Test loss=0.275410 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2044917345046997
[5/24] Train loss=0.17388875782489777
[10/24] Train loss=0.17381305992603302
[15/24] Train loss=0.19515633583068848
[20/24] Train loss=0.1979997456073761
Test set avg_accuracy=88.18% avg_sensitivity=76.71%, avg_specificity=91.50% avg_auc=92.16%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.191781 Test loss=0.316564 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.19069799780845642
[5/24] Train loss=0.1685958355665207
[10/24] Train loss=0.17734770476818085
[15/24] Train loss=0.19980645179748535
[20/24] Train loss=0.17874345183372498
Test set avg_accuracy=88.16% avg_sensitivity=72.65%, avg_specificity=92.66% avg_auc=92.06%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.190015 Test loss=0.290420 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.19788384437561035
[5/24] Train loss=0.17867159843444824
[10/24] Train loss=0.18727435171604156
[15/24] Train loss=0.2089928537607193
[20/24] Train loss=0.19181470572948456
Test set avg_accuracy=89.04% avg_sensitivity=62.11%, avg_specificity=96.84% avg_auc=91.61%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.192348 Test loss=0.287898 Current lr=[0.000276307469034998]

[0/24] Train loss=0.19570493698120117
[5/24] Train loss=0.18290464580059052
[10/24] Train loss=0.19235862791538239
[15/24] Train loss=0.19877296686172485
[20/24] Train loss=0.17545345425605774
Test set avg_accuracy=85.81% avg_sensitivity=84.41%, avg_specificity=86.21% avg_auc=92.66%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.194505 Test loss=0.326946 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.1983281522989273
[5/24] Train loss=0.1712329387664795
[10/24] Train loss=0.17935270071029663
[15/24] Train loss=0.1974380910396576
[20/24] Train loss=0.18665648996829987
Test set avg_accuracy=88.05% avg_sensitivity=75.09%, avg_specificity=91.80% avg_auc=91.37%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.188274 Test loss=0.307568 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.18759964406490326
[5/24] Train loss=0.1631297469139099
[10/24] Train loss=0.18395428359508514
[15/24] Train loss=0.1946440190076828
[20/24] Train loss=0.17976456880569458
Test set avg_accuracy=90.08% avg_sensitivity=70.22%, avg_specificity=95.83% avg_auc=92.67%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.185841 Test loss=0.268616 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.194358691573143
[5/24] Train loss=0.1555691957473755
[10/24] Train loss=0.19030791521072388
[15/24] Train loss=0.19448456168174744
[20/24] Train loss=0.16963160037994385
Test set avg_accuracy=87.41% avg_sensitivity=78.33%, avg_specificity=90.04% avg_auc=93.07%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.184563 Test loss=0.298589 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.18745237588882446
[5/24] Train loss=0.15966562926769257
[10/24] Train loss=0.18096670508384705
[15/24] Train loss=0.20314835011959076
[20/24] Train loss=0.1733398586511612
Test set avg_accuracy=88.71% avg_sensitivity=82.10%, avg_specificity=90.63% avg_auc=93.34%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.186307 Test loss=0.306997 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.19300000369548798
[5/24] Train loss=0.16701453924179077
[10/24] Train loss=0.17544575035572052
[15/24] Train loss=0.1868789941072464
[20/24] Train loss=0.17981429398059845
Test set avg_accuracy=88.91% avg_sensitivity=76.42%, avg_specificity=92.53% avg_auc=92.61%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.182790 Test loss=0.292497 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.19184398651123047
[5/24] Train loss=0.15710896253585815
[10/24] Train loss=0.17515186965465546
[15/24] Train loss=0.1910342127084732
[20/24] Train loss=0.1742585003376007
Test set avg_accuracy=89.47% avg_sensitivity=73.99%, avg_specificity=93.95% avg_auc=93.30%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.181295 Test loss=0.271886 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.1821790635585785
[5/24] Train loss=0.16014961898326874
[10/24] Train loss=0.17954528331756592
[15/24] Train loss=0.18922863900661469
[20/24] Train loss=0.16796912252902985
Test set avg_accuracy=90.35% avg_sensitivity=72.71%, avg_specificity=95.47% avg_auc=93.15%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.181060 Test loss=0.260525 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.18569326400756836
[5/24] Train loss=0.15886905789375305
[10/24] Train loss=0.1727803349494934
[15/24] Train loss=0.19074244797229767
[20/24] Train loss=0.17813129723072052
Test set avg_accuracy=87.84% avg_sensitivity=81.92%, avg_specificity=89.55% avg_auc=92.83%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.179417 Test loss=0.315110 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.1820669025182724
[5/24] Train loss=0.16828665137290955
[10/24] Train loss=0.16994744539260864
[15/24] Train loss=0.18696913123130798
[20/24] Train loss=0.17243139445781708
Test set avg_accuracy=89.43% avg_sensitivity=72.07%, avg_specificity=94.46% avg_auc=92.02%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.181483 Test loss=0.289399 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.19262506067752838
[5/24] Train loss=0.1628800630569458
[10/24] Train loss=0.16869515180587769
[15/24] Train loss=0.18130557239055634
[20/24] Train loss=0.17785753309726715
Test set avg_accuracy=89.00% avg_sensitivity=77.06%, avg_specificity=92.46% avg_auc=92.44%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.179125 Test loss=0.294528 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.17893268167972565
[5/24] Train loss=0.1623569279909134
[10/24] Train loss=0.18575520813465118
[15/24] Train loss=0.18904517590999603
[20/24] Train loss=0.17274132370948792
Test set avg_accuracy=88.98% avg_sensitivity=57.24%, avg_specificity=98.19% avg_auc=89.56%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.178595 Test loss=0.300290 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.19393768906593323
[5/24] Train loss=0.1660415381193161
[10/24] Train loss=0.16612012684345245
[15/24] Train loss=0.18578501045703888
[20/24] Train loss=0.16679291427135468
Test set avg_accuracy=88.67% avg_sensitivity=73.17%, avg_specificity=93.16% avg_auc=90.99%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.179388 Test loss=0.294029 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.18765099346637726
[5/24] Train loss=0.15924571454524994
[10/24] Train loss=0.1651545614004135
[15/24] Train loss=0.18203985691070557
[20/24] Train loss=0.17555175721645355
Test set avg_accuracy=88.05% avg_sensitivity=74.97%, avg_specificity=91.84% avg_auc=90.37%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.176178 Test loss=0.316920 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.19925546646118164
[5/24] Train loss=0.1592472344636917
[10/24] Train loss=0.16944070160388947
[15/24] Train loss=0.17887373268604279
[20/24] Train loss=0.17071737349033356
Test set avg_accuracy=88.87% avg_sensitivity=77.93%, avg_specificity=92.04% avg_auc=91.85%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.177190 Test loss=0.306174 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.18668566644191742
[5/24] Train loss=0.15441745519638062
[10/24] Train loss=0.1759207844734192
[15/24] Train loss=0.1850968450307846
[20/24] Train loss=0.18009094893932343
Test set avg_accuracy=86.34% avg_sensitivity=43.57%, avg_specificity=98.74% avg_auc=86.21%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.179713 Test loss=0.375172 Current lr=[0.000224838296036774]

[0/24] Train loss=0.19394725561141968
[5/24] Train loss=0.16138000786304474
[10/24] Train loss=0.1815177947282791
[15/24] Train loss=0.17793920636177063
[20/24] Train loss=0.15885449945926666
Test set avg_accuracy=90.46% avg_sensitivity=71.90%, avg_specificity=95.83% avg_auc=92.64%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.176668 Test loss=0.270544 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.17623469233512878
[5/24] Train loss=0.1546233743429184
[10/24] Train loss=0.17556972801685333
[15/24] Train loss=0.18262068927288055
[20/24] Train loss=0.17215575277805328
Test set avg_accuracy=89.99% avg_sensitivity=64.89%, avg_specificity=97.26% avg_auc=90.50%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.175302 Test loss=0.287084 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.177459254860878
[5/24] Train loss=0.16177579760551453
[10/24] Train loss=0.18110215663909912
[15/24] Train loss=0.17494256794452667
[20/24] Train loss=0.16230088472366333
Test set avg_accuracy=88.14% avg_sensitivity=78.56%, avg_specificity=90.91% avg_auc=92.89%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.174490 Test loss=0.292966 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.18903027474880219
[5/24] Train loss=0.15317203104496002
[10/24] Train loss=0.15708647668361664
[15/24] Train loss=0.1743481457233429
[20/24] Train loss=0.16699130833148956
Test set avg_accuracy=87.67% avg_sensitivity=79.72%, avg_specificity=89.97% avg_auc=92.72%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.170808 Test loss=0.312560 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.17683294415473938
[5/24] Train loss=0.15615291893482208
[10/24] Train loss=0.15773935616016388
[15/24] Train loss=0.1748577356338501
[20/24] Train loss=0.16377854347229004
Test set avg_accuracy=89.35% avg_sensitivity=69.64%, avg_specificity=95.06% avg_auc=91.94%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.172194 Test loss=0.281706 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.176462784409523
[5/24] Train loss=0.16103535890579224
[10/24] Train loss=0.15973912179470062
[15/24] Train loss=0.17063555121421814
[20/24] Train loss=0.16021868586540222
Test set avg_accuracy=89.78% avg_sensitivity=71.15%, avg_specificity=95.18% avg_auc=92.29%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.169459 Test loss=0.269292 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.1762896329164505
[5/24] Train loss=0.15692895650863647
[10/24] Train loss=0.15699990093708038
[15/24] Train loss=0.17014853656291962
[20/24] Train loss=0.15777598321437836
Test set avg_accuracy=87.45% avg_sensitivity=78.56%, avg_specificity=90.02% avg_auc=92.71%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.167705 Test loss=0.301249 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.18123173713684082
[5/24] Train loss=0.15311186015605927
[10/24] Train loss=0.15420396625995636
[15/24] Train loss=0.16613668203353882
[20/24] Train loss=0.1600836217403412
Test set avg_accuracy=86.00% avg_sensitivity=78.97%, avg_specificity=88.04% avg_auc=90.63%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.164041 Test loss=0.344006 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.17343194782733917
[5/24] Train loss=0.15292035043239594
[10/24] Train loss=0.15732164680957794
[15/24] Train loss=0.16902506351470947
[20/24] Train loss=0.15679462254047394
Test set avg_accuracy=86.15% avg_sensitivity=80.65%, avg_specificity=87.74% avg_auc=92.28%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.162620 Test loss=0.336000 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.17348052561283112
[5/24] Train loss=0.14640796184539795
[10/24] Train loss=0.151754692196846
[15/24] Train loss=0.16718527674674988
[20/24] Train loss=0.16142675280570984
Test set avg_accuracy=87.03% avg_sensitivity=83.02%, avg_specificity=88.19% avg_auc=92.54%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.162128 Test loss=0.334995 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.17206157743930817
[5/24] Train loss=0.15684092044830322
[10/24] Train loss=0.14817450940608978
[15/24] Train loss=0.16829176247119904
[20/24] Train loss=0.16261810064315796
Test set avg_accuracy=89.05% avg_sensitivity=63.50%, avg_specificity=96.46% avg_auc=91.02%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.162037 Test loss=0.308711 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.16682758927345276
[5/24] Train loss=0.15494677424430847
[10/24] Train loss=0.157664492726326
[15/24] Train loss=0.1644574999809265
[20/24] Train loss=0.159852996468544
Test set avg_accuracy=90.01% avg_sensitivity=66.69%, avg_specificity=96.78% avg_auc=91.63%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.162626 Test loss=0.280737 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.1717482954263687
[5/24] Train loss=0.15165917575359344
[10/24] Train loss=0.14540167152881622
[15/24] Train loss=0.16371509432792664
[20/24] Train loss=0.147541806101799
Test set avg_accuracy=88.28% avg_sensitivity=75.43%, avg_specificity=92.01% avg_auc=93.10%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.159195 Test loss=0.287452 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.166731595993042
[5/24] Train loss=0.1458817422389984
[10/24] Train loss=0.14543339610099792
[15/24] Train loss=0.17365606129169464
[20/24] Train loss=0.1503518521785736
Test set avg_accuracy=89.24% avg_sensitivity=60.83%, avg_specificity=97.48% avg_auc=90.77%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.159483 Test loss=0.292882 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.1651851236820221
[5/24] Train loss=0.1533389538526535
[10/24] Train loss=0.15137968957424164
[15/24] Train loss=0.15995612740516663
[20/24] Train loss=0.15151360630989075
Test set avg_accuracy=90.17% avg_sensitivity=69.76%, avg_specificity=96.09% avg_auc=91.98%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.158052 Test loss=0.272525 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.16036266088485718
[5/24] Train loss=0.1413172036409378
[10/24] Train loss=0.14877644181251526
[15/24] Train loss=0.1609746515750885
[20/24] Train loss=0.15105028450489044
Test set avg_accuracy=89.11% avg_sensitivity=63.85%, avg_specificity=96.44% avg_auc=90.04%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.158088 Test loss=0.306587 Current lr=[0.000156543481933168]

[0/24] Train loss=0.16648490726947784
[5/24] Train loss=0.14849840104579926
[10/24] Train loss=0.150773823261261
[15/24] Train loss=0.1672428846359253
[20/24] Train loss=0.15795212984085083
Test set avg_accuracy=89.44% avg_sensitivity=69.41%, avg_specificity=95.25% avg_auc=91.51%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.157867 Test loss=0.300848 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.16111527383327484
[5/24] Train loss=0.14928458631038666
[10/24] Train loss=0.14797456562519073
[15/24] Train loss=0.16095270216464996
[20/24] Train loss=0.14932988584041595
Test set avg_accuracy=89.65% avg_sensitivity=74.62%, avg_specificity=94.00% avg_auc=92.92%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.157902 Test loss=0.274670 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.16179972887039185
[5/24] Train loss=0.14626435935497284
[10/24] Train loss=0.14955665171146393
[15/24] Train loss=0.1649286448955536
[20/24] Train loss=0.14698722958564758
Test set avg_accuracy=90.21% avg_sensitivity=71.21%, avg_specificity=95.72% avg_auc=92.78%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.155636 Test loss=0.265376 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.1585964560508728
[5/24] Train loss=0.14991922676563263
[10/24] Train loss=0.14849036931991577
[15/24] Train loss=0.16178952157497406
[20/24] Train loss=0.144111767411232
Test set avg_accuracy=89.40% avg_sensitivity=72.36%, avg_specificity=94.34% avg_auc=91.87%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.154379 Test loss=0.281544 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.15639740228652954
[5/24] Train loss=0.1443980634212494
[10/24] Train loss=0.13784919679164886
[15/24] Train loss=0.15862205624580383
[20/24] Train loss=0.15931378304958344
Test set avg_accuracy=81.59% avg_sensitivity=88.41%, avg_specificity=79.61% avg_auc=91.20%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.153847 Test loss=0.451267 Current lr=[0.000134135431043539]

[0/24] Train loss=0.15516681969165802
[5/24] Train loss=0.14092668890953064
[10/24] Train loss=0.13768549263477325
[15/24] Train loss=0.15600131452083588
[20/24] Train loss=0.1464734822511673
Test set avg_accuracy=90.36% avg_sensitivity=71.49%, avg_specificity=95.83% avg_auc=92.81%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.153629 Test loss=0.267352 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.15482591092586517
[5/24] Train loss=0.14595042169094086
[10/24] Train loss=0.14077766239643097
[15/24] Train loss=0.15943416953086853
[20/24] Train loss=0.1438990980386734
Test set avg_accuracy=90.17% avg_sensitivity=71.26%, avg_specificity=95.65% avg_auc=91.94%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.152290 Test loss=0.273742 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.15769508481025696
[5/24] Train loss=0.14052556455135345
[10/24] Train loss=0.13796968758106232
[15/24] Train loss=0.15489462018013
[20/24] Train loss=0.14629137516021729
Test set avg_accuracy=90.36% avg_sensitivity=67.03%, avg_specificity=97.13% avg_auc=91.75%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.148949 Test loss=0.271971 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.15188539028167725
[5/24] Train loss=0.13827922940254211
[10/24] Train loss=0.14370620250701904
[15/24] Train loss=0.15129201114177704
[20/24] Train loss=0.14165647327899933
Test set avg_accuracy=90.17% avg_sensitivity=71.78%, avg_specificity=95.50% avg_auc=91.96%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.148372 Test loss=0.271752 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.14766289293766022
[5/24] Train loss=0.1379295140504837
[10/24] Train loss=0.13756641745567322
[15/24] Train loss=0.151541605591774
[20/24] Train loss=0.14256758987903595
Test set avg_accuracy=90.36% avg_sensitivity=68.89%, avg_specificity=96.59% avg_auc=91.70%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.147259 Test loss=0.273454 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.1541299968957901
[5/24] Train loss=0.14028874039649963
[10/24] Train loss=0.13423456251621246
[15/24] Train loss=0.14976866543293
[20/24] Train loss=0.1455041915178299
Test set avg_accuracy=90.76% avg_sensitivity=73.35%, avg_specificity=95.80% avg_auc=92.44%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.147735 Test loss=0.270751 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.14867937564849854
[5/24] Train loss=0.1389908343553543
[10/24] Train loss=0.1375676542520523
[15/24] Train loss=0.1475251019001007
[20/24] Train loss=0.14297381043434143
Test set avg_accuracy=90.08% avg_sensitivity=65.18%, avg_specificity=97.30% avg_auc=91.35%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.146900 Test loss=0.285583 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.15083472430706024
[5/24] Train loss=0.13740955293178558
[10/24] Train loss=0.14441655576229095
[15/24] Train loss=0.16245658695697784
[20/24] Train loss=0.14072173833847046
Test set avg_accuracy=90.46% avg_sensitivity=74.22%, avg_specificity=95.16% avg_auc=92.91%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.148219 Test loss=0.267746 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.1530519276857376
[5/24] Train loss=0.13784581422805786
[10/24] Train loss=0.13817548751831055
[15/24] Train loss=0.1562103033065796
[20/24] Train loss=0.1400906890630722
Test set avg_accuracy=90.35% avg_sensitivity=71.09%, avg_specificity=95.94% avg_auc=92.69%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.147621 Test loss=0.266870 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.15759553015232086
[5/24] Train loss=0.1395009458065033
[10/24] Train loss=0.13017024099826813
[15/24] Train loss=0.15115216374397278
[20/24] Train loss=0.14528508484363556
Test set avg_accuracy=90.09% avg_sensitivity=64.83%, avg_specificity=97.41% avg_auc=91.27%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.148046 Test loss=0.280719 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.15249882638454437
[5/24] Train loss=0.13495953381061554
[10/24] Train loss=0.13545569777488708
[15/24] Train loss=0.152541384100914
[20/24] Train loss=0.13947007060050964
Test set avg_accuracy=90.56% avg_sensitivity=71.03%, avg_specificity=96.22% avg_auc=92.18%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.146481 Test loss=0.274847 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.14765751361846924
[5/24] Train loss=0.14170096814632416
[10/24] Train loss=0.13719235360622406
[15/24] Train loss=0.14849230647087097
[20/24] Train loss=0.14130887389183044
Test set avg_accuracy=90.14% avg_sensitivity=68.13%, avg_specificity=96.52% avg_auc=92.47%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.145809 Test loss=0.272576 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.14939159154891968
[5/24] Train loss=0.1410757452249527
[10/24] Train loss=0.1327849179506302
[15/24] Train loss=0.15198583900928497
[20/24] Train loss=0.13385024666786194
Test set avg_accuracy=90.18% avg_sensitivity=73.12%, avg_specificity=95.13% avg_auc=93.61%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.145880 Test loss=0.260033 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.15026770532131195
[5/24] Train loss=0.13486722111701965
[10/24] Train loss=0.13957837224006653
[15/24] Train loss=0.1493242383003235
[20/24] Train loss=0.13844555616378784
Test set avg_accuracy=88.72% avg_sensitivity=73.17%, avg_specificity=93.23% avg_auc=92.78%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.143861 Test loss=0.282650 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1487409472465515
[5/24] Train loss=0.13584956526756287
[10/24] Train loss=0.12917424738407135
[15/24] Train loss=0.1492108404636383
[20/24] Train loss=0.13213247060775757
Test set avg_accuracy=89.74% avg_sensitivity=70.97%, avg_specificity=95.18% avg_auc=92.88%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.142835 Test loss=0.275310 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1476370245218277
[5/24] Train loss=0.13127538561820984
[10/24] Train loss=0.1308111548423767
[15/24] Train loss=0.14389170706272125
[20/24] Train loss=0.13904723525047302
Test set avg_accuracy=89.47% avg_sensitivity=60.83%, avg_specificity=97.77% avg_auc=90.44%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.140658 Test loss=0.295758 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1405227780342102
[5/24] Train loss=0.1325182020664215
[10/24] Train loss=0.13110113143920898
[15/24] Train loss=0.1461821049451828
[20/24] Train loss=0.12903863191604614
Test set avg_accuracy=89.82% avg_sensitivity=63.15%, avg_specificity=97.55% avg_auc=91.16%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.138962 Test loss=0.286179 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.14438287913799286
[5/24] Train loss=0.13428953289985657
[10/24] Train loss=0.1271131932735443
[15/24] Train loss=0.14593903720378876
[20/24] Train loss=0.13000328838825226
Test set avg_accuracy=90.21% avg_sensitivity=65.18%, avg_specificity=97.46% avg_auc=91.42%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.137614 Test loss=0.284472 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.14168879389762878
[5/24] Train loss=0.13209101557731628
[10/24] Train loss=0.1262434720993042
[15/24] Train loss=0.1459871083498001
[20/24] Train loss=0.1352224349975586
Test set avg_accuracy=89.83% avg_sensitivity=63.50%, avg_specificity=97.46% avg_auc=91.05%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.138424 Test loss=0.292183 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.14210888743400574
[5/24] Train loss=0.12879344820976257
[10/24] Train loss=0.12615452706813812
[15/24] Train loss=0.14002911746501923
[20/24] Train loss=0.12926071882247925
Test set avg_accuracy=90.46% avg_sensitivity=69.47%, avg_specificity=96.54% avg_auc=92.03%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.136724 Test loss=0.271120 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.14098286628723145
[5/24] Train loss=0.12823104858398438
[10/24] Train loss=0.1252482384443283
[15/24] Train loss=0.14171497523784637
[20/24] Train loss=0.13060176372528076
Test set avg_accuracy=90.39% avg_sensitivity=71.38%, avg_specificity=95.90% avg_auc=92.43%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.134757 Test loss=0.269095 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1404721438884735
[5/24] Train loss=0.12410785257816315
[10/24] Train loss=0.12334663420915604
[15/24] Train loss=0.13605909049510956
[20/24] Train loss=0.12784862518310547
Test set avg_accuracy=89.99% avg_sensitivity=74.28%, avg_specificity=94.54% avg_auc=92.83%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.133245 Test loss=0.273426 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.13961926102638245
[5/24] Train loss=0.1295700967311859
[10/24] Train loss=0.12401184439659119
[15/24] Train loss=0.13739243149757385
[20/24] Train loss=0.12882928550243378
Test set avg_accuracy=90.61% avg_sensitivity=68.08%, avg_specificity=97.14% avg_auc=91.77%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.132651 Test loss=0.274827 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1381070464849472
[5/24] Train loss=0.12533003091812134
[10/24] Train loss=0.12263951450586319
[15/24] Train loss=0.13774116337299347
[20/24] Train loss=0.12987516820430756
Test set avg_accuracy=90.09% avg_sensitivity=69.58%, avg_specificity=96.04% avg_auc=92.04%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.132040 Test loss=0.276821 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1402873396873474
[5/24] Train loss=0.12176991999149323
[10/24] Train loss=0.12306129932403564
[15/24] Train loss=0.1333887279033661
[20/24] Train loss=0.12733355164527893
Test set avg_accuracy=90.35% avg_sensitivity=70.63%, avg_specificity=96.07% avg_auc=92.07%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.130991 Test loss=0.270731 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.13857585191726685
[5/24] Train loss=0.12558941543102264
[10/24] Train loss=0.12167274951934814
[15/24] Train loss=0.13695140182971954
[20/24] Train loss=0.1262243241071701
Test set avg_accuracy=89.86% avg_sensitivity=70.05%, avg_specificity=95.60% avg_auc=92.25%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.131043 Test loss=0.273078 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.13888470828533173
[5/24] Train loss=0.12371814250946045
[10/24] Train loss=0.11826855689287186
[15/24] Train loss=0.1352451592683792
[20/24] Train loss=0.1269693374633789
Test set avg_accuracy=90.26% avg_sensitivity=69.24%, avg_specificity=96.36% avg_auc=91.81%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.130242 Test loss=0.275512 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.13543091714382172
[5/24] Train loss=0.12610062956809998
[10/24] Train loss=0.11930518597364426
[15/24] Train loss=0.13297554850578308
[20/24] Train loss=0.12476279586553574
Test set avg_accuracy=90.34% avg_sensitivity=70.39%, avg_specificity=96.12% avg_auc=92.02%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.129767 Test loss=0.274153 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.13320238888263702
[5/24] Train loss=0.124541737139225
[10/24] Train loss=0.11732088029384613
[15/24] Train loss=0.13173142075538635
[20/24] Train loss=0.12585385143756866
Test set avg_accuracy=90.38% avg_sensitivity=68.71%, avg_specificity=96.66% avg_auc=91.90%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.129095 Test loss=0.275397 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.13354820013046265
[5/24] Train loss=0.12570828199386597
[10/24] Train loss=0.11711511760950089
[15/24] Train loss=0.13539674878120422
[20/24] Train loss=0.1254507154226303
Test set avg_accuracy=90.49% avg_sensitivity=71.09%, avg_specificity=96.12% avg_auc=92.03%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.129636 Test loss=0.273953 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.13350854814052582
[5/24] Train loss=0.12331437319517136
[10/24] Train loss=0.12154508382081985
[15/24] Train loss=0.13151435554027557
[20/24] Train loss=0.12670409679412842
Test set avg_accuracy=90.27% avg_sensitivity=68.89%, avg_specificity=96.47% avg_auc=91.83%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.129482 Test loss=0.277159 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.13236413896083832
[5/24] Train loss=0.12422387301921844
[10/24] Train loss=0.11826971918344498
[15/24] Train loss=0.13074342906475067
[20/24] Train loss=0.12486452609300613
Test set avg_accuracy=90.22% avg_sensitivity=72.65%, avg_specificity=95.31% avg_auc=92.37%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.128720 Test loss=0.269754 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1350499838590622
[5/24] Train loss=0.12032222002744675
[10/24] Train loss=0.11948555707931519
[15/24] Train loss=0.12821878492832184
[20/24] Train loss=0.12374448031187057
Test set avg_accuracy=90.52% avg_sensitivity=70.45%, avg_specificity=96.34% avg_auc=91.96%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.127941 Test loss=0.274677 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.13217554986476898
[5/24] Train loss=0.12043904513120651
[10/24] Train loss=0.116200290620327
[15/24] Train loss=0.12989354133605957
[20/24] Train loss=0.12630654871463776
Test set avg_accuracy=90.53% avg_sensitivity=71.55%, avg_specificity=96.04% avg_auc=92.07%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.126873 Test loss=0.272520 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1300957053899765
[5/24] Train loss=0.12091758102178574
[10/24] Train loss=0.1153799444437027
[15/24] Train loss=0.12832334637641907
[20/24] Train loss=0.12025172263383865
Test set avg_accuracy=90.48% avg_sensitivity=70.10%, avg_specificity=96.39% avg_auc=91.83%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.125808 Test loss=0.274108 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1290893405675888
[5/24] Train loss=0.11982301622629166
[10/24] Train loss=0.11555372178554535
[15/24] Train loss=0.12597854435443878
[20/24] Train loss=0.1218993216753006
Test set avg_accuracy=90.43% avg_sensitivity=70.74%, avg_specificity=96.14% avg_auc=91.90%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.125217 Test loss=0.274060 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.13065041601657867
[5/24] Train loss=0.11895472556352615
[10/24] Train loss=0.11570113152265549
[15/24] Train loss=0.12687717378139496
[20/24] Train loss=0.1237068772315979
Test set avg_accuracy=90.38% avg_sensitivity=71.21%, avg_specificity=95.94% avg_auc=92.05%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.124985 Test loss=0.273592 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.12902946770191193
[5/24] Train loss=0.11783565580844879
[10/24] Train loss=0.11647570133209229
[15/24] Train loss=0.12630082666873932
[20/24] Train loss=0.12456782162189484
Test set avg_accuracy=90.68% avg_sensitivity=70.86%, avg_specificity=96.42% avg_auc=92.01%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.124979 Test loss=0.272938 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.13006147742271423
[5/24] Train loss=0.11897561699151993
[10/24] Train loss=0.11364470422267914
[15/24] Train loss=0.12667477130889893
[20/24] Train loss=0.12229622900485992
Test set avg_accuracy=90.34% avg_sensitivity=70.80%, avg_specificity=96.00% avg_auc=91.99%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.124744 Test loss=0.272982 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.13126838207244873
[5/24] Train loss=0.11847537010908127
[10/24] Train loss=0.11075814813375473
[15/24] Train loss=0.12658286094665527
[20/24] Train loss=0.12285088747739792
Test set avg_accuracy=90.51% avg_sensitivity=71.09%, avg_specificity=96.14% avg_auc=92.02%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.124643 Test loss=0.272986 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.12759844958782196
[5/24] Train loss=0.11645202338695526
[10/24] Train loss=0.11468423902988434
[15/24] Train loss=0.1277523636817932
[20/24] Train loss=0.12188006192445755
Test set avg_accuracy=90.61% avg_sensitivity=71.03%, avg_specificity=96.29% avg_auc=91.98%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.124071 Test loss=0.272638 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.12893450260162354
[5/24] Train loss=0.11604408174753189
[10/24] Train loss=0.11476053297519684
[15/24] Train loss=0.12510500848293304
[20/24] Train loss=0.12133078277111053
Test set avg_accuracy=90.49% avg_sensitivity=70.57%, avg_specificity=96.27% avg_auc=91.90%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.123475 Test loss=0.273828 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.12572212517261505
[5/24] Train loss=0.11739160120487213
[10/24] Train loss=0.11255098134279251
[15/24] Train loss=0.1254996806383133
[20/24] Train loss=0.11962633579969406
Test set avg_accuracy=90.46% avg_sensitivity=70.74%, avg_specificity=96.17% avg_auc=91.89%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.123773 Test loss=0.274480 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.12839378416538239
[5/24] Train loss=0.11662782728672028
[10/24] Train loss=0.11330144107341766
[15/24] Train loss=0.12408850342035294
[20/24] Train loss=0.1191188395023346
Test set avg_accuracy=90.52% avg_sensitivity=70.68%, avg_specificity=96.27% avg_auc=91.90%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.123357 Test loss=0.273709 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1283624917268753
[5/24] Train loss=0.11746084690093994
[10/24] Train loss=0.11317138373851776
[15/24] Train loss=0.12619782984256744
[20/24] Train loss=0.1200118288397789
Test set avg_accuracy=90.51% avg_sensitivity=70.74%, avg_specificity=96.24% avg_auc=91.97%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.123945 Test loss=0.273363 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1298668533563614
[5/24] Train loss=0.11842610687017441
[10/24] Train loss=0.11219459772109985
[15/24] Train loss=0.12488431483507156
[20/24] Train loss=0.12191038578748703
Test set avg_accuracy=90.48% avg_sensitivity=70.68%, avg_specificity=96.22% avg_auc=91.95%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.123579 Test loss=0.273564 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.12663185596466064
[5/24] Train loss=0.1164715513586998
[10/24] Train loss=0.11362355947494507
[15/24] Train loss=0.12245779484510422
[20/24] Train loss=0.12066485732793808
Test set avg_accuracy=90.49% avg_sensitivity=70.63%, avg_specificity=96.25% avg_auc=91.95%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.123316 Test loss=0.273475 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.12812469899654388
[5/24] Train loss=0.11822839081287384
[10/24] Train loss=0.11321552842855453
[15/24] Train loss=0.12434615194797516
[20/24] Train loss=0.1211082711815834
Test set avg_accuracy=90.49% avg_sensitivity=70.63%, avg_specificity=96.25% avg_auc=91.96%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.123341 Test loss=0.273444 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.12667429447174072
[5/24] Train loss=0.11686954647302628
[10/24] Train loss=0.11450722068548203
[15/24] Train loss=0.12457447499036789
[20/24] Train loss=0.12272372841835022
Test set avg_accuracy=90.51% avg_sensitivity=70.68%, avg_specificity=96.25% avg_auc=91.96%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.123152 Test loss=0.273372 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=90.87% sen=74.45%, spe=95.63%, auc=94.24%!
Fold[10] Avg_overlap=0.70%(0.2518416947711834)
Final Avg Result: avg_acc=89.23%(1.0917028143422471) avg_sen=79.60% (3.4716948366223592) avg_spe=92.48% (2.154008908998212) avg_auc=93.88% (0.9131147612398364) avg_overlap=0.71% (0.01695393710261174)
