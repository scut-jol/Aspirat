[0/24] Train loss=0.7057393193244934
[5/24] Train loss=0.7041506171226501
[10/24] Train loss=0.7027460932731628
[15/24] Train loss=0.7015008926391602
[20/24] Train loss=0.7001416683197021
Test set avg_accuracy=47.84% avg_sensitivity=53.79%, avg_specificity=45.71% avg_auc=49.62%
Best model saved!! Metric=-129.0390128744089!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.702756 Test loss=0.699688 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6990993022918701
[5/24] Train loss=0.6981713175773621
[10/24] Train loss=0.697309136390686
[15/24] Train loss=0.69666588306427
[20/24] Train loss=0.6955376267433167
Test set avg_accuracy=50.82% avg_sensitivity=48.19%, avg_specificity=51.76% avg_auc=50.01%
Best model saved!! Metric=-125.22193693622972!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.697410 Test loss=0.695387 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6945544481277466
[5/24] Train loss=0.6935766935348511
[10/24] Train loss=0.6928761601448059
[15/24] Train loss=0.6927659511566162
[20/24] Train loss=0.6915407180786133
Test set avg_accuracy=54.08% avg_sensitivity=42.11%, avg_specificity=58.35% avg_auc=49.93%
Best model saved!! Metric=-121.5390404978177!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.693103 Test loss=0.691537 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6905001401901245
[5/24] Train loss=0.6893383264541626
[10/24] Train loss=0.6893846392631531
[15/24] Train loss=0.6894568204879761
[20/24] Train loss=0.6885780692100525
Test set avg_accuracy=54.24% avg_sensitivity=41.12%, avg_specificity=58.93% avg_auc=49.98%
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.689570 Test loss=0.688593 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6876261234283447
[5/24] Train loss=0.6862736940383911
[10/24] Train loss=0.6865571737289429
[15/24] Train loss=0.6868549585342407
[20/24] Train loss=0.6858307719230652
Test set avg_accuracy=54.43% avg_sensitivity=40.33%, avg_specificity=59.46% avg_auc=50.02%
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.686761 Test loss=0.686008 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6847668886184692
[5/24] Train loss=0.6832729578018188
[10/24] Train loss=0.6833946108818054
[15/24] Train loss=0.6839568018913269
[20/24] Train loss=0.6824550628662109
Test set avg_accuracy=57.50% avg_sensitivity=34.19%, avg_specificity=65.82% avg_auc=50.08%
Best model saved!! Metric=-118.40650388625738!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.683641 Test loss=0.682523 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.681024968624115
[5/24] Train loss=0.6789906620979309
[10/24] Train loss=0.6788415908813477
[15/24] Train loss=0.6797152161598206
[20/24] Train loss=0.6776188015937805
Test set avg_accuracy=57.85% avg_sensitivity=32.71%, avg_specificity=66.83% avg_auc=50.16%
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.679154 Test loss=0.677605 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6758230924606323
[5/24] Train loss=0.6731048822402954
[10/24] Train loss=0.6729060411453247
[15/24] Train loss=0.6739499568939209
[20/24] Train loss=0.671280026435852
Test set avg_accuracy=61.02% avg_sensitivity=26.47%, avg_specificity=73.35% avg_auc=50.12%
Best model saved!! Metric=-115.03760649167356!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.673126 Test loss=0.671003 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6688156723976135
[5/24] Train loss=0.6652766466140747
[10/24] Train loss=0.6648412942886353
[15/24] Train loss=0.6660086512565613
[20/24] Train loss=0.6623393297195435
Test set avg_accuracy=64.38% avg_sensitivity=19.74%, avg_specificity=80.31% avg_auc=50.27%
Best model saved!! Metric=-111.29468582840066!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.664886 Test loss=0.661777 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6589756011962891
[5/24] Train loss=0.6540603637695312
[10/24] Train loss=0.6530677676200867
[15/24] Train loss=0.6550134420394897
[20/24] Train loss=0.6497061848640442
Test set avg_accuracy=67.24% avg_sensitivity=13.36%, avg_specificity=86.48% avg_auc=50.53%
Best model saved!! Metric=-108.39191449574339!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.653180 Test loss=0.648641 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.644691526889801
[5/24] Train loss=0.6378417015075684
[10/24] Train loss=0.6363525986671448
[15/24] Train loss=0.639228105545044
[20/24] Train loss=0.6319568157196045
Test set avg_accuracy=67.50% avg_sensitivity=12.47%, avg_specificity=87.15% avg_auc=50.93%
Best model saved!! Metric=-107.94332957734213!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.636401 Test loss=0.630211 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6244836449623108
[5/24] Train loss=0.6148453950881958
[10/24] Train loss=0.6138041019439697
[15/24] Train loss=0.6186326742172241
[20/24] Train loss=0.6096764206886292
Test set avg_accuracy=70.62% avg_sensitivity=6.88%, avg_specificity=93.39% avg_auc=51.32%
Best model saved!! Metric=-103.7821997516097!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.614009 Test loss=0.607957 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5995870232582092
[5/24] Train loss=0.5876764059066772
[10/24] Train loss=0.5900748372077942
[15/24] Train loss=0.5975104570388794
[20/24] Train loss=0.5898160338401794
Test set avg_accuracy=73.67% avg_sensitivity=0.05%, avg_specificity=99.96% avg_auc=52.24%
Best model saved!! Metric=-100.07602981880528!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.590509 Test loss=0.588790 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5774606466293335
[5/24] Train loss=0.5641300082206726
[10/24] Train loss=0.5726486444473267
[15/24] Train loss=0.5828633308410645
[20/24] Train loss=0.5769806504249573
Test set avg_accuracy=73.66% avg_sensitivity=0.00%, avg_specificity=99.96% avg_auc=53.52%
Best model saved!! Metric=-98.85203489979654!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.573098 Test loss=0.577881 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5647731423377991
[5/24] Train loss=0.551489531993866
[10/24] Train loss=0.5654424428939819
[15/24] Train loss=0.577659010887146
[20/24] Train loss=0.5696031451225281
Test set avg_accuracy=73.65% avg_sensitivity=0.00%, avg_specificity=99.95% avg_auc=57.53%
Best model saved!! Metric=-94.88156431561495!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.564417 Test loss=0.572806 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5584453344345093
[5/24] Train loss=0.5461310148239136
[10/24] Train loss=0.5618860125541687
[15/24] Train loss=0.5739246606826782
[20/24] Train loss=0.5639451742172241
Test set avg_accuracy=73.55% avg_sensitivity=0.15%, avg_specificity=99.77% avg_auc=62.88%
Best model saved!! Metric=-89.64763300132034!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.559237 Test loss=0.568889 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5533367395401001
[5/24] Train loss=0.5399398803710938
[10/24] Train loss=0.558576762676239
[15/24] Train loss=0.569908618927002
[20/24] Train loss=0.5554311275482178
Test set avg_accuracy=73.42% avg_sensitivity=0.64%, avg_specificity=99.42% avg_auc=67.43%
Best model saved!! Metric=-85.0884861727947!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.553776 Test loss=0.563765 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5485275387763977
[5/24] Train loss=0.534325361251831
[10/24] Train loss=0.5538945198059082
[15/24] Train loss=0.5644057393074036
[20/24] Train loss=0.5402736067771912
Test set avg_accuracy=73.03% avg_sensitivity=3.51%, avg_specificity=97.86% avg_auc=71.75%
Best model saved!! Metric=-79.84052519637237!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.545421 Test loss=0.558839 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5391854643821716
[5/24] Train loss=0.527959406375885
[10/24] Train loss=0.5421713590621948
[15/24] Train loss=0.5502439141273499
[20/24] Train loss=0.5174816846847534
Test set avg_accuracy=72.94% avg_sensitivity=23.90%, avg_specificity=90.46% avg_auc=73.97%
Best model saved!! Metric=-64.72769290253264!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.530550 Test loss=0.603269 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5198261737823486
[5/24] Train loss=0.5097548365592957
[10/24] Train loss=0.5208649635314941
[15/24] Train loss=0.5338101983070374
[20/24] Train loss=0.4951845407485962
Test set avg_accuracy=62.50% avg_sensitivity=58.29%, avg_specificity=64.00% avg_auc=65.45%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.512835 Test loss=0.677121 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.509459912776947
[5/24] Train loss=0.5051817297935486
[10/24] Train loss=0.5045225024223328
[15/24] Train loss=0.5231761932373047
[20/24] Train loss=0.4899323284626007
Test set avg_accuracy=64.99% avg_sensitivity=43.89%, avg_specificity=72.52% avg_auc=61.96%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.499484 Test loss=0.666339 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5078287124633789
[5/24] Train loss=0.5067031979560852
[10/24] Train loss=0.4956497251987457
[15/24] Train loss=0.525198221206665
[20/24] Train loss=0.47226741909980774
Test set avg_accuracy=73.80% avg_sensitivity=44.78%, avg_specificity=84.17% avg_auc=69.26%
Best model saved!! Metric=-53.994580062907545!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.493207 Test loss=0.636455 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.47313159704208374
[5/24] Train loss=0.4814959168434143
[10/24] Train loss=0.4852384924888611
[15/24] Train loss=0.5090414881706238
[20/24] Train loss=0.46942225098609924
Test set avg_accuracy=71.15% avg_sensitivity=47.55%, avg_specificity=79.57% avg_auc=68.47%
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.483742 Test loss=0.629536 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.46709513664245605
[5/24] Train loss=0.4767158031463623
[10/24] Train loss=0.4773840010166168
[15/24] Train loss=0.49987417459487915
[20/24] Train loss=0.45899102091789246
Test set avg_accuracy=61.15% avg_sensitivity=59.67%, avg_specificity=61.67% avg_auc=65.27%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.475159 Test loss=0.657268 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.466986745595932
[5/24] Train loss=0.4792223274707794
[10/24] Train loss=0.47393953800201416
[15/24] Train loss=0.4941290616989136
[20/24] Train loss=0.4493878483772278
Test set avg_accuracy=59.11% avg_sensitivity=61.90%, avg_specificity=58.12% avg_auc=65.94%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.467491 Test loss=0.661676 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4418688416481018
[5/24] Train loss=0.465448796749115
[10/24] Train loss=0.46161991357803345
[15/24] Train loss=0.48078984022140503
[20/24] Train loss=0.432015061378479
Test set avg_accuracy=59.05% avg_sensitivity=63.78%, avg_specificity=57.36% avg_auc=66.20%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.455496 Test loss=0.643879 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.44685354828834534
[5/24] Train loss=0.47179529070854187
[10/24] Train loss=0.4557846188545227
[15/24] Train loss=0.4806574583053589
[20/24] Train loss=0.41582271456718445
Test set avg_accuracy=59.17% avg_sensitivity=71.00%, avg_specificity=54.94% avg_auc=69.41%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.448356 Test loss=0.647496 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.40885990858078003
[5/24] Train loss=0.43720319867134094
[10/24] Train loss=0.4347477853298187
[15/24] Train loss=0.46218568086624146
[20/24] Train loss=0.40059641003608704
Test set avg_accuracy=55.51% avg_sensitivity=64.97%, avg_specificity=52.13% avg_auc=64.61%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.432030 Test loss=0.666282 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4242927134037018
[5/24] Train loss=0.44953736662864685
[10/24] Train loss=0.43525609374046326
[15/24] Train loss=0.47859862446784973
[20/24] Train loss=0.39574486017227173
Test set avg_accuracy=61.60% avg_sensitivity=69.03%, avg_specificity=58.95% avg_auc=70.36%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.437762 Test loss=0.627421 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3982071876525879
[5/24] Train loss=0.4246519207954407
[10/24] Train loss=0.4339650273323059
[15/24] Train loss=0.4660515785217285
[20/24] Train loss=0.3828822672367096
Test set avg_accuracy=57.75% avg_sensitivity=75.66%, avg_specificity=51.35% avg_auc=71.03%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.421572 Test loss=0.657839 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.38681814074516296
[5/24] Train loss=0.41702234745025635
[10/24] Train loss=0.41711753606796265
[15/24] Train loss=0.4646473824977875
[20/24] Train loss=0.3903500437736511
Test set avg_accuracy=62.12% avg_sensitivity=65.71%, avg_specificity=60.84% avg_auc=70.02%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.415913 Test loss=0.613403 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.41606155037879944
[5/24] Train loss=0.4403941333293915
[10/24] Train loss=0.4317978620529175
[15/24] Train loss=0.4699937403202057
[20/24] Train loss=0.38306787610054016
Test set avg_accuracy=61.37% avg_sensitivity=69.47%, avg_specificity=58.47% avg_auc=70.46%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.425183 Test loss=0.629080 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3889826536178589
[5/24] Train loss=0.42475131154060364
[10/24] Train loss=0.4116229712963104
[15/24] Train loss=0.4632391035556793
[20/24] Train loss=0.3828047513961792
Test set avg_accuracy=63.02% avg_sensitivity=69.37%, avg_specificity=60.75% avg_auc=71.88%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.415035 Test loss=0.618747 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.38105309009552
[5/24] Train loss=0.4187491834163666
[10/24] Train loss=0.40471890568733215
[15/24] Train loss=0.45163294672966003
[20/24] Train loss=0.37000253796577454
Test set avg_accuracy=65.38% avg_sensitivity=69.27%, avg_specificity=63.99% avg_auc=72.86%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.410053 Test loss=0.607084 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3682660758495331
[5/24] Train loss=0.4185205101966858
[10/24] Train loss=0.40471842885017395
[15/24] Train loss=0.46289199590682983
[20/24] Train loss=0.3716280162334442
Test set avg_accuracy=65.68% avg_sensitivity=67.44%, avg_specificity=65.05% avg_auc=72.55%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.409868 Test loss=0.600566 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.37515032291412354
[5/24] Train loss=0.4113239645957947
[10/24] Train loss=0.40565869212150574
[15/24] Train loss=0.4569493234157562
[20/24] Train loss=0.36949384212493896
Test set avg_accuracy=64.35% avg_sensitivity=68.98%, avg_specificity=62.70% avg_auc=72.29%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.406454 Test loss=0.609519 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.37345218658447266
[5/24] Train loss=0.4031740427017212
[10/24] Train loss=0.4013440012931824
[15/24] Train loss=0.45227327942848206
[20/24] Train loss=0.3867519199848175
Test set avg_accuracy=65.01% avg_sensitivity=73.73%, avg_specificity=61.90% avg_auc=74.84%
Best model saved!! Metric=-50.518710792861626!!
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.407849 Test loss=0.611045 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.39466801285743713
[5/24] Train loss=0.4156292676925659
[10/24] Train loss=0.3977203667163849
[15/24] Train loss=0.4564397931098938
[20/24] Train loss=0.37190794944763184
Test set avg_accuracy=63.59% avg_sensitivity=70.51%, avg_specificity=61.12% avg_auc=72.37%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.407062 Test loss=0.619717 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3726181983947754
[5/24] Train loss=0.4066222310066223
[10/24] Train loss=0.40026241540908813
[15/24] Train loss=0.45154187083244324
[20/24] Train loss=0.36459529399871826
Test set avg_accuracy=65.20% avg_sensitivity=73.58%, avg_specificity=62.20% avg_auc=74.82%
Best model saved!! Metric=-50.20998121795826!!
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.402331 Test loss=0.612019 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.37484389543533325
[5/24] Train loss=0.4034428596496582
[10/24] Train loss=0.39717844128608704
[15/24] Train loss=0.44490471482276917
[20/24] Train loss=0.3652697503566742
Test set avg_accuracy=67.25% avg_sensitivity=73.92%, avg_specificity=64.87% avg_auc=76.54%
Best model saved!! Metric=-43.41711969671901!!
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.403795 Test loss=0.599835 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.374109148979187
[5/24] Train loss=0.40499573945999146
[10/24] Train loss=0.39230144023895264
[15/24] Train loss=0.4438461661338806
[20/24] Train loss=0.36198511719703674
Test set avg_accuracy=70.60% avg_sensitivity=69.52%, avg_specificity=70.98% avg_auc=76.71%
Best model saved!! Metric=-38.18971692912335!!
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.402058 Test loss=0.572241 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3849611282348633
[5/24] Train loss=0.40932533144950867
[10/24] Train loss=0.3958757519721985
[15/24] Train loss=0.44627663493156433
[20/24] Train loss=0.36221209168434143
Test set avg_accuracy=64.73% avg_sensitivity=73.23%, avg_specificity=61.69% avg_auc=74.06%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.399321 Test loss=0.617096 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.37912681698799133
[5/24] Train loss=0.40332797169685364
[10/24] Train loss=0.40146970748901367
[15/24] Train loss=0.4446272850036621
[20/24] Train loss=0.3655349314212799
Test set avg_accuracy=71.39% avg_sensitivity=67.84%, avg_specificity=72.66% avg_auc=76.95%
Best model saved!! Metric=-37.151283351171514!!
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.404549 Test loss=0.562216 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3777177035808563
[5/24] Train loss=0.40340253710746765
[10/24] Train loss=0.4118208587169647
[15/24] Train loss=0.46058422327041626
[20/24] Train loss=0.36174964904785156
Test set avg_accuracy=70.03% avg_sensitivity=67.29%, avg_specificity=71.00% avg_auc=76.37%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.403583 Test loss=0.569106 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3686976730823517
[5/24] Train loss=0.39887353777885437
[10/24] Train loss=0.3861265480518341
[15/24] Train loss=0.44011709094047546
[20/24] Train loss=0.3585847318172455
Test set avg_accuracy=68.37% avg_sensitivity=72.04%, avg_specificity=67.06% avg_auc=76.73%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.394500 Test loss=0.584559 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3686884641647339
[5/24] Train loss=0.39730843901634216
[10/24] Train loss=0.3844282329082489
[15/24] Train loss=0.43856558203697205
[20/24] Train loss=0.35409045219421387
Test set avg_accuracy=67.53% avg_sensitivity=71.60%, avg_specificity=66.07% avg_auc=76.16%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.393140 Test loss=0.587850 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.35444533824920654
[5/24] Train loss=0.40148279070854187
[10/24] Train loss=0.3965173363685608
[15/24] Train loss=0.432687908411026
[20/24] Train loss=0.3554878234863281
Test set avg_accuracy=65.42% avg_sensitivity=74.52%, avg_specificity=62.17% avg_auc=75.63%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.395844 Test loss=0.608666 Current lr=[0.000299720220882401]

[0/24] Train loss=0.36587005853652954
[5/24] Train loss=0.40224263072013855
[10/24] Train loss=0.38900095224380493
[15/24] Train loss=0.4470927119255066
[20/24] Train loss=0.35498863458633423
Test set avg_accuracy=68.27% avg_sensitivity=68.38%, avg_specificity=68.23% avg_auc=74.94%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.393210 Test loss=0.577823 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.357501745223999
[5/24] Train loss=0.40509429574012756
[10/24] Train loss=0.4034368693828583
[15/24] Train loss=0.47076216340065
[20/24] Train loss=0.358327180147171
Test set avg_accuracy=70.26% avg_sensitivity=72.09%, avg_specificity=69.61% avg_auc=77.93%
Best model saved!! Metric=-36.113316844839446!!
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.400965 Test loss=0.572508 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3702201843261719
[5/24] Train loss=0.39772891998291016
[10/24] Train loss=0.38770729303359985
[15/24] Train loss=0.45458292961120605
[20/24] Train loss=0.35663244128227234
Test set avg_accuracy=74.83% avg_sensitivity=69.92%, avg_specificity=76.59% avg_auc=81.12%
Best model saved!! Metric=-23.544198905679195!!
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.397556 Test loss=0.544375 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3611624538898468
[5/24] Train loss=0.3991478681564331
[10/24] Train loss=0.38291603326797485
[15/24] Train loss=0.4403272867202759
[20/24] Train loss=0.351416677236557
Test set avg_accuracy=62.83% avg_sensitivity=74.72%, avg_specificity=58.58% avg_auc=73.42%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.390072 Test loss=0.632674 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3622221052646637
[5/24] Train loss=0.39439234137535095
[10/24] Train loss=0.3888186514377594
[15/24] Train loss=0.4435498118400574
[20/24] Train loss=0.3587384819984436
Test set avg_accuracy=64.61% avg_sensitivity=73.73%, avg_specificity=61.35% avg_auc=74.35%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.389266 Test loss=0.615272 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.35960879921913147
[5/24] Train loss=0.39384448528289795
[10/24] Train loss=0.3843691647052765
[15/24] Train loss=0.444730281829834
[20/24] Train loss=0.360513836145401
Test set avg_accuracy=64.26% avg_sensitivity=75.21%, avg_specificity=60.35% avg_auc=75.00%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.390280 Test loss=0.621004 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3695327937602997
[5/24] Train loss=0.394324392080307
[10/24] Train loss=0.3844628930091858
[15/24] Train loss=0.44640684127807617
[20/24] Train loss=0.3570137023925781
Test set avg_accuracy=72.47% avg_sensitivity=69.97%, avg_specificity=73.37% avg_auc=79.65%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.389809 Test loss=0.546632 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.35727158188819885
[5/24] Train loss=0.39910271763801575
[10/24] Train loss=0.4076229929924011
[15/24] Train loss=0.4401029050350189
[20/24] Train loss=0.360934853553772
Test set avg_accuracy=72.49% avg_sensitivity=65.71%, avg_specificity=74.91% avg_auc=77.53%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.394526 Test loss=0.548411 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3621259331703186
[5/24] Train loss=0.39211538434028625
[10/24] Train loss=0.39759960770606995
[15/24] Train loss=0.46708983182907104
[20/24] Train loss=0.35883110761642456
Test set avg_accuracy=74.56% avg_sensitivity=66.55%, avg_specificity=77.42% avg_auc=80.15%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.397972 Test loss=0.534363 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3530883193016052
[5/24] Train loss=0.3879448175430298
[10/24] Train loss=0.39714890718460083
[15/24] Train loss=0.42766866087913513
[20/24] Train loss=0.3579639196395874
Test set avg_accuracy=70.99% avg_sensitivity=69.37%, avg_specificity=71.57% avg_auc=77.91%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.387937 Test loss=0.557113 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.35161998867988586
[5/24] Train loss=0.39108964800834656
[10/24] Train loss=0.3925885856151581
[15/24] Train loss=0.43623560667037964
[20/24] Train loss=0.35347434878349304
Test set avg_accuracy=70.16% avg_sensitivity=73.82%, avg_specificity=68.85% avg_auc=79.03%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.386266 Test loss=0.566103 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.34837353229522705
[5/24] Train loss=0.3878447413444519
[10/24] Train loss=0.38275158405303955
[15/24] Train loss=0.43010127544403076
[20/24] Train loss=0.3463592827320099
Test set avg_accuracy=67.55% avg_sensitivity=66.40%, avg_specificity=67.96% avg_auc=74.24%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.384681 Test loss=0.579814 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.35005491971969604
[5/24] Train loss=0.39706435799598694
[10/24] Train loss=0.38917097449302673
[15/24] Train loss=0.43650564551353455
[20/24] Train loss=0.3491393029689789
Test set avg_accuracy=72.38% avg_sensitivity=66.50%, avg_specificity=74.48% avg_auc=78.23%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.388870 Test loss=0.537023 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.35927659273147583
[5/24] Train loss=0.38406574726104736
[10/24] Train loss=0.37848469614982605
[15/24] Train loss=0.42856651544570923
[20/24] Train loss=0.3483920395374298
Test set avg_accuracy=64.44% avg_sensitivity=73.03%, avg_specificity=61.37% avg_auc=74.17%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.380970 Test loss=0.614589 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3574930429458618
[5/24] Train loss=0.37980368733406067
[10/24] Train loss=0.3833755552768707
[15/24] Train loss=0.42436647415161133
[20/24] Train loss=0.3584830164909363
Test set avg_accuracy=68.03% avg_sensitivity=73.03%, avg_specificity=66.25% avg_auc=76.61%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.380304 Test loss=0.582229 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.35673049092292786
[5/24] Train loss=0.38418570160865784
[10/24] Train loss=0.3826005458831787
[15/24] Train loss=0.4264342188835144
[20/24] Train loss=0.34563112258911133
Test set avg_accuracy=69.84% avg_sensitivity=74.02%, avg_specificity=68.35% avg_auc=78.78%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.382959 Test loss=0.566863 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3568371534347534
[5/24] Train loss=0.38387975096702576
[10/24] Train loss=0.3848170340061188
[15/24] Train loss=0.46995171904563904
[20/24] Train loss=0.34746885299682617
Test set avg_accuracy=75.42% avg_sensitivity=66.40%, avg_specificity=78.64% avg_auc=81.06%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.384386 Test loss=0.512459 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3539586663246155
[5/24] Train loss=0.3955399692058563
[10/24] Train loss=0.38432297110557556
[15/24] Train loss=0.43899229168891907
[20/24] Train loss=0.352176696062088
Test set avg_accuracy=69.17% avg_sensitivity=75.90%, avg_specificity=66.76% avg_auc=79.06%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.382744 Test loss=0.573983 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.35129886865615845
[5/24] Train loss=0.3861226737499237
[10/24] Train loss=0.3788801431655884
[15/24] Train loss=0.4321019947528839
[20/24] Train loss=0.34616556763648987
Test set avg_accuracy=70.25% avg_sensitivity=72.29%, avg_specificity=69.52% avg_auc=78.37%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.381473 Test loss=0.558726 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.34910351037979126
[5/24] Train loss=0.3783157467842102
[10/24] Train loss=0.3856023848056793
[15/24] Train loss=0.42734649777412415
[20/24] Train loss=0.34494662284851074
Test set avg_accuracy=68.83% avg_sensitivity=71.80%, avg_specificity=67.77% avg_auc=77.16%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.378155 Test loss=0.571615 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3433437943458557
[5/24] Train loss=0.37338119745254517
[10/24] Train loss=0.37956464290618896
[15/24] Train loss=0.4465510845184326
[20/24] Train loss=0.3585679829120636
Test set avg_accuracy=74.67% avg_sensitivity=68.98%, avg_specificity=76.71% avg_auc=80.94%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.381821 Test loss=0.519826 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3619156777858734
[5/24] Train loss=0.38134533166885376
[10/24] Train loss=0.38311776518821716
[15/24] Train loss=0.4365416467189789
[20/24] Train loss=0.3496949374675751
Test set avg_accuracy=69.67% avg_sensitivity=68.13%, avg_specificity=70.22% avg_auc=75.80%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.384265 Test loss=0.562281 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.35813450813293457
[5/24] Train loss=0.375323623418808
[10/24] Train loss=0.38088253140449524
[15/24] Train loss=0.4230905771255493
[20/24] Train loss=0.3406674861907959
Test set avg_accuracy=71.52% avg_sensitivity=68.33%, avg_specificity=72.66% avg_auc=78.10%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.380894 Test loss=0.546017 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.35493871569633484
[5/24] Train loss=0.3808883726596832
[10/24] Train loss=0.38169512152671814
[15/24] Train loss=0.43108823895454407
[20/24] Train loss=0.34402990341186523
Test set avg_accuracy=68.19% avg_sensitivity=75.31%, avg_specificity=65.65% avg_auc=78.59%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.380070 Test loss=0.579916 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.35760077834129333
[5/24] Train loss=0.388035386800766
[10/24] Train loss=0.379787802696228
[15/24] Train loss=0.4201739430427551
[20/24] Train loss=0.34888458251953125
Test set avg_accuracy=70.40% avg_sensitivity=75.21%, avg_specificity=68.69% avg_auc=79.94%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.379670 Test loss=0.561404 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3419916331768036
[5/24] Train loss=0.37625405192375183
[10/24] Train loss=0.3851161599159241
[15/24] Train loss=0.4269407391548157
[20/24] Train loss=0.35505107045173645
Test set avg_accuracy=73.72% avg_sensitivity=71.50%, avg_specificity=74.52% avg_auc=80.68%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.383297 Test loss=0.540857 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3733215034008026
[5/24] Train loss=0.3853376507759094
[10/24] Train loss=0.3785582482814789
[15/24] Train loss=0.4248974025249481
[20/24] Train loss=0.3483189642429352
Test set avg_accuracy=70.18% avg_sensitivity=72.59%, avg_specificity=69.32% avg_auc=78.51%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.379816 Test loss=0.554621 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.34723010659217834
[5/24] Train loss=0.3716435134410858
[10/24] Train loss=0.3777207136154175
[15/24] Train loss=0.41969048976898193
[20/24] Train loss=0.3470604717731476
Test set avg_accuracy=69.83% avg_sensitivity=73.87%, avg_specificity=68.39% avg_auc=78.70%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.377310 Test loss=0.565689 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.35539907217025757
[5/24] Train loss=0.38597604632377625
[10/24] Train loss=0.38625890016555786
[15/24] Train loss=0.42572614550590515
[20/24] Train loss=0.3401629626750946
Test set avg_accuracy=74.23% avg_sensitivity=70.51%, avg_specificity=75.56% avg_auc=81.08%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.377483 Test loss=0.520334 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.347576767206192
[5/24] Train loss=0.36963269114494324
[10/24] Train loss=0.37854698300361633
[15/24] Train loss=0.42214784026145935
[20/24] Train loss=0.3381122052669525
Test set avg_accuracy=70.34% avg_sensitivity=72.44%, avg_specificity=69.59% avg_auc=78.92%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.374338 Test loss=0.553639 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3430235981941223
[5/24] Train loss=0.3758182227611542
[10/24] Train loss=0.38852229714393616
[15/24] Train loss=0.4311264157295227
[20/24] Train loss=0.35131368041038513
Test set avg_accuracy=72.62% avg_sensitivity=71.15%, avg_specificity=73.14% avg_auc=80.51%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.377697 Test loss=0.534679 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.35165858268737793
[5/24] Train loss=0.38406607508659363
[10/24] Train loss=0.3795071542263031
[15/24] Train loss=0.4218154847621918
[20/24] Train loss=0.3449942469596863
Test set avg_accuracy=76.13% avg_sensitivity=66.55%, avg_specificity=79.55% avg_auc=81.96%
Best model saved!! Metric=-21.79863201889198!!
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.381571 Test loss=0.501067 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.34474948048591614
[5/24] Train loss=0.37136346101760864
[10/24] Train loss=0.3778989613056183
[15/24] Train loss=0.4441083073616028
[20/24] Train loss=0.35219359397888184
Test set avg_accuracy=76.59% avg_sensitivity=68.58%, avg_specificity=79.45% avg_auc=82.39%
Best model saved!! Metric=-18.996454677165772!!
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.381018 Test loss=0.507546 Current lr=[0.000224838296036774]

[0/24] Train loss=0.35479575395584106
[5/24] Train loss=0.37350142002105713
[10/24] Train loss=0.3829580843448639
[15/24] Train loss=0.4205552935600281
[20/24] Train loss=0.34161725640296936
Test set avg_accuracy=69.75% avg_sensitivity=75.36%, avg_specificity=67.75% avg_auc=79.81%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.375588 Test loss=0.561930 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3419428765773773
[5/24] Train loss=0.37019574642181396
[10/24] Train loss=0.3726499080657959
[15/24] Train loss=0.4149707555770874
[20/24] Train loss=0.3365178108215332
Test set avg_accuracy=71.37% avg_sensitivity=73.82%, avg_specificity=70.49% avg_auc=80.24%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.370791 Test loss=0.541798 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3480137884616852
[5/24] Train loss=0.3714004158973694
[10/24] Train loss=0.3819383680820465
[15/24] Train loss=0.42950257658958435
[20/24] Train loss=0.3386906385421753
Test set avg_accuracy=72.72% avg_sensitivity=72.59%, avg_specificity=72.77% avg_auc=80.98%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.372293 Test loss=0.529233 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3436095416545868
[5/24] Train loss=0.37119558453559875
[10/24] Train loss=0.38141918182373047
[15/24] Train loss=0.43761980533599854
[20/24] Train loss=0.3400784432888031
Test set avg_accuracy=70.68% avg_sensitivity=68.04%, avg_specificity=71.62% avg_auc=77.18%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.374546 Test loss=0.544900 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3445444703102112
[5/24] Train loss=0.36897560954093933
[10/24] Train loss=0.37416747212409973
[15/24] Train loss=0.4203898310661316
[20/24] Train loss=0.3402706980705261
Test set avg_accuracy=67.53% avg_sensitivity=75.95%, avg_specificity=64.52% avg_auc=78.27%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.369781 Test loss=0.581465 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.335920512676239
[5/24] Train loss=0.3722379803657532
[10/24] Train loss=0.3821544349193573
[15/24] Train loss=0.4267527163028717
[20/24] Train loss=0.33942630887031555
Test set avg_accuracy=68.80% avg_sensitivity=74.96%, avg_specificity=66.60% avg_auc=78.48%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.371669 Test loss=0.566977 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.33750441670417786
[5/24] Train loss=0.3627431392669678
[10/24] Train loss=0.37103044986724854
[15/24] Train loss=0.4053981900215149
[20/24] Train loss=0.3403208553791046
Test set avg_accuracy=68.55% avg_sensitivity=74.81%, avg_specificity=66.32% avg_auc=78.09%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.367325 Test loss=0.569694 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.34839290380477905
[5/24] Train loss=0.36677414178848267
[10/24] Train loss=0.3756132423877716
[15/24] Train loss=0.4122920632362366
[20/24] Train loss=0.334585040807724
Test set avg_accuracy=67.84% avg_sensitivity=76.40%, avg_specificity=64.78% avg_auc=78.84%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.367494 Test loss=0.577771 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3352522850036621
[5/24] Train loss=0.3609687387943268
[10/24] Train loss=0.36838260293006897
[15/24] Train loss=0.40766441822052
[20/24] Train loss=0.334769606590271
Test set avg_accuracy=69.91% avg_sensitivity=75.31%, avg_specificity=67.98% avg_auc=80.01%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.365939 Test loss=0.552636 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3302417993545532
[5/24] Train loss=0.3596750497817993
[10/24] Train loss=0.3716442883014679
[15/24] Train loss=0.4043668210506439
[20/24] Train loss=0.3339960277080536
Test set avg_accuracy=69.95% avg_sensitivity=75.21%, avg_specificity=68.07% avg_auc=79.81%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.362529 Test loss=0.552145 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3344370424747467
[5/24] Train loss=0.3598981499671936
[10/24] Train loss=0.37221232056617737
[15/24] Train loss=0.4055851697921753
[20/24] Train loss=0.34173136949539185
Test set avg_accuracy=68.70% avg_sensitivity=75.16%, avg_specificity=66.39% avg_auc=78.44%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.366234 Test loss=0.570017 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3493037819862366
[5/24] Train loss=0.37057924270629883
[10/24] Train loss=0.3748619854450226
[15/24] Train loss=0.4129991829395294
[20/24] Train loss=0.3360934853553772
Test set avg_accuracy=70.73% avg_sensitivity=74.96%, avg_specificity=69.22% avg_auc=80.55%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.370030 Test loss=0.550325 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3339787423610687
[5/24] Train loss=0.36295974254608154
[10/24] Train loss=0.3740282952785492
[15/24] Train loss=0.41183093190193176
[20/24] Train loss=0.3328147530555725
Test set avg_accuracy=68.07% avg_sensitivity=75.06%, avg_specificity=65.58% avg_auc=78.46%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.366440 Test loss=0.572504 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3292134702205658
[5/24] Train loss=0.35956791043281555
[10/24] Train loss=0.3727833926677704
[15/24] Train loss=0.39864790439605713
[20/24] Train loss=0.3278883099555969
Test set avg_accuracy=66.37% avg_sensitivity=75.46%, avg_specificity=63.12% avg_auc=77.14%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.362120 Test loss=0.592492 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3291371464729309
[5/24] Train loss=0.36054468154907227
[10/24] Train loss=0.3689505159854889
[15/24] Train loss=0.39733225107192993
[20/24] Train loss=0.3294494152069092
Test set avg_accuracy=68.58% avg_sensitivity=74.96%, avg_specificity=66.30% avg_auc=78.31%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.361377 Test loss=0.569416 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3276904821395874
[5/24] Train loss=0.35289210081100464
[10/24] Train loss=0.36752137541770935
[15/24] Train loss=0.39760640263557434
[20/24] Train loss=0.3299260437488556
Test set avg_accuracy=69.05% avg_sensitivity=75.41%, avg_specificity=66.78% avg_auc=79.11%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.359765 Test loss=0.562954 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3308347463607788
[5/24] Train loss=0.3516121506690979
[10/24] Train loss=0.3704688549041748
[15/24] Train loss=0.4024750888347626
[20/24] Train loss=0.3307161331176758
Test set avg_accuracy=68.66% avg_sensitivity=78.13%, avg_specificity=65.28% avg_auc=79.83%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.362432 Test loss=0.570456 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.32493749260902405
[5/24] Train loss=0.3561040759086609
[10/24] Train loss=0.3755302429199219
[15/24] Train loss=0.40616342425346375
[20/24] Train loss=0.3303435742855072
Test set avg_accuracy=68.39% avg_sensitivity=75.61%, avg_specificity=65.81% avg_auc=78.58%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.363559 Test loss=0.572746 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3398224711418152
[5/24] Train loss=0.3738000988960266
[10/24] Train loss=0.38555973768234253
[15/24] Train loss=0.40897053480148315
[20/24] Train loss=0.3325863778591156
Test set avg_accuracy=68.44% avg_sensitivity=78.13%, avg_specificity=64.98% avg_auc=79.92%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.372629 Test loss=0.576546 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3599824905395508
[5/24] Train loss=0.37208572030067444
[10/24] Train loss=0.3807828426361084
[15/24] Train loss=0.41272419691085815
[20/24] Train loss=0.3364408016204834
Test set avg_accuracy=73.71% avg_sensitivity=69.27%, avg_specificity=75.30% avg_auc=80.00%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.370870 Test loss=0.516120 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3384854793548584
[5/24] Train loss=0.37171658873558044
[10/24] Train loss=0.38211458921432495
[15/24] Train loss=0.41604089736938477
[20/24] Train loss=0.33595341444015503
Test set avg_accuracy=70.44% avg_sensitivity=73.23%, avg_specificity=69.45% avg_auc=79.00%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.370628 Test loss=0.549788 Current lr=[0.000134135431043539]

[0/24] Train loss=0.34269875288009644
[5/24] Train loss=0.3726690411567688
[10/24] Train loss=0.3791324496269226
[15/24] Train loss=0.43592607975006104
[20/24] Train loss=0.3521232008934021
Test set avg_accuracy=75.22% avg_sensitivity=70.95%, avg_specificity=76.75% avg_auc=82.63%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.370504 Test loss=0.507976 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.33644208312034607
[5/24] Train loss=0.3575725853443146
[10/24] Train loss=0.37877732515335083
[15/24] Train loss=0.4236712157726288
[20/24] Train loss=0.3382144570350647
Test set avg_accuracy=72.07% avg_sensitivity=71.99%, avg_specificity=72.10% avg_auc=80.19%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.365349 Test loss=0.532163 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3363686203956604
[5/24] Train loss=0.3633393943309784
[10/24] Train loss=0.3727574944496155
[15/24] Train loss=0.4143608808517456
[20/24] Train loss=0.33646976947784424
Test set avg_accuracy=71.64% avg_sensitivity=76.30%, avg_specificity=69.98% avg_auc=81.84%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.363446 Test loss=0.534723 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.3346736431121826
[5/24] Train loss=0.3567880690097809
[10/24] Train loss=0.37213805317878723
[15/24] Train loss=0.4103979468345642
[20/24] Train loss=0.3310096859931946
Test set avg_accuracy=71.00% avg_sensitivity=75.56%, avg_specificity=69.38% avg_auc=80.72%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.360639 Test loss=0.539840 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3277304768562317
[5/24] Train loss=0.35847175121307373
[10/24] Train loss=0.3742465674877167
[15/24] Train loss=0.40633589029312134
[20/24] Train loss=0.3324180245399475
Test set avg_accuracy=67.73% avg_sensitivity=73.97%, avg_specificity=65.51% avg_auc=77.70%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.359775 Test loss=0.573534 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3282445967197418
[5/24] Train loss=0.35361209511756897
[10/24] Train loss=0.37541016936302185
[15/24] Train loss=0.4023318290710449
[20/24] Train loss=0.3355826139450073
Test set avg_accuracy=67.89% avg_sensitivity=73.68%, avg_specificity=65.82% avg_auc=77.69%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.362265 Test loss=0.574270 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.34332260489463806
[5/24] Train loss=0.363597571849823
[10/24] Train loss=0.37510180473327637
[15/24] Train loss=0.42692944407463074
[20/24] Train loss=0.33200588822364807
Test set avg_accuracy=70.40% avg_sensitivity=75.31%, avg_specificity=68.65% avg_auc=80.39%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.366254 Test loss=0.548438 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.32936543226242065
[5/24] Train loss=0.35809075832366943
[10/24] Train loss=0.36983904242515564
[15/24] Train loss=0.3986271619796753
[20/24] Train loss=0.3303622007369995
Test set avg_accuracy=68.84% avg_sensitivity=73.97%, avg_specificity=67.01% avg_auc=78.32%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.357472 Test loss=0.564830 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.32217422127723694
[5/24] Train loss=0.3523919880390167
[10/24] Train loss=0.368547260761261
[15/24] Train loss=0.39525824785232544
[20/24] Train loss=0.3305602967739105
Test set avg_accuracy=69.40% avg_sensitivity=73.63%, avg_specificity=67.89% avg_auc=78.53%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.356256 Test loss=0.558016 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3194376826286316
[5/24] Train loss=0.3555331528186798
[10/24] Train loss=0.3698638379573822
[15/24] Train loss=0.393410325050354
[20/24] Train loss=0.3335705101490021
Test set avg_accuracy=69.17% avg_sensitivity=75.01%, avg_specificity=67.08% avg_auc=78.95%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.355449 Test loss=0.561617 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.32801133394241333
[5/24] Train loss=0.34903350472450256
[10/24] Train loss=0.3687290847301483
[15/24] Train loss=0.391394704580307
[20/24] Train loss=0.33224087953567505
Test set avg_accuracy=67.84% avg_sensitivity=75.06%, avg_specificity=65.26% avg_auc=78.28%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.355859 Test loss=0.575994 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3217555582523346
[5/24] Train loss=0.35200825333595276
[10/24] Train loss=0.3694298267364502
[15/24] Train loss=0.3917218744754791
[20/24] Train loss=0.33328813314437866
Test set avg_accuracy=69.05% avg_sensitivity=76.20%, avg_specificity=66.50% avg_auc=79.46%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.355220 Test loss=0.562799 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3283313810825348
[5/24] Train loss=0.34704720973968506
[10/24] Train loss=0.3728589713573456
[15/24] Train loss=0.3944779932498932
[20/24] Train loss=0.3322637677192688
Test set avg_accuracy=67.23% avg_sensitivity=75.31%, avg_specificity=64.34% avg_auc=78.02%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.355709 Test loss=0.585283 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3278777003288269
[5/24] Train loss=0.3481200039386749
[10/24] Train loss=0.369815856218338
[15/24] Train loss=0.39283084869384766
[20/24] Train loss=0.32705390453338623
Test set avg_accuracy=67.54% avg_sensitivity=77.09%, avg_specificity=64.13% avg_auc=78.70%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.353829 Test loss=0.582856 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.32714253664016724
[5/24] Train loss=0.3458210229873657
[10/24] Train loss=0.36646467447280884
[15/24] Train loss=0.39788809418678284
[20/24] Train loss=0.32773441076278687
Test set avg_accuracy=67.17% avg_sensitivity=78.77%, avg_specificity=63.03% avg_auc=79.25%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.354535 Test loss=0.584882 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.32883933186531067
[5/24] Train loss=0.34685763716697693
[10/24] Train loss=0.3657703995704651
[15/24] Train loss=0.39489826560020447
[20/24] Train loss=0.3260226845741272
Test set avg_accuracy=67.59% avg_sensitivity=77.93%, avg_specificity=63.90% avg_auc=78.99%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.353750 Test loss=0.582914 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3277495503425598
[5/24] Train loss=0.35013511776924133
[10/24] Train loss=0.36712875962257385
[15/24] Train loss=0.40808871388435364
[20/24] Train loss=0.32621803879737854
Test set avg_accuracy=67.98% avg_sensitivity=77.78%, avg_specificity=64.48% avg_auc=79.43%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.354364 Test loss=0.575317 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.32386478781700134
[5/24] Train loss=0.3523663878440857
[10/24] Train loss=0.36513590812683105
[15/24] Train loss=0.3944520950317383
[20/24] Train loss=0.327129989862442
Test set avg_accuracy=67.73% avg_sensitivity=76.74%, avg_specificity=64.52% avg_auc=78.72%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.352811 Test loss=0.577845 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.32133474946022034
[5/24] Train loss=0.34821441769599915
[10/24] Train loss=0.3643244504928589
[15/24] Train loss=0.3891412317752838
[20/24] Train loss=0.3263597786426544
Test set avg_accuracy=67.59% avg_sensitivity=77.04%, avg_specificity=64.22% avg_auc=78.85%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.350489 Test loss=0.579918 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.31954702734947205
[5/24] Train loss=0.3423292934894562
[10/24] Train loss=0.36504054069519043
[15/24] Train loss=0.38856813311576843
[20/24] Train loss=0.32598960399627686
Test set avg_accuracy=67.68% avg_sensitivity=78.03%, avg_specificity=63.99% avg_auc=79.09%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.348929 Test loss=0.580273 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.31987595558166504
[5/24] Train loss=0.3425615131855011
[10/24] Train loss=0.362712562084198
[15/24] Train loss=0.3860650658607483
[20/24] Train loss=0.3272705376148224
Test set avg_accuracy=67.67% avg_sensitivity=77.04%, avg_specificity=64.32% avg_auc=78.82%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.348670 Test loss=0.579902 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3178972899913788
[5/24] Train loss=0.3427903652191162
[10/24] Train loss=0.3639379143714905
[15/24] Train loss=0.385763943195343
[20/24] Train loss=0.3262568414211273
Test set avg_accuracy=67.49% avg_sensitivity=76.10%, avg_specificity=64.41% avg_auc=78.49%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.348221 Test loss=0.580713 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3169916272163391
[5/24] Train loss=0.34125423431396484
[10/24] Train loss=0.36286744475364685
[15/24] Train loss=0.3850461542606354
[20/24] Train loss=0.32507675886154175
Test set avg_accuracy=67.30% avg_sensitivity=75.80%, avg_specificity=64.27% avg_auc=78.12%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.347497 Test loss=0.584414 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3160431385040283
[5/24] Train loss=0.340705931186676
[10/24] Train loss=0.3627239167690277
[15/24] Train loss=0.3848777413368225
[20/24] Train loss=0.32288336753845215
Test set avg_accuracy=67.16% avg_sensitivity=76.45%, avg_specificity=63.85% avg_auc=78.34%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.346682 Test loss=0.586286 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3162741959095001
[5/24] Train loss=0.3399847745895386
[10/24] Train loss=0.36187320947647095
[15/24] Train loss=0.38416293263435364
[20/24] Train loss=0.3235431909561157
Test set avg_accuracy=67.43% avg_sensitivity=76.40%, avg_specificity=64.23% avg_auc=78.50%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.346764 Test loss=0.582643 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3154906630516052
[5/24] Train loss=0.34028494358062744
[10/24] Train loss=0.3622320890426636
[15/24] Train loss=0.38570693135261536
[20/24] Train loss=0.3231790065765381
Test set avg_accuracy=66.94% avg_sensitivity=75.56%, avg_specificity=63.86% avg_auc=77.93%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.346773 Test loss=0.588404 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.31559649109840393
[5/24] Train loss=0.3393838405609131
[10/24] Train loss=0.36238422989845276
[15/24] Train loss=0.38488245010375977
[20/24] Train loss=0.3222588002681732
Test set avg_accuracy=67.07% avg_sensitivity=76.69%, avg_specificity=63.63% avg_auc=78.18%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.346435 Test loss=0.589570 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3156791031360626
[5/24] Train loss=0.34029942750930786
[10/24] Train loss=0.3626697063446045
[15/24] Train loss=0.38357290625572205
[20/24] Train loss=0.3217480778694153
Test set avg_accuracy=66.69% avg_sensitivity=75.61%, avg_specificity=63.51% avg_auc=77.58%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.346175 Test loss=0.592876 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3149554133415222
[5/24] Train loss=0.3392145335674286
[10/24] Train loss=0.36182087659835815
[15/24] Train loss=0.3833220899105072
[20/24] Train loss=0.3210025429725647
Test set avg_accuracy=66.45% avg_sensitivity=77.34%, avg_specificity=62.56% avg_auc=78.13%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.346143 Test loss=0.595447 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3148425817489624
[5/24] Train loss=0.3379982113838196
[10/24] Train loss=0.3619898557662964
[15/24] Train loss=0.3820013105869293
[20/24] Train loss=0.3212089240550995
Test set avg_accuracy=66.59% avg_sensitivity=76.94%, avg_specificity=62.89% avg_auc=77.96%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.345108 Test loss=0.595056 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3151370584964752
[5/24] Train loss=0.33637112379074097
[10/24] Train loss=0.36154183745384216
[15/24] Train loss=0.3825145959854126
[20/24] Train loss=0.3212178349494934
Test set avg_accuracy=66.91% avg_sensitivity=76.94%, avg_specificity=63.33% avg_auc=78.29%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.344663 Test loss=0.589817 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3147156834602356
[5/24] Train loss=0.3355419337749481
[10/24] Train loss=0.3618791997432709
[15/24] Train loss=0.38280120491981506
[20/24] Train loss=0.3210899829864502
Test set avg_accuracy=66.93% avg_sensitivity=77.09%, avg_specificity=63.30% avg_auc=78.39%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.344362 Test loss=0.588849 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.31357085704803467
[5/24] Train loss=0.33468249440193176
[10/24] Train loss=0.36159569025039673
[15/24] Train loss=0.3832322359085083
[20/24] Train loss=0.3210983872413635
Test set avg_accuracy=67.08% avg_sensitivity=77.29%, avg_specificity=63.44% avg_auc=78.54%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.343964 Test loss=0.586778 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3124769330024719
[5/24] Train loss=0.3350730538368225
[10/24] Train loss=0.3610352873802185
[15/24] Train loss=0.3818613290786743
[20/24] Train loss=0.3207167983055115
Test set avg_accuracy=66.80% avg_sensitivity=77.78%, avg_specificity=62.87% avg_auc=78.52%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.343535 Test loss=0.589733 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.31282371282577515
[5/24] Train loss=0.3342965245246887
[10/24] Train loss=0.36082544922828674
[15/24] Train loss=0.3806622326374054
[20/24] Train loss=0.3206394612789154
Test set avg_accuracy=66.86% avg_sensitivity=77.49%, avg_specificity=63.07% avg_auc=78.50%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.343199 Test loss=0.588709 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3121446371078491
[5/24] Train loss=0.3336787819862366
[10/24] Train loss=0.3606133460998535
[15/24] Train loss=0.38053905963897705
[20/24] Train loss=0.3200945258140564
Test set avg_accuracy=66.78% avg_sensitivity=77.14%, avg_specificity=63.09% avg_auc=78.34%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.342728 Test loss=0.590334 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.31174781918525696
[5/24] Train loss=0.33314770460128784
[10/24] Train loss=0.360095351934433
[15/24] Train loss=0.380258172750473
[20/24] Train loss=0.3196887671947479
Test set avg_accuracy=66.72% avg_sensitivity=77.29%, avg_specificity=62.94% avg_auc=78.32%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.342438 Test loss=0.591603 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3116547465324402
[5/24] Train loss=0.3332273066043854
[10/24] Train loss=0.35984891653060913
[15/24] Train loss=0.38008713722229004
[20/24] Train loss=0.3196488320827484
Test set avg_accuracy=66.72% avg_sensitivity=77.39%, avg_specificity=62.91% avg_auc=78.33%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.342270 Test loss=0.591721 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3114074170589447
[5/24] Train loss=0.33305037021636963
[10/24] Train loss=0.35977500677108765
[15/24] Train loss=0.38011473417282104
[20/24] Train loss=0.31959453225135803
Test set avg_accuracy=66.73% avg_sensitivity=77.54%, avg_specificity=62.87% avg_auc=78.30%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.342155 Test loss=0.592466 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3113325238227844
[5/24] Train loss=0.3328345715999603
[10/24] Train loss=0.35970938205718994
[15/24] Train loss=0.38003700971603394
[20/24] Train loss=0.3193703591823578
Test set avg_accuracy=66.73% avg_sensitivity=77.59%, avg_specificity=62.86% avg_auc=78.26%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.342018 Test loss=0.593163 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.31128865480422974
[5/24] Train loss=0.3326910138130188
[10/24] Train loss=0.35952863097190857
[15/24] Train loss=0.3799559473991394
[20/24] Train loss=0.31929829716682434
Test set avg_accuracy=66.71% avg_sensitivity=77.54%, avg_specificity=62.84% avg_auc=78.26%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.341925 Test loss=0.593352 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3112151622772217
[5/24] Train loss=0.33263424038887024
[10/24] Train loss=0.35950517654418945
[15/24] Train loss=0.3799254298210144
[20/24] Train loss=0.31921452283859253
Test set avg_accuracy=66.68% avg_sensitivity=77.54%, avg_specificity=62.80% avg_auc=78.24%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.341856 Test loss=0.593748 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3111756145954132
[5/24] Train loss=0.33253106474876404
[10/24] Train loss=0.3594287931919098
[15/24] Train loss=0.3798786401748657
[20/24] Train loss=0.31916627287864685
Test set avg_accuracy=66.65% avg_sensitivity=77.54%, avg_specificity=62.77% avg_auc=78.23%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.341796 Test loss=0.593951 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3111393451690674
[5/24] Train loss=0.332466721534729
[10/24] Train loss=0.3593977093696594
[15/24] Train loss=0.3798427879810333
[20/24] Train loss=0.3191166818141937
Test set avg_accuracy=66.61% avg_sensitivity=77.49%, avg_specificity=62.73% avg_auc=78.22%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.341753 Test loss=0.594120 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3111140727996826
[5/24] Train loss=0.3324168622493744
[10/24] Train loss=0.3593708872795105
[15/24] Train loss=0.379812091588974
[20/24] Train loss=0.31908124685287476
Test set avg_accuracy=66.61% avg_sensitivity=77.49%, avg_specificity=62.73% avg_auc=78.21%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.341720 Test loss=0.594230 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3110972046852112
[5/24] Train loss=0.3323822319507599
[10/24] Train loss=0.35935360193252563
[15/24] Train loss=0.379790335893631
[20/24] Train loss=0.31905728578567505
Test set avg_accuracy=66.59% avg_sensitivity=77.49%, avg_specificity=62.70% avg_auc=78.20%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.341697 Test loss=0.594320 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3110860586166382
[5/24] Train loss=0.3323601484298706
[10/24] Train loss=0.3593413531780243
[15/24] Train loss=0.37977442145347595
[20/24] Train loss=0.3190416395664215
Test set avg_accuracy=66.59% avg_sensitivity=77.49%, avg_specificity=62.70% avg_auc=78.20%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.341682 Test loss=0.594382 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3110785186290741
[5/24] Train loss=0.3323475122451782
[10/24] Train loss=0.35933366417884827
[15/24] Train loss=0.3797643780708313
[20/24] Train loss=0.31903356313705444
Test set avg_accuracy=66.59% avg_sensitivity=77.49%, avg_specificity=62.70% avg_auc=78.20%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.341674 Test loss=0.594415 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.311075359582901
[5/24] Train loss=0.33234110474586487
[10/24] Train loss=0.35933026671409607
[15/24] Train loss=0.37975969910621643
[20/24] Train loss=0.3190305829048157
Test set avg_accuracy=66.59% avg_sensitivity=77.49%, avg_specificity=62.70% avg_auc=78.19%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.341671 Test loss=0.594427 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=76.59% sen=68.58%, spe=79.45%, auc=82.39%!
Fold[1] Avg_overlap=0.60%(±0.2743061851317896)
[0/24] Train loss=0.6985064148902893
[5/24] Train loss=0.6969960927963257
[10/24] Train loss=0.696628749370575
[15/24] Train loss=0.6956082582473755
[20/24] Train loss=0.6952837705612183
Test set avg_accuracy=49.64% avg_sensitivity=51.43%, avg_specificity=49.04% avg_auc=50.91%
Best model saved!! Metric=-124.98191634406476!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.696218 Test loss=0.694882 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6938815116882324
[5/24] Train loss=0.6937339901924133
[10/24] Train loss=0.6928922533988953
[15/24] Train loss=0.6919212937355042
[20/24] Train loss=0.6913524866104126
Test set avg_accuracy=55.46% avg_sensitivity=41.84%, avg_specificity=59.99% avg_auc=51.07%
Best model saved!! Metric=-117.65566652931304!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.692496 Test loss=0.691035 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6898983120918274
[5/24] Train loss=0.690731406211853
[10/24] Train loss=0.6895709037780762
[15/24] Train loss=0.6886385679244995
[20/24] Train loss=0.6879494190216064
Test set avg_accuracy=55.44% avg_sensitivity=41.00%, avg_specificity=60.25% avg_auc=51.16%
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.689185 Test loss=0.687739 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6865187883377075
[5/24] Train loss=0.6880147457122803
[10/24] Train loss=0.6864370107650757
[15/24] Train loss=0.6854808926582336
[20/24] Train loss=0.684430718421936
Test set avg_accuracy=55.51% avg_sensitivity=40.32%, avg_specificity=60.56% avg_auc=51.21%
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.686039 Test loss=0.684340 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6828771233558655
[5/24] Train loss=0.6851369738578796
[10/24] Train loss=0.6829419136047363
[15/24] Train loss=0.6819633841514587
[20/24] Train loss=0.6805261373519897
Test set avg_accuracy=58.74% avg_sensitivity=34.64%, avg_specificity=66.75% avg_auc=51.13%
Best model saved!! Metric=-114.7426389356465!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.682602 Test loss=0.680638 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6790640354156494
[5/24] Train loss=0.6819967031478882
[10/24] Train loss=0.6793042421340942
[15/24] Train loss=0.6780978441238403
[20/24] Train loss=0.6762456893920898
Test set avg_accuracy=63.74% avg_sensitivity=26.60%, avg_specificity=76.09% avg_auc=51.37%
Best model saved!! Metric=-108.20213777481358!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.678907 Test loss=0.676486 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6748844385147095
[5/24] Train loss=0.6783354878425598
[10/24] Train loss=0.674932062625885
[15/24] Train loss=0.673313558101654
[20/24] Train loss=0.6708273887634277
Test set avg_accuracy=64.87% avg_sensitivity=21.96%, avg_specificity=79.14% avg_auc=51.61%
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.674402 Test loss=0.671085 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6693148016929626
[5/24] Train loss=0.6736403703689575
[10/24] Train loss=0.6690351366996765
[15/24] Train loss=0.6667640805244446
[20/24] Train loss=0.6632194519042969
Test set avg_accuracy=68.23% avg_sensitivity=15.49%, avg_specificity=85.77% avg_auc=51.55%
Best model saved!! Metric=-104.95343408239621!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.668307 Test loss=0.663469 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6613680124282837
[5/24] Train loss=0.6668210625648499
[10/24] Train loss=0.6603400111198425
[15/24] Train loss=0.6570087671279907
[20/24] Train loss=0.651639997959137
Test set avg_accuracy=68.44% avg_sensitivity=14.24%, avg_specificity=86.47% avg_auc=51.70%
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.659311 Test loss=0.651978 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6491914987564087
[5/24] Train loss=0.656612753868103
[10/24] Train loss=0.6468906998634338
[15/24] Train loss=0.6417341828346252
[20/24] Train loss=0.6329740285873413
Test set avg_accuracy=71.69% avg_sensitivity=7.36%, avg_specificity=93.09% avg_auc=51.84%
Best model saved!! Metric=-102.0189043676604!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.645369 Test loss=0.633854 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.629743754863739
[5/24] Train loss=0.6407220959663391
[10/24] Train loss=0.6253964900970459
[15/24] Train loss=0.6176062822341919
[20/24] Train loss=0.6034203171730042
Test set avg_accuracy=71.77% avg_sensitivity=6.99%, avg_specificity=93.32% avg_auc=51.98%
Best model saved!! Metric=-101.94052139473561!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.623284 Test loss=0.605996 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5993166565895081
[5/24] Train loss=0.6182643175125122
[10/24] Train loss=0.5952485203742981
[15/24] Train loss=0.5856614708900452
[20/24] Train loss=0.5698447227478027
Test set avg_accuracy=75.03% avg_sensitivity=0.10%, avg_specificity=99.95% avg_auc=52.49%
Best model saved!! Metric=-98.43485755815638!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.594626 Test loss=0.576917 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5689569115638733
[5/24] Train loss=0.6013572812080383
[10/24] Train loss=0.5745266079902649
[15/24] Train loss=0.5669128894805908
[20/24] Train loss=0.5531303882598877
Test set avg_accuracy=75.03% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=54.65%
Best model saved!! Metric=-96.34508678203531!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.575750 Test loss=0.564400 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5560136437416077
[5/24] Train loss=0.59391850233078
[10/24] Train loss=0.5663372278213501
[15/24] Train loss=0.5597493648529053
[20/24] Train loss=0.5449061989784241
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=56.25%
Best model saved!! Metric=-94.70804039616698!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.567875 Test loss=0.559577 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5497770309448242
[5/24] Train loss=0.5910516381263733
[10/24] Train loss=0.5613909959793091
[15/24] Train loss=0.5559539794921875
[20/24] Train loss=0.5392921566963196
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=59.31%
Best model saved!! Metric=-91.65200261227571!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.564241 Test loss=0.557806 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5459141135215759
[5/24] Train loss=0.5886706113815308
[10/24] Train loss=0.5586966276168823
[15/24] Train loss=0.5517374277114868
[20/24] Train loss=0.5332455039024353
Test set avg_accuracy=75.04% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=61.77%
Best model saved!! Metric=-89.18864178264926!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.560295 Test loss=0.554710 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5400492548942566
[5/24] Train loss=0.5840485692024231
[10/24] Train loss=0.5533652305603027
[15/24] Train loss=0.5451146960258484
[20/24] Train loss=0.5255878567695618
Test set avg_accuracy=75.08% avg_sensitivity=0.42%, avg_specificity=99.91% avg_auc=66.81%
Best model saved!! Metric=-83.78581075623315!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.554097 Test loss=0.548818 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5282004475593567
[5/24] Train loss=0.5765795707702637
[10/24] Train loss=0.5436588525772095
[15/24] Train loss=0.5351495742797852
[20/24] Train loss=0.5106551647186279
Test set avg_accuracy=75.18% avg_sensitivity=5.22%, avg_specificity=98.46% avg_auc=69.63%
Best model saved!! Metric=-77.51626769484946!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.543268 Test loss=0.555139 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5061986446380615
[5/24] Train loss=0.5629125237464905
[10/24] Train loss=0.5219419598579407
[15/24] Train loss=0.5207883715629578
[20/24] Train loss=0.5003489255905151
Test set avg_accuracy=73.50% avg_sensitivity=28.12%, avg_specificity=88.60% avg_auc=63.53%
Best model saved!! Metric=-72.25075380353358!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.528576 Test loss=0.628766 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.48028838634490967
[5/24] Train loss=0.5531604886054993
[10/24] Train loss=0.5022282600402832
[15/24] Train loss=0.4987293779850006
[20/24] Train loss=0.4867667853832245
Test set avg_accuracy=64.11% avg_sensitivity=37.04%, avg_specificity=73.12% avg_auc=56.40%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.513461 Test loss=0.656411 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.45930948853492737
[5/24] Train loss=0.5362772941589355
[10/24] Train loss=0.49100664258003235
[15/24] Train loss=0.4808588922023773
[20/24] Train loss=0.47000446915626526
Test set avg_accuracy=60.30% avg_sensitivity=40.22%, avg_specificity=66.98% avg_auc=55.46%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.500726 Test loss=0.656610 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.4795057475566864
[5/24] Train loss=0.5246284604072571
[10/24] Train loss=0.48192864656448364
[15/24] Train loss=0.4791567027568817
[20/24] Train loss=0.47343555092811584
Test set avg_accuracy=65.83% avg_sensitivity=38.86%, avg_specificity=74.80% avg_auc=58.16%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.496674 Test loss=0.644159 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.44225844740867615
[5/24] Train loss=0.5191853046417236
[10/24] Train loss=0.4758290946483612
[15/24] Train loss=0.46561911702156067
[20/24] Train loss=0.465287983417511
Test set avg_accuracy=55.79% avg_sensitivity=51.49%, avg_specificity=57.23% avg_auc=57.20%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.487536 Test loss=0.662722 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4394706189632416
[5/24] Train loss=0.5184704661369324
[10/24] Train loss=0.47789156436920166
[15/24] Train loss=0.467833012342453
[20/24] Train loss=0.46326759457588196
Test set avg_accuracy=58.03% avg_sensitivity=46.11%, avg_specificity=62.00% avg_auc=56.62%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.483592 Test loss=0.655196 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4335257411003113
[5/24] Train loss=0.5090538859367371
[10/24] Train loss=0.4764779806137085
[15/24] Train loss=0.4710847735404968
[20/24] Train loss=0.46451109647750854
Test set avg_accuracy=58.80% avg_sensitivity=51.54%, avg_specificity=61.22% avg_auc=59.87%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.478423 Test loss=0.652932 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.43168431520462036
[5/24] Train loss=0.5069345235824585
[10/24] Train loss=0.4699820578098297
[15/24] Train loss=0.46526873111724854
[20/24] Train loss=0.4485497772693634
Test set avg_accuracy=59.71% avg_sensitivity=53.63%, avg_specificity=61.74% avg_auc=62.12%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.474788 Test loss=0.649684 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4243555963039398
[5/24] Train loss=0.4988759160041809
[10/24] Train loss=0.46299228072166443
[15/24] Train loss=0.4599362313747406
[20/24] Train loss=0.45190900564193726
Test set avg_accuracy=59.66% avg_sensitivity=49.24%, avg_specificity=63.13% avg_auc=61.22%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.468395 Test loss=0.642778 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.42154404520988464
[5/24] Train loss=0.49506330490112305
[10/24] Train loss=0.44381406903266907
[15/24] Train loss=0.43417418003082275
[20/24] Train loss=0.42399224638938904
Test set avg_accuracy=54.71% avg_sensitivity=61.24%, avg_specificity=52.54% avg_auc=61.99%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.458754 Test loss=0.667900 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3996167778968811
[5/24] Train loss=0.48144567012786865
[10/24] Train loss=0.4425031244754791
[15/24] Train loss=0.4345572888851166
[20/24] Train loss=0.4101060628890991
Test set avg_accuracy=53.42% avg_sensitivity=65.21%, avg_specificity=49.51% avg_auc=63.00%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.449147 Test loss=0.667434 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.37964579463005066
[5/24] Train loss=0.47548359632492065
[10/24] Train loss=0.424295037984848
[15/24] Train loss=0.4099298119544983
[20/24] Train loss=0.38437700271606445
Test set avg_accuracy=52.41% avg_sensitivity=71.31%, avg_specificity=46.12% avg_auc=65.09%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.433719 Test loss=0.676342 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.36912110447883606
[5/24] Train loss=0.4486543834209442
[10/24] Train loss=0.41334590315818787
[15/24] Train loss=0.4052225947380066
[20/24] Train loss=0.37804901599884033
Test set avg_accuracy=54.93% avg_sensitivity=66.51%, avg_specificity=51.08% avg_auc=64.88%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.423434 Test loss=0.661004 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.36722642183303833
[5/24] Train loss=0.44953301548957825
[10/24] Train loss=0.4079146981239319
[15/24] Train loss=0.40491366386413574
[20/24] Train loss=0.3736015558242798
Test set avg_accuracy=58.75% avg_sensitivity=68.60%, avg_specificity=55.47% avg_auc=68.12%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.421026 Test loss=0.644424 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.36398816108703613
[5/24] Train loss=0.4385734796524048
[10/24] Train loss=0.41264480352401733
[15/24] Train loss=0.40853166580200195
[20/24] Train loss=0.36814939975738525
Test set avg_accuracy=64.62% avg_sensitivity=65.99%, avg_specificity=64.17% avg_auc=71.81%
Best model saved!! Metric=-59.408379159875636!!
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.417904 Test loss=0.614082 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.36393511295318604
[5/24] Train loss=0.4280482530593872
[10/24] Train loss=0.4181371331214905
[15/24] Train loss=0.40796416997909546
[20/24] Train loss=0.36772653460502625
Test set avg_accuracy=58.44% avg_sensitivity=63.38%, avg_specificity=56.79% avg_auc=65.61%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.416666 Test loss=0.647865 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3537023663520813
[5/24] Train loss=0.4298493564128876
[10/24] Train loss=0.40232402086257935
[15/24] Train loss=0.40736812353134155
[20/24] Train loss=0.3776549994945526
Test set avg_accuracy=65.10% avg_sensitivity=57.22%, avg_specificity=67.73% avg_auc=68.69%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.413346 Test loss=0.594817 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.35797467827796936
[5/24] Train loss=0.42807745933532715
[10/24] Train loss=0.39020514488220215
[15/24] Train loss=0.39304596185684204
[20/24] Train loss=0.3635251522064209
Test set avg_accuracy=59.48% avg_sensitivity=60.04%, avg_specificity=59.29% avg_auc=64.99%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.410426 Test loss=0.642372 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.35749417543411255
[5/24] Train loss=0.4507145881652832
[10/24] Train loss=0.3873882293701172
[15/24] Train loss=0.3963552713394165
[20/24] Train loss=0.37254586815834045
Test set avg_accuracy=59.96% avg_sensitivity=69.17%, avg_specificity=56.90% avg_auc=68.84%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.407845 Test loss=0.645936 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.35809892416000366
[5/24] Train loss=0.41416916251182556
[10/24] Train loss=0.3881740868091583
[15/24] Train loss=0.3899291455745697
[20/24] Train loss=0.352993905544281
Test set avg_accuracy=61.80% avg_sensitivity=67.61%, avg_specificity=59.86% avg_auc=69.86%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.404282 Test loss=0.629555 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.348043829202652
[5/24] Train loss=0.41854771971702576
[10/24] Train loss=0.3866468667984009
[15/24] Train loss=0.3909130394458771
[20/24] Train loss=0.3642241954803467
Test set avg_accuracy=64.06% avg_sensitivity=67.40%, avg_specificity=62.95% avg_auc=71.26%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.402726 Test loss=0.618427 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.36074984073638916
[5/24] Train loss=0.41757434606552124
[10/24] Train loss=0.4042600989341736
[15/24] Train loss=0.39191025495529175
[20/24] Train loss=0.35564494132995605
Test set avg_accuracy=61.07% avg_sensitivity=65.36%, avg_specificity=59.64% avg_auc=67.65%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.403838 Test loss=0.636736 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34470394253730774
[5/24] Train loss=0.4211467206478119
[10/24] Train loss=0.390781044960022
[15/24] Train loss=0.39005622267723083
[20/24] Train loss=0.36424681544303894
Test set avg_accuracy=65.30% avg_sensitivity=64.63%, avg_specificity=65.52% avg_auc=71.08%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.405959 Test loss=0.610439 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.35388293862342834
[5/24] Train loss=0.41791948676109314
[10/24] Train loss=0.3880642056465149
[15/24] Train loss=0.3890688419342041
[20/24] Train loss=0.3623213469982147
Test set avg_accuracy=64.27% avg_sensitivity=59.68%, avg_specificity=65.80% avg_auc=68.41%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.401752 Test loss=0.603873 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3547426462173462
[5/24] Train loss=0.4113585948944092
[10/24] Train loss=0.38975656032562256
[15/24] Train loss=0.38193657994270325
[20/24] Train loss=0.3478347361087799
Test set avg_accuracy=60.49% avg_sensitivity=70.27%, avg_specificity=57.24% avg_auc=69.63%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.398897 Test loss=0.644122 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.34217143058776855
[5/24] Train loss=0.41032037138938904
[10/24] Train loss=0.39127302169799805
[15/24] Train loss=0.4165182113647461
[20/24] Train loss=0.36350706219673157
Test set avg_accuracy=65.46% avg_sensitivity=68.81%, avg_specificity=64.34% avg_auc=73.03%
Best model saved!! Metric=-54.366760659469534!!
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.406289 Test loss=0.608575 Current lr=[0.00029967723776099]

[0/24] Train loss=0.349681556224823
[5/24] Train loss=0.4157816469669342
[10/24] Train loss=0.3870958387851715
[15/24] Train loss=0.4049895107746124
[20/24] Train loss=0.3435201048851013
Test set avg_accuracy=63.11% avg_sensitivity=64.68%, avg_specificity=62.59% avg_auc=69.50%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.405201 Test loss=0.618218 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.34432342648506165
[5/24] Train loss=0.40754038095474243
[10/24] Train loss=0.376969575881958
[15/24] Train loss=0.3848201036453247
[20/24] Train loss=0.3586207926273346
Test set avg_accuracy=62.49% avg_sensitivity=66.41%, avg_specificity=61.18% avg_auc=69.63%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.398341 Test loss=0.624214 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3544750511646271
[5/24] Train loss=0.414204478263855
[10/24] Train loss=0.38031890988349915
[15/24] Train loss=0.3884611129760742
[20/24] Train loss=0.35744109749794006
Test set avg_accuracy=62.63% avg_sensitivity=73.03%, avg_specificity=59.17% avg_auc=73.20%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.400292 Test loss=0.631332 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3415996730327606
[5/24] Train loss=0.4094727337360382
[10/24] Train loss=0.3840312659740448
[15/24] Train loss=0.39516231417655945
[20/24] Train loss=0.34840846061706543
Test set avg_accuracy=69.27% avg_sensitivity=58.74%, avg_specificity=72.77% avg_auc=72.87%
Best model saved!! Metric=-52.344455174081496!!
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.398713 Test loss=0.563475 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3468363881111145
[5/24] Train loss=0.41030120849609375
[10/24] Train loss=0.37334737181663513
[15/24] Train loss=0.39272379875183105
[20/24] Train loss=0.36436229944229126
Test set avg_accuracy=61.30% avg_sensitivity=68.60%, avg_specificity=58.88% avg_auc=69.62%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.398686 Test loss=0.635235 Current lr=[0.000298904600941902]

[0/24] Train loss=0.34501537680625916
[5/24] Train loss=0.40934646129608154
[10/24] Train loss=0.3795028328895569
[15/24] Train loss=0.38390493392944336
[20/24] Train loss=0.3511956036090851
Test set avg_accuracy=62.59% avg_sensitivity=65.41%, avg_specificity=61.65% avg_auc=69.36%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.394425 Test loss=0.621835 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.33888739347457886
[5/24] Train loss=0.40673530101776123
[10/24] Train loss=0.37356939911842346
[15/24] Train loss=0.3842639625072479
[20/24] Train loss=0.34677714109420776
Test set avg_accuracy=67.38% avg_sensitivity=65.88%, avg_specificity=67.88% avg_auc=73.51%
Best model saved!! Metric=-51.339644568100596!!
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.395465 Test loss=0.586697 Current lr=[0.000297555943323901]

[0/24] Train loss=0.34270817041397095
[5/24] Train loss=0.400850772857666
[10/24] Train loss=0.38465818762779236
[15/24] Train loss=0.38839343190193176
[20/24] Train loss=0.3645688593387604
Test set avg_accuracy=62.97% avg_sensitivity=68.23%, avg_specificity=61.22% avg_auc=70.81%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.398993 Test loss=0.621734 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3398700952529907
[5/24] Train loss=0.40398404002189636
[10/24] Train loss=0.3751485347747803
[15/24] Train loss=0.3817218840122223
[20/24] Train loss=0.3620004951953888
Test set avg_accuracy=63.58% avg_sensitivity=67.29%, avg_specificity=62.35% avg_auc=71.04%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.396197 Test loss=0.617416 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.36473989486694336
[5/24] Train loss=0.41510969400405884
[10/24] Train loss=0.37798529863357544
[15/24] Train loss=0.3890758156776428
[20/24] Train loss=0.3461580276489258
Test set avg_accuracy=66.99% avg_sensitivity=66.51%, avg_specificity=67.15% avg_auc=73.41%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.395643 Test loss=0.596594 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3556615114212036
[5/24] Train loss=0.4111729860305786
[10/24] Train loss=0.37629327178001404
[15/24] Train loss=0.3834514915943146
[20/24] Train loss=0.3700876832008362
Test set avg_accuracy=68.07% avg_sensitivity=66.77%, avg_specificity=68.51% avg_auc=75.04%
Best model saved!! Metric=-47.61221696919196!!
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.396396 Test loss=0.589761 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3476598262786865
[5/24] Train loss=0.4001305401325226
[10/24] Train loss=0.370610773563385
[15/24] Train loss=0.38218197226524353
[20/24] Train loss=0.35180240869522095
Test set avg_accuracy=64.48% avg_sensitivity=65.83%, avg_specificity=64.03% avg_auc=70.94%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.397373 Test loss=0.608565 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.35207974910736084
[5/24] Train loss=0.416936457157135
[10/24] Train loss=0.3725110590457916
[15/24] Train loss=0.3777736723423004
[20/24] Train loss=0.3458607792854309
Test set avg_accuracy=64.66% avg_sensitivity=69.22%, avg_specificity=63.14% avg_auc=72.45%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.392414 Test loss=0.609754 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.34347859025001526
[5/24] Train loss=0.4023575782775879
[10/24] Train loss=0.3733755052089691
[15/24] Train loss=0.394972026348114
[20/24] Train loss=0.3590874671936035
Test set avg_accuracy=68.19% avg_sensitivity=60.41%, avg_specificity=70.78% avg_auc=71.54%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.393746 Test loss=0.579851 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.34626108407974243
[5/24] Train loss=0.4090622365474701
[10/24] Train loss=0.3746397793292999
[15/24] Train loss=0.3844422996044159
[20/24] Train loss=0.3396477699279785
Test set avg_accuracy=65.56% avg_sensitivity=66.67%, avg_specificity=65.19% avg_auc=72.47%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.394172 Test loss=0.601311 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3391490578651428
[5/24] Train loss=0.3972708582878113
[10/24] Train loss=0.37643325328826904
[15/24] Train loss=0.37095579504966736
[20/24] Train loss=0.3474827706813812
Test set avg_accuracy=60.85% avg_sensitivity=74.28%, avg_specificity=56.38% avg_auc=72.63%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.388123 Test loss=0.641657 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3319922983646393
[5/24] Train loss=0.3963043987751007
[10/24] Train loss=0.37939566373825073
[15/24] Train loss=0.38614434003829956
[20/24] Train loss=0.35218051075935364
Test set avg_accuracy=70.22% avg_sensitivity=61.87%, avg_specificity=73.00% avg_auc=74.20%
Best model saved!! Metric=-46.706688494994765!!
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.392988 Test loss=0.567815 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3516320586204529
[5/24] Train loss=0.4070487320423126
[10/24] Train loss=0.38757002353668213
[15/24] Train loss=0.39337357878685
[20/24] Train loss=0.3565177321434021
Test set avg_accuracy=68.32% avg_sensitivity=64.32%, avg_specificity=69.65% avg_auc=73.43%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.399431 Test loss=0.581701 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3398292064666748
[5/24] Train loss=0.405093789100647
[10/24] Train loss=0.37326109409332275
[15/24] Train loss=0.37974101305007935
[20/24] Train loss=0.3591445982456207
Test set avg_accuracy=67.85% avg_sensitivity=62.75%, avg_specificity=69.55% avg_auc=72.53%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.393538 Test loss=0.582212 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.33892810344696045
[5/24] Train loss=0.3957236707210541
[10/24] Train loss=0.37209251523017883
[15/24] Train loss=0.37479832768440247
[20/24] Train loss=0.34887367486953735
Test set avg_accuracy=67.49% avg_sensitivity=63.54%, avg_specificity=68.80% avg_auc=72.23%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.392987 Test loss=0.587314 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3488687574863434
[5/24] Train loss=0.40779662132263184
[10/24] Train loss=0.3732277452945709
[15/24] Train loss=0.3739301860332489
[20/24] Train loss=0.33536168932914734
Test set avg_accuracy=66.89% avg_sensitivity=65.10%, avg_specificity=67.48% avg_auc=72.20%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.393574 Test loss=0.592599 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3314749300479889
[5/24] Train loss=0.4024498760700226
[10/24] Train loss=0.3723146617412567
[15/24] Train loss=0.3730297386646271
[20/24] Train loss=0.3491225838661194
Test set avg_accuracy=66.18% avg_sensitivity=68.34%, avg_specificity=65.47% avg_auc=73.04%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.388696 Test loss=0.600676 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.329024076461792
[5/24] Train loss=0.4005120098590851
[10/24] Train loss=0.3703259229660034
[15/24] Train loss=0.3801310360431671
[20/24] Train loss=0.35595494508743286
Test set avg_accuracy=67.54% avg_sensitivity=58.79%, avg_specificity=70.45% avg_auc=71.03%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.390538 Test loss=0.574798 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3563477396965027
[5/24] Train loss=0.3965945839881897
[10/24] Train loss=0.3746567368507385
[15/24] Train loss=0.3770049214363098
[20/24] Train loss=0.33574920892715454
Test set avg_accuracy=68.75% avg_sensitivity=66.20%, avg_specificity=69.60% avg_auc=74.33%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.390152 Test loss=0.585274 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.34994375705718994
[5/24] Train loss=0.3937682807445526
[10/24] Train loss=0.3709140419960022
[15/24] Train loss=0.39096441864967346
[20/24] Train loss=0.33894431591033936
Test set avg_accuracy=64.80% avg_sensitivity=71.26%, avg_specificity=62.66% avg_auc=74.35%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.392193 Test loss=0.612060 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.33953070640563965
[5/24] Train loss=0.4045655131340027
[10/24] Train loss=0.37245973944664
[15/24] Train loss=0.3790498971939087
[20/24] Train loss=0.35131657123565674
Test set avg_accuracy=66.80% avg_sensitivity=62.23%, avg_specificity=68.32% avg_auc=71.18%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.391982 Test loss=0.588608 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3412953317165375
[5/24] Train loss=0.39203014969825745
[10/24] Train loss=0.37628570199012756
[15/24] Train loss=0.3873501420021057
[20/24] Train loss=0.3381522595882416
Test set avg_accuracy=67.10% avg_sensitivity=64.79%, avg_specificity=67.86% avg_auc=72.53%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.388844 Test loss=0.588187 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.34568944573402405
[5/24] Train loss=0.3945619761943817
[10/24] Train loss=0.37252750992774963
[15/24] Train loss=0.37236031889915466
[20/24] Train loss=0.34260013699531555
Test set avg_accuracy=66.72% avg_sensitivity=69.74%, avg_specificity=65.71% avg_auc=75.01%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.388339 Test loss=0.593665 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.33294495940208435
[5/24] Train loss=0.3888823091983795
[10/24] Train loss=0.3706429600715637
[15/24] Train loss=0.3706866204738617
[20/24] Train loss=0.3416716456413269
Test set avg_accuracy=64.64% avg_sensitivity=67.97%, avg_specificity=63.53% avg_auc=72.41%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.383001 Test loss=0.604081 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3272669017314911
[5/24] Train loss=0.3902517557144165
[10/24] Train loss=0.3659980893135071
[15/24] Train loss=0.3676382899284363
[20/24] Train loss=0.33168843388557434
Test set avg_accuracy=64.32% avg_sensitivity=70.84%, avg_specificity=62.16% avg_auc=72.96%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.381428 Test loss=0.611746 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3330532908439636
[5/24] Train loss=0.399225115776062
[10/24] Train loss=0.3645903468132019
[15/24] Train loss=0.3718422055244446
[20/24] Train loss=0.34433871507644653
Test set avg_accuracy=64.74% avg_sensitivity=68.54%, avg_specificity=63.47% avg_auc=72.51%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.384954 Test loss=0.607799 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.33835700154304504
[5/24] Train loss=0.38783833384513855
[10/24] Train loss=0.3641171157360077
[15/24] Train loss=0.3768254816532135
[20/24] Train loss=0.34151479601860046
Test set avg_accuracy=66.47% avg_sensitivity=65.88%, avg_specificity=66.67% avg_auc=72.56%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.386410 Test loss=0.592743 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3442854881286621
[5/24] Train loss=0.3917746841907501
[10/24] Train loss=0.3766161799430847
[15/24] Train loss=0.38748037815093994
[20/24] Train loss=0.3529350757598877
Test set avg_accuracy=67.51% avg_sensitivity=64.68%, avg_specificity=68.45% avg_auc=72.88%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.389210 Test loss=0.582941 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3434656262397766
[5/24] Train loss=0.38822150230407715
[10/24] Train loss=0.36827322840690613
[15/24] Train loss=0.37033918499946594
[20/24] Train loss=0.3276761472225189
Test set avg_accuracy=66.29% avg_sensitivity=65.94%, avg_specificity=66.41% avg_auc=72.26%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.382335 Test loss=0.594267 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.33359789848327637
[5/24] Train loss=0.38242724537849426
[10/24] Train loss=0.3658989667892456
[15/24] Train loss=0.37250787019729614
[20/24] Train loss=0.3378712236881256
Test set avg_accuracy=63.91% avg_sensitivity=66.82%, avg_specificity=62.94% avg_auc=71.25%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.378393 Test loss=0.609574 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3367765545845032
[5/24] Train loss=0.38800540566444397
[10/24] Train loss=0.3672217130661011
[15/24] Train loss=0.3728603422641754
[20/24] Train loss=0.33801618218421936
Test set avg_accuracy=67.47% avg_sensitivity=66.35%, avg_specificity=67.85% avg_auc=73.11%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.385745 Test loss=0.584564 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3330328166484833
[5/24] Train loss=0.382522851228714
[10/24] Train loss=0.3646439015865326
[15/24] Train loss=0.3760818541049957
[20/24] Train loss=0.33535856008529663
Test set avg_accuracy=66.00% avg_sensitivity=65.52%, avg_specificity=66.16% avg_auc=72.17%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.377206 Test loss=0.592351 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.33484190702438354
[5/24] Train loss=0.39111262559890747
[10/24] Train loss=0.37039071321487427
[15/24] Train loss=0.36906957626342773
[20/24] Train loss=0.3292895257472992
Test set avg_accuracy=65.82% avg_sensitivity=66.35%, avg_specificity=65.64% avg_auc=72.43%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.379127 Test loss=0.595016 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.32910120487213135
[5/24] Train loss=0.37703076004981995
[10/24] Train loss=0.3617714047431946
[15/24] Train loss=0.3603512942790985
[20/24] Train loss=0.3303603529930115
Test set avg_accuracy=66.64% avg_sensitivity=70.53%, avg_specificity=65.35% avg_auc=74.76%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.376470 Test loss=0.591065 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.32731154561042786
[5/24] Train loss=0.37798380851745605
[10/24] Train loss=0.36142268776893616
[15/24] Train loss=0.3620527386665344
[20/24] Train loss=0.33404847979545593
Test set avg_accuracy=64.96% avg_sensitivity=68.44%, avg_specificity=63.80% avg_auc=72.49%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.375177 Test loss=0.603346 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3283642530441284
[5/24] Train loss=0.37871989607810974
[10/24] Train loss=0.3527373671531677
[15/24] Train loss=0.36638736724853516
[20/24] Train loss=0.3308388590812683
Test set avg_accuracy=62.72% avg_sensitivity=71.41%, avg_specificity=59.83% avg_auc=72.38%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.375496 Test loss=0.625850 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.32622969150543213
[5/24] Train loss=0.3838329017162323
[10/24] Train loss=0.35797205567359924
[15/24] Train loss=0.3688860535621643
[20/24] Train loss=0.32784557342529297
Test set avg_accuracy=64.84% avg_sensitivity=67.97%, avg_specificity=63.80% avg_auc=72.23%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.379475 Test loss=0.606214 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.32326140999794006
[5/24] Train loss=0.3744933605194092
[10/24] Train loss=0.3621947169303894
[15/24] Train loss=0.35925471782684326
[20/24] Train loss=0.32470303773880005
Test set avg_accuracy=63.53% avg_sensitivity=71.62%, avg_specificity=60.84% avg_auc=72.47%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.371137 Test loss=0.621515 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.32091403007507324
[5/24] Train loss=0.36997923254966736
[10/24] Train loss=0.36215370893478394
[15/24] Train loss=0.36303675174713135
[20/24] Train loss=0.3247101604938507
Test set avg_accuracy=65.36% avg_sensitivity=70.58%, avg_specificity=63.63% avg_auc=74.04%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.371623 Test loss=0.599542 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3238272964954376
[5/24] Train loss=0.3724379539489746
[10/24] Train loss=0.3560851514339447
[15/24] Train loss=0.36131197214126587
[20/24] Train loss=0.32776230573654175
Test set avg_accuracy=65.74% avg_sensitivity=65.26%, avg_specificity=65.90% avg_auc=71.40%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.374679 Test loss=0.602322 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.32386139035224915
[5/24] Train loss=0.3868838846683502
[10/24] Train loss=0.36223751306533813
[15/24] Train loss=0.37812530994415283
[20/24] Train loss=0.3409157693386078
Test set avg_accuracy=64.77% avg_sensitivity=71.47%, avg_specificity=62.54% avg_auc=73.71%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.381563 Test loss=0.607347 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3242146670818329
[5/24] Train loss=0.3751479685306549
[10/24] Train loss=0.35871008038520813
[15/24] Train loss=0.3618719279766083
[20/24] Train loss=0.330128937959671
Test set avg_accuracy=62.46% avg_sensitivity=73.87%, avg_specificity=58.67% avg_auc=73.41%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.373112 Test loss=0.625474 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3252774178981781
[5/24] Train loss=0.37254035472869873
[10/24] Train loss=0.3634417951107025
[15/24] Train loss=0.370646595954895
[20/24] Train loss=0.33459919691085815
Test set avg_accuracy=64.17% avg_sensitivity=73.45%, avg_specificity=61.08% avg_auc=74.42%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.374388 Test loss=0.613370 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3332824110984802
[5/24] Train loss=0.37896114587783813
[10/24] Train loss=0.36486756801605225
[15/24] Train loss=0.3668242394924164
[20/24] Train loss=0.32616978883743286
Test set avg_accuracy=64.95% avg_sensitivity=65.31%, avg_specificity=64.83% avg_auc=70.96%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.375049 Test loss=0.607269 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.32924705743789673
[5/24] Train loss=0.36876389384269714
[10/24] Train loss=0.35505932569503784
[15/24] Train loss=0.3597368597984314
[20/24] Train loss=0.32420992851257324
Test set avg_accuracy=63.72% avg_sensitivity=68.86%, avg_specificity=62.02% avg_auc=71.82%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.370670 Test loss=0.617509 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3313644230365753
[5/24] Train loss=0.3646713197231293
[10/24] Train loss=0.35521864891052246
[15/24] Train loss=0.3589194715023041
[20/24] Train loss=0.32484617829322815
Test set avg_accuracy=64.43% avg_sensitivity=70.63%, avg_specificity=62.36% avg_auc=73.34%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.370412 Test loss=0.609032 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.3239942789077759
[5/24] Train loss=0.3903381824493408
[10/24] Train loss=0.36248934268951416
[15/24] Train loss=0.3877924084663391
[20/24] Train loss=0.33009204268455505
Test set avg_accuracy=63.87% avg_sensitivity=71.62%, avg_specificity=61.29% avg_auc=73.06%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.377293 Test loss=0.622175 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3416121304035187
[5/24] Train loss=0.37259671092033386
[10/24] Train loss=0.3566974699497223
[15/24] Train loss=0.3658016324043274
[20/24] Train loss=0.32518547773361206
Test set avg_accuracy=63.66% avg_sensitivity=69.17%, avg_specificity=61.83% avg_auc=71.87%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.378640 Test loss=0.618410 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3311441242694855
[5/24] Train loss=0.37437891960144043
[10/24] Train loss=0.35483407974243164
[15/24] Train loss=0.35714417695999146
[20/24] Train loss=0.32569989562034607
Test set avg_accuracy=61.69% avg_sensitivity=68.96%, avg_specificity=59.27% avg_auc=70.27%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.372787 Test loss=0.637787 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3321516215801239
[5/24] Train loss=0.36934033036231995
[10/24] Train loss=0.356600821018219
[15/24] Train loss=0.36524349451065063
[20/24] Train loss=0.32665857672691345
Test set avg_accuracy=63.40% avg_sensitivity=67.55%, avg_specificity=62.02% avg_auc=70.66%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.372125 Test loss=0.624145 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3255498707294464
[5/24] Train loss=0.36984995007514954
[10/24] Train loss=0.3569546639919281
[15/24] Train loss=0.35678133368492126
[20/24] Train loss=0.3251979351043701
Test set avg_accuracy=63.15% avg_sensitivity=70.27%, avg_specificity=60.78% avg_auc=71.65%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.368051 Test loss=0.629157 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3257923722267151
[5/24] Train loss=0.3702245354652405
[10/24] Train loss=0.35283008217811584
[15/24] Train loss=0.3572613596916199
[20/24] Train loss=0.3203532099723816
Test set avg_accuracy=60.94% avg_sensitivity=69.74%, avg_specificity=58.01% avg_auc=69.97%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.366627 Test loss=0.650301 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3285527229309082
[5/24] Train loss=0.38202598690986633
[10/24] Train loss=0.35179364681243896
[15/24] Train loss=0.3572019636631012
[20/24] Train loss=0.3192580044269562
Test set avg_accuracy=61.68% avg_sensitivity=71.47%, avg_specificity=58.42% avg_auc=71.30%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.366457 Test loss=0.640721 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3215189278125763
[5/24] Train loss=0.3706861734390259
[10/24] Train loss=0.3528769016265869
[15/24] Train loss=0.3572653830051422
[20/24] Train loss=0.3197202980518341
Test set avg_accuracy=60.56% avg_sensitivity=67.61%, avg_specificity=58.22% avg_auc=68.71%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.364599 Test loss=0.654871 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3209187686443329
[5/24] Train loss=0.362051397562027
[10/24] Train loss=0.35330820083618164
[15/24] Train loss=0.35683882236480713
[20/24] Train loss=0.3198387920856476
Test set avg_accuracy=60.95% avg_sensitivity=69.48%, avg_specificity=58.11% avg_auc=69.65%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.364066 Test loss=0.650444 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.32208773493766785
[5/24] Train loss=0.3621435761451721
[10/24] Train loss=0.34775251150131226
[15/24] Train loss=0.35789865255355835
[20/24] Train loss=0.32208505272865295
Test set avg_accuracy=60.48% avg_sensitivity=68.91%, avg_specificity=57.68% avg_auc=69.07%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.363509 Test loss=0.658219 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.31906789541244507
[5/24] Train loss=0.3597828447818756
[10/24] Train loss=0.349446564912796
[15/24] Train loss=0.36098507046699524
[20/24] Train loss=0.32125791907310486
Test set avg_accuracy=62.76% avg_sensitivity=69.48%, avg_specificity=60.52% avg_auc=70.74%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.362891 Test loss=0.634212 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.31945547461509705
[5/24] Train loss=0.360393226146698
[10/24] Train loss=0.3475935757160187
[15/24] Train loss=0.3559795618057251
[20/24] Train loss=0.3221888840198517
Test set avg_accuracy=60.89% avg_sensitivity=70.63%, avg_specificity=57.64% avg_auc=70.13%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.361751 Test loss=0.655036 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3139006495475769
[5/24] Train loss=0.36613789200782776
[10/24] Train loss=0.3502773344516754
[15/24] Train loss=0.36054620146751404
[20/24] Train loss=0.3191142678260803
Test set avg_accuracy=62.84% avg_sensitivity=68.65%, avg_specificity=60.91% avg_auc=70.46%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.362241 Test loss=0.634565 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.31492602825164795
[5/24] Train loss=0.36216896772384644
[10/24] Train loss=0.34732165932655334
[15/24] Train loss=0.3523430824279785
[20/24] Train loss=0.31506064534187317
Test set avg_accuracy=63.88% avg_sensitivity=66.61%, avg_specificity=62.97% avg_auc=70.53%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.359659 Test loss=0.620828 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.31709006428718567
[5/24] Train loss=0.35831546783447266
[10/24] Train loss=0.344420462846756
[15/24] Train loss=0.3527286648750305
[20/24] Train loss=0.32021844387054443
Test set avg_accuracy=62.14% avg_sensitivity=67.92%, avg_specificity=60.21% avg_auc=69.89%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.357690 Test loss=0.641842 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3131672739982605
[5/24] Train loss=0.3567766547203064
[10/24] Train loss=0.3447731137275696
[15/24] Train loss=0.35175469517707825
[20/24] Train loss=0.31734389066696167
Test set avg_accuracy=61.88% avg_sensitivity=68.65%, avg_specificity=59.62% avg_auc=69.96%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.357997 Test loss=0.645678 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.31741684675216675
[5/24] Train loss=0.3594408333301544
[10/24] Train loss=0.3464559316635132
[15/24] Train loss=0.35572659969329834
[20/24] Train loss=0.31718936562538147
Test set avg_accuracy=62.84% avg_sensitivity=69.07%, avg_specificity=60.77% avg_auc=70.99%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.358748 Test loss=0.632243 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.31089136004447937
[5/24] Train loss=0.3558964729309082
[10/24] Train loss=0.3437407612800598
[15/24] Train loss=0.3508557081222534
[20/24] Train loss=0.31958550214767456
Test set avg_accuracy=62.89% avg_sensitivity=68.49%, avg_specificity=61.03% avg_auc=70.61%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.356423 Test loss=0.632945 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3103519082069397
[5/24] Train loss=0.3596857190132141
[10/24] Train loss=0.3445236086845398
[15/24] Train loss=0.351106733083725
[20/24] Train loss=0.3179243803024292
Test set avg_accuracy=62.08% avg_sensitivity=69.54%, avg_specificity=59.60% avg_auc=70.38%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.356120 Test loss=0.643126 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3117069900035858
[5/24] Train loss=0.3542478680610657
[10/24] Train loss=0.3445815443992615
[15/24] Train loss=0.34996312856674194
[20/24] Train loss=0.3140639066696167
Test set avg_accuracy=62.02% avg_sensitivity=69.48%, avg_specificity=59.53% avg_auc=70.53%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.354786 Test loss=0.641598 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.30911222100257874
[5/24] Train loss=0.35364407300949097
[10/24] Train loss=0.3419331908226013
[15/24] Train loss=0.34966611862182617
[20/24] Train loss=0.313979834318161
Test set avg_accuracy=62.02% avg_sensitivity=69.69%, avg_specificity=59.47% avg_auc=70.53%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.354250 Test loss=0.644746 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.30856066942214966
[5/24] Train loss=0.3525250256061554
[10/24] Train loss=0.34162193536758423
[15/24] Train loss=0.3519437313079834
[20/24] Train loss=0.3171296715736389
Test set avg_accuracy=61.86% avg_sensitivity=70.32%, avg_specificity=59.05% avg_auc=71.01%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.354847 Test loss=0.641655 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3116501569747925
[5/24] Train loss=0.3575740456581116
[10/24] Train loss=0.3431280255317688
[15/24] Train loss=0.3488084375858307
[20/24] Train loss=0.3131444454193115
Test set avg_accuracy=61.56% avg_sensitivity=70.47%, avg_specificity=58.60% avg_auc=70.51%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.354478 Test loss=0.649506 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3080204725265503
[5/24] Train loss=0.35380205512046814
[10/24] Train loss=0.3436702787876129
[15/24] Train loss=0.34858858585357666
[20/24] Train loss=0.312402606010437
Test set avg_accuracy=61.82% avg_sensitivity=68.08%, avg_specificity=59.74% avg_auc=69.92%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.353221 Test loss=0.646342 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.30691537261009216
[5/24] Train loss=0.3536742627620697
[10/24] Train loss=0.34087759256362915
[15/24] Train loss=0.34709423780441284
[20/24] Train loss=0.31267037987709045
Test set avg_accuracy=61.94% avg_sensitivity=69.85%, avg_specificity=59.31% avg_auc=70.29%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.352087 Test loss=0.646398 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3077019453048706
[5/24] Train loss=0.3512815535068512
[10/24] Train loss=0.34406957030296326
[15/24] Train loss=0.34703224897384644
[20/24] Train loss=0.31121906638145447
Test set avg_accuracy=61.55% avg_sensitivity=67.40%, avg_specificity=59.60% avg_auc=69.25%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.351952 Test loss=0.651732 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3068080544471741
[5/24] Train loss=0.35113847255706787
[10/24] Train loss=0.3440702557563782
[15/24] Train loss=0.34646111726760864
[20/24] Train loss=0.3158573508262634
Test set avg_accuracy=62.02% avg_sensitivity=68.96%, avg_specificity=59.71% avg_auc=70.03%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.352834 Test loss=0.646558 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3099156320095062
[5/24] Train loss=0.35607635974884033
[10/24] Train loss=0.34528905153274536
[15/24] Train loss=0.3472815454006195
[20/24] Train loss=0.3126447796821594
Test set avg_accuracy=62.10% avg_sensitivity=67.34%, avg_specificity=60.35% avg_auc=69.31%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.353475 Test loss=0.649106 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3071272075176239
[5/24] Train loss=0.3594001233577728
[10/24] Train loss=0.34235134720802307
[15/24] Train loss=0.34799352288246155
[20/24] Train loss=0.3117595613002777
Test set avg_accuracy=61.20% avg_sensitivity=68.49%, avg_specificity=58.77% avg_auc=69.44%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.351933 Test loss=0.656743 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3062523603439331
[5/24] Train loss=0.3526884615421295
[10/24] Train loss=0.34173813462257385
[15/24] Train loss=0.3471718728542328
[20/24] Train loss=0.30924293398857117
Test set avg_accuracy=61.67% avg_sensitivity=66.35%, avg_specificity=60.11% avg_auc=68.76%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.350720 Test loss=0.653511 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.306120902299881
[5/24] Train loss=0.35279038548469543
[10/24] Train loss=0.34283098578453064
[15/24] Train loss=0.3467600643634796
[20/24] Train loss=0.3115360140800476
Test set avg_accuracy=61.71% avg_sensitivity=67.34%, avg_specificity=59.83% avg_auc=69.27%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.350748 Test loss=0.652269 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.306422621011734
[5/24] Train loss=0.3524914085865021
[10/24] Train loss=0.3420793116092682
[15/24] Train loss=0.347260057926178
[20/24] Train loss=0.30913245677948
Test set avg_accuracy=61.98% avg_sensitivity=67.40%, avg_specificity=60.18% avg_auc=69.39%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.351109 Test loss=0.651083 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.30670681595802307
[5/24] Train loss=0.3512416481971741
[10/24] Train loss=0.34079504013061523
[15/24] Train loss=0.3472908139228821
[20/24] Train loss=0.30872493982315063
Test set avg_accuracy=61.55% avg_sensitivity=67.29%, avg_specificity=59.64% avg_auc=69.05%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.350430 Test loss=0.655796 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.304816335439682
[5/24] Train loss=0.3508854806423187
[10/24] Train loss=0.3398597836494446
[15/24] Train loss=0.3463857173919678
[20/24] Train loss=0.30790773034095764
Test set avg_accuracy=61.84% avg_sensitivity=67.61%, avg_specificity=59.92% avg_auc=69.40%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.349647 Test loss=0.651199 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3043171167373657
[5/24] Train loss=0.34943586587905884
[10/24] Train loss=0.340006023645401
[15/24] Train loss=0.3453846275806427
[20/24] Train loss=0.3083517253398895
Test set avg_accuracy=61.95% avg_sensitivity=68.39%, avg_specificity=59.81% avg_auc=69.60%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.349032 Test loss=0.650833 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.30408722162246704
[5/24] Train loss=0.3503589928150177
[10/24] Train loss=0.3400934338569641
[15/24] Train loss=0.3456784188747406
[20/24] Train loss=0.3077877163887024
Test set avg_accuracy=61.52% avg_sensitivity=68.34%, avg_specificity=59.26% avg_auc=69.26%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.349015 Test loss=0.657141 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.303619921207428
[5/24] Train loss=0.3486473262310028
[10/24] Train loss=0.3386659026145935
[15/24] Train loss=0.34501153230667114
[20/24] Train loss=0.30774474143981934
Test set avg_accuracy=61.38% avg_sensitivity=68.86%, avg_specificity=58.89% avg_auc=69.51%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.348297 Test loss=0.656993 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.30299365520477295
[5/24] Train loss=0.3485671877861023
[10/24] Train loss=0.3389674127101898
[15/24] Train loss=0.34489426016807556
[20/24] Train loss=0.30784907937049866
Test set avg_accuracy=61.46% avg_sensitivity=68.34%, avg_specificity=59.17% avg_auc=69.42%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.347951 Test loss=0.656563 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3030722439289093
[5/24] Train loss=0.3488360643386841
[10/24] Train loss=0.33810558915138245
[15/24] Train loss=0.3443235158920288
[20/24] Train loss=0.30794161558151245
Test set avg_accuracy=61.37% avg_sensitivity=69.12%, avg_specificity=58.79% avg_auc=69.60%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.347657 Test loss=0.657047 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.3022867441177368
[5/24] Train loss=0.3478618860244751
[10/24] Train loss=0.33856505155563354
[15/24] Train loss=0.34397369623184204
[20/24] Train loss=0.3073062300682068
Test set avg_accuracy=61.51% avg_sensitivity=68.75%, avg_specificity=59.10% avg_auc=69.53%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.347282 Test loss=0.656630 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3021864593029022
[5/24] Train loss=0.34809666872024536
[10/24] Train loss=0.33850783109664917
[15/24] Train loss=0.3437348008155823
[20/24] Train loss=0.3069792091846466
Test set avg_accuracy=61.37% avg_sensitivity=68.28%, avg_specificity=59.07% avg_auc=69.38%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.347096 Test loss=0.658110 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.30175313353538513
[5/24] Train loss=0.34720900654792786
[10/24] Train loss=0.3381636142730713
[15/24] Train loss=0.3438301384449005
[20/24] Train loss=0.3066738247871399
Test set avg_accuracy=61.38% avg_sensitivity=68.75%, avg_specificity=58.93% avg_auc=69.44%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.346848 Test loss=0.658330 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.301431804895401
[5/24] Train loss=0.34713706374168396
[10/24] Train loss=0.3379676342010498
[15/24] Train loss=0.34375879168510437
[20/24] Train loss=0.30627769231796265
Test set avg_accuracy=61.28% avg_sensitivity=68.39%, avg_specificity=58.91% avg_auc=69.24%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.346652 Test loss=0.660405 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.30127355456352234
[5/24] Train loss=0.34677624702453613
[10/24] Train loss=0.3375915586948395
[15/24] Train loss=0.34364211559295654
[20/24] Train loss=0.3060897886753082
Test set avg_accuracy=61.16% avg_sensitivity=68.49%, avg_specificity=58.72% avg_auc=69.22%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.346484 Test loss=0.661231 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.30110710859298706
[5/24] Train loss=0.346534788608551
[10/24] Train loss=0.33751609921455383
[15/24] Train loss=0.34357577562332153
[20/24] Train loss=0.305983304977417
Test set avg_accuracy=61.15% avg_sensitivity=68.49%, avg_specificity=58.70% avg_auc=69.18%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.346343 Test loss=0.661564 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3008807599544525
[5/24] Train loss=0.3463425636291504
[10/24] Train loss=0.33737269043922424
[15/24] Train loss=0.34351688623428345
[20/24] Train loss=0.30589261651039124
Test set avg_accuracy=61.11% avg_sensitivity=68.54%, avg_specificity=58.63% avg_auc=69.16%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.346223 Test loss=0.662134 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3008077144622803
[5/24] Train loss=0.34611374139785767
[10/24] Train loss=0.33734458684921265
[15/24] Train loss=0.3434613049030304
[20/24] Train loss=0.30580905079841614
Test set avg_accuracy=61.07% avg_sensitivity=68.44%, avg_specificity=58.62% avg_auc=69.11%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.346127 Test loss=0.662473 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3006945550441742
[5/24] Train loss=0.34597349166870117
[10/24] Train loss=0.33723118901252747
[15/24] Train loss=0.34342044591903687
[20/24] Train loss=0.305749773979187
Test set avg_accuracy=61.07% avg_sensitivity=68.49%, avg_specificity=58.60% avg_auc=69.11%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.346046 Test loss=0.662687 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3006408214569092
[5/24] Train loss=0.34590497612953186
[10/24] Train loss=0.3371870815753937
[15/24] Train loss=0.34339284896850586
[20/24] Train loss=0.30569255352020264
Test set avg_accuracy=61.03% avg_sensitivity=68.49%, avg_specificity=58.55% avg_auc=69.09%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.345985 Test loss=0.662945 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3005613088607788
[5/24] Train loss=0.3457862436771393
[10/24] Train loss=0.33715930581092834
[15/24] Train loss=0.3433625400066376
[20/24] Train loss=0.30564600229263306
Test set avg_accuracy=61.02% avg_sensitivity=68.49%, avg_specificity=58.53% avg_auc=69.08%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.345936 Test loss=0.663096 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3005167245864868
[5/24] Train loss=0.34573662281036377
[10/24] Train loss=0.3371257185935974
[15/24] Train loss=0.3433382511138916
[20/24] Train loss=0.30562373995780945
Test set avg_accuracy=61.03% avg_sensitivity=68.54%, avg_specificity=58.53% avg_auc=69.07%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.345900 Test loss=0.663222 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.300479531288147
[5/24] Train loss=0.3456958830356598
[10/24] Train loss=0.3371034860610962
[15/24] Train loss=0.3433273732662201
[20/24] Train loss=0.3056032359600067
Test set avg_accuracy=61.02% avg_sensitivity=68.54%, avg_specificity=58.51% avg_auc=69.06%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.345875 Test loss=0.663330 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3004581034183502
[5/24] Train loss=0.34566861391067505
[10/24] Train loss=0.3370929956436157
[15/24] Train loss=0.3433191180229187
[20/24] Train loss=0.30559030175209045
Test set avg_accuracy=61.00% avg_sensitivity=68.54%, avg_specificity=58.49% avg_auc=69.06%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.345859 Test loss=0.663395 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.30044475197792053
[5/24] Train loss=0.34565410017967224
[10/24] Train loss=0.33708709478378296
[15/24] Train loss=0.34331387281417847
[20/24] Train loss=0.3055843412876129
Test set avg_accuracy=61.02% avg_sensitivity=68.54%, avg_specificity=58.51% avg_auc=69.06%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.345851 Test loss=0.663425 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.30043837428092957
[5/24] Train loss=0.3456486761569977
[10/24] Train loss=0.33708465099334717
[15/24] Train loss=0.34331169724464417
[20/24] Train loss=0.305582731962204
Test set avg_accuracy=61.00% avg_sensitivity=68.54%, avg_specificity=58.49% avg_auc=69.06%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.345847 Test loss=0.663435 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=70.22% sen=61.87%, spe=73.00%, auc=74.20%!
Fold[2] Avg_overlap=0.31%(±0.1854494793883681)
[0/24] Train loss=0.6781398057937622
[5/24] Train loss=0.675126314163208
[10/24] Train loss=0.678265392780304
[15/24] Train loss=0.6756312847137451
[20/24] Train loss=0.6739699840545654
Test set avg_accuracy=66.03% avg_sensitivity=14.55%, avg_specificity=85.53% avg_auc=49.41%
Best model saved!! Metric=-110.48315571014179!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.674297 Test loss=0.673487 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6707150936126709
[5/24] Train loss=0.6674318313598633
[10/24] Train loss=0.6725176572799683
[15/24] Train loss=0.6699446439743042
[20/24] Train loss=0.6679548025131226
Test set avg_accuracy=66.00% avg_sensitivity=14.08%, avg_specificity=85.67% avg_auc=49.64%
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.667389 Test loss=0.667864 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6643486618995667
[5/24] Train loss=0.6608250141143799
[10/24] Train loss=0.6675949692726135
[15/24] Train loss=0.6648341417312622
[20/24] Train loss=0.6623538136482239
Test set avg_accuracy=66.16% avg_sensitivity=13.74%, avg_specificity=86.01% avg_auc=49.77%
Best model saved!! Metric=-110.31642385455399!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.661290 Test loss=0.662470 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6580537557601929
[5/24] Train loss=0.6542308926582336
[10/24] Train loss=0.6624143719673157
[15/24] Train loss=0.6593754887580872
[20/24] Train loss=0.656220555305481
Test set avg_accuracy=66.24% avg_sensitivity=13.46%, avg_specificity=86.23% avg_auc=49.99%
Best model saved!! Metric=-110.08311749197348!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.654881 Test loss=0.656482 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.651190996170044
[5/24] Train loss=0.6468027234077454
[10/24] Train loss=0.6567354202270508
[15/24] Train loss=0.653181254863739
[20/24] Train loss=0.649297833442688
Test set avg_accuracy=66.42% avg_sensitivity=13.27%, avg_specificity=86.55% avg_auc=50.16%
Best model saved!! Metric=-109.59640216095735!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.647693 Test loss=0.649742 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6434561610221863
[5/24] Train loss=0.6381831765174866
[10/24] Train loss=0.6500841975212097
[15/24] Train loss=0.6457985043525696
[20/24] Train loss=0.6408728361129761
Test set avg_accuracy=66.59% avg_sensitivity=12.89%, avg_specificity=86.93% avg_auc=50.33%
Best model saved!! Metric=-109.26298181304438!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.639176 Test loss=0.641518 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.634051501750946
[5/24] Train loss=0.6271925568580627
[10/24] Train loss=0.6419224143028259
[15/24] Train loss=0.6364888548851013
[20/24] Train loss=0.6304481625556946
Test set avg_accuracy=72.51% avg_sensitivity=0.90%, avg_specificity=99.64% avg_auc=50.51%
Best model saved!! Metric=-102.43500387588243!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.628465 Test loss=0.631280 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6223920583724976
[5/24] Train loss=0.6135050654411316
[10/24] Train loss=0.632317841053009
[15/24] Train loss=0.6253014802932739
[20/24] Train loss=0.6182239055633545
Test set avg_accuracy=72.51% avg_sensitivity=0.14%, avg_specificity=99.93% avg_auc=50.69%
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.615424 Test loss=0.619426 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6085957884788513
[5/24] Train loss=0.5972046256065369
[10/24] Train loss=0.6219544410705566
[15/24] Train loss=0.6126999258995056
[20/24] Train loss=0.604955792427063
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.18%
Best model saved!! Metric=-102.28972407226993!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.600459 Test loss=0.607071 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.5937687158584595
[5/24] Train loss=0.5797960162162781
[10/24] Train loss=0.6128107309341431
[15/24] Train loss=0.6005969047546387
[20/24] Train loss=0.5931252837181091
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.33%
Best model saved!! Metric=-102.1395415610172!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.585557 Test loss=0.596842 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.5806757807731628
[5/24] Train loss=0.5645226836204529
[10/24] Train loss=0.6073886156082153
[15/24] Train loss=0.5917266011238098
[20/24] Train loss=0.5848653316497803
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=51.97%
Best model saved!! Metric=-101.49994810589624!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.573760 Test loss=0.590593 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5720912218093872
[5/24] Train loss=0.5547509789466858
[10/24] Train loss=0.605600893497467
[15/24] Train loss=0.5870253443717957
[20/24] Train loss=0.5796095728874207
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.98%
Best model saved!! Metric=-100.49088210404135!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.566886 Test loss=0.587661 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5679432153701782
[5/24] Train loss=0.549924373626709
[10/24] Train loss=0.6042645573616028
[15/24] Train loss=0.5843974351882935
[20/24] Train loss=0.5756956934928894
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.75%
Best model saved!! Metric=-98.72359458713035!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.563334 Test loss=0.585892 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5657655596733093
[5/24] Train loss=0.547038733959198
[10/24] Train loss=0.6030986309051514
[15/24] Train loss=0.5828258395195007
[20/24] Train loss=0.5721982717514038
Test set avg_accuracy=72.53% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.51%
Best model saved!! Metric=-95.96157394506511!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.560781 Test loss=0.584410 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.564190685749054
[5/24] Train loss=0.5455686450004578
[10/24] Train loss=0.6045194864273071
[15/24] Train loss=0.5820919275283813
[20/24] Train loss=0.5685893297195435
Test set avg_accuracy=72.51% avg_sensitivity=0.00%, avg_specificity=99.98% avg_auc=59.80%
Best model saved!! Metric=-93.70229139279343!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.558428 Test loss=0.582731 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5610729455947876
[5/24] Train loss=0.5433151721954346
[10/24] Train loss=0.6024056077003479
[15/24] Train loss=0.5804885029792786
[20/24] Train loss=0.5639757513999939
Test set avg_accuracy=72.54% avg_sensitivity=0.09%, avg_specificity=99.98% avg_auc=62.60%
Best model saved!! Metric=-90.78500771365302!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.555605 Test loss=0.580576 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5582048296928406
[5/24] Train loss=0.5394840240478516
[10/24] Train loss=0.5979399681091309
[15/24] Train loss=0.5776543021202087
[20/24] Train loss=0.5575145483016968
Test set avg_accuracy=72.53% avg_sensitivity=0.24%, avg_specificity=99.91% avg_auc=65.99%
Best model saved!! Metric=-87.33219090967752!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.551227 Test loss=0.576559 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5501767992973328
[5/24] Train loss=0.535026490688324
[10/24] Train loss=0.5942639708518982
[15/24] Train loss=0.5741332173347473
[20/24] Train loss=0.547221302986145
Test set avg_accuracy=72.45% avg_sensitivity=1.23%, avg_specificity=99.43% avg_auc=68.77%
Best model saved!! Metric=-84.12394767088979!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.544470 Test loss=0.570878 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5414859056472778
[5/24] Train loss=0.5275275111198425
[10/24] Train loss=0.5864837765693665
[15/24] Train loss=0.5652506351470947
[20/24] Train loss=0.5338158011436462
Test set avg_accuracy=72.45% avg_sensitivity=4.50%, avg_specificity=98.19% avg_auc=70.76%
Best model saved!! Metric=-80.1010593133209!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.532862 Test loss=0.566568 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5242656469345093
[5/24] Train loss=0.5132776498794556
[10/24] Train loss=0.5746283531188965
[15/24] Train loss=0.5560292601585388
[20/24] Train loss=0.5123802423477173
Test set avg_accuracy=70.66% avg_sensitivity=43.98%, avg_specificity=80.77% avg_auc=69.60%
Best model saved!! Metric=-60.979798059701174!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.517943 Test loss=0.642007 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5047153234481812
[5/24] Train loss=0.5092411041259766
[10/24] Train loss=0.5627442598342896
[15/24] Train loss=0.5490038990974426
[20/24] Train loss=0.49858757853507996
Test set avg_accuracy=60.73% avg_sensitivity=52.80%, avg_specificity=63.73% avg_auc=62.29%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.503969 Test loss=0.667418 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.48233142495155334
[5/24] Train loss=0.4881630837917328
[10/24] Train loss=0.5495290160179138
[15/24] Train loss=0.5348408222198486
[20/24] Train loss=0.48658132553100586
Test set avg_accuracy=54.05% avg_sensitivity=48.72%, avg_specificity=56.07% avg_auc=57.27%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.489246 Test loss=0.675290 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4743671119213104
[5/24] Train loss=0.48078373074531555
[10/24] Train loss=0.5496339201927185
[15/24] Train loss=0.5277719497680664
[20/24] Train loss=0.47749975323677063
Test set avg_accuracy=58.52% avg_sensitivity=43.74%, avg_specificity=64.11% avg_auc=56.83%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.482347 Test loss=0.665668 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4692053198814392
[5/24] Train loss=0.4853517413139343
[10/24] Train loss=0.5394577980041504
[15/24] Train loss=0.5337422490119934
[20/24] Train loss=0.5038016438484192
Test set avg_accuracy=64.26% avg_sensitivity=42.46%, avg_specificity=72.51% avg_auc=59.79%
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.482563 Test loss=0.654275 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4737425446510315
[5/24] Train loss=0.48905661702156067
[10/24] Train loss=0.5363295674324036
[15/24] Train loss=0.5326094627380371
[20/24] Train loss=0.4752989411354065
Test set avg_accuracy=63.62% avg_sensitivity=47.11%, avg_specificity=69.87% avg_auc=61.30%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.481157 Test loss=0.653993 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4718191921710968
[5/24] Train loss=0.4864414930343628
[10/24] Train loss=0.5296177268028259
[15/24] Train loss=0.5180987119674683
[20/24] Train loss=0.4730980694293976
Test set avg_accuracy=67.37% avg_sensitivity=46.54%, avg_specificity=75.26% avg_auc=64.47%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.477919 Test loss=0.640953 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.46537038683891296
[5/24] Train loss=0.47770270705223083
[10/24] Train loss=0.5435709953308105
[15/24] Train loss=0.5215649604797363
[20/24] Train loss=0.47313469648361206
Test set avg_accuracy=64.95% avg_sensitivity=48.15%, avg_specificity=71.31% avg_auc=63.09%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.475072 Test loss=0.647743 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.46283724904060364
[5/24] Train loss=0.4767247438430786
[10/24] Train loss=0.5378445982933044
[15/24] Train loss=0.5226976871490479
[20/24] Train loss=0.46791961789131165
Test set avg_accuracy=60.55% avg_sensitivity=50.33%, avg_specificity=64.42% avg_auc=60.47%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.475244 Test loss=0.662434 Current lr=[0.000210185142098938]

[0/24] Train loss=0.46931931376457214
[5/24] Train loss=0.4881868064403534
[10/24] Train loss=0.5327772498130798
[15/24] Train loss=0.5234035849571228
[20/24] Train loss=0.472726970911026
Test set avg_accuracy=68.66% avg_sensitivity=45.02%, avg_specificity=77.61% avg_auc=64.68%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.476955 Test loss=0.637365 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.46357566118240356
[5/24] Train loss=0.47658205032348633
[10/24] Train loss=0.5371109247207642
[15/24] Train loss=0.5196967124938965
[20/24] Train loss=0.46942371129989624
Test set avg_accuracy=64.78% avg_sensitivity=50.62%, avg_specificity=70.14% avg_auc=64.73%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.473437 Test loss=0.648075 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4664440155029297
[5/24] Train loss=0.48640304803848267
[10/24] Train loss=0.5395729541778564
[15/24] Train loss=0.5193724036216736
[20/24] Train loss=0.4852716624736786
Test set avg_accuracy=72.86% avg_sensitivity=39.67%, avg_specificity=85.44% avg_auc=68.53%
Best model saved!! Metric=-59.5021621804635!!
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.475029 Test loss=0.620634 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.47169050574302673
[5/24] Train loss=0.47839805483818054
[10/24] Train loss=0.5502134561538696
[15/24] Train loss=0.5216930508613586
[20/24] Train loss=0.4647314250469208
Test set avg_accuracy=63.02% avg_sensitivity=50.09%, avg_specificity=67.92% avg_auc=62.44%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.476424 Test loss=0.655177 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.46233630180358887
[5/24] Train loss=0.47261282801628113
[10/24] Train loss=0.5362844467163086
[15/24] Train loss=0.5186125040054321
[20/24] Train loss=0.45749983191490173
Test set avg_accuracy=58.18% avg_sensitivity=54.64%, avg_specificity=59.52% avg_auc=60.90%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.468477 Test loss=0.669914 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.45324239134788513
[5/24] Train loss=0.4717906415462494
[10/24] Train loss=0.5275387167930603
[15/24] Train loss=0.5167534947395325
[20/24] Train loss=0.46243441104888916
Test set avg_accuracy=58.78% avg_sensitivity=54.55%, avg_specificity=60.38% avg_auc=61.34%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.469719 Test loss=0.669405 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.45408153533935547
[5/24] Train loss=0.46941742300987244
[10/24] Train loss=0.5376545190811157
[15/24] Train loss=0.530606210231781
[20/24] Train loss=0.4826451241970062
Test set avg_accuracy=60.85% avg_sensitivity=52.56%, avg_specificity=63.99% avg_auc=62.54%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.470313 Test loss=0.661692 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.47367605566978455
[5/24] Train loss=0.472607284784317
[10/24] Train loss=0.5345407128334045
[15/24] Train loss=0.5161224603652954
[20/24] Train loss=0.46192097663879395
Test set avg_accuracy=65.18% avg_sensitivity=48.48%, avg_specificity=71.51% avg_auc=65.08%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.471003 Test loss=0.643170 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4630129933357239
[5/24] Train loss=0.470939576625824
[10/24] Train loss=0.5304353833198547
[15/24] Train loss=0.5097283720970154
[20/24] Train loss=0.4579532742500305
Test set avg_accuracy=57.49% avg_sensitivity=56.21%, avg_specificity=57.97% avg_auc=61.93%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.465479 Test loss=0.673606 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4492368996143341
[5/24] Train loss=0.4703297019004822
[10/24] Train loss=0.5340949892997742
[15/24] Train loss=0.5079705715179443
[20/24] Train loss=0.4569178819656372
Test set avg_accuracy=62.17% avg_sensitivity=52.99%, avg_specificity=65.66% avg_auc=64.41%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.464668 Test loss=0.653633 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4568941593170166
[5/24] Train loss=0.4664820730686188
[10/24] Train loss=0.5189365744590759
[15/24] Train loss=0.5238524675369263
[20/24] Train loss=0.45668986439704895
Test set avg_accuracy=70.64% avg_sensitivity=44.88%, avg_specificity=80.39% avg_auc=69.24%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.465567 Test loss=0.619730 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.45168739557266235
[5/24] Train loss=0.47085338830947876
[10/24] Train loss=0.5460762977600098
[15/24] Train loss=0.5108667016029358
[20/24] Train loss=0.4639755189418793
Test set avg_accuracy=67.88% avg_sensitivity=47.39%, avg_specificity=75.64% avg_auc=67.20%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.468985 Test loss=0.635010 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4641262888908386
[5/24] Train loss=0.47492340207099915
[10/24] Train loss=0.5254203677177429
[15/24] Train loss=0.5048494338989258
[20/24] Train loss=0.45610690116882324
Test set avg_accuracy=55.30% avg_sensitivity=56.78%, avg_specificity=54.74% avg_auc=60.22%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.467810 Test loss=0.681399 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.45116040110588074
[5/24] Train loss=0.4723950922489166
[10/24] Train loss=0.5363602042198181
[15/24] Train loss=0.508246123790741
[20/24] Train loss=0.45928406715393066
Test set avg_accuracy=57.89% avg_sensitivity=55.92%, avg_specificity=58.64% avg_auc=62.43%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.468148 Test loss=0.672967 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.45079922676086426
[5/24] Train loss=0.4715884029865265
[10/24] Train loss=0.5352268218994141
[15/24] Train loss=0.5187942981719971
[20/24] Train loss=0.45831626653671265
Test set avg_accuracy=62.17% avg_sensitivity=52.42%, avg_specificity=65.87% avg_auc=64.34%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.468698 Test loss=0.654171 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4470592141151428
[5/24] Train loss=0.4759778678417206
[10/24] Train loss=0.5451779365539551
[15/24] Train loss=0.5065740346908569
[20/24] Train loss=0.45523104071617126
Test set avg_accuracy=62.01% avg_sensitivity=53.98%, avg_specificity=65.04% avg_auc=64.68%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.466685 Test loss=0.656155 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4550667703151703
[5/24] Train loss=0.4759272038936615
[10/24] Train loss=0.5250009298324585
[15/24] Train loss=0.5062654614448547
[20/24] Train loss=0.4551503658294678
Test set avg_accuracy=61.54% avg_sensitivity=54.03%, avg_specificity=64.38% avg_auc=64.18%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.466781 Test loss=0.659291 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.45513206720352173
[5/24] Train loss=0.47115200757980347
[10/24] Train loss=0.5244088172912598
[15/24] Train loss=0.5028519034385681
[20/24] Train loss=0.45516130328178406
Test set avg_accuracy=62.64% avg_sensitivity=53.32%, avg_specificity=66.18% avg_auc=65.16%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.466446 Test loss=0.652529 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.45421481132507324
[5/24] Train loss=0.46966370940208435
[10/24] Train loss=0.5389258861541748
[15/24] Train loss=0.5160823464393616
[20/24] Train loss=0.48708122968673706
Test set avg_accuracy=71.86% avg_sensitivity=43.41%, avg_specificity=82.64% avg_auc=68.89%
Best model saved!! Metric=-59.19315284555179!!
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.474771 Test loss=0.626960 Current lr=[0.000299720220882401]

[0/24] Train loss=0.46169382333755493
[5/24] Train loss=0.4766671657562256
[10/24] Train loss=0.5299428701400757
[15/24] Train loss=0.521848201751709
[20/24] Train loss=0.46145766973495483
Test set avg_accuracy=66.25% avg_sensitivity=51.23%, avg_specificity=71.94% avg_auc=67.15%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.471590 Test loss=0.644790 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.4599809944629669
[5/24] Train loss=0.47223982214927673
[10/24] Train loss=0.521370530128479
[15/24] Train loss=0.5104221701622009
[20/24] Train loss=0.4582357108592987
Test set avg_accuracy=58.32% avg_sensitivity=55.59%, avg_specificity=59.35% avg_auc=62.07%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.466580 Test loss=0.671560 Current lr=[0.000298904600941902]

[0/24] Train loss=0.459720253944397
[5/24] Train loss=0.4731801450252533
[10/24] Train loss=0.5353158712387085
[15/24] Train loss=0.5108928084373474
[20/24] Train loss=0.44966810941696167
Test set avg_accuracy=61.33% avg_sensitivity=54.55%, avg_specificity=63.90% avg_auc=64.43%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.463999 Test loss=0.657074 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.4526211619377136
[5/24] Train loss=0.4675478935241699
[10/24] Train loss=0.5263878703117371
[15/24] Train loss=0.507917582988739
[20/24] Train loss=0.45258206129074097
Test set avg_accuracy=62.92% avg_sensitivity=53.41%, avg_specificity=66.52% avg_auc=65.77%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.462617 Test loss=0.647770 Current lr=[0.000297555943323901]

[0/24] Train loss=0.45097991824150085
[5/24] Train loss=0.4725009500980377
[10/24] Train loss=0.5268000364303589
[15/24] Train loss=0.5043637752532959
[20/24] Train loss=0.45153874158859253
Test set avg_accuracy=61.09% avg_sensitivity=54.31%, avg_specificity=63.66% avg_auc=64.57%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.463051 Test loss=0.655989 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.4522782266139984
[5/24] Train loss=0.4675794839859009
[10/24] Train loss=0.5333150625228882
[15/24] Train loss=0.5162023901939392
[20/24] Train loss=0.4568266272544861
Test set avg_accuracy=63.36% avg_sensitivity=52.27%, avg_specificity=67.56% avg_auc=65.38%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.464770 Test loss=0.651421 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.4700011909008026
[5/24] Train loss=0.4730782210826874
[10/24] Train loss=0.5441374778747559
[15/24] Train loss=0.5109664797782898
[20/24] Train loss=0.4545081555843353
Test set avg_accuracy=65.86% avg_sensitivity=49.62%, avg_specificity=72.01% avg_auc=67.64%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.468206 Test loss=0.632902 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.4517824351787567
[5/24] Train loss=0.4683912694454193
[10/24] Train loss=0.5323854684829712
[15/24] Train loss=0.5183039903640747
[20/24] Train loss=0.45863431692123413
Test set avg_accuracy=63.27% avg_sensitivity=52.51%, avg_specificity=67.34% avg_auc=65.70%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.466189 Test loss=0.647229 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.4539298713207245
[5/24] Train loss=0.4699069559574127
[10/24] Train loss=0.5349357724189758
[15/24] Train loss=0.5158918499946594
[20/24] Train loss=0.4534217417240143
Test set avg_accuracy=64.35% avg_sensitivity=52.61%, avg_specificity=68.80% avg_auc=67.11%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.464387 Test loss=0.641022 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.4511934518814087
[5/24] Train loss=0.47307461500167847
[10/24] Train loss=0.5333966612815857
[15/24] Train loss=0.5098983645439148
[20/24] Train loss=0.4493228495121002
Test set avg_accuracy=61.56% avg_sensitivity=54.36%, avg_specificity=64.29% avg_auc=65.25%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.464606 Test loss=0.653417 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.4506676197052002
[5/24] Train loss=0.4697955548763275
[10/24] Train loss=0.5338191986083984
[15/24] Train loss=0.5131852626800537
[20/24] Train loss=0.449535608291626
Test set avg_accuracy=61.08% avg_sensitivity=54.31%, avg_specificity=63.64% avg_auc=64.80%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.464077 Test loss=0.655388 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.4484769403934479
[5/24] Train loss=0.47578057646751404
[10/24] Train loss=0.5226873755455017
[15/24] Train loss=0.5063177347183228
[20/24] Train loss=0.4523670971393585
Test set avg_accuracy=62.34% avg_sensitivity=53.89%, avg_specificity=65.55% avg_auc=65.68%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.465811 Test loss=0.651122 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.4511924386024475
[5/24] Train loss=0.47083231806755066
[10/24] Train loss=0.5242379903793335
[15/24] Train loss=0.5130762457847595
[20/24] Train loss=0.45110297203063965
Test set avg_accuracy=62.06% avg_sensitivity=54.50%, avg_specificity=64.92% avg_auc=65.93%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.463708 Test loss=0.651205 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.45084184408187866
[5/24] Train loss=0.48192375898361206
[10/24] Train loss=0.52146315574646
[15/24] Train loss=0.5023261308670044
[20/24] Train loss=0.4512813687324524
Test set avg_accuracy=64.41% avg_sensitivity=52.27%, avg_specificity=69.01% avg_auc=67.02%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.466175 Test loss=0.639670 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.4491274952888489
[5/24] Train loss=0.4715477228164673
[10/24] Train loss=0.5280112028121948
[15/24] Train loss=0.5060427784919739
[20/24] Train loss=0.4565109610557556
Test set avg_accuracy=59.02% avg_sensitivity=56.26%, avg_specificity=60.07% avg_auc=63.55%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.464911 Test loss=0.666253 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.45331573486328125
[5/24] Train loss=0.4750387668609619
[10/24] Train loss=0.5185090899467468
[15/24] Train loss=0.5030591487884521
[20/24] Train loss=0.4512728750705719
Test set avg_accuracy=65.76% avg_sensitivity=51.33%, avg_specificity=71.22% avg_auc=67.48%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.463365 Test loss=0.632920 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.4511971175670624
[5/24] Train loss=0.4654521644115448
[10/24] Train loss=0.5265696048736572
[15/24] Train loss=0.5010278224945068
[20/24] Train loss=0.4491972327232361
Test set avg_accuracy=58.78% avg_sensitivity=56.07%, avg_specificity=59.80% avg_auc=63.39%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.459962 Test loss=0.667140 Current lr=[0.000276307469034998]

[0/24] Train loss=0.4485355019569397
[5/24] Train loss=0.467088907957077
[10/24] Train loss=0.5267089009284973
[15/24] Train loss=0.5246676206588745
[20/24] Train loss=0.45064476132392883
Test set avg_accuracy=63.57% avg_sensitivity=53.03%, avg_specificity=67.56% avg_auc=66.87%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.460645 Test loss=0.640009 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.4509108066558838
[5/24] Train loss=0.4731593132019043
[10/24] Train loss=0.5526542663574219
[15/24] Train loss=0.5223004817962646
[20/24] Train loss=0.4541535973548889
Test set avg_accuracy=66.56% avg_sensitivity=50.95%, avg_specificity=72.48% avg_auc=68.69%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.464028 Test loss=0.626525 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.45835286378860474
[5/24] Train loss=0.47090402245521545
[10/24] Train loss=0.5399283170700073
[15/24] Train loss=0.5115901827812195
[20/24] Train loss=0.4504653811454773
Test set avg_accuracy=62.23% avg_sensitivity=54.17%, avg_specificity=65.28% avg_auc=66.30%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.462211 Test loss=0.646145 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.4488324224948883
[5/24] Train loss=0.46785280108451843
[10/24] Train loss=0.5403235554695129
[15/24] Train loss=0.5180959701538086
[20/24] Train loss=0.45668235421180725
Test set avg_accuracy=68.49% avg_sensitivity=48.25%, avg_specificity=76.16% avg_auc=69.34%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.463852 Test loss=0.616341 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4552935063838959
[5/24] Train loss=0.4713844656944275
[10/24] Train loss=0.5302338600158691
[15/24] Train loss=0.5077052712440491
[20/24] Train loss=0.44954556226730347
Test set avg_accuracy=59.95% avg_sensitivity=55.36%, avg_specificity=61.69% avg_auc=64.37%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.463171 Test loss=0.658610 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.4505573809146881
[5/24] Train loss=0.467288076877594
[10/24] Train loss=0.5257248878479004
[15/24] Train loss=0.5024991631507874
[20/24] Train loss=0.44815751910209656
Test set avg_accuracy=56.28% avg_sensitivity=57.63%, avg_specificity=55.76% avg_auc=61.40%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.460154 Test loss=0.680133 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.4481397271156311
[5/24] Train loss=0.47066760063171387
[10/24] Train loss=0.5501217842102051
[15/24] Train loss=0.5021790266036987
[20/24] Train loss=0.4499512016773224
Test set avg_accuracy=63.45% avg_sensitivity=53.36%, avg_specificity=67.27% avg_auc=66.95%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.462374 Test loss=0.638893 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.4500897228717804
[5/24] Train loss=0.4649413526058197
[10/24] Train loss=0.527312695980072
[15/24] Train loss=0.5024353861808777
[20/24] Train loss=0.44973403215408325
Test set avg_accuracy=60.38% avg_sensitivity=55.12%, avg_specificity=62.37% avg_auc=65.09%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.458545 Test loss=0.655345 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4459494948387146
[5/24] Train loss=0.46792173385620117
[10/24] Train loss=0.5221686959266663
[15/24] Train loss=0.4937830865383148
[20/24] Train loss=0.4459535479545593
Test set avg_accuracy=60.89% avg_sensitivity=54.79%, avg_specificity=63.20% avg_auc=65.33%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.458409 Test loss=0.651749 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.4438415765762329
[5/24] Train loss=0.46770286560058594
[10/24] Train loss=0.5289533138275146
[15/24] Train loss=0.5034279227256775
[20/24] Train loss=0.4479773938655853
Test set avg_accuracy=60.48% avg_sensitivity=55.59%, avg_specificity=62.33% avg_auc=65.67%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.457856 Test loss=0.655104 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.4466433525085449
[5/24] Train loss=0.4621855914592743
[10/24] Train loss=0.5347262620925903
[15/24] Train loss=0.5130512714385986
[20/24] Train loss=0.4528057873249054
Test set avg_accuracy=66.04% avg_sensitivity=51.14%, avg_specificity=71.69% avg_auc=68.49%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.459954 Test loss=0.625489 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.45431631803512573
[5/24] Train loss=0.46694549918174744
[10/24] Train loss=0.532665491104126
[15/24] Train loss=0.513156533241272
[20/24] Train loss=0.4453815817832947
Test set avg_accuracy=60.05% avg_sensitivity=55.88%, avg_specificity=61.63% avg_auc=65.05%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.459815 Test loss=0.656855 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.4488825798034668
[5/24] Train loss=0.4652252495288849
[10/24] Train loss=0.5221500396728516
[15/24] Train loss=0.5003597736358643
[20/24] Train loss=0.44514065980911255
Test set avg_accuracy=62.47% avg_sensitivity=53.89%, avg_specificity=65.73% avg_auc=66.54%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.461137 Test loss=0.640740 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.4468308985233307
[5/24] Train loss=0.46861204504966736
[10/24] Train loss=0.5195571184158325
[15/24] Train loss=0.5211450457572937
[20/24] Train loss=0.4477478861808777
Test set avg_accuracy=61.58% avg_sensitivity=54.93%, avg_specificity=64.09% avg_auc=66.06%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.460707 Test loss=0.648710 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.4471196234226227
[5/24] Train loss=0.46570906043052673
[10/24] Train loss=0.5172505378723145
[15/24] Train loss=0.5180343389511108
[20/24] Train loss=0.450599730014801
Test set avg_accuracy=58.82% avg_sensitivity=56.26%, avg_specificity=59.78% avg_auc=63.46%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.458624 Test loss=0.668449 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.45269739627838135
[5/24] Train loss=0.4675177037715912
[10/24] Train loss=0.5250478386878967
[15/24] Train loss=0.4983464777469635
[20/24] Train loss=0.44526252150535583
Test set avg_accuracy=60.09% avg_sensitivity=55.83%, avg_specificity=61.71% avg_auc=64.87%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.458691 Test loss=0.656052 Current lr=[0.000224838296036774]

[0/24] Train loss=0.44687700271606445
[5/24] Train loss=0.46408864855766296
[10/24] Train loss=0.5156363248825073
[15/24] Train loss=0.5051678419113159
[20/24] Train loss=0.4485759735107422
Test set avg_accuracy=58.16% avg_sensitivity=57.16%, avg_specificity=58.55% avg_auc=62.96%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.460115 Test loss=0.673625 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.4513137936592102
[5/24] Train loss=0.4657225012779236
[10/24] Train loss=0.5196992754936218
[15/24] Train loss=0.5025808215141296
[20/24] Train loss=0.4490337073802948
Test set avg_accuracy=60.78% avg_sensitivity=54.98%, avg_specificity=62.98% avg_auc=65.25%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.459361 Test loss=0.653461 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.45192912220954895
[5/24] Train loss=0.4625740349292755
[10/24] Train loss=0.5157727003097534
[15/24] Train loss=0.4995277523994446
[20/24] Train loss=0.4403791129589081
Test set avg_accuracy=62.07% avg_sensitivity=54.64%, avg_specificity=64.88% avg_auc=66.75%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.456699 Test loss=0.643083 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.44509974122047424
[5/24] Train loss=0.4600505530834198
[10/24] Train loss=0.5227489471435547
[15/24] Train loss=0.49173998832702637
[20/24] Train loss=0.4392385184764862
Test set avg_accuracy=60.90% avg_sensitivity=54.41%, avg_specificity=63.36% avg_auc=65.31%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.454498 Test loss=0.649747 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.4511839747428894
[5/24] Train loss=0.4573131799697876
[10/24] Train loss=0.5175837278366089
[15/24] Train loss=0.4947819411754608
[20/24] Train loss=0.44212788343429565
Test set avg_accuracy=58.31% avg_sensitivity=57.25%, avg_specificity=58.71% avg_auc=63.49%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.454368 Test loss=0.670648 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.445158451795578
[5/24] Train loss=0.45560452342033386
[10/24] Train loss=0.5432941317558289
[15/24] Train loss=0.4931505024433136
[20/24] Train loss=0.4404119551181793
Test set avg_accuracy=64.08% avg_sensitivity=52.99%, avg_specificity=68.28% avg_auc=67.79%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.456693 Test loss=0.631521 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.4457913339138031
[5/24] Train loss=0.46073082089424133
[10/24] Train loss=0.5244365334510803
[15/24] Train loss=0.5236259698867798
[20/24] Train loss=0.45113348960876465
Test set avg_accuracy=68.27% avg_sensitivity=46.11%, avg_specificity=76.66% avg_auc=69.24%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.462705 Test loss=0.610889 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.45817384123802185
[5/24] Train loss=0.4748919904232025
[10/24] Train loss=0.5243024230003357
[15/24] Train loss=0.49527767300605774
[20/24] Train loss=0.44881880283355713
Test set avg_accuracy=66.09% avg_sensitivity=50.00%, avg_specificity=72.19% avg_auc=68.86%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.463804 Test loss=0.626094 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.4481106996536255
[5/24] Train loss=0.46647945046424866
[10/24] Train loss=0.5127871632575989
[15/24] Train loss=0.49291732907295227
[20/24] Train loss=0.4398791193962097
Test set avg_accuracy=63.49% avg_sensitivity=54.17%, avg_specificity=67.02% avg_auc=67.59%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.456817 Test loss=0.635818 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.44295424222946167
[5/24] Train loss=0.4673028290271759
[10/24] Train loss=0.5123592615127563
[15/24] Train loss=0.490303635597229
[20/24] Train loss=0.446544885635376
Test set avg_accuracy=62.21% avg_sensitivity=54.36%, avg_specificity=65.19% avg_auc=66.87%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.456051 Test loss=0.641749 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.4475747048854828
[5/24] Train loss=0.45529770851135254
[10/24] Train loss=0.5188297033309937
[15/24] Train loss=0.518974244594574
[20/24] Train loss=0.4397311210632324
Test set avg_accuracy=64.61% avg_sensitivity=53.93%, avg_specificity=68.65% avg_auc=68.99%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.455662 Test loss=0.627072 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.4451022744178772
[5/24] Train loss=0.46066468954086304
[10/24] Train loss=0.52879798412323
[15/24] Train loss=0.5048549771308899
[20/24] Train loss=0.44158586859703064
Test set avg_accuracy=63.15% avg_sensitivity=54.31%, avg_specificity=66.50% avg_auc=67.74%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.456405 Test loss=0.637187 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.44531214237213135
[5/24] Train loss=0.45814546942710876
[10/24] Train loss=0.519459068775177
[15/24] Train loss=0.5052089691162109
[20/24] Train loss=0.4478716254234314
Test set avg_accuracy=64.83% avg_sensitivity=51.56%, avg_specificity=69.86% avg_auc=67.76%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.456649 Test loss=0.627191 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.44748803973197937
[5/24] Train loss=0.470960795879364
[10/24] Train loss=0.5212673544883728
[15/24] Train loss=0.4994373619556427
[20/24] Train loss=0.4458892345428467
Test set avg_accuracy=65.87% avg_sensitivity=49.76%, avg_specificity=71.97% avg_auc=68.67%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.457744 Test loss=0.620731 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.4470563530921936
[5/24] Train loss=0.45922502875328064
[10/24] Train loss=0.5297849178314209
[15/24] Train loss=0.48801881074905396
[20/24] Train loss=0.4415366053581238
Test set avg_accuracy=65.89% avg_sensitivity=50.38%, avg_specificity=71.76% avg_auc=69.00%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.456101 Test loss=0.617532 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.4468442499637604
[5/24] Train loss=0.459005206823349
[10/24] Train loss=0.5239416360855103
[15/24] Train loss=0.49206292629241943
[20/24] Train loss=0.4442310035228729
Test set avg_accuracy=68.14% avg_sensitivity=47.96%, avg_specificity=75.78% avg_auc=69.85%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.454864 Test loss=0.607667 Current lr=[0.000156543481933168]

[0/24] Train loss=0.44787365198135376
[5/24] Train loss=0.45598453283309937
[10/24] Train loss=0.5237959027290344
[15/24] Train loss=0.4913131296634674
[20/24] Train loss=0.43945008516311646
Test set avg_accuracy=67.46% avg_sensitivity=45.45%, avg_specificity=75.80% avg_auc=68.97%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.452652 Test loss=0.604227 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.4438495934009552
[5/24] Train loss=0.45570385456085205
[10/24] Train loss=0.5262174010276794
[15/24] Train loss=0.49387213587760925
[20/24] Train loss=0.44241803884506226
Test set avg_accuracy=66.90% avg_sensitivity=49.05%, avg_specificity=73.66% avg_auc=68.91%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.452643 Test loss=0.612737 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.4470694959163666
[5/24] Train loss=0.45671698451042175
[10/24] Train loss=0.5234469175338745
[15/24] Train loss=0.482026070356369
[20/24] Train loss=0.44066640734672546
Test set avg_accuracy=65.94% avg_sensitivity=48.01%, avg_specificity=72.73% avg_auc=68.05%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.452179 Test loss=0.614037 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.44121459126472473
[5/24] Train loss=0.45155808329582214
[10/24] Train loss=0.5249446034431458
[15/24] Train loss=0.48575010895729065
[20/24] Train loss=0.4396965503692627
Test set avg_accuracy=65.76% avg_sensitivity=49.00%, avg_specificity=72.10% avg_auc=68.12%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.450995 Test loss=0.615387 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.4397730827331543
[5/24] Train loss=0.45228591561317444
[10/24] Train loss=0.5218082070350647
[15/24] Train loss=0.49730297923088074
[20/24] Train loss=0.4436586797237396
Test set avg_accuracy=67.55% avg_sensitivity=47.68%, avg_specificity=75.08% avg_auc=69.66%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.451973 Test loss=0.603583 Current lr=[0.000134135431043539]

[0/24] Train loss=0.4419881999492645
[5/24] Train loss=0.45318275690078735
[10/24] Train loss=0.5232356190681458
[15/24] Train loss=0.4828052818775177
[20/24] Train loss=0.4362841546535492
Test set avg_accuracy=64.17% avg_sensitivity=50.24%, avg_specificity=69.44% avg_auc=67.14%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.448741 Test loss=0.623510 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.4363112151622772
[5/24] Train loss=0.45063576102256775
[10/24] Train loss=0.5229625105857849
[15/24] Train loss=0.49063730239868164
[20/24] Train loss=0.434845507144928
Test set avg_accuracy=63.58% avg_sensitivity=51.47%, avg_specificity=68.17% avg_auc=66.59%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.448433 Test loss=0.629864 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.43798527121543884
[5/24] Train loss=0.4554607570171356
[10/24] Train loss=0.5182879567146301
[15/24] Train loss=0.496509313583374
[20/24] Train loss=0.4482439160346985
Test set avg_accuracy=65.99% avg_sensitivity=48.20%, avg_specificity=72.73% avg_auc=67.68%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.452240 Test loss=0.618333 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.4471733272075653
[5/24] Train loss=0.45460766553878784
[10/24] Train loss=0.5209925174713135
[15/24] Train loss=0.48652803897857666
[20/24] Train loss=0.43845537304878235
Test set avg_accuracy=65.76% avg_sensitivity=49.00%, avg_specificity=72.10% avg_auc=68.08%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.452429 Test loss=0.616327 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.4370594322681427
[5/24] Train loss=0.4487196207046509
[10/24] Train loss=0.5212852954864502
[15/24] Train loss=0.48536768555641174
[20/24] Train loss=0.4345623552799225
Test set avg_accuracy=64.35% avg_sensitivity=50.85%, avg_specificity=69.46% avg_auc=67.69%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.447718 Test loss=0.620343 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.43549737334251404
[5/24] Train loss=0.4483800530433655
[10/24] Train loss=0.51915442943573
[15/24] Train loss=0.48243892192840576
[20/24] Train loss=0.43606242537498474
Test set avg_accuracy=63.31% avg_sensitivity=52.51%, avg_specificity=67.40% avg_auc=66.86%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.446794 Test loss=0.631844 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.43425247073173523
[5/24] Train loss=0.4476497769355774
[10/24] Train loss=0.5185866951942444
[15/24] Train loss=0.48603737354278564
[20/24] Train loss=0.4342745542526245
Test set avg_accuracy=62.97% avg_sensitivity=52.80%, avg_specificity=66.82% avg_auc=66.28%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.446675 Test loss=0.637123 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.4387214779853821
[5/24] Train loss=0.45004376769065857
[10/24] Train loss=0.5124942660331726
[15/24] Train loss=0.49833038449287415
[20/24] Train loss=0.44929423928260803
Test set avg_accuracy=63.50% avg_sensitivity=52.80%, avg_specificity=67.56% avg_auc=66.86%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.450025 Test loss=0.633447 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.4359346032142639
[5/24] Train loss=0.4539034068584442
[10/24] Train loss=0.5156444311141968
[15/24] Train loss=0.4856615662574768
[20/24] Train loss=0.43738052248954773
Test set avg_accuracy=65.51% avg_sensitivity=49.10%, avg_specificity=71.72% avg_auc=67.98%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.450517 Test loss=0.616975 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.4373566508293152
[5/24] Train loss=0.4500673711299896
[10/24] Train loss=0.5208406448364258
[15/24] Train loss=0.4848535656929016
[20/24] Train loss=0.4405513405799866
Test set avg_accuracy=63.06% avg_sensitivity=53.08%, avg_specificity=66.84% avg_auc=66.77%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.448262 Test loss=0.633449 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.4357490837574005
[5/24] Train loss=0.4513438045978546
[10/24] Train loss=0.512328028678894
[15/24] Train loss=0.4853138327598572
[20/24] Train loss=0.4342406094074249
Test set avg_accuracy=62.30% avg_sensitivity=53.03%, avg_specificity=65.82% avg_auc=66.08%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.447840 Test loss=0.638577 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.4368174970149994
[5/24] Train loss=0.4482824206352234
[10/24] Train loss=0.5157398581504822
[15/24] Train loss=0.49577710032463074
[20/24] Train loss=0.43319183588027954
Test set avg_accuracy=62.41% avg_sensitivity=53.36%, avg_specificity=65.83% avg_auc=66.39%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.447693 Test loss=0.639102 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.44428738951683044
[5/24] Train loss=0.4504184424877167
[10/24] Train loss=0.5128548741340637
[15/24] Train loss=0.4785931408405304
[20/24] Train loss=0.43628478050231934
Test set avg_accuracy=62.28% avg_sensitivity=54.41%, avg_specificity=65.26% avg_auc=66.37%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.447468 Test loss=0.640925 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.43422460556030273
[5/24] Train loss=0.44745275378227234
[10/24] Train loss=0.5120816230773926
[15/24] Train loss=0.4792943000793457
[20/24] Train loss=0.4356275796890259
Test set avg_accuracy=62.76% avg_sensitivity=53.32%, avg_specificity=66.34% avg_auc=66.63%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.445050 Test loss=0.635639 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.4335283041000366
[5/24] Train loss=0.44681239128112793
[10/24] Train loss=0.5145617127418518
[15/24] Train loss=0.4749414026737213
[20/24] Train loss=0.4321184456348419
Test set avg_accuracy=62.99% avg_sensitivity=52.42%, avg_specificity=67.00% avg_auc=66.34%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.444085 Test loss=0.634293 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.43177175521850586
[5/24] Train loss=0.4432840049266815
[10/24] Train loss=0.5105671286582947
[15/24] Train loss=0.47785428166389465
[20/24] Train loss=0.43198972940444946
Test set avg_accuracy=61.86% avg_sensitivity=54.74%, avg_specificity=64.56% avg_auc=65.70%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.443488 Test loss=0.647691 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.4351218640804291
[5/24] Train loss=0.4453951120376587
[10/24] Train loss=0.5101163387298584
[15/24] Train loss=0.4763037860393524
[20/24] Train loss=0.4346453547477722
Test set avg_accuracy=62.49% avg_sensitivity=53.65%, avg_specificity=65.83% avg_auc=66.06%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.445116 Test loss=0.641842 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.4330707788467407
[5/24] Train loss=0.44387704133987427
[10/24] Train loss=0.5107004046440125
[15/24] Train loss=0.4783306121826172
[20/24] Train loss=0.4318273663520813
Test set avg_accuracy=62.16% avg_sensitivity=54.17%, avg_specificity=65.19% avg_auc=65.81%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.443487 Test loss=0.645193 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.43207162618637085
[5/24] Train loss=0.4429185688495636
[10/24] Train loss=0.5110511183738708
[15/24] Train loss=0.4713818430900574
[20/24] Train loss=0.4299868047237396
Test set avg_accuracy=62.23% avg_sensitivity=54.22%, avg_specificity=65.26% avg_auc=65.89%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.442466 Test loss=0.643658 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.43111059069633484
[5/24] Train loss=0.4422523081302643
[10/24] Train loss=0.5079917907714844
[15/24] Train loss=0.4758751690387726
[20/24] Train loss=0.43138742446899414
Test set avg_accuracy=62.25% avg_sensitivity=55.45%, avg_specificity=64.83% avg_auc=66.11%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.442449 Test loss=0.645422 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.43102267384529114
[5/24] Train loss=0.44515174627304077
[10/24] Train loss=0.508539617061615
[15/24] Train loss=0.47601255774497986
[20/24] Train loss=0.43007606267929077
Test set avg_accuracy=61.63% avg_sensitivity=55.45%, avg_specificity=63.97% avg_auc=65.25%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.442595 Test loss=0.652789 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.43102872371673584
[5/24] Train loss=0.441455215215683
[10/24] Train loss=0.5097901821136475
[15/24] Train loss=0.49243536591529846
[20/24] Train loss=0.43531566858291626
Test set avg_accuracy=61.51% avg_sensitivity=55.31%, avg_specificity=63.86% avg_auc=65.20%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.443638 Test loss=0.653389 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.4335139989852905
[5/24] Train loss=0.44414451718330383
[10/24] Train loss=0.505107045173645
[15/24] Train loss=0.48341286182403564
[20/24] Train loss=0.4314191937446594
Test set avg_accuracy=61.64% avg_sensitivity=57.25%, avg_specificity=63.30% avg_auc=65.89%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.444892 Test loss=0.652452 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.43045753240585327
[5/24] Train loss=0.4463666081428528
[10/24] Train loss=0.508524477481842
[15/24] Train loss=0.47804588079452515
[20/24] Train loss=0.4322335124015808
Test set avg_accuracy=62.67% avg_sensitivity=52.89%, avg_specificity=66.37% avg_auc=66.21%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.443381 Test loss=0.636805 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.43022048473358154
[5/24] Train loss=0.44202274084091187
[10/24] Train loss=0.5071654915809631
[15/24] Train loss=0.47220292687416077
[20/24] Train loss=0.4301413297653198
Test set avg_accuracy=61.55% avg_sensitivity=56.82%, avg_specificity=63.34% avg_auc=65.70%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.442144 Test loss=0.652701 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.42978301644325256
[5/24] Train loss=0.4427030384540558
[10/24] Train loss=0.5072458386421204
[15/24] Train loss=0.4758574962615967
[20/24] Train loss=0.42965802550315857
Test set avg_accuracy=61.35% avg_sensitivity=57.30%, avg_specificity=62.89% avg_auc=65.44%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.443047 Test loss=0.656145 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.4298837184906006
[5/24] Train loss=0.4455137848854065
[10/24] Train loss=0.5088351368904114
[15/24] Train loss=0.48823222517967224
[20/24] Train loss=0.4294719994068146
Test set avg_accuracy=62.32% avg_sensitivity=54.45%, avg_specificity=65.30% avg_auc=66.33%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.442677 Test loss=0.639800 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.43205568194389343
[5/24] Train loss=0.443512499332428
[10/24] Train loss=0.5076841115951538
[15/24] Train loss=0.4730032980442047
[20/24] Train loss=0.4312494993209839
Test set avg_accuracy=61.63% avg_sensitivity=56.26%, avg_specificity=63.66% avg_auc=65.38%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.442340 Test loss=0.653271 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.43197792768478394
[5/24] Train loss=0.44114699959754944
[10/24] Train loss=0.5066238641738892
[15/24] Train loss=0.474213182926178
[20/24] Train loss=0.43031787872314453
Test set avg_accuracy=61.60% avg_sensitivity=57.06%, avg_specificity=63.32% avg_auc=65.64%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.441848 Test loss=0.653150 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.4300495684146881
[5/24] Train loss=0.4442385137081146
[10/24] Train loss=0.5117237567901611
[15/24] Train loss=0.46924450993537903
[20/24] Train loss=0.4308260381221771
Test set avg_accuracy=61.35% avg_sensitivity=56.87%, avg_specificity=63.05% avg_auc=65.39%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.441741 Test loss=0.655053 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.4302230477333069
[5/24] Train loss=0.44125494360923767
[10/24] Train loss=0.5104374885559082
[15/24] Train loss=0.4699326455593109
[20/24] Train loss=0.4293997883796692
Test set avg_accuracy=61.63% avg_sensitivity=56.07%, avg_specificity=63.73% avg_auc=65.65%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.440989 Test loss=0.651189 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.43087756633758545
[5/24] Train loss=0.44030848145484924
[10/24] Train loss=0.5105135440826416
[15/24] Train loss=0.4687119722366333
[20/24] Train loss=0.42866548895835876
Test set avg_accuracy=61.60% avg_sensitivity=56.45%, avg_specificity=63.55% avg_auc=65.56%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.440401 Test loss=0.652480 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.4287067651748657
[5/24] Train loss=0.439627468585968
[10/24] Train loss=0.5073262453079224
[15/24] Train loss=0.466749906539917
[20/24] Train loss=0.42882534861564636
Test set avg_accuracy=61.45% avg_sensitivity=56.78%, avg_specificity=63.21% avg_auc=65.35%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.439558 Test loss=0.655351 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.42861759662628174
[5/24] Train loss=0.4393797218799591
[10/24] Train loss=0.5079416036605835
[15/24] Train loss=0.46540018916130066
[20/24] Train loss=0.42815303802490234
Test set avg_accuracy=61.32% avg_sensitivity=57.20%, avg_specificity=62.87% avg_auc=65.31%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.439235 Test loss=0.656928 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.4282490611076355
[5/24] Train loss=0.43917033076286316
[10/24] Train loss=0.5077627897262573
[15/24] Train loss=0.4652020335197449
[20/24] Train loss=0.4280192255973816
Test set avg_accuracy=61.22% avg_sensitivity=57.35%, avg_specificity=62.69% avg_auc=65.28%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.439003 Test loss=0.657441 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.4280664622783661
[5/24] Train loss=0.4390786290168762
[10/24] Train loss=0.5073240399360657
[15/24] Train loss=0.4650694727897644
[20/24] Train loss=0.4278251826763153
Test set avg_accuracy=61.15% avg_sensitivity=57.63%, avg_specificity=62.48% avg_auc=65.24%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.438850 Test loss=0.658248 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.42785486578941345
[5/24] Train loss=0.43903690576553345
[10/24] Train loss=0.5071480870246887
[15/24] Train loss=0.46484777331352234
[20/24] Train loss=0.427693247795105
Test set avg_accuracy=60.99% avg_sensitivity=57.87%, avg_specificity=62.17% avg_auc=65.20%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.438737 Test loss=0.659074 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.4277401864528656
[5/24] Train loss=0.4389325976371765
[10/24] Train loss=0.5069242715835571
[15/24] Train loss=0.4646880030632019
[20/24] Train loss=0.42759186029434204
Test set avg_accuracy=60.92% avg_sensitivity=58.01%, avg_specificity=62.03% avg_auc=65.18%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.438631 Test loss=0.659563 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.42761749029159546
[5/24] Train loss=0.43886205554008484
[10/24] Train loss=0.5067470669746399
[15/24] Train loss=0.46459314227104187
[20/24] Train loss=0.42752671241760254
Test set avg_accuracy=60.76% avg_sensitivity=58.01%, avg_specificity=61.80% avg_auc=65.15%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.438544 Test loss=0.659987 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.4275265038013458
[5/24] Train loss=0.43879565596580505
[10/24] Train loss=0.5066277384757996
[15/24] Train loss=0.4644981622695923
[20/24] Train loss=0.4274640679359436
Test set avg_accuracy=60.72% avg_sensitivity=58.01%, avg_specificity=61.74% avg_auc=65.14%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.438470 Test loss=0.660313 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.42745038866996765
[5/24] Train loss=0.43875887989997864
[10/24] Train loss=0.5064729452133179
[15/24] Train loss=0.4644066393375397
[20/24] Train loss=0.42739439010620117
Test set avg_accuracy=60.70% avg_sensitivity=58.10%, avg_specificity=61.69% avg_auc=65.12%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.438407 Test loss=0.660611 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.42738866806030273
[5/24] Train loss=0.43872159719467163
[10/24] Train loss=0.5063984990119934
[15/24] Train loss=0.46431341767311096
[20/24] Train loss=0.4273518919944763
Test set avg_accuracy=60.65% avg_sensitivity=58.10%, avg_specificity=61.62% avg_auc=65.12%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.438355 Test loss=0.660841 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.42733266949653625
[5/24] Train loss=0.43868759274482727
[10/24] Train loss=0.5063199996948242
[15/24] Train loss=0.46427443623542786
[20/24] Train loss=0.42731261253356934
Test set avg_accuracy=60.65% avg_sensitivity=58.10%, avg_specificity=61.62% avg_auc=65.11%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.438314 Test loss=0.661016 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.4272978901863098
[5/24] Train loss=0.438661128282547
[10/24] Train loss=0.5062581896781921
[15/24] Train loss=0.4642315208911896
[20/24] Train loss=0.4272829592227936
Test set avg_accuracy=60.65% avg_sensitivity=58.20%, avg_specificity=61.58% avg_auc=65.10%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.438281 Test loss=0.661150 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.42726582288742065
[5/24] Train loss=0.43864449858665466
[10/24] Train loss=0.5062159299850464
[15/24] Train loss=0.4641948342323303
[20/24] Train loss=0.4272627830505371
Test set avg_accuracy=60.64% avg_sensitivity=58.20%, avg_specificity=61.56% avg_auc=65.10%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.438258 Test loss=0.661249 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.42724767327308655
[5/24] Train loss=0.4386301636695862
[10/24] Train loss=0.5061837434768677
[15/24] Train loss=0.46416977047920227
[20/24] Train loss=0.427250474691391
Test set avg_accuracy=60.61% avg_sensitivity=58.20%, avg_specificity=61.53% avg_auc=65.10%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.438242 Test loss=0.661311 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.42723479866981506
[5/24] Train loss=0.4386201798915863
[10/24] Train loss=0.5061659216880798
[15/24] Train loss=0.4641551077365875
[20/24] Train loss=0.4272438883781433
Test set avg_accuracy=60.62% avg_sensitivity=58.25%, avg_specificity=61.53% avg_auc=65.10%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.438232 Test loss=0.661342 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.4272267818450928
[5/24] Train loss=0.43861475586891174
[10/24] Train loss=0.5061547756195068
[15/24] Train loss=0.46414655447006226
[20/24] Train loss=0.4272406995296478
Test set avg_accuracy=60.62% avg_sensitivity=58.25%, avg_specificity=61.53% avg_auc=65.09%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.438227 Test loss=0.661356 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.4272231459617615
[5/24] Train loss=0.43861231207847595
[10/24] Train loss=0.5061495304107666
[15/24] Train loss=0.46414339542388916
[20/24] Train loss=0.4272400140762329
Test set avg_accuracy=60.62% avg_sensitivity=58.25%, avg_specificity=61.53% avg_auc=65.09%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.438225 Test loss=0.661360 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=71.86% sen=43.41%, spe=82.64%, auc=68.89%!
Fold[3] Avg_overlap=0.19%(±0.23254896672560502)
[0/24] Train loss=0.7029736638069153
[5/24] Train loss=0.7020360827445984
[10/24] Train loss=0.6995874047279358
[15/24] Train loss=0.6978639364242554
[20/24] Train loss=0.6984338760375977
Test set avg_accuracy=51.46% avg_sensitivity=47.93%, avg_specificity=52.70% avg_auc=50.53%
Best model saved!! Metric=-123.38124142058219!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.699513 Test loss=0.697017 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6976032853126526
[5/24] Train loss=0.6965892314910889
[10/24] Train loss=0.6950407028198242
[15/24] Train loss=0.693782389163971
[20/24] Train loss=0.6941249966621399
Test set avg_accuracy=54.60% avg_sensitivity=41.63%, avg_specificity=59.17% avg_auc=50.54%
Best model saved!! Metric=-120.06525885496127!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.694737 Test loss=0.692759 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6932234764099121
[5/24] Train loss=0.6921064257621765
[10/24] Train loss=0.6911876797676086
[15/24] Train loss=0.6902015805244446
[20/24] Train loss=0.6902238130569458
Test set avg_accuracy=55.00% avg_sensitivity=40.48%, avg_specificity=60.12% avg_auc=50.72%
Best model saved!! Metric=-119.68573813111053!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.690609 Test loss=0.688791 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6890818476676941
[5/24] Train loss=0.6877385973930359
[10/24] Train loss=0.6874195337295532
[15/24] Train loss=0.6867066025733948
[20/24] Train loss=0.6863397359848022
Test set avg_accuracy=55.10% avg_sensitivity=39.73%, avg_specificity=60.52% avg_auc=50.75%
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.686567 Test loss=0.684887 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6849683523178101
[5/24] Train loss=0.6833910942077637
[10/24] Train loss=0.6837568283081055
[15/24] Train loss=0.6830847263336182
[20/24] Train loss=0.6824606657028198
Test set avg_accuracy=58.01% avg_sensitivity=33.78%, avg_specificity=66.54% avg_auc=50.78%
Best model saved!! Metric=-116.88250286353677!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.682534 Test loss=0.680877 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6809117197990417
[5/24] Train loss=0.6788159608840942
[10/24] Train loss=0.6798245310783386
[15/24] Train loss=0.6790207028388977
[20/24] Train loss=0.6777833700180054
Test set avg_accuracy=58.19% avg_sensitivity=32.73%, avg_specificity=67.16% avg_auc=50.81%
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.678034 Test loss=0.675905 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6758018732070923
[5/24] Train loss=0.6729514002799988
[10/24] Train loss=0.6746214628219604
[15/24] Train loss=0.6735703945159912
[20/24] Train loss=0.6715695858001709
Test set avg_accuracy=67.01% avg_sensitivity=15.89%, avg_specificity=85.01% avg_auc=50.55%
Best model saved!! Metric=-107.53575274098074!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.672094 Test loss=0.669426 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6692214012145996
[5/24] Train loss=0.6650221347808838
[10/24] Train loss=0.6678460836410522
[15/24] Train loss=0.6663238406181335
[20/24] Train loss=0.6631935238838196
Test set avg_accuracy=67.29% avg_sensitivity=14.54%, avg_specificity=85.88% avg_auc=50.51%
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.664243 Test loss=0.660694 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.660374104976654
[5/24] Train loss=0.6541419625282288
[10/24] Train loss=0.6583806872367859
[15/24] Train loss=0.656095564365387
[20/24] Train loss=0.6505709886550903
Test set avg_accuracy=67.38% avg_sensitivity=13.84%, avg_specificity=86.25% avg_auc=50.60%
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.653075 Test loss=0.647307 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6468093991279602
[5/24] Train loss=0.6369181275367737
[10/24] Train loss=0.6433817148208618
[15/24] Train loss=0.6401079297065735
[20/24] Train loss=0.631412148475647
Test set avg_accuracy=73.76% avg_sensitivity=1.55%, avg_specificity=99.21% avg_auc=50.88%
Best model saved!! Metric=-100.60219170038923!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.635660 Test loss=0.627323 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6266605854034424
[5/24] Train loss=0.6113374829292297
[10/24] Train loss=0.6229484677314758
[15/24] Train loss=0.618876576423645
[20/24] Train loss=0.6063917279243469
Test set avg_accuracy=73.80% avg_sensitivity=0.35%, avg_specificity=99.68% avg_auc=51.77%
Best model saved!! Metric=-100.39720582293376!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.611458 Test loss=0.601878 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6009165048599243
[5/24] Train loss=0.5791563987731934
[10/24] Train loss=0.6019579768180847
[15/24] Train loss=0.5972753763198853
[20/24] Train loss=0.5829308032989502
Test set avg_accuracy=73.96% avg_sensitivity=0.10%, avg_specificity=99.98% avg_auc=52.83%
Best model saved!! Metric=-99.12698560255001!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.584843 Test loss=0.579518 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5787056088447571
[5/24] Train loss=0.5521954894065857
[10/24] Train loss=0.5935462713241577
[15/24] Train loss=0.5859583616256714
[20/24] Train loss=0.5719752311706543
Test set avg_accuracy=73.98% avg_sensitivity=0.15%, avg_specificity=100.00% avg_auc=55.71%
Best model saved!! Metric=-96.15261619800901!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.568452 Test loss=0.570390 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5698769092559814
[5/24] Train loss=0.5436670184135437
[10/24] Train loss=0.5910668969154358
[15/24] Train loss=0.5834295749664307
[20/24] Train loss=0.5674968957901001
Test set avg_accuracy=73.97% avg_sensitivity=0.15%, avg_specificity=99.98% avg_auc=58.16%
Best model saved!! Metric=-93.73971493340206!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.563515 Test loss=0.567732 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5668393969535828
[5/24] Train loss=0.5414327383041382
[10/24] Train loss=0.5902364253997803
[15/24] Train loss=0.5822319388389587
[20/24] Train loss=0.564513623714447
Test set avg_accuracy=73.98% avg_sensitivity=0.15%, avg_specificity=100.00% avg_auc=60.49%
Best model saved!! Metric=-91.37472692464956!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.560975 Test loss=0.566192 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5640303492546082
[5/24] Train loss=0.5394399762153625
[10/24] Train loss=0.5896950364112854
[15/24] Train loss=0.5803079009056091
[20/24] Train loss=0.5604643225669861
Test set avg_accuracy=73.98% avg_sensitivity=0.15%, avg_specificity=100.00% avg_auc=62.66%
Best model saved!! Metric=-89.2072202571346!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.558016 Test loss=0.563268 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5606486201286316
[5/24] Train loss=0.5360771417617798
[10/24] Train loss=0.5891552567481995
[15/24] Train loss=0.5771220326423645
[20/24] Train loss=0.5530622601509094
Test set avg_accuracy=73.97% avg_sensitivity=0.20%, avg_specificity=99.96% avg_auc=65.81%
Best model saved!! Metric=-86.05255217563672!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.553621 Test loss=0.558330 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5539635419845581
[5/24] Train loss=0.5305433869361877
[10/24] Train loss=0.5884717106819153
[15/24] Train loss=0.5721089839935303
[20/24] Train loss=0.5430452823638916
Test set avg_accuracy=74.04% avg_sensitivity=0.85%, avg_specificity=99.82% avg_auc=69.89%
Best model saved!! Metric=-81.40291161015065!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.546155 Test loss=0.551282 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5395663380622864
[5/24] Train loss=0.5166958570480347
[10/24] Train loss=0.5795609951019287
[15/24] Train loss=0.5612790584564209
[20/24] Train loss=0.5264456868171692
Test set avg_accuracy=74.31% avg_sensitivity=13.19%, avg_specificity=95.84% avg_auc=72.71%
Best model saved!! Metric=-69.9390312966921!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.532719 Test loss=0.561715 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5177590250968933
[5/24] Train loss=0.5020698308944702
[10/24] Train loss=0.5550400018692017
[15/24] Train loss=0.5483474731445312
[20/24] Train loss=0.5053624510765076
Test set avg_accuracy=73.98% avg_sensitivity=33.38%, avg_specificity=88.29% avg_auc=72.30%
Best model saved!! Metric=-58.04085679333031!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.514726 Test loss=0.607746 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4966542720794678
[5/24] Train loss=0.49293914437294006
[10/24] Train loss=0.5366540551185608
[15/24] Train loss=0.5384964346885681
[20/24] Train loss=0.4934546649456024
Test set avg_accuracy=70.92% avg_sensitivity=41.03%, avg_specificity=81.46% avg_auc=62.72%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.499020 Test loss=0.649147 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.4910200238227844
[5/24] Train loss=0.4855286478996277
[10/24] Train loss=0.5284246802330017
[15/24] Train loss=0.530175507068634
[20/24] Train loss=0.4923098087310791
Test set avg_accuracy=67.17% avg_sensitivity=39.48%, avg_specificity=76.93% avg_auc=58.88%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.490911 Test loss=0.655000 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4817311763763428
[5/24] Train loss=0.4792591333389282
[10/24] Train loss=0.5199575424194336
[15/24] Train loss=0.5282581448554993
[20/24] Train loss=0.48462769389152527
Test set avg_accuracy=73.61% avg_sensitivity=36.33%, avg_specificity=86.74% avg_auc=63.30%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.486076 Test loss=0.632267 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4674656093120575
[5/24] Train loss=0.4771978259086609
[10/24] Train loss=0.5158809423446655
[15/24] Train loss=0.5224548578262329
[20/24] Train loss=0.4788680672645569
Test set avg_accuracy=75.44% avg_sensitivity=36.53%, avg_specificity=89.15% avg_auc=69.31%
Best model saved!! Metric=-55.564934877989344!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.481430 Test loss=0.606727 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4730227291584015
[5/24] Train loss=0.4748845100402832
[10/24] Train loss=0.508807897567749
[15/24] Train loss=0.5198394060134888
[20/24] Train loss=0.4695790708065033
Test set avg_accuracy=73.66% avg_sensitivity=34.98%, avg_specificity=87.29% avg_auc=63.92%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.475901 Test loss=0.626782 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4636419415473938
[5/24] Train loss=0.4690752327442169
[10/24] Train loss=0.5051113367080688
[15/24] Train loss=0.5104068517684937
[20/24] Train loss=0.46063923835754395
Test set avg_accuracy=71.50% avg_sensitivity=44.58%, avg_specificity=80.98% avg_auc=66.58%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.470158 Test loss=0.626480 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.45236292481422424
[5/24] Train loss=0.45778676867485046
[10/24] Train loss=0.4944602847099304
[15/24] Train loss=0.5035505890846252
[20/24] Train loss=0.44866010546684265
Test set avg_accuracy=71.39% avg_sensitivity=48.88%, avg_specificity=79.33% avg_auc=68.91%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.461203 Test loss=0.608957 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.444679319858551
[5/24] Train loss=0.4424806237220764
[10/24] Train loss=0.4805353283882141
[15/24] Train loss=0.4890787899494171
[20/24] Train loss=0.42369505763053894
Test set avg_accuracy=57.63% avg_sensitivity=61.17%, avg_specificity=56.38% avg_auc=65.41%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.444658 Test loss=0.632372 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4100571572780609
[5/24] Train loss=0.42486128211021423
[10/24] Train loss=0.4650349020957947
[15/24] Train loss=0.4812161326408386
[20/24] Train loss=0.42741817235946655
Test set avg_accuracy=56.69% avg_sensitivity=63.92%, avg_specificity=54.15% avg_auc=65.65%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.433357 Test loss=0.639421 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.40636634826660156
[5/24] Train loss=0.4160621464252472
[10/24] Train loss=0.4580521881580353
[15/24] Train loss=0.48745492100715637
[20/24] Train loss=0.3954002857208252
Test set avg_accuracy=72.57% avg_sensitivity=60.17%, avg_specificity=76.93% avg_auc=75.03%
Best model saved!! Metric=-41.30538214326869!!
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.428765 Test loss=0.563030 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4061666429042816
[5/24] Train loss=0.42202410101890564
[10/24] Train loss=0.4585597813129425
[15/24] Train loss=0.48099324107170105
[20/24] Train loss=0.3933194577693939
Test set avg_accuracy=73.67% avg_sensitivity=64.27%, avg_specificity=76.99% avg_auc=77.24%
Best model saved!! Metric=-33.838611172655874!!
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.422489 Test loss=0.567313 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3861558735370636
[5/24] Train loss=0.41127026081085205
[10/24] Train loss=0.4512947201728821
[15/24] Train loss=0.4655737280845642
[20/24] Train loss=0.3820944130420685
Test set avg_accuracy=66.82% avg_sensitivity=63.52%, avg_specificity=67.99% avg_auc=72.95%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.415468 Test loss=0.576544 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.40121695399284363
[5/24] Train loss=0.40018752217292786
[10/24] Train loss=0.4438386857509613
[15/24] Train loss=0.47998112440109253
[20/24] Train loss=0.39174145460128784
Test set avg_accuracy=70.68% avg_sensitivity=62.27%, avg_specificity=73.64% avg_auc=75.22%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.418620 Test loss=0.559379 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.40512189269065857
[5/24] Train loss=0.4113755226135254
[10/24] Train loss=0.4459601938724518
[15/24] Train loss=0.49605607986450195
[20/24] Train loss=0.40513715147972107
Test set avg_accuracy=70.07% avg_sensitivity=64.17%, avg_specificity=72.14% avg_auc=74.76%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.419331 Test loss=0.577376 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.39217931032180786
[5/24] Train loss=0.4035375714302063
[10/24] Train loss=0.44548043608665466
[15/24] Train loss=0.4691861569881439
[20/24] Train loss=0.37227511405944824
Test set avg_accuracy=61.22% avg_sensitivity=68.42%, avg_specificity=58.69% avg_auc=70.03%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.411195 Test loss=0.629453 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.37614426016807556
[5/24] Train loss=0.40300336480140686
[10/24] Train loss=0.4344925284385681
[15/24] Train loss=0.46503546833992004
[20/24] Train loss=0.3685636818408966
Test set avg_accuracy=57.28% avg_sensitivity=69.77%, avg_specificity=52.88% avg_auc=67.99%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.405959 Test loss=0.660082 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.37269511818885803
[5/24] Train loss=0.39953774213790894
[10/24] Train loss=0.4379769265651703
[15/24] Train loss=0.47927701473236084
[20/24] Train loss=0.39662426710128784
Test set avg_accuracy=72.72% avg_sensitivity=61.02%, avg_specificity=76.84% avg_auc=76.37%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.409817 Test loss=0.551397 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.38945797085762024
[5/24] Train loss=0.40903279185295105
[10/24] Train loss=0.436683714389801
[15/24] Train loss=0.4762021005153656
[20/24] Train loss=0.37230560183525085
Test set avg_accuracy=66.52% avg_sensitivity=68.22%, avg_specificity=65.93% avg_auc=73.97%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.409829 Test loss=0.596085 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3732020854949951
[5/24] Train loss=0.4010227620601654
[10/24] Train loss=0.4350897967815399
[15/24] Train loss=0.4585384726524353
[20/24] Train loss=0.36320599913597107
Test set avg_accuracy=63.78% avg_sensitivity=71.91%, avg_specificity=60.91% avg_auc=73.33%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.401619 Test loss=0.619036 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.361875057220459
[5/24] Train loss=0.39974018931388855
[10/24] Train loss=0.43875575065612793
[15/24] Train loss=0.4620074927806854
[20/24] Train loss=0.37171486020088196
Test set avg_accuracy=60.07% avg_sensitivity=69.42%, avg_specificity=56.77% avg_auc=70.10%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.403001 Test loss=0.641896 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.37736234068870544
[5/24] Train loss=0.3920159935951233
[10/24] Train loss=0.4319814443588257
[15/24] Train loss=0.4580721855163574
[20/24] Train loss=0.36090412735939026
Test set avg_accuracy=65.53% avg_sensitivity=73.91%, avg_specificity=62.58% avg_auc=75.60%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.400950 Test loss=0.610322 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3718770444393158
[5/24] Train loss=0.3973057270050049
[10/24] Train loss=0.4413937032222748
[15/24] Train loss=0.4696960747241974
[20/24] Train loss=0.3724444806575775
Test set avg_accuracy=71.28% avg_sensitivity=61.67%, avg_specificity=74.66% avg_auc=75.70%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.405541 Test loss=0.553798 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.37435102462768555
[5/24] Train loss=0.3988721966743469
[10/24] Train loss=0.43810656666755676
[15/24] Train loss=0.4768252372741699
[20/24] Train loss=0.365540087223053
Test set avg_accuracy=66.18% avg_sensitivity=68.27%, avg_specificity=65.45% avg_auc=73.75%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.401534 Test loss=0.596483 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.37010908126831055
[5/24] Train loss=0.39449942111968994
[10/24] Train loss=0.4258445203304291
[15/24] Train loss=0.45343974232673645
[20/24] Train loss=0.3577568829059601
Test set avg_accuracy=61.91% avg_sensitivity=77.26%, avg_specificity=56.51% avg_auc=74.76%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.397712 Test loss=0.636362 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3674492835998535
[5/24] Train loss=0.396663099527359
[10/24] Train loss=0.4237264096736908
[15/24] Train loss=0.45776093006134033
[20/24] Train loss=0.3608195185661316
Test set avg_accuracy=66.45% avg_sensitivity=70.86%, avg_specificity=64.89% avg_auc=75.19%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.397243 Test loss=0.598855 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3683132827281952
[5/24] Train loss=0.3868274390697479
[10/24] Train loss=0.4230438470840454
[15/24] Train loss=0.4835711121559143
[20/24] Train loss=0.35436731576919556
Test set avg_accuracy=68.24% avg_sensitivity=65.97%, avg_specificity=69.04% avg_auc=74.58%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.396304 Test loss=0.579677 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.36279717087745667
[5/24] Train loss=0.3922897279262543
[10/24] Train loss=0.42467692494392395
[15/24] Train loss=0.45677950978279114
[20/24] Train loss=0.3565683364868164
Test set avg_accuracy=71.93% avg_sensitivity=61.77%, avg_specificity=75.51% avg_auc=76.69%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.399090 Test loss=0.537399 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3733121454715729
[5/24] Train loss=0.38810890913009644
[10/24] Train loss=0.42211398482322693
[15/24] Train loss=0.4525670111179352
[20/24] Train loss=0.37376049160957336
Test set avg_accuracy=70.39% avg_sensitivity=70.76%, avg_specificity=70.26% avg_auc=78.35%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.395201 Test loss=0.566234 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3673931956291199
[5/24] Train loss=0.39241668581962585
[10/24] Train loss=0.4330926537513733
[15/24] Train loss=0.45732319355010986
[20/24] Train loss=0.35493797063827515
Test set avg_accuracy=68.89% avg_sensitivity=70.21%, avg_specificity=68.43% avg_auc=77.35%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.398340 Test loss=0.579128 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3670627772808075
[5/24] Train loss=0.38956090807914734
[10/24] Train loss=0.4582255780696869
[15/24] Train loss=0.47164595127105713
[20/24] Train loss=0.36413389444351196
Test set avg_accuracy=73.33% avg_sensitivity=63.42%, avg_specificity=76.83% avg_auc=77.68%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.413376 Test loss=0.540837 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3777827024459839
[5/24] Train loss=0.3884525001049042
[10/24] Train loss=0.4293036460876465
[15/24] Train loss=0.44856277108192444
[20/24] Train loss=0.3522734045982361
Test set avg_accuracy=70.09% avg_sensitivity=68.52%, avg_specificity=70.65% avg_auc=76.99%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.395041 Test loss=0.568731 Current lr=[0.000297555943323901]

[0/24] Train loss=0.36475056409835815
[5/24] Train loss=0.37792834639549255
[10/24] Train loss=0.41436928510665894
[15/24] Train loss=0.4484885334968567
[20/24] Train loss=0.35468265414237976
Test set avg_accuracy=64.83% avg_sensitivity=72.86%, avg_specificity=62.00% avg_auc=74.65%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.391955 Test loss=0.614625 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3785548508167267
[5/24] Train loss=0.37858450412750244
[10/24] Train loss=0.42110997438430786
[15/24] Train loss=0.4535108506679535
[20/24] Train loss=0.34810230135917664
Test set avg_accuracy=73.07% avg_sensitivity=61.22%, avg_specificity=77.25% avg_auc=77.78%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.389948 Test loss=0.526299 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.36460644006729126
[5/24] Train loss=0.3856933116912842
[10/24] Train loss=0.41826489567756653
[15/24] Train loss=0.44328826665878296
[20/24] Train loss=0.34557467699050903
Test set avg_accuracy=69.17% avg_sensitivity=69.17%, avg_specificity=69.17% avg_auc=76.76%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.391116 Test loss=0.574958 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.36079734563827515
[5/24] Train loss=0.3824833333492279
[10/24] Train loss=0.42760786414146423
[15/24] Train loss=0.46517252922058105
[20/24] Train loss=0.34542378783226013
Test set avg_accuracy=71.00% avg_sensitivity=70.51%, avg_specificity=71.17% avg_auc=78.86%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.390143 Test loss=0.556392 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3715665340423584
[5/24] Train loss=0.37442538142204285
[10/24] Train loss=0.4206559658050537
[15/24] Train loss=0.44639095664024353
[20/24] Train loss=0.34541645646095276
Test set avg_accuracy=67.79% avg_sensitivity=69.52%, avg_specificity=67.18% avg_auc=75.72%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.389338 Test loss=0.587111 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.36078494787216187
[5/24] Train loss=0.3744047284126282
[10/24] Train loss=0.4130222201347351
[15/24] Train loss=0.4775266945362091
[20/24] Train loss=0.351689875125885
Test set avg_accuracy=74.79% avg_sensitivity=68.82%, avg_specificity=76.90% avg_auc=80.98%
Best model saved!! Metric=-24.518851872267774!!
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.390892 Test loss=0.523364 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.36677634716033936
[5/24] Train loss=0.37760791182518005
[10/24] Train loss=0.42954573035240173
[15/24] Train loss=0.4543003439903259
[20/24] Train loss=0.33853551745414734
Test set avg_accuracy=69.82% avg_sensitivity=72.16%, avg_specificity=68.99% avg_auc=78.40%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.387093 Test loss=0.572091 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3641524612903595
[5/24] Train loss=0.3744538724422455
[10/24] Train loss=0.41582682728767395
[15/24] Train loss=0.4502280354499817
[20/24] Train loss=0.35899099707603455
Test set avg_accuracy=70.16% avg_sensitivity=73.96%, avg_specificity=68.81% avg_auc=79.42%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.385356 Test loss=0.572704 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.36209431290626526
[5/24] Train loss=0.37304043769836426
[10/24] Train loss=0.41345521807670593
[15/24] Train loss=0.46306732296943665
[20/24] Train loss=0.3537103235721588
Test set avg_accuracy=71.63% avg_sensitivity=66.52%, avg_specificity=73.43% avg_auc=77.50%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.388700 Test loss=0.552494 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.35877788066864014
[5/24] Train loss=0.38020142912864685
[10/24] Train loss=0.41660621762275696
[15/24] Train loss=0.44133228063583374
[20/24] Train loss=0.34985703229904175
Test set avg_accuracy=75.79% avg_sensitivity=71.21%, avg_specificity=77.41% avg_auc=81.87%
Best model saved!! Metric=-19.715264766889092!!
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.388292 Test loss=0.522364 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.35901719331741333
[5/24] Train loss=0.3782351613044739
[10/24] Train loss=0.40972667932510376
[15/24] Train loss=0.4318753182888031
[20/24] Train loss=0.3529992401599884
Test set avg_accuracy=74.84% avg_sensitivity=69.92%, avg_specificity=76.58% avg_auc=80.63%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.384574 Test loss=0.528152 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3566904067993164
[5/24] Train loss=0.37853536009788513
[10/24] Train loss=0.4228467643260956
[15/24] Train loss=0.4396759569644928
[20/24] Train loss=0.34076741337776184
Test set avg_accuracy=75.55% avg_sensitivity=68.17%, avg_specificity=78.15% avg_auc=81.32%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.384270 Test loss=0.509867 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3560573160648346
[5/24] Train loss=0.3685036301612854
[10/24] Train loss=0.4140232503414154
[15/24] Train loss=0.45504140853881836
[20/24] Train loss=0.3483723998069763
Test set avg_accuracy=80.74% avg_sensitivity=65.17%, avg_specificity=86.23% avg_auc=83.76%
Best model saved!! Metric=-10.104927593624154!!
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.387228 Test loss=0.472436 Current lr=[0.000276307469034998]

[0/24] Train loss=0.36658430099487305
[5/24] Train loss=0.3789447247982025
[10/24] Train loss=0.42594578862190247
[15/24] Train loss=0.4859426021575928
[20/24] Train loss=0.3616054654121399
Test set avg_accuracy=73.58% avg_sensitivity=68.57%, avg_specificity=75.35% avg_auc=79.31%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.394885 Test loss=0.553061 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3843897581100464
[5/24] Train loss=0.37612417340278625
[10/24] Train loss=0.4171495735645294
[15/24] Train loss=0.45454925298690796
[20/24] Train loss=0.3509458005428314
Test set avg_accuracy=75.39% avg_sensitivity=68.12%, avg_specificity=77.95% avg_auc=80.79%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.391477 Test loss=0.528006 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.37049421668052673
[5/24] Train loss=0.3755146563053131
[10/24] Train loss=0.41576170921325684
[15/24] Train loss=0.44655585289001465
[20/24] Train loss=0.34604018926620483
Test set avg_accuracy=72.90% avg_sensitivity=71.71%, avg_specificity=73.32% avg_auc=80.09%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.385845 Test loss=0.553223 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3603927195072174
[5/24] Train loss=0.38740700483322144
[10/24] Train loss=0.44144386053085327
[15/24] Train loss=0.4467674493789673
[20/24] Train loss=0.34548404812812805
Test set avg_accuracy=74.31% avg_sensitivity=68.07%, avg_specificity=76.51% avg_auc=80.11%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.391837 Test loss=0.527022 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.360477089881897
[5/24] Train loss=0.3684673309326172
[10/24] Train loss=0.4121030271053314
[15/24] Train loss=0.4471431374549866
[20/24] Train loss=0.34832099080085754
Test set avg_accuracy=76.55% avg_sensitivity=67.67%, avg_specificity=79.68% avg_auc=82.19%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.386254 Test loss=0.491339 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3683752119541168
[5/24] Train loss=0.3672831356525421
[10/24] Train loss=0.40953606367111206
[15/24] Train loss=0.4640539586544037
[20/24] Train loss=0.36330151557922363
Test set avg_accuracy=74.14% avg_sensitivity=69.97%, avg_specificity=75.61% avg_auc=80.77%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.386541 Test loss=0.531471 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3727995753288269
[5/24] Train loss=0.37749773263931274
[10/24] Train loss=0.42141368985176086
[15/24] Train loss=0.4329468607902527
[20/24] Train loss=0.3448534905910492
Test set avg_accuracy=73.28% avg_sensitivity=68.82%, avg_specificity=74.85% avg_auc=79.30%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.387045 Test loss=0.542940 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3691887855529785
[5/24] Train loss=0.3728673458099365
[10/24] Train loss=0.4137987494468689
[15/24] Train loss=0.42186397314071655
[20/24] Train loss=0.3448082506656647
Test set avg_accuracy=71.05% avg_sensitivity=72.86%, avg_specificity=70.42% avg_auc=79.18%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.381239 Test loss=0.562129 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.37665843963623047
[5/24] Train loss=0.36827898025512695
[10/24] Train loss=0.4095320701599121
[15/24] Train loss=0.43254348635673523
[20/24] Train loss=0.3407270014286041
Test set avg_accuracy=76.58% avg_sensitivity=68.02%, avg_specificity=79.59% avg_auc=81.74%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.382854 Test loss=0.501545 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3534361720085144
[5/24] Train loss=0.36481860280036926
[10/24] Train loss=0.41770702600479126
[15/24] Train loss=0.4423414468765259
[20/24] Train loss=0.3403755724430084
Test set avg_accuracy=72.03% avg_sensitivity=72.46%, avg_specificity=71.88% avg_auc=79.46%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.380886 Test loss=0.550237 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.36115768551826477
[5/24] Train loss=0.37033286690711975
[10/24] Train loss=0.41258999705314636
[15/24] Train loss=0.44155004620552063
[20/24] Train loss=0.34631776809692383
Test set avg_accuracy=71.81% avg_sensitivity=75.81%, avg_specificity=70.40% avg_auc=80.90%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.379881 Test loss=0.555971 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.35820651054382324
[5/24] Train loss=0.3718549907207489
[10/24] Train loss=0.4061611592769623
[15/24] Train loss=0.41804859042167664
[20/24] Train loss=0.3399740159511566
Test set avg_accuracy=72.89% avg_sensitivity=70.21%, avg_specificity=73.83% avg_auc=79.64%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.375797 Test loss=0.539276 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3596906065940857
[5/24] Train loss=0.3731271028518677
[10/24] Train loss=0.4140874445438385
[15/24] Train loss=0.4464031457901001
[20/24] Train loss=0.3492833077907562
Test set avg_accuracy=74.74% avg_sensitivity=69.82%, avg_specificity=76.47% avg_auc=81.26%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.379396 Test loss=0.518072 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.35536983609199524
[5/24] Train loss=0.3615877330303192
[10/24] Train loss=0.4023382067680359
[15/24] Train loss=0.4278269112110138
[20/24] Train loss=0.3408069908618927
Test set avg_accuracy=71.26% avg_sensitivity=72.06%, avg_specificity=70.98% avg_auc=79.20%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.376775 Test loss=0.556618 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3663718104362488
[5/24] Train loss=0.3729220926761627
[10/24] Train loss=0.41404059529304504
[15/24] Train loss=0.4757763743400574
[20/24] Train loss=0.34399497509002686
Test set avg_accuracy=79.28% avg_sensitivity=70.26%, avg_specificity=82.46% avg_auc=84.16%
Best model saved!! Metric=-9.831893823046883!!
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.383063 Test loss=0.485480 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.38740864396095276
[5/24] Train loss=0.3741283118724823
[10/24] Train loss=0.4161607325077057
[15/24] Train loss=0.43929651379585266
[20/24] Train loss=0.3435259759426117
Test set avg_accuracy=71.37% avg_sensitivity=70.71%, avg_specificity=71.60% avg_auc=78.91%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.381835 Test loss=0.551512 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3746885061264038
[5/24] Train loss=0.3766738772392273
[10/24] Train loss=0.41640618443489075
[15/24] Train loss=0.4409789741039276
[20/24] Train loss=0.33790862560272217
Test set avg_accuracy=76.02% avg_sensitivity=69.27%, avg_specificity=78.39% avg_auc=81.98%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.379523 Test loss=0.501678 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.35523924231529236
[5/24] Train loss=0.3647972345352173
[10/24] Train loss=0.407794713973999
[15/24] Train loss=0.4202274680137634
[20/24] Train loss=0.33495059609413147
Test set avg_accuracy=73.63% avg_sensitivity=71.11%, avg_specificity=74.52% avg_auc=80.67%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.375081 Test loss=0.528916 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3599438965320587
[5/24] Train loss=0.36624985933303833
[10/24] Train loss=0.42054107785224915
[15/24] Train loss=0.41724082827568054
[20/24] Train loss=0.3386067748069763
Test set avg_accuracy=77.28% avg_sensitivity=71.36%, avg_specificity=79.36% avg_auc=83.46%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.376553 Test loss=0.488640 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3619896173477173
[5/24] Train loss=0.37029972672462463
[10/24] Train loss=0.4060756266117096
[15/24] Train loss=0.40674808621406555
[20/24] Train loss=0.33251118659973145
Test set avg_accuracy=72.92% avg_sensitivity=73.46%, avg_specificity=72.72% avg_auc=80.53%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.370799 Test loss=0.536346 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.36268603801727295
[5/24] Train loss=0.3635377585887909
[10/24] Train loss=0.41144925355911255
[15/24] Train loss=0.4066234230995178
[20/24] Train loss=0.33739879727363586
Test set avg_accuracy=72.64% avg_sensitivity=72.61%, avg_specificity=72.65% avg_auc=80.37%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.370610 Test loss=0.537163 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.38065478205680847
[5/24] Train loss=0.3650186061859131
[10/24] Train loss=0.4041621685028076
[15/24] Train loss=0.4346921443939209
[20/24] Train loss=0.3427523970603943
Test set avg_accuracy=77.43% avg_sensitivity=65.72%, avg_specificity=81.56% avg_auc=82.99%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.374704 Test loss=0.469685 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.37508171796798706
[5/24] Train loss=0.36368170380592346
[10/24] Train loss=0.40468093752861023
[15/24] Train loss=0.4510960578918457
[20/24] Train loss=0.3402837812900543
Test set avg_accuracy=81.95% avg_sensitivity=61.77%, avg_specificity=89.06% avg_auc=85.33%
Best model saved!! Metric=-7.88206429036979!!
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.376670 Test loss=0.432667 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.35766273736953735
[5/24] Train loss=0.3635266423225403
[10/24] Train loss=0.40461015701293945
[15/24] Train loss=0.43172702193260193
[20/24] Train loss=0.33435192704200745
Test set avg_accuracy=72.99% avg_sensitivity=71.26%, avg_specificity=73.60% avg_auc=80.49%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.373391 Test loss=0.531485 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.35352441668510437
[5/24] Train loss=0.35915738344192505
[10/24] Train loss=0.40164312720298767
[15/24] Train loss=0.45088261365890503
[20/24] Train loss=0.3453468084335327
Test set avg_accuracy=76.07% avg_sensitivity=70.26%, avg_specificity=78.11% avg_auc=82.31%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.373964 Test loss=0.507406 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.36467891931533813
[5/24] Train loss=0.36648809909820557
[10/24] Train loss=0.4136272668838501
[15/24] Train loss=0.44178900122642517
[20/24] Train loss=0.3400849401950836
Test set avg_accuracy=72.51% avg_sensitivity=73.41%, avg_specificity=72.20% avg_auc=80.12%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.375047 Test loss=0.546884 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.36079713702201843
[5/24] Train loss=0.3624354302883148
[10/24] Train loss=0.4098256528377533
[15/24] Train loss=0.41366374492645264
[20/24] Train loss=0.33483877778053284
Test set avg_accuracy=71.99% avg_sensitivity=71.76%, avg_specificity=72.07% avg_auc=79.10%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.371547 Test loss=0.546939 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3583472669124603
[5/24] Train loss=0.3609950542449951
[10/24] Train loss=0.40467309951782227
[15/24] Train loss=0.42172497510910034
[20/24] Train loss=0.3430584967136383
Test set avg_accuracy=76.22% avg_sensitivity=68.72%, avg_specificity=78.87% avg_auc=82.41%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.370384 Test loss=0.485825 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3663468360900879
[5/24] Train loss=0.36362287402153015
[10/24] Train loss=0.39751702547073364
[15/24] Train loss=0.41499611735343933
[20/24] Train loss=0.3371267318725586
Test set avg_accuracy=74.45% avg_sensitivity=72.21%, avg_specificity=75.24% avg_auc=81.30%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.368329 Test loss=0.516802 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.359531432390213
[5/24] Train loss=0.35507893562316895
[10/24] Train loss=0.39758238196372986
[15/24] Train loss=0.4067673683166504
[20/24] Train loss=0.3331165909767151
Test set avg_accuracy=73.45% avg_sensitivity=73.36%, avg_specificity=73.48% avg_auc=80.78%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.364497 Test loss=0.530455 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.34488144516944885
[5/24] Train loss=0.35007238388061523
[10/24] Train loss=0.39775189757347107
[15/24] Train loss=0.4119405150413513
[20/24] Train loss=0.33275943994522095
Test set avg_accuracy=73.74% avg_sensitivity=71.71%, avg_specificity=74.45% avg_auc=80.75%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.364070 Test loss=0.524437 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.349036306142807
[5/24] Train loss=0.35059159994125366
[10/24] Train loss=0.39967015385627747
[15/24] Train loss=0.41415974497795105
[20/24] Train loss=0.3312404155731201
Test set avg_accuracy=72.79% avg_sensitivity=71.76%, avg_specificity=73.15% avg_auc=79.72%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.364700 Test loss=0.541115 Current lr=[0.000156543481933168]

[0/24] Train loss=0.3545219600200653
[5/24] Train loss=0.35201889276504517
[10/24] Train loss=0.3995475471019745
[15/24] Train loss=0.41138964891433716
[20/24] Train loss=0.3325394093990326
Test set avg_accuracy=71.26% avg_sensitivity=69.92%, avg_specificity=71.74% avg_auc=77.84%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.365909 Test loss=0.551097 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3508634567260742
[5/24] Train loss=0.3503294289112091
[10/24] Train loss=0.400064617395401
[15/24] Train loss=0.40642213821411133
[20/24] Train loss=0.333610475063324
Test set avg_accuracy=73.29% avg_sensitivity=71.01%, avg_specificity=74.10% avg_auc=80.07%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.363933 Test loss=0.527648 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3443519175052643
[5/24] Train loss=0.34644097089767456
[10/24] Train loss=0.3939771354198456
[15/24] Train loss=0.3999268412590027
[20/24] Train loss=0.3344678282737732
Test set avg_accuracy=75.35% avg_sensitivity=72.61%, avg_specificity=76.32% avg_auc=82.35%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.361985 Test loss=0.501537 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.35282593965530396
[5/24] Train loss=0.3454383313655853
[10/24] Train loss=0.39267441630363464
[15/24] Train loss=0.40885260701179504
[20/24] Train loss=0.3380652964115143
Test set avg_accuracy=73.18% avg_sensitivity=71.81%, avg_specificity=73.66% avg_auc=80.48%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.361223 Test loss=0.526366 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.349839985370636
[5/24] Train loss=0.34811630845069885
[10/24] Train loss=0.4017825722694397
[15/24] Train loss=0.4023406505584717
[20/24] Train loss=0.335083544254303
Test set avg_accuracy=74.86% avg_sensitivity=72.11%, avg_specificity=75.82% avg_auc=81.67%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.361527 Test loss=0.506579 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3429162800312042
[5/24] Train loss=0.34392109513282776
[10/24] Train loss=0.39306557178497314
[15/24] Train loss=0.4073139429092407
[20/24] Train loss=0.3341706693172455
Test set avg_accuracy=74.75% avg_sensitivity=72.31%, avg_specificity=75.61% avg_auc=81.60%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.360384 Test loss=0.510809 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3430435359477997
[5/24] Train loss=0.3414447605609894
[10/24] Train loss=0.39192041754722595
[15/24] Train loss=0.4068145751953125
[20/24] Train loss=0.33523181080818176
Test set avg_accuracy=74.02% avg_sensitivity=71.01%, avg_specificity=75.08% avg_auc=80.64%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.358882 Test loss=0.513810 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.34414851665496826
[5/24] Train loss=0.3440026640892029
[10/24] Train loss=0.3968043029308319
[15/24] Train loss=0.41507336497306824
[20/24] Train loss=0.33379238843917847
Test set avg_accuracy=77.04% avg_sensitivity=69.07%, avg_specificity=79.86% avg_auc=82.58%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.362644 Test loss=0.488430 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.34019744396209717
[5/24] Train loss=0.3485805094242096
[10/24] Train loss=0.4025651514530182
[15/24] Train loss=0.40519818663597107
[20/24] Train loss=0.3326045870780945
Test set avg_accuracy=73.67% avg_sensitivity=71.31%, avg_specificity=74.50% avg_auc=80.52%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.360439 Test loss=0.520986 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.33880355954170227
[5/24] Train loss=0.34163737297058105
[10/24] Train loss=0.39082005620002747
[15/24] Train loss=0.39189621806144714
[20/24] Train loss=0.3291188180446625
Test set avg_accuracy=72.20% avg_sensitivity=73.21%, avg_specificity=71.84% avg_auc=79.88%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.356329 Test loss=0.538737 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3376215100288391
[5/24] Train loss=0.3390331566333771
[10/24] Train loss=0.38763365149497986
[15/24] Train loss=0.39888256788253784
[20/24] Train loss=0.3309756815433502
Test set avg_accuracy=73.54% avg_sensitivity=74.81%, avg_specificity=73.09% avg_auc=81.73%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.356197 Test loss=0.523034 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.34061816334724426
[5/24] Train loss=0.3404180705547333
[10/24] Train loss=0.3915969431400299
[15/24] Train loss=0.3996127247810364
[20/24] Train loss=0.33108216524124146
Test set avg_accuracy=73.01% avg_sensitivity=71.71%, avg_specificity=73.46% avg_auc=79.95%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.356894 Test loss=0.528276 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.33763620257377625
[5/24] Train loss=0.33717823028564453
[10/24] Train loss=0.3910347819328308
[15/24] Train loss=0.3966561257839203
[20/24] Train loss=0.32938820123672485
Test set avg_accuracy=72.84% avg_sensitivity=71.86%, avg_specificity=73.18% avg_auc=79.93%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.355726 Test loss=0.529911 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3382657468318939
[5/24] Train loss=0.33794981241226196
[10/24] Train loss=0.38905632495880127
[15/24] Train loss=0.39952152967453003
[20/24] Train loss=0.32793575525283813
Test set avg_accuracy=72.75% avg_sensitivity=72.86%, avg_specificity=72.71% avg_auc=80.28%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.355185 Test loss=0.530921 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3366759121417999
[5/24] Train loss=0.33749422430992126
[10/24] Train loss=0.3883724510669708
[15/24] Train loss=0.3936026394367218
[20/24] Train loss=0.327457457780838
Test set avg_accuracy=72.57% avg_sensitivity=72.71%, avg_specificity=72.51% avg_auc=80.17%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.354462 Test loss=0.532374 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3382652699947357
[5/24] Train loss=0.3395274579524994
[10/24] Train loss=0.38634830713272095
[15/24] Train loss=0.39325276017189026
[20/24] Train loss=0.3292853832244873
Test set avg_accuracy=72.30% avg_sensitivity=73.56%, avg_specificity=71.86% avg_auc=80.08%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.353713 Test loss=0.535440 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3324108123779297
[5/24] Train loss=0.3338389992713928
[10/24] Train loss=0.39249640703201294
[15/24] Train loss=0.38888272643089294
[20/24] Train loss=0.3281945586204529
Test set avg_accuracy=72.99% avg_sensitivity=71.66%, avg_specificity=73.46% avg_auc=80.04%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.353335 Test loss=0.525782 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3342818021774292
[5/24] Train loss=0.3309131860733032
[10/24] Train loss=0.3869020640850067
[15/24] Train loss=0.40169304609298706
[20/24] Train loss=0.33037269115448
Test set avg_accuracy=72.75% avg_sensitivity=73.31%, avg_specificity=72.55% avg_auc=80.59%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.354213 Test loss=0.529021 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.33285364508628845
[5/24] Train loss=0.33484506607055664
[10/24] Train loss=0.38596588373184204
[15/24] Train loss=0.3913770318031311
[20/24] Train loss=0.3283548355102539
Test set avg_accuracy=71.93% avg_sensitivity=72.41%, avg_specificity=71.76% avg_auc=79.44%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.352750 Test loss=0.538885 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.33478471636772156
[5/24] Train loss=0.33002281188964844
[10/24] Train loss=0.38598325848579407
[15/24] Train loss=0.392179012298584
[20/24] Train loss=0.3290044367313385
Test set avg_accuracy=72.02% avg_sensitivity=72.96%, avg_specificity=71.69% avg_auc=79.79%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.352653 Test loss=0.537985 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3285796046257019
[5/24] Train loss=0.33086302876472473
[10/24] Train loss=0.3902605175971985
[15/24] Train loss=0.3908407390117645
[20/24] Train loss=0.32707229256629944
Test set avg_accuracy=72.41% avg_sensitivity=73.26%, avg_specificity=72.11% avg_auc=80.07%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.351908 Test loss=0.533738 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.32967886328697205
[5/24] Train loss=0.3297958970069885
[10/24] Train loss=0.39014384150505066
[15/24] Train loss=0.38793373107910156
[20/24] Train loss=0.3272700905799866
Test set avg_accuracy=72.30% avg_sensitivity=73.06%, avg_specificity=72.04% avg_auc=80.01%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.351634 Test loss=0.534019 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3284139037132263
[5/24] Train loss=0.32878756523132324
[10/24] Train loss=0.3902730643749237
[15/24] Train loss=0.38338080048561096
[20/24] Train loss=0.3254542946815491
Test set avg_accuracy=71.64% avg_sensitivity=73.61%, avg_specificity=70.95% avg_auc=79.94%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.349520 Test loss=0.538306 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.32601574063301086
[5/24] Train loss=0.32604727149009705
[10/24] Train loss=0.38652339577674866
[15/24] Train loss=0.38265758752822876
[20/24] Train loss=0.32447683811187744
Test set avg_accuracy=71.39% avg_sensitivity=74.11%, avg_specificity=70.43% avg_auc=79.89%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.347484 Test loss=0.541160 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.32558175921440125
[5/24] Train loss=0.32592496275901794
[10/24] Train loss=0.3852243721485138
[15/24] Train loss=0.38120171427726746
[20/24] Train loss=0.32337096333503723
Test set avg_accuracy=71.38% avg_sensitivity=74.46%, avg_specificity=70.29% avg_auc=80.04%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.346390 Test loss=0.540765 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3274158835411072
[5/24] Train loss=0.3250262141227722
[10/24] Train loss=0.38347703218460083
[15/24] Train loss=0.3820541501045227
[20/24] Train loss=0.3245869576931
Test set avg_accuracy=70.38% avg_sensitivity=75.26%, avg_specificity=68.66% avg_auc=79.72%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.346308 Test loss=0.552159 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3266433775424957
[5/24] Train loss=0.32477959990501404
[10/24] Train loss=0.3822328746318817
[15/24] Train loss=0.37815046310424805
[20/24] Train loss=0.32342392206192017
Test set avg_accuracy=70.99% avg_sensitivity=74.31%, avg_specificity=69.82% avg_auc=79.63%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.345724 Test loss=0.546561 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.32466259598731995
[5/24] Train loss=0.3241976499557495
[10/24] Train loss=0.3816283643245697
[15/24] Train loss=0.38149601221084595
[20/24] Train loss=0.3241136372089386
Test set avg_accuracy=70.73% avg_sensitivity=75.11%, avg_specificity=69.18% avg_auc=79.77%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.345709 Test loss=0.548889 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.32424211502075195
[5/24] Train loss=0.32383233308792114
[10/24] Train loss=0.3813420236110687
[15/24] Train loss=0.3773515224456787
[20/24] Train loss=0.3228844404220581
Test set avg_accuracy=71.12% avg_sensitivity=74.51%, avg_specificity=69.92% avg_auc=79.70%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.345212 Test loss=0.543929 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.32479560375213623
[5/24] Train loss=0.32260021567344666
[10/24] Train loss=0.37998294830322266
[15/24] Train loss=0.375624418258667
[20/24] Train loss=0.3227894604206085
Test set avg_accuracy=70.48% avg_sensitivity=75.96%, avg_specificity=68.55% avg_auc=80.08%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.344460 Test loss=0.550177 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3260778784751892
[5/24] Train loss=0.322270929813385
[10/24] Train loss=0.3791824281215668
[15/24] Train loss=0.3763304650783539
[20/24] Train loss=0.32248708605766296
Test set avg_accuracy=70.09% avg_sensitivity=75.76%, avg_specificity=68.09% avg_auc=79.71%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.344360 Test loss=0.556091 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.32699739933013916
[5/24] Train loss=0.32360002398490906
[10/24] Train loss=0.3792480528354645
[15/24] Train loss=0.3777548372745514
[20/24] Train loss=0.32186493277549744
Test set avg_accuracy=69.79% avg_sensitivity=76.61%, avg_specificity=67.39% avg_auc=80.15%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.343670 Test loss=0.555746 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3262576162815094
[5/24] Train loss=0.3193597197532654
[10/24] Train loss=0.38037633895874023
[15/24] Train loss=0.3737667202949524
[20/24] Train loss=0.32324400544166565
Test set avg_accuracy=69.99% avg_sensitivity=76.16%, avg_specificity=67.81% avg_auc=79.77%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.342960 Test loss=0.555872 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3236812651157379
[5/24] Train loss=0.32058194279670715
[10/24] Train loss=0.38384488224983215
[15/24] Train loss=0.3792230188846588
[20/24] Train loss=0.3226465582847595
Test set avg_accuracy=70.25% avg_sensitivity=75.56%, avg_specificity=68.37% avg_auc=79.61%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.343496 Test loss=0.552366 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3248951733112335
[5/24] Train loss=0.32031792402267456
[10/24] Train loss=0.38387298583984375
[15/24] Train loss=0.3747886121273041
[20/24] Train loss=0.3246690034866333
Test set avg_accuracy=69.67% avg_sensitivity=76.41%, avg_specificity=67.30% avg_auc=79.58%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.344385 Test loss=0.560038 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3244295120239258
[5/24] Train loss=0.32045578956604004
[10/24] Train loss=0.3835303783416748
[15/24] Train loss=0.38104894757270813
[20/24] Train loss=0.32352355122566223
Test set avg_accuracy=70.44% avg_sensitivity=75.21%, avg_specificity=68.76% avg_auc=79.31%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.344992 Test loss=0.555040 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.32457074522972107
[5/24] Train loss=0.3202514946460724
[10/24] Train loss=0.38172024488449097
[15/24] Train loss=0.3751174509525299
[20/24] Train loss=0.321642130613327
Test set avg_accuracy=69.35% avg_sensitivity=76.76%, avg_specificity=66.74% avg_auc=79.43%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.343561 Test loss=0.565989 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3253014087677002
[5/24] Train loss=0.321126252412796
[10/24] Train loss=0.3841719627380371
[15/24] Train loss=0.37510061264038086
[20/24] Train loss=0.3232997953891754
Test set avg_accuracy=69.71% avg_sensitivity=76.81%, avg_specificity=67.21% avg_auc=79.80%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.343361 Test loss=0.559428 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.32345545291900635
[5/24] Train loss=0.32115086913108826
[10/24] Train loss=0.38401949405670166
[15/24] Train loss=0.3760877251625061
[20/24] Train loss=0.3225066065788269
Test set avg_accuracy=69.60% avg_sensitivity=76.31%, avg_specificity=67.23% avg_auc=79.64%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.344498 Test loss=0.560971 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3246927857398987
[5/24] Train loss=0.3179318308830261
[10/24] Train loss=0.3802647292613983
[15/24] Train loss=0.375235378742218
[20/24] Train loss=0.32182398438453674
Test set avg_accuracy=70.10% avg_sensitivity=76.26%, avg_specificity=67.93% avg_auc=79.89%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.342292 Test loss=0.553924 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3211926221847534
[5/24] Train loss=0.3177349269390106
[10/24] Train loss=0.38110068440437317
[15/24] Train loss=0.37159478664398193
[20/24] Train loss=0.32067909836769104
Test set avg_accuracy=69.97% avg_sensitivity=76.41%, avg_specificity=67.71% avg_auc=79.95%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.341193 Test loss=0.555081 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.32076194882392883
[5/24] Train loss=0.3175864815711975
[10/24] Train loss=0.37811774015426636
[15/24] Train loss=0.37037229537963867
[20/24] Train loss=0.32024452090263367
Test set avg_accuracy=70.21% avg_sensitivity=76.41%, avg_specificity=68.02% avg_auc=79.97%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.340087 Test loss=0.553825 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.31993815302848816
[5/24] Train loss=0.31630346179008484
[10/24] Train loss=0.3783045709133148
[15/24] Train loss=0.3703582286834717
[20/24] Train loss=0.3204823434352875
Test set avg_accuracy=69.96% avg_sensitivity=76.46%, avg_specificity=67.67% avg_auc=79.93%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.339752 Test loss=0.555764 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.31953439116477966
[5/24] Train loss=0.3161167800426483
[10/24] Train loss=0.37799403071403503
[15/24] Train loss=0.37015557289123535
[20/24] Train loss=0.32015347480773926
Test set avg_accuracy=69.91% avg_sensitivity=76.51%, avg_specificity=67.58% avg_auc=79.89%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.339531 Test loss=0.556756 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3193685710430145
[5/24] Train loss=0.3155815303325653
[10/24] Train loss=0.377785861492157
[15/24] Train loss=0.3699110746383667
[20/24] Train loss=0.32019972801208496
Test set avg_accuracy=69.73% avg_sensitivity=76.56%, avg_specificity=67.32% avg_auc=79.82%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.339316 Test loss=0.558445 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.31914961338043213
[5/24] Train loss=0.31550684571266174
[10/24] Train loss=0.37756043672561646
[15/24] Train loss=0.36985284090042114
[20/24] Train loss=0.3200926184654236
Test set avg_accuracy=69.67% avg_sensitivity=76.56%, avg_specificity=67.25% avg_auc=79.82%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.339204 Test loss=0.558530 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.31907689571380615
[5/24] Train loss=0.31533724069595337
[10/24] Train loss=0.3774908185005188
[15/24] Train loss=0.3697993755340576
[20/24] Train loss=0.32006531953811646
Test set avg_accuracy=69.69% avg_sensitivity=76.66%, avg_specificity=67.23% avg_auc=79.81%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.339103 Test loss=0.558763 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3189615309238434
[5/24] Train loss=0.31527823209762573
[10/24] Train loss=0.3773304522037506
[15/24] Train loss=0.3697519600391388
[20/24] Train loss=0.3200300335884094
Test set avg_accuracy=69.67% avg_sensitivity=76.66%, avg_specificity=67.21% avg_auc=79.81%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.339027 Test loss=0.558964 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.31887421011924744
[5/24] Train loss=0.3151966631412506
[10/24] Train loss=0.3772805631160736
[15/24] Train loss=0.3697197139263153
[20/24] Train loss=0.3199962377548218
Test set avg_accuracy=69.66% avg_sensitivity=76.66%, avg_specificity=67.19% avg_auc=79.81%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.338972 Test loss=0.559092 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.3188227117061615
[5/24] Train loss=0.3151332437992096
[10/24] Train loss=0.3772279620170593
[15/24] Train loss=0.36968421936035156
[20/24] Train loss=0.3199770152568817
Test set avg_accuracy=69.64% avg_sensitivity=76.66%, avg_specificity=67.16% avg_auc=79.81%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.338929 Test loss=0.559207 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3187830150127411
[5/24] Train loss=0.31509312987327576
[10/24] Train loss=0.37718233466148376
[15/24] Train loss=0.369659960269928
[20/24] Train loss=0.31996291875839233
Test set avg_accuracy=69.62% avg_sensitivity=76.66%, avg_specificity=67.14% avg_auc=79.81%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.338900 Test loss=0.559296 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3187558054924011
[5/24] Train loss=0.31506621837615967
[10/24] Train loss=0.3771534860134125
[15/24] Train loss=0.3696446418762207
[20/24] Train loss=0.31995323300361633
Test set avg_accuracy=69.61% avg_sensitivity=76.66%, avg_specificity=67.12% avg_auc=79.80%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.338881 Test loss=0.559341 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3187403380870819
[5/24] Train loss=0.31505030393600464
[10/24] Train loss=0.37713611125946045
[15/24] Train loss=0.36963579058647156
[20/24] Train loss=0.3199479579925537
Test set avg_accuracy=69.61% avg_sensitivity=76.66%, avg_specificity=67.12% avg_auc=79.80%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.338870 Test loss=0.559365 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3187330663204193
[5/24] Train loss=0.3150431215763092
[10/24] Train loss=0.3771282732486725
[15/24] Train loss=0.369631826877594
[20/24] Train loss=0.31994619965553284
Test set avg_accuracy=69.61% avg_sensitivity=76.66%, avg_specificity=67.12% avg_auc=79.80%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.338865 Test loss=0.559374 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=81.95% sen=61.77%, spe=89.06%, auc=85.33%!
Fold[4] Avg_overlap=0.56%(±0.29785848579943514)
[0/24] Train loss=0.6860675811767578
[5/24] Train loss=0.6841303110122681
[10/24] Train loss=0.6834901571273804
[15/24] Train loss=0.6828011274337769
[20/24] Train loss=0.6827253103256226
Test set avg_accuracy=58.09% avg_sensitivity=32.72%, avg_specificity=66.74% avg_auc=50.29%
Best model saved!! Metric=-118.16921163904377!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.683375 Test loss=0.681336 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6830157041549683
[5/24] Train loss=0.6810973882675171
[10/24] Train loss=0.680457592010498
[15/24] Train loss=0.6796536445617676
[20/24] Train loss=0.6799664497375488
Test set avg_accuracy=61.32% avg_sensitivity=28.21%, avg_specificity=72.60% avg_auc=50.46%
Best model saved!! Metric=-113.41042418508044!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.680277 Test loss=0.678224 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.680206835269928
[5/24] Train loss=0.6782785654067993
[10/24] Train loss=0.677552342414856
[15/24] Train loss=0.676567792892456
[20/24] Train loss=0.6772940754890442
Test set avg_accuracy=61.42% avg_sensitivity=27.96%, avg_specificity=72.83% avg_auc=50.61%
Best model saved!! Metric=-113.18437816234663!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.677320 Test loss=0.675257 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.67751544713974
[5/24] Train loss=0.6756319403648376
[10/24] Train loss=0.6747992634773254
[15/24] Train loss=0.6735783219337463
[20/24] Train loss=0.674687385559082
Test set avg_accuracy=61.50% avg_sensitivity=27.39%, avg_specificity=73.13% avg_auc=50.75%
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.674475 Test loss=0.672361 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6749677658081055
[5/24] Train loss=0.6729398369789124
[10/24] Train loss=0.6719843745231628
[15/24] Train loss=0.6704384088516235
[20/24] Train loss=0.6718016862869263
Test set avg_accuracy=64.79% avg_sensitivity=21.51%, avg_specificity=79.55% avg_auc=50.73%
Best model saved!! Metric=-109.41855662593382!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.671509 Test loss=0.669127 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6721251606941223
[5/24] Train loss=0.6697803735733032
[10/24] Train loss=0.6685880422592163
[15/24] Train loss=0.6666557192802429
[20/24] Train loss=0.6682010889053345
Test set avg_accuracy=64.83% avg_sensitivity=20.84%, avg_specificity=79.83% avg_auc=50.89%
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.667938 Test loss=0.665010 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6686547994613647
[5/24] Train loss=0.6657320261001587
[10/24] Train loss=0.6641969680786133
[15/24] Train loss=0.6617910861968994
[20/24] Train loss=0.6635397672653198
Test set avg_accuracy=68.16% avg_sensitivity=16.49%, avg_specificity=85.79% avg_auc=51.05%
Best model saved!! Metric=-104.5080910622666!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.663335 Test loss=0.659631 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6640963554382324
[5/24] Train loss=0.6605353355407715
[10/24] Train loss=0.6585789322853088
[15/24] Train loss=0.6555330157279968
[20/24] Train loss=0.6576803922653198
Test set avg_accuracy=68.14% avg_sensitivity=14.54%, avg_specificity=86.42% avg_auc=51.25%
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.657432 Test loss=0.652760 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6582862138748169
[5/24] Train loss=0.6538856625556946
[10/24] Train loss=0.6511802673339844
[15/24] Train loss=0.6471740007400513
[20/24] Train loss=0.6498750448226929
Test set avg_accuracy=68.22% avg_sensitivity=14.08%, avg_specificity=86.68% avg_auc=51.46%
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.649637 Test loss=0.643426 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6506059169769287
[5/24] Train loss=0.6447786092758179
[10/24] Train loss=0.640992283821106
[15/24] Train loss=0.6355741024017334
[20/24] Train loss=0.6391322016716003
Test set avg_accuracy=71.35% avg_sensitivity=7.32%, avg_specificity=93.19% avg_auc=51.84%
Best model saved!! Metric=-102.29065693415484!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.638913 Test loss=0.630619 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6403383016586304
[5/24] Train loss=0.6323664784431458
[10/24] Train loss=0.627155065536499
[15/24] Train loss=0.6195183992385864
[20/24] Train loss=0.624549925327301
Test set avg_accuracy=71.59% avg_sensitivity=6.61%, avg_specificity=93.75% avg_auc=52.13%
Best model saved!! Metric=-101.93041950494155!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.624188 Test loss=0.613089 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6268594861030579
[5/24] Train loss=0.6153663992881775
[10/24] Train loss=0.6091248989105225
[15/24] Train loss=0.5990252494812012
[20/24] Train loss=0.6075011491775513
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.79%
Best model saved!! Metric=-98.64235436997774!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.605216 Test loss=0.593381 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.6126759052276611
[5/24] Train loss=0.5965809226036072
[10/24] Train loss=0.5912083387374878
[15/24] Train loss=0.5782293081283569
[20/24] Train loss=0.592301607131958
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.42%
Best model saved!! Metric=-98.00635012458503!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.586095 Test loss=0.576199 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.6011665463447571
[5/24] Train loss=0.5799479484558105
[10/24] Train loss=0.5783659219741821
[15/24] Train loss=0.5638477206230164
[20/24] Train loss=0.5820627808570862
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.67%
Best model saved!! Metric=-96.75694367400925!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.571839 Test loss=0.567122 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5946195125579834
[5/24] Train loss=0.5713094472885132
[10/24] Train loss=0.5730864405632019
[15/24] Train loss=0.5573756694793701
[20/24] Train loss=0.5773465037345886
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=58.12%
Best model saved!! Metric=-93.30876461792874!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.565353 Test loss=0.564001 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5921661853790283
[5/24] Train loss=0.5673519372940063
[10/24] Train loss=0.5707423090934753
[15/24] Train loss=0.5543681979179382
[20/24] Train loss=0.5751466155052185
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=60.49%
Best model saved!! Metric=-90.93650704872631!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.562894 Test loss=0.562433 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5914651155471802
[5/24] Train loss=0.5661155581474304
[10/24] Train loss=0.5699607133865356
[15/24] Train loss=0.5518636703491211
[20/24] Train loss=0.5716249942779541
Test set avg_accuracy=74.58% avg_sensitivity=0.05%, avg_specificity=100.00% avg_auc=63.10%
Best model saved!! Metric=-88.26286487922795!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.560948 Test loss=0.560827 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5904285311698914
[5/24] Train loss=0.563183605670929
[10/24] Train loss=0.5676820278167725
[15/24] Train loss=0.5487692952156067
[20/24] Train loss=0.5657489895820618
Test set avg_accuracy=74.57% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=64.94%
Best model saved!! Metric=-86.49286815959155!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.557224 Test loss=0.556482 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5846542716026306
[5/24] Train loss=0.5608833432197571
[10/24] Train loss=0.5660557150840759
[15/24] Train loss=0.53836590051651
[20/24] Train loss=0.555496096611023
Test set avg_accuracy=74.66% avg_sensitivity=0.87%, avg_specificity=99.83% avg_auc=70.03%
Best model saved!! Metric=-80.61623035056364!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.551461 Test loss=0.550723 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5780758261680603
[5/24] Train loss=0.5516395568847656
[10/24] Train loss=0.5550876259803772
[15/24] Train loss=0.526337206363678
[20/24] Train loss=0.5373061895370483
Test set avg_accuracy=74.65% avg_sensitivity=4.15%, avg_specificity=98.69% avg_auc=72.82%
Best model saved!! Metric=-75.68905137220555!!
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.540623 Test loss=0.545292 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5674721002578735
[5/24] Train loss=0.5383865833282471
[10/24] Train loss=0.5363009572029114
[15/24] Train loss=0.5042822957038879
[20/24] Train loss=0.523177981376648
Test set avg_accuracy=74.83% avg_sensitivity=31.08%, avg_specificity=89.75% avg_auc=71.76%
Best model saved!! Metric=-58.576615655977484!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.524654 Test loss=0.628821 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5478969812393188
[5/24] Train loss=0.5241920948028564
[10/24] Train loss=0.5204694271087646
[15/24] Train loss=0.48183339834213257
[20/24] Train loss=0.5140106678009033
Test set avg_accuracy=68.45% avg_sensitivity=40.50%, avg_specificity=77.98% avg_auc=61.88%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.509706 Test loss=0.663945 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5255095958709717
[5/24] Train loss=0.5120672583580017
[10/24] Train loss=0.5049812197685242
[15/24] Train loss=0.47351232171058655
[20/24] Train loss=0.4966542720794678
Test set avg_accuracy=75.53% avg_sensitivity=23.04%, avg_specificity=93.43% avg_auc=63.22%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.497659 Test loss=0.639161 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5367878675460815
[5/24] Train loss=0.5092554092407227
[10/24] Train loss=0.49692079424858093
[15/24] Train loss=0.46723273396492004
[20/24] Train loss=0.49007004499435425
Test set avg_accuracy=76.18% avg_sensitivity=24.17%, avg_specificity=93.92% avg_auc=63.50%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.490079 Test loss=0.627388 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5137702822685242
[5/24] Train loss=0.5028467178344727
[10/24] Train loss=0.4922834634780884
[15/24] Train loss=0.46435150504112244
[20/24] Train loss=0.4911937415599823
Test set avg_accuracy=76.46% avg_sensitivity=19.82%, avg_specificity=95.77% avg_auc=64.89%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.483773 Test loss=0.610671 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5057976245880127
[5/24] Train loss=0.5051839351654053
[10/24] Train loss=0.49207091331481934
[15/24] Train loss=0.46108970046043396
[20/24] Train loss=0.4794504642486572
Test set avg_accuracy=76.67% avg_sensitivity=19.51%, avg_specificity=96.16% avg_auc=66.40%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.482292 Test loss=0.602468 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5074132084846497
[5/24] Train loss=0.4989500939846039
[10/24] Train loss=0.4917556643486023
[15/24] Train loss=0.4558882713317871
[20/24] Train loss=0.4867716133594513
Test set avg_accuracy=76.69% avg_sensitivity=18.69%, avg_specificity=96.47% avg_auc=66.69%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.478896 Test loss=0.593542 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.49674245715141296
[5/24] Train loss=0.49625226855278015
[10/24] Train loss=0.48429492115974426
[15/24] Train loss=0.45661142468452454
[20/24] Train loss=0.47285035252571106
Test set avg_accuracy=76.45% avg_sensitivity=27.80%, avg_specificity=93.03% avg_auc=66.90%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.473652 Test loss=0.609126 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4937172830104828
[5/24] Train loss=0.4962379038333893
[10/24] Train loss=0.4814631938934326
[15/24] Train loss=0.4609673321247101
[20/24] Train loss=0.48315051198005676
Test set avg_accuracy=76.05% avg_sensitivity=38.97%, avg_specificity=88.70% avg_auc=69.12%
Best model saved!! Metric=-53.16016661804612!!
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.474269 Test loss=0.619856 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5049870610237122
[5/24] Train loss=0.49705901741981506
[10/24] Train loss=0.4833748936653137
[15/24] Train loss=0.45286649465560913
[20/24] Train loss=0.47060129046440125
Test set avg_accuracy=76.84% avg_sensitivity=22.38%, avg_specificity=95.41% avg_auc=69.83%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.474257 Test loss=0.590761 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.49853622913360596
[5/24] Train loss=0.500627875328064
[10/24] Train loss=0.481803297996521
[15/24] Train loss=0.44784605503082275
[20/24] Train loss=0.47201916575431824
Test set avg_accuracy=76.73% avg_sensitivity=26.57%, avg_specificity=93.84% avg_auc=68.65%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.473242 Test loss=0.596903 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.49012431502342224
[5/24] Train loss=0.5024994015693665
[10/24] Train loss=0.4794427156448364
[15/24] Train loss=0.44959908723831177
[20/24] Train loss=0.4648332893848419
Test set avg_accuracy=76.54% avg_sensitivity=22.63%, avg_specificity=94.92% avg_auc=70.21%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.468844 Test loss=0.573126 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4870014488697052
[5/24] Train loss=0.48882341384887695
[10/24] Train loss=0.4757155478000641
[15/24] Train loss=0.44001513719558716
[20/24] Train loss=0.45955294370651245
Test set avg_accuracy=76.68% avg_sensitivity=26.22%, avg_specificity=93.89% avg_auc=68.49%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.462244 Test loss=0.576128 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.47381192445755005
[5/24] Train loss=0.4831916093826294
[10/24] Train loss=0.47181716561317444
[15/24] Train loss=0.42940694093704224
[20/24] Train loss=0.44312039017677307
Test set avg_accuracy=77.37% avg_sensitivity=32.31%, avg_specificity=92.74% avg_auc=70.88%
Best model saved!! Metric=-52.7091076926531!!
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.455683 Test loss=0.559511 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.46096155047416687
[5/24] Train loss=0.47461724281311035
[10/24] Train loss=0.460644394159317
[15/24] Train loss=0.42203110456466675
[20/24] Train loss=0.4325864315032959
Test set avg_accuracy=75.40% avg_sensitivity=39.02%, avg_specificity=87.81% avg_auc=69.84%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.444134 Test loss=0.552274 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4486193060874939
[5/24] Train loss=0.46313121914863586
[10/24] Train loss=0.44842764735221863
[15/24] Train loss=0.4051893949508667
[20/24] Train loss=0.41320446133613586
Test set avg_accuracy=77.04% avg_sensitivity=51.66%, avg_specificity=85.70% avg_auc=74.74%
Best model saved!! Metric=-36.851594557927406!!
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.431612 Test loss=0.556310 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4515543282032013
[5/24] Train loss=0.46188315749168396
[10/24] Train loss=0.4507414400577545
[15/24] Train loss=0.40746742486953735
[20/24] Train loss=0.41670137643814087
Test set avg_accuracy=77.99% avg_sensitivity=44.91%, avg_specificity=89.28% avg_auc=73.71%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.433929 Test loss=0.542960 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.44707024097442627
[5/24] Train loss=0.44636085629463196
[10/24] Train loss=0.4369056522846222
[15/24] Train loss=0.40104347467422485
[20/24] Train loss=0.4005877673625946
Test set avg_accuracy=79.36% avg_sensitivity=33.59%, avg_specificity=94.97% avg_auc=76.29%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.425503 Test loss=0.516222 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4331124722957611
[5/24] Train loss=0.4421568214893341
[10/24] Train loss=0.43101251125335693
[15/24] Train loss=0.39640283584594727
[20/24] Train loss=0.3997928202152252
Test set avg_accuracy=79.84% avg_sensitivity=43.93%, avg_specificity=92.09% avg_auc=76.96%
Best model saved!! Metric=-33.170568767981386!!
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.420505 Test loss=0.534379 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.43284332752227783
[5/24] Train loss=0.43308863043785095
[10/24] Train loss=0.4295024871826172
[15/24] Train loss=0.4182833433151245
[20/24] Train loss=0.4016273617744446
Test set avg_accuracy=80.38% avg_sensitivity=40.55%, avg_specificity=93.96% avg_auc=76.56%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.422504 Test loss=0.516516 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4266546964645386
[5/24] Train loss=0.43976911902427673
[10/24] Train loss=0.43409183621406555
[15/24] Train loss=0.403425008058548
[20/24] Train loss=0.4047740399837494
Test set avg_accuracy=80.43% avg_sensitivity=39.84%, avg_specificity=94.27% avg_auc=78.34%
Best model saved!! Metric=-33.12349502014713!!
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.421041 Test loss=0.524064 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.42663177847862244
[5/24] Train loss=0.43540188670158386
[10/24] Train loss=0.4256632328033447
[15/24] Train loss=0.40913939476013184
[20/24] Train loss=0.3924376964569092
Test set avg_accuracy=74.22% avg_sensitivity=50.23%, avg_specificity=82.40% avg_auc=73.60%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.417718 Test loss=0.545767 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4216972589492798
[5/24] Train loss=0.429029256105423
[10/24] Train loss=0.4215887784957886
[15/24] Train loss=0.3902706205844879
[20/24] Train loss=0.3893996775150299
Test set avg_accuracy=79.61% avg_sensitivity=42.70%, avg_specificity=92.19% avg_auc=77.22%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.409746 Test loss=0.527400 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.41565921902656555
[5/24] Train loss=0.42578622698783875
[10/24] Train loss=0.421576589345932
[15/24] Train loss=0.39087438583374023
[20/24] Train loss=0.3860543966293335
Test set avg_accuracy=78.72% avg_sensitivity=28.42%, avg_specificity=95.88% avg_auc=75.32%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.409254 Test loss=0.509341 Current lr=[0.00029967723776099]

[0/24] Train loss=0.42131730914115906
[5/24] Train loss=0.4499257504940033
[10/24] Train loss=0.4291680157184601
[15/24] Train loss=0.39182233810424805
[20/24] Train loss=0.3922584652900696
Test set avg_accuracy=74.93% avg_sensitivity=52.12%, avg_specificity=82.71% avg_auc=74.95%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.422367 Test loss=0.539059 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4113418757915497
[5/24] Train loss=0.4339197278022766
[10/24] Train loss=0.41990476846694946
[15/24] Train loss=0.38907313346862793
[20/24] Train loss=0.38884437084198
Test set avg_accuracy=77.55% avg_sensitivity=42.35%, avg_specificity=89.56% avg_auc=74.45%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.409508 Test loss=0.523047 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.41745519638061523
[5/24] Train loss=0.43541771173477173
[10/24] Train loss=0.4188455045223236
[15/24] Train loss=0.40183258056640625
[20/24] Train loss=0.3833208978176117
Test set avg_accuracy=75.77% avg_sensitivity=44.55%, avg_specificity=86.42% avg_auc=73.40%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.411891 Test loss=0.526262 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4034137427806854
[5/24] Train loss=0.42359575629234314
[10/24] Train loss=0.41638243198394775
[15/24] Train loss=0.38543036580085754
[20/24] Train loss=0.3796493113040924
Test set avg_accuracy=78.07% avg_sensitivity=38.10%, avg_specificity=91.71% avg_auc=74.83%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.405498 Test loss=0.523434 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.4014817476272583
[5/24] Train loss=0.4314008951187134
[10/24] Train loss=0.4199267327785492
[15/24] Train loss=0.39083293080329895
[20/24] Train loss=0.388979434967041
Test set avg_accuracy=76.85% avg_sensitivity=54.79%, avg_specificity=84.37% avg_auc=76.95%
Best model saved!! Metric=-33.03767795111298!!
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.410189 Test loss=0.533951 Current lr=[0.000298904600941902]

[0/24] Train loss=0.41986894607543945
[5/24] Train loss=0.41812747716903687
[10/24] Train loss=0.41796571016311646
[15/24] Train loss=0.3911665081977844
[20/24] Train loss=0.3840700685977936
Test set avg_accuracy=78.32% avg_sensitivity=38.50%, avg_specificity=91.90% avg_auc=74.83%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.408276 Test loss=0.507986 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.4099290668964386
[5/24] Train loss=0.43596944212913513
[10/24] Train loss=0.4272224009037018
[15/24] Train loss=0.38787317276000977
[20/24] Train loss=0.38688603043556213
Test set avg_accuracy=77.85% avg_sensitivity=34.87%, avg_specificity=92.51% avg_auc=73.55%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.412049 Test loss=0.518160 Current lr=[0.000297555943323901]

[0/24] Train loss=0.41874194145202637
[5/24] Train loss=0.4197457730770111
[10/24] Train loss=0.4197244346141815
[15/24] Train loss=0.38226136565208435
[20/24] Train loss=0.37297770380973816
Test set avg_accuracy=77.25% avg_sensitivity=33.85%, avg_specificity=92.06% avg_auc=72.87%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.404401 Test loss=0.518798 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.4044853746891022
[5/24] Train loss=0.43803563714027405
[10/24] Train loss=0.4147111475467682
[15/24] Train loss=0.3932172656059265
[20/24] Train loss=0.3751009404659271
Test set avg_accuracy=77.37% avg_sensitivity=42.35%, avg_specificity=89.31% avg_auc=74.69%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.403221 Test loss=0.516396 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.40606266260147095
[5/24] Train loss=0.41855794191360474
[10/24] Train loss=0.41177618503570557
[15/24] Train loss=0.38789528608322144
[20/24] Train loss=0.37523800134658813
Test set avg_accuracy=77.46% avg_sensitivity=43.42%, avg_specificity=89.07% avg_auc=74.60%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.404436 Test loss=0.517282 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.4159485697746277
[5/24] Train loss=0.4215749204158783
[10/24] Train loss=0.4124126136302948
[15/24] Train loss=0.3962661027908325
[20/24] Train loss=0.3912316560745239
Test set avg_accuracy=72.98% avg_sensitivity=47.21%, avg_specificity=81.77% avg_auc=71.81%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.405826 Test loss=0.542270 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.419038325548172
[5/24] Train loss=0.41697993874549866
[10/24] Train loss=0.41345807909965515
[15/24] Train loss=0.3794020414352417
[20/24] Train loss=0.38014864921569824
Test set avg_accuracy=72.68% avg_sensitivity=48.44%, avg_specificity=80.95% avg_auc=72.35%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.404544 Test loss=0.537481 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.40656548738479614
[5/24] Train loss=0.4214392602443695
[10/24] Train loss=0.41115763783454895
[15/24] Train loss=0.37934789061546326
[20/24] Train loss=0.37206128239631653
Test set avg_accuracy=75.05% avg_sensitivity=45.06%, avg_specificity=85.28% avg_auc=73.40%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.402413 Test loss=0.530103 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.4025234878063202
[5/24] Train loss=0.42545586824417114
[10/24] Train loss=0.4154611825942993
[15/24] Train loss=0.3846738040447235
[20/24] Train loss=0.3715374171733856
Test set avg_accuracy=76.09% avg_sensitivity=42.55%, avg_specificity=87.53% avg_auc=73.89%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.405511 Test loss=0.519093 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.39691200852394104
[5/24] Train loss=0.4150826632976532
[10/24] Train loss=0.40935513377189636
[15/24] Train loss=0.374790221452713
[20/24] Train loss=0.3657515347003937
Test set avg_accuracy=78.15% avg_sensitivity=43.01%, avg_specificity=90.13% avg_auc=76.54%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.396011 Test loss=0.519432 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.4012541174888611
[5/24] Train loss=0.4151436984539032
[10/24] Train loss=0.40498554706573486
[15/24] Train loss=0.38205790519714355
[20/24] Train loss=0.3737962543964386
Test set avg_accuracy=79.62% avg_sensitivity=37.22%, avg_specificity=94.08% avg_auc=78.02%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.397721 Test loss=0.497757 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.4036208689212799
[5/24] Train loss=0.4153479337692261
[10/24] Train loss=0.4101594090461731
[15/24] Train loss=0.4048210382461548
[20/24] Train loss=0.37791043519973755
Test set avg_accuracy=73.50% avg_sensitivity=54.02%, avg_specificity=80.15% avg_auc=74.43%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.403453 Test loss=0.533591 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3922809064388275
[5/24] Train loss=0.4156176447868347
[10/24] Train loss=0.4099729359149933
[15/24] Train loss=0.38829851150512695
[20/24] Train loss=0.36926648020744324
Test set avg_accuracy=74.41% avg_sensitivity=42.14%, avg_specificity=85.42% avg_auc=72.10%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.399386 Test loss=0.530316 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3961184322834015
[5/24] Train loss=0.41255566477775574
[10/24] Train loss=0.4133855402469635
[15/24] Train loss=0.38837021589279175
[20/24] Train loss=0.3727985620498657
Test set avg_accuracy=74.53% avg_sensitivity=49.67%, avg_specificity=83.01% avg_auc=74.40%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.401446 Test loss=0.529444 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3970707058906555
[5/24] Train loss=0.42070773243904114
[10/24] Train loss=0.40311986207962036
[15/24] Train loss=0.380512535572052
[20/24] Train loss=0.3648945689201355
Test set avg_accuracy=76.22% avg_sensitivity=46.54%, avg_specificity=86.35% avg_auc=74.79%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.396092 Test loss=0.517403 Current lr=[0.000276307469034998]

[0/24] Train loss=0.4017498791217804
[5/24] Train loss=0.4133930206298828
[10/24] Train loss=0.40304407477378845
[15/24] Train loss=0.3817618191242218
[20/24] Train loss=0.37680691480636597
Test set avg_accuracy=74.24% avg_sensitivity=51.66%, avg_specificity=81.95% avg_auc=74.13%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.397375 Test loss=0.531858 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.40985313057899475
[5/24] Train loss=0.4118855893611908
[10/24] Train loss=0.4016271233558655
[15/24] Train loss=0.3902893662452698
[20/24] Train loss=0.367067813873291
Test set avg_accuracy=72.77% avg_sensitivity=59.60%, avg_specificity=77.27% avg_auc=75.46%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.398156 Test loss=0.543793 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.39366626739501953
[5/24] Train loss=0.41287195682525635
[10/24] Train loss=0.4037858545780182
[15/24] Train loss=0.37384340167045593
[20/24] Train loss=0.3660171627998352
Test set avg_accuracy=74.84% avg_sensitivity=58.83%, avg_specificity=80.30% avg_auc=76.85%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.392432 Test loss=0.536640 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3968272805213928
[5/24] Train loss=0.4126955568790436
[10/24] Train loss=0.40421372652053833
[15/24] Train loss=0.38551613688468933
[20/24] Train loss=0.37780433893203735
Test set avg_accuracy=68.95% avg_sensitivity=59.04%, avg_specificity=72.32% avg_auc=72.43%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.397594 Test loss=0.560752 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4012534022331238
[5/24] Train loss=0.4148349165916443
[10/24] Train loss=0.4083523452281952
[15/24] Train loss=0.38102322816848755
[20/24] Train loss=0.36870676279067993
Test set avg_accuracy=73.75% avg_sensitivity=57.25%, avg_specificity=79.38% avg_auc=74.95%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.396008 Test loss=0.541848 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.39110904932022095
[5/24] Train loss=0.4111659824848175
[10/24] Train loss=0.4039332866668701
[15/24] Train loss=0.37495681643486023
[20/24] Train loss=0.36245018243789673
Test set avg_accuracy=71.30% avg_sensitivity=48.54%, avg_specificity=79.06% avg_auc=70.89%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.396313 Test loss=0.542798 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3927652835845947
[5/24] Train loss=0.4133037328720093
[10/24] Train loss=0.4066811501979828
[15/24] Train loss=0.3737563192844391
[20/24] Train loss=0.36874914169311523
Test set avg_accuracy=70.65% avg_sensitivity=52.33%, avg_specificity=76.90% avg_auc=70.94%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.394062 Test loss=0.552915 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.38818758726119995
[5/24] Train loss=0.41080442070961
[10/24] Train loss=0.4008219242095947
[15/24] Train loss=0.37495556473731995
[20/24] Train loss=0.3669675886631012
Test set avg_accuracy=70.53% avg_sensitivity=57.09%, avg_specificity=75.12% avg_auc=72.32%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.395803 Test loss=0.564480 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.39567407965660095
[5/24] Train loss=0.40973934531211853
[10/24] Train loss=0.3956674635410309
[15/24] Train loss=0.37001070380210876
[20/24] Train loss=0.3570854961872101
Test set avg_accuracy=69.51% avg_sensitivity=54.48%, avg_specificity=74.63% avg_auc=71.04%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.390072 Test loss=0.559873 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3868553638458252
[5/24] Train loss=0.41110625863075256
[10/24] Train loss=0.4038759768009186
[15/24] Train loss=0.3790898323059082
[20/24] Train loss=0.367216020822525
Test set avg_accuracy=72.64% avg_sensitivity=54.79%, avg_specificity=78.73% avg_auc=73.32%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.393427 Test loss=0.539466 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.38971149921417236
[5/24] Train loss=0.41346511244773865
[10/24] Train loss=0.4004158675670624
[15/24] Train loss=0.3715338706970215
[20/24] Train loss=0.3660311996936798
Test set avg_accuracy=68.70% avg_sensitivity=58.22%, avg_specificity=72.27% avg_auc=71.15%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.392711 Test loss=0.569872 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.391472190618515
[5/24] Train loss=0.4101097285747528
[10/24] Train loss=0.40079349279403687
[15/24] Train loss=0.370613694190979
[20/24] Train loss=0.36952173709869385
Test set avg_accuracy=74.58% avg_sensitivity=50.69%, avg_specificity=82.73% avg_auc=73.52%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.391083 Test loss=0.531729 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.4085749387741089
[5/24] Train loss=0.4233652949333191
[10/24] Train loss=0.4136510491371155
[15/24] Train loss=0.37156781554222107
[20/24] Train loss=0.36215654015541077
Test set avg_accuracy=75.98% avg_sensitivity=48.85%, avg_specificity=85.23% avg_auc=74.62%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.396538 Test loss=0.521852 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3881441354751587
[5/24] Train loss=0.40799015760421753
[10/24] Train loss=0.40230846405029297
[15/24] Train loss=0.3708080053329468
[20/24] Train loss=0.35837963223457336
Test set avg_accuracy=70.89% avg_sensitivity=58.58%, avg_specificity=75.08% avg_auc=72.78%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.389326 Test loss=0.556643 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.39348286390304565
[5/24] Train loss=0.40949517488479614
[10/24] Train loss=0.39622020721435547
[15/24] Train loss=0.36845532059669495
[20/24] Train loss=0.35878074169158936
Test set avg_accuracy=68.89% avg_sensitivity=57.19%, avg_specificity=72.88% avg_auc=70.88%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.388831 Test loss=0.569972 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.38765743374824524
[5/24] Train loss=0.4053013026714325
[10/24] Train loss=0.39698970317840576
[15/24] Train loss=0.365475058555603
[20/24] Train loss=0.35289326310157776
Test set avg_accuracy=67.68% avg_sensitivity=56.48%, avg_specificity=71.50% avg_auc=69.69%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.386744 Test loss=0.577029 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3876327574253082
[5/24] Train loss=0.41040194034576416
[10/24] Train loss=0.40767186880111694
[15/24] Train loss=0.3700641691684723
[20/24] Train loss=0.36791348457336426
Test set avg_accuracy=74.26% avg_sensitivity=57.76%, avg_specificity=79.88% avg_auc=75.96%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.391369 Test loss=0.530502 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3890538811683655
[5/24] Train loss=0.40329164266586304
[10/24] Train loss=0.39125239849090576
[15/24] Train loss=0.37041786313056946
[20/24] Train loss=0.3563336133956909
Test set avg_accuracy=69.49% avg_sensitivity=52.07%, avg_specificity=75.43% avg_auc=70.67%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.386208 Test loss=0.554370 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.39475321769714355
[5/24] Train loss=0.4079621732234955
[10/24] Train loss=0.39915478229522705
[15/24] Train loss=0.38495829701423645
[20/24] Train loss=0.36722901463508606
Test set avg_accuracy=67.72% avg_sensitivity=56.27%, avg_specificity=71.63% avg_auc=70.55%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.390720 Test loss=0.569275 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.39908894896507263
[5/24] Train loss=0.40546685457229614
[10/24] Train loss=0.40220722556114197
[15/24] Train loss=0.37498125433921814
[20/24] Train loss=0.3495672345161438
Test set avg_accuracy=71.99% avg_sensitivity=52.79%, avg_specificity=78.54% avg_auc=72.20%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.388427 Test loss=0.544920 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3782552182674408
[5/24] Train loss=0.40630587935447693
[10/24] Train loss=0.3941919207572937
[15/24] Train loss=0.3675636053085327
[20/24] Train loss=0.3552588224411011
Test set avg_accuracy=72.41% avg_sensitivity=55.61%, avg_specificity=78.14% avg_auc=73.24%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.385235 Test loss=0.541669 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3854596018791199
[5/24] Train loss=0.40280893445014954
[10/24] Train loss=0.40499454736709595
[15/24] Train loss=0.3734353482723236
[20/24] Train loss=0.3540481626987457
Test set avg_accuracy=67.94% avg_sensitivity=57.04%, avg_specificity=71.66% avg_auc=70.11%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.387503 Test loss=0.576667 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.38561558723449707
[5/24] Train loss=0.40595176815986633
[10/24] Train loss=0.39568549394607544
[15/24] Train loss=0.366504430770874
[20/24] Train loss=0.37139344215393066
Test set avg_accuracy=72.32% avg_sensitivity=57.14%, avg_specificity=77.49% avg_auc=73.88%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.388468 Test loss=0.544293 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3858088254928589
[5/24] Train loss=0.4029037654399872
[10/24] Train loss=0.4063187539577484
[15/24] Train loss=0.3714379370212555
[20/24] Train loss=0.35986360907554626
Test set avg_accuracy=72.98% avg_sensitivity=54.33%, avg_specificity=79.34% avg_auc=73.53%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.389678 Test loss=0.535872 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3823883533477783
[5/24] Train loss=0.3964700400829315
[10/24] Train loss=0.3910013735294342
[15/24] Train loss=0.3731847405433655
[20/24] Train loss=0.3503764271736145
Test set avg_accuracy=68.32% avg_sensitivity=57.60%, avg_specificity=71.97% avg_auc=70.38%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.378749 Test loss=0.575766 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3835398554801941
[5/24] Train loss=0.3925665020942688
[10/24] Train loss=0.3926520347595215
[15/24] Train loss=0.3692171275615692
[20/24] Train loss=0.3500903844833374
Test set avg_accuracy=69.71% avg_sensitivity=59.40%, avg_specificity=73.23% avg_auc=72.66%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.380140 Test loss=0.561000 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3799193501472473
[5/24] Train loss=0.41458335518836975
[10/24] Train loss=0.39515218138694763
[15/24] Train loss=0.36522069573402405
[20/24] Train loss=0.35812652111053467
Test set avg_accuracy=71.46% avg_sensitivity=58.22%, avg_specificity=75.97% avg_auc=73.98%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.382878 Test loss=0.543904 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.38140353560447693
[5/24] Train loss=0.3964361250400543
[10/24] Train loss=0.39453819394111633
[15/24] Train loss=0.36518970131874084
[20/24] Train loss=0.3462548553943634
Test set avg_accuracy=71.00% avg_sensitivity=57.19%, avg_specificity=75.71% avg_auc=72.71%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.378251 Test loss=0.550186 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.37873879075050354
[5/24] Train loss=0.3978213965892792
[10/24] Train loss=0.40097448229789734
[15/24] Train loss=0.3664856255054474
[20/24] Train loss=0.3474607765674591
Test set avg_accuracy=70.73% avg_sensitivity=54.33%, avg_specificity=76.32% avg_auc=71.62%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.380527 Test loss=0.550803 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3806215524673462
[5/24] Train loss=0.3936426043510437
[10/24] Train loss=0.3901100158691406
[15/24] Train loss=0.36382055282592773
[20/24] Train loss=0.3500521779060364
Test set avg_accuracy=71.71% avg_sensitivity=55.30%, avg_specificity=77.30% avg_auc=73.05%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.375850 Test loss=0.540918 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.37512290477752686
[5/24] Train loss=0.3966233730316162
[10/24] Train loss=0.39165398478507996
[15/24] Train loss=0.36506831645965576
[20/24] Train loss=0.3467121422290802
Test set avg_accuracy=69.32% avg_sensitivity=54.33%, avg_specificity=74.44% avg_auc=70.76%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.376753 Test loss=0.562567 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.37459254264831543
[5/24] Train loss=0.39331719279289246
[10/24] Train loss=0.38951072096824646
[15/24] Train loss=0.36344408988952637
[20/24] Train loss=0.34458738565444946
Test set avg_accuracy=68.40% avg_sensitivity=51.82%, avg_specificity=74.05% avg_auc=69.11%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.374520 Test loss=0.574339 Current lr=[0.000156543481933168]

[0/24] Train loss=0.38637030124664307
[5/24] Train loss=0.39725223183631897
[10/24] Train loss=0.39341649413108826
[15/24] Train loss=0.3640957772731781
[20/24] Train loss=0.3438411355018616
Test set avg_accuracy=71.86% avg_sensitivity=48.80%, avg_specificity=79.73% avg_auc=71.48%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.376564 Test loss=0.538209 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.38234901428222656
[5/24] Train loss=0.38949015736579895
[10/24] Train loss=0.390321284532547
[15/24] Train loss=0.35702377557754517
[20/24] Train loss=0.35330381989479065
Test set avg_accuracy=71.63% avg_sensitivity=49.92%, avg_specificity=79.03% avg_auc=71.62%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.374534 Test loss=0.541075 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.37689778208732605
[5/24] Train loss=0.39832937717437744
[10/24] Train loss=0.3956562578678131
[15/24] Train loss=0.3685849606990814
[20/24] Train loss=0.3518413007259369
Test set avg_accuracy=71.97% avg_sensitivity=51.72%, avg_specificity=78.87% avg_auc=72.49%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.378118 Test loss=0.538859 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3787873685359955
[5/24] Train loss=0.39218413829803467
[10/24] Train loss=0.3876095712184906
[15/24] Train loss=0.3578832149505615
[20/24] Train loss=0.3520928919315338
Test set avg_accuracy=71.34% avg_sensitivity=50.74%, avg_specificity=78.37% avg_auc=71.59%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.375602 Test loss=0.543835 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.37392082810401917
[5/24] Train loss=0.39229708909988403
[10/24] Train loss=0.39033088088035583
[15/24] Train loss=0.357953280210495
[20/24] Train loss=0.34436628222465515
Test set avg_accuracy=71.76% avg_sensitivity=47.57%, avg_specificity=80.01% avg_auc=71.22%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.373036 Test loss=0.539534 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3781072199344635
[5/24] Train loss=0.38592320680618286
[10/24] Train loss=0.38949477672576904
[15/24] Train loss=0.3576202690601349
[20/24] Train loss=0.34800606966018677
Test set avg_accuracy=72.23% avg_sensitivity=51.31%, avg_specificity=79.36% avg_auc=72.86%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.371851 Test loss=0.532311 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.37397223711013794
[5/24] Train loss=0.38698992133140564
[10/24] Train loss=0.3869689404964447
[15/24] Train loss=0.3551180064678192
[20/24] Train loss=0.3399224281311035
Test set avg_accuracy=72.16% avg_sensitivity=51.51%, avg_specificity=79.20% avg_auc=72.27%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.370894 Test loss=0.537075 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3823906183242798
[5/24] Train loss=0.3904445171356201
[10/24] Train loss=0.3892674446105957
[15/24] Train loss=0.3545939326286316
[20/24] Train loss=0.345255047082901
Test set avg_accuracy=71.26% avg_sensitivity=55.15%, avg_specificity=76.76% avg_auc=72.58%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.372923 Test loss=0.546244 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.37637972831726074
[5/24] Train loss=0.3927500545978546
[10/24] Train loss=0.38863512873649597
[15/24] Train loss=0.3545863926410675
[20/24] Train loss=0.3429757356643677
Test set avg_accuracy=71.21% avg_sensitivity=50.33%, avg_specificity=78.33% avg_auc=71.57%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.371401 Test loss=0.542326 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3739745318889618
[5/24] Train loss=0.3975168466567993
[10/24] Train loss=0.3865581750869751
[15/24] Train loss=0.3580842912197113
[20/24] Train loss=0.3481985926628113
Test set avg_accuracy=69.56% avg_sensitivity=50.23%, avg_specificity=76.15% avg_auc=69.70%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.372023 Test loss=0.564245 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.37106311321258545
[5/24] Train loss=0.3825846016407013
[10/24] Train loss=0.38248127698898315
[15/24] Train loss=0.3567754924297333
[20/24] Train loss=0.3355756998062134
Test set avg_accuracy=71.00% avg_sensitivity=51.72%, avg_specificity=77.58% avg_auc=71.36%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.366339 Test loss=0.548196 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.37124714255332947
[5/24] Train loss=0.3893109858036041
[10/24] Train loss=0.3832462728023529
[15/24] Train loss=0.35115116834640503
[20/24] Train loss=0.3424109220504761
Test set avg_accuracy=70.34% avg_sensitivity=51.92%, avg_specificity=76.62% avg_auc=70.98%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.365859 Test loss=0.553942 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.37229281663894653
[5/24] Train loss=0.3885369896888733
[10/24] Train loss=0.38811054825782776
[15/24] Train loss=0.353475421667099
[20/24] Train loss=0.3409010171890259
Test set avg_accuracy=68.78% avg_sensitivity=52.02%, avg_specificity=74.49% avg_auc=69.81%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.368545 Test loss=0.570361 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.36911335587501526
[5/24] Train loss=0.38344860076904297
[10/24] Train loss=0.38028082251548767
[15/24] Train loss=0.35512274503707886
[20/24] Train loss=0.33775925636291504
Test set avg_accuracy=72.11% avg_sensitivity=54.53%, avg_specificity=78.10% avg_auc=73.32%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.365544 Test loss=0.533693 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.3723967373371124
[5/24] Train loss=0.3842943012714386
[10/24] Train loss=0.3825579583644867
[15/24] Train loss=0.35607412457466125
[20/24] Train loss=0.3355645537376404
Test set avg_accuracy=71.51% avg_sensitivity=51.92%, avg_specificity=78.19% avg_auc=72.19%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.366991 Test loss=0.539501 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.37021875381469727
[5/24] Train loss=0.3810761272907257
[10/24] Train loss=0.38083669543266296
[15/24] Train loss=0.3509156107902527
[20/24] Train loss=0.34078726172447205
Test set avg_accuracy=71.34% avg_sensitivity=51.36%, avg_specificity=78.16% avg_auc=71.92%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.364617 Test loss=0.541900 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.36304959654808044
[5/24] Train loss=0.37697964906692505
[10/24] Train loss=0.382006973028183
[15/24] Train loss=0.3510199785232544
[20/24] Train loss=0.3352200388908386
Test set avg_accuracy=70.04% avg_sensitivity=50.08%, avg_specificity=76.85% avg_auc=70.34%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.362444 Test loss=0.558585 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3664684593677521
[5/24] Train loss=0.37902310490608215
[10/24] Train loss=0.3810538947582245
[15/24] Train loss=0.3483227491378784
[20/24] Train loss=0.33320584893226624
Test set avg_accuracy=70.46% avg_sensitivity=55.40%, avg_specificity=75.59% avg_auc=71.76%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.361110 Test loss=0.556124 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3684655725955963
[5/24] Train loss=0.3764098286628723
[10/24] Train loss=0.3790024518966675
[15/24] Train loss=0.34643325209617615
[20/24] Train loss=0.3323010504245758
Test set avg_accuracy=70.96% avg_sensitivity=55.15%, avg_specificity=76.36% avg_auc=71.93%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.359865 Test loss=0.550685 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3655889630317688
[5/24] Train loss=0.3729100525379181
[10/24] Train loss=0.37857380509376526
[15/24] Train loss=0.34670913219451904
[20/24] Train loss=0.33021536469459534
Test set avg_accuracy=69.82% avg_sensitivity=55.35%, avg_specificity=74.75% avg_auc=71.03%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.358331 Test loss=0.566903 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3628060817718506
[5/24] Train loss=0.37329787015914917
[10/24] Train loss=0.3781946003437042
[15/24] Train loss=0.34776782989501953
[20/24] Train loss=0.32878318428993225
Test set avg_accuracy=70.04% avg_sensitivity=55.71%, avg_specificity=74.93% avg_auc=71.22%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.357501 Test loss=0.565242 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.3633316457271576
[5/24] Train loss=0.37136706709861755
[10/24] Train loss=0.3780362904071808
[15/24] Train loss=0.3470320701599121
[20/24] Train loss=0.32780954241752625
Test set avg_accuracy=70.12% avg_sensitivity=56.17%, avg_specificity=74.87% avg_auc=71.84%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.357336 Test loss=0.559774 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3615189492702484
[5/24] Train loss=0.36974218487739563
[10/24] Train loss=0.3771916925907135
[15/24] Train loss=0.3457948863506317
[20/24] Train loss=0.3286133110523224
Test set avg_accuracy=70.38% avg_sensitivity=56.22%, avg_specificity=75.21% avg_auc=71.90%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.356345 Test loss=0.558883 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3605597913265228
[5/24] Train loss=0.37018364667892456
[10/24] Train loss=0.37830790877342224
[15/24] Train loss=0.34505894780158997
[20/24] Train loss=0.33179545402526855
Test set avg_accuracy=70.16% avg_sensitivity=56.27%, avg_specificity=74.89% avg_auc=71.64%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.356621 Test loss=0.562678 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3587854206562042
[5/24] Train loss=0.369006484746933
[10/24] Train loss=0.37852147221565247
[15/24] Train loss=0.34445515275001526
[20/24] Train loss=0.33004558086395264
Test set avg_accuracy=69.97% avg_sensitivity=54.58%, avg_specificity=75.22% avg_auc=70.92%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.355486 Test loss=0.567170 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3597050905227661
[5/24] Train loss=0.3704155683517456
[10/24] Train loss=0.37906286120414734
[15/24] Train loss=0.3430701494216919
[20/24] Train loss=0.32844582200050354
Test set avg_accuracy=69.26% avg_sensitivity=54.94%, avg_specificity=74.14% avg_auc=70.55%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.354825 Test loss=0.574129 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3607570230960846
[5/24] Train loss=0.3690589368343353
[10/24] Train loss=0.37759360671043396
[15/24] Train loss=0.3443620800971985
[20/24] Train loss=0.3250773847103119
Test set avg_accuracy=69.75% avg_sensitivity=53.81%, avg_specificity=75.19% avg_auc=70.60%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.354339 Test loss=0.569185 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3597925305366516
[5/24] Train loss=0.3733319938182831
[10/24] Train loss=0.37775295972824097
[15/24] Train loss=0.3421081006526947
[20/24] Train loss=0.3254735469818115
Test set avg_accuracy=69.04% avg_sensitivity=56.94%, avg_specificity=73.16% avg_auc=70.84%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.354456 Test loss=0.576948 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3597474992275238
[5/24] Train loss=0.3681996166706085
[10/24] Train loss=0.3795943856239319
[15/24] Train loss=0.3459704518318176
[20/24] Train loss=0.32660096883773804
Test set avg_accuracy=68.53% avg_sensitivity=55.66%, avg_specificity=72.92% avg_auc=70.32%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.354163 Test loss=0.583311 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.36040791869163513
[5/24] Train loss=0.3675115406513214
[10/24] Train loss=0.3786782920360565
[15/24] Train loss=0.34188589453697205
[20/24] Train loss=0.3235054910182953
Test set avg_accuracy=69.32% avg_sensitivity=55.86%, avg_specificity=73.91% avg_auc=70.86%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.353393 Test loss=0.574291 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.3586235046386719
[5/24] Train loss=0.36946049332618713
[10/24] Train loss=0.3779356777667999
[15/24] Train loss=0.3458516597747803
[20/24] Train loss=0.32333651185035706
Test set avg_accuracy=68.01% avg_sensitivity=56.17%, avg_specificity=72.04% avg_auc=69.86%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.353355 Test loss=0.591733 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.3589397966861725
[5/24] Train loss=0.36726775765419006
[10/24] Train loss=0.3766718804836273
[15/24] Train loss=0.3441595137119293
[20/24] Train loss=0.325604647397995
Test set avg_accuracy=69.44% avg_sensitivity=58.83%, avg_specificity=73.06% avg_auc=72.08%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.353498 Test loss=0.566622 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.35852232575416565
[5/24] Train loss=0.3712187707424164
[10/24] Train loss=0.38126370310783386
[15/24] Train loss=0.34279775619506836
[20/24] Train loss=0.3264818489551544
Test set avg_accuracy=68.29% avg_sensitivity=56.78%, avg_specificity=72.22% avg_auc=70.48%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.354027 Test loss=0.583606 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.35617128014564514
[5/24] Train loss=0.3718666732311249
[10/24] Train loss=0.3780594766139984
[15/24] Train loss=0.34228330850601196
[20/24] Train loss=0.32643699645996094
Test set avg_accuracy=69.77% avg_sensitivity=58.32%, avg_specificity=73.67% avg_auc=72.28%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.353530 Test loss=0.562780 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.358227401971817
[5/24] Train loss=0.38082417845726013
[10/24] Train loss=0.3765128254890442
[15/24] Train loss=0.3417418599128723
[20/24] Train loss=0.32577085494995117
Test set avg_accuracy=68.68% avg_sensitivity=56.68%, avg_specificity=72.78% avg_auc=70.64%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.352971 Test loss=0.579791 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3565898537635803
[5/24] Train loss=0.367633193731308
[10/24] Train loss=0.3808956444263458
[15/24] Train loss=0.3417656123638153
[20/24] Train loss=0.32374149560928345
Test set avg_accuracy=68.37% avg_sensitivity=57.55%, avg_specificity=72.06% avg_auc=70.73%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.352381 Test loss=0.582212 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.35523486137390137
[5/24] Train loss=0.36670419573783875
[10/24] Train loss=0.3761064112186432
[15/24] Train loss=0.3405452370643616
[20/24] Train loss=0.3217198848724365
Test set avg_accuracy=69.05% avg_sensitivity=57.35%, avg_specificity=73.04% avg_auc=71.22%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.350985 Test loss=0.575072 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.35517799854278564
[5/24] Train loss=0.36551037430763245
[10/24] Train loss=0.3768317997455597
[15/24] Train loss=0.339045912027359
[20/24] Train loss=0.32243964076042175
Test set avg_accuracy=68.67% avg_sensitivity=56.99%, avg_specificity=72.66% avg_auc=70.89%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.350303 Test loss=0.579230 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.35416707396507263
[5/24] Train loss=0.36543142795562744
[10/24] Train loss=0.3762470781803131
[15/24] Train loss=0.3388907313346863
[20/24] Train loss=0.32122644782066345
Test set avg_accuracy=69.17% avg_sensitivity=57.30%, avg_specificity=73.21% avg_auc=71.27%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.349541 Test loss=0.574689 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.35245373845100403
[5/24] Train loss=0.3640526533126831
[10/24] Train loss=0.3753286600112915
[15/24] Train loss=0.33820655941963196
[20/24] Train loss=0.32095304131507874
Test set avg_accuracy=69.18% avg_sensitivity=57.09%, avg_specificity=73.30% avg_auc=71.29%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.348857 Test loss=0.574119 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3524883985519409
[5/24] Train loss=0.36391350626945496
[10/24] Train loss=0.3751274347305298
[15/24] Train loss=0.33769696950912476
[20/24] Train loss=0.32097315788269043
Test set avg_accuracy=69.32% avg_sensitivity=57.45%, avg_specificity=73.37% avg_auc=71.53%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.348519 Test loss=0.571742 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.35204315185546875
[5/24] Train loss=0.3632592260837555
[10/24] Train loss=0.3751240074634552
[15/24] Train loss=0.337573766708374
[20/24] Train loss=0.32096657156944275
Test set avg_accuracy=69.31% avg_sensitivity=57.55%, avg_specificity=73.32% avg_auc=71.53%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.348345 Test loss=0.572045 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.35170358419418335
[5/24] Train loss=0.36308324337005615
[10/24] Train loss=0.3749513328075409
[15/24] Train loss=0.3374127745628357
[20/24] Train loss=0.3206386864185333
Test set avg_accuracy=69.15% avg_sensitivity=57.25%, avg_specificity=73.21% avg_auc=71.42%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.348143 Test loss=0.573457 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3514937162399292
[5/24] Train loss=0.3628256022930145
[10/24] Train loss=0.37470361590385437
[15/24] Train loss=0.33730244636535645
[20/24] Train loss=0.32058340311050415
Test set avg_accuracy=69.27% avg_sensitivity=57.55%, avg_specificity=73.27% avg_auc=71.52%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.347918 Test loss=0.572434 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3512123227119446
[5/24] Train loss=0.3624674081802368
[10/24] Train loss=0.37468868494033813
[15/24] Train loss=0.3371686339378357
[20/24] Train loss=0.3205043375492096
Test set avg_accuracy=69.24% avg_sensitivity=57.55%, avg_specificity=73.23% avg_auc=71.52%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.347772 Test loss=0.572589 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.35101401805877686
[5/24] Train loss=0.36228999495506287
[10/24] Train loss=0.3746028542518616
[15/24] Train loss=0.3371194005012512
[20/24] Train loss=0.3203975558280945
Test set avg_accuracy=69.24% avg_sensitivity=57.50%, avg_specificity=73.25% avg_auc=71.52%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.347661 Test loss=0.572551 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.35087111592292786
[5/24] Train loss=0.3620533049106598
[10/24] Train loss=0.37453368306159973
[15/24] Train loss=0.3370313048362732
[20/24] Train loss=0.3203307092189789
Test set avg_accuracy=69.19% avg_sensitivity=57.40%, avg_specificity=73.21% avg_auc=71.50%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.347553 Test loss=0.572644 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3507564663887024
[5/24] Train loss=0.36194899678230286
[10/24] Train loss=0.37448376417160034
[15/24] Train loss=0.3369985520839691
[20/24] Train loss=0.320278525352478
Test set avg_accuracy=69.17% avg_sensitivity=57.35%, avg_specificity=73.20% avg_auc=71.50%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.347477 Test loss=0.572690 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.3506675362586975
[5/24] Train loss=0.3618232309818268
[10/24] Train loss=0.3744261562824249
[15/24] Train loss=0.33695489168167114
[20/24] Train loss=0.32023826241493225
Test set avg_accuracy=69.17% avg_sensitivity=57.35%, avg_specificity=73.20% avg_auc=71.50%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.347416 Test loss=0.572675 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.35060372948646545
[5/24] Train loss=0.36175304651260376
[10/24] Train loss=0.37440118193626404
[15/24] Train loss=0.3369251489639282
[20/24] Train loss=0.32020050287246704
Test set avg_accuracy=69.14% avg_sensitivity=57.25%, avg_specificity=73.20% avg_auc=71.49%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.347374 Test loss=0.572758 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.35055994987487793
[5/24] Train loss=0.3617076277732849
[10/24] Train loss=0.3743792772293091
[15/24] Train loss=0.3369053602218628
[20/24] Train loss=0.32017937302589417
Test set avg_accuracy=69.13% avg_sensitivity=57.19%, avg_specificity=73.20% avg_auc=71.48%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.347344 Test loss=0.572818 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3505305051803589
[5/24] Train loss=0.36167457699775696
[10/24] Train loss=0.3743610680103302
[15/24] Train loss=0.3368936777114868
[20/24] Train loss=0.3201674520969391
Test set avg_accuracy=69.11% avg_sensitivity=57.19%, avg_specificity=73.18% avg_auc=71.48%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.347324 Test loss=0.572851 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3505134582519531
[5/24] Train loss=0.361653208732605
[10/24] Train loss=0.37434977293014526
[15/24] Train loss=0.33688825368881226
[20/24] Train loss=0.32016095519065857
Test set avg_accuracy=69.11% avg_sensitivity=57.19%, avg_specificity=73.18% avg_auc=71.47%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.347313 Test loss=0.572875 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3505057692527771
[5/24] Train loss=0.36164453625679016
[10/24] Train loss=0.37434446811676025
[15/24] Train loss=0.336886465549469
[20/24] Train loss=0.32015877962112427
Test set avg_accuracy=69.11% avg_sensitivity=57.19%, avg_specificity=73.18% avg_auc=71.47%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.347309 Test loss=0.572888 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=76.85% sen=54.79%, spe=84.37%, auc=76.95%!
Fold[5] Avg_overlap=0.10%(±0.24483528129262494)
[0/24] Train loss=0.701848030090332
[5/24] Train loss=0.7003790140151978
[10/24] Train loss=0.6988927721977234
[15/24] Train loss=0.7001960277557373
[20/24] Train loss=0.6974183917045593
Test set avg_accuracy=47.86% avg_sensitivity=53.02%, avg_specificity=45.94% avg_auc=49.08%
Best model saved!! Metric=-130.09057228920483!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.699361 Test loss=0.698366 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.698401927947998
[5/24] Train loss=0.6973592638969421
[10/24] Train loss=0.6958515644073486
[15/24] Train loss=0.696955144405365
[20/24] Train loss=0.694536030292511
Test set avg_accuracy=47.99% avg_sensitivity=52.64%, avg_specificity=46.27% avg_auc=48.94%
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.696381 Test loss=0.695718 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6953685283660889
[5/24] Train loss=0.694401741027832
[10/24] Train loss=0.6927887201309204
[15/24] Train loss=0.6937089562416077
[20/24] Train loss=0.6915075182914734
Test set avg_accuracy=51.02% avg_sensitivity=46.93%, avg_specificity=52.54% avg_auc=49.05%
Best model saved!! Metric=-126.46352568893465!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.693379 Test loss=0.692870 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6920725703239441
[5/24] Train loss=0.6911011338233948
[10/24] Train loss=0.689428985118866
[15/24] Train loss=0.6901373863220215
[20/24] Train loss=0.6881960034370422
Test set avg_accuracy=51.20% avg_sensitivity=46.16%, avg_specificity=53.07% avg_auc=49.22%
Best model saved!! Metric=-126.35038987666908!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.690069 Test loss=0.689701 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6884295344352722
[5/24] Train loss=0.6873223781585693
[10/24] Train loss=0.6856323480606079
[15/24] Train loss=0.6861035823822021
[20/24] Train loss=0.6843386888504028
Test set avg_accuracy=51.28% avg_sensitivity=45.54%, avg_specificity=53.41% avg_auc=49.42%
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.686329 Test loss=0.686116 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6843287348747253
[5/24] Train loss=0.682981014251709
[10/24] Train loss=0.6810537576675415
[15/24] Train loss=0.6812445521354675
[20/24] Train loss=0.6795470714569092
Test set avg_accuracy=51.45% avg_sensitivity=44.63%, avg_specificity=53.98% avg_auc=49.66%
Best model saved!! Metric=-126.28108430248712!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.681880 Test loss=0.681745 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6792466044425964
[5/24] Train loss=0.6777065396308899
[10/24] Train loss=0.6754926443099976
[15/24] Train loss=0.6751697659492493
[20/24] Train loss=0.6736640930175781
Test set avg_accuracy=55.07% avg_sensitivity=37.04%, avg_specificity=61.78% avg_auc=49.74%
Best model saved!! Metric=-122.37336761671575!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.676425 Test loss=0.676267 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6728149652481079
[5/24] Train loss=0.6709402203559875
[10/24] Train loss=0.6680665016174316
[15/24] Train loss=0.6668146848678589
[20/24] Train loss=0.6653043627738953
Test set avg_accuracy=59.78% avg_sensitivity=26.06%, avg_specificity=72.34% avg_auc=49.95%
Best model saved!! Metric=-117.87359599967326!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.669077 Test loss=0.668540 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6638466119766235
[5/24] Train loss=0.6612647175788879
[10/24] Train loss=0.6574468612670898
[15/24] Train loss=0.6548550128936768
[20/24] Train loss=0.6533558368682861
Test set avg_accuracy=59.83% avg_sensitivity=24.95%, avg_specificity=72.82% avg_auc=50.08%
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.658605 Test loss=0.657612 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6510518789291382
[5/24] Train loss=0.6473002433776855
[10/24] Train loss=0.6420106291770935
[15/24] Train loss=0.6369027495384216
[20/24] Train loss=0.6355031728744507
Test set avg_accuracy=69.19% avg_sensitivity=7.73%, avg_specificity=92.08% avg_auc=50.39%
Best model saved!! Metric=-106.60440305278152!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.643316 Test loss=0.642076 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6324512958526611
[5/24] Train loss=0.626646876335144
[10/24] Train loss=0.6202435493469238
[15/24] Train loss=0.6108973026275635
[20/24] Train loss=0.6106845140457153
Test set avg_accuracy=69.53% avg_sensitivity=6.57%, avg_specificity=92.98% avg_auc=50.66%
Best model saved!! Metric=-106.25537439170287!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.621485 Test loss=0.621603 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6081319451332092
[5/24] Train loss=0.5984660387039185
[10/24] Train loss=0.5933030247688293
[15/24] Train loss=0.5797250270843506
[20/24] Train loss=0.5859985947608948
Test set avg_accuracy=72.86% avg_sensitivity=0.19%, avg_specificity=99.93% avg_auc=51.50%
Best model saved!! Metric=-101.5194891601807!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.595777 Test loss=0.601490 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5859131813049316
[5/24] Train loss=0.5724104046821594
[10/24] Train loss=0.5738329887390137
[15/24] Train loss=0.5583605766296387
[20/24] Train loss=0.5722054839134216
Test set avg_accuracy=72.89% avg_sensitivity=0.14%, avg_specificity=99.98% avg_auc=53.00%
Best model saved!! Metric=-99.98192689132901!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.576764 Test loss=0.587934 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5725748538970947
[5/24] Train loss=0.5591068267822266
[10/24] Train loss=0.5650342702865601
[15/24] Train loss=0.5470221638679504
[20/24] Train loss=0.5645738244056702
Test set avg_accuracy=72.89% avg_sensitivity=0.14%, avg_specificity=99.98% avg_auc=55.24%
Best model saved!! Metric=-97.74132008279153!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.566681 Test loss=0.581000 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5657755136489868
[5/24] Train loss=0.5514615774154663
[10/24] Train loss=0.5608922839164734
[15/24] Train loss=0.5422547459602356
[20/24] Train loss=0.5619334578514099
Test set avg_accuracy=72.92% avg_sensitivity=0.19%, avg_specificity=100.00% avg_auc=58.75%
Best model saved!! Metric=-94.1422273678713!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.562153 Test loss=0.578606 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5640498995780945
[5/24] Train loss=0.5525411367416382
[10/24] Train loss=0.5592420101165771
[15/24] Train loss=0.5401537418365479
[20/24] Train loss=0.5592544674873352
Test set avg_accuracy=72.92% avg_sensitivity=0.19%, avg_specificity=100.00% avg_auc=60.41%
Best model saved!! Metric=-92.4776678182067!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.560554 Test loss=0.576417 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5610391497612
[5/24] Train loss=0.5455154776573181
[10/24] Train loss=0.5580461621284485
[15/24] Train loss=0.5358533263206482
[20/24] Train loss=0.5554752349853516
Test set avg_accuracy=72.90% avg_sensitivity=0.48%, avg_specificity=99.87% avg_auc=62.05%
Best model saved!! Metric=-90.69113584510711!!
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.557633 Test loss=0.573351 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5584303736686707
[5/24] Train loss=0.5407556891441345
[10/24] Train loss=0.555768609046936
[15/24] Train loss=0.5287740230560303
[20/24] Train loss=0.5477347373962402
Test set avg_accuracy=72.99% avg_sensitivity=1.20%, avg_specificity=99.73% avg_auc=65.32%
Best model saved!! Metric=-86.75362113573262!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.553527 Test loss=0.568603 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5511340498924255
[5/24] Train loss=0.5352857112884521
[10/24] Train loss=0.5501241683959961
[15/24] Train loss=0.5169149041175842
[20/24] Train loss=0.533820629119873
Test set avg_accuracy=72.80% avg_sensitivity=2.98%, avg_specificity=98.80% avg_auc=69.01%
Best model saved!! Metric=-82.41625400029245!!
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.546284 Test loss=0.560284 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.541944146156311
[5/24] Train loss=0.5212165117263794
[10/24] Train loss=0.5386694669723511
[15/24] Train loss=0.4960787892341614
[20/24] Train loss=0.515778660774231
Test set avg_accuracy=73.61% avg_sensitivity=10.75%, avg_specificity=97.02% avg_auc=71.52%
Best model saved!! Metric=-73.11249035405169!!
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.534032 Test loss=0.548165 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5260833501815796
[5/24] Train loss=0.5127311944961548
[10/24] Train loss=0.5110375881195068
[15/24] Train loss=0.4759356379508972
[20/24] Train loss=0.4962921142578125
Test set avg_accuracy=72.20% avg_sensitivity=29.51%, avg_specificity=88.10% avg_auc=73.19%
Best model saved!! Metric=-63.000071789036085!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.517475 Test loss=0.593884 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5226752758026123
[5/24] Train loss=0.5045466423034668
[10/24] Train loss=0.5001775026321411
[15/24] Train loss=0.4601297378540039
[20/24] Train loss=0.4848691523075104
Test set avg_accuracy=73.35% avg_sensitivity=23.13%, avg_specificity=92.05% avg_auc=73.94%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.507788 Test loss=0.598439 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5012234449386597
[5/24] Train loss=0.49531230330467224
[10/24] Train loss=0.4970046877861023
[15/24] Train loss=0.45298048853874207
[20/24] Train loss=0.4784093499183655
Test set avg_accuracy=72.33% avg_sensitivity=24.47%, avg_specificity=90.15% avg_auc=61.25%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.497318 Test loss=0.650286 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.49343645572662354
[5/24] Train loss=0.4827190637588501
[10/24] Train loss=0.4840381443500519
[15/24] Train loss=0.45016035437583923
[20/24] Train loss=0.4724407494068146
Test set avg_accuracy=74.04% avg_sensitivity=22.41%, avg_specificity=93.26% avg_auc=69.55%
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.489449 Test loss=0.618649 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4979861080646515
[5/24] Train loss=0.47810810804367065
[10/24] Train loss=0.4800226092338562
[15/24] Train loss=0.4479674696922302
[20/24] Train loss=0.4691150188446045
Test set avg_accuracy=74.34% avg_sensitivity=25.86%, avg_specificity=92.39% avg_auc=72.75%
Best model saved!! Metric=-60.66579666986907!!
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.483418 Test loss=0.596203 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.48103973269462585
[5/24] Train loss=0.4845103323459625
[10/24] Train loss=0.48246997594833374
[15/24] Train loss=0.443438857793808
[20/24] Train loss=0.4687875211238861
Test set avg_accuracy=73.55% avg_sensitivity=34.21%, avg_specificity=88.21% avg_auc=66.58%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.480009 Test loss=0.625519 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.47384127974510193
[5/24] Train loss=0.47431451082229614
[10/24] Train loss=0.4809066951274872
[15/24] Train loss=0.4422360956668854
[20/24] Train loss=0.4663875102996826
Test set avg_accuracy=74.35% avg_sensitivity=35.51%, avg_specificity=88.81% avg_auc=69.61%
Best model saved!! Metric=-57.71663605887716!!
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.479004 Test loss=0.619128 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4746960699558258
[5/24] Train loss=0.47923460602760315
[10/24] Train loss=0.4790293872356415
[15/24] Train loss=0.43962278962135315
[20/24] Train loss=0.45955708622932434
Test set avg_accuracy=72.16% avg_sensitivity=36.47%, avg_specificity=85.45% avg_auc=65.95%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.476034 Test loss=0.628154 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4833599030971527
[5/24] Train loss=0.47783568501472473
[10/24] Train loss=0.47697439789772034
[15/24] Train loss=0.44258368015289307
[20/24] Train loss=0.4615125358104706
Test set avg_accuracy=73.10% avg_sensitivity=42.37%, avg_specificity=84.54% avg_auc=71.12%
Best model saved!! Metric=-54.86332724493138!!
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.473634 Test loss=0.610871 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4723830819129944
[5/24] Train loss=0.4684736132621765
[10/24] Train loss=0.4738771319389343
[15/24] Train loss=0.43590661883354187
[20/24] Train loss=0.4546767771244049
Test set avg_accuracy=67.19% avg_sensitivity=44.10%, avg_specificity=75.79% avg_auc=63.59%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.470851 Test loss=0.643498 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.47071680426597595
[5/24] Train loss=0.46894168853759766
[10/24] Train loss=0.47596579790115356
[15/24] Train loss=0.4372450113296509
[20/24] Train loss=0.4555707573890686
Test set avg_accuracy=73.71% avg_sensitivity=42.47%, avg_specificity=85.35% avg_auc=72.52%
Best model saved!! Metric=-51.95147646034184!!
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.473152 Test loss=0.607058 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.45851099491119385
[5/24] Train loss=0.47579315304756165
[10/24] Train loss=0.4783785343170166
[15/24] Train loss=0.4349590539932251
[20/24] Train loss=0.45347800850868225
Test set avg_accuracy=67.68% avg_sensitivity=48.32%, avg_specificity=74.89% avg_auc=67.09%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.469812 Test loss=0.638819 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.47189900279045105
[5/24] Train loss=0.46596115827560425
[10/24] Train loss=0.47364914417266846
[15/24] Train loss=0.4344002306461334
[20/24] Train loss=0.4552991986274719
Test set avg_accuracy=66.43% avg_sensitivity=50.00%, avg_specificity=72.55% avg_auc=66.50%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.469184 Test loss=0.639966 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.46125155687332153
[5/24] Train loss=0.46735620498657227
[10/24] Train loss=0.4716523587703705
[15/24] Train loss=0.43970733880996704
[20/24] Train loss=0.45176419615745544
Test set avg_accuracy=66.82% avg_sensitivity=50.91%, avg_specificity=72.75% avg_auc=67.10%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.472060 Test loss=0.642078 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.47054287791252136
[5/24] Train loss=0.46272680163383484
[10/24] Train loss=0.4692433476448059
[15/24] Train loss=0.43407875299453735
[20/24] Train loss=0.45105382800102234
Test set avg_accuracy=75.34% avg_sensitivity=40.26%, avg_specificity=88.40% avg_auc=76.02%
Best model saved!! Metric=-45.97921683645937!!
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.470223 Test loss=0.571425 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4594953954219818
[5/24] Train loss=0.4721631109714508
[10/24] Train loss=0.47565212845802307
[15/24] Train loss=0.4391317665576935
[20/24] Train loss=0.4487099051475525
Test set avg_accuracy=62.24% avg_sensitivity=54.85%, avg_specificity=64.99% avg_auc=63.79%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.469136 Test loss=0.659847 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4650130867958069
[5/24] Train loss=0.4657789468765259
[10/24] Train loss=0.4708499312400818
[15/24] Train loss=0.4338257908821106
[20/24] Train loss=0.4479982554912567
Test set avg_accuracy=65.69% avg_sensitivity=52.40%, avg_specificity=70.64% avg_auc=66.61%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.466408 Test loss=0.643752 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4684630334377289
[5/24] Train loss=0.47306424379348755
[10/24] Train loss=0.47059497237205505
[15/24] Train loss=0.4369664788246155
[20/24] Train loss=0.45685315132141113
Test set avg_accuracy=62.89% avg_sensitivity=56.62%, avg_specificity=65.23% avg_auc=65.82%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.467914 Test loss=0.654044 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4539577066898346
[5/24] Train loss=0.46502453088760376
[10/24] Train loss=0.46903637051582336
[15/24] Train loss=0.4347990155220032
[20/24] Train loss=0.4513320028781891
Test set avg_accuracy=76.08% avg_sensitivity=39.40%, avg_specificity=89.74% avg_auc=77.36%
Best model saved!! Metric=-43.416416793087976!!
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.469494 Test loss=0.551456 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.46042829751968384
[5/24] Train loss=0.46683046221733093
[10/24] Train loss=0.4686362147331238
[15/24] Train loss=0.4380480647087097
[20/24] Train loss=0.45080962777137756
Test set avg_accuracy=62.47% avg_sensitivity=57.34%, avg_specificity=64.39% avg_auc=65.53%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.466108 Test loss=0.656221 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4555988609790802
[5/24] Train loss=0.4615994095802307
[10/24] Train loss=0.46902894973754883
[15/24] Train loss=0.43466323614120483
[20/24] Train loss=0.44835150241851807
Test set avg_accuracy=66.61% avg_sensitivity=54.32%, avg_specificity=71.19% avg_auc=68.18%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.466737 Test loss=0.638567 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4494978189468384
[5/24] Train loss=0.4680502712726593
[10/24] Train loss=0.4733717739582062
[15/24] Train loss=0.44468122720718384
[20/24] Train loss=0.4500550627708435
Test set avg_accuracy=70.20% avg_sensitivity=51.54%, avg_specificity=77.14% avg_auc=71.29%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.468088 Test loss=0.619136 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4738073945045471
[5/24] Train loss=0.46888166666030884
[10/24] Train loss=0.47068551182746887
[15/24] Train loss=0.43495652079582214
[20/24] Train loss=0.44719669222831726
Test set avg_accuracy=66.58% avg_sensitivity=52.78%, avg_specificity=71.71% avg_auc=67.06%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.466744 Test loss=0.640319 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4484204649925232
[5/24] Train loss=0.46399664878845215
[10/24] Train loss=0.46943145990371704
[15/24] Train loss=0.44144120812416077
[20/24] Train loss=0.4441969096660614
Test set avg_accuracy=63.58% avg_sensitivity=55.66%, avg_specificity=66.53% avg_auc=65.31%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.465755 Test loss=0.653451 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4566555917263031
[5/24] Train loss=0.46498364210128784
[10/24] Train loss=0.47328341007232666
[15/24] Train loss=0.43174993991851807
[20/24] Train loss=0.444676011800766
Test set avg_accuracy=71.71% avg_sensitivity=47.98%, avg_specificity=80.54% avg_auc=71.53%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.464451 Test loss=0.608398 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4489423930644989
[5/24] Train loss=0.4633299708366394
[10/24] Train loss=0.4716767370700836
[15/24] Train loss=0.4326389729976654
[20/24] Train loss=0.44435033202171326
Test set avg_accuracy=67.41% avg_sensitivity=54.37%, avg_specificity=72.27% avg_auc=68.27%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.465274 Test loss=0.634145 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4440169334411621
[5/24] Train loss=0.4659953713417053
[10/24] Train loss=0.4670196771621704
[15/24] Train loss=0.4344604015350342
[20/24] Train loss=0.44351428747177124
Test set avg_accuracy=73.36% avg_sensitivity=48.94%, avg_specificity=82.45% avg_auc=73.96%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.463157 Test loss=0.592190 Current lr=[0.000299720220882401]

[0/24] Train loss=0.45222368836402893
[5/24] Train loss=0.4599228799343109
[10/24] Train loss=0.4676116406917572
[15/24] Train loss=0.4289965331554413
[20/24] Train loss=0.4496941864490509
Test set avg_accuracy=69.80% avg_sensitivity=52.78%, avg_specificity=76.14% avg_auc=71.09%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.460863 Test loss=0.613848 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.446078896522522
[5/24] Train loss=0.45441266894340515
[10/24] Train loss=0.46238094568252563
[15/24] Train loss=0.42875799536705017
[20/24] Train loss=0.45959100127220154
Test set avg_accuracy=67.50% avg_sensitivity=55.61%, avg_specificity=71.93% avg_auc=69.27%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.459815 Test loss=0.625830 Current lr=[0.000298904600941902]

[0/24] Train loss=0.4438832104206085
[5/24] Train loss=0.45766159892082214
[10/24] Train loss=0.46448391675949097
[15/24] Train loss=0.426524817943573
[20/24] Train loss=0.43853068351745605
Test set avg_accuracy=67.01% avg_sensitivity=55.85%, avg_specificity=71.16% avg_auc=68.79%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.459973 Test loss=0.632508 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.4464118480682373
[5/24] Train loss=0.46587640047073364
[10/24] Train loss=0.4673595130443573
[15/24] Train loss=0.4290056526660919
[20/24] Train loss=0.4485326409339905
Test set avg_accuracy=72.50% avg_sensitivity=51.87%, avg_specificity=80.18% avg_auc=74.43%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.463243 Test loss=0.586583 Current lr=[0.000297555943323901]

[0/24] Train loss=0.44845831394195557
[5/24] Train loss=0.45824599266052246
[10/24] Train loss=0.4661058485507965
[15/24] Train loss=0.4282892942428589
[20/24] Train loss=0.4500599503517151
Test set avg_accuracy=75.33% avg_sensitivity=41.31%, avg_specificity=87.99% avg_auc=74.47%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.460812 Test loss=0.577351 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.45291849970817566
[5/24] Train loss=0.46017324924468994
[10/24] Train loss=0.4677482843399048
[15/24] Train loss=0.4403306543827057
[20/24] Train loss=0.44894081354141235
Test set avg_accuracy=75.12% avg_sensitivity=43.81%, avg_specificity=86.78% avg_auc=76.14%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.465163 Test loss=0.562740 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.44579559564590454
[5/24] Train loss=0.4601169526576996
[10/24] Train loss=0.46536383032798767
[15/24] Train loss=0.426991730928421
[20/24] Train loss=0.4410216808319092
Test set avg_accuracy=65.30% avg_sensitivity=58.93%, avg_specificity=67.67% avg_auc=68.53%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.460447 Test loss=0.636293 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.445142924785614
[5/24] Train loss=0.4552065432071686
[10/24] Train loss=0.46810680627822876
[15/24] Train loss=0.428931325674057
[20/24] Train loss=0.4486404061317444
Test set avg_accuracy=70.98% avg_sensitivity=52.78%, avg_specificity=77.75% avg_auc=71.90%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.461168 Test loss=0.608165 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.4445226788520813
[5/24] Train loss=0.4595203697681427
[10/24] Train loss=0.4654679298400879
[15/24] Train loss=0.42566779255867004
[20/24] Train loss=0.44244125485420227
Test set avg_accuracy=63.14% avg_sensitivity=59.93%, avg_specificity=64.33% avg_auc=67.41%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.457413 Test loss=0.645429 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.46464571356773376
[5/24] Train loss=0.45785439014434814
[10/24] Train loss=0.46966078877449036
[15/24] Train loss=0.4242601692676544
[20/24] Train loss=0.4441452622413635
Test set avg_accuracy=63.63% avg_sensitivity=60.60%, avg_specificity=64.76% avg_auc=68.22%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.460684 Test loss=0.643567 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.44747278094291687
[5/24] Train loss=0.4607544243335724
[10/24] Train loss=0.4700191020965576
[15/24] Train loss=0.4282083809375763
[20/24] Train loss=0.43842607736587524
Test set avg_accuracy=65.07% avg_sensitivity=60.27%, avg_specificity=66.85% avg_auc=68.88%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.459063 Test loss=0.637139 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.4409779906272888
[5/24] Train loss=0.4548662602901459
[10/24] Train loss=0.46935078501701355
[15/24] Train loss=0.43270114064216614
[20/24] Train loss=0.44195041060447693
Test set avg_accuracy=69.56% avg_sensitivity=55.09%, avg_specificity=74.95% avg_auc=70.71%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.461504 Test loss=0.621469 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.4512336254119873
[5/24] Train loss=0.4564553499221802
[10/24] Train loss=0.4652574062347412
[15/24] Train loss=0.42938730120658875
[20/24] Train loss=0.44805005192756653
Test set avg_accuracy=65.78% avg_sensitivity=58.69%, avg_specificity=68.42% avg_auc=68.71%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.461592 Test loss=0.635001 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.44736447930336
[5/24] Train loss=0.46004343032836914
[10/24] Train loss=0.46724066138267517
[15/24] Train loss=0.43439027667045593
[20/24] Train loss=0.43898406624794006
Test set avg_accuracy=68.74% avg_sensitivity=55.33%, avg_specificity=73.73% avg_auc=69.71%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.461107 Test loss=0.621925 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.45076867938041687
[5/24] Train loss=0.4529218077659607
[10/24] Train loss=0.4663863778114319
[15/24] Train loss=0.42412200570106506
[20/24] Train loss=0.4368354380130768
Test set avg_accuracy=64.21% avg_sensitivity=60.65%, avg_specificity=65.53% avg_auc=68.98%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.458448 Test loss=0.637421 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.44138655066490173
[5/24] Train loss=0.4493372142314911
[10/24] Train loss=0.4655395746231079
[15/24] Train loss=0.42802169919013977
[20/24] Train loss=0.44597405195236206
Test set avg_accuracy=74.57% avg_sensitivity=46.02%, avg_specificity=85.20% avg_auc=74.43%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.458700 Test loss=0.568418 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.43934449553489685
[5/24] Train loss=0.45039311051368713
[10/24] Train loss=0.46853017807006836
[15/24] Train loss=0.42816856503486633
[20/24] Train loss=0.4374525845050812
Test set avg_accuracy=67.70% avg_sensitivity=56.33%, avg_specificity=71.93% avg_auc=69.63%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.457318 Test loss=0.622257 Current lr=[0.000276307469034998]

[0/24] Train loss=0.44093817472457886
[5/24] Train loss=0.44902148842811584
[10/24] Train loss=0.46588295698165894
[15/24] Train loss=0.4268209934234619
[20/24] Train loss=0.440871000289917
Test set avg_accuracy=76.52% avg_sensitivity=39.97%, avg_specificity=90.14% avg_auc=78.50%
Best model saved!! Metric=-40.87376714576423!!
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.459434 Test loss=0.526041 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.4446350336074829
[5/24] Train loss=0.4496857523918152
[10/24] Train loss=0.4654393792152405
[15/24] Train loss=0.4290209710597992
[20/24] Train loss=0.42975881695747375
Test set avg_accuracy=69.48% avg_sensitivity=53.50%, avg_specificity=75.43% avg_auc=70.25%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.455990 Test loss=0.617728 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.44311997294425964
[5/24] Train loss=0.4459250867366791
[10/24] Train loss=0.46734583377838135
[15/24] Train loss=0.42173659801483154
[20/24] Train loss=0.43429526686668396
Test set avg_accuracy=76.42% avg_sensitivity=30.37%, avg_specificity=93.57% avg_auc=79.35%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.456752 Test loss=0.508182 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.44469887018203735
[5/24] Train loss=0.47421130537986755
[10/24] Train loss=0.473712682723999
[15/24] Train loss=0.42903879284858704
[20/24] Train loss=0.4429870545864105
Test set avg_accuracy=65.53% avg_sensitivity=59.74%, avg_specificity=67.69% avg_auc=69.72%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.464196 Test loss=0.635518 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.4452575147151947
[5/24] Train loss=0.4517830014228821
[10/24] Train loss=0.46300750970840454
[15/24] Train loss=0.45658209919929504
[20/24] Train loss=0.44736501574516296
Test set avg_accuracy=76.22% avg_sensitivity=38.48%, avg_specificity=90.28% avg_auc=77.26%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.460759 Test loss=0.550443 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.45365220308303833
[5/24] Train loss=0.4558801054954529
[10/24] Train loss=0.46491551399230957
[15/24] Train loss=0.44199514389038086
[20/24] Train loss=0.4416460692882538
Test set avg_accuracy=75.07% avg_sensitivity=50.14%, avg_specificity=84.35% avg_auc=76.49%
Best model saved!! Metric=-39.95324198543817!!
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.460104 Test loss=0.559112 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.4473972022533417
[5/24] Train loss=0.45224103331565857
[10/24] Train loss=0.4644036591053009
[15/24] Train loss=0.42463597655296326
[20/24] Train loss=0.4450854957103729
Test set avg_accuracy=68.11% avg_sensitivity=56.81%, avg_specificity=72.32% avg_auc=70.72%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.455522 Test loss=0.612654 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.4385313391685486
[5/24] Train loss=0.45104220509529114
[10/24] Train loss=0.46947619318962097
[15/24] Train loss=0.4243113398551941
[20/24] Train loss=0.43658149242401123
Test set avg_accuracy=68.59% avg_sensitivity=55.66%, avg_specificity=73.41% avg_auc=70.75%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.456984 Test loss=0.617806 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.4469882547855377
[5/24] Train loss=0.44997572898864746
[10/24] Train loss=0.46673890948295593
[15/24] Train loss=0.4452405571937561
[20/24] Train loss=0.44216272234916687
Test set avg_accuracy=76.17% avg_sensitivity=42.61%, avg_specificity=88.67% avg_auc=77.77%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.461540 Test loss=0.535518 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.44240298867225647
[5/24] Train loss=0.4487465023994446
[10/24] Train loss=0.4650554060935974
[15/24] Train loss=0.42413556575775146
[20/24] Train loss=0.4393414556980133
Test set avg_accuracy=69.77% avg_sensitivity=53.74%, avg_specificity=75.73% avg_auc=71.35%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.456830 Test loss=0.607579 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.44414377212524414
[5/24] Train loss=0.4463333785533905
[10/24] Train loss=0.46641477942466736
[15/24] Train loss=0.42262473702430725
[20/24] Train loss=0.4412952661514282
Test set avg_accuracy=72.66% avg_sensitivity=51.68%, avg_specificity=80.47% avg_auc=73.82%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.455895 Test loss=0.587729 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.4414096474647522
[5/24] Train loss=0.45167437195777893
[10/24] Train loss=0.4654789865016937
[15/24] Train loss=0.42065271735191345
[20/24] Train loss=0.4358641803264618
Test set avg_accuracy=69.52% avg_sensitivity=55.28%, avg_specificity=74.82% avg_auc=71.84%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.454241 Test loss=0.602933 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.4394821524620056
[5/24] Train loss=0.44682785868644714
[10/24] Train loss=0.461246132850647
[15/24] Train loss=0.41990718245506287
[20/24] Train loss=0.431079238653183
Test set avg_accuracy=68.29% avg_sensitivity=57.82%, avg_specificity=72.19% avg_auc=71.13%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.449978 Test loss=0.608751 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.4388924539089203
[5/24] Train loss=0.44492635130882263
[10/24] Train loss=0.458953857421875
[15/24] Train loss=0.4175518751144409
[20/24] Train loss=0.4400361478328705
Test set avg_accuracy=73.70% avg_sensitivity=50.62%, avg_specificity=82.29% avg_auc=74.74%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.450662 Test loss=0.573341 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.44586876034736633
[5/24] Train loss=0.44443240761756897
[10/24] Train loss=0.45819738507270813
[15/24] Train loss=0.4194371700286865
[20/24] Train loss=0.4414249062538147
Test set avg_accuracy=69.58% avg_sensitivity=54.32%, avg_specificity=75.27% avg_auc=71.73%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.451574 Test loss=0.600352 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.4390757977962494
[5/24] Train loss=0.4539589285850525
[10/24] Train loss=0.4645628333091736
[15/24] Train loss=0.4219353497028351
[20/24] Train loss=0.43393149971961975
Test set avg_accuracy=76.48% avg_sensitivity=31.72%, avg_specificity=93.16% avg_auc=79.46%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.454166 Test loss=0.488328 Current lr=[0.000224838296036774]

[0/24] Train loss=0.44259971380233765
[5/24] Train loss=0.4488615393638611
[10/24] Train loss=0.4640496075153351
[15/24] Train loss=0.4291955530643463
[20/24] Train loss=0.4288560450077057
Test set avg_accuracy=71.80% avg_sensitivity=53.89%, avg_specificity=78.47% avg_auc=72.65%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.457564 Test loss=0.590700 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.44069114327430725
[5/24] Train loss=0.44427257776260376
[10/24] Train loss=0.4637615382671356
[15/24] Train loss=0.4275270402431488
[20/24] Train loss=0.4325416088104248
Test set avg_accuracy=63.70% avg_sensitivity=60.70%, avg_specificity=64.81% avg_auc=68.44%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.454561 Test loss=0.638873 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.4436729848384857
[5/24] Train loss=0.4538785517215729
[10/24] Train loss=0.4641716778278351
[15/24] Train loss=0.424985408782959
[20/24] Train loss=0.43544819951057434
Test set avg_accuracy=72.98% avg_sensitivity=52.45%, avg_specificity=80.63% avg_auc=74.64%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.455178 Test loss=0.577592 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.44177278876304626
[5/24] Train loss=0.4468100965023041
[10/24] Train loss=0.46185314655303955
[15/24] Train loss=0.4242105484008789
[20/24] Train loss=0.4395076334476471
Test set avg_accuracy=69.51% avg_sensitivity=55.61%, avg_specificity=74.68% avg_auc=72.33%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.453843 Test loss=0.601681 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.44590020179748535
[5/24] Train loss=0.447021484375
[10/24] Train loss=0.4615310728549957
[15/24] Train loss=0.4182569980621338
[20/24] Train loss=0.43673276901245117
Test set avg_accuracy=71.26% avg_sensitivity=54.61%, avg_specificity=77.47% avg_auc=73.30%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.453109 Test loss=0.595049 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.4485437572002411
[5/24] Train loss=0.45762887597084045
[10/24] Train loss=0.4635464549064636
[15/24] Train loss=0.42374187707901
[20/24] Train loss=0.42852723598480225
Test set avg_accuracy=71.22% avg_sensitivity=51.92%, avg_specificity=78.41% avg_auc=72.21%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.454257 Test loss=0.592149 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.4462886452674866
[5/24] Train loss=0.45191213488578796
[10/24] Train loss=0.46495935320854187
[15/24] Train loss=0.4447827637195587
[20/24] Train loss=0.43337875604629517
Test set avg_accuracy=70.27% avg_sensitivity=57.53%, avg_specificity=75.02% avg_auc=73.43%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.454294 Test loss=0.602018 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.4502861201763153
[5/24] Train loss=0.45126715302467346
[10/24] Train loss=0.46520644426345825
[15/24] Train loss=0.41956329345703125
[20/24] Train loss=0.4306214451789856
Test set avg_accuracy=68.98% avg_sensitivity=57.58%, avg_specificity=73.23% avg_auc=72.19%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.450851 Test loss=0.601538 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.4406535029411316
[5/24] Train loss=0.44309478998184204
[10/24] Train loss=0.45632755756378174
[15/24] Train loss=0.41547441482543945
[20/24] Train loss=0.43215274810791016
Test set avg_accuracy=74.17% avg_sensitivity=48.80%, avg_specificity=83.61% avg_auc=74.67%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.449302 Test loss=0.567503 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.4440539479255676
[5/24] Train loss=0.4417757987976074
[10/24] Train loss=0.46185407042503357
[15/24] Train loss=0.42016464471817017
[20/24] Train loss=0.44599249958992004
Test set avg_accuracy=76.71% avg_sensitivity=30.57%, avg_specificity=93.89% avg_auc=79.86%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.454010 Test loss=0.486829 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.456469863653183
[5/24] Train loss=0.4523501992225647
[10/24] Train loss=0.4646608829498291
[15/24] Train loss=0.42125028371810913
[20/24] Train loss=0.43228182196617126
Test set avg_accuracy=67.97% avg_sensitivity=57.39%, avg_specificity=71.91% avg_auc=71.27%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.454845 Test loss=0.612068 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.44152846932411194
[5/24] Train loss=0.4455169141292572
[10/24] Train loss=0.4607774019241333
[15/24] Train loss=0.42259660363197327
[20/24] Train loss=0.42813539505004883
Test set avg_accuracy=65.47% avg_sensitivity=60.03%, avg_specificity=67.49% avg_auc=69.82%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.452884 Test loss=0.627613 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.44682207703590393
[5/24] Train loss=0.45863768458366394
[10/24] Train loss=0.46933436393737793
[15/24] Train loss=0.43359866738319397
[20/24] Train loss=0.43802326917648315
Test set avg_accuracy=70.51% avg_sensitivity=52.30%, avg_specificity=77.29% avg_auc=72.08%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.456869 Test loss=0.603274 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.4489452540874481
[5/24] Train loss=0.45436763763427734
[10/24] Train loss=0.46940040588378906
[15/24] Train loss=0.41843748092651367
[20/24] Train loss=0.43369022011756897
Test set avg_accuracy=69.97% avg_sensitivity=50.86%, avg_specificity=77.09% avg_auc=69.78%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.453530 Test loss=0.603452 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.43940046429634094
[5/24] Train loss=0.4464149475097656
[10/24] Train loss=0.46102678775787354
[15/24] Train loss=0.41644883155822754
[20/24] Train loss=0.43131783604621887
Test set avg_accuracy=71.34% avg_sensitivity=51.20%, avg_specificity=78.84% avg_auc=72.35%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.451459 Test loss=0.592166 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.45111513137817383
[5/24] Train loss=0.45112344622612
[10/24] Train loss=0.46705198287963867
[15/24] Train loss=0.4383336901664734
[20/24] Train loss=0.43261104822158813
Test set avg_accuracy=70.87% avg_sensitivity=53.45%, avg_specificity=77.36% avg_auc=73.11%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.454752 Test loss=0.593940 Current lr=[0.000156543481933168]

[0/24] Train loss=0.44522708654403687
[5/24] Train loss=0.45154502987861633
[10/24] Train loss=0.46501755714416504
[15/24] Train loss=0.430142879486084
[20/24] Train loss=0.42979809641838074
Test set avg_accuracy=67.93% avg_sensitivity=54.27%, avg_specificity=73.02% avg_auc=69.97%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.454033 Test loss=0.612631 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.4424641728401184
[5/24] Train loss=0.4424279034137726
[10/24] Train loss=0.45966219902038574
[15/24] Train loss=0.42440468072891235
[20/24] Train loss=0.4409063756465912
Test set avg_accuracy=72.53% avg_sensitivity=50.82%, avg_specificity=80.61% avg_auc=73.41%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.450728 Test loss=0.585030 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.45088109374046326
[5/24] Train loss=0.45399370789527893
[10/24] Train loss=0.4694109261035919
[15/24] Train loss=0.4221830368041992
[20/24] Train loss=0.4309367835521698
Test set avg_accuracy=72.21% avg_sensitivity=47.84%, avg_specificity=81.29% avg_auc=71.56%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.453719 Test loss=0.587126 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.4391802251338959
[5/24] Train loss=0.4452664852142334
[10/24] Train loss=0.4633977711200714
[15/24] Train loss=0.42582958936691284
[20/24] Train loss=0.4277716279029846
Test set avg_accuracy=65.95% avg_sensitivity=57.53%, avg_specificity=69.09% avg_auc=69.31%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.448796 Test loss=0.621668 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.443942666053772
[5/24] Train loss=0.4427257776260376
[10/24] Train loss=0.45812052488327026
[15/24] Train loss=0.4186713993549347
[20/24] Train loss=0.428080290555954
Test set avg_accuracy=68.68% avg_sensitivity=55.57%, avg_specificity=73.57% avg_auc=71.32%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.447963 Test loss=0.604118 Current lr=[0.000134135431043539]

[0/24] Train loss=0.4467383027076721
[5/24] Train loss=0.444394588470459
[10/24] Train loss=0.46244868636131287
[15/24] Train loss=0.41872766613960266
[20/24] Train loss=0.4324905574321747
Test set avg_accuracy=68.83% avg_sensitivity=56.53%, avg_specificity=73.41% avg_auc=71.37%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.448693 Test loss=0.605534 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.43618571758270264
[5/24] Train loss=0.44020840525627136
[10/24] Train loss=0.45619288086891174
[15/24] Train loss=0.41711723804473877
[20/24] Train loss=0.4256572425365448
Test set avg_accuracy=66.54% avg_sensitivity=58.06%, avg_specificity=69.69% avg_auc=70.14%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.444438 Test loss=0.614638 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.4310319423675537
[5/24] Train loss=0.4406277537345886
[10/24] Train loss=0.4556986093521118
[15/24] Train loss=0.41988319158554077
[20/24] Train loss=0.43209534883499146
Test set avg_accuracy=64.99% avg_sensitivity=59.69%, avg_specificity=66.96% avg_auc=69.65%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.444953 Test loss=0.625707 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.433775931596756
[5/24] Train loss=0.4420645534992218
[10/24] Train loss=0.4588738977909088
[15/24] Train loss=0.42089134454727173
[20/24] Train loss=0.4263959527015686
Test set avg_accuracy=67.23% avg_sensitivity=58.40%, avg_specificity=70.51% avg_auc=71.11%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.444276 Test loss=0.608358 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.43401482701301575
[5/24] Train loss=0.4470237195491791
[10/24] Train loss=0.45810675621032715
[15/24] Train loss=0.4223838448524475
[20/24] Train loss=0.4262753427028656
Test set avg_accuracy=68.70% avg_sensitivity=57.34%, avg_specificity=72.93% avg_auc=72.32%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.443657 Test loss=0.596735 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.4333517849445343
[5/24] Train loss=0.44488129019737244
[10/24] Train loss=0.4600776731967926
[15/24] Train loss=0.4159446656703949
[20/24] Train loss=0.4269285500049591
Test set avg_accuracy=68.41% avg_sensitivity=56.14%, avg_specificity=72.98% avg_auc=70.94%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.443344 Test loss=0.603666 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.4345661401748657
[5/24] Train loss=0.44321051239967346
[10/24] Train loss=0.45798438787460327
[15/24] Train loss=0.41515737771987915
[20/24] Train loss=0.42774394154548645
Test set avg_accuracy=68.88% avg_sensitivity=55.81%, avg_specificity=73.75% avg_auc=71.07%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.444331 Test loss=0.603521 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.43818947672843933
[5/24] Train loss=0.44006070494651794
[10/24] Train loss=0.4543929100036621
[15/24] Train loss=0.41400274634361267
[20/24] Train loss=0.4256141185760498
Test set avg_accuracy=66.51% avg_sensitivity=58.21%, avg_specificity=69.60% avg_auc=70.32%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.442607 Test loss=0.612689 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.42790350317955017
[5/24] Train loss=0.442134827375412
[10/24] Train loss=0.45469874143600464
[15/24] Train loss=0.41101565957069397
[20/24] Train loss=0.4273638427257538
Test set avg_accuracy=65.64% avg_sensitivity=58.40%, avg_specificity=68.33% avg_auc=69.75%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.440131 Test loss=0.618452 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.42797237634658813
[5/24] Train loss=0.4408586621284485
[10/24] Train loss=0.45380544662475586
[15/24] Train loss=0.41301730275154114
[20/24] Train loss=0.4255225658416748
Test set avg_accuracy=65.13% avg_sensitivity=59.98%, avg_specificity=67.05% avg_auc=70.03%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.440071 Test loss=0.622092 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.43087154626846313
[5/24] Train loss=0.43867936730384827
[10/24] Train loss=0.4544958472251892
[15/24] Train loss=0.4110487699508667
[20/24] Train loss=0.42847347259521484
Test set avg_accuracy=68.22% avg_sensitivity=57.15%, avg_specificity=72.34% avg_auc=71.82%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.440974 Test loss=0.596865 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.43124163150787354
[5/24] Train loss=0.43850061297416687
[10/24] Train loss=0.4577370882034302
[15/24] Train loss=0.4151894450187683
[20/24] Train loss=0.425001859664917
Test set avg_accuracy=68.63% avg_sensitivity=56.86%, avg_specificity=73.02% avg_auc=71.57%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.441389 Test loss=0.596649 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.4338281750679016
[5/24] Train loss=0.4435281753540039
[10/24] Train loss=0.45755189657211304
[15/24] Train loss=0.4136609733104706
[20/24] Train loss=0.4242545962333679
Test set avg_accuracy=72.30% avg_sensitivity=51.68%, avg_specificity=79.99% avg_auc=73.42%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.444989 Test loss=0.578772 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.4376365840435028
[5/24] Train loss=0.4436740577220917
[10/24] Train loss=0.45765066146850586
[15/24] Train loss=0.4165302515029907
[20/24] Train loss=0.4239054024219513
Test set avg_accuracy=69.01% avg_sensitivity=56.24%, avg_specificity=73.77% avg_auc=71.91%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.443580 Test loss=0.593195 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.4286932349205017
[5/24] Train loss=0.44005388021469116
[10/24] Train loss=0.45361626148223877
[15/24] Train loss=0.4093705713748932
[20/24] Train loss=0.42414534091949463
Test set avg_accuracy=65.48% avg_sensitivity=59.45%, avg_specificity=67.73% avg_auc=70.20%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.439500 Test loss=0.616536 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.4273281395435333
[5/24] Train loss=0.43859419226646423
[10/24] Train loss=0.4534956216812134
[15/24] Train loss=0.40839576721191406
[20/24] Train loss=0.4239632487297058
Test set avg_accuracy=65.44% avg_sensitivity=59.50%, avg_specificity=67.66% avg_auc=69.97%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.438321 Test loss=0.616988 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.427558034658432
[5/24] Train loss=0.4418577551841736
[10/24] Train loss=0.4550585448741913
[15/24] Train loss=0.40900298953056335
[20/24] Train loss=0.42376306653022766
Test set avg_accuracy=66.42% avg_sensitivity=57.44%, avg_specificity=69.76% avg_auc=70.31%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.439108 Test loss=0.610423 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.4293675422668457
[5/24] Train loss=0.4414582848548889
[10/24] Train loss=0.4538702070713043
[15/24] Train loss=0.4097983241081238
[20/24] Train loss=0.4251698851585388
Test set avg_accuracy=66.09% avg_sensitivity=58.78%, avg_specificity=68.82% avg_auc=70.59%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.439684 Test loss=0.611750 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.4259842038154602
[5/24] Train loss=0.44232961535453796
[10/24] Train loss=0.4519893229007721
[15/24] Train loss=0.40948155522346497
[20/24] Train loss=0.4233538508415222
Test set avg_accuracy=66.26% avg_sensitivity=58.45%, avg_specificity=69.17% avg_auc=70.61%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.439007 Test loss=0.610992 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.4259691834449768
[5/24] Train loss=0.4378378689289093
[10/24] Train loss=0.4508877694606781
[15/24] Train loss=0.4092744290828705
[20/24] Train loss=0.4241383969783783
Test set avg_accuracy=65.70% avg_sensitivity=58.64%, avg_specificity=68.33% avg_auc=70.17%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.438305 Test loss=0.614861 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.4264604151248932
[5/24] Train loss=0.4392267167568207
[10/24] Train loss=0.4532548487186432
[15/24] Train loss=0.409421443939209
[20/24] Train loss=0.42391061782836914
Test set avg_accuracy=65.47% avg_sensitivity=58.21%, avg_specificity=68.17% avg_auc=69.74%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.437742 Test loss=0.615676 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.4282416105270386
[5/24] Train loss=0.44059544801712036
[10/24] Train loss=0.4523835778236389
[15/24] Train loss=0.4082700312137604
[20/24] Train loss=0.4223792850971222
Test set avg_accuracy=65.51% avg_sensitivity=58.69%, avg_specificity=68.05% avg_auc=70.08%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.437546 Test loss=0.614990 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.42479246854782104
[5/24] Train loss=0.43902868032455444
[10/24] Train loss=0.45017069578170776
[15/24] Train loss=0.40788158774375916
[20/24] Train loss=0.42347678542137146
Test set avg_accuracy=64.61% avg_sensitivity=59.12%, avg_specificity=66.65% avg_auc=69.48%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.436587 Test loss=0.621264 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.4258440136909485
[5/24] Train loss=0.4391380548477173
[10/24] Train loss=0.45105457305908203
[15/24] Train loss=0.40783122181892395
[20/24] Train loss=0.422806054353714
Test set avg_accuracy=64.60% avg_sensitivity=59.26%, avg_specificity=66.58% avg_auc=69.33%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.436421 Test loss=0.622348 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.4245851933956146
[5/24] Train loss=0.43896612524986267
[10/24] Train loss=0.45013540983200073
[15/24] Train loss=0.4076216518878937
[20/24] Train loss=0.4240399897098541
Test set avg_accuracy=64.41% avg_sensitivity=59.98%, avg_specificity=66.07% avg_auc=69.48%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.436308 Test loss=0.623869 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.42473557591438293
[5/24] Train loss=0.43921414017677307
[10/24] Train loss=0.4503607451915741
[15/24] Train loss=0.4074258506298065
[20/24] Train loss=0.4221477210521698
Test set avg_accuracy=64.54% avg_sensitivity=59.17%, avg_specificity=66.55% avg_auc=69.37%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.435877 Test loss=0.621579 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.42488086223602295
[5/24] Train loss=0.43780848383903503
[10/24] Train loss=0.45012444257736206
[15/24] Train loss=0.4067937731742859
[20/24] Train loss=0.4227292239665985
Test set avg_accuracy=64.01% avg_sensitivity=59.93%, avg_specificity=65.53% avg_auc=69.19%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.435797 Test loss=0.626799 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.42458122968673706
[5/24] Train loss=0.4396856427192688
[10/24] Train loss=0.45077019929885864
[15/24] Train loss=0.4068374037742615
[20/24] Train loss=0.4220941364765167
Test set avg_accuracy=64.11% avg_sensitivity=60.12%, avg_specificity=65.60% avg_auc=69.27%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.435764 Test loss=0.625907 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.42434248328208923
[5/24] Train loss=0.4376942217350006
[10/24] Train loss=0.45037367939949036
[15/24] Train loss=0.4066859781742096
[20/24] Train loss=0.4224211573600769
Test set avg_accuracy=64.00% avg_sensitivity=59.74%, avg_specificity=65.58% avg_auc=69.18%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.435318 Test loss=0.626126 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.4249218702316284
[5/24] Train loss=0.43823540210723877
[10/24] Train loss=0.45111533999443054
[15/24] Train loss=0.4058111310005188
[20/24] Train loss=0.42141541838645935
Test set avg_accuracy=63.76% avg_sensitivity=60.17%, avg_specificity=65.10% avg_auc=69.18%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.435267 Test loss=0.627665 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.42488932609558105
[5/24] Train loss=0.43918880820274353
[10/24] Train loss=0.45017576217651367
[15/24] Train loss=0.4063819646835327
[20/24] Train loss=0.4203570783138275
Test set avg_accuracy=64.09% avg_sensitivity=59.79%, avg_specificity=65.69% avg_auc=69.35%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.435140 Test loss=0.624806 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.4235709607601166
[5/24] Train loss=0.4396381676197052
[10/24] Train loss=0.4488178491592407
[15/24] Train loss=0.405176043510437
[20/24] Train loss=0.4200533628463745
Test set avg_accuracy=64.30% avg_sensitivity=60.08%, avg_specificity=65.87% avg_auc=69.53%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.434753 Test loss=0.623514 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.42315906286239624
[5/24] Train loss=0.4380809962749481
[10/24] Train loss=0.44832587242126465
[15/24] Train loss=0.40510129928588867
[20/24] Train loss=0.42025619745254517
Test set avg_accuracy=64.05% avg_sensitivity=60.12%, avg_specificity=65.51% avg_auc=69.40%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.434214 Test loss=0.625058 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.42304137349128723
[5/24] Train loss=0.4377634823322296
[10/24] Train loss=0.4481295049190521
[15/24] Train loss=0.40497133135795593
[20/24] Train loss=0.42110010981559753
Test set avg_accuracy=63.71% avg_sensitivity=60.51%, avg_specificity=64.90% avg_auc=69.21%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.434064 Test loss=0.627788 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.42326804995536804
[5/24] Train loss=0.4373326897621155
[10/24] Train loss=0.4490557014942169
[15/24] Train loss=0.40491315722465515
[20/24] Train loss=0.4200539290904999
Test set avg_accuracy=63.67% avg_sensitivity=60.46%, avg_specificity=64.87% avg_auc=69.17%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.433902 Test loss=0.628453 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.4231105446815491
[5/24] Train loss=0.43774646520614624
[10/24] Train loss=0.4485466778278351
[15/24] Train loss=0.40464094281196594
[20/24] Train loss=0.4197511672973633
Test set avg_accuracy=63.84% avg_sensitivity=60.27%, avg_specificity=65.17% avg_auc=69.31%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.433819 Test loss=0.626547 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.4226071834564209
[5/24] Train loss=0.4372515380382538
[10/24] Train loss=0.4481284022331238
[15/24] Train loss=0.4046361446380615
[20/24] Train loss=0.41995352506637573
Test set avg_accuracy=63.75% avg_sensitivity=60.41%, avg_specificity=64.99% avg_auc=69.26%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.433580 Test loss=0.627224 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.42266878485679626
[5/24] Train loss=0.43705421686172485
[10/24] Train loss=0.4482050836086273
[15/24] Train loss=0.4042956233024597
[20/24] Train loss=0.41996410489082336
Test set avg_accuracy=63.59% avg_sensitivity=60.36%, avg_specificity=64.80% avg_auc=69.19%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.433449 Test loss=0.628213 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.42286455631256104
[5/24] Train loss=0.4371319115161896
[10/24] Train loss=0.4481327533721924
[15/24] Train loss=0.4041905999183655
[20/24] Train loss=0.4196438491344452
Test set avg_accuracy=63.58% avg_sensitivity=60.46%, avg_specificity=64.74% avg_auc=69.21%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.433379 Test loss=0.628389 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.4225393235683441
[5/24] Train loss=0.4370131194591522
[10/24] Train loss=0.4480777382850647
[15/24] Train loss=0.40416860580444336
[20/24] Train loss=0.41963738203048706
Test set avg_accuracy=63.58% avg_sensitivity=60.46%, avg_specificity=64.74% avg_auc=69.20%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.433272 Test loss=0.628534 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.4225323498249054
[5/24] Train loss=0.4369131326675415
[10/24] Train loss=0.44804972410202026
[15/24] Train loss=0.404068261384964
[20/24] Train loss=0.41956865787506104
Test set avg_accuracy=63.55% avg_sensitivity=60.32%, avg_specificity=64.76% avg_auc=69.22%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.433208 Test loss=0.628303 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.4225217401981354
[5/24] Train loss=0.4369097650051117
[10/24] Train loss=0.4479658305644989
[15/24] Train loss=0.4040011167526245
[20/24] Train loss=0.41950300335884094
Test set avg_accuracy=63.54% avg_sensitivity=60.32%, avg_specificity=64.74% avg_auc=69.21%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.433159 Test loss=0.628535 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.4224851131439209
[5/24] Train loss=0.43683168292045593
[10/24] Train loss=0.4479685425758362
[15/24] Train loss=0.40394625067710876
[20/24] Train loss=0.41944992542266846
Test set avg_accuracy=63.53% avg_sensitivity=60.36%, avg_specificity=64.71% avg_auc=69.21%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.433120 Test loss=0.628632 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.4224623441696167
[5/24] Train loss=0.43679508566856384
[10/24] Train loss=0.4479424059391022
[15/24] Train loss=0.4039130210876465
[20/24] Train loss=0.4194209575653076
Test set avg_accuracy=63.53% avg_sensitivity=60.36%, avg_specificity=64.71% avg_auc=69.21%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.433089 Test loss=0.628690 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.4224454164505005
[5/24] Train loss=0.43676894903182983
[10/24] Train loss=0.4479318857192993
[15/24] Train loss=0.4038926362991333
[20/24] Train loss=0.41938844323158264
Test set avg_accuracy=63.54% avg_sensitivity=60.41%, avg_specificity=64.71% avg_auc=69.21%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.433067 Test loss=0.628706 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.42242980003356934
[5/24] Train loss=0.4367482364177704
[10/24] Train loss=0.44792330265045166
[15/24] Train loss=0.4038790166378021
[20/24] Train loss=0.41937318444252014
Test set avg_accuracy=63.54% avg_sensitivity=60.41%, avg_specificity=64.71% avg_auc=69.21%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.433052 Test loss=0.628718 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.4224228858947754
[5/24] Train loss=0.4367336630821228
[10/24] Train loss=0.44791629910469055
[15/24] Train loss=0.40387091040611267
[20/24] Train loss=0.4193635582923889
Test set avg_accuracy=63.54% avg_sensitivity=60.41%, avg_specificity=64.71% avg_auc=69.21%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.433042 Test loss=0.628726 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.42241862416267395
[5/24] Train loss=0.4367241859436035
[10/24] Train loss=0.4479125142097473
[15/24] Train loss=0.4038671851158142
[20/24] Train loss=0.4193592071533203
Test set avg_accuracy=63.54% avg_sensitivity=60.41%, avg_specificity=64.71% avg_auc=69.21%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.433037 Test loss=0.628729 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.42241644859313965
[5/24] Train loss=0.43671926856040955
[10/24] Train loss=0.4479108452796936
[15/24] Train loss=0.40386614203453064
[20/24] Train loss=0.41935789585113525
Test set avg_accuracy=63.54% avg_sensitivity=60.41%, avg_specificity=64.71% avg_auc=69.21%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.433035 Test loss=0.628729 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=75.07% sen=50.14%, spe=84.35%, auc=76.49%!
Fold[6] Avg_overlap=0.38%(±0.21859028626603308)
[0/24] Train loss=0.7018166184425354
[5/24] Train loss=0.7017323970794678
[10/24] Train loss=0.6985541582107544
[15/24] Train loss=0.6987565755844116
[20/24] Train loss=0.6983160376548767
Test set avg_accuracy=49.15% avg_sensitivity=54.27%, avg_specificity=47.20% avg_auc=50.66%
Best model saved!! Metric=-124.71660954468308!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.699448 Test loss=0.696765 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6971127986907959
[5/24] Train loss=0.696873128414154
[10/24] Train loss=0.6942129731178284
[15/24] Train loss=0.6937426328659058
[20/24] Train loss=0.6935629844665527
Test set avg_accuracy=52.02% avg_sensitivity=48.61%, avg_specificity=53.32% avg_auc=50.81%
Best model saved!! Metric=-121.24187268192695!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.694817 Test loss=0.692569 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6926715970039368
[5/24] Train loss=0.6923133134841919
[10/24] Train loss=0.6902884244918823
[15/24] Train loss=0.6893450021743774
[20/24] Train loss=0.6894832253456116
Test set avg_accuracy=54.66% avg_sensitivity=42.62%, avg_specificity=59.26% avg_auc=50.93%
Best model saved!! Metric=-118.52757018327208!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.690628 Test loss=0.688886 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6887455582618713
[5/24] Train loss=0.6876308917999268
[10/24] Train loss=0.6863723993301392
[15/24] Train loss=0.6849170923233032
[20/24] Train loss=0.6854445338249207
Test set avg_accuracy=54.70% avg_sensitivity=42.15%, avg_specificity=59.49% avg_auc=50.91%
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.686507 Test loss=0.685312 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6849035620689392
[5/24] Train loss=0.6832042336463928
[10/24] Train loss=0.6824381947517395
[15/24] Train loss=0.6803923845291138
[20/24] Train loss=0.6809964776039124
Test set avg_accuracy=54.74% avg_sensitivity=41.58%, avg_specificity=59.76% avg_auc=50.85%
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.682305 Test loss=0.681144 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6802412271499634
[5/24] Train loss=0.6776942014694214
[10/24] Train loss=0.6774179935455322
[15/24] Train loss=0.6746554374694824
[20/24] Train loss=0.6753432154655457
Test set avg_accuracy=59.80% avg_sensitivity=29.51%, avg_specificity=71.36% avg_auc=50.81%
Best model saved!! Metric=-114.50760922963441!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.677063 Test loss=0.676229 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6747074723243713
[5/24] Train loss=0.6713249683380127
[10/24] Train loss=0.6713811755180359
[15/24] Train loss=0.6677080988883972
[20/24] Train loss=0.6684139370918274
Test set avg_accuracy=62.62% avg_sensitivity=22.68%, avg_specificity=77.86% avg_auc=50.78%
Best model saved!! Metric=-112.06894393019644!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.670712 Test loss=0.669899 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6677479147911072
[5/24] Train loss=0.6628535389900208
[10/24] Train loss=0.663578450679779
[15/24] Train loss=0.6585254669189453
[20/24] Train loss=0.6589657068252563
Test set avg_accuracy=65.66% avg_sensitivity=15.79%, avg_specificity=84.69% avg_auc=50.81%
Best model saved!! Metric=-109.0408126132148!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.662421 Test loss=0.661442 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6585028171539307
[5/24] Train loss=0.6511534452438354
[10/24] Train loss=0.6525149941444397
[15/24] Train loss=0.644974410533905
[20/24] Train loss=0.6451416611671448
Test set avg_accuracy=68.71% avg_sensitivity=8.44%, avg_specificity=91.71% avg_auc=50.96%
Best model saved!! Metric=-106.18319792387311!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.650614 Test loss=0.649073 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6449379324913025
[5/24] Train loss=0.633611261844635
[10/24] Train loss=0.6362019777297974
[15/24] Train loss=0.6247981786727905
[20/24] Train loss=0.6249377131462097
Test set avg_accuracy=69.34% avg_sensitivity=7.02%, avg_specificity=93.11% avg_auc=51.28%
Best model saved!! Metric=-105.25069550606524!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.633125 Test loss=0.631604 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6254889965057373
[5/24] Train loss=0.6082332730293274
[10/24] Train loss=0.6135668754577637
[15/24] Train loss=0.5972111225128174
[20/24] Train loss=0.5992814898490906
Test set avg_accuracy=72.33% avg_sensitivity=0.38%, avg_specificity=99.78% avg_auc=51.63%
Best model saved!! Metric=-101.87984279639659!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.609058 Test loss=0.610908 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6013249754905701
[5/24] Train loss=0.5754970908164978
[10/24] Train loss=0.5886451005935669
[15/24] Train loss=0.5690253376960754
[20/24] Train loss=0.5782657265663147
Test set avg_accuracy=72.38% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=52.51%
Best model saved!! Metric=-101.10996545715737!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.583307 Test loss=0.595023 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5839463472366333
[5/24] Train loss=0.5470552444458008
[10/24] Train loss=0.5745069980621338
[15/24] Train loss=0.5538365840911865
[20/24] Train loss=0.5683057308197021
Test set avg_accuracy=72.36% avg_sensitivity=0.05%, avg_specificity=99.95% avg_auc=54.46%
Best model saved!! Metric=-99.19464075682731!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.568157 Test loss=0.587471 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5776854753494263
[5/24] Train loss=0.5380908846855164
[10/24] Train loss=0.5693878531455994
[15/24] Train loss=0.547636866569519
[20/24] Train loss=0.5619150996208191
Test set avg_accuracy=72.41% avg_sensitivity=0.24%, avg_specificity=99.95% avg_auc=57.04%
Best model saved!! Metric=-96.37290685578512!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.562181 Test loss=0.584145 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5753106474876404
[5/24] Train loss=0.5317518711090088
[10/24] Train loss=0.5675638914108276
[15/24] Train loss=0.5425553917884827
[20/24] Train loss=0.5575507283210754
Test set avg_accuracy=72.42% avg_sensitivity=0.38%, avg_specificity=99.91% avg_auc=59.22%
Best model saved!! Metric=-94.07112118112303!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.559289 Test loss=0.582323 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5741450786590576
[5/24] Train loss=0.5277297496795654
[10/24] Train loss=0.5672690272331238
[15/24] Train loss=0.5386983156204224
[20/24] Train loss=0.5528861284255981
Test set avg_accuracy=72.47% avg_sensitivity=0.57%, avg_specificity=99.91% avg_auc=60.95%
Best model saved!! Metric=-92.1045190502928!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.556836 Test loss=0.580275 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5713146328926086
[5/24] Train loss=0.5228689312934875
[10/24] Train loss=0.5646566152572632
[15/24] Train loss=0.5337421894073486
[20/24] Train loss=0.5447587966918945
Test set avg_accuracy=72.47% avg_sensitivity=0.71%, avg_specificity=99.86% avg_auc=64.10%
Best model saved!! Metric=-88.8606575428715!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.552750 Test loss=0.576934 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5650362968444824
[5/24] Train loss=0.5174641609191895
[10/24] Train loss=0.5594719052314758
[15/24] Train loss=0.5246952772140503
[20/24] Train loss=0.5309226512908936
Test set avg_accuracy=72.90% avg_sensitivity=2.97%, avg_specificity=99.59% avg_auc=68.92%
Best model saved!! Metric=-81.6182985667963!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.545767 Test loss=0.569345 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.561284601688385
[5/24] Train loss=0.5130297541618347
[10/24] Train loss=0.5511200428009033
[15/24] Train loss=0.5054187774658203
[20/24] Train loss=0.5124667286872864
Test set avg_accuracy=72.67% avg_sensitivity=13.11%, avg_specificity=95.39% avg_auc=69.47%
Best model saved!! Metric=-75.35551086000834!!
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.534162 Test loss=0.581158 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5525290966033936
[5/24] Train loss=0.5029594302177429
[10/24] Train loss=0.5361526012420654
[15/24] Train loss=0.4847618639469147
[20/24] Train loss=0.4900471866130829
Test set avg_accuracy=73.57% avg_sensitivity=27.49%, avg_specificity=91.15% avg_auc=70.74%
Best model saved!! Metric=-63.056885465187676!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.522939 Test loss=0.597987 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5267268419265747
[5/24] Train loss=0.48134472966194153
[10/24] Train loss=0.5179522633552551
[15/24] Train loss=0.4631902575492859
[20/24] Train loss=0.47546350955963135
Test set avg_accuracy=64.54% avg_sensitivity=50.83%, avg_specificity=69.78% avg_auc=63.33%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.506923 Test loss=0.650797 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5142249464988708
[5/24] Train loss=0.4799080789089203
[10/24] Train loss=0.5073928833007812
[15/24] Train loss=0.4520336985588074
[20/24] Train loss=0.46793249249458313
Test set avg_accuracy=56.61% avg_sensitivity=56.91%, avg_specificity=56.50% avg_auc=58.72%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.495847 Test loss=0.669907 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5002304315567017
[5/24] Train loss=0.4729067087173462
[10/24] Train loss=0.4943833351135254
[15/24] Train loss=0.44555577635765076
[20/24] Train loss=0.4590114653110504
Test set avg_accuracy=61.47% avg_sensitivity=47.48%, avg_specificity=66.81% avg_auc=60.35%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.485808 Test loss=0.656177 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.48141300678253174
[5/24] Train loss=0.4606565833091736
[10/24] Train loss=0.48545533418655396
[15/24] Train loss=0.43549710512161255
[20/24] Train loss=0.44878143072128296
Test set avg_accuracy=61.77% avg_sensitivity=50.59%, avg_specificity=66.04% avg_auc=61.44%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.476076 Test loss=0.651662 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.47176024317741394
[5/24] Train loss=0.45183953642845154
[10/24] Train loss=0.47482386231422424
[15/24] Train loss=0.4260650873184204
[20/24] Train loss=0.441786527633667
Test set avg_accuracy=61.29% avg_sensitivity=56.81%, avg_specificity=63.00% avg_auc=64.31%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.470006 Test loss=0.651408 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4885140657424927
[5/24] Train loss=0.4494987726211548
[10/24] Train loss=0.46689093112945557
[15/24] Train loss=0.41843512654304504
[20/24] Train loss=0.4238429665565491
Test set avg_accuracy=57.77% avg_sensitivity=62.66%, avg_specificity=55.91% avg_auc=64.12%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.461828 Test loss=0.656990 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.45272892713546753
[5/24] Train loss=0.4344482123851776
[10/24] Train loss=0.4510990083217621
[15/24] Train loss=0.40316417813301086
[20/24] Train loss=0.4144314229488373
Test set avg_accuracy=55.42% avg_sensitivity=64.83%, avg_specificity=51.83% avg_auc=62.92%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.444942 Test loss=0.665016 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.43821534514427185
[5/24] Train loss=0.4187740981578827
[10/24] Train loss=0.43360960483551025
[15/24] Train loss=0.3868860900402069
[20/24] Train loss=0.3817257881164551
Test set avg_accuracy=52.29% avg_sensitivity=66.20%, avg_specificity=46.99% avg_auc=61.70%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.428929 Test loss=0.712492 Current lr=[0.000210185142098938]

[0/24] Train loss=0.4176519513130188
[5/24] Train loss=0.4018090069293976
[10/24] Train loss=0.4286046028137207
[15/24] Train loss=0.37968361377716064
[20/24] Train loss=0.3779681622982025
Test set avg_accuracy=66.78% avg_sensitivity=59.88%, avg_specificity=69.42% avg_auc=70.35%
Best model saved!! Metric=-59.57135982979273!!
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.424654 Test loss=0.590663 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4278031885623932
[5/24] Train loss=0.4156401455402374
[10/24] Train loss=0.4315202832221985
[15/24] Train loss=0.3846917450428009
[20/24] Train loss=0.3891890347003937
Test set avg_accuracy=57.42% avg_sensitivity=59.59%, avg_specificity=56.59% avg_auc=64.71%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.422220 Test loss=0.655447 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4195403754711151
[5/24] Train loss=0.4049266576766968
[10/24] Train loss=0.4157668948173523
[15/24] Train loss=0.37294405698776245
[20/24] Train loss=0.3526259660720825
Test set avg_accuracy=61.42% avg_sensitivity=69.59%, avg_specificity=58.30% avg_auc=69.97%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.413426 Test loss=0.634672 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3991014063358307
[5/24] Train loss=0.40397411584854126
[10/24] Train loss=0.41678398847579956
[15/24] Train loss=0.3759728968143463
[20/24] Train loss=0.3539697229862213
Test set avg_accuracy=59.41% avg_sensitivity=64.12%, avg_specificity=57.62% avg_auc=66.88%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.404591 Test loss=0.652525 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3956761360168457
[5/24] Train loss=0.39650392532348633
[10/24] Train loss=0.4050186276435852
[15/24] Train loss=0.3785640001296997
[20/24] Train loss=0.35903090238571167
Test set avg_accuracy=63.42% avg_sensitivity=68.46%, avg_specificity=61.50% avg_auc=70.60%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.401211 Test loss=0.622690 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.41006147861480713
[5/24] Train loss=0.40327149629592896
[10/24] Train loss=0.41961386799812317
[15/24] Train loss=0.38108935952186584
[20/24] Train loss=0.36903277039527893
Test set avg_accuracy=62.11% avg_sensitivity=68.93%, avg_specificity=59.51% avg_auc=70.22%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.411696 Test loss=0.628067 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.42125552892684937
[5/24] Train loss=0.40579670667648315
[10/24] Train loss=0.40638619661331177
[15/24] Train loss=0.376779705286026
[20/24] Train loss=0.35220471024513245
Test set avg_accuracy=62.10% avg_sensitivity=66.53%, avg_specificity=60.41% avg_auc=69.17%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.407182 Test loss=0.629620 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3945947289466858
[5/24] Train loss=0.3984541594982147
[10/24] Train loss=0.40305495262145996
[15/24] Train loss=0.37102776765823364
[20/24] Train loss=0.3572051227092743
Test set avg_accuracy=63.36% avg_sensitivity=74.16%, avg_specificity=59.24% avg_auc=72.73%
Best model saved!! Metric=-56.514006247615164!!
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.400717 Test loss=0.633268 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4037036597728729
[5/24] Train loss=0.3947823941707611
[10/24] Train loss=0.40774843096733093
[15/24] Train loss=0.36844146251678467
[20/24] Train loss=0.35404321551322937
Test set avg_accuracy=58.52% avg_sensitivity=72.56%, avg_specificity=53.16% avg_auc=69.36%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.398482 Test loss=0.664873 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.39575520157814026
[5/24] Train loss=0.3855508267879486
[10/24] Train loss=0.3984842300415039
[15/24] Train loss=0.37320396304130554
[20/24] Train loss=0.35183650255203247
Test set avg_accuracy=61.09% avg_sensitivity=72.14%, avg_specificity=56.88% avg_auc=70.53%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.393202 Test loss=0.648903 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.39623427391052246
[5/24] Train loss=0.3871367871761322
[10/24] Train loss=0.3927951157093048
[15/24] Train loss=0.36257287859916687
[20/24] Train loss=0.34113964438438416
Test set avg_accuracy=62.19% avg_sensitivity=73.83%, avg_specificity=57.74% avg_auc=71.76%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.396959 Test loss=0.643059 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.39207249879837036
[5/24] Train loss=0.3831906318664551
[10/24] Train loss=0.3974463641643524
[15/24] Train loss=0.3841992914676666
[20/24] Train loss=0.34076154232025146
Test set avg_accuracy=63.23% avg_sensitivity=71.76%, avg_specificity=59.97% avg_auc=71.97%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.394372 Test loss=0.629124 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3962635099887848
[5/24] Train loss=0.38856959342956543
[10/24] Train loss=0.3959144055843353
[15/24] Train loss=0.3631974160671234
[20/24] Train loss=0.34991538524627686
Test set avg_accuracy=58.41% avg_sensitivity=71.52%, avg_specificity=53.41% avg_auc=69.11%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.394524 Test loss=0.669013 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4094592034816742
[5/24] Train loss=0.37836045026779175
[10/24] Train loss=0.38124150037765503
[15/24] Train loss=0.36311280727386475
[20/24] Train loss=0.3471755385398865
Test set avg_accuracy=61.94% avg_sensitivity=72.94%, avg_specificity=57.74% avg_auc=71.20%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.388107 Test loss=0.648153 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3894711434841156
[5/24] Train loss=0.3811745345592499
[10/24] Train loss=0.3826123774051666
[15/24] Train loss=0.3624480664730072
[20/24] Train loss=0.3355036675930023
Test set avg_accuracy=63.28% avg_sensitivity=70.72%, avg_specificity=60.44% avg_auc=71.42%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.389721 Test loss=0.631726 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.39528611302375793
[5/24] Train loss=0.38743042945861816
[10/24] Train loss=0.4196581244468689
[15/24] Train loss=0.36597099900245667
[20/24] Train loss=0.3396534323692322
Test set avg_accuracy=60.52% avg_sensitivity=73.50%, avg_specificity=55.57% avg_auc=71.44%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.395160 Test loss=0.650184 Current lr=[0.00029967723776099]

[0/24] Train loss=0.37997785210609436
[5/24] Train loss=0.37972936034202576
[10/24] Train loss=0.3893277645111084
[15/24] Train loss=0.35725775361061096
[20/24] Train loss=0.33971986174583435
Test set avg_accuracy=63.58% avg_sensitivity=73.03%, avg_specificity=59.97% avg_auc=72.66%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.388237 Test loss=0.629723 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3883449137210846
[5/24] Train loss=0.37491780519485474
[10/24] Train loss=0.3888091742992401
[15/24] Train loss=0.3631017804145813
[20/24] Train loss=0.34440237283706665
Test set avg_accuracy=63.37% avg_sensitivity=69.78%, avg_specificity=60.93% avg_auc=71.37%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.387755 Test loss=0.629077 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.38218986988067627
[5/24] Train loss=0.3755935728549957
[10/24] Train loss=0.3974376320838928
[15/24] Train loss=0.36137130856513977
[20/24] Train loss=0.3347395062446594
Test set avg_accuracy=70.14% avg_sensitivity=69.68%, avg_specificity=70.32% avg_auc=76.91%
Best model saved!! Metric=-38.94682218678413!!
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.387214 Test loss=0.572427 Current lr=[0.000299720220882401]

[0/24] Train loss=0.38065844774246216
[5/24] Train loss=0.370370090007782
[10/24] Train loss=0.38754597306251526
[15/24] Train loss=0.3570636808872223
[20/24] Train loss=0.3371707499027252
Test set avg_accuracy=68.66% avg_sensitivity=70.11%, avg_specificity=68.11% avg_auc=75.06%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.383307 Test loss=0.586998 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3892670273780823
[5/24] Train loss=0.36500442028045654
[10/24] Train loss=0.3896794319152832
[15/24] Train loss=0.3593238592147827
[20/24] Train loss=0.3462861180305481
Test set avg_accuracy=72.42% avg_sensitivity=68.69%, avg_specificity=73.84% avg_auc=77.91%
Best model saved!! Metric=-33.132498600955785!!
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.386151 Test loss=0.559022 Current lr=[0.000298904600941902]

[0/24] Train loss=0.39665377140045166
[5/24] Train loss=0.37419435381889343
[10/24] Train loss=0.389099657535553
[15/24] Train loss=0.3505609631538391
[20/24] Train loss=0.3316439688205719
Test set avg_accuracy=65.31% avg_sensitivity=68.13%, avg_specificity=64.24% avg_auc=71.65%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.385514 Test loss=0.616641 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.37741270661354065
[5/24] Train loss=0.3743269145488739
[10/24] Train loss=0.38236919045448303
[15/24] Train loss=0.36662930250167847
[20/24] Train loss=0.34910330176353455
Test set avg_accuracy=69.38% avg_sensitivity=64.12%, avg_specificity=71.38% avg_auc=74.09%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.391770 Test loss=0.570888 Current lr=[0.000297555943323901]

[0/24] Train loss=0.39557090401649475
[5/24] Train loss=0.37135788798332214
[10/24] Train loss=0.39774972200393677
[15/24] Train loss=0.39581191539764404
[20/24] Train loss=0.4141218960285187
Test set avg_accuracy=65.43% avg_sensitivity=62.28%, avg_specificity=66.63% avg_auc=70.29%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.396028 Test loss=0.607560 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.4286632835865021
[5/24] Train loss=0.39011871814727783
[10/24] Train loss=0.3995915949344635
[15/24] Train loss=0.36178451776504517
[20/24] Train loss=0.33883821964263916
Test set avg_accuracy=63.18% avg_sensitivity=69.45%, avg_specificity=60.78% avg_auc=71.26%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.395064 Test loss=0.626168 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3808966279029846
[5/24] Train loss=0.38806313276290894
[10/24] Train loss=0.38428550958633423
[15/24] Train loss=0.3554653227329254
[20/24] Train loss=0.34216493368148804
Test set avg_accuracy=63.85% avg_sensitivity=74.16%, avg_specificity=59.92% avg_auc=73.58%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.387139 Test loss=0.629319 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.395513653755188
[5/24] Train loss=0.3737117052078247
[10/24] Train loss=0.3809179961681366
[15/24] Train loss=0.3573378920555115
[20/24] Train loss=0.3466458320617676
Test set avg_accuracy=66.45% avg_sensitivity=68.46%, avg_specificity=65.68% avg_auc=72.18%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.382714 Test loss=0.607094 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.4065258204936981
[5/24] Train loss=0.37656641006469727
[10/24] Train loss=0.38415810465812683
[15/24] Train loss=0.3505188524723053
[20/24] Train loss=0.3264075815677643
Test set avg_accuracy=63.48% avg_sensitivity=68.22%, avg_specificity=61.67% avg_auc=71.03%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.382470 Test loss=0.627074 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3822696805000305
[5/24] Train loss=0.36658909916877747
[10/24] Train loss=0.38054099678993225
[15/24] Train loss=0.3559487760066986
[20/24] Train loss=0.33246171474456787
Test set avg_accuracy=64.38% avg_sensitivity=75.67%, avg_specificity=60.06% avg_auc=74.46%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.377289 Test loss=0.626828 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3791637122631073
[5/24] Train loss=0.37320220470428467
[10/24] Train loss=0.3837580978870392
[15/24] Train loss=0.35625529289245605
[20/24] Train loss=0.33004966378211975
Test set avg_accuracy=66.82% avg_sensitivity=74.73%, avg_specificity=63.81% avg_auc=75.82%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.378815 Test loss=0.602770 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.38461360335350037
[5/24] Train loss=0.36949020624160767
[10/24] Train loss=0.3854786455631256
[15/24] Train loss=0.352374792098999
[20/24] Train loss=0.3362133502960205
Test set avg_accuracy=68.67% avg_sensitivity=70.91%, avg_specificity=67.82% avg_auc=75.98%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.378422 Test loss=0.581467 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.37345966696739197
[5/24] Train loss=0.3769293427467346
[10/24] Train loss=0.38539907336235046
[15/24] Train loss=0.35346025228500366
[20/24] Train loss=0.3339461088180542
Test set avg_accuracy=67.79% avg_sensitivity=68.84%, avg_specificity=67.39% avg_auc=74.53%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.381773 Test loss=0.589345 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.37669435143470764
[5/24] Train loss=0.3717976212501526
[10/24] Train loss=0.37097474932670593
[15/24] Train loss=0.34647029638290405
[20/24] Train loss=0.357846200466156
Test set avg_accuracy=66.85% avg_sensitivity=76.61%, avg_specificity=63.12% avg_auc=77.60%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.386491 Test loss=0.605269 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.413268119096756
[5/24] Train loss=0.3818230926990509
[10/24] Train loss=0.37640878558158875
[15/24] Train loss=0.3513377606868744
[20/24] Train loss=0.3386560082435608
Test set avg_accuracy=67.96% avg_sensitivity=72.65%, avg_specificity=66.16% avg_auc=76.52%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.383187 Test loss=0.587822 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.37988629937171936
[5/24] Train loss=0.3739992678165436
[10/24] Train loss=0.3734522759914398
[15/24] Train loss=0.35475459694862366
[20/24] Train loss=0.33945396542549133
Test set avg_accuracy=65.94% avg_sensitivity=64.03%, avg_specificity=66.67% avg_auc=71.10%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.381686 Test loss=0.603636 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3832983076572418
[5/24] Train loss=0.36631739139556885
[10/24] Train loss=0.37323668599128723
[15/24] Train loss=0.3485538065433502
[20/24] Train loss=0.3324536383152008
Test set avg_accuracy=69.82% avg_sensitivity=74.02%, avg_specificity=68.21% avg_auc=78.91%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.378049 Test loss=0.572337 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3762843608856201
[5/24] Train loss=0.37676095962524414
[10/24] Train loss=0.3838311731815338
[15/24] Train loss=0.365382581949234
[20/24] Train loss=0.32159367203712463
Test set avg_accuracy=69.35% avg_sensitivity=72.56%, avg_specificity=68.12% avg_auc=77.30%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.380772 Test loss=0.573871 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3703426122665405
[5/24] Train loss=0.367896169424057
[10/24] Train loss=0.3731865882873535
[15/24] Train loss=0.3449265956878662
[20/24] Train loss=0.3230828642845154
Test set avg_accuracy=65.00% avg_sensitivity=69.87%, avg_specificity=63.14% avg_auc=72.62%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.374516 Test loss=0.616505 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3711468279361725
[5/24] Train loss=0.37393927574157715
[10/24] Train loss=0.38309526443481445
[15/24] Train loss=0.3539271354675293
[20/24] Train loss=0.3636631965637207
Test set avg_accuracy=61.18% avg_sensitivity=72.65%, avg_specificity=56.81% avg_auc=71.70%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.381357 Test loss=0.647666 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.380188524723053
[5/24] Train loss=0.3805496394634247
[10/24] Train loss=0.38690251111984253
[15/24] Train loss=0.3452208936214447
[20/24] Train loss=0.35590821504592896
Test set avg_accuracy=69.21% avg_sensitivity=74.73%, avg_specificity=67.10% avg_auc=78.33%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.382192 Test loss=0.580178 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.38911548256874084
[5/24] Train loss=0.37928491830825806
[10/24] Train loss=0.3921869099140167
[15/24] Train loss=0.3494552969932556
[20/24] Train loss=0.3330043852329254
Test set avg_accuracy=64.74% avg_sensitivity=72.84%, avg_specificity=61.65% avg_auc=74.40%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.377928 Test loss=0.614617 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3669827878475189
[5/24] Train loss=0.368164986371994
[10/24] Train loss=0.3722982108592987
[15/24] Train loss=0.34446293115615845
[20/24] Train loss=0.3240000903606415
Test set avg_accuracy=69.11% avg_sensitivity=71.71%, avg_specificity=68.12% avg_auc=77.08%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.373567 Test loss=0.574830 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.36814308166503906
[5/24] Train loss=0.3583468198776245
[10/24] Train loss=0.3783867657184601
[15/24] Train loss=0.3450057804584503
[20/24] Train loss=0.3455984890460968
Test set avg_accuracy=71.69% avg_sensitivity=71.81%, avg_specificity=71.65% avg_auc=79.26%
Best model saved!! Metric=-31.594222425890166!!
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.378023 Test loss=0.553882 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3851604163646698
[5/24] Train loss=0.37187638878822327
[10/24] Train loss=0.3756365478038788
[15/24] Train loss=0.3545755445957184
[20/24] Train loss=0.32582953572273254
Test set avg_accuracy=67.23% avg_sensitivity=66.10%, avg_specificity=67.66% avg_auc=72.95%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.377666 Test loss=0.590731 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.36634039878845215
[5/24] Train loss=0.3645467460155487
[10/24] Train loss=0.37092843651771545
[15/24] Train loss=0.34309807419776917
[20/24] Train loss=0.32833194732666016
Test set avg_accuracy=67.71% avg_sensitivity=72.51%, avg_specificity=65.88% avg_auc=76.75%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.372011 Test loss=0.586633 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.36132165789604187
[5/24] Train loss=0.3636113703250885
[10/24] Train loss=0.37028586864471436
[15/24] Train loss=0.3423005938529968
[20/24] Train loss=0.32567694783210754
Test set avg_accuracy=67.75% avg_sensitivity=74.96%, avg_specificity=64.99% avg_auc=77.93%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.371156 Test loss=0.587875 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3651438057422638
[5/24] Train loss=0.3626345694065094
[10/24] Train loss=0.37337401509284973
[15/24] Train loss=0.3435439169406891
[20/24] Train loss=0.32784953713417053
Test set avg_accuracy=68.98% avg_sensitivity=70.11%, avg_specificity=68.56% avg_auc=76.00%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.372275 Test loss=0.576829 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.365754097700119
[5/24] Train loss=0.3636336326599121
[10/24] Train loss=0.3793475031852722
[15/24] Train loss=0.3421633243560791
[20/24] Train loss=0.32815927267074585
Test set avg_accuracy=68.39% avg_sensitivity=73.03%, avg_specificity=66.61% avg_auc=77.01%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.369079 Test loss=0.579546 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3591564893722534
[5/24] Train loss=0.36120477318763733
[10/24] Train loss=0.36877113580703735
[15/24] Train loss=0.34700942039489746
[20/24] Train loss=0.32381945848464966
Test set avg_accuracy=71.48% avg_sensitivity=73.74%, avg_specificity=70.62% avg_auc=80.47%
Best model saved!! Metric=-29.687288724078073!!
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.367905 Test loss=0.544480 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.36307254433631897
[5/24] Train loss=0.35807543992996216
[10/24] Train loss=0.37054643034935
[15/24] Train loss=0.3411036431789398
[20/24] Train loss=0.31584829092025757
Test set avg_accuracy=67.49% avg_sensitivity=74.73%, avg_specificity=64.72% avg_auc=76.91%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.364509 Test loss=0.588102 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3584974408149719
[5/24] Train loss=0.36078667640686035
[10/24] Train loss=0.3734627664089203
[15/24] Train loss=0.3414919674396515
[20/24] Train loss=0.32273051142692566
Test set avg_accuracy=69.54% avg_sensitivity=73.31%, avg_specificity=68.11% avg_auc=78.23%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.368812 Test loss=0.568771 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3711611032485962
[5/24] Train loss=0.35834479331970215
[10/24] Train loss=0.37043890357017517
[15/24] Train loss=0.34387972950935364
[20/24] Train loss=0.3187347948551178
Test set avg_accuracy=68.28% avg_sensitivity=72.51%, avg_specificity=66.67% avg_auc=76.98%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.367652 Test loss=0.579144 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3570915460586548
[5/24] Train loss=0.35659050941467285
[10/24] Train loss=0.37551170587539673
[15/24] Train loss=0.3403658866882324
[20/24] Train loss=0.31444379687309265
Test set avg_accuracy=67.21% avg_sensitivity=72.70%, avg_specificity=65.12% avg_auc=76.30%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.366428 Test loss=0.589140 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.35621559619903564
[5/24] Train loss=0.3531065583229065
[10/24] Train loss=0.36165928840637207
[15/24] Train loss=0.3466993570327759
[20/24] Train loss=0.32765844464302063
Test set avg_accuracy=72.03% avg_sensitivity=68.08%, avg_specificity=73.54% avg_auc=78.63%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.369692 Test loss=0.536956 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.366344153881073
[5/24] Train loss=0.3603358864784241
[10/24] Train loss=0.3746170103549957
[15/24] Train loss=0.34592270851135254
[20/24] Train loss=0.31589582562446594
Test set avg_accuracy=70.78% avg_sensitivity=72.51%, avg_specificity=70.12% avg_auc=78.85%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.369004 Test loss=0.557541 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.3637446165084839
[5/24] Train loss=0.35395655035972595
[10/24] Train loss=0.3661644160747528
[15/24] Train loss=0.3443112373352051
[20/24] Train loss=0.32316890358924866
Test set avg_accuracy=70.82% avg_sensitivity=70.20%, avg_specificity=71.06% avg_auc=78.08%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.366768 Test loss=0.554053 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3662269711494446
[5/24] Train loss=0.35266992449760437
[10/24] Train loss=0.36781519651412964
[15/24] Train loss=0.34667420387268066
[20/24] Train loss=0.32698163390159607
Test set avg_accuracy=65.96% avg_sensitivity=69.73%, avg_specificity=64.53% avg_auc=73.66%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.372017 Test loss=0.607403 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3645821511745453
[5/24] Train loss=0.3657256066799164
[10/24] Train loss=0.3760296106338501
[15/24] Train loss=0.34937581419944763
[20/24] Train loss=0.3160572350025177
Test set avg_accuracy=69.80% avg_sensitivity=73.31%, avg_specificity=68.47% avg_auc=78.26%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.370651 Test loss=0.569063 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.3623780906200409
[5/24] Train loss=0.3656778037548065
[10/24] Train loss=0.3698901832103729
[15/24] Train loss=0.3430848717689514
[20/24] Train loss=0.3174600899219513
Test set avg_accuracy=63.70% avg_sensitivity=73.55%, avg_specificity=59.94% avg_auc=73.50%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.366850 Test loss=0.635326 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3687140941619873
[5/24] Train loss=0.36126044392585754
[10/24] Train loss=0.36954614520072937
[15/24] Train loss=0.3388108015060425
[20/24] Train loss=0.31849613785743713
Test set avg_accuracy=69.17% avg_sensitivity=72.56%, avg_specificity=67.87% avg_auc=77.13%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.365880 Test loss=0.573653 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3788529932498932
[5/24] Train loss=0.36293545365333557
[10/24] Train loss=0.37316691875457764
[15/24] Train loss=0.34121352434158325
[20/24] Train loss=0.31613805890083313
Test set avg_accuracy=68.98% avg_sensitivity=70.39%, avg_specificity=68.45% avg_auc=76.05%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.367228 Test loss=0.576423 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3730308711528778
[5/24] Train loss=0.3646623492240906
[10/24] Train loss=0.3706102669239044
[15/24] Train loss=0.33532992005348206
[20/24] Train loss=0.31689146161079407
Test set avg_accuracy=69.60% avg_sensitivity=75.11%, avg_specificity=67.49% avg_auc=78.98%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.364721 Test loss=0.570881 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3681543469429016
[5/24] Train loss=0.35638678073883057
[10/24] Train loss=0.365852952003479
[15/24] Train loss=0.3377589285373688
[20/24] Train loss=0.3202640116214752
Test set avg_accuracy=69.47% avg_sensitivity=70.91%, avg_specificity=68.92% avg_auc=76.94%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.363300 Test loss=0.569192 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.36304497718811035
[5/24] Train loss=0.35753384232521057
[10/24] Train loss=0.3655923306941986
[15/24] Train loss=0.3397463262081146
[20/24] Train loss=0.3197159469127655
Test set avg_accuracy=71.05% avg_sensitivity=72.23%, avg_specificity=70.61% avg_auc=78.84%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.361807 Test loss=0.550433 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.35933229327201843
[5/24] Train loss=0.35150542855262756
[10/24] Train loss=0.36382073163986206
[15/24] Train loss=0.33631548285484314
[20/24] Train loss=0.31530824303627014
Test set avg_accuracy=70.98% avg_sensitivity=72.28%, avg_specificity=70.48% avg_auc=79.35%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.362222 Test loss=0.548909 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3614003658294678
[5/24] Train loss=0.35551518201828003
[10/24] Train loss=0.3746943473815918
[15/24] Train loss=0.34686750173568726
[20/24] Train loss=0.3218388855457306
Test set avg_accuracy=68.41% avg_sensitivity=73.22%, avg_specificity=66.58% avg_auc=77.25%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.369844 Test loss=0.582834 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.36677342653274536
[5/24] Train loss=0.3604246973991394
[10/24] Train loss=0.3668003976345062
[15/24] Train loss=0.3429877758026123
[20/24] Train loss=0.3210310637950897
Test set avg_accuracy=69.95% avg_sensitivity=73.31%, avg_specificity=68.66% avg_auc=78.27%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.364636 Test loss=0.566022 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.364614337682724
[5/24] Train loss=0.35831218957901
[10/24] Train loss=0.36729732155799866
[15/24] Train loss=0.337056040763855
[20/24] Train loss=0.3153115212917328
Test set avg_accuracy=66.47% avg_sensitivity=72.37%, avg_specificity=64.22% avg_auc=74.92%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.361831 Test loss=0.606259 Current lr=[0.000156543481933168]

[0/24] Train loss=0.35577940940856934
[5/24] Train loss=0.3536464273929596
[10/24] Train loss=0.3622630536556244
[15/24] Train loss=0.3355240225791931
[20/24] Train loss=0.31764501333236694
Test set avg_accuracy=67.01% avg_sensitivity=71.71%, avg_specificity=65.21% avg_auc=75.57%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.360340 Test loss=0.595737 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.35574841499328613
[5/24] Train loss=0.3529488146305084
[10/24] Train loss=0.3736625611782074
[15/24] Train loss=0.33777403831481934
[20/24] Train loss=0.3157784044742584
Test set avg_accuracy=67.45% avg_sensitivity=68.74%, avg_specificity=66.95% avg_auc=74.31%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.364268 Test loss=0.593237 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.35228776931762695
[5/24] Train loss=0.35173168778419495
[10/24] Train loss=0.37131717801094055
[15/24] Train loss=0.3465224802494049
[20/24] Train loss=0.323640376329422
Test set avg_accuracy=66.15% avg_sensitivity=71.99%, avg_specificity=63.91% avg_auc=74.60%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.365218 Test loss=0.611026 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3642096519470215
[5/24] Train loss=0.35564500093460083
[10/24] Train loss=0.36994966864585876
[15/24] Train loss=0.3357412815093994
[20/24] Train loss=0.3159788250923157
Test set avg_accuracy=68.15% avg_sensitivity=70.53%, avg_specificity=67.24% avg_auc=75.59%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.363476 Test loss=0.586041 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.36632320284843445
[5/24] Train loss=0.3600432276725769
[10/24] Train loss=0.364224910736084
[15/24] Train loss=0.3389149606227875
[20/24] Train loss=0.3182812035083771
Test set avg_accuracy=68.82% avg_sensitivity=71.43%, avg_specificity=67.82% avg_auc=76.32%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.364634 Test loss=0.579138 Current lr=[0.000134135431043539]

[0/24] Train loss=0.3598571717739105
[5/24] Train loss=0.3579142689704895
[10/24] Train loss=0.3679450452327728
[15/24] Train loss=0.35025840997695923
[20/24] Train loss=0.32132604718208313
Test set avg_accuracy=70.82% avg_sensitivity=67.14%, avg_specificity=72.23% avg_auc=76.81%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.365738 Test loss=0.553648 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3581138551235199
[5/24] Train loss=0.3518534302711487
[10/24] Train loss=0.3846709430217743
[15/24] Train loss=0.3431871235370636
[20/24] Train loss=0.3152083158493042
Test set avg_accuracy=69.41% avg_sensitivity=70.96%, avg_specificity=68.83% avg_auc=76.86%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.367932 Test loss=0.569799 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.3631192147731781
[5/24] Train loss=0.3513970971107483
[10/24] Train loss=0.3605296015739441
[15/24] Train loss=0.3379806578159332
[20/24] Train loss=0.3343694806098938
Test set avg_accuracy=66.11% avg_sensitivity=73.69%, avg_specificity=63.21% avg_auc=75.14%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.365018 Test loss=0.611397 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.37102246284484863
[5/24] Train loss=0.35534337162971497
[10/24] Train loss=0.37024736404418945
[15/24] Train loss=0.33539238572120667
[20/24] Train loss=0.31603366136550903
Test set avg_accuracy=66.82% avg_sensitivity=75.81%, avg_specificity=63.39% avg_auc=76.87%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.366656 Test loss=0.600145 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.36463403701782227
[5/24] Train loss=0.34926682710647583
[10/24] Train loss=0.36085131764411926
[15/24] Train loss=0.34200993180274963
[20/24] Train loss=0.31758934259414673
Test set avg_accuracy=71.69% avg_sensitivity=68.93%, avg_specificity=72.75% avg_auc=78.52%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.362591 Test loss=0.540662 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.36448290944099426
[5/24] Train loss=0.36011531949043274
[10/24] Train loss=0.3686382472515106
[15/24] Train loss=0.3345143496990204
[20/24] Train loss=0.32154580950737
Test set avg_accuracy=70.10% avg_sensitivity=72.47%, avg_specificity=69.20% avg_auc=78.55%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.363093 Test loss=0.560814 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.36184999346733093
[5/24] Train loss=0.3492404520511627
[10/24] Train loss=0.3623778820037842
[15/24] Train loss=0.33280256390571594
[20/24] Train loss=0.32465600967407227
Test set avg_accuracy=67.23% avg_sensitivity=71.95%, avg_specificity=65.43% avg_auc=75.64%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.361162 Test loss=0.594845 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3581359386444092
[5/24] Train loss=0.3558838367462158
[10/24] Train loss=0.37760961055755615
[15/24] Train loss=0.3367637097835541
[20/24] Train loss=0.3216761350631714
Test set avg_accuracy=66.97% avg_sensitivity=71.05%, avg_specificity=65.41% avg_auc=74.73%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.363485 Test loss=0.599302 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.35375139117240906
[5/24] Train loss=0.34654828906059265
[10/24] Train loss=0.3613375425338745
[15/24] Train loss=0.33318763971328735
[20/24] Train loss=0.31675446033477783
Test set avg_accuracy=68.57% avg_sensitivity=74.16%, avg_specificity=66.43% avg_auc=77.84%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.358759 Test loss=0.578577 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.35149699449539185
[5/24] Train loss=0.34748125076293945
[10/24] Train loss=0.36141347885131836
[15/24] Train loss=0.3296431005001068
[20/24] Train loss=0.31035447120666504
Test set avg_accuracy=68.09% avg_sensitivity=74.35%, avg_specificity=65.70% avg_auc=77.39%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.354525 Test loss=0.583560 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3467022776603699
[5/24] Train loss=0.3453277051448822
[10/24] Train loss=0.3584863543510437
[15/24] Train loss=0.3276870846748352
[20/24] Train loss=0.3095771074295044
Test set avg_accuracy=67.14% avg_sensitivity=72.32%, avg_specificity=65.16% avg_auc=75.65%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.352167 Test loss=0.596236 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.34449711441993713
[5/24] Train loss=0.3408301770687103
[10/24] Train loss=0.3576957881450653
[15/24] Train loss=0.32629260420799255
[20/24] Train loss=0.30742189288139343
Test set avg_accuracy=66.56% avg_sensitivity=74.16%, avg_specificity=63.66% avg_auc=76.14%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.350496 Test loss=0.601720 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3429476022720337
[5/24] Train loss=0.3443449139595032
[10/24] Train loss=0.35763081908226013
[15/24] Train loss=0.32684892416000366
[20/24] Train loss=0.30772387981414795
Test set avg_accuracy=67.03% avg_sensitivity=73.46%, avg_specificity=64.58% avg_auc=76.09%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.350238 Test loss=0.597422 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3431210517883301
[5/24] Train loss=0.3397117853164673
[10/24] Train loss=0.35908642411231995
[15/24] Train loss=0.3257751762866974
[20/24] Train loss=0.30731400847435
Test set avg_accuracy=66.86% avg_sensitivity=73.60%, avg_specificity=64.29% avg_auc=75.88%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.349575 Test loss=0.601184 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.34192946553230286
[5/24] Train loss=0.34272500872612
[10/24] Train loss=0.36219847202301025
[15/24] Train loss=0.32578372955322266
[20/24] Train loss=0.3061767816543579
Test set avg_accuracy=66.42% avg_sensitivity=73.93%, avg_specificity=63.55% avg_auc=75.52%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.350777 Test loss=0.609123 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.34200817346572876
[5/24] Train loss=0.34116068482398987
[10/24] Train loss=0.36182570457458496
[15/24] Train loss=0.3261009454727173
[20/24] Train loss=0.30678579211235046
Test set avg_accuracy=66.84% avg_sensitivity=73.88%, avg_specificity=64.15% avg_auc=76.18%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.351457 Test loss=0.600716 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.34099820256233215
[5/24] Train loss=0.3391788601875305
[10/24] Train loss=0.35933515429496765
[15/24] Train loss=0.3262351453304291
[20/24] Train loss=0.3079626262187958
Test set avg_accuracy=66.93% avg_sensitivity=73.97%, avg_specificity=64.24% avg_auc=76.16%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.349742 Test loss=0.599620 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3402135968208313
[5/24] Train loss=0.33919572830200195
[10/24] Train loss=0.35946130752563477
[15/24] Train loss=0.32576924562454224
[20/24] Train loss=0.3113406002521515
Test set avg_accuracy=66.39% avg_sensitivity=73.27%, avg_specificity=63.77% avg_auc=75.58%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.350123 Test loss=0.606592 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.33996400237083435
[5/24] Train loss=0.3373144268989563
[10/24] Train loss=0.36101233959198
[15/24] Train loss=0.32479947805404663
[20/24] Train loss=0.3094194829463959
Test set avg_accuracy=66.81% avg_sensitivity=71.90%, avg_specificity=64.87% avg_auc=75.15%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.348981 Test loss=0.602717 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.33728209137916565
[5/24] Train loss=0.3366330564022064
[10/24] Train loss=0.3596329689025879
[15/24] Train loss=0.32416021823883057
[20/24] Train loss=0.30819106101989746
Test set avg_accuracy=66.64% avg_sensitivity=72.09%, avg_specificity=64.56% avg_auc=75.46%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.348582 Test loss=0.602187 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.3392058312892914
[5/24] Train loss=0.3349577784538269
[10/24] Train loss=0.3648506999015808
[15/24] Train loss=0.32643264532089233
[20/24] Train loss=0.309036523103714
Test set avg_accuracy=66.90% avg_sensitivity=69.73%, avg_specificity=65.82% avg_auc=74.73%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.349656 Test loss=0.598878 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.3403673768043518
[5/24] Train loss=0.33908140659332275
[10/24] Train loss=0.3625824749469757
[15/24] Train loss=0.32648229598999023
[20/24] Train loss=0.30353236198425293
Test set avg_accuracy=67.50% avg_sensitivity=71.48%, avg_specificity=65.98% avg_auc=75.98%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.348404 Test loss=0.590178 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3371902108192444
[5/24] Train loss=0.3376729190349579
[10/24] Train loss=0.3562556803226471
[15/24] Train loss=0.3257167637348175
[20/24] Train loss=0.3006761372089386
Test set avg_accuracy=65.78% avg_sensitivity=71.90%, avg_specificity=63.45% avg_auc=74.23%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.346688 Test loss=0.618622 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3367060422897339
[5/24] Train loss=0.3349229097366333
[10/24] Train loss=0.3558102548122406
[15/24] Train loss=0.3232647180557251
[20/24] Train loss=0.30124929547309875
Test set avg_accuracy=65.66% avg_sensitivity=71.95%, avg_specificity=63.27% avg_auc=74.40%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.345317 Test loss=0.618248 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.335374116897583
[5/24] Train loss=0.3364332616329193
[10/24] Train loss=0.35382089018821716
[15/24] Train loss=0.3234016001224518
[20/24] Train loss=0.2998269498348236
Test set avg_accuracy=65.59% avg_sensitivity=73.27%, avg_specificity=62.66% avg_auc=74.82%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.345387 Test loss=0.619072 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.33623647689819336
[5/24] Train loss=0.33640825748443604
[10/24] Train loss=0.35396215319633484
[15/24] Train loss=0.32273465394973755
[20/24] Train loss=0.30168241262435913
Test set avg_accuracy=65.29% avg_sensitivity=73.55%, avg_specificity=62.13% avg_auc=74.66%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.345147 Test loss=0.623982 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.33410099148750305
[5/24] Train loss=0.33598557114601135
[10/24] Train loss=0.35414353013038635
[15/24] Train loss=0.3231643736362457
[20/24] Train loss=0.3025222420692444
Test set avg_accuracy=65.26% avg_sensitivity=74.30%, avg_specificity=61.81% avg_auc=74.93%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.345809 Test loss=0.623833 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.33486419916152954
[5/24] Train loss=0.331335186958313
[10/24] Train loss=0.35841408371925354
[15/24] Train loss=0.3235609233379364
[20/24] Train loss=0.30294153094291687
Test set avg_accuracy=65.27% avg_sensitivity=72.47%, avg_specificity=62.53% avg_auc=74.37%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.345733 Test loss=0.623084 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3345249891281128
[5/24] Train loss=0.3415345549583435
[10/24] Train loss=0.3554225265979767
[15/24] Train loss=0.32421356439590454
[20/24] Train loss=0.3032500445842743
Test set avg_accuracy=65.26% avg_sensitivity=73.88%, avg_specificity=61.97% avg_auc=74.75%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.346943 Test loss=0.624962 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.336854487657547
[5/24] Train loss=0.335085391998291
[10/24] Train loss=0.35920149087905884
[15/24] Train loss=0.32502368092536926
[20/24] Train loss=0.3019407391548157
Test set avg_accuracy=65.04% avg_sensitivity=74.96%, avg_specificity=61.25% avg_auc=74.84%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.346360 Test loss=0.627699 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.33452513813972473
[5/24] Train loss=0.33756962418556213
[10/24] Train loss=0.35498255491256714
[15/24] Train loss=0.3239971995353699
[20/24] Train loss=0.30145493149757385
Test set avg_accuracy=65.10% avg_sensitivity=74.73%, avg_specificity=61.43% avg_auc=74.91%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.345793 Test loss=0.626640 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.3344298303127289
[5/24] Train loss=0.33540764451026917
[10/24] Train loss=0.3568859398365021
[15/24] Train loss=0.32382261753082275
[20/24] Train loss=0.30365538597106934
Test set avg_accuracy=65.59% avg_sensitivity=74.73%, avg_specificity=62.10% avg_auc=75.37%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.345486 Test loss=0.618140 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.3340809643268585
[5/24] Train loss=0.3335804045200348
[10/24] Train loss=0.35405275225639343
[15/24] Train loss=0.3238435983657837
[20/24] Train loss=0.3012414276599884
Test set avg_accuracy=65.60% avg_sensitivity=74.82%, avg_specificity=62.08% avg_auc=75.29%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.344249 Test loss=0.619293 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.33269912004470825
[5/24] Train loss=0.33054283261299133
[10/24] Train loss=0.35314714908599854
[15/24] Train loss=0.3213236331939697
[20/24] Train loss=0.29981330037117004
Test set avg_accuracy=65.43% avg_sensitivity=74.73%, avg_specificity=61.88% avg_auc=75.21%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.342731 Test loss=0.621569 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.33195242285728455
[5/24] Train loss=0.32946550846099854
[10/24] Train loss=0.3519275188446045
[15/24] Train loss=0.32122358679771423
[20/24] Train loss=0.29877883195877075
Test set avg_accuracy=65.05% avg_sensitivity=74.73%, avg_specificity=61.36% avg_auc=74.85%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.342152 Test loss=0.628613 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.331117182970047
[5/24] Train loss=0.32835662364959717
[10/24] Train loss=0.35147470235824585
[15/24] Train loss=0.32139936089515686
[20/24] Train loss=0.2987362742424011
Test set avg_accuracy=65.39% avg_sensitivity=75.01%, avg_specificity=61.72% avg_auc=75.07%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.341495 Test loss=0.624630 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3301963806152344
[5/24] Train loss=0.3286569118499756
[10/24] Train loss=0.35104018449783325
[15/24] Train loss=0.3207823932170868
[20/24] Train loss=0.2986009418964386
Test set avg_accuracy=65.12% avg_sensitivity=75.20%, avg_specificity=61.27% avg_auc=74.92%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.341188 Test loss=0.628272 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3300187587738037
[5/24] Train loss=0.3274863660335541
[10/24] Train loss=0.3511313199996948
[15/24] Train loss=0.32085761427879333
[20/24] Train loss=0.29841870069503784
Test set avg_accuracy=65.01% avg_sensitivity=75.01%, avg_specificity=61.20% avg_auc=74.83%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.341015 Test loss=0.629554 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.32996463775634766
[5/24] Train loss=0.32746031880378723
[10/24] Train loss=0.3506450057029724
[15/24] Train loss=0.3205868601799011
[20/24] Train loss=0.29848945140838623
Test set avg_accuracy=64.96% avg_sensitivity=75.25%, avg_specificity=61.04% avg_auc=74.84%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.340843 Test loss=0.630131 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3297486901283264
[5/24] Train loss=0.3271845877170563
[10/24] Train loss=0.3506520688533783
[15/24] Train loss=0.32055583596229553
[20/24] Train loss=0.298384428024292
Test set avg_accuracy=64.91% avg_sensitivity=75.29%, avg_specificity=60.95% avg_auc=74.78%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.340734 Test loss=0.631227 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3296428918838501
[5/24] Train loss=0.32695621252059937
[10/24] Train loss=0.35052719712257385
[15/24] Train loss=0.32045575976371765
[20/24] Train loss=0.29832059144973755
Test set avg_accuracy=64.88% avg_sensitivity=75.29%, avg_specificity=60.91% avg_auc=74.77%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.340636 Test loss=0.631733 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3295370042324066
[5/24] Train loss=0.326798677444458
[10/24] Train loss=0.3504285216331482
[15/24] Train loss=0.32041773200035095
[20/24] Train loss=0.2982772886753082
Test set avg_accuracy=64.88% avg_sensitivity=75.34%, avg_specificity=60.89% avg_auc=74.77%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.340559 Test loss=0.631865 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.3294544219970703
[5/24] Train loss=0.3266850411891937
[10/24] Train loss=0.35035333037376404
[15/24] Train loss=0.32037094235420227
[20/24] Train loss=0.2982441782951355
Test set avg_accuracy=64.90% avg_sensitivity=75.39%, avg_specificity=60.89% avg_auc=74.77%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.340499 Test loss=0.632131 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.32939091324806213
[5/24] Train loss=0.3265845477581024
[10/24] Train loss=0.35029658675193787
[15/24] Train loss=0.32032936811447144
[20/24] Train loss=0.2982172667980194
Test set avg_accuracy=64.88% avg_sensitivity=75.39%, avg_specificity=60.87% avg_auc=74.76%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.340450 Test loss=0.632363 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.32934877276420593
[5/24] Train loss=0.32651761174201965
[10/24] Train loss=0.35025662183761597
[15/24] Train loss=0.3203001320362091
[20/24] Train loss=0.29819852113723755
Test set avg_accuracy=64.87% avg_sensitivity=75.39%, avg_specificity=60.86% avg_auc=74.75%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.340417 Test loss=0.632548 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3293185830116272
[5/24] Train loss=0.3264656364917755
[10/24] Train loss=0.3502293527126312
[15/24] Train loss=0.32028380036354065
[20/24] Train loss=0.29818156361579895
Test set avg_accuracy=64.87% avg_sensitivity=75.39%, avg_specificity=60.86% avg_auc=74.75%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.340394 Test loss=0.632659 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3293009102344513
[5/24] Train loss=0.3264336585998535
[10/24] Train loss=0.3502117395401001
[15/24] Train loss=0.3202733099460602
[20/24] Train loss=0.29817086458206177
Test set avg_accuracy=64.88% avg_sensitivity=75.44%, avg_specificity=60.86% avg_auc=74.74%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.340378 Test loss=0.632728 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3292911946773529
[5/24] Train loss=0.32641565799713135
[10/24] Train loss=0.35020118951797485
[15/24] Train loss=0.3202674388885498
[20/24] Train loss=0.2981654703617096
Test set avg_accuracy=64.88% avg_sensitivity=75.44%, avg_specificity=60.86% avg_auc=74.74%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.340370 Test loss=0.632767 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3292868137359619
[5/24] Train loss=0.326407790184021
[10/24] Train loss=0.35019659996032715
[15/24] Train loss=0.3202653229236603
[20/24] Train loss=0.29816365242004395
Test set avg_accuracy=64.88% avg_sensitivity=75.44%, avg_specificity=60.86% avg_auc=74.74%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.340366 Test loss=0.632782 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=71.48% sen=73.74%, spe=70.62%, auc=80.47%!
Fold[7] Avg_overlap=0.27%(±0.3115303700688568)
[0/24] Train loss=0.7011741995811462
[5/24] Train loss=0.7000065445899963
[10/24] Train loss=0.6996169090270996
[15/24] Train loss=0.698865532875061
[20/24] Train loss=0.6979718804359436
Test set avg_accuracy=47.81% avg_sensitivity=52.82%, avg_specificity=46.13% avg_auc=49.20%
Best model saved!! Metric=-130.03091608416082!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.699346 Test loss=0.696993 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6972628831863403
[5/24] Train loss=0.6958552002906799
[10/24] Train loss=0.6956994533538818
[15/24] Train loss=0.6950458288192749
[20/24] Train loss=0.6937358379364014
Test set avg_accuracy=51.11% avg_sensitivity=46.92%, avg_specificity=52.51% avg_auc=49.33%
Best model saved!! Metric=-126.13334757061489!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.695412 Test loss=0.693009 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6935864090919495
[5/24] Train loss=0.6917498707771301
[10/24] Train loss=0.6917832493782043
[15/24] Train loss=0.6911397576332092
[20/24] Train loss=0.6893633604049683
Test set avg_accuracy=54.31% avg_sensitivity=39.56%, avg_specificity=59.26% avg_auc=49.38%
Best model saved!! Metric=-123.48759777981299!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.691430 Test loss=0.688838 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6896884441375732
[5/24] Train loss=0.6873761415481567
[10/24] Train loss=0.6876391172409058
[15/24] Train loss=0.6869063973426819
[20/24] Train loss=0.6847156882286072
Test set avg_accuracy=57.38% avg_sensitivity=33.14%, avg_specificity=65.52% avg_auc=49.50%
Best model saved!! Metric=-120.44820415666936!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.687219 Test loss=0.684457 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.685545027256012
[5/24] Train loss=0.6827065348625183
[10/24] Train loss=0.6832391023635864
[15/24] Train loss=0.682437002658844
[20/24] Train loss=0.679448664188385
Test set avg_accuracy=57.53% avg_sensitivity=32.31%, avg_specificity=65.99% avg_auc=49.62%
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.682673 Test loss=0.679385 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6808097958564758
[5/24] Train loss=0.6772491931915283
[10/24] Train loss=0.6777626276016235
[15/24] Train loss=0.6770221590995789
[20/24] Train loss=0.6729806661605835
Test set avg_accuracy=63.89% avg_sensitivity=20.66%, avg_specificity=78.41% avg_auc=49.87%
Best model saved!! Metric=-113.1582359790516!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.677173 Test loss=0.673301 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6751039028167725
[5/24] Train loss=0.6706028580665588
[10/24] Train loss=0.6711593866348267
[15/24] Train loss=0.6706943511962891
[20/24] Train loss=0.6652140617370605
Test set avg_accuracy=64.24% avg_sensitivity=19.89%, avg_specificity=79.14% avg_auc=49.98%
Best model saved!! Metric=-112.74326659920246!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.670593 Test loss=0.665916 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6682617664337158
[5/24] Train loss=0.662455677986145
[10/24] Train loss=0.6632066965103149
[15/24] Train loss=0.6624079346656799
[20/24] Train loss=0.6547458171844482
Test set avg_accuracy=64.66% avg_sensitivity=19.78%, avg_specificity=79.74% avg_auc=50.24%
Best model saved!! Metric=-111.58092727868268!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.662203 Test loss=0.655612 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6588761210441589
[5/24] Train loss=0.6508656144142151
[10/24] Train loss=0.6515958309173584
[15/24] Train loss=0.6503790616989136
[20/24] Train loss=0.6392560005187988
Test set avg_accuracy=65.25% avg_sensitivity=16.68%, avg_specificity=81.56% avg_auc=50.43%
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.650109 Test loss=0.640754 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6455138921737671
[5/24] Train loss=0.6339542269706726
[10/24] Train loss=0.635090172290802
[15/24] Train loss=0.6331411600112915
[20/24] Train loss=0.6169654130935669
Test set avg_accuracy=74.51% avg_sensitivity=0.78%, avg_specificity=99.27% avg_auc=50.64%
Best model saved!! Metric=-100.80442325188642!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.632839 Test loss=0.620234 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6272670030593872
[5/24] Train loss=0.6105263233184814
[10/24] Train loss=0.6139578819274902
[15/24] Train loss=0.6105569005012512
[20/24] Train loss=0.5885939598083496
Test set avg_accuracy=74.70% avg_sensitivity=0.36%, avg_specificity=99.67% avg_auc=50.92%
Best model saved!! Metric=-100.34364229719199!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.610531 Test loss=0.596450 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6065357327461243
[5/24] Train loss=0.5839198231697083
[10/24] Train loss=0.5931496024131775
[15/24] Train loss=0.5880330204963684
[20/24] Train loss=0.5611292719841003
Test set avg_accuracy=74.88% avg_sensitivity=0.21%, avg_specificity=99.97% avg_auc=51.51%
Best model saved!! Metric=-99.43143736526375!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.588272 Test loss=0.576939 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5910357236862183
[5/24] Train loss=0.562113344669342
[10/24] Train loss=0.5799514055252075
[15/24] Train loss=0.5742028951644897
[20/24] Train loss=0.5451458096504211
Test set avg_accuracy=74.87% avg_sensitivity=0.21%, avg_specificity=99.95% avg_auc=52.79%
Best model saved!! Metric=-98.18133802341792!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.573671 Test loss=0.567114 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5829235315322876
[5/24] Train loss=0.5532475709915161
[10/24] Train loss=0.572796642780304
[15/24] Train loss=0.566215991973877
[20/24] Train loss=0.5378495454788208
Test set avg_accuracy=74.82% avg_sensitivity=0.21%, avg_specificity=99.88% avg_auc=55.31%
Best model saved!! Metric=-95.78894156115216!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.566292 Test loss=0.563131 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5791745781898499
[5/24] Train loss=0.5478239059448242
[10/24] Train loss=0.5691663026809692
[15/24] Train loss=0.565222442150116
[20/24] Train loss=0.5301558375358582
Test set avg_accuracy=74.73% avg_sensitivity=0.31%, avg_specificity=99.72% avg_auc=59.28%
Best model saved!! Metric=-91.96475084754006!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.562693 Test loss=0.560844 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5770403742790222
[5/24] Train loss=0.5440557599067688
[10/24] Train loss=0.5678545832633972
[15/24] Train loss=0.5626139044761658
[20/24] Train loss=0.5254148840904236
Test set avg_accuracy=74.82% avg_sensitivity=0.52%, avg_specificity=99.77% avg_auc=61.96%
Best model saved!! Metric=-88.92655881185907!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.560035 Test loss=0.558072 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5721380114555359
[5/24] Train loss=0.5392464995384216
[10/24] Train loss=0.5644574761390686
[15/24] Train loss=0.5583478808403015
[20/24] Train loss=0.5178531408309937
Test set avg_accuracy=74.84% avg_sensitivity=0.41%, avg_specificity=99.84% avg_auc=64.78%
Best model saved!! Metric=-86.11616332201156!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.555441 Test loss=0.554417 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5673394203186035
[5/24] Train loss=0.531631588935852
[10/24] Train loss=0.5591916441917419
[15/24] Train loss=0.5534257292747498
[20/24] Train loss=0.5080767869949341
Test set avg_accuracy=74.93% avg_sensitivity=1.45%, avg_specificity=99.62% avg_auc=69.49%
Best model saved!! Metric=-80.50766860427989!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.549088 Test loss=0.546766 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5561255216598511
[5/24] Train loss=0.5220339894294739
[10/24] Train loss=0.5503066182136536
[15/24] Train loss=0.5429767370223999
[20/24] Train loss=0.48653358221054077
Test set avg_accuracy=74.65% avg_sensitivity=5.44%, avg_specificity=97.90% avg_auc=71.66%
Best model saved!! Metric=-76.35605520937985!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.537203 Test loss=0.553397 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.538291335105896
[5/24] Train loss=0.5107080936431885
[10/24] Train loss=0.5360204577445984
[15/24] Train loss=0.5294882655143738
[20/24] Train loss=0.47000259160995483
Test set avg_accuracy=74.14% avg_sensitivity=25.43%, avg_specificity=90.50% avg_auc=71.18%
Best model saved!! Metric=-64.747393081455!!
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.522887 Test loss=0.622583 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5196599960327148
[5/24] Train loss=0.4978661835193634
[10/24] Train loss=0.5177720785140991
[15/24] Train loss=0.5164731740951538
[20/24] Train loss=0.45680728554725647
Test set avg_accuracy=69.45% avg_sensitivity=29.47%, avg_specificity=82.88% avg_auc=59.88%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.511003 Test loss=0.667328 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5050076842308044
[5/24] Train loss=0.48364782333374023
[10/24] Train loss=0.5112213492393494
[15/24] Train loss=0.5036221742630005
[20/24] Train loss=0.4512629210948944
Test set avg_accuracy=71.71% avg_sensitivity=26.41%, avg_specificity=86.92% avg_auc=58.68%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.501086 Test loss=0.658008 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4955058991909027
[5/24] Train loss=0.4706890285015106
[10/24] Train loss=0.5015992522239685
[15/24] Train loss=0.5017977952957153
[20/24] Train loss=0.44766244292259216
Test set avg_accuracy=73.35% avg_sensitivity=29.05%, avg_specificity=88.22% avg_auc=60.56%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.495291 Test loss=0.650152 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4915919899940491
[5/24] Train loss=0.4730120301246643
[10/24] Train loss=0.49573084712028503
[15/24] Train loss=0.498870313167572
[20/24] Train loss=0.4377790689468384
Test set avg_accuracy=75.00% avg_sensitivity=25.17%, avg_specificity=91.74% avg_auc=62.34%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.489281 Test loss=0.636299 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.48601481318473816
[5/24] Train loss=0.472150057554245
[10/24] Train loss=0.4913448691368103
[15/24] Train loss=0.4916052520275116
[20/24] Train loss=0.4365782141685486
Test set avg_accuracy=75.85% avg_sensitivity=28.85%, avg_specificity=91.63% avg_auc=64.91%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.483628 Test loss=0.625607 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4818633794784546
[5/24] Train loss=0.4617820382118225
[10/24] Train loss=0.491963654756546
[15/24] Train loss=0.4837721884250641
[20/24] Train loss=0.43236514925956726
Test set avg_accuracy=68.10% avg_sensitivity=47.28%, avg_specificity=75.09% avg_auc=64.14%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.478372 Test loss=0.642883 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.4759519696235657
[5/24] Train loss=0.4565408229827881
[10/24] Train loss=0.49545735120773315
[15/24] Train loss=0.4879326820373535
[20/24] Train loss=0.4310280680656433
Test set avg_accuracy=67.70% avg_sensitivity=51.53%, avg_specificity=73.13% avg_auc=65.89%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.479842 Test loss=0.643513 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.47867491841316223
[5/24] Train loss=0.4806089997291565
[10/24] Train loss=0.4888058602809906
[15/24] Train loss=0.4849189519882202
[20/24] Train loss=0.4357002377510071
Test set avg_accuracy=75.90% avg_sensitivity=42.15%, avg_specificity=87.23% avg_auc=70.90%
Best model saved!! Metric=-49.81153390069571!!
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.478719 Test loss=0.605572 Current lr=[0.000210185142098938]

[0/24] Train loss=0.47726231813430786
[5/24] Train loss=0.45641881227493286
[10/24] Train loss=0.47903209924697876
[15/24] Train loss=0.4882156252861023
[20/24] Train loss=0.42990654706954956
Test set avg_accuracy=72.14% avg_sensitivity=49.20%, avg_specificity=79.84% avg_auc=69.46%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.474075 Test loss=0.622933 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4716186225414276
[5/24] Train loss=0.44966617226600647
[10/24] Train loss=0.4749467372894287
[15/24] Train loss=0.4696029722690582
[20/24] Train loss=0.4174146354198456
Test set avg_accuracy=62.98% avg_sensitivity=58.31%, avg_specificity=64.55% avg_auc=66.72%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.466209 Test loss=0.651003 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4601272940635681
[5/24] Train loss=0.4517107307910919
[10/24] Train loss=0.47252020239830017
[15/24] Train loss=0.4731794595718384
[20/24] Train loss=0.4224020838737488
Test set avg_accuracy=69.30% avg_sensitivity=52.82%, avg_specificity=74.83% avg_auc=69.68%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.463834 Test loss=0.623299 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.45531517267227173
[5/24] Train loss=0.44660502672195435
[10/24] Train loss=0.4661739766597748
[15/24] Train loss=0.4651206433773041
[20/24] Train loss=0.4040433466434479
Test set avg_accuracy=60.20% avg_sensitivity=64.53%, avg_specificity=58.74% avg_auc=68.00%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.457237 Test loss=0.652620 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.44284459948539734
[5/24] Train loss=0.44701752066612244
[10/24] Train loss=0.4589472711086273
[15/24] Train loss=0.4588659405708313
[20/24] Train loss=0.3915535509586334
Test set avg_accuracy=65.64% avg_sensitivity=56.97%, avg_specificity=68.55% avg_auc=69.11%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.448271 Test loss=0.603172 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.42085930705070496
[5/24] Train loss=0.422710120677948
[10/24] Train loss=0.4473455548286438
[15/24] Train loss=0.451265811920166
[20/24] Train loss=0.3718850910663605
Test set avg_accuracy=58.46% avg_sensitivity=67.12%, avg_specificity=55.56% avg_auc=68.60%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.434300 Test loss=0.629938 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.41114145517349243
[5/24] Train loss=0.40662476420402527
[10/24] Train loss=0.43208378553390503
[15/24] Train loss=0.45050886273384094
[20/24] Train loss=0.38834190368652344
Test set avg_accuracy=56.08% avg_sensitivity=72.71%, avg_specificity=50.50% avg_auc=69.81%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.426296 Test loss=0.651631 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.43086764216423035
[5/24] Train loss=0.4097921550273895
[10/24] Train loss=0.4299512505531311
[15/24] Train loss=0.45434561371803284
[20/24] Train loss=0.3574554920196533
Test set avg_accuracy=70.64% avg_sensitivity=67.22%, avg_specificity=71.79% avg_auc=77.22%
Best model saved!! Metric=-39.13412822390933!!
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.424976 Test loss=0.582053 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4061128497123718
[5/24] Train loss=0.4061516523361206
[10/24] Train loss=0.4203411042690277
[15/24] Train loss=0.4721904993057251
[20/24] Train loss=0.35304388403892517
Test set avg_accuracy=62.34% avg_sensitivity=67.01%, avg_specificity=60.78% avg_auc=71.54%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.420390 Test loss=0.606529 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4029631018638611
[5/24] Train loss=0.4073588252067566
[10/24] Train loss=0.4154163897037506
[15/24] Train loss=0.46115222573280334
[20/24] Train loss=0.3539910912513733
Test set avg_accuracy=62.67% avg_sensitivity=70.64%, avg_specificity=59.99% avg_auc=72.86%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.416516 Test loss=0.614255 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.40076568722724915
[5/24] Train loss=0.398128479719162
[10/24] Train loss=0.41552215814590454
[15/24] Train loss=0.44502878189086914
[20/24] Train loss=0.3435147702693939
Test set avg_accuracy=67.88% avg_sensitivity=70.59%, avg_specificity=66.97% avg_auc=75.95%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.411839 Test loss=0.591265 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.40044429898262024
[5/24] Train loss=0.4126594364643097
[10/24] Train loss=0.4192827343940735
[15/24] Train loss=0.4350591003894806
[20/24] Train loss=0.3551768362522125
Test set avg_accuracy=65.35% avg_sensitivity=71.26%, avg_specificity=63.37% avg_auc=74.67%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.413612 Test loss=0.604946 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3968092203140259
[5/24] Train loss=0.39827215671539307
[10/24] Train loss=0.41529181599617004
[15/24] Train loss=0.45491912961006165
[20/24] Train loss=0.35247984528541565
Test set avg_accuracy=64.57% avg_sensitivity=78.87%, avg_specificity=59.77% avg_auc=77.37%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.409343 Test loss=0.623300 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.40872928500175476
[5/24] Train loss=0.3996756374835968
[10/24] Train loss=0.4017638862133026
[15/24] Train loss=0.42029356956481934
[20/24] Train loss=0.33087483048439026
Test set avg_accuracy=64.70% avg_sensitivity=70.33%, avg_specificity=62.81% avg_auc=73.20%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.405483 Test loss=0.608050 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3899325430393219
[5/24] Train loss=0.3951639235019684
[10/24] Train loss=0.3988414406776428
[15/24] Train loss=0.4303976893424988
[20/24] Train loss=0.3446088433265686
Test set avg_accuracy=68.53% avg_sensitivity=72.14%, avg_specificity=67.32% avg_auc=77.13%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.403780 Test loss=0.587713 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.40183958411216736
[5/24] Train loss=0.39861801266670227
[10/24] Train loss=0.40078070759773254
[15/24] Train loss=0.4290900230407715
[20/24] Train loss=0.3340843915939331
Test set avg_accuracy=62.84% avg_sensitivity=72.86%, avg_specificity=59.47% avg_auc=73.20%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.403039 Test loss=0.622940 Current lr=[0.00029967723776099]

[0/24] Train loss=0.38485148549079895
[5/24] Train loss=0.39037129282951355
[10/24] Train loss=0.40170779824256897
[15/24] Train loss=0.42677733302116394
[20/24] Train loss=0.3268662393093109
Test set avg_accuracy=62.40% avg_sensitivity=73.69%, avg_specificity=58.60% avg_auc=73.69%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.402052 Test loss=0.624569 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3877326548099518
[5/24] Train loss=0.3837381601333618
[10/24] Train loss=0.40558624267578125
[15/24] Train loss=0.42280465364456177
[20/24] Train loss=0.3279894292354584
Test set avg_accuracy=63.23% avg_sensitivity=75.56%, avg_specificity=59.09% avg_auc=74.32%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.396854 Test loss=0.623106 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.37633389234542847
[5/24] Train loss=0.38434532284736633
[10/24] Train loss=0.3933313488960266
[15/24] Train loss=0.43121033906936646
[20/24] Train loss=0.3335608243942261
Test set avg_accuracy=68.89% avg_sensitivity=71.88%, avg_specificity=67.89% avg_auc=77.51%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.395248 Test loss=0.577802 Current lr=[0.000299720220882401]

[0/24] Train loss=0.37982815504074097
[5/24] Train loss=0.38467350602149963
[10/24] Train loss=0.3939450979232788
[15/24] Train loss=0.42001211643218994
[20/24] Train loss=0.3311156630516052
Test set avg_accuracy=66.08% avg_sensitivity=75.04%, avg_specificity=63.07% avg_auc=76.30%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.396243 Test loss=0.601679 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.38118013739585876
[5/24] Train loss=0.38599035143852234
[10/24] Train loss=0.3969041705131531
[15/24] Train loss=0.4220025837421417
[20/24] Train loss=0.33283892273902893
Test set avg_accuracy=65.29% avg_sensitivity=79.75%, avg_specificity=60.43% avg_auc=77.98%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.399064 Test loss=0.614408 Current lr=[0.000298904600941902]

[0/24] Train loss=0.39746591448783875
[5/24] Train loss=0.3907108008861542
[10/24] Train loss=0.4057154059410095
[15/24] Train loss=0.4249834716320038
[20/24] Train loss=0.33253055810928345
Test set avg_accuracy=64.32% avg_sensitivity=73.28%, avg_specificity=61.32% avg_auc=74.28%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.399522 Test loss=0.615564 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.38561955094337463
[5/24] Train loss=0.3804203271865845
[10/24] Train loss=0.3957798182964325
[15/24] Train loss=0.4619717001914978
[20/24] Train loss=0.3356620967388153
Test set avg_accuracy=72.42% avg_sensitivity=71.00%, avg_specificity=72.90% avg_auc=80.40%
Best model saved!! Metric=-29.283939777505267!!
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.400994 Test loss=0.565335 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3885978162288666
[5/24] Train loss=0.39057233929634094
[10/24] Train loss=0.40464216470718384
[15/24] Train loss=0.416275292634964
[20/24] Train loss=0.3277587294578552
Test set avg_accuracy=66.54% avg_sensitivity=70.07%, avg_specificity=65.35% avg_auc=74.47%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.396411 Test loss=0.597892 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.39004725217819214
[5/24] Train loss=0.3825521171092987
[10/24] Train loss=0.39274585247039795
[15/24] Train loss=0.4223248064517975
[20/24] Train loss=0.33095839619636536
Test set avg_accuracy=68.28% avg_sensitivity=72.86%, avg_specificity=66.74% avg_auc=77.27%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.394709 Test loss=0.585734 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3840312063694
[5/24] Train loss=0.3765013515949249
[10/24] Train loss=0.38697436451911926
[15/24] Train loss=0.4310210645198822
[20/24] Train loss=0.3268185555934906
Test set avg_accuracy=67.46% avg_sensitivity=73.07%, avg_specificity=65.58% avg_auc=77.06%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.394083 Test loss=0.589877 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3909907341003418
[5/24] Train loss=0.38781315088272095
[10/24] Train loss=0.3919970691204071
[15/24] Train loss=0.41554510593414307
[20/24] Train loss=0.3303850293159485
Test set avg_accuracy=63.75% avg_sensitivity=77.58%, avg_specificity=59.11% avg_auc=75.72%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.394816 Test loss=0.621376 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.38075587153434753
[5/24] Train loss=0.3760179579257965
[10/24] Train loss=0.3845064342021942
[15/24] Train loss=0.43959566950798035
[20/24] Train loss=0.33381977677345276
Test set avg_accuracy=71.88% avg_sensitivity=72.71%, avg_specificity=71.60% avg_auc=79.88%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.395181 Test loss=0.563759 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3890419602394104
[5/24] Train loss=0.37695279717445374
[10/24] Train loss=0.38940533995628357
[15/24] Train loss=0.41878581047058105
[20/24] Train loss=0.3256556987762451
Test set avg_accuracy=61.50% avg_sensitivity=75.25%, avg_specificity=56.88% avg_auc=73.45%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.392716 Test loss=0.632663 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.38357311487197876
[5/24] Train loss=0.3767416775226593
[10/24] Train loss=0.3825589120388031
[15/24] Train loss=0.3956282138824463
[20/24] Train loss=0.33212900161743164
Test set avg_accuracy=65.53% avg_sensitivity=75.09%, avg_specificity=62.32% avg_auc=75.80%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.387430 Test loss=0.606518 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3868163526058197
[5/24] Train loss=0.388203889131546
[10/24] Train loss=0.3874889016151428
[15/24] Train loss=0.4241497814655304
[20/24] Train loss=0.3373847007751465
Test set avg_accuracy=76.46% avg_sensitivity=68.41%, avg_specificity=79.16% avg_auc=81.98%
Best model saved!! Metric=-19.99034488229131!!
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.391096 Test loss=0.529306 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.38625261187553406
[5/24] Train loss=0.3791801631450653
[10/24] Train loss=0.3899482488632202
[15/24] Train loss=0.412780225276947
[20/24] Train loss=0.3306768834590912
Test set avg_accuracy=68.27% avg_sensitivity=68.82%, avg_specificity=68.08% avg_auc=75.67%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.391677 Test loss=0.580133 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.39801186323165894
[5/24] Train loss=0.37903472781181335
[10/24] Train loss=0.41233909130096436
[15/24] Train loss=0.42582786083221436
[20/24] Train loss=0.33285778760910034
Test set avg_accuracy=75.55% avg_sensitivity=71.00%, avg_specificity=77.07% avg_auc=82.40%
Best model saved!! Metric=-19.975800638813723!!
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.397721 Test loss=0.544069 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.37406498193740845
[5/24] Train loss=0.3726118803024292
[10/24] Train loss=0.3851300776004791
[15/24] Train loss=0.4467387795448303
[20/24] Train loss=0.32563918828964233
Test set avg_accuracy=68.91% avg_sensitivity=73.90%, avg_specificity=67.23% avg_auc=78.22%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.388806 Test loss=0.572181 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.39485806226730347
[5/24] Train loss=0.3798830807209015
[10/24] Train loss=0.3948867917060852
[15/24] Train loss=0.42873525619506836
[20/24] Train loss=0.3271116316318512
Test set avg_accuracy=67.66% avg_sensitivity=71.52%, avg_specificity=66.36% avg_auc=76.54%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.393845 Test loss=0.584432 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.37623172998428345
[5/24] Train loss=0.3639991581439972
[10/24] Train loss=0.38219785690307617
[15/24] Train loss=0.42747625708580017
[20/24] Train loss=0.3200753927230835
Test set avg_accuracy=70.14% avg_sensitivity=73.28%, avg_specificity=69.09% avg_auc=78.82%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.386482 Test loss=0.572317 Current lr=[0.000276307469034998]

[0/24] Train loss=0.37354040145874023
[5/24] Train loss=0.37171030044555664
[10/24] Train loss=0.3865962624549866
[15/24] Train loss=0.41491907835006714
[20/24] Train loss=0.3414342999458313
Test set avg_accuracy=73.50% avg_sensitivity=69.29%, avg_specificity=74.92% avg_auc=80.03%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.390918 Test loss=0.547187 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3766140043735504
[5/24] Train loss=0.38321661949157715
[10/24] Train loss=0.39928051829338074
[15/24] Train loss=0.4307224452495575
[20/24] Train loss=0.31967851519584656
Test set avg_accuracy=69.64% avg_sensitivity=74.52%, avg_specificity=67.99% avg_auc=78.98%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.389622 Test loss=0.572839 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3752836287021637
[5/24] Train loss=0.37072068452835083
[10/24] Train loss=0.3789743185043335
[15/24] Train loss=0.42707905173301697
[20/24] Train loss=0.3155747354030609
Test set avg_accuracy=64.39% avg_sensitivity=76.18%, avg_specificity=60.43% avg_auc=75.78%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.383603 Test loss=0.611771 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.37381142377853394
[5/24] Train loss=0.3869527280330658
[10/24] Train loss=0.3845731019973755
[15/24] Train loss=0.4045459032058716
[20/24] Train loss=0.31550273299217224
Test set avg_accuracy=70.16% avg_sensitivity=73.64%, avg_specificity=68.99% avg_auc=78.99%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.383246 Test loss=0.565089 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3766266703605652
[5/24] Train loss=0.37118247151374817
[10/24] Train loss=0.38373181223869324
[15/24] Train loss=0.4108678102493286
[20/24] Train loss=0.3245280086994171
Test set avg_accuracy=68.15% avg_sensitivity=77.11%, avg_specificity=65.14% avg_auc=78.93%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.384663 Test loss=0.584276 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.37215501070022583
[5/24] Train loss=0.36224648356437683
[10/24] Train loss=0.37539470195770264
[15/24] Train loss=0.39878812432289124
[20/24] Train loss=0.3182920813560486
Test set avg_accuracy=63.57% avg_sensitivity=76.95%, avg_specificity=59.07% avg_auc=75.24%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.379613 Test loss=0.621179 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.37404653429985046
[5/24] Train loss=0.3708474040031433
[10/24] Train loss=0.37947866320610046
[15/24] Train loss=0.39174896478652954
[20/24] Train loss=0.3356993496417999
Test set avg_accuracy=71.67% avg_sensitivity=75.35%, avg_specificity=70.43% avg_auc=80.62%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.380803 Test loss=0.559169 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3772428631782532
[5/24] Train loss=0.36836040019989014
[10/24] Train loss=0.38037434220314026
[15/24] Train loss=0.40709808468818665
[20/24] Train loss=0.3265007436275482
Test set avg_accuracy=75.35% avg_sensitivity=73.28%, avg_specificity=76.05% avg_auc=83.00%
Best model saved!! Metric=-18.325791875637705!!
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.384774 Test loss=0.532367 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.37415146827697754
[5/24] Train loss=0.37170177698135376
[10/24] Train loss=0.3784818649291992
[15/24] Train loss=0.3961491584777832
[20/24] Train loss=0.3115841746330261
Test set avg_accuracy=67.88% avg_sensitivity=78.51%, avg_specificity=64.31% avg_auc=78.82%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.380198 Test loss=0.588751 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3727099299430847
[5/24] Train loss=0.35834842920303345
[10/24] Train loss=0.3723524808883667
[15/24] Train loss=0.40939876437187195
[20/24] Train loss=0.33199700713157654
Test set avg_accuracy=75.20% avg_sensitivity=74.31%, avg_specificity=75.49% avg_auc=82.88%
Best model saved!! Metric=-18.122341375183638!!
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.382882 Test loss=0.537035 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.39145541191101074
[5/24] Train loss=0.38309812545776367
[10/24] Train loss=0.38767510652542114
[15/24] Train loss=0.4230877757072449
[20/24] Train loss=0.3240191340446472
Test set avg_accuracy=72.43% avg_sensitivity=75.71%, avg_specificity=71.33% avg_auc=81.32%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.389142 Test loss=0.554749 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3941470682621002
[5/24] Train loss=0.3644084632396698
[10/24] Train loss=0.38205209374427795
[15/24] Train loss=0.4044838547706604
[20/24] Train loss=0.31125757098197937
Test set avg_accuracy=69.48% avg_sensitivity=73.90%, avg_specificity=67.99% avg_auc=78.20%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.382227 Test loss=0.571881 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3768249750137329
[5/24] Train loss=0.3708994388580322
[10/24] Train loss=0.3791556656360626
[15/24] Train loss=0.39727139472961426
[20/24] Train loss=0.3286624550819397
Test set avg_accuracy=71.56% avg_sensitivity=71.52%, avg_specificity=71.58% avg_auc=79.39%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.380619 Test loss=0.549214 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.3666016459465027
[5/24] Train loss=0.36353400349617004
[10/24] Train loss=0.3794710338115692
[15/24] Train loss=0.3960558772087097
[20/24] Train loss=0.33397361636161804
Test set avg_accuracy=69.24% avg_sensitivity=73.64%, avg_specificity=67.77% avg_auc=77.82%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.377796 Test loss=0.573564 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.3683917224407196
[5/24] Train loss=0.36724844574928284
[10/24] Train loss=0.3779233396053314
[15/24] Train loss=0.4015224575996399
[20/24] Train loss=0.3180033564567566
Test set avg_accuracy=68.36% avg_sensitivity=74.99%, avg_specificity=66.13% avg_auc=77.76%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.377511 Test loss=0.580611 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3673565685749054
[5/24] Train loss=0.374774307012558
[10/24] Train loss=0.3778756856918335
[15/24] Train loss=0.41828450560569763
[20/24] Train loss=0.31897157430648804
Test set avg_accuracy=69.49% avg_sensitivity=78.56%, avg_specificity=66.45% avg_auc=80.74%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.383549 Test loss=0.580705 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3797445595264435
[5/24] Train loss=0.36847570538520813
[10/24] Train loss=0.3805560767650604
[15/24] Train loss=0.39649760723114014
[20/24] Train loss=0.31829583644866943
Test set avg_accuracy=70.51% avg_sensitivity=73.69%, avg_specificity=69.44% avg_auc=79.35%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.383280 Test loss=0.559684 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.37123408913612366
[5/24] Train loss=0.36787310242652893
[10/24] Train loss=0.37805208563804626
[15/24] Train loss=0.40677711367607117
[20/24] Train loss=0.3150847852230072
Test set avg_accuracy=71.05% avg_sensitivity=71.10%, avg_specificity=71.04% avg_auc=78.69%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.378708 Test loss=0.551349 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.3691149353981018
[5/24] Train loss=0.3618769943714142
[10/24] Train loss=0.37666425108909607
[15/24] Train loss=0.4416973292827606
[20/24] Train loss=0.3167206943035126
Test set avg_accuracy=69.27% avg_sensitivity=78.56%, avg_specificity=66.15% avg_auc=81.04%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.378749 Test loss=0.576026 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.37081480026245117
[5/24] Train loss=0.3672402799129486
[10/24] Train loss=0.3781376779079437
[15/24] Train loss=0.4027436673641205
[20/24] Train loss=0.3220263421535492
Test set avg_accuracy=67.73% avg_sensitivity=76.33%, avg_specificity=64.85% avg_auc=78.18%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.380602 Test loss=0.587721 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.36808574199676514
[5/24] Train loss=0.364470511674881
[10/24] Train loss=0.3771839439868927
[15/24] Train loss=0.3979094326496124
[20/24] Train loss=0.30934277176856995
Test set avg_accuracy=66.41% avg_sensitivity=77.42%, avg_specificity=62.71% avg_auc=77.76%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.375876 Test loss=0.596545 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.36476823687553406
[5/24] Train loss=0.3526788651943207
[10/24] Train loss=0.3709299862384796
[15/24] Train loss=0.39401623606681824
[20/24] Train loss=0.31072983145713806
Test set avg_accuracy=70.47% avg_sensitivity=78.30%, avg_specificity=67.84% avg_auc=80.85%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.374125 Test loss=0.564445 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.364843487739563
[5/24] Train loss=0.36651745438575745
[10/24] Train loss=0.37141820788383484
[15/24] Train loss=0.422791063785553
[20/24] Train loss=0.3090358078479767
Test set avg_accuracy=72.53% avg_sensitivity=76.75%, avg_specificity=71.11% avg_auc=81.59%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.375399 Test loss=0.543756 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.3751438856124878
[5/24] Train loss=0.3649517297744751
[10/24] Train loss=0.374250590801239
[15/24] Train loss=0.43317753076553345
[20/24] Train loss=0.31007450819015503
Test set avg_accuracy=72.19% avg_sensitivity=75.04%, avg_specificity=71.23% avg_auc=81.28%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.378557 Test loss=0.546641 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.3821775019168854
[5/24] Train loss=0.36268118023872375
[10/24] Train loss=0.3778747320175171
[15/24] Train loss=0.39426732063293457
[20/24] Train loss=0.309950590133667
Test set avg_accuracy=67.67% avg_sensitivity=77.21%, avg_specificity=64.46% avg_auc=78.51%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.376251 Test loss=0.587760 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3674972355365753
[5/24] Train loss=0.3589990735054016
[10/24] Train loss=0.37899014353752136
[15/24] Train loss=0.38996782898902893
[20/24] Train loss=0.3157164454460144
Test set avg_accuracy=68.27% avg_sensitivity=76.75%, avg_specificity=65.42% avg_auc=78.30%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.373729 Test loss=0.585069 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3684970438480377
[5/24] Train loss=0.3526811897754669
[10/24] Train loss=0.3723002076148987
[15/24] Train loss=0.39677372574806213
[20/24] Train loss=0.31376418471336365
Test set avg_accuracy=71.21% avg_sensitivity=77.47%, avg_specificity=69.11% avg_auc=81.14%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.375505 Test loss=0.558869 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.3650185465812683
[5/24] Train loss=0.3631630837917328
[10/24] Train loss=0.3742941915988922
[15/24] Train loss=0.4087778925895691
[20/24] Train loss=0.30779579281806946
Test set avg_accuracy=69.36% avg_sensitivity=77.99%, avg_specificity=66.46% avg_auc=79.51%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.374427 Test loss=0.574908 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.36491909623146057
[5/24] Train loss=0.35670778155326843
[10/24] Train loss=0.37426289916038513
[15/24] Train loss=0.38550853729248047
[20/24] Train loss=0.3091076910495758
Test set avg_accuracy=68.87% avg_sensitivity=76.49%, avg_specificity=66.31% avg_auc=78.46%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.373194 Test loss=0.577802 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.3621118664741516
[5/24] Train loss=0.3545157313346863
[10/24] Train loss=0.3784419000148773
[15/24] Train loss=0.4458186626434326
[20/24] Train loss=0.3187853693962097
Test set avg_accuracy=76.99% avg_sensitivity=74.37%, avg_specificity=77.87% avg_auc=84.06%
Best model saved!! Metric=-12.711783172313815!!
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.376585 Test loss=0.515965 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3691081702709198
[5/24] Train loss=0.36095666885375977
[10/24] Train loss=0.37769845128059387
[15/24] Train loss=0.4115790128707886
[20/24] Train loss=0.3094770610332489
Test set avg_accuracy=73.07% avg_sensitivity=75.56%, avg_specificity=72.24% avg_auc=81.54%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.376671 Test loss=0.543260 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.36698147654533386
[5/24] Train loss=0.36080431938171387
[10/24] Train loss=0.3737945854663849
[15/24] Train loss=0.40324994921684265
[20/24] Train loss=0.31434640288352966
Test set avg_accuracy=69.51% avg_sensitivity=76.28%, avg_specificity=67.23% avg_auc=79.11%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.374875 Test loss=0.570950 Current lr=[0.000156543481933168]

[0/24] Train loss=0.36701908707618713
[5/24] Train loss=0.354580819606781
[10/24] Train loss=0.36963987350463867
[15/24] Train loss=0.4211772084236145
[20/24] Train loss=0.3139646053314209
Test set avg_accuracy=70.20% avg_sensitivity=75.25%, avg_specificity=68.50% avg_auc=79.65%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.372642 Test loss=0.560593 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.36453762650489807
[5/24] Train loss=0.3583203852176666
[10/24] Train loss=0.37644433975219727
[15/24] Train loss=0.3920705318450928
[20/24] Train loss=0.3095351457595825
Test set avg_accuracy=67.58% avg_sensitivity=74.16%, avg_specificity=65.37% avg_auc=76.61%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.371137 Test loss=0.586574 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.36306726932525635
[5/24] Train loss=0.35433727502822876
[10/24] Train loss=0.3657779395580292
[15/24] Train loss=0.3834770917892456
[20/24] Train loss=0.3071911036968231
Test set avg_accuracy=67.15% avg_sensitivity=75.61%, avg_specificity=64.31% avg_auc=77.04%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.368417 Test loss=0.590179 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.3647838532924652
[5/24] Train loss=0.3558351397514343
[10/24] Train loss=0.37137332558631897
[15/24] Train loss=0.41525524854660034
[20/24] Train loss=0.32436349987983704
Test set avg_accuracy=74.56% avg_sensitivity=74.88%, avg_specificity=74.45% avg_auc=82.56%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.372254 Test loss=0.524602 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.3653946816921234
[5/24] Train loss=0.35073813796043396
[10/24] Train loss=0.37153658270835876
[15/24] Train loss=0.3907945454120636
[20/24] Train loss=0.3084263503551483
Test set avg_accuracy=69.84% avg_sensitivity=75.66%, avg_specificity=67.89% avg_auc=79.55%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.371118 Test loss=0.563357 Current lr=[0.000134135431043539]

[0/24] Train loss=0.36340177059173584
[5/24] Train loss=0.3484989404678345
[10/24] Train loss=0.3731565773487091
[15/24] Train loss=0.3953498601913452
[20/24] Train loss=0.3072056472301483
Test set avg_accuracy=69.09% avg_sensitivity=73.64%, avg_specificity=67.56% avg_auc=77.61%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.368923 Test loss=0.570999 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3658115565776825
[5/24] Train loss=0.3508700132369995
[10/24] Train loss=0.3715271055698395
[15/24] Train loss=0.3975795805454254
[20/24] Train loss=0.30619052052497864
Test set avg_accuracy=70.25% avg_sensitivity=76.75%, avg_specificity=68.06% avg_auc=79.76%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.370948 Test loss=0.564770 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.36006516218185425
[5/24] Train loss=0.3499976694583893
[10/24] Train loss=0.3736378848552704
[15/24] Train loss=0.3963490426540375
[20/24] Train loss=0.3073712885379791
Test set avg_accuracy=70.13% avg_sensitivity=76.44%, avg_specificity=68.01% avg_auc=79.88%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.368851 Test loss=0.561687 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.36363598704338074
[5/24] Train loss=0.34920111298561096
[10/24] Train loss=0.37458065152168274
[15/24] Train loss=0.39811885356903076
[20/24] Train loss=0.30110374093055725
Test set avg_accuracy=71.34% avg_sensitivity=73.07%, avg_specificity=70.76% avg_auc=79.18%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.370143 Test loss=0.551017 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3619323968887329
[5/24] Train loss=0.357738196849823
[10/24] Train loss=0.3733409643173218
[15/24] Train loss=0.3778739869594574
[20/24] Train loss=0.3105746805667877
Test set avg_accuracy=69.43% avg_sensitivity=77.11%, avg_specificity=66.85% avg_auc=79.72%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.369080 Test loss=0.571485 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3624938130378723
[5/24] Train loss=0.3581438362598419
[10/24] Train loss=0.3806487023830414
[15/24] Train loss=0.41121143102645874
[20/24] Train loss=0.3055126965045929
Test set avg_accuracy=71.38% avg_sensitivity=72.45%, avg_specificity=71.02% avg_auc=79.32%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.373446 Test loss=0.552850 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3621117174625397
[5/24] Train loss=0.3518442213535309
[10/24] Train loss=0.37421050667762756
[15/24] Train loss=0.39277103543281555
[20/24] Train loss=0.31066209077835083
Test set avg_accuracy=70.62% avg_sensitivity=74.57%, avg_specificity=69.30% avg_auc=79.50%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.369152 Test loss=0.559434 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.36720824241638184
[5/24] Train loss=0.35521674156188965
[10/24] Train loss=0.37246033549308777
[15/24] Train loss=0.39724957942962646
[20/24] Train loss=0.31120848655700684
Test set avg_accuracy=71.02% avg_sensitivity=74.78%, avg_specificity=69.75% avg_auc=80.06%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.371794 Test loss=0.555294 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.3609325587749481
[5/24] Train loss=0.35192039608955383
[10/24] Train loss=0.37190911173820496
[15/24] Train loss=0.4164978265762329
[20/24] Train loss=0.30632224678993225
Test set avg_accuracy=71.58% avg_sensitivity=74.83%, avg_specificity=70.48% avg_auc=79.81%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.367745 Test loss=0.552456 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.36791640520095825
[5/24] Train loss=0.3466903269290924
[10/24] Train loss=0.37589266896247864
[15/24] Train loss=0.3907099664211273
[20/24] Train loss=0.31252551078796387
Test set avg_accuracy=72.11% avg_sensitivity=72.09%, avg_specificity=72.12% avg_auc=79.37%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.371847 Test loss=0.543759 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3622756600379944
[5/24] Train loss=0.3452731966972351
[10/24] Train loss=0.3714820444583893
[15/24] Train loss=0.38547059893608093
[20/24] Train loss=0.30495551228523254
Test set avg_accuracy=71.43% avg_sensitivity=73.02%, avg_specificity=70.90% avg_auc=79.03%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.367238 Test loss=0.552930 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.3622555732727051
[5/24] Train loss=0.34377622604370117
[10/24] Train loss=0.36763009428977966
[15/24] Train loss=0.3740898072719574
[20/24] Train loss=0.30622753500938416
Test set avg_accuracy=70.47% avg_sensitivity=74.05%, avg_specificity=69.26% avg_auc=78.64%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.363192 Test loss=0.559175 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3621312379837036
[5/24] Train loss=0.34478119015693665
[10/24] Train loss=0.36823785305023193
[15/24] Train loss=0.3785914182662964
[20/24] Train loss=0.304470956325531
Test set avg_accuracy=70.21% avg_sensitivity=75.30%, avg_specificity=68.50% avg_auc=78.93%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.364027 Test loss=0.562860 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3591804504394531
[5/24] Train loss=0.3443309962749481
[10/24] Train loss=0.36904266476631165
[15/24] Train loss=0.3794628083705902
[20/24] Train loss=0.3053695559501648
Test set avg_accuracy=71.09% avg_sensitivity=75.14%, avg_specificity=69.73% avg_auc=79.65%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.361110 Test loss=0.551294 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.35805192589759827
[5/24] Train loss=0.3434593975543976
[10/24] Train loss=0.3672657310962677
[15/24] Train loss=0.3800807595252991
[20/24] Train loss=0.30603039264678955
Test set avg_accuracy=70.60% avg_sensitivity=74.62%, avg_specificity=69.25% avg_auc=79.01%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.360174 Test loss=0.555938 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.3597877025604248
[5/24] Train loss=0.34420162439346313
[10/24] Train loss=0.3698994219303131
[15/24] Train loss=0.37860995531082153
[20/24] Train loss=0.30333125591278076
Test set avg_accuracy=70.39% avg_sensitivity=74.00%, avg_specificity=69.18% avg_auc=78.71%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.360746 Test loss=0.558436 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.36304688453674316
[5/24] Train loss=0.34435054659843445
[10/24] Train loss=0.3679990768432617
[15/24] Train loss=0.38011565804481506
[20/24] Train loss=0.3025539517402649
Test set avg_accuracy=69.40% avg_sensitivity=75.82%, avg_specificity=67.25% avg_auc=78.91%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.360538 Test loss=0.565966 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.3562496602535248
[5/24] Train loss=0.3420864939689636
[10/24] Train loss=0.3659982979297638
[15/24] Train loss=0.3817498981952667
[20/24] Train loss=0.30394473671913147
Test set avg_accuracy=70.10% avg_sensitivity=74.94%, avg_specificity=68.48% avg_auc=78.79%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.360111 Test loss=0.562751 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.3571433126926422
[5/24] Train loss=0.342290997505188
[10/24] Train loss=0.3673320412635803
[15/24] Train loss=0.3718729317188263
[20/24] Train loss=0.30368101596832275
Test set avg_accuracy=69.35% avg_sensitivity=76.33%, avg_specificity=67.00% avg_auc=78.90%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.358959 Test loss=0.567347 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3567611277103424
[5/24] Train loss=0.34280484914779663
[10/24] Train loss=0.36408355832099915
[15/24] Train loss=0.3761884272098541
[20/24] Train loss=0.30236029624938965
Test set avg_accuracy=68.36% avg_sensitivity=74.16%, avg_specificity=66.41% avg_auc=77.12%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.359331 Test loss=0.576991 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.35503149032592773
[5/24] Train loss=0.3398401737213135
[10/24] Train loss=0.3672546446323395
[15/24] Train loss=0.3687763214111328
[20/24] Train loss=0.30577966570854187
Test set avg_accuracy=68.91% avg_sensitivity=75.04%, avg_specificity=66.85% avg_auc=77.91%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.358609 Test loss=0.572864 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.35481536388397217
[5/24] Train loss=0.34048527479171753
[10/24] Train loss=0.36591556668281555
[15/24] Train loss=0.3715909421443939
[20/24] Train loss=0.3046533763408661
Test set avg_accuracy=69.39% avg_sensitivity=73.49%, avg_specificity=68.01% avg_auc=77.43%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.358133 Test loss=0.568739 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3545069694519043
[5/24] Train loss=0.33958837389945984
[10/24] Train loss=0.3668939173221588
[15/24] Train loss=0.37007570266723633
[20/24] Train loss=0.30441510677337646
Test set avg_accuracy=69.36% avg_sensitivity=73.64%, avg_specificity=67.92% avg_auc=77.49%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.357525 Test loss=0.567931 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3546411097049713
[5/24] Train loss=0.339778333902359
[10/24] Train loss=0.3667418360710144
[15/24] Train loss=0.3724539577960968
[20/24] Train loss=0.3030101954936981
Test set avg_accuracy=69.38% avg_sensitivity=71.98%, avg_specificity=68.50% avg_auc=76.61%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.358001 Test loss=0.570656 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.35740017890930176
[5/24] Train loss=0.3406613767147064
[10/24] Train loss=0.36691832542419434
[15/24] Train loss=0.3703318238258362
[20/24] Train loss=0.3029240369796753
Test set avg_accuracy=69.28% avg_sensitivity=73.54%, avg_specificity=67.86% avg_auc=77.45%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.357985 Test loss=0.569753 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.35889217257499695
[5/24] Train loss=0.33868443965911865
[10/24] Train loss=0.367819607257843
[15/24] Train loss=0.3715559244155884
[20/24] Train loss=0.3038675785064697
Test set avg_accuracy=69.78% avg_sensitivity=72.92%, avg_specificity=68.72% avg_auc=77.17%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.358391 Test loss=0.567097 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.36073315143585205
[5/24] Train loss=0.3401218056678772
[10/24] Train loss=0.3705909252166748
[15/24] Train loss=0.3775278329849243
[20/24] Train loss=0.29959720373153687
Test set avg_accuracy=69.41% avg_sensitivity=72.45%, avg_specificity=68.39% avg_auc=76.82%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.359409 Test loss=0.570671 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.36289241909980774
[5/24] Train loss=0.3418768346309662
[10/24] Train loss=0.36977922916412354
[15/24] Train loss=0.37395811080932617
[20/24] Train loss=0.29940345883369446
Test set avg_accuracy=69.62% avg_sensitivity=73.28%, avg_specificity=68.39% avg_auc=77.75%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.360092 Test loss=0.567812 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.3602282404899597
[5/24] Train loss=0.3393990695476532
[10/24] Train loss=0.3685404062271118
[15/24] Train loss=0.37626203894615173
[20/24] Train loss=0.3011166453361511
Test set avg_accuracy=68.46% avg_sensitivity=73.38%, avg_specificity=66.81% avg_auc=76.74%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.359089 Test loss=0.577895 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.35597071051597595
[5/24] Train loss=0.34052932262420654
[10/24] Train loss=0.36977434158325195
[15/24] Train loss=0.3800245523452759
[20/24] Train loss=0.2996971905231476
Test set avg_accuracy=68.83% avg_sensitivity=73.49%, avg_specificity=67.26% avg_auc=76.98%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.358732 Test loss=0.573843 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.35640573501586914
[5/24] Train loss=0.34555473923683167
[10/24] Train loss=0.3677771985530853
[15/24] Train loss=0.3698665201663971
[20/24] Train loss=0.30009138584136963
Test set avg_accuracy=67.97% avg_sensitivity=74.37%, avg_specificity=65.82% avg_auc=76.98%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.358235 Test loss=0.582624 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.35414212942123413
[5/24] Train loss=0.3406336009502411
[10/24] Train loss=0.36733776330947876
[15/24] Train loss=0.37205201387405396
[20/24] Train loss=0.3013235926628113
Test set avg_accuracy=67.98% avg_sensitivity=75.40%, avg_specificity=65.49% avg_auc=77.51%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.356459 Test loss=0.580400 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.35272008180618286
[5/24] Train loss=0.34027984738349915
[10/24] Train loss=0.36751559376716614
[15/24] Train loss=0.36667194962501526
[20/24] Train loss=0.29963991045951843
Test set avg_accuracy=68.23% avg_sensitivity=75.14%, avg_specificity=65.91% avg_auc=77.56%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.355367 Test loss=0.578260 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.351790189743042
[5/24] Train loss=0.3390732705593109
[10/24] Train loss=0.3657662272453308
[15/24] Train loss=0.36815762519836426
[20/24] Train loss=0.30034056305885315
Test set avg_accuracy=68.55% avg_sensitivity=75.92%, avg_specificity=66.08% avg_auc=78.17%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.354575 Test loss=0.574782 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3516765832901001
[5/24] Train loss=0.33781981468200684
[10/24] Train loss=0.36550310254096985
[15/24] Train loss=0.36668282747268677
[20/24] Train loss=0.29972946643829346
Test set avg_accuracy=68.14% avg_sensitivity=75.09%, avg_specificity=65.80% avg_auc=77.44%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.354034 Test loss=0.578288 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.3514695465564728
[5/24] Train loss=0.3381444215774536
[10/24] Train loss=0.36494311690330505
[15/24] Train loss=0.36646661162376404
[20/24] Train loss=0.2993070185184479
Test set avg_accuracy=68.29% avg_sensitivity=75.35%, avg_specificity=65.92% avg_auc=77.66%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.353567 Test loss=0.577149 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.3514059782028198
[5/24] Train loss=0.3376377820968628
[10/24] Train loss=0.3650585114955902
[15/24] Train loss=0.36633244156837463
[20/24] Train loss=0.29911741614341736
Test set avg_accuracy=68.18% avg_sensitivity=75.50%, avg_specificity=65.72% avg_auc=77.61%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.353430 Test loss=0.578682 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.35110220313072205
[5/24] Train loss=0.33754733204841614
[10/24] Train loss=0.36498236656188965
[15/24] Train loss=0.36633193492889404
[20/24] Train loss=0.29902639985084534
Test set avg_accuracy=68.02% avg_sensitivity=75.35%, avg_specificity=65.56% avg_auc=77.48%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.353255 Test loss=0.579277 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.3509862720966339
[5/24] Train loss=0.33736172318458557
[10/24] Train loss=0.3647829592227936
[15/24] Train loss=0.3662605583667755
[20/24] Train loss=0.29892992973327637
Test set avg_accuracy=67.98% avg_sensitivity=75.35%, avg_specificity=65.51% avg_auc=77.47%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.353143 Test loss=0.579532 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.3509761393070221
[5/24] Train loss=0.3372124135494232
[10/24] Train loss=0.36477726697921753
[15/24] Train loss=0.36621010303497314
[20/24] Train loss=0.2988782227039337
Test set avg_accuracy=67.93% avg_sensitivity=75.30%, avg_specificity=65.45% avg_auc=77.45%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.353070 Test loss=0.579749 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3509359657764435
[5/24] Train loss=0.33711862564086914
[10/24] Train loss=0.3647203743457794
[15/24] Train loss=0.36620375514030457
[20/24] Train loss=0.2988135516643524
Test set avg_accuracy=67.89% avg_sensitivity=75.35%, avg_specificity=65.39% avg_auc=77.42%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.353006 Test loss=0.580100 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.3509138226509094
[5/24] Train loss=0.3370381295681
[10/24] Train loss=0.3647087812423706
[15/24] Train loss=0.3661724328994751
[20/24] Train loss=0.2987518608570099
Test set avg_accuracy=67.89% avg_sensitivity=75.45%, avg_specificity=65.35% avg_auc=77.41%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.352959 Test loss=0.580303 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.35088229179382324
[5/24] Train loss=0.3369610011577606
[10/24] Train loss=0.3646819591522217
[15/24] Train loss=0.3661450445652008
[20/24] Train loss=0.2987090051174164
Test set avg_accuracy=67.85% avg_sensitivity=75.45%, avg_specificity=65.30% avg_auc=77.40%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.352918 Test loss=0.580418 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.35086095333099365
[5/24] Train loss=0.33691853284835815
[10/24] Train loss=0.36466556787490845
[15/24] Train loss=0.36612454056739807
[20/24] Train loss=0.29867497086524963
Test set avg_accuracy=67.85% avg_sensitivity=75.45%, avg_specificity=65.30% avg_auc=77.39%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.352888 Test loss=0.580551 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.35084477066993713
[5/24] Train loss=0.3368832468986511
[10/24] Train loss=0.3646466135978699
[15/24] Train loss=0.36610469222068787
[20/24] Train loss=0.2986502945423126
Test set avg_accuracy=67.85% avg_sensitivity=75.45%, avg_specificity=65.30% avg_auc=77.39%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.352865 Test loss=0.580641 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.35083189606666565
[5/24] Train loss=0.336856484413147
[10/24] Train loss=0.3646297752857208
[15/24] Train loss=0.3660888373851776
[20/24] Train loss=0.2986319959163666
Test set avg_accuracy=67.85% avg_sensitivity=75.45%, avg_specificity=65.30% avg_auc=77.38%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.352848 Test loss=0.580701 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.35082367062568665
[5/24] Train loss=0.3368384838104248
[10/24] Train loss=0.3646183907985687
[15/24] Train loss=0.3660769760608673
[20/24] Train loss=0.29861900210380554
Test set avg_accuracy=67.85% avg_sensitivity=75.45%, avg_specificity=65.30% avg_auc=77.38%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.352837 Test loss=0.580747 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.35081905126571655
[5/24] Train loss=0.33682748675346375
[10/24] Train loss=0.3646107017993927
[15/24] Train loss=0.36606937646865845
[20/24] Train loss=0.2986113429069519
Test set avg_accuracy=67.85% avg_sensitivity=75.45%, avg_specificity=65.30% avg_auc=77.38%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.352830 Test loss=0.580774 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.35081684589385986
[5/24] Train loss=0.33682236075401306
[10/24] Train loss=0.36460649967193604
[15/24] Train loss=0.3660658895969391
[20/24] Train loss=0.29860827326774597
Test set avg_accuracy=67.85% avg_sensitivity=75.45%, avg_specificity=65.30% avg_auc=77.37%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.352827 Test loss=0.580784 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=76.99% sen=74.37%, spe=77.87%, auc=84.06%!
Fold[8] Avg_overlap=0.03%(±0.09118091203081341)
[0/23] Train loss=0.6813361048698425
[5/23] Train loss=0.6811361908912659
[10/23] Train loss=0.6798556447029114
[15/23] Train loss=0.6799697875976562
[20/23] Train loss=0.678831160068512
Test set avg_accuracy=61.97% avg_sensitivity=26.90%, avg_specificity=73.13% avg_auc=50.02%
Best model saved!! Metric=-113.9791406560296!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.680656 Test loss=0.678792 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.6783044338226318
[5/23] Train loss=0.6782395243644714
[10/23] Train loss=0.676861584186554
[15/23] Train loss=0.6769463419914246
[20/23] Train loss=0.675571084022522
Test set avg_accuracy=62.06% avg_sensitivity=26.95%, avg_specificity=73.24% avg_auc=50.15%
Best model saved!! Metric=-113.5980048871318!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.677765 Test loss=0.675649 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.6751434803009033
[5/23] Train loss=0.6751534938812256
[10/23] Train loss=0.6737122535705566
[15/23] Train loss=0.6736263036727905
[20/23] Train loss=0.6720861196517944
Test set avg_accuracy=62.02% avg_sensitivity=26.74%, avg_specificity=73.25% avg_auc=50.15%
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.674679 Test loss=0.672150 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.6717101335525513
[5/23] Train loss=0.671671450138092
[10/23] Train loss=0.6700013279914856
[15/23] Train loss=0.6696428060531616
[20/23] Train loss=0.6677290797233582
Test set avg_accuracy=62.06% avg_sensitivity=26.25%, avg_specificity=73.46% avg_auc=50.24%
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.671055 Test loss=0.667788 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.667323112487793
[5/23] Train loss=0.6671434044837952
[10/23] Train loss=0.6652187705039978
[15/23] Train loss=0.6644266843795776
[20/23] Train loss=0.6622458100318909
Test set avg_accuracy=62.14% avg_sensitivity=26.15%, avg_specificity=73.60% avg_auc=50.46%
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.666396 Test loss=0.662210 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.6618019938468933
[5/23] Train loss=0.6613905429840088
[10/23] Train loss=0.6589618921279907
[15/23] Train loss=0.6575691103935242
[20/23] Train loss=0.6549844741821289
Test set avg_accuracy=62.06% avg_sensitivity=25.28%, avg_specificity=73.77% avg_auc=50.47%
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.660332 Test loss=0.654696 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.6544650197029114
[5/23] Train loss=0.6536557078361511
[10/23] Train loss=0.6508888006210327
[15/23] Train loss=0.6487993597984314
[20/23] Train loss=0.6454915404319763
Test set avg_accuracy=65.33% avg_sensitivity=19.14%, avg_specificity=80.03% avg_auc=50.86%
Best model saved!! Metric=-110.63886263322846!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.652520 Test loss=0.645177 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.645194411277771
[5/23] Train loss=0.6439002752304077
[10/23] Train loss=0.6407970786094666
[15/23] Train loss=0.637459397315979
[20/23] Train loss=0.6331384181976318
Test set avg_accuracy=68.98% avg_sensitivity=13.42%, avg_specificity=86.68% avg_auc=51.22%
Best model saved!! Metric=-105.69029385693464!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.642630 Test loss=0.633123 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.6334072351455688
[5/23] Train loss=0.6313139796257019
[10/23] Train loss=0.6280922293663025
[15/23] Train loss=0.6230834126472473
[20/23] Train loss=0.6174600124359131
Test set avg_accuracy=72.25% avg_sensitivity=7.28%, avg_specificity=92.94% avg_auc=51.48%
Best model saved!! Metric=-102.04794070104963!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.630241 Test loss=0.618199 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.6187018156051636
[5/23] Train loss=0.6156654953956604
[10/23] Train loss=0.6126576662063599
[15/23] Train loss=0.605518639087677
[20/23] Train loss=0.5982363224029541
Test set avg_accuracy=72.32% avg_sensitivity=6.63%, avg_specificity=93.24% avg_auc=51.82%
Best model saved!! Metric=-101.99929130804884!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.615329 Test loss=0.600783 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.601761519908905
[5/23] Train loss=0.5971775650978088
[10/23] Train loss=0.5957845449447632
[15/23] Train loss=0.5854009985923767
[20/23] Train loss=0.5776806473731995
Test set avg_accuracy=75.87% avg_sensitivity=1.89%, avg_specificity=99.43% avg_auc=52.51%
Best model saved!! Metric=-96.29884301770146!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.599302 Test loss=0.583059 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.5859853029251099
[5/23] Train loss=0.5788198113441467
[10/23] Train loss=0.5832537412643433
[15/23] Train loss=0.5691537261009216
[20/23] Train loss=0.5624802112579346
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=53.46%
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.586435 Test loss=0.570262 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.5756247043609619
[5/23] Train loss=0.5667819976806641
[10/23] Train loss=0.5750907063484192
[15/23] Train loss=0.5587655305862427
[20/23] Train loss=0.5525332689285278
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=54.68%
Best model saved!! Metric=-95.47074958956577!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.577289 Test loss=0.561588 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.5676865577697754
[5/23] Train loss=0.5585489273071289
[10/23] Train loss=0.5688063502311707
[15/23] Train loss=0.5507532954216003
[20/23] Train loss=0.543693482875824
Test set avg_accuracy=75.85% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=57.05%
Best model saved!! Metric=-93.10135935553872!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.570358 Test loss=0.554768 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.5621119737625122
[5/23] Train loss=0.5491937398910522
[10/23] Train loss=0.5645731687545776
[15/23] Train loss=0.5450710654258728
[20/23] Train loss=0.5379973649978638
Test set avg_accuracy=75.83% avg_sensitivity=0.05%, avg_specificity=99.97% avg_auc=60.27%
Best model saved!! Metric=-89.87857393504004!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.565748 Test loss=0.550721 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.5592457056045532
[5/23] Train loss=0.5451552271842957
[10/23] Train loss=0.5630477070808411
[15/23] Train loss=0.5396652221679688
[20/23] Train loss=0.5292671918869019
Test set avg_accuracy=75.85% avg_sensitivity=0.16%, avg_specificity=99.95% avg_auc=65.52%
Best model saved!! Metric=-84.52542376792607!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.561778 Test loss=0.548097 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.555667519569397
[5/23] Train loss=0.5414963960647583
[10/23] Train loss=0.5596010088920593
[15/23] Train loss=0.5338274836540222
[20/23] Train loss=0.524651825428009
Test set avg_accuracy=75.78% avg_sensitivity=0.32%, avg_specificity=99.81% avg_auc=69.31%
Best model saved!! Metric=-80.77523693358629!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.557034 Test loss=0.542683 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.5483461022377014
[5/23] Train loss=0.5364289879798889
[10/23] Train loss=0.554760754108429
[15/23] Train loss=0.5231062173843384
[20/23] Train loss=0.5113677382469177
Test set avg_accuracy=75.87% avg_sensitivity=1.24%, avg_specificity=99.64% avg_auc=74.08%
Best model saved!! Metric=-75.17063599110591!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.548575 Test loss=0.545200 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.533958911895752
[5/23] Train loss=0.5232394337654114
[10/23] Train loss=0.54279625415802
[15/23] Train loss=0.50277179479599
[20/23] Train loss=0.4897953271865845
Test set avg_accuracy=76.50% avg_sensitivity=17.25%, avg_specificity=95.36% avg_auc=75.14%
Best model saved!! Metric=-61.74716300890951!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.533541 Test loss=0.616347 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.5155305862426758
[5/23] Train loss=0.5127342343330383
[10/23] Train loss=0.5243242383003235
[15/23] Train loss=0.4796050786972046
[20/23] Train loss=0.4723522663116455
Test set avg_accuracy=64.70% avg_sensitivity=27.28%, avg_specificity=76.62% avg_auc=54.55%
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.516391 Test loss=0.677992 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.4949691891670227
[5/23] Train loss=0.5038456916809082
[10/23] Train loss=0.506726086139679
[15/23] Train loss=0.46214213967323303
[20/23] Train loss=0.472086101770401
Test set avg_accuracy=67.28% avg_sensitivity=22.53%, avg_specificity=81.53% avg_auc=52.55%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.502709 Test loss=0.662684 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.4909190237522125
[5/23] Train loss=0.4939896762371063
[10/23] Train loss=0.4948370158672333
[15/23] Train loss=0.456429660320282
[20/23] Train loss=0.4668283462524414
Test set avg_accuracy=67.67% avg_sensitivity=22.32%, avg_specificity=82.11% avg_auc=53.56%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.493116 Test loss=0.650441 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.48308223485946655
[5/23] Train loss=0.490825355052948
[10/23] Train loss=0.4963532090187073
[15/23] Train loss=0.4524582326412201
[20/23] Train loss=0.46234971284866333
Test set avg_accuracy=66.20% avg_sensitivity=28.46%, avg_specificity=78.21% avg_auc=55.65%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.488152 Test loss=0.652591 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.4704241156578064
[5/23] Train loss=0.4867169260978699
[10/23] Train loss=0.4855802655220032
[15/23] Train loss=0.447735995054245
[20/23] Train loss=0.4558722674846649
Test set avg_accuracy=63.55% avg_sensitivity=34.39%, avg_specificity=72.84% avg_auc=56.19%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.481204 Test loss=0.653102 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.4665871262550354
[5/23] Train loss=0.48412033915519714
[10/23] Train loss=0.4932608902454376
[15/23] Train loss=0.44389742612838745
[20/23] Train loss=0.45706331729888916
Test set avg_accuracy=64.21% avg_sensitivity=36.87%, avg_specificity=72.91% avg_auc=57.90%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.479791 Test loss=0.654102 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.4651976525783539
[5/23] Train loss=0.49136975407600403
[10/23] Train loss=0.4763931334018707
[15/23] Train loss=0.44046348333358765
[20/23] Train loss=0.4507218599319458
Test set avg_accuracy=62.28% avg_sensitivity=46.31%, avg_specificity=67.36% avg_auc=59.33%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.477597 Test loss=0.661047 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.46034321188926697
[5/23] Train loss=0.48210716247558594
[10/23] Train loss=0.4754592180252075
[15/23] Train loss=0.4403112828731537
[20/23] Train loss=0.44317176938056946
Test set avg_accuracy=61.12% avg_sensitivity=51.43%, avg_specificity=64.21% avg_auc=60.56%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.471307 Test loss=0.660339 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.45756521821022034
[5/23] Train loss=0.4742337167263031
[10/23] Train loss=0.46816301345825195
[15/23] Train loss=0.4304030239582062
[20/23] Train loss=0.4262900948524475
Test set avg_accuracy=59.06% avg_sensitivity=56.17%, avg_specificity=59.98% avg_auc=61.56%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.462749 Test loss=0.659970 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.4374769330024719
[5/23] Train loss=0.4567982852458954
[10/23] Train loss=0.45524778962135315
[15/23] Train loss=0.4101812541484833
[20/23] Train loss=0.4028470814228058
Test set avg_accuracy=55.99% avg_sensitivity=65.07%, avg_specificity=53.10% avg_auc=63.67%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.445425 Test loss=0.673036 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.42636236548423767
[5/23] Train loss=0.4434382915496826
[10/23] Train loss=0.4388740062713623
[15/23] Train loss=0.39645108580589294
[20/23] Train loss=0.3885965049266815
Test set avg_accuracy=56.29% avg_sensitivity=71.37%, avg_specificity=51.48% avg_auc=65.91%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.433576 Test loss=0.683935 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.41017597913742065
[5/23] Train loss=0.4400717616081238
[10/23] Train loss=0.4282708764076233
[15/23] Train loss=0.39046555757522583
[20/23] Train loss=0.38468706607818604
Test set avg_accuracy=55.29% avg_sensitivity=71.75%, avg_specificity=50.04% avg_auc=66.33%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.428941 Test loss=0.678398 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.4015544652938843
[5/23] Train loss=0.4267438054084778
[10/23] Train loss=0.42213958501815796
[15/23] Train loss=0.38776424527168274
[20/23] Train loss=0.37961816787719727
Test set avg_accuracy=55.92% avg_sensitivity=76.33%, avg_specificity=49.42% avg_auc=69.43%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.417432 Test loss=0.683598 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.4026811122894287
[5/23] Train loss=0.426779568195343
[10/23] Train loss=0.41767382621765137
[15/23] Train loss=0.3879064619541168
[20/23] Train loss=0.36482203006744385
Test set avg_accuracy=55.98% avg_sensitivity=71.70%, avg_specificity=50.97% avg_auc=67.21%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.413288 Test loss=0.674033 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.3921429514884949
[5/23] Train loss=0.42026329040527344
[10/23] Train loss=0.40188390016555786
[15/23] Train loss=0.3750528395175934
[20/23] Train loss=0.37650108337402344
Test set avg_accuracy=60.07% avg_sensitivity=72.72%, avg_specificity=56.03% avg_auc=70.43%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.409128 Test loss=0.650571 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.38535019755363464
[5/23] Train loss=0.4160354435443878
[10/23] Train loss=0.4054863750934601
[15/23] Train loss=0.381583034992218
[20/23] Train loss=0.3769102394580841
Test set avg_accuracy=62.58% avg_sensitivity=72.02%, avg_specificity=59.57% avg_auc=71.83%
Best model saved!! Metric=-60.000480555105675!!
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.409599 Test loss=0.634734 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.3965526223182678
[5/23] Train loss=0.42421725392341614
[10/23] Train loss=0.40498989820480347
[15/23] Train loss=0.3834291696548462
[20/23] Train loss=0.36997947096824646
Test set avg_accuracy=65.22% avg_sensitivity=71.59%, avg_specificity=63.19% avg_auc=73.74%
Best model saved!! Metric=-52.25938574286908!!
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.415089 Test loss=0.620409 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.407298743724823
[5/23] Train loss=0.41857004165649414
[10/23] Train loss=0.40885129570961
[15/23] Train loss=0.3898009955883026
[20/23] Train loss=0.37362152338027954
Test set avg_accuracy=68.32% avg_sensitivity=69.65%, avg_specificity=67.90% avg_auc=74.88%
Best model saved!! Metric=-45.2515996270664!!
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.413431 Test loss=0.600566 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.3903163969516754
[5/23] Train loss=0.42183515429496765
[10/23] Train loss=0.39008548855781555
[15/23] Train loss=0.3822838366031647
[20/23] Train loss=0.3649808466434479
Test set avg_accuracy=62.27% avg_sensitivity=71.81%, avg_specificity=59.23% avg_auc=71.55%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.406876 Test loss=0.635989 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.3833671808242798
[5/23] Train loss=0.45002612471580505
[10/23] Train loss=0.4104190468788147
[15/23] Train loss=0.37624770402908325
[20/23] Train loss=0.3651619851589203
Test set avg_accuracy=62.12% avg_sensitivity=73.53%, avg_specificity=58.49% avg_auc=72.21%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.411328 Test loss=0.639924 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.3871680200099945
[5/23] Train loss=0.42139607667922974
[10/23] Train loss=0.38954558968544006
[15/23] Train loss=0.4015266001224518
[20/23] Train loss=0.3548462688922882
Test set avg_accuracy=69.86% avg_sensitivity=68.19%, avg_specificity=70.39% avg_auc=75.17%
Best model saved!! Metric=-42.39555729040137!!
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.405891 Test loss=0.601361 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.39244624972343445
[5/23] Train loss=0.4113326668739319
[10/23] Train loss=0.3888995051383972
[15/23] Train loss=0.3759918808937073
[20/23] Train loss=0.3594246208667755
Test set avg_accuracy=65.39% avg_sensitivity=72.40%, avg_specificity=63.16% avg_auc=73.43%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.400081 Test loss=0.622217 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.3804905116558075
[5/23] Train loss=0.4105015993118286
[10/23] Train loss=0.41196349263191223
[15/23] Train loss=0.39446452260017395
[20/23] Train loss=0.36973536014556885
Test set avg_accuracy=66.08% avg_sensitivity=67.44%, avg_specificity=65.65% avg_auc=72.83%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.409125 Test loss=0.608994 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.40330764651298523
[5/23] Train loss=0.41057702898979187
[10/23] Train loss=0.40750178694725037
[15/23] Train loss=0.3876686692237854
[20/23] Train loss=0.3571731150150299
Test set avg_accuracy=68.22% avg_sensitivity=69.16%, avg_specificity=67.91% avg_auc=74.55%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.408374 Test loss=0.601808 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.38296401500701904
[5/23] Train loss=0.4127774238586426
[10/23] Train loss=0.38561365008354187
[15/23] Train loss=0.3961015045642853
[20/23] Train loss=0.35779497027397156
Test set avg_accuracy=71.84% avg_sensitivity=68.73%, avg_specificity=72.82% avg_auc=77.25%
Best model saved!! Metric=-35.358190422446!!
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.404893 Test loss=0.587582 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.38676926493644714
[5/23] Train loss=0.4114466607570648
[10/23] Train loss=0.40341639518737793
[15/23] Train loss=0.38727080821990967
[20/23] Train loss=0.3588787019252777
Test set avg_accuracy=64.44% avg_sensitivity=73.42%, avg_specificity=61.58% avg_auc=74.38%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.404439 Test loss=0.626712 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.388362854719162
[5/23] Train loss=0.4031549096107483
[10/23] Train loss=0.3886549174785614
[15/23] Train loss=0.37677061557769775
[20/23] Train loss=0.3568550944328308
Test set avg_accuracy=64.57% avg_sensitivity=67.33%, avg_specificity=63.69% avg_auc=71.58%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.400831 Test loss=0.612945 Current lr=[0.000299926900870094]

[0/23] Train loss=0.3888726830482483
[5/23] Train loss=0.4033445715904236
[10/23] Train loss=0.3933807909488678
[15/23] Train loss=0.36761629581451416
[20/23] Train loss=0.3571597933769226
Test set avg_accuracy=61.85% avg_sensitivity=70.67%, avg_specificity=59.04% avg_auc=70.97%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.396621 Test loss=0.633692 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.37644124031066895
[5/23] Train loss=0.40537509322166443
[10/23] Train loss=0.3837643265724182
[15/23] Train loss=0.37536269426345825
[20/23] Train loss=0.3678635358810425
Test set avg_accuracy=69.06% avg_sensitivity=66.95%, avg_specificity=69.73% avg_auc=75.17%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.398507 Test loss=0.583136 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.3912481367588043
[5/23] Train loss=0.40446874499320984
[10/23] Train loss=0.3903322219848633
[15/23] Train loss=0.3775898516178131
[20/23] Train loss=0.346716970205307
Test set avg_accuracy=66.21% avg_sensitivity=73.05%, avg_specificity=64.03% avg_auc=75.53%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.397813 Test loss=0.613059 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.37595680356025696
[5/23] Train loss=0.3953767418861389
[10/23] Train loss=0.3835276663303375
[15/23] Train loss=0.3624117076396942
[20/23] Train loss=0.348410040140152
Test set avg_accuracy=65.83% avg_sensitivity=68.41%, avg_specificity=65.01% avg_auc=72.81%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.390046 Test loss=0.605420 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.37347128987312317
[5/23] Train loss=0.3931054174900055
[10/23] Train loss=0.3862415552139282
[15/23] Train loss=0.3660290539264679
[20/23] Train loss=0.3415926694869995
Test set avg_accuracy=67.02% avg_sensitivity=73.10%, avg_specificity=65.08% avg_auc=75.13%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.389583 Test loss=0.606103 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3701760768890381
[5/23] Train loss=0.3952209949493408
[10/23] Train loss=0.37129953503608704
[15/23] Train loss=0.3671804666519165
[20/23] Train loss=0.3460298776626587
Test set avg_accuracy=64.88% avg_sensitivity=71.21%, avg_specificity=62.87% avg_auc=73.27%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.388949 Test loss=0.615829 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.3709622025489807
[5/23] Train loss=0.3951956331729889
[10/23] Train loss=0.37557080388069153
[15/23] Train loss=0.3918154537677765
[20/23] Train loss=0.36377426981925964
Test set avg_accuracy=70.69% avg_sensitivity=70.40%, avg_specificity=70.78% avg_auc=76.86%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.393616 Test loss=0.585243 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.3883720934391022
[5/23] Train loss=0.3975389301776886
[10/23] Train loss=0.3822256922721863
[15/23] Train loss=0.36539924144744873
[20/23] Train loss=0.34341293573379517
Test set avg_accuracy=68.28% avg_sensitivity=70.78%, avg_specificity=67.48% avg_auc=75.78%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.391454 Test loss=0.589937 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.3770197033882141
[5/23] Train loss=0.39375895261764526
[10/23] Train loss=0.3934963047504425
[15/23] Train loss=0.37299004197120667
[20/23] Train loss=0.3422486186027527
Test set avg_accuracy=64.83% avg_sensitivity=72.56%, avg_specificity=62.37% avg_auc=73.99%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.395428 Test loss=0.616760 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.3742166757583618
[5/23] Train loss=0.39445260167121887
[10/23] Train loss=0.3897169828414917
[15/23] Train loss=0.36621978878974915
[20/23] Train loss=0.33991125226020813
Test set avg_accuracy=66.78% avg_sensitivity=73.75%, avg_specificity=64.57% avg_auc=76.15%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.390010 Test loss=0.603988 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.36772477626800537
[5/23] Train loss=0.3916524052619934
[10/23] Train loss=0.37293970584869385
[15/23] Train loss=0.39282286167144775
[20/23] Train loss=0.33966365456581116
Test set avg_accuracy=66.59% avg_sensitivity=73.91%, avg_specificity=64.26% avg_auc=75.66%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.392662 Test loss=0.608904 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.38303807377815247
[5/23] Train loss=0.3956529200077057
[10/23] Train loss=0.3751002252101898
[15/23] Train loss=0.36335840821266174
[20/23] Train loss=0.3513558804988861
Test set avg_accuracy=60.92% avg_sensitivity=72.29%, avg_specificity=57.30% avg_auc=71.27%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.390497 Test loss=0.641535 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.3765389323234558
[5/23] Train loss=0.3881588578224182
[10/23] Train loss=0.37105366587638855
[15/23] Train loss=0.39387914538383484
[20/23] Train loss=0.3443608582019806
Test set avg_accuracy=67.53% avg_sensitivity=69.33%, avg_specificity=66.95% avg_auc=74.67%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.389844 Test loss=0.596571 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.3746936321258545
[5/23] Train loss=0.3889881372451782
[10/23] Train loss=0.3912658989429474
[15/23] Train loss=0.3769814968109131
[20/23] Train loss=0.3426266014575958
Test set avg_accuracy=64.96% avg_sensitivity=76.12%, avg_specificity=61.41% avg_auc=75.69%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.389868 Test loss=0.619814 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.3732334077358246
[5/23] Train loss=0.3926351070404053
[10/23] Train loss=0.3698543608188629
[15/23] Train loss=0.37418144941329956
[20/23] Train loss=0.3448560833930969
Test set avg_accuracy=63.85% avg_sensitivity=74.18%, avg_specificity=60.57% avg_auc=73.94%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.386231 Test loss=0.622918 Current lr=[0.000283047938381597]

[0/23] Train loss=0.3849850594997406
[5/23] Train loss=0.3901277482509613
[10/23] Train loss=0.38335612416267395
[15/23] Train loss=0.36393123865127563
[20/23] Train loss=0.3313199579715729
Test set avg_accuracy=63.03% avg_sensitivity=76.12%, avg_specificity=58.87% avg_auc=74.77%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.385021 Test loss=0.629350 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.3704840838909149
[5/23] Train loss=0.3855116665363312
[10/23] Train loss=0.37047457695007324
[15/23] Train loss=0.36212828755378723
[20/23] Train loss=0.3437415659427643
Test set avg_accuracy=68.01% avg_sensitivity=74.23%, avg_specificity=66.03% avg_auc=77.04%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.384703 Test loss=0.593493 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.3778773844242096
[5/23] Train loss=0.391792893409729
[10/23] Train loss=0.3769702613353729
[15/23] Train loss=0.36737367510795593
[20/23] Train loss=0.33478468656539917
Test set avg_accuracy=64.64% avg_sensitivity=76.55%, avg_specificity=60.84% avg_auc=75.73%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.382663 Test loss=0.618644 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.37186098098754883
[5/23] Train loss=0.3771245777606964
[10/23] Train loss=0.37000009417533875
[15/23] Train loss=0.3731265068054199
[20/23] Train loss=0.3320324718952179
Test set avg_accuracy=69.30% avg_sensitivity=73.32%, avg_specificity=68.02% avg_auc=77.60%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.383334 Test loss=0.583339 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.3721510171890259
[5/23] Train loss=0.38070276379585266
[10/23] Train loss=0.36957502365112305
[15/23] Train loss=0.38029447197914124
[20/23] Train loss=0.34130385518074036
Test set avg_accuracy=64.44% avg_sensitivity=74.34%, avg_specificity=61.29% avg_auc=74.18%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.384333 Test loss=0.621300 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.3783248960971832
[5/23] Train loss=0.3829183280467987
[10/23] Train loss=0.3728882372379303
[15/23] Train loss=0.3641376793384552
[20/23] Train loss=0.3300589621067047
Test set avg_accuracy=62.92% avg_sensitivity=76.98%, avg_specificity=58.44% avg_auc=74.91%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.381554 Test loss=0.631046 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.3684830665588379
[5/23] Train loss=0.3893256187438965
[10/23] Train loss=0.3762170076370239
[15/23] Train loss=0.3622282147407532
[20/23] Train loss=0.3309561610221863
Test set avg_accuracy=61.02% avg_sensitivity=77.25%, avg_specificity=55.85% avg_auc=73.49%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.382021 Test loss=0.644461 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.3639143705368042
[5/23] Train loss=0.38468578457832336
[10/23] Train loss=0.3685884475708008
[15/23] Train loss=0.363200306892395
[20/23] Train loss=0.33201777935028076
Test set avg_accuracy=63.87% avg_sensitivity=73.42%, avg_specificity=60.82% avg_auc=73.52%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.379721 Test loss=0.622474 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.3674551248550415
[5/23] Train loss=0.37916767597198486
[10/23] Train loss=0.36687350273132324
[15/23] Train loss=0.38067924976348877
[20/23] Train loss=0.3389228880405426
Test set avg_accuracy=65.49% avg_sensitivity=76.60%, avg_specificity=61.96% avg_auc=76.73%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.383769 Test loss=0.613042 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.37458911538124084
[5/23] Train loss=0.38986194133758545
[10/23] Train loss=0.366737961769104
[15/23] Train loss=0.3646591603755951
[20/23] Train loss=0.32795000076293945
Test set avg_accuracy=65.20% avg_sensitivity=71.97%, avg_specificity=63.04% avg_auc=73.80%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.379813 Test loss=0.610651 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.36378681659698486
[5/23] Train loss=0.3923049569129944
[10/23] Train loss=0.3771740794181824
[15/23] Train loss=0.3681158125400543
[20/23] Train loss=0.33065265417099
Test set avg_accuracy=61.73% avg_sensitivity=77.95%, avg_specificity=56.57% avg_auc=74.81%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.380464 Test loss=0.640545 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.36407044529914856
[5/23] Train loss=0.3735257089138031
[10/23] Train loss=0.3696425259113312
[15/23] Train loss=0.35804423689842224
[20/23] Train loss=0.3283402919769287
Test set avg_accuracy=63.16% avg_sensitivity=72.88%, avg_specificity=60.07% avg_auc=72.72%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.378058 Test loss=0.628494 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.36725154519081116
[5/23] Train loss=0.38124218583106995
[10/23] Train loss=0.37865445017814636
[15/23] Train loss=0.3584322929382324
[20/23] Train loss=0.3288561701774597
Test set avg_accuracy=64.87% avg_sensitivity=74.50%, avg_specificity=61.80% avg_auc=74.70%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.377760 Test loss=0.615604 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.36594316363334656
[5/23] Train loss=0.3758011758327484
[10/23] Train loss=0.36715811491012573
[15/23] Train loss=0.3546403646469116
[20/23] Train loss=0.34084048867225647
Test set avg_accuracy=62.99% avg_sensitivity=76.33%, avg_specificity=58.75% avg_auc=74.55%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.380303 Test loss=0.633472 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.3720696270465851
[5/23] Train loss=0.3800235092639923
[10/23] Train loss=0.36157330870628357
[15/23] Train loss=0.3710702955722809
[20/23] Train loss=0.3382298946380615
Test set avg_accuracy=63.36% avg_sensitivity=76.23%, avg_specificity=59.26% avg_auc=74.42%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.380412 Test loss=0.631423 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.3759748041629791
[5/23] Train loss=0.3918253779411316
[10/23] Train loss=0.37465760111808777
[15/23] Train loss=0.3617602288722992
[20/23] Train loss=0.33371126651763916
Test set avg_accuracy=64.73% avg_sensitivity=77.30%, avg_specificity=60.72% avg_auc=76.41%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.380749 Test loss=0.615726 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.36317989230155945
[5/23] Train loss=0.3829716444015503
[10/23] Train loss=0.38184309005737305
[15/23] Train loss=0.3588601350784302
[20/23] Train loss=0.33389779925346375
Test set avg_accuracy=65.38% avg_sensitivity=76.23%, avg_specificity=61.92% avg_auc=76.51%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.379825 Test loss=0.609205 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.3696857690811157
[5/23] Train loss=0.3763755261898041
[10/23] Train loss=0.3622610867023468
[15/23] Train loss=0.36163437366485596
[20/23] Train loss=0.32661211490631104
Test set avg_accuracy=60.83% avg_sensitivity=79.57%, avg_specificity=54.87% avg_auc=74.22%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.377444 Test loss=0.651782 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.3702952265739441
[5/23] Train loss=0.3847145140171051
[10/23] Train loss=0.36385685205459595
[15/23] Train loss=0.359761118888855
[20/23] Train loss=0.32667240500450134
Test set avg_accuracy=63.02% avg_sensitivity=73.48%, avg_specificity=59.69% avg_auc=73.16%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.377089 Test loss=0.629818 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.36656585335731506
[5/23] Train loss=0.3742612302303314
[10/23] Train loss=0.3687500059604645
[15/23] Train loss=0.36930540204048157
[20/23] Train loss=0.32487931847572327
Test set avg_accuracy=62.34% avg_sensitivity=74.72%, avg_specificity=58.40% avg_auc=73.01%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.373945 Test loss=0.637681 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.37143489718437195
[5/23] Train loss=0.3801935911178589
[10/23] Train loss=0.37542322278022766
[15/23] Train loss=0.35958850383758545
[20/23] Train loss=0.32733696699142456
Test set avg_accuracy=62.86% avg_sensitivity=76.28%, avg_specificity=58.59% avg_auc=74.54%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.376516 Test loss=0.628259 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.37366995215415955
[5/23] Train loss=0.3775123059749603
[10/23] Train loss=0.3643798530101776
[15/23] Train loss=0.3568613827228546
[20/23] Train loss=0.3215305507183075
Test set avg_accuracy=62.33% avg_sensitivity=78.60%, avg_specificity=57.15% avg_auc=74.92%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.373438 Test loss=0.640363 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.3728781044483185
[5/23] Train loss=0.38300809264183044
[10/23] Train loss=0.36487606167793274
[15/23] Train loss=0.36417925357818604
[20/23] Train loss=0.3231368362903595
Test set avg_accuracy=63.15% avg_sensitivity=75.42%, avg_specificity=59.24% avg_auc=73.83%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.374868 Test loss=0.632950 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.36513635516166687
[5/23] Train loss=0.370493620634079
[10/23] Train loss=0.3650777339935303
[15/23] Train loss=0.35092100501060486
[20/23] Train loss=0.3167305290699005
Test set avg_accuracy=62.02% avg_sensitivity=74.29%, avg_specificity=58.11% avg_auc=72.49%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.367625 Test loss=0.642970 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.3555951714515686
[5/23] Train loss=0.3614426255226135
[10/23] Train loss=0.3577612042427063
[15/23] Train loss=0.35189589858055115
[20/23] Train loss=0.3171941936016083
Test set avg_accuracy=62.77% avg_sensitivity=77.36%, avg_specificity=58.13% avg_auc=74.33%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.364162 Test loss=0.636965 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.361045777797699
[5/23] Train loss=0.36668556928634644
[10/23] Train loss=0.3637103736400604
[15/23] Train loss=0.35314980149269104
[20/23] Train loss=0.31897157430648804
Test set avg_accuracy=62.89% avg_sensitivity=77.04%, avg_specificity=58.39% avg_auc=74.36%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.367674 Test loss=0.637250 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.3574538230895996
[5/23] Train loss=0.37722283601760864
[10/23] Train loss=0.35830867290496826
[15/23] Train loss=0.35815533995628357
[20/23] Train loss=0.32163700461387634
Test set avg_accuracy=62.27% avg_sensitivity=78.27%, avg_specificity=57.17% avg_auc=74.89%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.368602 Test loss=0.638287 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.36556175351142883
[5/23] Train loss=0.3750835657119751
[10/23] Train loss=0.36525586247444153
[15/23] Train loss=0.36259761452674866
[20/23] Train loss=0.32585573196411133
Test set avg_accuracy=66.21% avg_sensitivity=73.91%, avg_specificity=63.76% avg_auc=75.64%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.374552 Test loss=0.602394 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.36179497838020325
[5/23] Train loss=0.3713260889053345
[10/23] Train loss=0.36108705401420593
[15/23] Train loss=0.35447564721107483
[20/23] Train loss=0.31831666827201843
Test set avg_accuracy=60.18% avg_sensitivity=74.99%, avg_specificity=55.47% avg_auc=71.67%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.367864 Test loss=0.664020 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.35689598321914673
[5/23] Train loss=0.36595430970191956
[10/23] Train loss=0.3640911281108856
[15/23] Train loss=0.3531491458415985
[20/23] Train loss=0.3202399015426636
Test set avg_accuracy=61.04% avg_sensitivity=76.66%, avg_specificity=56.07% avg_auc=73.36%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.370238 Test loss=0.651155 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.36408376693725586
[5/23] Train loss=0.3760696053504944
[10/23] Train loss=0.3653176426887512
[15/23] Train loss=0.36149173974990845
[20/23] Train loss=0.3259540796279907
Test set avg_accuracy=61.85% avg_sensitivity=75.85%, avg_specificity=57.39% avg_auc=73.30%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.370871 Test loss=0.645816 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.3607375919818878
[5/23] Train loss=0.366033136844635
[10/23] Train loss=0.3614344000816345
[15/23] Train loss=0.35236868262290955
[20/23] Train loss=0.31956788897514343
Test set avg_accuracy=60.44% avg_sensitivity=75.47%, avg_specificity=55.66% avg_auc=72.42%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.366939 Test loss=0.657712 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.3609657883644104
[5/23] Train loss=0.3704107403755188
[10/23] Train loss=0.35723352432250977
[15/23] Train loss=0.3530777096748352
[20/23] Train loss=0.31995147466659546
Test set avg_accuracy=63.37% avg_sensitivity=73.64%, avg_specificity=60.10% avg_auc=73.17%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.365785 Test loss=0.630899 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.35964101552963257
[5/23] Train loss=0.3631812632083893
[10/23] Train loss=0.35484084486961365
[15/23] Train loss=0.3518674373626709
[20/23] Train loss=0.3211889863014221
Test set avg_accuracy=57.62% avg_sensitivity=72.99%, avg_specificity=52.72% avg_auc=69.04%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.363097 Test loss=0.688786 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.3542749583721161
[5/23] Train loss=0.36462411284446716
[10/23] Train loss=0.35743436217308044
[15/23] Train loss=0.35482412576675415
[20/23] Train loss=0.3178926706314087
Test set avg_accuracy=61.16% avg_sensitivity=70.73%, avg_specificity=58.11% avg_auc=70.49%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.364281 Test loss=0.654541 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.353792667388916
[5/23] Train loss=0.357634574174881
[10/23] Train loss=0.3547733426094055
[15/23] Train loss=0.35269445180892944
[20/23] Train loss=0.3163278102874756
Test set avg_accuracy=62.49% avg_sensitivity=74.50%, avg_specificity=58.66% avg_auc=73.08%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.363764 Test loss=0.640895 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.36070260405540466
[5/23] Train loss=0.36039018630981445
[10/23] Train loss=0.3592213988304138
[15/23] Train loss=0.36393222212791443
[20/23] Train loss=0.3163391351699829
Test set avg_accuracy=61.37% avg_sensitivity=73.37%, avg_specificity=57.55% avg_auc=71.81%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.367697 Test loss=0.653207 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.36034145951271057
[5/23] Train loss=0.3654467463493347
[10/23] Train loss=0.36414244771003723
[15/23] Train loss=0.35480183362960815
[20/23] Train loss=0.31819668412208557
Test set avg_accuracy=63.85% avg_sensitivity=73.21%, avg_specificity=60.88% avg_auc=73.31%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.365571 Test loss=0.630225 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.353715717792511
[5/23] Train loss=0.35914504528045654
[10/23] Train loss=0.3593260943889618
[15/23] Train loss=0.34756749868392944
[20/23] Train loss=0.3137253522872925
Test set avg_accuracy=62.53% avg_sensitivity=72.45%, avg_specificity=59.36% avg_auc=72.10%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.362136 Test loss=0.643015 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.3523694574832916
[5/23] Train loss=0.3608766794204712
[10/23] Train loss=0.3565688729286194
[15/23] Train loss=0.34808292984962463
[20/23] Train loss=0.3136579692363739
Test set avg_accuracy=59.84% avg_sensitivity=71.59%, avg_specificity=56.10% avg_auc=70.02%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.359614 Test loss=0.673048 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.3477197289466858
[5/23] Train loss=0.35397738218307495
[10/23] Train loss=0.35845357179641724
[15/23] Train loss=0.3464542627334595
[20/23] Train loss=0.31296050548553467
Test set avg_accuracy=61.61% avg_sensitivity=70.30%, avg_specificity=58.85% avg_auc=70.72%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.359213 Test loss=0.655246 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.34834229946136475
[5/23] Train loss=0.3533303737640381
[10/23] Train loss=0.35496461391448975
[15/23] Train loss=0.3522571623325348
[20/23] Train loss=0.31305721402168274
Test set avg_accuracy=63.72% avg_sensitivity=71.59%, avg_specificity=61.22% avg_auc=72.56%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.356941 Test loss=0.631306 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.3534730076789856
[5/23] Train loss=0.3513808846473694
[10/23] Train loss=0.36021044850349426
[15/23] Train loss=0.3463706374168396
[20/23] Train loss=0.3113480508327484
Test set avg_accuracy=61.13% avg_sensitivity=69.16%, avg_specificity=58.58% avg_auc=69.75%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.356968 Test loss=0.662301 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.3473656475543976
[5/23] Train loss=0.3496754765510559
[10/23] Train loss=0.3582794964313507
[15/23] Train loss=0.3481175899505615
[20/23] Train loss=0.31451061367988586
Test set avg_accuracy=62.08% avg_sensitivity=72.78%, avg_specificity=58.68% avg_auc=72.38%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.357456 Test loss=0.643636 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.3595639169216156
[5/23] Train loss=0.36591148376464844
[10/23] Train loss=0.3636799454689026
[15/23] Train loss=0.3475325405597687
[20/23] Train loss=0.316030889749527
Test set avg_accuracy=64.01% avg_sensitivity=70.78%, avg_specificity=61.85% avg_auc=72.89%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.362318 Test loss=0.624878 Current lr=[0.000112073915556435]

[0/23] Train loss=0.34887418150901794
[5/23] Train loss=0.3541322350502014
[10/23] Train loss=0.3566953241825104
[15/23] Train loss=0.35214948654174805
[20/23] Train loss=0.31732046604156494
Test set avg_accuracy=64.86% avg_sensitivity=69.11%, avg_specificity=63.50% avg_auc=72.86%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.359857 Test loss=0.613959 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.35386914014816284
[5/23] Train loss=0.35858744382858276
[10/23] Train loss=0.3592933118343353
[15/23] Train loss=0.343983918428421
[20/23] Train loss=0.31463783979415894
Test set avg_accuracy=63.53% avg_sensitivity=72.35%, avg_specificity=60.72% avg_auc=73.01%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.359424 Test loss=0.631197 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.35052651166915894
[5/23] Train loss=0.3531263470649719
[10/23] Train loss=0.35450875759124756
[15/23] Train loss=0.3423044979572296
[20/23] Train loss=0.3121258616447449
Test set avg_accuracy=62.97% avg_sensitivity=71.11%, avg_specificity=60.38% avg_auc=71.88%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.354937 Test loss=0.641037 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.35109490156173706
[5/23] Train loss=0.34938955307006836
[10/23] Train loss=0.3578627407550812
[15/23] Train loss=0.3395741283893585
[20/23] Train loss=0.30913245677948
Test set avg_accuracy=61.81% avg_sensitivity=72.08%, avg_specificity=58.54% avg_auc=71.84%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.353950 Test loss=0.651983 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.3493829369544983
[5/23] Train loss=0.34446191787719727
[10/23] Train loss=0.353763610124588
[15/23] Train loss=0.33955782651901245
[20/23] Train loss=0.3097154200077057
Test set avg_accuracy=61.55% avg_sensitivity=74.56%, avg_specificity=57.41% avg_auc=72.50%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.352380 Test loss=0.657128 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.34959253668785095
[5/23] Train loss=0.3407628834247589
[10/23] Train loss=0.3571474254131317
[15/23] Train loss=0.33943426609039307
[20/23] Train loss=0.30983418226242065
Test set avg_accuracy=60.78% avg_sensitivity=73.10%, avg_specificity=56.86% avg_auc=71.43%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.353314 Test loss=0.666912 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.3495749831199646
[5/23] Train loss=0.34150880575180054
[10/23] Train loss=0.35543984174728394
[15/23] Train loss=0.33965519070625305
[20/23] Train loss=0.3103718161582947
Test set avg_accuracy=61.35% avg_sensitivity=73.58%, avg_specificity=57.46% avg_auc=72.36%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.354231 Test loss=0.656696 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.35130399465560913
[5/23] Train loss=0.3418976962566376
[10/23] Train loss=0.35547351837158203
[15/23] Train loss=0.3387657403945923
[20/23] Train loss=0.31130993366241455
Test set avg_accuracy=61.41% avg_sensitivity=73.75%, avg_specificity=57.48% avg_auc=72.23%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.353526 Test loss=0.655378 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.34690290689468384
[5/23] Train loss=0.3406509459018707
[10/23] Train loss=0.3541486859321594
[15/23] Train loss=0.33804991841316223
[20/23] Train loss=0.3117925822734833
Test set avg_accuracy=61.71% avg_sensitivity=71.97%, avg_specificity=58.44% avg_auc=71.61%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.352986 Test loss=0.656402 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.34527450799942017
[5/23] Train loss=0.3415397107601166
[10/23] Train loss=0.3548714518547058
[15/23] Train loss=0.3394235670566559
[20/23] Train loss=0.31065624952316284
Test set avg_accuracy=60.21% avg_sensitivity=72.08%, avg_specificity=56.43% avg_auc=70.74%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.351707 Test loss=0.672632 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.3450910151004791
[5/23] Train loss=0.341182142496109
[10/23] Train loss=0.3543921411037445
[15/23] Train loss=0.33563506603240967
[20/23] Train loss=0.31059566140174866
Test set avg_accuracy=61.05% avg_sensitivity=70.40%, avg_specificity=58.08% avg_auc=70.71%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.351007 Test loss=0.664417 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.3420923352241516
[5/23] Train loss=0.33894312381744385
[10/23] Train loss=0.35373592376708984
[15/23] Train loss=0.33829158544540405
[20/23] Train loss=0.3098538815975189
Test set avg_accuracy=60.33% avg_sensitivity=70.24%, avg_specificity=57.17% avg_auc=70.13%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.349680 Test loss=0.674104 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.34107235074043274
[5/23] Train loss=0.33605584502220154
[10/23] Train loss=0.3525959849357605
[15/23] Train loss=0.3357771933078766
[20/23] Train loss=0.3074275851249695
Test set avg_accuracy=60.90% avg_sensitivity=70.13%, avg_specificity=57.96% avg_auc=70.25%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.347882 Test loss=0.669348 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.3400556743144989
[5/23] Train loss=0.33762142062187195
[10/23] Train loss=0.35269612073898315
[15/23] Train loss=0.33582451939582825
[20/23] Train loss=0.3049299418926239
Test set avg_accuracy=60.99% avg_sensitivity=70.46%, avg_specificity=57.97% avg_auc=70.53%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.347138 Test loss=0.668190 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.3397975564002991
[5/23] Train loss=0.3346242308616638
[10/23] Train loss=0.35257408022880554
[15/23] Train loss=0.3352890610694885
[20/23] Train loss=0.3036082088947296
Test set avg_accuracy=60.35% avg_sensitivity=69.81%, avg_specificity=57.34% avg_auc=69.69%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.346575 Test loss=0.677625 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.3392889201641083
[5/23] Train loss=0.3351927101612091
[10/23] Train loss=0.35218849778175354
[15/23] Train loss=0.33459004759788513
[20/23] Train loss=0.3024843633174896
Test set avg_accuracy=60.38% avg_sensitivity=70.40%, avg_specificity=57.18% avg_auc=70.00%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.346010 Test loss=0.677838 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.3393692374229431
[5/23] Train loss=0.3339604139328003
[10/23] Train loss=0.3525189161300659
[15/23] Train loss=0.3340696692466736
[20/23] Train loss=0.3014720678329468
Test set avg_accuracy=60.42% avg_sensitivity=69.87%, avg_specificity=57.41% avg_auc=69.45%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.345781 Test loss=0.680796 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.3379521667957306
[5/23] Train loss=0.3340494930744171
[10/23] Train loss=0.35244351625442505
[15/23] Train loss=0.3346480429172516
[20/23] Train loss=0.3011530041694641
Test set avg_accuracy=60.62% avg_sensitivity=70.13%, avg_specificity=57.60% avg_auc=70.15%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.345320 Test loss=0.674459 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.3377349376678467
[5/23] Train loss=0.3324226438999176
[10/23] Train loss=0.3528881371021271
[15/23] Train loss=0.3347233533859253
[20/23] Train loss=0.3004745841026306
Test set avg_accuracy=60.40% avg_sensitivity=70.13%, avg_specificity=57.30% avg_auc=69.70%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.344943 Test loss=0.679956 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.33730486035346985
[5/23] Train loss=0.3311087489128113
[10/23] Train loss=0.3527434468269348
[15/23] Train loss=0.33399108052253723
[20/23] Train loss=0.3001766502857208
Test set avg_accuracy=60.68% avg_sensitivity=69.97%, avg_specificity=57.72% avg_auc=70.05%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.344521 Test loss=0.674000 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.3370267450809479
[5/23] Train loss=0.3306887745857239
[10/23] Train loss=0.35387346148490906
[15/23] Train loss=0.3333207964897156
[20/23] Train loss=0.29962337017059326
Test set avg_accuracy=60.64% avg_sensitivity=70.03%, avg_specificity=57.65% avg_auc=70.00%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.344253 Test loss=0.675177 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.3362537622451782
[5/23] Train loss=0.33061009645462036
[10/23] Train loss=0.3520820140838623
[15/23] Train loss=0.3337308466434479
[20/23] Train loss=0.2991774380207062
Test set avg_accuracy=60.98% avg_sensitivity=69.49%, avg_specificity=58.27% avg_auc=69.83%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.343973 Test loss=0.674462 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.3370152413845062
[5/23] Train loss=0.3305278420448303
[10/23] Train loss=0.35423222184181213
[15/23] Train loss=0.331802636384964
[20/23] Train loss=0.2990714907646179
Test set avg_accuracy=60.69% avg_sensitivity=70.24%, avg_specificity=57.65% avg_auc=70.30%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.343850 Test loss=0.671519 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.33660051226615906
[5/23] Train loss=0.3377751111984253
[10/23] Train loss=0.35139134526252747
[15/23] Train loss=0.3321274518966675
[20/23] Train loss=0.2974945306777954
Test set avg_accuracy=60.95% avg_sensitivity=69.81%, avg_specificity=58.13% avg_auc=70.03%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.343529 Test loss=0.673163 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.33889931440353394
[5/23] Train loss=0.3315782845020294
[10/23] Train loss=0.3560703992843628
[15/23] Train loss=0.3332916796207428
[20/23] Train loss=0.29976916313171387
Test set avg_accuracy=61.08% avg_sensitivity=69.76%, avg_specificity=58.32% avg_auc=70.02%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.344026 Test loss=0.672585 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.33803433179855347
[5/23] Train loss=0.3313847482204437
[10/23] Train loss=0.35273364186286926
[15/23] Train loss=0.3326488733291626
[20/23] Train loss=0.29826682806015015
Test set avg_accuracy=61.22% avg_sensitivity=69.87%, avg_specificity=58.47% avg_auc=70.36%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.343899 Test loss=0.669215 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.3360457718372345
[5/23] Train loss=0.33488500118255615
[10/23] Train loss=0.3526769280433655
[15/23] Train loss=0.33548301458358765
[20/23] Train loss=0.2989203929901123
Test set avg_accuracy=60.57% avg_sensitivity=70.62%, avg_specificity=57.37% avg_auc=70.18%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.343648 Test loss=0.677113 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.33617836236953735
[5/23] Train loss=0.331758975982666
[10/23] Train loss=0.34967127442359924
[15/23] Train loss=0.33067235350608826
[20/23] Train loss=0.29839614033699036
Test set avg_accuracy=60.05% avg_sensitivity=70.94%, avg_specificity=56.58% avg_auc=70.11%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.342464 Test loss=0.681996 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.3342777490615845
[5/23] Train loss=0.3318224251270294
[10/23] Train loss=0.3486552834510803
[15/23] Train loss=0.3297972083091736
[20/23] Train loss=0.2973784804344177
Test set avg_accuracy=60.16% avg_sensitivity=71.43%, avg_specificity=56.57% avg_auc=70.28%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.341310 Test loss=0.681236 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.3342936038970947
[5/23] Train loss=0.3290230333805084
[10/23] Train loss=0.3482992947101593
[15/23] Train loss=0.3293255567550659
[20/23] Train loss=0.2971697151660919
Test set avg_accuracy=59.99% avg_sensitivity=70.62%, avg_specificity=56.60% avg_auc=70.00%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.340695 Test loss=0.683563 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.3336426317691803
[5/23] Train loss=0.3289412260055542
[10/23] Train loss=0.3482055962085724
[15/23] Train loss=0.3290867805480957
[20/23] Train loss=0.29655489325523376
Test set avg_accuracy=59.70% avg_sensitivity=70.35%, avg_specificity=56.31% avg_auc=69.66%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.340263 Test loss=0.688360 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.33318251371383667
[5/23] Train loss=0.32785454392433167
[10/23] Train loss=0.3479168117046356
[15/23] Train loss=0.3289383053779602
[20/23] Train loss=0.2962127923965454
Test set avg_accuracy=59.71% avg_sensitivity=70.19%, avg_specificity=56.38% avg_auc=69.44%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.339922 Test loss=0.690647 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.3330296277999878
[5/23] Train loss=0.3277365267276764
[10/23] Train loss=0.34794503450393677
[15/23] Train loss=0.32851672172546387
[20/23] Train loss=0.29620546102523804
Test set avg_accuracy=59.67% avg_sensitivity=70.24%, avg_specificity=56.31% avg_auc=69.50%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.339755 Test loss=0.690282 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.33276429772377014
[5/23] Train loss=0.3275729715824127
[10/23] Train loss=0.34791427850723267
[15/23] Train loss=0.3284348249435425
[20/23] Train loss=0.29586678743362427
Test set avg_accuracy=59.60% avg_sensitivity=70.19%, avg_specificity=56.22% avg_auc=69.44%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.339571 Test loss=0.691314 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.33249858021736145
[5/23] Train loss=0.32705873250961304
[10/23] Train loss=0.3478224575519562
[15/23] Train loss=0.32846224308013916
[20/23] Train loss=0.29557421803474426
Test set avg_accuracy=59.54% avg_sensitivity=70.13%, avg_specificity=56.17% avg_auc=69.39%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.339426 Test loss=0.692430 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.33231890201568604
[5/23] Train loss=0.3269195556640625
[10/23] Train loss=0.3477628827095032
[15/23] Train loss=0.3282601833343506
[20/23] Train loss=0.29547056555747986
Test set avg_accuracy=59.52% avg_sensitivity=70.13%, avg_specificity=56.14% avg_auc=69.36%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.339308 Test loss=0.692873 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.3322271406650543
[5/23] Train loss=0.3268236219882965
[10/23] Train loss=0.34773194789886475
[15/23] Train loss=0.3282371163368225
[20/23] Train loss=0.2953411340713501
Test set avg_accuracy=59.49% avg_sensitivity=70.08%, avg_specificity=56.12% avg_auc=69.35%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.339219 Test loss=0.693139 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.33207112550735474
[5/23] Train loss=0.326697438955307
[10/23] Train loss=0.34769177436828613
[15/23] Train loss=0.3281590938568115
[20/23] Train loss=0.2952273190021515
Test set avg_accuracy=59.49% avg_sensitivity=70.03%, avg_specificity=56.14% avg_auc=69.33%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.339140 Test loss=0.693493 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.332019567489624
[5/23] Train loss=0.32662883400917053
[10/23] Train loss=0.3476676344871521
[15/23] Train loss=0.32811808586120605
[20/23] Train loss=0.29516369104385376
Test set avg_accuracy=59.48% avg_sensitivity=69.92%, avg_specificity=56.15% avg_auc=69.31%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.339086 Test loss=0.693810 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.33195021748542786
[5/23] Train loss=0.3265649974346161
[10/23] Train loss=0.3476494550704956
[15/23] Train loss=0.3280904293060303
[20/23] Train loss=0.29511407017707825
Test set avg_accuracy=59.47% avg_sensitivity=69.92%, avg_specificity=56.14% avg_auc=69.30%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.339044 Test loss=0.694026 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.3319060802459717
[5/23] Train loss=0.3265281915664673
[10/23] Train loss=0.3476334512233734
[15/23] Train loss=0.3280685544013977
[20/23] Train loss=0.2950809597969055
Test set avg_accuracy=59.48% avg_sensitivity=69.92%, avg_specificity=56.15% avg_auc=69.29%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.339015 Test loss=0.694149 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.33188050985336304
[5/23] Train loss=0.32650554180145264
[10/23] Train loss=0.3476223945617676
[15/23] Train loss=0.32805362343788147
[20/23] Train loss=0.29506099224090576
Test set avg_accuracy=59.45% avg_sensitivity=69.92%, avg_specificity=56.12% avg_auc=69.28%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.338996 Test loss=0.694223 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.3318667411804199
[5/23] Train loss=0.3264927864074707
[10/23] Train loss=0.347615510225296
[15/23] Train loss=0.32804545760154724
[20/23] Train loss=0.2950518727302551
Test set avg_accuracy=59.45% avg_sensitivity=69.92%, avg_specificity=56.12% avg_auc=69.28%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.338986 Test loss=0.694255 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.33186131715774536
[5/23] Train loss=0.3264879286289215
[10/23] Train loss=0.34761202335357666
[15/23] Train loss=0.3280427157878876
[20/23] Train loss=0.29504892230033875
Test set avg_accuracy=59.45% avg_sensitivity=69.92%, avg_specificity=56.12% avg_auc=69.28%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.338982 Test loss=0.694264 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=71.84% sen=68.73%, spe=72.82%, auc=77.25%!
Fold[9] Avg_overlap=0.25%(±0.15630503994854197)
[0/24] Train loss=0.690251350402832
[5/24] Train loss=0.6892591714859009
[10/24] Train loss=0.6892430782318115
[15/24] Train loss=0.6887490749359131
[20/24] Train loss=0.6882522702217102
Test set avg_accuracy=62.19% avg_sensitivity=27.64%, avg_specificity=72.20% avg_auc=49.73%
Best model saved!! Metric=-114.24267129004873!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.688819 Test loss=0.686385 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.6878349781036377
[5/24] Train loss=0.6869786977767944
[10/24] Train loss=0.6864985227584839
[15/24] Train loss=0.6862664222717285
[20/24] Train loss=0.6856730580329895
Test set avg_accuracy=62.42% avg_sensitivity=27.23%, avg_specificity=72.62% avg_auc=49.91%
Best model saved!! Metric=-113.81774209529725!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.686254 Test loss=0.683413 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6852792501449585
[5/24] Train loss=0.6845278143882751
[10/24] Train loss=0.6837034225463867
[15/24] Train loss=0.6837531328201294
[20/24] Train loss=0.6831169724464417
Test set avg_accuracy=66.30% avg_sensitivity=21.84%, avg_specificity=79.19% avg_auc=49.90%
Best model saved!! Metric=-108.7674487805829!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.683598 Test loss=0.680150 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6825460195541382
[5/24] Train loss=0.6816362142562866
[10/24] Train loss=0.6804307699203491
[15/24] Train loss=0.6803797483444214
[20/24] Train loss=0.6796585917472839
Test set avg_accuracy=66.42% avg_sensitivity=21.49%, avg_specificity=79.44% avg_auc=50.18%
Best model saved!! Metric=-108.46572074559683!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.680342 Test loss=0.675575 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6786206960678101
[5/24] Train loss=0.6776204705238342
[10/24] Train loss=0.6758613586425781
[15/24] Train loss=0.6758705377578735
[20/24] Train loss=0.6750119924545288
Test set avg_accuracy=69.90% avg_sensitivity=15.24%, avg_specificity=85.74% avg_auc=50.53%
Best model saved!! Metric=-104.60070793652585!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.675859 Test loss=0.669604 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6735564470291138
[5/24] Train loss=0.6724337339401245
[10/24] Train loss=0.6700617671012878
[15/24] Train loss=0.6701167225837708
[20/24] Train loss=0.6691824793815613
Test set avg_accuracy=73.54% avg_sensitivity=8.86%, avg_specificity=92.29% avg_auc=50.82%
Best model saved!! Metric=-100.48778450222142!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.670120 Test loss=0.661983 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6672717928886414
[5/24] Train loss=0.6658189296722412
[10/24] Train loss=0.6625796556472778
[15/24] Train loss=0.662757933139801
[20/24] Train loss=0.6614288687705994
Test set avg_accuracy=77.06% avg_sensitivity=1.51%, avg_specificity=98.96% avg_auc=51.07%
Best model saved!! Metric=-97.40544952682488!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.662707 Test loss=0.651845 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.659125566482544
[5/24] Train loss=0.6571275591850281
[10/24] Train loss=0.6527379751205444
[15/24] Train loss=0.6528708338737488
[20/24] Train loss=0.6509960889816284
Test set avg_accuracy=74.67% avg_sensitivity=5.56%, avg_specificity=94.71% avg_auc=51.47%
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.652836 Test loss=0.638098 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6482405662536621
[5/24] Train loss=0.6453425288200378
[10/24] Train loss=0.6394851803779602
[15/24] Train loss=0.6393095254898071
[20/24] Train loss=0.6367558240890503
Test set avg_accuracy=77.33% avg_sensitivity=0.70%, avg_specificity=99.55% avg_auc=51.87%
Best model saved!! Metric=-96.55843733230516!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.639406 Test loss=0.618687 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6333562135696411
[5/24] Train loss=0.6286606192588806
[10/24] Train loss=0.6203539967536926
[15/24] Train loss=0.6197835803031921
[20/24] Train loss=0.6162458062171936
Test set avg_accuracy=77.42% avg_sensitivity=0.29%, avg_specificity=99.78% avg_auc=52.50%
Best model saved!! Metric=-96.00744600915827!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.620166 Test loss=0.590883 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6133427023887634
[5/24] Train loss=0.6063029170036316
[10/24] Train loss=0.5965903997421265
[15/24] Train loss=0.5976172685623169
[20/24] Train loss=0.5951663255691528
Test set avg_accuracy=77.46% avg_sensitivity=0.06%, avg_specificity=99.90% avg_auc=53.12%
Best model saved!! Metric=-95.46639861220206!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.597075 Test loss=0.561430 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5954715609550476
[5/24] Train loss=0.5860608220100403
[10/24] Train loss=0.5781492590904236
[15/24] Train loss=0.5816728472709656
[20/24] Train loss=0.5823136568069458
Test set avg_accuracy=77.53% avg_sensitivity=0.06%, avg_specificity=99.98% avg_auc=53.49%
Best model saved!! Metric=-94.93972173143644!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.579026 Test loss=0.542355 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5872210264205933
[5/24] Train loss=0.5758707523345947
[10/24] Train loss=0.5692781209945679
[15/24] Train loss=0.5738607048988342
[20/24] Train loss=0.5767368674278259
Test set avg_accuracy=77.55% avg_sensitivity=0.12%, avg_specificity=100.00% avg_auc=56.08%
Best model saved!! Metric=-92.25190580549113!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.570485 Test loss=0.536641 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5844042897224426
[5/24] Train loss=0.5730334520339966
[10/24] Train loss=0.5662326812744141
[15/24] Train loss=0.5700427889823914
[20/24] Train loss=0.5746541619300842
Test set avg_accuracy=77.55% avg_sensitivity=0.12%, avg_specificity=100.00% avg_auc=58.20%
Best model saved!! Metric=-90.13403204096736!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.567234 Test loss=0.534409 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5835868120193481
[5/24] Train loss=0.571391761302948
[10/24] Train loss=0.5647574663162231
[15/24] Train loss=0.5680716633796692
[20/24] Train loss=0.5727843046188354
Test set avg_accuracy=77.54% avg_sensitivity=0.12%, avg_specificity=99.98% avg_auc=59.66%
Best model saved!! Metric=-88.70538985021219!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.565604 Test loss=0.533376 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5818411707878113
[5/24] Train loss=0.569879412651062
[10/24] Train loss=0.5629885196685791
[15/24] Train loss=0.5656688809394836
[20/24] Train loss=0.5705465078353882
Test set avg_accuracy=77.53% avg_sensitivity=0.06%, avg_specificity=99.98% avg_auc=61.87%
Best model saved!! Metric=-86.56635733985338!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.563829 Test loss=0.531776 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.5787175893783569
[5/24] Train loss=0.5670291185379028
[10/24] Train loss=0.5611695647239685
[15/24] Train loss=0.5603365898132324
[20/24] Train loss=0.566435694694519
Test set avg_accuracy=77.50% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=65.08%
Best model saved!! Metric=-83.45663061454934!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.560369 Test loss=0.529546 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.5705392360687256
[5/24] Train loss=0.5621697902679443
[10/24] Train loss=0.5585739016532898
[15/24] Train loss=0.553550124168396
[20/24] Train loss=0.5562635064125061
Test set avg_accuracy=77.51% avg_sensitivity=0.12%, avg_specificity=99.95% avg_auc=71.01%
Best model saved!! Metric=-77.40676628700332!!
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.554001 Test loss=0.525526 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5566754937171936
[5/24] Train loss=0.550125002861023
[10/24] Train loss=0.5491378903388977
[15/24] Train loss=0.5398885607719421
[20/24] Train loss=0.5408036708831787
Test set avg_accuracy=77.24% avg_sensitivity=3.71%, avg_specificity=98.56% avg_auc=73.85%
Best model saved!! Metric=-72.64714033530272!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.542043 Test loss=0.539789 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5380903482437134
[5/24] Train loss=0.5344629287719727
[10/24] Train loss=0.5331326127052307
[15/24] Train loss=0.5206798315048218
[20/24] Train loss=0.523036003112793
Test set avg_accuracy=77.42% avg_sensitivity=28.22%, avg_specificity=91.69% avg_auc=69.36%
Best model saved!! Metric=-59.316166477515324!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.525991 Test loss=0.630710 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5125107765197754
[5/24] Train loss=0.5565204620361328
[10/24] Train loss=0.5254240036010742
[15/24] Train loss=0.5093631148338318
[20/24] Train loss=0.5097615122795105
Test set avg_accuracy=76.52% avg_sensitivity=30.01%, avg_specificity=90.01% avg_auc=64.55%
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.516849 Test loss=0.637315 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5111567378044128
[5/24] Train loss=0.5128013491630554
[10/24] Train loss=0.5034510493278503
[15/24] Train loss=0.49861928820610046
[20/24] Train loss=0.5013001561164856
Test set avg_accuracy=66.68% avg_sensitivity=28.45%, avg_specificity=77.76% avg_auc=53.41%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.501917 Test loss=0.649881 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.48573756217956543
[5/24] Train loss=0.5074049234390259
[10/24] Train loss=0.4980178773403168
[15/24] Train loss=0.4939834475517273
[20/24] Train loss=0.49470674991607666
Test set avg_accuracy=68.42% avg_sensitivity=28.97%, avg_specificity=79.86% avg_auc=55.81%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.494566 Test loss=0.641399 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4804774820804596
[5/24] Train loss=0.5024724006652832
[10/24] Train loss=0.4924059808254242
[15/24] Train loss=0.4900070130825043
[20/24] Train loss=0.4869834780693054
Test set avg_accuracy=67.97% avg_sensitivity=37.02%, avg_specificity=76.94% avg_auc=58.73%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.489905 Test loss=0.639776 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.4831939935684204
[5/24] Train loss=0.5001680850982666
[10/24] Train loss=0.48651716113090515
[15/24] Train loss=0.4819974899291992
[20/24] Train loss=0.48293691873550415
Test set avg_accuracy=64.51% avg_sensitivity=45.48%, avg_specificity=70.02% avg_auc=60.42%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.485058 Test loss=0.645724 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.4697883725166321
[5/24] Train loss=0.505332350730896
[10/24] Train loss=0.48705947399139404
[15/24] Train loss=0.48362237215042114
[20/24] Train loss=0.47730880975723267
Test set avg_accuracy=65.44% avg_sensitivity=46.23%, avg_specificity=71.01% avg_auc=62.08%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.482001 Test loss=0.642139 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.48292070627212524
[5/24] Train loss=0.49595800042152405
[10/24] Train loss=0.47959622740745544
[15/24] Train loss=0.47520652413368225
[20/24] Train loss=0.4724547266960144
Test set avg_accuracy=64.00% avg_sensitivity=50.23%, avg_specificity=67.99% avg_auc=62.96%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.477720 Test loss=0.642883 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.46700912714004517
[5/24] Train loss=0.49038779735565186
[10/24] Train loss=0.4788386821746826
[15/24] Train loss=0.47648942470550537
[20/24] Train loss=0.468210369348526
Test set avg_accuracy=59.53% avg_sensitivity=54.11%, avg_specificity=61.10% avg_auc=61.99%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.473595 Test loss=0.657197 Current lr=[0.000210185142098938]

[0/24] Train loss=0.45763450860977173
[5/24] Train loss=0.4879266023635864
[10/24] Train loss=0.47336047887802124
[15/24] Train loss=0.4653879404067993
[20/24] Train loss=0.4594522714614868
Test set avg_accuracy=58.84% avg_sensitivity=59.79%, avg_specificity=58.57% avg_auc=63.22%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.467795 Test loss=0.657093 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.44569000601768494
[5/24] Train loss=0.4908313453197479
[10/24] Train loss=0.46839284896850586
[15/24] Train loss=0.4606649577617645
[20/24] Train loss=0.449921190738678
Test set avg_accuracy=66.84% avg_sensitivity=57.53%, avg_specificity=69.53% avg_auc=69.40%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.461075 Test loss=0.615622 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4361012279987335
[5/24] Train loss=0.4815593659877777
[10/24] Train loss=0.4636441767215729
[15/24] Train loss=0.44740429520606995
[20/24] Train loss=0.42692166566848755
Test set avg_accuracy=62.14% avg_sensitivity=67.21%, avg_specificity=60.67% avg_auc=70.90%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.447251 Test loss=0.624865 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.41698992252349854
[5/24] Train loss=0.4632195830345154
[10/24] Train loss=0.4489426910877228
[15/24] Train loss=0.4232736825942993
[20/24] Train loss=0.4036419689655304
Test set avg_accuracy=56.91% avg_sensitivity=70.86%, avg_specificity=52.87% avg_auc=68.82%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.433932 Test loss=0.644377 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.40340039134025574
[5/24] Train loss=0.4427058696746826
[10/24] Train loss=0.42041680216789246
[15/24] Train loss=0.4240759611129761
[20/24] Train loss=0.4027922451496124
Test set avg_accuracy=64.01% avg_sensitivity=72.13%, avg_specificity=61.66% avg_auc=73.88%
Best model saved!! Metric=-54.31697572871998!!
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.427453 Test loss=0.616775 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.42109230160713196
[5/24] Train loss=0.4373280107975006
[10/24] Train loss=0.4195098876953125
[15/24] Train loss=0.4113956689834595
[20/24] Train loss=0.3953789472579956
Test set avg_accuracy=63.28% avg_sensitivity=72.31%, avg_specificity=60.67% avg_auc=73.72%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.420870 Test loss=0.618103 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.39907920360565186
[5/24] Train loss=0.43512436747550964
[10/24] Train loss=0.40917128324508667
[15/24] Train loss=0.41541895270347595
[20/24] Train loss=0.3880154490470886
Test set avg_accuracy=67.64% avg_sensitivity=72.02%, avg_specificity=66.38% avg_auc=76.55%
Best model saved!! Metric=-43.41311824148492!!
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.414877 Test loss=0.589289 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.39795228838920593
[5/24] Train loss=0.4261398911476135
[10/24] Train loss=0.4060472846031189
[15/24] Train loss=0.41200563311576843
[20/24] Train loss=0.38432660698890686
Test set avg_accuracy=69.53% avg_sensitivity=72.94%, avg_specificity=68.54% avg_auc=77.92%
Best model saved!! Metric=-37.06402252388045!!
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.412506 Test loss=0.581912 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.389139324426651
[5/24] Train loss=0.41598621010780334
[10/24] Train loss=0.3995119333267212
[15/24] Train loss=0.4042139947414398
[20/24] Train loss=0.37702709436416626
Test set avg_accuracy=63.02% avg_sensitivity=76.59%, avg_specificity=59.09% avg_auc=75.06%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.403132 Test loss=0.637669 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3831966519355774
[5/24] Train loss=0.41525140404701233
[10/24] Train loss=0.3925640285015106
[15/24] Train loss=0.4048381745815277
[20/24] Train loss=0.38165298104286194
Test set avg_accuracy=67.90% avg_sensitivity=75.03%, avg_specificity=65.84% avg_auc=78.31%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.402813 Test loss=0.590739 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4058402478694916
[5/24] Train loss=0.41839614510536194
[10/24] Train loss=0.3975674510002136
[15/24] Train loss=0.41027817130088806
[20/24] Train loss=0.37770700454711914
Test set avg_accuracy=64.51% avg_sensitivity=75.67%, avg_specificity=61.27% avg_auc=75.84%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.408316 Test loss=0.619135 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.38661137223243713
[5/24] Train loss=0.41660910844802856
[10/24] Train loss=0.4101768732070923
[15/24] Train loss=0.4018799960613251
[20/24] Train loss=0.3791130483150482
Test set avg_accuracy=71.16% avg_sensitivity=68.66%, avg_specificity=71.88% avg_auc=77.93%
Best model saved!! Metric=-36.37235011054399!!
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.406453 Test loss=0.551792 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.38663309812545776
[5/24] Train loss=0.4121241569519043
[10/24] Train loss=0.3909371793270111
[15/24] Train loss=0.39804741740226746
[20/24] Train loss=0.38473594188690186
Test set avg_accuracy=63.23% avg_sensitivity=73.75%, avg_specificity=60.18% avg_auc=73.81%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.400937 Test loss=0.628859 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.39929917454719543
[5/24] Train loss=0.4222927987575531
[10/24] Train loss=0.3966776132583618
[15/24] Train loss=0.4105275571346283
[20/24] Train loss=0.37303677201271057
Test set avg_accuracy=69.22% avg_sensitivity=75.84%, avg_specificity=67.30% avg_auc=79.09%
Best model saved!! Metric=-34.55167396495963!!
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.407356 Test loss=0.591187 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4070054590702057
[5/24] Train loss=0.4252418875694275
[10/24] Train loss=0.39860397577285767
[15/24] Train loss=0.3986954987049103
[20/24] Train loss=0.37538251280784607
Test set avg_accuracy=66.15% avg_sensitivity=77.11%, avg_specificity=62.97% avg_auc=77.52%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.404206 Test loss=0.614258 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.38944679498672485
[5/24] Train loss=0.44729533791542053
[10/24] Train loss=0.4074784517288208
[15/24] Train loss=0.41055750846862793
[20/24] Train loss=0.37490543723106384
Test set avg_accuracy=71.90% avg_sensitivity=72.31%, avg_specificity=71.78% avg_auc=80.01%
Best model saved!! Metric=-29.99966444208289!!
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.409390 Test loss=0.559994 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3850365877151489
[5/24] Train loss=0.4112383723258972
[10/24] Train loss=0.3828246593475342
[15/24] Train loss=0.3968884348869324
[20/24] Train loss=0.3656228482723236
Test set avg_accuracy=68.97% avg_sensitivity=73.64%, avg_specificity=67.62% avg_auc=78.08%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.394742 Test loss=0.580412 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3760296702384949
[5/24] Train loss=0.40776777267456055
[10/24] Train loss=0.3780094087123871
[15/24] Train loss=0.38576892018318176
[20/24] Train loss=0.3703151345252991
Test set avg_accuracy=67.01% avg_sensitivity=70.39%, avg_specificity=66.02% avg_auc=75.62%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.391178 Test loss=0.589278 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.36996620893478394
[5/24] Train loss=0.41272953152656555
[10/24] Train loss=0.38137882947921753
[15/24] Train loss=0.385493665933609
[20/24] Train loss=0.36752915382385254
Test set avg_accuracy=65.64% avg_sensitivity=74.39%, avg_specificity=63.10% avg_auc=76.25%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.391119 Test loss=0.607402 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3909188508987427
[5/24] Train loss=0.4109632074832916
[10/24] Train loss=0.3761318027973175
[15/24] Train loss=0.38820207118988037
[20/24] Train loss=0.36515751481056213
Test set avg_accuracy=69.32% avg_sensitivity=71.21%, avg_specificity=68.78% avg_auc=77.61%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.390791 Test loss=0.567963 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.4051131010055542
[5/24] Train loss=0.42536333203315735
[10/24] Train loss=0.38203316926956177
[15/24] Train loss=0.41797855496406555
[20/24] Train loss=0.3644900321960449
Test set avg_accuracy=75.40% avg_sensitivity=69.29%, avg_specificity=77.18% avg_auc=81.45%
Best model saved!! Metric=-22.677165103820627!!
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.400624 Test loss=0.529710 Current lr=[0.000298904600941902]

[0/24] Train loss=0.39649710059165955
[5/24] Train loss=0.41412100195884705
[10/24] Train loss=0.37984180450439453
[15/24] Train loss=0.3888648748397827
[20/24] Train loss=0.3707939684391022
Test set avg_accuracy=68.95% avg_sensitivity=76.77%, avg_specificity=66.68% avg_auc=79.97%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.396962 Test loss=0.585240 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.39499396085739136
[5/24] Train loss=0.41788527369499207
[10/24] Train loss=0.3881632089614868
[15/24] Train loss=0.40122467279434204
[20/24] Train loss=0.3769151270389557
Test set avg_accuracy=70.66% avg_sensitivity=74.39%, avg_specificity=69.58% avg_auc=80.09%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.397713 Test loss=0.572105 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3810493052005768
[5/24] Train loss=0.41206204891204834
[10/24] Train loss=0.3845524787902832
[15/24] Train loss=0.4010179042816162
[20/24] Train loss=0.36649224162101746
Test set avg_accuracy=72.21% avg_sensitivity=70.16%, avg_specificity=72.81% avg_auc=79.46%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.393317 Test loss=0.545792 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3860126733779907
[5/24] Train loss=0.40589970350265503
[10/24] Train loss=0.3765876293182373
[15/24] Train loss=0.3979940414428711
[20/24] Train loss=0.37896278500556946
Test set avg_accuracy=71.93% avg_sensitivity=73.81%, avg_specificity=71.38% avg_auc=81.08%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.390259 Test loss=0.558355 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.375398725271225
[5/24] Train loss=0.40904223918914795
[10/24] Train loss=0.3909934163093567
[15/24] Train loss=0.40261557698249817
[20/24] Train loss=0.3659139573574066
Test set avg_accuracy=68.48% avg_sensitivity=77.64%, avg_specificity=65.82% avg_auc=80.62%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.393585 Test loss=0.584424 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3776990473270416
[5/24] Train loss=0.41038039326667786
[10/24] Train loss=0.3795902132987976
[15/24] Train loss=0.387942910194397
[20/24] Train loss=0.3699580729007721
Test set avg_accuracy=72.30% avg_sensitivity=70.45%, avg_specificity=72.84% avg_auc=80.10%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.392819 Test loss=0.543892 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.38363194465637207
[5/24] Train loss=0.40941089391708374
[10/24] Train loss=0.38490030169487
[15/24] Train loss=0.38834404945373535
[20/24] Train loss=0.3620593249797821
Test set avg_accuracy=71.67% avg_sensitivity=69.18%, avg_specificity=72.39% avg_auc=78.82%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.393619 Test loss=0.548464 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.37070614099502563
[5/24] Train loss=0.4162925183773041
[10/24] Train loss=0.39633655548095703
[15/24] Train loss=0.3883131146430969
[20/24] Train loss=0.3621731400489807
Test set avg_accuracy=74.53% avg_sensitivity=73.46%, avg_specificity=74.84% avg_auc=82.67%
Best model saved!! Metric=-20.497954589376008!!
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.396015 Test loss=0.535023 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.38269707560539246
[5/24] Train loss=0.4110245108604431
[10/24] Train loss=0.38252127170562744
[15/24] Train loss=0.3863455653190613
[20/24] Train loss=0.3643290102481842
Test set avg_accuracy=74.01% avg_sensitivity=71.55%, avg_specificity=74.72% avg_auc=81.67%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.393075 Test loss=0.540289 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.40330106019973755
[5/24] Train loss=0.41272130608558655
[10/24] Train loss=0.3823745846748352
[15/24] Train loss=0.3841645121574402
[20/24] Train loss=0.3611452281475067
Test set avg_accuracy=70.92% avg_sensitivity=73.12%, avg_specificity=70.29% avg_auc=80.42%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.390906 Test loss=0.556443 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.37409424781799316
[5/24] Train loss=0.40265801548957825
[10/24] Train loss=0.3765771687030792
[15/24] Train loss=0.38513562083244324
[20/24] Train loss=0.3654036223888397
Test set avg_accuracy=71.46% avg_sensitivity=72.07%, avg_specificity=71.28% avg_auc=79.95%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.387741 Test loss=0.551424 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3710364103317261
[5/24] Train loss=0.40113651752471924
[10/24] Train loss=0.3681400716304779
[15/24] Train loss=0.38614732027053833
[20/24] Train loss=0.3567602038383484
Test set avg_accuracy=76.26% avg_sensitivity=70.05%, avg_specificity=78.07% avg_auc=82.40%
Best model saved!! Metric=-19.227615372946488!!
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.384419 Test loss=0.510809 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3692878186702728
[5/24] Train loss=0.40234917402267456
[10/24] Train loss=0.37325701117515564
[15/24] Train loss=0.37757715582847595
[20/24] Train loss=0.3669900596141815
Test set avg_accuracy=69.19% avg_sensitivity=77.23%, avg_specificity=66.86% avg_auc=80.81%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.385754 Test loss=0.575508 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.36897096037864685
[5/24] Train loss=0.4029949903488159
[10/24] Train loss=0.37610742449760437
[15/24] Train loss=0.39261743426322937
[20/24] Train loss=0.36140191555023193
Test set avg_accuracy=76.41% avg_sensitivity=72.60%, avg_specificity=77.51% avg_auc=83.03%
Best model saved!! Metric=-16.455210264499826!!
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.385061 Test loss=0.516949 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.372697114944458
[5/24] Train loss=0.4003942608833313
[10/24] Train loss=0.3716076612472534
[15/24] Train loss=0.37956011295318604
[20/24] Train loss=0.35826119780540466
Test set avg_accuracy=72.89% avg_sensitivity=75.90%, avg_specificity=72.02% avg_auc=82.95%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.383526 Test loss=0.546744 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3623534142971039
[5/24] Train loss=0.4080512821674347
[10/24] Train loss=0.3854093551635742
[15/24] Train loss=0.37967780232429504
[20/24] Train loss=0.3628802001476288
Test set avg_accuracy=72.29% avg_sensitivity=73.64%, avg_specificity=71.90% avg_auc=81.01%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.393597 Test loss=0.549481 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.389589786529541
[5/24] Train loss=0.4016214609146118
[10/24] Train loss=0.3826253116130829
[15/24] Train loss=0.38270628452301025
[20/24] Train loss=0.36091187596321106
Test set avg_accuracy=75.53% avg_sensitivity=71.78%, avg_specificity=76.62% avg_auc=82.63%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.394082 Test loss=0.527613 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.37256306409835815
[5/24] Train loss=0.4034586250782013
[10/24] Train loss=0.3746508061885834
[15/24] Train loss=0.3817518949508667
[20/24] Train loss=0.3542150557041168
Test set avg_accuracy=69.74% avg_sensitivity=75.61%, avg_specificity=68.04% avg_auc=80.10%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.384125 Test loss=0.568574 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3608998656272888
[5/24] Train loss=0.39938077330589294
[10/24] Train loss=0.3696334660053253
[15/24] Train loss=0.3751021921634674
[20/24] Train loss=0.35683906078338623
Test set avg_accuracy=73.33% avg_sensitivity=74.39%, avg_specificity=73.03% avg_auc=82.46%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.382430 Test loss=0.537138 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3857496976852417
[5/24] Train loss=0.3897719383239746
[10/24] Train loss=0.3630516231060028
[15/24] Train loss=0.37413668632507324
[20/24] Train loss=0.35691240429878235
Test set avg_accuracy=71.42% avg_sensitivity=71.61%, avg_specificity=71.36% avg_auc=79.81%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.379112 Test loss=0.543421 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3718898296356201
[5/24] Train loss=0.40324366092681885
[10/24] Train loss=0.37684378027915955
[15/24] Train loss=0.387920081615448
[20/24] Train loss=0.35515668988227844
Test set avg_accuracy=74.49% avg_sensitivity=72.83%, avg_specificity=74.97% avg_auc=82.40%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.384071 Test loss=0.519934 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.37402454018592834
[5/24] Train loss=0.3932185471057892
[10/24] Train loss=0.3736734688282013
[15/24] Train loss=0.38055288791656494
[20/24] Train loss=0.35406994819641113
Test set avg_accuracy=75.21% avg_sensitivity=72.13%, avg_specificity=76.10% avg_auc=82.87%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.385827 Test loss=0.514845 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.36631667613983154
[5/24] Train loss=0.3989122211933136
[10/24] Train loss=0.3699660301208496
[15/24] Train loss=0.37548524141311646
[20/24] Train loss=0.3531363308429718
Test set avg_accuracy=69.99% avg_sensitivity=74.80%, avg_specificity=68.59% avg_auc=80.38%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.380033 Test loss=0.558452 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3641979396343231
[5/24] Train loss=0.39570352435112
[10/24] Train loss=0.3645551800727844
[15/24] Train loss=0.368171751499176
[20/24] Train loss=0.35205212235450745
Test set avg_accuracy=75.91% avg_sensitivity=71.15%, avg_specificity=77.29% avg_auc=82.81%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.381893 Test loss=0.512224 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3718357980251312
[5/24] Train loss=0.39871761202812195
[10/24] Train loss=0.37778544425964355
[15/24] Train loss=0.37507301568984985
[20/24] Train loss=0.35749438405036926
Test set avg_accuracy=69.51% avg_sensitivity=75.61%, avg_specificity=67.74% avg_auc=80.69%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.385739 Test loss=0.569676 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.36644768714904785
[5/24] Train loss=0.3984644114971161
[10/24] Train loss=0.37040573358535767
[15/24] Train loss=0.37180382013320923
[20/24] Train loss=0.3525729775428772
Test set avg_accuracy=70.44% avg_sensitivity=75.26%, avg_specificity=69.05% avg_auc=80.60%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.381605 Test loss=0.557585 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3607041835784912
[5/24] Train loss=0.3975401222705841
[10/24] Train loss=0.3745332956314087
[15/24] Train loss=0.3721614480018616
[20/24] Train loss=0.35147133469581604
Test set avg_accuracy=70.25% avg_sensitivity=75.09%, avg_specificity=68.84% avg_auc=80.47%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.377401 Test loss=0.559517 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3602568507194519
[5/24] Train loss=0.387815922498703
[10/24] Train loss=0.3668726682662964
[15/24] Train loss=0.3667042553424835
[20/24] Train loss=0.35515984892845154
Test set avg_accuracy=70.44% avg_sensitivity=76.13%, avg_specificity=68.79% avg_auc=81.22%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.373816 Test loss=0.557362 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.36383524537086487
[5/24] Train loss=0.38837212324142456
[10/24] Train loss=0.3706105947494507
[15/24] Train loss=0.37549126148223877
[20/24] Train loss=0.35069355368614197
Test set avg_accuracy=73.14% avg_sensitivity=72.36%, avg_specificity=73.36% avg_auc=81.58%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.378459 Test loss=0.526152 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.36404624581336975
[5/24] Train loss=0.3898570239543915
[10/24] Train loss=0.3639480471611023
[15/24] Train loss=0.367996484041214
[20/24] Train loss=0.34675490856170654
Test set avg_accuracy=70.99% avg_sensitivity=74.57%, avg_specificity=69.95% avg_auc=81.08%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.375900 Test loss=0.547581 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.3606795370578766
[5/24] Train loss=0.38617441058158875
[10/24] Train loss=0.3588666319847107
[15/24] Train loss=0.37260153889656067
[20/24] Train loss=0.3500658869743347
Test set avg_accuracy=71.95% avg_sensitivity=72.89%, avg_specificity=71.68% avg_auc=80.98%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.371523 Test loss=0.539275 Current lr=[0.000224838296036774]

[0/24] Train loss=0.36368149518966675
[5/24] Train loss=0.38080117106437683
[10/24] Train loss=0.3652731776237488
[15/24] Train loss=0.3656071424484253
[20/24] Train loss=0.346392959356308
Test set avg_accuracy=71.17% avg_sensitivity=75.43%, avg_specificity=69.94% avg_auc=81.08%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.372041 Test loss=0.550744 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.3518225848674774
[5/24] Train loss=0.3860487937927246
[10/24] Train loss=0.3575023114681244
[15/24] Train loss=0.36968448758125305
[20/24] Train loss=0.3484766185283661
Test set avg_accuracy=72.66% avg_sensitivity=72.02%, avg_specificity=72.84% avg_auc=81.10%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.369510 Test loss=0.527869 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.367693156003952
[5/24] Train loss=0.3857726752758026
[10/24] Train loss=0.3693813383579254
[15/24] Train loss=0.3667185306549072
[20/24] Train loss=0.3574092388153076
Test set avg_accuracy=74.10% avg_sensitivity=75.09%, avg_specificity=73.82% avg_auc=83.25%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.375178 Test loss=0.521964 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.37013062834739685
[5/24] Train loss=0.3887728750705719
[10/24] Train loss=0.37812262773513794
[15/24] Train loss=0.3762670159339905
[20/24] Train loss=0.34852492809295654
Test set avg_accuracy=71.71% avg_sensitivity=76.42%, avg_specificity=70.34% avg_auc=82.55%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.378018 Test loss=0.538264 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3620331287384033
[5/24] Train loss=0.38606950640678406
[10/24] Train loss=0.37004148960113525
[15/24] Train loss=0.36783358454704285
[20/24] Train loss=0.34760019183158875
Test set avg_accuracy=72.21% avg_sensitivity=68.71%, avg_specificity=73.23% avg_auc=79.53%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.375381 Test loss=0.525860 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.368887722492218
[5/24] Train loss=0.3862192928791046
[10/24] Train loss=0.3640376031398773
[15/24] Train loss=0.38727352023124695
[20/24] Train loss=0.34456518292427063
Test set avg_accuracy=71.33% avg_sensitivity=72.25%, avg_specificity=71.06% avg_auc=80.07%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.373834 Test loss=0.540636 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.35418373346328735
[5/24] Train loss=0.38291722536087036
[10/24] Train loss=0.3625028431415558
[15/24] Train loss=0.3664489686489105
[20/24] Train loss=0.34426549077033997
Test set avg_accuracy=68.97% avg_sensitivity=72.42%, avg_specificity=67.97% avg_auc=77.88%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.369608 Test loss=0.571690 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.35450634360313416
[5/24] Train loss=0.39093607664108276
[10/24] Train loss=0.3639637529850006
[15/24] Train loss=0.3657374382019043
[20/24] Train loss=0.347419798374176
Test set avg_accuracy=68.85% avg_sensitivity=73.93%, avg_specificity=67.38% avg_auc=78.64%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.370366 Test loss=0.574539 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.35423773527145386
[5/24] Train loss=0.38247498869895935
[10/24] Train loss=0.36884766817092896
[15/24] Train loss=0.36804062128067017
[20/24] Train loss=0.3428233563899994
Test set avg_accuracy=71.80% avg_sensitivity=73.41%, avg_specificity=71.33% avg_auc=81.29%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.370634 Test loss=0.534326 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.3533206582069397
[5/24] Train loss=0.3804110288619995
[10/24] Train loss=0.3621355891227722
[15/24] Train loss=0.3778165876865387
[20/24] Train loss=0.34239324927330017
Test set avg_accuracy=71.00% avg_sensitivity=74.45%, avg_specificity=70.00% avg_auc=80.91%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.366901 Test loss=0.546738 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.3523271083831787
[5/24] Train loss=0.3799189329147339
[10/24] Train loss=0.36285561323165894
[15/24] Train loss=0.36808085441589355
[20/24] Train loss=0.34366539120674133
Test set avg_accuracy=68.71% avg_sensitivity=76.65%, avg_specificity=66.41% avg_auc=80.46%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.366518 Test loss=0.570854 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.35043320059776306
[5/24] Train loss=0.3787095546722412
[10/24] Train loss=0.3611929416656494
[15/24] Train loss=0.36313605308532715
[20/24] Train loss=0.3431350588798523
Test set avg_accuracy=72.76% avg_sensitivity=72.89%, avg_specificity=72.72% avg_auc=81.56%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.369781 Test loss=0.529650 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.3613549768924713
[5/24] Train loss=0.3840924799442291
[10/24] Train loss=0.38539373874664307
[15/24] Train loss=0.3684280812740326
[20/24] Train loss=0.3485146462917328
Test set avg_accuracy=73.14% avg_sensitivity=73.46%, avg_specificity=73.04% avg_auc=81.79%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.378901 Test loss=0.532831 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.35579216480255127
[5/24] Train loss=0.3852224051952362
[10/24] Train loss=0.37789589166641235
[15/24] Train loss=0.37965986132621765
[20/24] Train loss=0.3467152416706085
Test set avg_accuracy=72.89% avg_sensitivity=73.81%, avg_specificity=72.62% avg_auc=81.69%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.376243 Test loss=0.537306 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.3766040503978729
[5/24] Train loss=0.3859151303768158
[10/24] Train loss=0.3725987374782562
[15/24] Train loss=0.3726707398891449
[20/24] Train loss=0.3559000492095947
Test set avg_accuracy=75.55% avg_sensitivity=72.71%, avg_specificity=76.37% avg_auc=83.17%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.379749 Test loss=0.506445 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.36477699875831604
[5/24] Train loss=0.4007068872451782
[10/24] Train loss=0.37722304463386536
[15/24] Train loss=0.36809614300727844
[20/24] Train loss=0.3523799479007721
Test set avg_accuracy=70.20% avg_sensitivity=71.90%, avg_specificity=69.70% avg_auc=78.63%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.376751 Test loss=0.561952 Current lr=[0.000156543481933168]

[0/24] Train loss=0.36147743463516235
[5/24] Train loss=0.3915560245513916
[10/24] Train loss=0.3710290491580963
[15/24] Train loss=0.3720192015171051
[20/24] Train loss=0.3427305519580841
Test set avg_accuracy=71.95% avg_sensitivity=69.47%, avg_specificity=72.67% avg_auc=78.92%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.372091 Test loss=0.537779 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.3566470146179199
[5/24] Train loss=0.37965211272239685
[10/24] Train loss=0.3702625334262848
[15/24] Train loss=0.36116713285446167
[20/24] Train loss=0.35437875986099243
Test set avg_accuracy=73.16% avg_sensitivity=74.68%, avg_specificity=72.72% avg_auc=82.37%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.372214 Test loss=0.534175 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.3555148243904114
[5/24] Train loss=0.37644872069358826
[10/24] Train loss=0.36316946148872375
[15/24] Train loss=0.36517569422721863
[20/24] Train loss=0.3423781394958496
Test set avg_accuracy=70.62% avg_sensitivity=70.39%, avg_specificity=70.69% avg_auc=78.65%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.368815 Test loss=0.551851 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.36177146434783936
[5/24] Train loss=0.38629215955734253
[10/24] Train loss=0.375974178314209
[15/24] Train loss=0.3654402494430542
[20/24] Train loss=0.3560340404510498
Test set avg_accuracy=76.94% avg_sensitivity=71.78%, avg_specificity=78.43% avg_auc=83.69%
Best model saved!! Metric=-15.14739905910713!!
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.373509 Test loss=0.496255 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.35864269733428955
[5/24] Train loss=0.38231268525123596
[10/24] Train loss=0.36717888712882996
[15/24] Train loss=0.36256253719329834
[20/24] Train loss=0.3420158624649048
Test set avg_accuracy=71.15% avg_sensitivity=72.65%, avg_specificity=70.71% avg_auc=80.11%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.367884 Test loss=0.546388 Current lr=[0.000134135431043539]

[0/24] Train loss=0.35347986221313477
[5/24] Train loss=0.37589478492736816
[10/24] Train loss=0.36412808299064636
[15/24] Train loss=0.3730587065219879
[20/24] Train loss=0.34781724214553833
Test set avg_accuracy=81.37% avg_sensitivity=60.60%, avg_specificity=87.39% avg_auc=84.14%
Best model saved!! Metric=-12.508250728426432!!
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.374915 Test loss=0.449201 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.3620854914188385
[5/24] Train loss=0.37884265184402466
[10/24] Train loss=0.3711257874965668
[15/24] Train loss=0.36874714493751526
[20/24] Train loss=0.3446027934551239
Test set avg_accuracy=74.64% avg_sensitivity=69.93%, avg_specificity=76.00% avg_auc=82.01%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.370378 Test loss=0.510980 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.36014142632484436
[5/24] Train loss=0.3836148679256439
[10/24] Train loss=0.3641933500766754
[15/24] Train loss=0.36140990257263184
[20/24] Train loss=0.3418169319629669
Test set avg_accuracy=70.62% avg_sensitivity=69.64%, avg_specificity=70.91% avg_auc=78.16%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.367287 Test loss=0.552578 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.35741010308265686
[5/24] Train loss=0.37577784061431885
[10/24] Train loss=0.369549423456192
[15/24] Train loss=0.361604779958725
[20/24] Train loss=0.3485359251499176
Test set avg_accuracy=71.74% avg_sensitivity=72.13%, avg_specificity=71.63% avg_auc=80.31%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.366788 Test loss=0.539423 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.3578151762485504
[5/24] Train loss=0.3731657564640045
[10/24] Train loss=0.36435770988464355
[15/24] Train loss=0.35866594314575195
[20/24] Train loss=0.3419172167778015
Test set avg_accuracy=71.04% avg_sensitivity=70.51%, avg_specificity=71.20% avg_auc=79.24%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.362328 Test loss=0.543864 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.3521447777748108
[5/24] Train loss=0.37317758798599243
[10/24] Train loss=0.36161401867866516
[15/24] Train loss=0.35706382989883423
[20/24] Train loss=0.343176931142807
Test set avg_accuracy=71.94% avg_sensitivity=71.84%, avg_specificity=71.97% avg_auc=80.46%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.358764 Test loss=0.536141 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.3513364791870117
[5/24] Train loss=0.3733827769756317
[10/24] Train loss=0.36291441321372986
[15/24] Train loss=0.35419943928718567
[20/24] Train loss=0.3425637185573578
Test set avg_accuracy=71.60% avg_sensitivity=70.74%, avg_specificity=71.85% avg_auc=79.39%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.358134 Test loss=0.540343 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.3487296402454376
[5/24] Train loss=0.3710765838623047
[10/24] Train loss=0.3609095811843872
[15/24] Train loss=0.35254544019699097
[20/24] Train loss=0.3412299156188965
Test set avg_accuracy=70.87% avg_sensitivity=71.84%, avg_specificity=70.59% avg_auc=79.74%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.356347 Test loss=0.547582 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.34676864743232727
[5/24] Train loss=0.3709700405597687
[10/24] Train loss=0.3592268228530884
[15/24] Train loss=0.3513561189174652
[20/24] Train loss=0.33916887640953064
Test set avg_accuracy=71.56% avg_sensitivity=70.63%, avg_specificity=71.83% avg_auc=79.34%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.355545 Test loss=0.540111 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.34567415714263916
[5/24] Train loss=0.37005114555358887
[10/24] Train loss=0.36069366335868835
[15/24] Train loss=0.35015639662742615
[20/24] Train loss=0.338299036026001
Test set avg_accuracy=72.07% avg_sensitivity=71.09%, avg_specificity=72.35% avg_auc=79.98%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.354401 Test loss=0.534608 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.3457004129886627
[5/24] Train loss=0.37002190947532654
[10/24] Train loss=0.35799917578697205
[15/24] Train loss=0.3495108187198639
[20/24] Train loss=0.3376433849334717
Test set avg_accuracy=71.91% avg_sensitivity=71.15%, avg_specificity=72.14% avg_auc=79.76%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.353374 Test loss=0.537229 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.34459975361824036
[5/24] Train loss=0.367784708738327
[10/24] Train loss=0.3592228889465332
[15/24] Train loss=0.348495751619339
[20/24] Train loss=0.3364483118057251
Test set avg_accuracy=71.77% avg_sensitivity=70.86%, avg_specificity=72.04% avg_auc=79.89%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.352271 Test loss=0.537323 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.3449566662311554
[5/24] Train loss=0.3696131408214569
[10/24] Train loss=0.35950735211372375
[15/24] Train loss=0.3486451506614685
[20/24] Train loss=0.3345296382904053
Test set avg_accuracy=71.72% avg_sensitivity=69.00%, avg_specificity=72.51% avg_auc=78.70%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.351952 Test loss=0.537238 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.3462410569190979
[5/24] Train loss=0.36868369579315186
[10/24] Train loss=0.36090630292892456
[15/24] Train loss=0.3474108576774597
[20/24] Train loss=0.3368728756904602
Test set avg_accuracy=71.85% avg_sensitivity=69.52%, avg_specificity=72.52% avg_auc=78.92%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.351605 Test loss=0.536965 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.3462231457233429
[5/24] Train loss=0.3688448965549469
[10/24] Train loss=0.3586977422237396
[15/24] Train loss=0.34816378355026245
[20/24] Train loss=0.33366522192955017
Test set avg_accuracy=71.77% avg_sensitivity=70.34%, avg_specificity=72.19% avg_auc=79.57%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.350870 Test loss=0.536433 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.34258031845092773
[5/24] Train loss=0.37014541029930115
[10/24] Train loss=0.358100950717926
[15/24] Train loss=0.3478032350540161
[20/24] Train loss=0.33356910943984985
Test set avg_accuracy=71.50% avg_sensitivity=69.99%, avg_specificity=71.93% avg_auc=78.98%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.350607 Test loss=0.540282 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.34237241744995117
[5/24] Train loss=0.36827507615089417
[10/24] Train loss=0.3588632047176361
[15/24] Train loss=0.34690722823143005
[20/24] Train loss=0.33125439286231995
Test set avg_accuracy=71.81% avg_sensitivity=70.74%, avg_specificity=72.12% avg_auc=79.82%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.349473 Test loss=0.536026 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.34082117676734924
[5/24] Train loss=0.369051069021225
[10/24] Train loss=0.3564169108867645
[15/24] Train loss=0.34754595160484314
[20/24] Train loss=0.33034446835517883
Test set avg_accuracy=71.24% avg_sensitivity=69.70%, avg_specificity=71.68% avg_auc=78.68%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.349186 Test loss=0.542366 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.34007954597473145
[5/24] Train loss=0.36900439858436584
[10/24] Train loss=0.35704106092453003
[15/24] Train loss=0.34668445587158203
[20/24] Train loss=0.33023861050605774
Test set avg_accuracy=71.18% avg_sensitivity=70.05%, avg_specificity=71.51% avg_auc=78.98%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.348721 Test loss=0.543669 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.3404400050640106
[5/24] Train loss=0.36650964617729187
[10/24] Train loss=0.35467755794525146
[15/24] Train loss=0.34630122780799866
[20/24] Train loss=0.32915401458740234
Test set avg_accuracy=70.38% avg_sensitivity=70.28%, avg_specificity=70.41% avg_auc=78.28%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.347593 Test loss=0.556633 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.338819682598114
[5/24] Train loss=0.3647715449333191
[10/24] Train loss=0.3536198139190674
[15/24] Train loss=0.34577834606170654
[20/24] Train loss=0.32839253544807434
Test set avg_accuracy=70.57% avg_sensitivity=70.10%, avg_specificity=70.71% avg_auc=78.38%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.347015 Test loss=0.553401 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.33900028467178345
[5/24] Train loss=0.3654584586620331
[10/24] Train loss=0.3545941710472107
[15/24] Train loss=0.3458881974220276
[20/24] Train loss=0.329147607088089
Test set avg_accuracy=70.40% avg_sensitivity=71.44%, avg_specificity=70.10% avg_auc=79.03%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.346893 Test loss=0.554851 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.3402343690395355
[5/24] Train loss=0.3636072278022766
[10/24] Train loss=0.3556691110134125
[15/24] Train loss=0.3449798822402954
[20/24] Train loss=0.32894739508628845
Test set avg_accuracy=70.21% avg_sensitivity=71.44%, avg_specificity=69.85% avg_auc=78.67%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.346767 Test loss=0.558924 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.3379935324192047
[5/24] Train loss=0.36254629492759705
[10/24] Train loss=0.3543798327445984
[15/24] Train loss=0.34488895535469055
[20/24] Train loss=0.32715296745300293
Test set avg_accuracy=70.70% avg_sensitivity=70.39%, avg_specificity=70.79% avg_auc=78.62%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.346172 Test loss=0.552386 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.3371872305870056
[5/24] Train loss=0.36300820112228394
[10/24] Train loss=0.35387951135635376
[15/24] Train loss=0.34575244784355164
[20/24] Train loss=0.32603931427001953
Test set avg_accuracy=70.21% avg_sensitivity=70.45%, avg_specificity=70.14% avg_auc=78.02%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.345397 Test loss=0.560943 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.337167888879776
[5/24] Train loss=0.36182811856269836
[10/24] Train loss=0.3528067171573639
[15/24] Train loss=0.3440054655075073
[20/24] Train loss=0.3260977566242218
Test set avg_accuracy=70.01% avg_sensitivity=71.03%, avg_specificity=69.72% avg_auc=78.44%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.344313 Test loss=0.560484 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.33780673146247864
[5/24] Train loss=0.36100783944129944
[10/24] Train loss=0.3531828224658966
[15/24] Train loss=0.3426049053668976
[20/24] Train loss=0.3259240686893463
Test set avg_accuracy=70.12% avg_sensitivity=71.84%, avg_specificity=69.62% avg_auc=79.01%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.344082 Test loss=0.558642 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.3362208902835846
[5/24] Train loss=0.35972145199775696
[10/24] Train loss=0.35255590081214905
[15/24] Train loss=0.3425452411174774
[20/24] Train loss=0.3254968523979187
Test set avg_accuracy=70.39% avg_sensitivity=70.80%, avg_specificity=70.27% avg_auc=78.43%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.343723 Test loss=0.557800 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.33650797605514526
[5/24] Train loss=0.3591998815536499
[10/24] Train loss=0.35267379879951477
[15/24] Train loss=0.34197720885276794
[20/24] Train loss=0.3247385323047638
Test set avg_accuracy=69.61% avg_sensitivity=71.44%, avg_specificity=69.08% avg_auc=78.49%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.343156 Test loss=0.564286 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.3354666531085968
[5/24] Train loss=0.36067304015159607
[10/24] Train loss=0.351553350687027
[15/24] Train loss=0.3418225646018982
[20/24] Train loss=0.3261612057685852
Test set avg_accuracy=70.31% avg_sensitivity=70.92%, avg_specificity=70.14% avg_auc=78.28%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.343430 Test loss=0.560192 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.3353790044784546
[5/24] Train loss=0.3588865399360657
[10/24] Train loss=0.3520876169204712
[15/24] Train loss=0.3426792025566101
[20/24] Train loss=0.32402440905570984
Test set avg_accuracy=69.54% avg_sensitivity=71.90%, avg_specificity=68.86% avg_auc=78.92%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.342763 Test loss=0.562975 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.33463263511657715
[5/24] Train loss=0.35911262035369873
[10/24] Train loss=0.35183706879615784
[15/24] Train loss=0.34209948778152466
[20/24] Train loss=0.32551175355911255
Test set avg_accuracy=69.84% avg_sensitivity=71.55%, avg_specificity=69.35% avg_auc=78.71%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.342604 Test loss=0.561608 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.33544909954071045
[5/24] Train loss=0.359220415353775
[10/24] Train loss=0.3515383005142212
[15/24] Train loss=0.3422401547431946
[20/24] Train loss=0.32481563091278076
Test set avg_accuracy=69.41% avg_sensitivity=71.61%, avg_specificity=68.78% avg_auc=78.22%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.342628 Test loss=0.568697 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.33368316292762756
[5/24] Train loss=0.3577978014945984
[10/24] Train loss=0.3518044352531433
[15/24] Train loss=0.3426022529602051
[20/24] Train loss=0.324201762676239
Test set avg_accuracy=69.79% avg_sensitivity=71.61%, avg_specificity=69.26% avg_auc=78.83%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.342134 Test loss=0.561680 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.3333917558193207
[5/24] Train loss=0.358120858669281
[10/24] Train loss=0.35226088762283325
[15/24] Train loss=0.3412056565284729
[20/24] Train loss=0.32426413893699646
Test set avg_accuracy=69.24% avg_sensitivity=72.07%, avg_specificity=68.42% avg_auc=78.57%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.341966 Test loss=0.567168 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.333310604095459
[5/24] Train loss=0.356299489736557
[10/24] Train loss=0.3530488610267639
[15/24] Train loss=0.3399278223514557
[20/24] Train loss=0.3230911195278168
Test set avg_accuracy=69.36% avg_sensitivity=72.19%, avg_specificity=68.54% avg_auc=78.66%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.341307 Test loss=0.565471 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.33336612582206726
[5/24] Train loss=0.356494665145874
[10/24] Train loss=0.351436972618103
[15/24] Train loss=0.33977293968200684
[20/24] Train loss=0.3224354386329651
Test set avg_accuracy=69.26% avg_sensitivity=71.38%, avg_specificity=68.64% avg_auc=78.26%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.340657 Test loss=0.568217 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.3326289653778076
[5/24] Train loss=0.3554099500179291
[10/24] Train loss=0.35009852051734924
[15/24] Train loss=0.33962059020996094
[20/24] Train loss=0.3222334086894989
Test set avg_accuracy=69.15% avg_sensitivity=71.61%, avg_specificity=68.44% avg_auc=78.24%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.340071 Test loss=0.569180 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.33199381828308105
[5/24] Train loss=0.35499948263168335
[10/24] Train loss=0.35024192929267883
[15/24] Train loss=0.3394806683063507
[20/24] Train loss=0.32190611958503723
Test set avg_accuracy=69.17% avg_sensitivity=71.84%, avg_specificity=68.39% avg_auc=78.38%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.339807 Test loss=0.568721 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.33197957277297974
[5/24] Train loss=0.3542606234550476
[10/24] Train loss=0.35011962056159973
[15/24] Train loss=0.33915507793426514
[20/24] Train loss=0.3217111825942993
Test set avg_accuracy=69.05% avg_sensitivity=71.96%, avg_specificity=68.21% avg_auc=78.24%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.339612 Test loss=0.570511 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.3318532407283783
[5/24] Train loss=0.3540785312652588
[10/24] Train loss=0.34987011551856995
[15/24] Train loss=0.3389771282672882
[20/24] Train loss=0.3215189278125763
Test set avg_accuracy=69.04% avg_sensitivity=71.96%, avg_specificity=68.19% avg_auc=78.20%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.339437 Test loss=0.570836 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.33172428607940674
[5/24] Train loss=0.35393109917640686
[10/24] Train loss=0.34980857372283936
[15/24] Train loss=0.3388512432575226
[20/24] Train loss=0.32138487696647644
Test set avg_accuracy=68.95% avg_sensitivity=71.96%, avg_specificity=68.07% avg_auc=78.16%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.339330 Test loss=0.571540 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.33162984251976013
[5/24] Train loss=0.35371142625808716
[10/24] Train loss=0.349716454744339
[15/24] Train loss=0.33875706791877747
[20/24] Train loss=0.32129448652267456
Test set avg_accuracy=68.93% avg_sensitivity=71.96%, avg_specificity=68.06% avg_auc=78.14%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.339233 Test loss=0.571956 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.33153969049453735
[5/24] Train loss=0.35358983278274536
[10/24] Train loss=0.3496567904949188
[15/24] Train loss=0.33868342638015747
[20/24] Train loss=0.3212263882160187
Test set avg_accuracy=68.92% avg_sensitivity=71.96%, avg_specificity=68.04% avg_auc=78.12%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.339161 Test loss=0.572324 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.331477552652359
[5/24] Train loss=0.3534992039203644
[10/24] Train loss=0.34960639476776123
[15/24] Train loss=0.33862897753715515
[20/24] Train loss=0.32117438316345215
Test set avg_accuracy=68.92% avg_sensitivity=71.96%, avg_specificity=68.04% avg_auc=78.11%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.339108 Test loss=0.572520 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.3314354717731476
[5/24] Train loss=0.35343846678733826
[10/24] Train loss=0.3495664894580841
[15/24] Train loss=0.33859285712242126
[20/24] Train loss=0.3211405575275421
Test set avg_accuracy=68.89% avg_sensitivity=71.96%, avg_specificity=68.00% avg_auc=78.11%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.339071 Test loss=0.572654 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.3314087986946106
[5/24] Train loss=0.35339540243148804
[10/24] Train loss=0.3495405912399292
[15/24] Train loss=0.3385714888572693
[20/24] Train loss=0.3211204409599304
Test set avg_accuracy=68.91% avg_sensitivity=72.02%, avg_specificity=68.00% avg_auc=78.10%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.339047 Test loss=0.572742 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.3313940167427063
[5/24] Train loss=0.35336583852767944
[10/24] Train loss=0.3495251536369324
[15/24] Train loss=0.33856114745140076
[20/24] Train loss=0.32111117243766785
Test set avg_accuracy=68.91% avg_sensitivity=72.02%, avg_specificity=68.00% avg_auc=78.10%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.339035 Test loss=0.572791 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.3313871920108795
[5/24] Train loss=0.3533514142036438
[10/24] Train loss=0.3495177626609802
[15/24] Train loss=0.3385573923587799
[20/24] Train loss=0.32110852003097534
Test set avg_accuracy=68.91% avg_sensitivity=72.02%, avg_specificity=68.00% avg_auc=78.10%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.339030 Test loss=0.572804 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=81.37% sen=60.60%, spe=87.39%, auc=84.14%!
Fold[10] Avg_overlap=0.04%(±0.10026552928344729)
Final Avg Result: avg_acc=75.42%(±4.1106358158878935) avg_sen=61.80% (±10.105279311366564) avg_spe=80.16% (±6.452174781884258) avg_auc=79.02% (±5.2101827350571535) avg_overlap=0.27% (±0.1973107908135448)
