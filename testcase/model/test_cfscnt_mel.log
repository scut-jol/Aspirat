[0/24] Train loss=0.7261266112327576
[5/24] Train loss=0.7234041094779968
[10/24] Train loss=0.7238667011260986
[15/24] Train loss=0.7230779528617859
[20/24] Train loss=0.7200233936309814
Test set avg_accuracy=60.31% avg_sensitivity=26.62%, avg_specificity=72.34% avg_auc=49.87%
Best model saved!! Metric=-116.84985351393861!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=0.720369 Test loss=0.686527 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7172257900238037
[5/24] Train loss=0.7129748463630676
[10/24] Train loss=0.7164663076400757
[15/24] Train loss=0.7205025553703308
[20/24] Train loss=0.714417040348053
Test set avg_accuracy=60.55% avg_sensitivity=29.14%, avg_specificity=71.76% avg_auc=50.83%
Best model saved!! Metric=-113.71445402631574!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.711224 Test loss=0.681713 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7123114466667175
[5/24] Train loss=0.7088707089424133
[10/24] Train loss=0.7050302028656006
[15/24] Train loss=0.7029906511306763
[20/24] Train loss=0.6989706754684448
Test set avg_accuracy=55.04% avg_sensitivity=41.71%, avg_specificity=59.80% avg_auc=51.29%
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.703958 Test loss=0.687903 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6933000087738037
[5/24] Train loss=0.6933319568634033
[10/24] Train loss=0.6918073296546936
[15/24] Train loss=0.6903787851333618
[20/24] Train loss=0.6959192156791687
Test set avg_accuracy=55.14% avg_sensitivity=42.16%, avg_specificity=59.78% avg_auc=51.47%
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.693976 Test loss=0.685293 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6879900693893433
[5/24] Train loss=0.6804454326629639
[10/24] Train loss=0.681821882724762
[15/24] Train loss=0.6872118711471558
[20/24] Train loss=0.6811677813529968
Test set avg_accuracy=55.27% avg_sensitivity=41.51%, avg_specificity=60.19% avg_auc=51.72%
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.685314 Test loss=0.679691 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6758971214294434
[5/24] Train loss=0.6753523349761963
[10/24] Train loss=0.6689574718475342
[15/24] Train loss=0.6792348027229309
[20/24] Train loss=0.678425133228302
Test set avg_accuracy=57.93% avg_sensitivity=36.12%, avg_specificity=65.72% avg_auc=52.07%
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.676449 Test loss=0.673228 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6730068325996399
[5/24] Train loss=0.6693280935287476
[10/24] Train loss=0.6649273037910461
[15/24] Train loss=0.6739402413368225
[20/24] Train loss=0.6649821400642395
Test set avg_accuracy=57.96% avg_sensitivity=35.92%, avg_specificity=65.82% avg_auc=52.73%
Best model saved!! Metric=-113.5667399351542!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.668342 Test loss=0.666669 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6595680713653564
[5/24] Train loss=0.6503834128379822
[10/24] Train loss=0.6517806649208069
[15/24] Train loss=0.6672901511192322
[20/24] Train loss=0.6483879685401917
Test set avg_accuracy=58.16% avg_sensitivity=35.82%, avg_specificity=66.14% avg_auc=52.83%
Best model saved!! Metric=-113.04062648792754!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.654472 Test loss=0.668487 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6405577063560486
[5/24] Train loss=0.6407541632652283
[10/24] Train loss=0.6438804864883423
[15/24] Train loss=0.6457875967025757
[20/24] Train loss=0.6438664197921753
Test set avg_accuracy=58.52% avg_sensitivity=35.72%, avg_specificity=66.65% avg_auc=53.27%
Best model saved!! Metric=-111.83838750293022!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.643188 Test loss=0.655455 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6351654529571533
[5/24] Train loss=0.6297897696495056
[10/24] Train loss=0.6228100061416626
[15/24] Train loss=0.6432881951332092
[20/24] Train loss=0.6337710618972778
Test set avg_accuracy=61.22% avg_sensitivity=31.27%, avg_specificity=71.92% avg_auc=53.79%
Best model saved!! Metric=-107.79682739251277!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.632515 Test loss=0.652070 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.623431921005249
[5/24] Train loss=0.6129611134529114
[10/24] Train loss=0.6267575621604919
[15/24] Train loss=0.6387497186660767
[20/24] Train loss=0.618492603302002
Test set avg_accuracy=61.55% avg_sensitivity=31.12%, avg_specificity=72.42% avg_auc=54.51%
Best model saved!! Metric=-106.40306121621362!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.622498 Test loss=0.641077 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6116442680358887
[5/24] Train loss=0.5965407490730286
[10/24] Train loss=0.6132712960243225
[15/24] Train loss=0.6222641468048096
[20/24] Train loss=0.610549807548523
Test set avg_accuracy=69.77% avg_sensitivity=15.19%, avg_specificity=89.26% avg_auc=56.07%
Best model saved!! Metric=-95.7199400236923!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.610028 Test loss=0.615578 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5970006585121155
[5/24] Train loss=0.5891494154930115
[10/24] Train loss=0.594707727432251
[15/24] Train loss=0.6122421622276306
[20/24] Train loss=0.5982965230941772
Test set avg_accuracy=73.05% avg_sensitivity=11.78%, avg_specificity=94.93% avg_auc=57.81%
Best model saved!! Metric=-88.43485644694962!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.597846 Test loss=0.605280 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5836427807807922
[5/24] Train loss=0.5744839906692505
[10/24] Train loss=0.5919439792633057
[15/24] Train loss=0.6072021722793579
[20/24] Train loss=0.5696070790290833
Test set avg_accuracy=73.36% avg_sensitivity=11.88%, avg_specificity=95.32% avg_auc=61.01%
Best model saved!! Metric=-84.43691504133047!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.585472 Test loss=0.567417 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5689182281494141
[5/24] Train loss=0.5633761882781982
[10/24] Train loss=0.5661067962646484
[15/24] Train loss=0.5824280381202698
[20/24] Train loss=0.5441476106643677
Test set avg_accuracy=73.20% avg_sensitivity=14.35%, avg_specificity=94.22% avg_auc=63.04%
Best model saved!! Metric=-81.18125638370226!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.563999 Test loss=0.594117 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5232670903205872
[5/24] Train loss=0.5344239473342896
[10/24] Train loss=0.525112509727478
[15/24] Train loss=0.5548734068870544
[20/24] Train loss=0.4936656653881073
Test set avg_accuracy=73.37% avg_sensitivity=18.16%, avg_specificity=93.09% avg_auc=62.95%
Best model saved!! Metric=-78.42418135027481!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.524819 Test loss=0.673727 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4704350531101227
[5/24] Train loss=0.5005024075508118
[10/24] Train loss=0.49903610348701477
[15/24] Train loss=0.5334985256195068
[20/24] Train loss=0.456142395734787
Test set avg_accuracy=73.79% avg_sensitivity=20.39%, avg_specificity=92.86% avg_auc=66.77%
Best model saved!! Metric=-72.19190426887731!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.498878 Test loss=0.646707 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4491986334323883
[5/24] Train loss=0.469250351190567
[10/24] Train loss=0.4735760986804962
[15/24] Train loss=0.49511805176734924
[20/24] Train loss=0.43970420956611633
Test set avg_accuracy=78.14% avg_sensitivity=44.58%, avg_specificity=90.12% avg_auc=79.66%
Best model saved!! Metric=-33.4998376693526!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.470104 Test loss=0.464102 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4267909824848175
[5/24] Train loss=0.4484695792198181
[10/24] Train loss=0.44547006487846375
[15/24] Train loss=0.4811694324016571
[20/24] Train loss=0.4075767993927002
Test set avg_accuracy=71.02% avg_sensitivity=65.46%, avg_specificity=73.00% avg_auc=76.20%
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.446222 Test loss=0.560040 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.41473302245140076
[5/24] Train loss=0.42864373326301575
[10/24] Train loss=0.4382918179035187
[15/24] Train loss=0.47154417634010315
[20/24] Train loss=0.3972553312778473
Test set avg_accuracy=59.44% avg_sensitivity=65.31%, avg_specificity=57.34% avg_auc=65.31%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.433412 Test loss=0.668817 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3979358673095703
[5/24] Train loss=0.41890254616737366
[10/24] Train loss=0.4344041645526886
[15/24] Train loss=0.4763270318508148
[20/24] Train loss=0.38857609033584595
Test set avg_accuracy=69.24% avg_sensitivity=69.57%, avg_specificity=69.13% avg_auc=75.68%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.429958 Test loss=0.597881 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.39729854464530945
[5/24] Train loss=0.41469335556030273
[10/24] Train loss=0.42184585332870483
[15/24] Train loss=0.4702301621437073
[20/24] Train loss=0.3886447548866272
Test set avg_accuracy=65.83% avg_sensitivity=68.04%, avg_specificity=65.05% avg_auc=71.48%
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.420856 Test loss=0.635635 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.38760116696357727
[5/24] Train loss=0.41614702343940735
[10/24] Train loss=0.414791077375412
[15/24] Train loss=0.46436578035354614
[20/24] Train loss=0.38309863209724426
Test set avg_accuracy=78.01% avg_sensitivity=60.66%, avg_specificity=84.20% avg_auc=79.32%
Best model saved!! Metric=-23.807349364217906!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.415973 Test loss=0.535347 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.39257171750068665
[5/24] Train loss=0.3992823660373688
[10/24] Train loss=0.40537312626838684
[15/24] Train loss=0.45814746618270874
[20/24] Train loss=0.38142383098602295
Test set avg_accuracy=70.30% avg_sensitivity=63.63%, avg_specificity=72.68% avg_auc=72.95%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.407281 Test loss=0.618787 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3731082081794739
[5/24] Train loss=0.40341314673423767
[10/24] Train loss=0.40426623821258545
[15/24] Train loss=0.4556470513343811
[20/24] Train loss=0.36768224835395813
Test set avg_accuracy=57.33% avg_sensitivity=58.93%, avg_specificity=56.76% avg_auc=64.45%
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.404537 Test loss=0.651534 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.370532751083374
[5/24] Train loss=0.4004233479499817
[10/24] Train loss=0.40134865045547485
[15/24] Train loss=0.4484052062034607
[20/24] Train loss=0.36121416091918945
Test set avg_accuracy=69.77% avg_sensitivity=67.34%, avg_specificity=70.63% avg_auc=74.59%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.403239 Test loss=0.608360 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.36653754115104675
[5/24] Train loss=0.38806673884391785
[10/24] Train loss=0.42702174186706543
[15/24] Train loss=0.4406510293483734
[20/24] Train loss=0.3635401427745819
Test set avg_accuracy=61.81% avg_sensitivity=60.47%, avg_specificity=62.29% avg_auc=67.27%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.397275 Test loss=0.636018 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3619793653488159
[5/24] Train loss=0.3961823880672455
[10/24] Train loss=0.40919235348701477
[15/24] Train loss=0.44634810090065
[20/24] Train loss=0.3612879514694214
Test set avg_accuracy=74.05% avg_sensitivity=46.46%, avg_specificity=83.90% avg_auc=70.33%
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.395232 Test loss=0.592545 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3596220016479492
[5/24] Train loss=0.3782251179218292
[10/24] Train loss=0.39144349098205566
[15/24] Train loss=0.44557985663414
[20/24] Train loss=0.34853395819664
Test set avg_accuracy=65.29% avg_sensitivity=68.13%, avg_specificity=64.27% avg_auc=72.43%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.388482 Test loss=0.631642 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3466756343841553
[5/24] Train loss=0.3669452369213104
[10/24] Train loss=0.3928467035293579
[15/24] Train loss=0.48637497425079346
[20/24] Train loss=0.364494651556015
Test set avg_accuracy=69.75% avg_sensitivity=50.32%, avg_specificity=76.69% avg_auc=69.86%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.386861 Test loss=0.584228 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.35570430755615234
[5/24] Train loss=0.3697167932987213
[10/24] Train loss=0.3916090726852417
[15/24] Train loss=0.4556341767311096
[20/24] Train loss=0.35052376985549927
Test set avg_accuracy=67.92% avg_sensitivity=57.05%, avg_specificity=71.80% avg_auc=70.24%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.385760 Test loss=0.625490 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.34410974383354187
[5/24] Train loss=0.36651358008384705
[10/24] Train loss=0.3790212571620941
[15/24] Train loss=0.43099215626716614
[20/24] Train loss=0.37093839049339294
Test set avg_accuracy=79.35% avg_sensitivity=51.46%, avg_specificity=89.31% avg_auc=77.21%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.382335 Test loss=0.537102 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.35681337118148804
[5/24] Train loss=0.3815171420574188
[10/24] Train loss=0.37896430492401123
[15/24] Train loss=0.4351869225502014
[20/24] Train loss=0.35667186975479126
Test set avg_accuracy=70.95% avg_sensitivity=57.84%, avg_specificity=75.63% avg_auc=75.11%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.382881 Test loss=0.548035 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.36144310235977173
[5/24] Train loss=0.3612295687198639
[10/24] Train loss=0.39262986183166504
[15/24] Train loss=0.4280751645565033
[20/24] Train loss=0.3672983646392822
Test set avg_accuracy=61.71% avg_sensitivity=61.50%, avg_specificity=61.78% avg_auc=68.11%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.377524 Test loss=0.622422 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.34550294280052185
[5/24] Train loss=0.36349231004714966
[10/24] Train loss=0.37960416078567505
[15/24] Train loss=0.40261557698249817
[20/24] Train loss=0.3313148021697998
Test set avg_accuracy=62.50% avg_sensitivity=69.12%, avg_specificity=60.13% avg_auc=70.88%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.367647 Test loss=0.633043 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3348768949508667
[5/24] Train loss=0.3516384959220886
[10/24] Train loss=0.3772174119949341
[15/24] Train loss=0.3989699184894562
[20/24] Train loss=0.3360806107521057
Test set avg_accuracy=65.96% avg_sensitivity=69.32%, avg_specificity=64.76% avg_auc=74.24%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.362141 Test loss=0.609549 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.34234634041786194
[5/24] Train loss=0.34305721521377563
[10/24] Train loss=0.3655387759208679
[15/24] Train loss=0.40943121910095215
[20/24] Train loss=0.32357531785964966
Test set avg_accuracy=82.11% avg_sensitivity=53.79%, avg_specificity=92.22% avg_auc=85.86%
Best model saved!! Metric=-12.016896603543621!!
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.364140 Test loss=0.401587 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.35102760791778564
[5/24] Train loss=0.3458491265773773
[10/24] Train loss=0.3653610646724701
[15/24] Train loss=0.3921844959259033
[20/24] Train loss=0.34153589606285095
Test set avg_accuracy=74.92% avg_sensitivity=63.43%, avg_specificity=79.02% avg_auc=78.11%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.358132 Test loss=0.542473 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.33620408177375793
[5/24] Train loss=0.335491418838501
[10/24] Train loss=0.3634044826030731
[15/24] Train loss=0.38930413126945496
[20/24] Train loss=0.323747843503952
Test set avg_accuracy=68.55% avg_sensitivity=34.39%, avg_specificity=80.76% avg_auc=67.11%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.352768 Test loss=0.589480 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.33174508810043335
[5/24] Train loss=0.3418486416339874
[10/24] Train loss=0.3515926003456116
[15/24] Train loss=0.385641485452652
[20/24] Train loss=0.31728771328926086
Test set avg_accuracy=54.99% avg_sensitivity=57.10%, avg_specificity=54.23% avg_auc=61.02%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.351318 Test loss=0.722112 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3386301100254059
[5/24] Train loss=0.34915879368782043
[10/24] Train loss=0.35618939995765686
[15/24] Train loss=0.40429073572158813
[20/24] Train loss=0.3189280331134796
Test set avg_accuracy=79.69% avg_sensitivity=58.04%, avg_specificity=87.42% avg_auc=81.37%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.355841 Test loss=0.497727 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.330895334482193
[5/24] Train loss=0.3505874276161194
[10/24] Train loss=0.3522126078605652
[15/24] Train loss=0.4061141312122345
[20/24] Train loss=0.3289005756378174
Test set avg_accuracy=82.21% avg_sensitivity=54.92%, avg_specificity=91.96% avg_auc=82.62%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.353788 Test loss=0.456334 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33849337697029114
[5/24] Train loss=0.3367787301540375
[10/24] Train loss=0.35020074248313904
[15/24] Train loss=0.3791971206665039
[20/24] Train loss=0.34248852729797363
Test set avg_accuracy=80.55% avg_sensitivity=56.11%, avg_specificity=89.27% avg_auc=81.33%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.349342 Test loss=0.481781 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.341150164604187
[5/24] Train loss=0.36331918835639954
[10/24] Train loss=0.35748541355133057
[15/24] Train loss=0.38468319177627563
[20/24] Train loss=0.3104148507118225
Test set avg_accuracy=51.22% avg_sensitivity=83.18%, avg_specificity=39.81% avg_auc=68.83%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.348587 Test loss=0.681197 Current lr=[0.00029967723776099]

[0/24] Train loss=0.31404411792755127
[5/24] Train loss=0.3315543532371521
[10/24] Train loss=0.34928807616233826
[15/24] Train loss=0.3781467080116272
[20/24] Train loss=0.317712664604187
Test set avg_accuracy=77.64% avg_sensitivity=57.25%, avg_specificity=84.93% avg_auc=77.46%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.343165 Test loss=0.567257 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3256326913833618
[5/24] Train loss=0.33315902948379517
[10/24] Train loss=0.3631768226623535
[15/24] Train loss=0.3801534175872803
[20/24] Train loss=0.346601665019989
Test set avg_accuracy=57.51% avg_sensitivity=68.09%, avg_specificity=53.74% avg_auc=65.39%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.347989 Test loss=0.707465 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3228638768196106
[5/24] Train loss=0.33932051062583923
[10/24] Train loss=0.35139840841293335
[15/24] Train loss=0.38705557584762573
[20/24] Train loss=0.33120325207710266
Test set avg_accuracy=80.26% avg_sensitivity=43.89%, avg_specificity=93.25% avg_auc=80.49%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.342046 Test loss=0.456766 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3262627422809601
[5/24] Train loss=0.3351641893386841
[10/24] Train loss=0.34676817059516907
[15/24] Train loss=0.37210607528686523
[20/24] Train loss=0.3074782192707062
Test set avg_accuracy=77.76% avg_sensitivity=22.22%, avg_specificity=97.60% avg_auc=80.11%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.343039 Test loss=0.493048 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.31993117928504944
[5/24] Train loss=0.33626195788383484
[10/24] Train loss=0.3439466655254364
[15/24] Train loss=0.36771851778030396
[20/24] Train loss=0.30849188566207886
Test set avg_accuracy=76.43% avg_sensitivity=24.79%, avg_specificity=94.88% avg_auc=75.30%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.334937 Test loss=0.529247 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3069473206996918
[5/24] Train loss=0.3256112039089203
[10/24] Train loss=0.33639276027679443
[15/24] Train loss=0.3649204671382904
[20/24] Train loss=0.30997851490974426
Test set avg_accuracy=80.23% avg_sensitivity=36.86%, avg_specificity=95.72% avg_auc=80.70%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.331850 Test loss=0.478593 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.32104822993278503
[5/24] Train loss=0.3193478286266327
[10/24] Train loss=0.330222487449646
[15/24] Train loss=0.36463242769241333
[20/24] Train loss=0.329619437456131
Test set avg_accuracy=81.51% avg_sensitivity=52.99%, avg_specificity=91.69% avg_auc=81.81%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.329453 Test loss=0.487697 Current lr=[0.000297555943323901]

[0/24] Train loss=0.31346896290779114
[5/24] Train loss=0.3355615735054016
[10/24] Train loss=0.34557342529296875
[15/24] Train loss=0.3503182828426361
[20/24] Train loss=0.30063650012016296
Test set avg_accuracy=60.77% avg_sensitivity=61.95%, avg_specificity=60.35% avg_auc=65.95%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.330607 Test loss=0.644961 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.29638782143592834
[5/24] Train loss=0.3144325315952301
[10/24] Train loss=0.3449680507183075
[15/24] Train loss=0.3551643192768097
[20/24] Train loss=0.30584803223609924
Test set avg_accuracy=74.74% avg_sensitivity=40.97%, avg_specificity=86.80% avg_auc=74.89%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.327062 Test loss=0.526901 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.31055107712745667
[5/24] Train loss=0.3196814954280853
[10/24] Train loss=0.3333889842033386
[15/24] Train loss=0.3655742108821869
[20/24] Train loss=0.31110879778862
Test set avg_accuracy=70.68% avg_sensitivity=61.60%, avg_specificity=73.92% avg_auc=75.13%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.328330 Test loss=0.548045 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3081963062286377
[5/24] Train loss=0.3170263171195984
[10/24] Train loss=0.3498583137989044
[15/24] Train loss=0.37870219349861145
[20/24] Train loss=0.2967863380908966
Test set avg_accuracy=82.60% avg_sensitivity=58.24%, avg_specificity=91.31% avg_auc=84.43%
Best model saved!! Metric=-9.421576985053896!!
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.325832 Test loss=0.417665 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3123636841773987
[5/24] Train loss=0.31839296221733093
[10/24] Train loss=0.3430196940898895
[15/24] Train loss=0.3427952527999878
[20/24] Train loss=0.3019072711467743
Test set avg_accuracy=71.08% avg_sensitivity=44.53%, avg_specificity=80.56% avg_auc=72.57%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.326988 Test loss=0.564560 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2989925444126129
[5/24] Train loss=0.31482917070388794
[10/24] Train loss=0.3334744870662689
[15/24] Train loss=0.33926036953926086
[20/24] Train loss=0.30198854207992554
Test set avg_accuracy=73.59% avg_sensitivity=64.37%, avg_specificity=76.89% avg_auc=78.07%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.325818 Test loss=0.536621 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.31232431530952454
[5/24] Train loss=0.32097429037094116
[10/24] Train loss=0.3367830216884613
[15/24] Train loss=0.345110684633255
[20/24] Train loss=0.32446131110191345
Test set avg_accuracy=79.74% avg_sensitivity=42.26%, avg_specificity=93.13% avg_auc=79.42%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.327526 Test loss=0.515377 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3237972557544708
[5/24] Train loss=0.3428393304347992
[10/24] Train loss=0.33763429522514343
[15/24] Train loss=0.36304232478141785
[20/24] Train loss=0.2998213469982147
Test set avg_accuracy=71.50% avg_sensitivity=31.42%, avg_specificity=85.81% avg_auc=69.21%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.329445 Test loss=0.566306 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2986413240432739
[5/24] Train loss=0.3207206428050995
[10/24] Train loss=0.34127676486968994
[15/24] Train loss=0.3360673487186432
[20/24] Train loss=0.33584582805633545
Test set avg_accuracy=79.41% avg_sensitivity=55.52%, avg_specificity=87.95% avg_auc=82.03%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.318368 Test loss=0.446200 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2954588532447815
[5/24] Train loss=0.3172495663166046
[10/24] Train loss=0.346573144197464
[15/24] Train loss=0.35249751806259155
[20/24] Train loss=0.30416667461395264
Test set avg_accuracy=78.15% avg_sensitivity=66.01%, avg_specificity=82.49% avg_auc=81.89%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.323783 Test loss=0.476549 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.307127445936203
[5/24] Train loss=0.30330270528793335
[10/24] Train loss=0.3242351710796356
[15/24] Train loss=0.3382013440132141
[20/24] Train loss=0.29367437958717346
Test set avg_accuracy=70.40% avg_sensitivity=63.48%, avg_specificity=72.88% avg_auc=74.81%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.314912 Test loss=0.574716 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2806403636932373
[5/24] Train loss=0.3140290677547455
[10/24] Train loss=0.3328869640827179
[15/24] Train loss=0.3450765609741211
[20/24] Train loss=0.2991422712802887
Test set avg_accuracy=69.57% avg_sensitivity=48.94%, avg_specificity=76.94% avg_auc=71.88%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.313830 Test loss=0.548112 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.29958340525627136
[5/24] Train loss=0.31682664155960083
[10/24] Train loss=0.32718995213508606
[15/24] Train loss=0.35377413034439087
[20/24] Train loss=0.29621732234954834
Test set avg_accuracy=75.77% avg_sensitivity=27.41%, avg_specificity=93.04% avg_auc=74.38%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.318164 Test loss=0.514537 Current lr=[0.000276307469034998]

[0/24] Train loss=0.28674808144569397
[5/24] Train loss=0.3162676692008972
[10/24] Train loss=0.32278555631637573
[15/24] Train loss=0.33073797821998596
[20/24] Train loss=0.2942071557044983
Test set avg_accuracy=69.70% avg_sensitivity=41.86%, avg_specificity=79.64% avg_auc=70.33%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.310912 Test loss=0.557750 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.28938058018684387
[5/24] Train loss=0.3009166121482849
[10/24] Train loss=0.33240270614624023
[15/24] Train loss=0.33189132809638977
[20/24] Train loss=0.280564546585083
Test set avg_accuracy=60.43% avg_sensitivity=74.57%, avg_specificity=55.38% avg_auc=70.30%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.311454 Test loss=0.616826 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2819003164768219
[5/24] Train loss=0.30320626497268677
[10/24] Train loss=0.331184059381485
[15/24] Train loss=0.3357984125614166
[20/24] Train loss=0.3008051812648773
Test set avg_accuracy=71.71% avg_sensitivity=37.21%, avg_specificity=84.03% avg_auc=71.27%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.308027 Test loss=0.534770 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.27237626910209656
[5/24] Train loss=0.3137117624282837
[10/24] Train loss=0.3275105059146881
[15/24] Train loss=0.3451983332633972
[20/24] Train loss=0.28406643867492676
Test set avg_accuracy=48.54% avg_sensitivity=82.09%, avg_specificity=36.56% avg_auc=60.99%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.308441 Test loss=0.716302 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2882362902164459
[5/24] Train loss=0.3015140891075134
[10/24] Train loss=0.3315140902996063
[15/24] Train loss=0.3347517251968384
[20/24] Train loss=0.31112879514694214
Test set avg_accuracy=72.21% avg_sensitivity=16.53%, avg_specificity=92.10% avg_auc=68.50%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.311841 Test loss=0.539441 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2874796688556671
[5/24] Train loss=0.30590444803237915
[10/24] Train loss=0.332462877035141
[15/24] Train loss=0.3195682764053345
[20/24] Train loss=0.2842404544353485
Test set avg_accuracy=64.39% avg_sensitivity=51.66%, avg_specificity=68.93% avg_auc=67.64%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.303943 Test loss=0.588237 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2701655328273773
[5/24] Train loss=0.2828856408596039
[10/24] Train loss=0.33720293641090393
[15/24] Train loss=0.32605260610580444
[20/24] Train loss=0.2868019640445709
Test set avg_accuracy=63.96% avg_sensitivity=72.29%, avg_specificity=60.98% avg_auc=74.03%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.301316 Test loss=0.605098 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.26793670654296875
[5/24] Train loss=0.28633227944374084
[10/24] Train loss=0.32363829016685486
[15/24] Train loss=0.33791983127593994
[20/24] Train loss=0.2941516935825348
Test set avg_accuracy=65.39% avg_sensitivity=54.48%, avg_specificity=69.29% avg_auc=69.73%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.302875 Test loss=0.617167 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.27600184082984924
[5/24] Train loss=0.30362436175346375
[10/24] Train loss=0.31863048672676086
[15/24] Train loss=0.3188234567642212
[20/24] Train loss=0.2790120542049408
Test set avg_accuracy=74.70% avg_sensitivity=8.21%, avg_specificity=98.44% avg_auc=77.77%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.302034 Test loss=0.519167 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2829492390155792
[5/24] Train loss=0.3024345636367798
[10/24] Train loss=0.310179740190506
[15/24] Train loss=0.3172058165073395
[20/24] Train loss=0.2862214148044586
Test set avg_accuracy=59.18% avg_sensitivity=66.75%, avg_specificity=56.48% avg_auc=66.82%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.297950 Test loss=0.657508 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2664374113082886
[5/24] Train loss=0.2945740818977356
[10/24] Train loss=0.31175822019577026
[15/24] Train loss=0.32951268553733826
[20/24] Train loss=0.28797656297683716
Test set avg_accuracy=72.03% avg_sensitivity=63.14%, avg_specificity=75.21% avg_auc=77.63%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.295863 Test loss=0.523513 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2592502534389496
[5/24] Train loss=0.2967384457588196
[10/24] Train loss=0.31743207573890686
[15/24] Train loss=0.32027745246887207
[20/24] Train loss=0.2709929943084717
Test set avg_accuracy=65.61% avg_sensitivity=60.12%, avg_specificity=67.57% avg_auc=71.94%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.292507 Test loss=0.579190 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2663254141807556
[5/24] Train loss=0.28605785965919495
[10/24] Train loss=0.3090084493160248
[15/24] Train loss=0.33315908908843994
[20/24] Train loss=0.2728792428970337
Test set avg_accuracy=66.46% avg_sensitivity=48.49%, avg_specificity=72.88% avg_auc=68.83%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.291444 Test loss=0.581276 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.27442240715026855
[5/24] Train loss=0.2787010371685028
[10/24] Train loss=0.31885477900505066
[15/24] Train loss=0.3209995925426483
[20/24] Train loss=0.2766011953353882
Test set avg_accuracy=74.56% avg_sensitivity=18.01%, avg_specificity=94.75% avg_auc=72.55%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.298475 Test loss=0.519377 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2758239209651947
[5/24] Train loss=0.2891824245452881
[10/24] Train loss=0.3128352463245392
[15/24] Train loss=0.31090056896209717
[20/24] Train loss=0.2887572646141052
Test set avg_accuracy=69.27% avg_sensitivity=65.31%, avg_specificity=70.68% avg_auc=75.96%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.296684 Test loss=0.546768 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2552158236503601
[5/24] Train loss=0.2831979990005493
[10/24] Train loss=0.3085324764251709
[15/24] Train loss=0.3131785988807678
[20/24] Train loss=0.2756875455379486
Test set avg_accuracy=61.28% avg_sensitivity=79.56%, avg_specificity=54.74% avg_auc=73.85%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.287655 Test loss=0.599986 Current lr=[0.000224838296036774]

[0/24] Train loss=0.25122418999671936
[5/24] Train loss=0.2773524224758148
[10/24] Train loss=0.3002847731113434
[15/24] Train loss=0.3280119001865387
[20/24] Train loss=0.27193573117256165
Test set avg_accuracy=57.75% avg_sensitivity=78.97%, avg_specificity=50.17% avg_auc=68.84%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.286242 Test loss=0.633889 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.27427321672439575
[5/24] Train loss=0.2936583161354065
[10/24] Train loss=0.29722273349761963
[15/24] Train loss=0.3348517417907715
[20/24] Train loss=0.2925141453742981
Test set avg_accuracy=77.50% avg_sensitivity=36.42%, avg_specificity=92.17% avg_auc=79.12%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.292618 Test loss=0.471125 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.27461904287338257
[5/24] Train loss=0.2820461392402649
[10/24] Train loss=0.30911993980407715
[15/24] Train loss=0.3279971480369568
[20/24] Train loss=0.27508795261383057
Test set avg_accuracy=72.53% avg_sensitivity=11.83%, avg_specificity=94.20% avg_auc=68.74%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.292526 Test loss=0.542648 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2635309100151062
[5/24] Train loss=0.28462323546409607
[10/24] Train loss=0.2998105585575104
[15/24] Train loss=0.3222852647304535
[20/24] Train loss=0.262601375579834
Test set avg_accuracy=64.62% avg_sensitivity=63.19%, avg_specificity=65.14% avg_auc=71.10%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.285330 Test loss=0.614514 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2504100203514099
[5/24] Train loss=0.2819299101829529
[10/24] Train loss=0.2815324366092682
[15/24] Train loss=0.3042590022087097
[20/24] Train loss=0.26330235600471497
Test set avg_accuracy=59.78% avg_sensitivity=81.15%, avg_specificity=52.15% avg_auc=71.88%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.277641 Test loss=0.670444 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2421906739473343
[5/24] Train loss=0.27257832884788513
[10/24] Train loss=0.28922829031944275
[15/24] Train loss=0.29293620586395264
[20/24] Train loss=0.26378268003463745
Test set avg_accuracy=78.82% avg_sensitivity=59.33%, avg_specificity=85.77% avg_auc=83.07%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.275971 Test loss=0.443934 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2737731337547302
[5/24] Train loss=0.28506243228912354
[10/24] Train loss=0.30641797184944153
[15/24] Train loss=0.30464866757392883
[20/24] Train loss=0.25701236724853516
Test set avg_accuracy=72.27% avg_sensitivity=38.10%, avg_specificity=84.47% avg_auc=73.35%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.283817 Test loss=0.528684 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.24890737235546112
[5/24] Train loss=0.2940237820148468
[10/24] Train loss=0.2966988980770111
[15/24] Train loss=0.3380647897720337
[20/24] Train loss=0.2711676061153412
Test set avg_accuracy=81.11% avg_sensitivity=46.26%, avg_specificity=93.55% avg_auc=83.88%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.284392 Test loss=0.439407 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2558261454105377
[5/24] Train loss=0.2778942883014679
[10/24] Train loss=0.2923199534416199
[15/24] Train loss=0.32897987961769104
[20/24] Train loss=0.261690229177475
Test set avg_accuracy=66.50% avg_sensitivity=64.62%, avg_specificity=67.17% avg_auc=72.99%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.281460 Test loss=0.572281 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.24338780343532562
[5/24] Train loss=0.27266180515289307
[10/24] Train loss=0.2935442626476288
[15/24] Train loss=0.2987959086894989
[20/24] Train loss=0.2672950029373169
Test set avg_accuracy=71.86% avg_sensitivity=46.81%, avg_specificity=80.81% avg_auc=74.41%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.275274 Test loss=0.530047 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2606263756752014
[5/24] Train loss=0.2695869207382202
[10/24] Train loss=0.27790966629981995
[15/24] Train loss=0.2981205880641937
[20/24] Train loss=0.2539474070072174
Test set avg_accuracy=69.08% avg_sensitivity=61.11%, avg_specificity=71.92% avg_auc=73.94%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.276111 Test loss=0.555730 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.24124625325202942
[5/24] Train loss=0.28748348355293274
[10/24] Train loss=0.2874665856361389
[15/24] Train loss=0.30689865350723267
[20/24] Train loss=0.2643420398235321
Test set avg_accuracy=64.51% avg_sensitivity=59.92%, avg_specificity=66.14% avg_auc=70.88%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.278196 Test loss=0.590726 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.23754696547985077
[5/24] Train loss=0.2682868540287018
[10/24] Train loss=0.28802239894866943
[15/24] Train loss=0.2944951355457306
[20/24] Train loss=0.26063457131385803
Test set avg_accuracy=78.61% avg_sensitivity=65.81%, avg_specificity=83.18% avg_auc=82.97%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.274441 Test loss=0.455950 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2381652295589447
[5/24] Train loss=0.2745778560638428
[10/24] Train loss=0.27745383977890015
[15/24] Train loss=0.29793334007263184
[20/24] Train loss=0.25117796659469604
Test set avg_accuracy=75.44% avg_sensitivity=60.12%, avg_specificity=80.92% avg_auc=80.84%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.273562 Test loss=0.478588 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24531792104244232
[5/24] Train loss=0.26859769225120544
[10/24] Train loss=0.28320789337158203
[15/24] Train loss=0.2927439510822296
[20/24] Train loss=0.2599412798881531
Test set avg_accuracy=74.53% avg_sensitivity=16.63%, avg_specificity=95.21% avg_auc=71.72%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.273771 Test loss=0.532115 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.24353326857089996
[5/24] Train loss=0.27400779724121094
[10/24] Train loss=0.2650284171104431
[15/24] Train loss=0.30276674032211304
[20/24] Train loss=0.263126939535141
Test set avg_accuracy=68.72% avg_sensitivity=73.48%, avg_specificity=67.03% avg_auc=77.50%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.269652 Test loss=0.557544 Current lr=[0.000156543481933168]

[0/24] Train loss=0.24540944397449493
[5/24] Train loss=0.2607989013195038
[10/24] Train loss=0.27658113837242126
[15/24] Train loss=0.2929030954837799
[20/24] Train loss=0.2587485909461975
Test set avg_accuracy=67.45% avg_sensitivity=71.50%, avg_specificity=66.00% avg_auc=74.74%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.265243 Test loss=0.578522 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.23678918182849884
[5/24] Train loss=0.27484792470932007
[10/24] Train loss=0.2750663161277771
[15/24] Train loss=0.2855503261089325
[20/24] Train loss=0.255414217710495
Test set avg_accuracy=65.44% avg_sensitivity=54.48%, avg_specificity=69.36% avg_auc=69.98%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.267700 Test loss=0.592903 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2324967235326767
[5/24] Train loss=0.2580709755420685
[10/24] Train loss=0.27952536940574646
[15/24] Train loss=0.2943474352359772
[20/24] Train loss=0.24810653924942017
Test set avg_accuracy=69.31% avg_sensitivity=68.83%, avg_specificity=69.48% avg_auc=78.13%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.263853 Test loss=0.575931 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2361387312412262
[5/24] Train loss=0.25624534487724304
[10/24] Train loss=0.2718384563922882
[15/24] Train loss=0.3082270324230194
[20/24] Train loss=0.25295624136924744
Test set avg_accuracy=77.88% avg_sensitivity=39.44%, avg_specificity=91.61% avg_auc=79.52%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.264263 Test loss=0.473798 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.24806846678256989
[5/24] Train loss=0.2611735463142395
[10/24] Train loss=0.2752368450164795
[15/24] Train loss=0.2872459590435028
[20/24] Train loss=0.26185378432273865
Test set avg_accuracy=70.40% avg_sensitivity=71.10%, avg_specificity=70.15% avg_auc=76.92%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.264790 Test loss=0.547572 Current lr=[0.000134135431043539]

[0/24] Train loss=0.22855691611766815
[5/24] Train loss=0.2681618630886078
[10/24] Train loss=0.27026355266571045
[15/24] Train loss=0.2940753400325775
[20/24] Train loss=0.254853218793869
Test set avg_accuracy=70.47% avg_sensitivity=32.36%, avg_specificity=84.08% avg_auc=70.75%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.265594 Test loss=0.550497 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.23238320648670197
[5/24] Train loss=0.2629724144935608
[10/24] Train loss=0.2696778178215027
[15/24] Train loss=0.2728606164455414
[20/24] Train loss=0.24289929866790771
Test set avg_accuracy=63.06% avg_sensitivity=66.85%, avg_specificity=61.71% avg_auc=69.82%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.256293 Test loss=0.624308 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.23055033385753632
[5/24] Train loss=0.25940531492233276
[10/24] Train loss=0.25729474425315857
[15/24] Train loss=0.2648164927959442
[20/24] Train loss=0.23675104975700378
Test set avg_accuracy=72.45% avg_sensitivity=64.18%, avg_specificity=75.40% avg_auc=77.96%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.251578 Test loss=0.522851 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.22719630599021912
[5/24] Train loss=0.2525550425052643
[10/24] Train loss=0.2559409737586975
[15/24] Train loss=0.2872370779514313
[20/24] Train loss=0.2396504431962967
Test set avg_accuracy=72.76% avg_sensitivity=48.39%, avg_specificity=81.46% avg_auc=75.22%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.249028 Test loss=0.521977 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.22531303763389587
[5/24] Train loss=0.244437575340271
[10/24] Train loss=0.25772175192832947
[15/24] Train loss=0.27406373620033264
[20/24] Train loss=0.23558899760246277
Test set avg_accuracy=69.32% avg_sensitivity=67.29%, avg_specificity=70.05% avg_auc=75.64%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.248393 Test loss=0.546736 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.22096802294254303
[5/24] Train loss=0.24104128777980804
[10/24] Train loss=0.2551230192184448
[15/24] Train loss=0.2882343530654907
[20/24] Train loss=0.23579742014408112
Test set avg_accuracy=70.94% avg_sensitivity=62.44%, avg_specificity=73.97% avg_auc=75.31%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.247394 Test loss=0.543957 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.221223846077919
[5/24] Train loss=0.25140032172203064
[10/24] Train loss=0.2561999261379242
[15/24] Train loss=0.27558383345603943
[20/24] Train loss=0.23407131433486938
Test set avg_accuracy=61.68% avg_sensitivity=74.62%, avg_specificity=57.06% avg_auc=71.86%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.248215 Test loss=0.655780 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2227817177772522
[5/24] Train loss=0.24390430748462677
[10/24] Train loss=0.26115965843200684
[15/24] Train loss=0.2645282745361328
[20/24] Train loss=0.22735711932182312
Test set avg_accuracy=76.98% avg_sensitivity=42.65%, avg_specificity=89.24% avg_auc=77.38%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.246696 Test loss=0.491676 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2252614051103592
[5/24] Train loss=0.2384001910686493
[10/24] Train loss=0.2631351351737976
[15/24] Train loss=0.27778589725494385
[20/24] Train loss=0.24129655957221985
Test set avg_accuracy=66.78% avg_sensitivity=63.98%, avg_specificity=67.79% avg_auc=71.80%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.243980 Test loss=0.601233 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.22337466478347778
[5/24] Train loss=0.2493506222963333
[10/24] Train loss=0.2557445466518402
[15/24] Train loss=0.26952293515205383
[20/24] Train loss=0.2329781949520111
Test set avg_accuracy=63.65% avg_sensitivity=66.65%, avg_specificity=62.57% avg_auc=71.92%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.243713 Test loss=0.590522 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.22163935005664825
[5/24] Train loss=0.2347472906112671
[10/24] Train loss=0.2643364369869232
[15/24] Train loss=0.2760150730609894
[20/24] Train loss=0.23174439370632172
Test set avg_accuracy=61.63% avg_sensitivity=70.56%, avg_specificity=58.44% avg_auc=70.34%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.241747 Test loss=0.627741 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2185225933790207
[5/24] Train loss=0.23469558358192444
[10/24] Train loss=0.2538200616836548
[15/24] Train loss=0.2653888165950775
[20/24] Train loss=0.22509679198265076
Test set avg_accuracy=60.57% avg_sensitivity=70.51%, avg_specificity=57.02% avg_auc=68.83%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.237627 Test loss=0.695564 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.21427521109580994
[5/24] Train loss=0.2352563589811325
[10/24] Train loss=0.2522629499435425
[15/24] Train loss=0.25740259885787964
[20/24] Train loss=0.23250558972358704
Test set avg_accuracy=70.64% avg_sensitivity=32.46%, avg_specificity=84.27% avg_auc=67.75%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.238308 Test loss=0.603355 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.21688073873519897
[5/24] Train loss=0.231953427195549
[10/24] Train loss=0.25663164258003235
[15/24] Train loss=0.2669963836669922
[20/24] Train loss=0.2224774956703186
Test set avg_accuracy=63.05% avg_sensitivity=41.81%, avg_specificity=70.63% avg_auc=63.65%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.237844 Test loss=0.673965 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.21270209550857544
[5/24] Train loss=0.2241620570421219
[10/24] Train loss=0.24738557636737823
[15/24] Train loss=0.2575843930244446
[20/24] Train loss=0.22233274579048157
Test set avg_accuracy=62.33% avg_sensitivity=56.56%, avg_specificity=64.39% avg_auc=66.73%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.236403 Test loss=0.633722 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.21582089364528656
[5/24] Train loss=0.22650973498821259
[10/24] Train loss=0.2434578835964203
[15/24] Train loss=0.25819337368011475
[20/24] Train loss=0.22720801830291748
Test set avg_accuracy=67.14% avg_sensitivity=49.98%, avg_specificity=73.26% avg_auc=70.37%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.238162 Test loss=0.599498 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.21603870391845703
[5/24] Train loss=0.2319520115852356
[10/24] Train loss=0.24769529700279236
[15/24] Train loss=0.25905558466911316
[20/24] Train loss=0.2285136878490448
Test set avg_accuracy=66.33% avg_sensitivity=68.78%, avg_specificity=65.45% avg_auc=73.48%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.236173 Test loss=0.616485 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.21229299902915955
[5/24] Train loss=0.2393762469291687
[10/24] Train loss=0.25131770968437195
[15/24] Train loss=0.25228139758110046
[20/24] Train loss=0.21502304077148438
Test set avg_accuracy=64.39% avg_sensitivity=75.56%, avg_specificity=60.40% avg_auc=74.31%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.233838 Test loss=0.636028 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.21100789308547974
[5/24] Train loss=0.22243818640708923
[10/24] Train loss=0.24113412201404572
[15/24] Train loss=0.2551540434360504
[20/24] Train loss=0.21438609063625336
Test set avg_accuracy=65.04% avg_sensitivity=70.76%, avg_specificity=63.00% avg_auc=73.49%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.228849 Test loss=0.630940 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.20928175747394562
[5/24] Train loss=0.22242829203605652
[10/24] Train loss=0.23674330115318298
[15/24] Train loss=0.2463303953409195
[20/24] Train loss=0.21901576220989227
Test set avg_accuracy=62.81% avg_sensitivity=75.90%, avg_specificity=58.14% avg_auc=73.64%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.228354 Test loss=0.672144 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.20468831062316895
[5/24] Train loss=0.22153757512569427
[10/24] Train loss=0.24283309280872345
[15/24] Train loss=0.25217360258102417
[20/24] Train loss=0.22179079055786133
Test set avg_accuracy=61.15% avg_sensitivity=60.47%, avg_specificity=61.39% avg_auc=67.36%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.226855 Test loss=0.662635 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2073477804660797
[5/24] Train loss=0.22528816759586334
[10/24] Train loss=0.23676122725009918
[15/24] Train loss=0.24672578275203705
[20/24] Train loss=0.21465009450912476
Test set avg_accuracy=65.57% avg_sensitivity=60.32%, avg_specificity=67.45% avg_auc=71.05%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.227455 Test loss=0.611422 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.20310692489147186
[5/24] Train loss=0.22018375992774963
[10/24] Train loss=0.24134601652622223
[15/24] Train loss=0.23994992673397064
[20/24] Train loss=0.2110476791858673
Test set avg_accuracy=66.91% avg_sensitivity=69.32%, avg_specificity=66.05% avg_auc=74.55%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.223069 Test loss=0.603907 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.20295099914073944
[5/24] Train loss=0.220309779047966
[10/24] Train loss=0.2312825322151184
[15/24] Train loss=0.25109708309173584
[20/24] Train loss=0.207393079996109
Test set avg_accuracy=65.86% avg_sensitivity=64.97%, avg_specificity=66.18% avg_auc=72.86%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.220210 Test loss=0.592432 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.20141547918319702
[5/24] Train loss=0.2090415358543396
[10/24] Train loss=0.23277850449085236
[15/24] Train loss=0.2452259212732315
[20/24] Train loss=0.21080973744392395
Test set avg_accuracy=66.20% avg_sensitivity=57.00%, avg_specificity=69.48% avg_auc=71.00%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.218862 Test loss=0.606345 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.20491276681423187
[5/24] Train loss=0.20505249500274658
[10/24] Train loss=0.22487346827983856
[15/24] Train loss=0.2313092052936554
[20/24] Train loss=0.20539310574531555
Test set avg_accuracy=61.20% avg_sensitivity=68.09%, avg_specificity=58.74% avg_auc=70.07%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.216985 Test loss=0.667969 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.19580072164535522
[5/24] Train loss=0.21029962599277496
[10/24] Train loss=0.22476491332054138
[15/24] Train loss=0.2364397644996643
[20/24] Train loss=0.20519331097602844
Test set avg_accuracy=63.68% avg_sensitivity=68.48%, avg_specificity=61.97% avg_auc=72.34%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.215818 Test loss=0.631473 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.19662149250507355
[5/24] Train loss=0.2100096493959427
[10/24] Train loss=0.23134182393550873
[15/24] Train loss=0.24175962805747986
[20/24] Train loss=0.1991901844739914
Test set avg_accuracy=69.23% avg_sensitivity=53.54%, avg_specificity=74.84% avg_auc=72.29%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.215414 Test loss=0.585686 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1914810985326767
[5/24] Train loss=0.20408599078655243
[10/24] Train loss=0.22633445262908936
[15/24] Train loss=0.24103766679763794
[20/24] Train loss=0.20357368886470795
Test set avg_accuracy=61.90% avg_sensitivity=67.44%, avg_specificity=59.92% avg_auc=70.46%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.213217 Test loss=0.656628 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1903814822435379
[5/24] Train loss=0.20508207380771637
[10/24] Train loss=0.2244502156972885
[15/24] Train loss=0.2359388768672943
[20/24] Train loss=0.20361435413360596
Test set avg_accuracy=62.85% avg_sensitivity=68.93%, avg_specificity=60.68% avg_auc=71.23%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.212014 Test loss=0.658269 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1937711536884308
[5/24] Train loss=0.20311082899570465
[10/24] Train loss=0.22674354910850525
[15/24] Train loss=0.2337874174118042
[20/24] Train loss=0.20656929910182953
Test set avg_accuracy=63.93% avg_sensitivity=60.71%, avg_specificity=65.08% avg_auc=70.57%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.211507 Test loss=0.636980 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.19634662568569183
[5/24] Train loss=0.20464421808719635
[10/24] Train loss=0.22768981754779816
[15/24] Train loss=0.23855772614479065
[20/24] Train loss=0.19869278371334076
Test set avg_accuracy=63.96% avg_sensitivity=64.97%, avg_specificity=63.60% avg_auc=71.88%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.210185 Test loss=0.635690 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.19257056713104248
[5/24] Train loss=0.20252622663974762
[10/24] Train loss=0.2219681590795517
[15/24] Train loss=0.24322277307510376
[20/24] Train loss=0.19720323383808136
Test set avg_accuracy=64.66% avg_sensitivity=62.54%, avg_specificity=65.42% avg_auc=71.41%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.210112 Test loss=0.631472 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.19370602071285248
[5/24] Train loss=0.19931060075759888
[10/24] Train loss=0.21900568902492523
[15/24] Train loss=0.24480848014354706
[20/24] Train loss=0.20270901918411255
Test set avg_accuracy=63.72% avg_sensitivity=64.72%, avg_specificity=63.37% avg_auc=71.46%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.208740 Test loss=0.639453 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.19263845682144165
[5/24] Train loss=0.202177032828331
[10/24] Train loss=0.22034992277622223
[15/24] Train loss=0.24274982511997223
[20/24] Train loss=0.1987484246492386
Test set avg_accuracy=64.86% avg_sensitivity=66.40%, avg_specificity=64.30% avg_auc=72.66%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.209125 Test loss=0.626958 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.19116821885108948
[5/24] Train loss=0.2050209790468216
[10/24] Train loss=0.22978554666042328
[15/24] Train loss=0.23767125606536865
[20/24] Train loss=0.20008330047130585
Test set avg_accuracy=63.72% avg_sensitivity=65.07%, avg_specificity=63.24% avg_auc=71.64%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.208735 Test loss=0.641522 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.18668808043003082
[5/24] Train loss=0.20010130107402802
[10/24] Train loss=0.22207923233509064
[15/24] Train loss=0.23745830357074738
[20/24] Train loss=0.2039252072572708
Test set avg_accuracy=64.05% avg_sensitivity=63.73%, avg_specificity=64.16% avg_auc=71.25%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.208161 Test loss=0.632190 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.18907642364501953
[5/24] Train loss=0.19468356668949127
[10/24] Train loss=0.22191989421844482
[15/24] Train loss=0.22751204669475555
[20/24] Train loss=0.19559846818447113
Test set avg_accuracy=64.38% avg_sensitivity=63.98%, avg_specificity=64.52% avg_auc=71.49%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.206621 Test loss=0.635651 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.18940195441246033
[5/24] Train loss=0.20967400074005127
[10/24] Train loss=0.22360984981060028
[15/24] Train loss=0.2322441041469574
[20/24] Train loss=0.20024707913398743
Test set avg_accuracy=64.86% avg_sensitivity=62.30%, avg_specificity=65.77% avg_auc=71.69%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.207049 Test loss=0.628501 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.18617062270641327
[5/24] Train loss=0.20173877477645874
[10/24] Train loss=0.21707503497600555
[15/24] Train loss=0.23065610229969025
[20/24] Train loss=0.19874319434165955
Test set avg_accuracy=64.52% avg_sensitivity=63.83%, avg_specificity=64.76% avg_auc=71.86%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.205931 Test loss=0.631957 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.18977203965187073
[5/24] Train loss=0.20331430435180664
[10/24] Train loss=0.21386368572711945
[15/24] Train loss=0.24674828350543976
[20/24] Train loss=0.19327883422374725
Test set avg_accuracy=64.34% avg_sensitivity=65.26%, avg_specificity=64.00% avg_auc=71.86%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.205909 Test loss=0.635848 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1910782754421234
[5/24] Train loss=0.20089077949523926
[10/24] Train loss=0.22618068754673004
[15/24] Train loss=0.22839684784412384
[20/24] Train loss=0.20005151629447937
Test set avg_accuracy=64.48% avg_sensitivity=64.57%, avg_specificity=64.45% avg_auc=71.78%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.205406 Test loss=0.636231 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.18957307934761047
[5/24] Train loss=0.19843563437461853
[10/24] Train loss=0.21301807463169098
[15/24] Train loss=0.22626058757305145
[20/24] Train loss=0.20000819861888885
Test set avg_accuracy=64.78% avg_sensitivity=65.02%, avg_specificity=64.69% avg_auc=71.91%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.204992 Test loss=0.635260 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.18787692487239838
[5/24] Train loss=0.19589799642562866
[10/24] Train loss=0.21828636527061462
[15/24] Train loss=0.22553189098834991
[20/24] Train loss=0.19185705482959747
Test set avg_accuracy=64.64% avg_sensitivity=63.88%, avg_specificity=64.91% avg_auc=71.76%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.204473 Test loss=0.634289 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1856633871793747
[5/24] Train loss=0.19281227886676788
[10/24] Train loss=0.2149215191602707
[15/24] Train loss=0.22794099152088165
[20/24] Train loss=0.19491355121135712
Test set avg_accuracy=64.52% avg_sensitivity=63.58%, avg_specificity=64.85% avg_auc=71.56%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.204849 Test loss=0.637919 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1881810575723648
[5/24] Train loss=0.1956678032875061
[10/24] Train loss=0.21818210184574127
[15/24] Train loss=0.23264221847057343
[20/24] Train loss=0.1978541612625122
Test set avg_accuracy=64.57% avg_sensitivity=64.18%, avg_specificity=64.71% avg_auc=71.73%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.205577 Test loss=0.637542 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.18911604583263397
[5/24] Train loss=0.19502367079257965
[10/24] Train loss=0.2208900898694992
[15/24] Train loss=0.24111361801624298
[20/24] Train loss=0.19953738152980804
Test set avg_accuracy=64.73% avg_sensitivity=64.67%, avg_specificity=64.75% avg_auc=71.72%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.205430 Test loss=0.637096 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1848265379667282
[5/24] Train loss=0.19296011328697205
[10/24] Train loss=0.21144062280654907
[15/24] Train loss=0.23165163397789001
[20/24] Train loss=0.19288451969623566
Test set avg_accuracy=64.66% avg_sensitivity=63.78%, avg_specificity=64.98% avg_auc=71.63%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.203819 Test loss=0.636366 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.18906036019325256
[5/24] Train loss=0.1973804235458374
[10/24] Train loss=0.2160864919424057
[15/24] Train loss=0.2457202821969986
[20/24] Train loss=0.19691626727581024
Test set avg_accuracy=64.74% avg_sensitivity=64.47%, avg_specificity=64.83% avg_auc=71.88%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.204995 Test loss=0.636298 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=82.60% sen=58.24%, spe=91.31%, auc=84.43%!
Fold[1] Avg_overlap=0.57%(±0.3165415261666026)
[0/24] Train loss=0.7171964645385742
[5/24] Train loss=0.7178875207901001
[10/24] Train loss=0.7231495380401611
[15/24] Train loss=0.7119926810264587
[20/24] Train loss=0.7138183116912842
Test set avg_accuracy=48.72% avg_sensitivity=53.16%, avg_specificity=47.25% avg_auc=50.18%
Best model saved!! Metric=-126.68704874680148!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=0.715566 Test loss=0.696093 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7099155783653259
[5/24] Train loss=0.7094085812568665
[10/24] Train loss=0.7046627998352051
[15/24] Train loss=0.7093855142593384
[20/24] Train loss=0.7023378014564514
Test set avg_accuracy=45.76% avg_sensitivity=58.63%, avg_specificity=41.47% avg_auc=50.32%
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.705371 Test loss=0.693597 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.6981278657913208
[5/24] Train loss=0.6993438601493835
[10/24] Train loss=0.7000135779380798
[15/24] Train loss=0.6929467916488647
[20/24] Train loss=0.6908909678459167
Test set avg_accuracy=48.72% avg_sensitivity=53.05%, avg_specificity=47.28% avg_auc=50.09%
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.698327 Test loss=0.692376 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6892943382263184
[5/24] Train loss=0.6957084536552429
[10/24] Train loss=0.6789451837539673
[15/24] Train loss=0.6865349411964417
[20/24] Train loss=0.6754860281944275
Test set avg_accuracy=51.76% avg_sensitivity=46.74%, avg_specificity=53.43% avg_auc=50.73%
Best model saved!! Metric=-123.3425001360298!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.689429 Test loss=0.684377 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6824740171432495
[5/24] Train loss=0.6948719620704651
[10/24] Train loss=0.6814683675765991
[15/24] Train loss=0.6727263927459717
[20/24] Train loss=0.6717013120651245
Test set avg_accuracy=55.16% avg_sensitivity=41.00%, avg_specificity=59.86% avg_auc=51.04%
Best model saved!! Metric=-118.93408053210945!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.681405 Test loss=0.673741 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6763593554496765
[5/24] Train loss=0.68060302734375
[10/24] Train loss=0.6697468161582947
[15/24] Train loss=0.6631467342376709
[20/24] Train loss=0.6618359684944153
Test set avg_accuracy=55.38% avg_sensitivity=41.16%, avg_specificity=60.11% avg_auc=51.74%
Best model saved!! Metric=-117.6188396991943!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.672192 Test loss=0.671951 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6594301462173462
[5/24] Train loss=0.6758569478988647
[10/24] Train loss=0.6551283001899719
[15/24] Train loss=0.666050374507904
[20/24] Train loss=0.6456254720687866
Test set avg_accuracy=57.42% avg_sensitivity=37.40%, avg_specificity=64.08% avg_auc=52.24%
Best model saved!! Metric=-114.85224015060506!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.661840 Test loss=0.663747 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6494699120521545
[5/24] Train loss=0.6627711057662964
[10/24] Train loss=0.641786515712738
[15/24] Train loss=0.6475004553794861
[20/24] Train loss=0.6402871608734131
Test set avg_accuracy=67.84% avg_sensitivity=17.63%, avg_specificity=84.54% avg_auc=52.98%
Best model saved!! Metric=-103.01436896037863!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.649900 Test loss=0.650738 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6348196864128113
[5/24] Train loss=0.6567705869674683
[10/24] Train loss=0.6420668959617615
[15/24] Train loss=0.641371488571167
[20/24] Train loss=0.6276249885559082
Test set avg_accuracy=71.17% avg_sensitivity=13.35%, avg_specificity=90.40% avg_auc=53.91%
Best model saved!! Metric=-97.15500095421694!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.639861 Test loss=0.638566 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6235098242759705
[5/24] Train loss=0.6451249122619629
[10/24] Train loss=0.6216651201248169
[15/24] Train loss=0.6230707764625549
[20/24] Train loss=0.6019814014434814
Test set avg_accuracy=71.56% avg_sensitivity=11.16%, avg_specificity=91.65% avg_auc=54.91%
Best model saved!! Metric=-96.70825552847293!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.627366 Test loss=0.621804 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6094102263450623
[5/24] Train loss=0.6400924921035767
[10/24] Train loss=0.6111777424812317
[15/24] Train loss=0.6100199222564697
[20/24] Train loss=0.5880441069602966
Test set avg_accuracy=71.73% avg_sensitivity=11.79%, avg_specificity=91.67% avg_auc=55.92%
Best model saved!! Metric=-94.88467674190673!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.615001 Test loss=0.610070 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.5963566303253174
[5/24] Train loss=0.6299892663955688
[10/24] Train loss=0.6004152894020081
[15/24] Train loss=0.6012268662452698
[20/24] Train loss=0.5716618895530701
Test set avg_accuracy=75.00% avg_sensitivity=10.38%, avg_specificity=96.49% avg_auc=57.86%
Best model saved!! Metric=-86.26203848756901!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.602383 Test loss=0.585550 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5819990038871765
[5/24] Train loss=0.6156999468803406
[10/24] Train loss=0.5806912779808044
[15/24] Train loss=0.5876557230949402
[20/24] Train loss=0.5510112643241882
Test set avg_accuracy=74.92% avg_sensitivity=9.81%, avg_specificity=96.58% avg_auc=61.82%
Best model saved!! Metric=-82.87226061464675!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.587319 Test loss=0.552910 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5563056468963623
[5/24] Train loss=0.6004807353019714
[10/24] Train loss=0.5640044808387756
[15/24] Train loss=0.566740870475769
[20/24] Train loss=0.5239748954772949
Test set avg_accuracy=75.12% avg_sensitivity=10.90%, avg_specificity=96.48% avg_auc=63.09%
Best model saved!! Metric=-80.41774796286816!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.571643 Test loss=0.547064 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5256147980690002
[5/24] Train loss=0.5723995566368103
[10/24] Train loss=0.5356602668762207
[15/24] Train loss=0.5452620387077332
[20/24] Train loss=0.4986577332019806
Test set avg_accuracy=75.23% avg_sensitivity=15.39%, avg_specificity=95.14% avg_auc=64.40%
Best model saved!! Metric=-75.83251013805307!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.543934 Test loss=0.569029 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4868345558643341
[5/24] Train loss=0.5385773181915283
[10/24] Train loss=0.4940395653247833
[15/24] Train loss=0.5054967403411865
[20/24] Train loss=0.4654982388019562
Test set avg_accuracy=76.56% avg_sensitivity=26.71%, avg_specificity=93.15% avg_auc=71.83%
Best model saved!! Metric=-57.74854130454283!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.511048 Test loss=0.527063 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.43873387575149536
[5/24] Train loss=0.4890934228897095
[10/24] Train loss=0.47244641184806824
[15/24] Train loss=0.463543176651001
[20/24] Train loss=0.43760427832603455
Test set avg_accuracy=77.03% avg_sensitivity=29.63%, avg_specificity=92.80% avg_auc=73.97%
Best model saved!! Metric=-52.56560765443232!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.476346 Test loss=0.516103 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.42023181915283203
[5/24] Train loss=0.47725147008895874
[10/24] Train loss=0.44958218932151794
[15/24] Train loss=0.45338863134384155
[20/24] Train loss=0.41641414165496826
Test set avg_accuracy=79.01% avg_sensitivity=50.97%, avg_specificity=88.34% avg_auc=79.64%
Best model saved!! Metric=-28.043639885162214!!
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.458998 Test loss=0.470005 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.39478185772895813
[5/24] Train loss=0.44845640659332275
[10/24] Train loss=0.42686495184898376
[15/24] Train loss=0.4388064444065094
[20/24] Train loss=0.3995228707790375
Test set avg_accuracy=55.86% avg_sensitivity=69.22%, avg_specificity=51.41% avg_auc=66.85%
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.438311 Test loss=0.669640 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.3855845034122467
[5/24] Train loss=0.4406563937664032
[10/24] Train loss=0.4178643822669983
[15/24] Train loss=0.43581101298332214
[20/24] Train loss=0.39165544509887695
Test set avg_accuracy=55.65% avg_sensitivity=64.48%, avg_specificity=52.72% avg_auc=62.32%
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.428139 Test loss=0.674804 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.37682637572288513
[5/24] Train loss=0.43043994903564453
[10/24] Train loss=0.4038398861885071
[15/24] Train loss=0.42488351464271545
[20/24] Train loss=0.37743526697158813
Test set avg_accuracy=57.32% avg_sensitivity=66.98%, avg_specificity=54.10% avg_auc=63.53%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.419376 Test loss=0.673954 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3705402910709381
[5/24] Train loss=0.41716593503952026
[10/24] Train loss=0.39837655425071716
[15/24] Train loss=0.41086065769195557
[20/24] Train loss=0.37056562304496765
Test set avg_accuracy=59.36% avg_sensitivity=64.74%, avg_specificity=57.57% avg_auc=69.14%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.416666 Test loss=0.637567 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3644084930419922
[5/24] Train loss=0.4252379834651947
[10/24] Train loss=0.3944140672683716
[15/24] Train loss=0.41439488530158997
[20/24] Train loss=0.36371245980262756
Test set avg_accuracy=56.45% avg_sensitivity=69.17%, avg_specificity=52.21% avg_auc=65.78%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.410915 Test loss=0.673316 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3616522550582886
[5/24] Train loss=0.4117046892642975
[10/24] Train loss=0.3995097577571869
[15/24] Train loss=0.4136687219142914
[20/24] Train loss=0.3665139079093933
Test set avg_accuracy=65.31% avg_sensitivity=64.63%, avg_specificity=65.54% avg_auc=72.11%
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.410382 Test loss=0.601881 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.35933512449264526
[5/24] Train loss=0.39658376574516296
[10/24] Train loss=0.40430712699890137
[15/24] Train loss=0.41468939185142517
[20/24] Train loss=0.36061403155326843
Test set avg_accuracy=63.62% avg_sensitivity=60.88%, avg_specificity=64.53% avg_auc=68.60%
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.405887 Test loss=0.633141 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.35182833671569824
[5/24] Train loss=0.3897932469844818
[10/24] Train loss=0.38990455865859985
[15/24] Train loss=0.4072554111480713
[20/24] Train loss=0.3513992428779602
Test set avg_accuracy=57.57% avg_sensitivity=70.27%, avg_specificity=53.34% avg_auc=67.86%
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.397107 Test loss=0.656769 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.34894055128097534
[5/24] Train loss=0.38815703988075256
[10/24] Train loss=0.3863423466682434
[15/24] Train loss=0.4022477865219116
[20/24] Train loss=0.3486960530281067
Test set avg_accuracy=54.17% avg_sensitivity=62.81%, avg_specificity=51.29% avg_auc=62.94%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.392232 Test loss=0.666381 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.35164281725883484
[5/24] Train loss=0.37548747658729553
[10/24] Train loss=0.39574095606803894
[15/24] Train loss=0.40295061469078064
[20/24] Train loss=0.34256288409233093
Test set avg_accuracy=57.15% avg_sensitivity=62.91%, avg_specificity=55.23% avg_auc=62.92%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.389663 Test loss=0.667912 Current lr=[0.000210185142098938]

[0/24] Train loss=0.34647467732429504
[5/24] Train loss=0.3794565498828888
[10/24] Train loss=0.37994563579559326
[15/24] Train loss=0.3944007456302643
[20/24] Train loss=0.346220999956131
Test set avg_accuracy=59.28% avg_sensitivity=70.42%, avg_specificity=55.58% avg_auc=67.31%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.388357 Test loss=0.664857 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.34187114238739014
[5/24] Train loss=0.4014602303504944
[10/24] Train loss=0.3861858546733856
[15/24] Train loss=0.4036529064178467
[20/24] Train loss=0.3528590500354767
Test set avg_accuracy=67.70% avg_sensitivity=54.20%, avg_specificity=72.18% avg_auc=69.22%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.390994 Test loss=0.615092 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.341509073972702
[5/24] Train loss=0.37532490491867065
[10/24] Train loss=0.3802452087402344
[15/24] Train loss=0.3798747658729553
[20/24] Train loss=0.33407238125801086
Test set avg_accuracy=56.89% avg_sensitivity=63.28%, avg_specificity=54.76% avg_auc=64.63%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.383110 Test loss=0.661258 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3374997675418854
[5/24] Train loss=0.36668333411216736
[10/24] Train loss=0.37839290499687195
[15/24] Train loss=0.3742225170135498
[20/24] Train loss=0.33454158902168274
Test set avg_accuracy=55.96% avg_sensitivity=54.67%, avg_specificity=56.39% avg_auc=60.06%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.378794 Test loss=0.676156 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3449746370315552
[5/24] Train loss=0.3745374381542206
[10/24] Train loss=0.3703286647796631
[15/24] Train loss=0.36808156967163086
[20/24] Train loss=0.344342440366745
Test set avg_accuracy=56.25% avg_sensitivity=70.16%, avg_specificity=51.62% avg_auc=66.38%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.374534 Test loss=0.666208 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.33413323760032654
[5/24] Train loss=0.36189284920692444
[10/24] Train loss=0.37082725763320923
[15/24] Train loss=0.37724554538726807
[20/24] Train loss=0.3313066065311432
Test set avg_accuracy=50.20% avg_sensitivity=69.27%, avg_specificity=43.85% avg_auc=61.30%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.368780 Test loss=0.712243 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3300093412399292
[5/24] Train loss=0.36242011189460754
[10/24] Train loss=0.36902400851249695
[15/24] Train loss=0.3791986405849457
[20/24] Train loss=0.3248305916786194
Test set avg_accuracy=61.52% avg_sensitivity=58.69%, avg_specificity=62.47% avg_auc=65.38%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.367554 Test loss=0.644923 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.323454350233078
[5/24] Train loss=0.3564433455467224
[10/24] Train loss=0.35680797696113586
[15/24] Train loss=0.3567030131816864
[20/24] Train loss=0.30736175179481506
Test set avg_accuracy=57.32% avg_sensitivity=63.28%, avg_specificity=55.34% avg_auc=63.64%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.357059 Test loss=0.678308 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.32126784324645996
[5/24] Train loss=0.34348076581954956
[10/24] Train loss=0.36140206456184387
[15/24] Train loss=0.35945236682891846
[20/24] Train loss=0.3107219338417053
Test set avg_accuracy=64.23% avg_sensitivity=66.77%, avg_specificity=63.39% avg_auc=70.69%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.359124 Test loss=0.627119 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3102256953716278
[5/24] Train loss=0.36758953332901
[10/24] Train loss=0.361743301153183
[15/24] Train loss=0.3611503839492798
[20/24] Train loss=0.31443551182746887
Test set avg_accuracy=57.76% avg_sensitivity=64.53%, avg_specificity=55.51% avg_auc=66.81%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.358272 Test loss=0.637019 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3135477602481842
[5/24] Train loss=0.3510093092918396
[10/24] Train loss=0.3668845593929291
[15/24] Train loss=0.3534794747829437
[20/24] Train loss=0.3059912323951721
Test set avg_accuracy=47.67% avg_sensitivity=80.33%, avg_specificity=36.80% avg_auc=63.17%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.351396 Test loss=0.702980 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3106078505516052
[5/24] Train loss=0.33866381645202637
[10/24] Train loss=0.34688299894332886
[15/24] Train loss=0.3576603829860687
[20/24] Train loss=0.3036477565765381
Test set avg_accuracy=56.54% avg_sensitivity=74.60%, avg_specificity=50.53% avg_auc=69.37%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.347294 Test loss=0.654476 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.316946417093277
[5/24] Train loss=0.337178111076355
[10/24] Train loss=0.33931764960289
[15/24] Train loss=0.36229491233825684
[20/24] Train loss=0.30343830585479736
Test set avg_accuracy=48.31% avg_sensitivity=79.92%, avg_specificity=37.79% avg_auc=63.64%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.343910 Test loss=0.741504 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.2978048622608185
[5/24] Train loss=0.32671058177948
[10/24] Train loss=0.3450261354446411
[15/24] Train loss=0.3411829173564911
[20/24] Train loss=0.2947549521923065
Test set avg_accuracy=62.08% avg_sensitivity=66.51%, avg_specificity=60.61% avg_auc=69.35%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.339845 Test loss=0.629722 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.2952965497970581
[5/24] Train loss=0.3317257761955261
[10/24] Train loss=0.3395942449569702
[15/24] Train loss=0.3502037227153778
[20/24] Train loss=0.2905481457710266
Test set avg_accuracy=67.20% avg_sensitivity=40.48%, avg_specificity=76.09% avg_auc=64.42%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.338610 Test loss=0.610689 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.287484347820282
[5/24] Train loss=0.3260240852832794
[10/24] Train loss=0.3460400700569153
[15/24] Train loss=0.33354857563972473
[20/24] Train loss=0.29018962383270264
Test set avg_accuracy=55.65% avg_sensitivity=66.56%, avg_specificity=52.02% avg_auc=63.05%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.336078 Test loss=0.649846 Current lr=[0.00029967723776099]

[0/24] Train loss=0.2866562604904175
[5/24] Train loss=0.3294903039932251
[10/24] Train loss=0.33940625190734863
[15/24] Train loss=0.3436442017555237
[20/24] Train loss=0.2930489480495453
Test set avg_accuracy=66.61% avg_sensitivity=40.48%, avg_specificity=75.31% avg_auc=63.41%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.336053 Test loss=0.634242 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.31107211112976074
[5/24] Train loss=0.3328685164451599
[10/24] Train loss=0.3393632471561432
[15/24] Train loss=0.3361279368400574
[20/24] Train loss=0.290875107049942
Test set avg_accuracy=50.91% avg_sensitivity=65.52%, avg_specificity=46.05% avg_auc=58.76%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.337879 Test loss=0.738112 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.2926080822944641
[5/24] Train loss=0.326357364654541
[10/24] Train loss=0.33490079641342163
[15/24] Train loss=0.3226660490036011
[20/24] Train loss=0.2834967374801636
Test set avg_accuracy=62.51% avg_sensitivity=59.36%, avg_specificity=63.56% avg_auc=65.93%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.330723 Test loss=0.653128 Current lr=[0.000299720220882401]

[0/24] Train loss=0.29788726568222046
[5/24] Train loss=0.33358028531074524
[10/24] Train loss=0.36436569690704346
[15/24] Train loss=0.32715779542922974
[20/24] Train loss=0.3022790849208832
Test set avg_accuracy=66.93% avg_sensitivity=67.40%, avg_specificity=66.77% avg_auc=75.24%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.345123 Test loss=0.566442 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3041822016239166
[5/24] Train loss=0.34098052978515625
[10/24] Train loss=0.33877044916152954
[15/24] Train loss=0.3331090211868286
[20/24] Train loss=0.283953994512558
Test set avg_accuracy=55.73% avg_sensitivity=63.02%, avg_specificity=53.31% avg_auc=62.66%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.333291 Test loss=0.670078 Current lr=[0.000298904600941902]

[0/24] Train loss=0.28691282868385315
[5/24] Train loss=0.330621600151062
[10/24] Train loss=0.3378778398036957
[15/24] Train loss=0.325377494096756
[20/24] Train loss=0.27916234731674194
Test set avg_accuracy=61.45% avg_sensitivity=59.73%, avg_specificity=62.02% avg_auc=65.32%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.329199 Test loss=0.640033 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.28970086574554443
[5/24] Train loss=0.3331729471683502
[10/24] Train loss=0.3327638804912567
[15/24] Train loss=0.3369881808757782
[20/24] Train loss=0.2948927581310272
Test set avg_accuracy=63.74% avg_sensitivity=65.68%, avg_specificity=63.09% avg_auc=69.14%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.335660 Test loss=0.605845 Current lr=[0.000297555943323901]

[0/24] Train loss=0.28045448660850525
[5/24] Train loss=0.339798241853714
[10/24] Train loss=0.3467858135700226
[15/24] Train loss=0.319446861743927
[20/24] Train loss=0.2863370478153229
Test set avg_accuracy=77.02% avg_sensitivity=45.75%, avg_specificity=87.42% avg_auc=74.43%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.333978 Test loss=0.501434 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.2812310457229614
[5/24] Train loss=0.33450087904930115
[10/24] Train loss=0.33611929416656494
[15/24] Train loss=0.3186061382293701
[20/24] Train loss=0.29209068417549133
Test set avg_accuracy=68.71% avg_sensitivity=32.55%, avg_specificity=80.74% avg_auc=65.05%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.331907 Test loss=0.574389 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.28724345564842224
[5/24] Train loss=0.3183402121067047
[10/24] Train loss=0.3289223909378052
[15/24] Train loss=0.32133129239082336
[20/24] Train loss=0.27459049224853516
Test set avg_accuracy=57.06% avg_sensitivity=57.54%, avg_specificity=56.90% avg_auc=62.10%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.322202 Test loss=0.675326 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.27587658166885376
[5/24] Train loss=0.3149041533470154
[10/24] Train loss=0.3370577096939087
[15/24] Train loss=0.32347044348716736
[20/24] Train loss=0.2867841124534607
Test set avg_accuracy=60.91% avg_sensitivity=70.53%, avg_specificity=57.71% avg_auc=68.72%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.321145 Test loss=0.641882 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.28228920698165894
[5/24] Train loss=0.3183041512966156
[10/24] Train loss=0.3248683512210846
[15/24] Train loss=0.31536728143692017
[20/24] Train loss=0.2965323328971863
Test set avg_accuracy=70.46% avg_sensitivity=42.93%, avg_specificity=79.61% avg_auc=69.66%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.323425 Test loss=0.553641 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.2813085615634918
[5/24] Train loss=0.3104892075061798
[10/24] Train loss=0.32898515462875366
[15/24] Train loss=0.31044477224349976
[20/24] Train loss=0.2736406922340393
Test set avg_accuracy=78.93% avg_sensitivity=26.40%, avg_specificity=96.41% avg_auc=72.68%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.320381 Test loss=0.547965 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.28966790437698364
[5/24] Train loss=0.32850685715675354
[10/24] Train loss=0.3279440104961395
[15/24] Train loss=0.3130023777484894
[20/24] Train loss=0.28402674198150635
Test set avg_accuracy=67.73% avg_sensitivity=27.75%, avg_specificity=81.03% avg_auc=60.05%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.327139 Test loss=0.603439 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.285369873046875
[5/24] Train loss=0.32770588994026184
[10/24] Train loss=0.33422043919563293
[15/24] Train loss=0.31636330485343933
[20/24] Train loss=0.2720832824707031
Test set avg_accuracy=54.66% avg_sensitivity=73.97%, avg_specificity=48.24% avg_auc=64.86%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.317621 Test loss=0.680586 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2796916365623474
[5/24] Train loss=0.3136104345321655
[10/24] Train loss=0.30932632088661194
[15/24] Train loss=0.31506308913230896
[20/24] Train loss=0.273112416267395
Test set avg_accuracy=58.50% avg_sensitivity=67.29%, avg_specificity=55.58% avg_auc=65.94%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.312923 Test loss=0.635194 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.27369198203086853
[5/24] Train loss=0.30995649099349976
[10/24] Train loss=0.316267728805542
[15/24] Train loss=0.30575114488601685
[20/24] Train loss=0.27258965373039246
Test set avg_accuracy=79.67% avg_sensitivity=49.03%, avg_specificity=89.87% avg_auc=78.10%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.314817 Test loss=0.498915 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.27481693029403687
[5/24] Train loss=0.3052860200405121
[10/24] Train loss=0.3287792205810547
[15/24] Train loss=0.3083215653896332
[20/24] Train loss=0.2765143811702728
Test set avg_accuracy=61.82% avg_sensitivity=69.27%, avg_specificity=59.34% avg_auc=70.34%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.312270 Test loss=0.597516 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2644551396369934
[5/24] Train loss=0.30577340722084045
[10/24] Train loss=0.3061448037624359
[15/24] Train loss=0.2978607714176178
[20/24] Train loss=0.2697369456291199
Test set avg_accuracy=60.46% avg_sensitivity=51.54%, avg_specificity=63.42% avg_auc=61.41%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.303054 Test loss=0.638688 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2630156874656677
[5/24] Train loss=0.29581430554389954
[10/24] Train loss=0.3077837824821472
[15/24] Train loss=0.30032819509506226
[20/24] Train loss=0.25884366035461426
Test set avg_accuracy=63.40% avg_sensitivity=54.72%, avg_specificity=66.28% avg_auc=65.72%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.302287 Test loss=0.625855 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2522065043449402
[5/24] Train loss=0.30864042043685913
[10/24] Train loss=0.3112064599990845
[15/24] Train loss=0.30536606907844543
[20/24] Train loss=0.2577643096446991
Test set avg_accuracy=61.60% avg_sensitivity=55.97%, avg_specificity=63.47% avg_auc=64.96%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.299611 Test loss=0.635505 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.27716585993766785
[5/24] Train loss=0.30742183327674866
[10/24] Train loss=0.31670287251472473
[15/24] Train loss=0.29179319739341736
[20/24] Train loss=0.267446905374527
Test set avg_accuracy=81.63% avg_sensitivity=44.50%, avg_specificity=93.98% avg_auc=83.94%
Best model saved!! Metric=-21.958187444977092!!
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.303917 Test loss=0.413791 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.28020015358924866
[5/24] Train loss=0.3008611798286438
[10/24] Train loss=0.3195979595184326
[15/24] Train loss=0.29208239912986755
[20/24] Train loss=0.27492380142211914
Test set avg_accuracy=75.73% avg_sensitivity=12.31%, avg_specificity=96.82% avg_auc=71.79%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.312515 Test loss=0.509079 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.27350640296936035
[5/24] Train loss=0.34041303396224976
[10/24] Train loss=0.32196229696273804
[15/24] Train loss=0.3109641671180725
[20/24] Train loss=0.26278072595596313
Test set avg_accuracy=73.74% avg_sensitivity=13.62%, avg_specificity=93.74% avg_auc=63.19%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.306481 Test loss=0.555782 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2531726658344269
[5/24] Train loss=0.3135627210140228
[10/24] Train loss=0.30619826912879944
[15/24] Train loss=0.3008650541305542
[20/24] Train loss=0.2737990915775299
Test set avg_accuracy=55.86% avg_sensitivity=62.49%, avg_specificity=53.65% avg_auc=61.53%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.298353 Test loss=0.702152 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.250022292137146
[5/24] Train loss=0.3150688409805298
[10/24] Train loss=0.30228495597839355
[15/24] Train loss=0.29243147373199463
[20/24] Train loss=0.257508248090744
Test set avg_accuracy=67.60% avg_sensitivity=51.70%, avg_specificity=72.90% avg_auc=69.69%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.296146 Test loss=0.576755 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.24800778925418854
[5/24] Train loss=0.29113757610321045
[10/24] Train loss=0.32030558586120605
[15/24] Train loss=0.30551254749298096
[20/24] Train loss=0.26301416754722595
Test set avg_accuracy=60.47% avg_sensitivity=46.06%, avg_specificity=65.26% avg_auc=61.20%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.304318 Test loss=0.631215 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.26448488235473633
[5/24] Train loss=0.2868768274784088
[10/24] Train loss=0.3120308220386505
[15/24] Train loss=0.29672789573669434
[20/24] Train loss=0.25492292642593384
Test set avg_accuracy=52.50% avg_sensitivity=73.29%, avg_specificity=45.58% avg_auc=62.77%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.296352 Test loss=0.703239 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2479146122932434
[5/24] Train loss=0.293483167886734
[10/24] Train loss=0.30365321040153503
[15/24] Train loss=0.2974717617034912
[20/24] Train loss=0.2606901526451111
Test set avg_accuracy=67.03% avg_sensitivity=42.25%, avg_specificity=75.27% avg_auc=67.22%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.293169 Test loss=0.610864 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2506515383720398
[5/24] Train loss=0.2984539866447449
[10/24] Train loss=0.30283123254776
[15/24] Train loss=0.284932941198349
[20/24] Train loss=0.2532813847064972
Test set avg_accuracy=75.86% avg_sensitivity=42.72%, avg_specificity=86.88% avg_auc=75.07%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.293645 Test loss=0.505501 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.26110607385635376
[5/24] Train loss=0.286683589220047
[10/24] Train loss=0.3067249357700348
[15/24] Train loss=0.3032585382461548
[20/24] Train loss=0.2541671395301819
Test set avg_accuracy=52.58% avg_sensitivity=77.10%, avg_specificity=44.42% avg_auc=62.19%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.292953 Test loss=0.740628 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.24924908578395844
[5/24] Train loss=0.29258254170417786
[10/24] Train loss=0.29895803332328796
[15/24] Train loss=0.30209243297576904
[20/24] Train loss=0.25313204526901245
Test set avg_accuracy=46.72% avg_sensitivity=85.45%, avg_specificity=33.84% avg_auc=62.44%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.291676 Test loss=0.810023 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.24638578295707703
[5/24] Train loss=0.28807273507118225
[10/24] Train loss=0.29760387539863586
[15/24] Train loss=0.28099945187568665
[20/24] Train loss=0.25660163164138794
Test set avg_accuracy=59.01% avg_sensitivity=65.88%, avg_specificity=56.72% avg_auc=66.31%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.285000 Test loss=0.644292 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.24142992496490479
[5/24] Train loss=0.2875351011753082
[10/24] Train loss=0.3018052279949188
[15/24] Train loss=0.28427261114120483
[20/24] Train loss=0.2471180260181427
Test set avg_accuracy=54.84% avg_sensitivity=77.15%, avg_specificity=47.42% avg_auc=66.94%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.285502 Test loss=0.680735 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.23394350707530975
[5/24] Train loss=0.2900744378566742
[10/24] Train loss=0.3052305281162262
[15/24] Train loss=0.28981471061706543
[20/24] Train loss=0.2442834973335266
Test set avg_accuracy=61.67% avg_sensitivity=63.69%, avg_specificity=60.99% avg_auc=68.00%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.285902 Test loss=0.667491 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.23894870281219482
[5/24] Train loss=0.2874852418899536
[10/24] Train loss=0.2891313135623932
[15/24] Train loss=0.2829497754573822
[20/24] Train loss=0.24663472175598145
Test set avg_accuracy=57.17% avg_sensitivity=59.47%, avg_specificity=56.41% avg_auc=62.13%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.281781 Test loss=0.701780 Current lr=[0.000224838296036774]

[0/24] Train loss=0.23417505621910095
[5/24] Train loss=0.27494388818740845
[10/24] Train loss=0.2988564968109131
[15/24] Train loss=0.28776776790618896
[20/24] Train loss=0.2519162893295288
Test set avg_accuracy=57.67% avg_sensitivity=64.16%, avg_specificity=55.51% avg_auc=64.53%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.284622 Test loss=0.683923 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.23358938097953796
[5/24] Train loss=0.29156655073165894
[10/24] Train loss=0.31197890639305115
[15/24] Train loss=0.2918430268764496
[20/24] Train loss=0.25013771653175354
Test set avg_accuracy=57.62% avg_sensitivity=60.82%, avg_specificity=56.55% avg_auc=61.90%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.285930 Test loss=0.698852 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.23374618589878082
[5/24] Train loss=0.29519975185394287
[10/24] Train loss=0.2846772074699402
[15/24] Train loss=0.2845599353313446
[20/24] Train loss=0.255770206451416
Test set avg_accuracy=61.56% avg_sensitivity=53.26%, avg_specificity=64.32% avg_auc=63.60%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.285704 Test loss=0.641218 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2351633608341217
[5/24] Train loss=0.2805343270301819
[10/24] Train loss=0.2946261763572693
[15/24] Train loss=0.284900426864624
[20/24] Train loss=0.24537256360054016
Test set avg_accuracy=60.21% avg_sensitivity=37.40%, avg_specificity=67.79% avg_auc=58.34%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.283608 Test loss=0.626955 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2462981641292572
[5/24] Train loss=0.27604424953460693
[10/24] Train loss=0.2909303903579712
[15/24] Train loss=0.27205684781074524
[20/24] Train loss=0.24636755883693695
Test set avg_accuracy=50.00% avg_sensitivity=78.98%, avg_specificity=40.36% avg_auc=62.46%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.278497 Test loss=0.730284 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2235172986984253
[5/24] Train loss=0.2770640254020691
[10/24] Train loss=0.2826180160045624
[15/24] Train loss=0.2683010995388031
[20/24] Train loss=0.24067144095897675
Test set avg_accuracy=48.57% avg_sensitivity=78.87%, avg_specificity=38.49% avg_auc=60.30%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.276016 Test loss=0.853104 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.24221087992191315
[5/24] Train loss=0.27628105878829956
[10/24] Train loss=0.2947062849998474
[15/24] Train loss=0.27371570467948914
[20/24] Train loss=0.2418355643749237
Test set avg_accuracy=52.86% avg_sensitivity=77.62%, avg_specificity=44.63% avg_auc=63.75%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.273212 Test loss=0.794236 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.23998090624809265
[5/24] Train loss=0.27028918266296387
[10/24] Train loss=0.2825540006160736
[15/24] Train loss=0.26692402362823486
[20/24] Train loss=0.23992694914340973
Test set avg_accuracy=58.92% avg_sensitivity=70.63%, avg_specificity=55.02% avg_auc=67.74%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.277744 Test loss=0.671442 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.23072506487369537
[5/24] Train loss=0.2774420976638794
[10/24] Train loss=0.2914777398109436
[15/24] Train loss=0.2701679468154907
[20/24] Train loss=0.24062994122505188
Test set avg_accuracy=75.81% avg_sensitivity=50.34%, avg_specificity=84.28% avg_auc=74.80%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.276404 Test loss=0.519960 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2318747341632843
[5/24] Train loss=0.288211464881897
[10/24] Train loss=0.2986801862716675
[15/24] Train loss=0.2656043469905853
[20/24] Train loss=0.24344921112060547
Test set avg_accuracy=65.62% avg_sensitivity=45.75%, avg_specificity=72.24% avg_auc=66.00%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.275218 Test loss=0.603756 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.231585294008255
[5/24] Train loss=0.28180843591690063
[10/24] Train loss=0.27448713779449463
[15/24] Train loss=0.2646559476852417
[20/24] Train loss=0.23637604713439941
Test set avg_accuracy=55.92% avg_sensitivity=59.89%, avg_specificity=54.61% avg_auc=60.89%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.267709 Test loss=0.718256 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.23005767166614532
[5/24] Train loss=0.286302387714386
[10/24] Train loss=0.2710154354572296
[15/24] Train loss=0.2652601897716522
[20/24] Train loss=0.2354453057050705
Test set avg_accuracy=59.84% avg_sensitivity=56.49%, avg_specificity=60.96% avg_auc=63.53%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.270127 Test loss=0.668209 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.22784169018268585
[5/24] Train loss=0.26772260665893555
[10/24] Train loss=0.2679784893989563
[15/24] Train loss=0.2630143463611603
[20/24] Train loss=0.25625887513160706
Test set avg_accuracy=64.18% avg_sensitivity=66.56%, avg_specificity=63.39% avg_auc=72.19%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.264938 Test loss=0.585631 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.22745905816555023
[5/24] Train loss=0.25966015458106995
[10/24] Train loss=0.2662232220172882
[15/24] Train loss=0.25429782271385193
[20/24] Train loss=0.23303987085819244
Test set avg_accuracy=67.17% avg_sensitivity=33.39%, avg_specificity=78.41% avg_auc=60.68%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.264515 Test loss=0.641341 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.21975629031658173
[5/24] Train loss=0.2712511420249939
[10/24] Train loss=0.2656477093696594
[15/24] Train loss=0.2659885287284851
[20/24] Train loss=0.23455999791622162
Test set avg_accuracy=59.43% avg_sensitivity=46.01%, avg_specificity=63.89% avg_auc=60.44%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.264066 Test loss=0.678591 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.22234049439430237
[5/24] Train loss=0.25141066312789917
[10/24] Train loss=0.2696682810783386
[15/24] Train loss=0.26602858304977417
[20/24] Train loss=0.24681808054447174
Test set avg_accuracy=60.17% avg_sensitivity=52.74%, avg_specificity=62.64% avg_auc=61.91%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.268605 Test loss=0.729801 Current lr=[0.000156543481933168]

[0/24] Train loss=0.22088408470153809
[5/24] Train loss=0.2628350257873535
[10/24] Train loss=0.2779999375343323
[15/24] Train loss=0.2582102417945862
[20/24] Train loss=0.23068693280220032
Test set avg_accuracy=58.23% avg_sensitivity=64.95%, avg_specificity=56.00% avg_auc=64.06%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.268055 Test loss=0.714346 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2241944819688797
[5/24] Train loss=0.2903952896595001
[10/24] Train loss=0.280958354473114
[15/24] Train loss=0.25971516966819763
[20/24] Train loss=0.22781439125537872
Test set avg_accuracy=58.88% avg_sensitivity=51.54%, avg_specificity=61.32% avg_auc=62.10%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.265852 Test loss=0.680233 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.21874850988388062
[5/24] Train loss=0.25853851437568665
[10/24] Train loss=0.2777349650859833
[15/24] Train loss=0.2527660131454468
[20/24] Train loss=0.22872376441955566
Test set avg_accuracy=54.60% avg_sensitivity=58.58%, avg_specificity=53.27% avg_auc=60.74%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.255047 Test loss=0.716282 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.21607238054275513
[5/24] Train loss=0.2645217478275299
[10/24] Train loss=0.2610592246055603
[15/24] Train loss=0.2426932454109192
[20/24] Train loss=0.220598965883255
Test set avg_accuracy=52.57% avg_sensitivity=64.84%, avg_specificity=48.48% avg_auc=61.25%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.250259 Test loss=0.735169 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.20715993642807007
[5/24] Train loss=0.27745750546455383
[10/24] Train loss=0.2538154125213623
[15/24] Train loss=0.24156464636325836
[20/24] Train loss=0.22303441166877747
Test set avg_accuracy=65.79% avg_sensitivity=41.52%, avg_specificity=73.87% avg_auc=62.01%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.248983 Test loss=0.666162 Current lr=[0.000134135431043539]

[0/24] Train loss=0.20557276904582977
[5/24] Train loss=0.25706663727760315
[10/24] Train loss=0.252867192029953
[15/24] Train loss=0.24053741991519928
[20/24] Train loss=0.22652804851531982
Test set avg_accuracy=62.30% avg_sensitivity=47.63%, avg_specificity=67.19% avg_auc=63.43%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.247460 Test loss=0.668991 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2016029804944992
[5/24] Train loss=0.25014254450798035
[10/24] Train loss=0.2588094174861908
[15/24] Train loss=0.24495132267475128
[20/24] Train loss=0.21804505586624146
Test set avg_accuracy=57.04% avg_sensitivity=56.86%, avg_specificity=57.11% avg_auc=62.79%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.247873 Test loss=0.674808 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.20563308894634247
[5/24] Train loss=0.25435733795166016
[10/24] Train loss=0.26329004764556885
[15/24] Train loss=0.23872214555740356
[20/24] Train loss=0.21258796751499176
Test set avg_accuracy=58.54% avg_sensitivity=48.30%, avg_specificity=61.95% avg_auc=59.93%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.246467 Test loss=0.733070 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.21099339425563812
[5/24] Train loss=0.25363582372665405
[10/24] Train loss=0.2501714527606964
[15/24] Train loss=0.23182269930839539
[20/24] Train loss=0.21748998761177063
Test set avg_accuracy=64.38% avg_sensitivity=36.72%, avg_specificity=73.57% avg_auc=60.27%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.244680 Test loss=0.672322 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2121427059173584
[5/24] Train loss=0.23822680115699768
[10/24] Train loss=0.2641829550266266
[15/24] Train loss=0.23272310197353363
[20/24] Train loss=0.2125897854566574
Test set avg_accuracy=55.39% avg_sensitivity=68.18%, avg_specificity=51.14% avg_auc=63.52%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.242917 Test loss=0.754197 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.200004443526268
[5/24] Train loss=0.2389875054359436
[10/24] Train loss=0.24741946160793304
[15/24] Train loss=0.2421586513519287
[20/24] Train loss=0.22823584079742432
Test set avg_accuracy=58.44% avg_sensitivity=56.76%, avg_specificity=59.00% avg_auc=63.97%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.243206 Test loss=0.662709 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.20684030652046204
[5/24] Train loss=0.24756178259849548
[10/24] Train loss=0.2507736384868622
[15/24] Train loss=0.23395667970180511
[20/24] Train loss=0.21829834580421448
Test set avg_accuracy=67.37% avg_sensitivity=30.57%, avg_specificity=79.61% avg_auc=59.62%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.241233 Test loss=0.660911 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.20431335270404816
[5/24] Train loss=0.2328554093837738
[10/24] Train loss=0.25252339243888855
[15/24] Train loss=0.23045264184474945
[20/24] Train loss=0.2062201201915741
Test set avg_accuracy=55.82% avg_sensitivity=55.61%, avg_specificity=55.89% avg_auc=60.17%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.237709 Test loss=0.755411 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.20316408574581146
[5/24] Train loss=0.23461641371250153
[10/24] Train loss=0.24983786046504974
[15/24] Train loss=0.2265380620956421
[20/24] Train loss=0.20127898454666138
Test set avg_accuracy=63.02% avg_sensitivity=41.99%, avg_specificity=70.02% avg_auc=61.88%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.235036 Test loss=0.689918 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.19862066209316254
[5/24] Train loss=0.2361414134502411
[10/24] Train loss=0.2401556521654129
[15/24] Train loss=0.24255982041358948
[20/24] Train loss=0.19973596930503845
Test set avg_accuracy=65.68% avg_sensitivity=36.25%, avg_specificity=75.46% avg_auc=61.50%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.233818 Test loss=0.679205 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.20074136555194855
[5/24] Train loss=0.240275576710701
[10/24] Train loss=0.23295758664608002
[15/24] Train loss=0.23485875129699707
[20/24] Train loss=0.2019326388835907
Test set avg_accuracy=62.85% avg_sensitivity=39.70%, avg_specificity=70.55% avg_auc=58.73%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.231011 Test loss=0.706015 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.19494083523750305
[5/24] Train loss=0.2284976989030838
[10/24] Train loss=0.24035583436489105
[15/24] Train loss=0.22979199886322021
[20/24] Train loss=0.19825297594070435
Test set avg_accuracy=58.01% avg_sensitivity=60.30%, avg_specificity=57.24% avg_auc=63.45%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.230307 Test loss=0.760849 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.195634663105011
[5/24] Train loss=0.22790546715259552
[10/24] Train loss=0.24565105140209198
[15/24] Train loss=0.2240617722272873
[20/24] Train loss=0.19974151253700256
Test set avg_accuracy=56.25% avg_sensitivity=51.33%, avg_specificity=57.89% avg_auc=59.73%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.231140 Test loss=0.735598 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.19870665669441223
[5/24] Train loss=0.23704305291175842
[10/24] Train loss=0.23978355526924133
[15/24] Train loss=0.22921450436115265
[20/24] Train loss=0.1967131346464157
Test set avg_accuracy=54.83% avg_sensitivity=67.55%, avg_specificity=50.60% avg_auc=63.63%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.229662 Test loss=0.747644 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1969616413116455
[5/24] Train loss=0.23148766160011292
[10/24] Train loss=0.26711326837539673
[15/24] Train loss=0.22339026629924774
[20/24] Train loss=0.1977565884590149
Test set avg_accuracy=65.29% avg_sensitivity=61.87%, avg_specificity=66.42% avg_auc=70.23%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.234893 Test loss=0.616644 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1978321075439453
[5/24] Train loss=0.22947804629802704
[10/24] Train loss=0.24525457620620728
[15/24] Train loss=0.23488418757915497
[20/24] Train loss=0.19863548874855042
Test set avg_accuracy=73.15% avg_sensitivity=68.49%, avg_specificity=74.70% avg_auc=78.91%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.233984 Test loss=0.533162 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.2038804143667221
[5/24] Train loss=0.2401171177625656
[10/24] Train loss=0.2387838214635849
[15/24] Train loss=0.24219341576099396
[20/24] Train loss=0.20392411947250366
Test set avg_accuracy=72.07% avg_sensitivity=60.51%, avg_specificity=75.92% avg_auc=75.88%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.235736 Test loss=0.548273 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.19986265897750854
[5/24] Train loss=0.24492140114307404
[10/24] Train loss=0.24185392260551453
[15/24] Train loss=0.23633837699890137
[20/24] Train loss=0.21463757753372192
Test set avg_accuracy=67.43% avg_sensitivity=49.71%, avg_specificity=73.33% avg_auc=68.34%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.238782 Test loss=0.609794 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.201921284198761
[5/24] Train loss=0.23009629547595978
[10/24] Train loss=0.23703189194202423
[15/24] Train loss=0.22392913699150085
[20/24] Train loss=0.19436992704868317
Test set avg_accuracy=55.94% avg_sensitivity=48.36%, avg_specificity=58.46% avg_auc=60.40%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.230675 Test loss=0.718811 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1934930831193924
[5/24] Train loss=0.2223455160856247
[10/24] Train loss=0.22972293198108673
[15/24] Train loss=0.21347253024578094
[20/24] Train loss=0.19230513274669647
Test set avg_accuracy=59.71% avg_sensitivity=52.69%, avg_specificity=62.05% avg_auc=62.64%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.221533 Test loss=0.764531 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18978135287761688
[5/24] Train loss=0.21918688714504242
[10/24] Train loss=0.23340095579624176
[15/24] Train loss=0.2110675573348999
[20/24] Train loss=0.18110641837120056
Test set avg_accuracy=61.64% avg_sensitivity=52.16%, avg_specificity=64.79% avg_auc=64.34%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.217745 Test loss=0.734067 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1879560500383377
[5/24] Train loss=0.2209395468235016
[10/24] Train loss=0.2266397774219513
[15/24] Train loss=0.20929981768131256
[20/24] Train loss=0.18098725378513336
Test set avg_accuracy=59.01% avg_sensitivity=56.86%, avg_specificity=59.73% avg_auc=63.59%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.216061 Test loss=0.761101 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.18091733753681183
[5/24] Train loss=0.2135312706232071
[10/24] Train loss=0.221698597073555
[15/24] Train loss=0.205140620470047
[20/24] Train loss=0.1787266880273819
Test set avg_accuracy=60.22% avg_sensitivity=57.22%, avg_specificity=61.22% avg_auc=65.73%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.213406 Test loss=0.693806 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.18130211532115936
[5/24] Train loss=0.21713513135910034
[10/24] Train loss=0.21906974911689758
[15/24] Train loss=0.21232320368289948
[20/24] Train loss=0.1838659644126892
Test set avg_accuracy=59.32% avg_sensitivity=61.71%, avg_specificity=58.53% avg_auc=65.82%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.211455 Test loss=0.712650 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.17544971406459808
[5/24] Train loss=0.21652846038341522
[10/24] Train loss=0.21735380589962006
[15/24] Train loss=0.2085326611995697
[20/24] Train loss=0.1854289174079895
Test set avg_accuracy=59.18% avg_sensitivity=61.24%, avg_specificity=58.49% avg_auc=65.06%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.211364 Test loss=0.744294 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.17778877913951874
[5/24] Train loss=0.21421074867248535
[10/24] Train loss=0.21963202953338623
[15/24] Train loss=0.20233647525310516
[20/24] Train loss=0.17799998819828033
Test set avg_accuracy=58.91% avg_sensitivity=52.01%, avg_specificity=61.20% avg_auc=62.84%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.208984 Test loss=0.725015 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.18019352853298187
[5/24] Train loss=0.2107231616973877
[10/24] Train loss=0.2164383977651596
[15/24] Train loss=0.20196205377578735
[20/24] Train loss=0.1733306646347046
Test set avg_accuracy=58.37% avg_sensitivity=55.71%, avg_specificity=59.26% avg_auc=63.55%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.209017 Test loss=0.728167 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.1749294102191925
[5/24] Train loss=0.21927198767662048
[10/24] Train loss=0.2159949392080307
[15/24] Train loss=0.20095738768577576
[20/24] Train loss=0.17754188179969788
Test set avg_accuracy=59.75% avg_sensitivity=56.81%, avg_specificity=60.73% avg_auc=64.93%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.208694 Test loss=0.731955 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18163371086120605
[5/24] Train loss=0.21487832069396973
[10/24] Train loss=0.2224656194448471
[15/24] Train loss=0.1999431699514389
[20/24] Train loss=0.17540757358074188
Test set avg_accuracy=58.84% avg_sensitivity=58.06%, avg_specificity=59.10% avg_auc=64.39%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.207318 Test loss=0.739404 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.17847666144371033
[5/24] Train loss=0.20616748929023743
[10/24] Train loss=0.21100470423698425
[15/24] Train loss=0.20312558114528656
[20/24] Train loss=0.1710684895515442
Test set avg_accuracy=58.24% avg_sensitivity=56.81%, avg_specificity=58.72% avg_auc=63.95%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.204987 Test loss=0.745035 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.17845991253852844
[5/24] Train loss=0.20191797614097595
[10/24] Train loss=0.20904392004013062
[15/24] Train loss=0.19817817211151123
[20/24] Train loss=0.1741829365491867
Test set avg_accuracy=61.85% avg_sensitivity=52.32%, avg_specificity=65.02% avg_auc=63.85%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.203759 Test loss=0.730781 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.17512834072113037
[5/24] Train loss=0.20852163434028625
[10/24] Train loss=0.21465592086315155
[15/24] Train loss=0.19346222281455994
[20/24] Train loss=0.1710149496793747
Test set avg_accuracy=61.25% avg_sensitivity=53.05%, avg_specificity=63.98% avg_auc=64.37%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.204454 Test loss=0.720949 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1744752675294876
[5/24] Train loss=0.21113723516464233
[10/24] Train loss=0.20880091190338135
[15/24] Train loss=0.19271916151046753
[20/24] Train loss=0.17608262598514557
Test set avg_accuracy=61.16% avg_sensitivity=54.20%, avg_specificity=63.47% avg_auc=65.10%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.204001 Test loss=0.718978 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1766064316034317
[5/24] Train loss=0.2047395557165146
[10/24] Train loss=0.21316270530223846
[15/24] Train loss=0.19745676219463348
[20/24] Train loss=0.17234227061271667
Test set avg_accuracy=60.07% avg_sensitivity=53.52%, avg_specificity=62.24% avg_auc=64.11%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.202828 Test loss=0.734121 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1694587618112564
[5/24] Train loss=0.2017550766468048
[10/24] Train loss=0.20891235768795013
[15/24] Train loss=0.19497202336788177
[20/24] Train loss=0.16959407925605774
Test set avg_accuracy=60.08% avg_sensitivity=54.72%, avg_specificity=61.86% avg_auc=65.03%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.201945 Test loss=0.711595 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.17283043265342712
[5/24] Train loss=0.20748691260814667
[10/24] Train loss=0.20765221118927002
[15/24] Train loss=0.1956051141023636
[20/24] Train loss=0.17045532166957855
Test set avg_accuracy=59.66% avg_sensitivity=53.47%, avg_specificity=61.72% avg_auc=64.29%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.201888 Test loss=0.729902 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.17051516473293304
[5/24] Train loss=0.20603345334529877
[10/24] Train loss=0.20519864559173584
[15/24] Train loss=0.19565331935882568
[20/24] Train loss=0.17045851051807404
Test set avg_accuracy=61.11% avg_sensitivity=52.63%, avg_specificity=63.93% avg_auc=64.50%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.200619 Test loss=0.729011 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.17651695013046265
[5/24] Train loss=0.2057027965784073
[10/24] Train loss=0.20587891340255737
[15/24] Train loss=0.20063108205795288
[20/24] Train loss=0.17102821171283722
Test set avg_accuracy=59.99% avg_sensitivity=54.51%, avg_specificity=61.81% avg_auc=65.10%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.201427 Test loss=0.712950 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.17298811674118042
[5/24] Train loss=0.20987381041049957
[10/24] Train loss=0.2115282267332077
[15/24] Train loss=0.19420485198497772
[20/24] Train loss=0.16815049946308136
Test set avg_accuracy=60.13% avg_sensitivity=54.30%, avg_specificity=62.07% avg_auc=64.67%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.200667 Test loss=0.723538 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17412346601486206
[5/24] Train loss=0.19580714404582977
[10/24] Train loss=0.20569923520088196
[15/24] Train loss=0.19064007699489594
[20/24] Train loss=0.16798831522464752
Test set avg_accuracy=61.95% avg_sensitivity=52.79%, avg_specificity=65.00% avg_auc=65.27%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.200000 Test loss=0.710382 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1731613576412201
[5/24] Train loss=0.2020615041255951
[10/24] Train loss=0.20910733938217163
[15/24] Train loss=0.19282463192939758
[20/24] Train loss=0.16930058598518372
Test set avg_accuracy=62.45% avg_sensitivity=51.70%, avg_specificity=66.02% avg_auc=64.70%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.200145 Test loss=0.722528 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.17030300199985504
[5/24] Train loss=0.2063867300748825
[10/24] Train loss=0.2086775302886963
[15/24] Train loss=0.18935222923755646
[20/24] Train loss=0.16912297904491425
Test set avg_accuracy=61.77% avg_sensitivity=52.11%, avg_specificity=64.98% avg_auc=64.75%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.199458 Test loss=0.720671 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.17157681286334991
[5/24] Train loss=0.19845369458198547
[10/24] Train loss=0.20497408509254456
[15/24] Train loss=0.1870964616537094
[20/24] Train loss=0.1688256412744522
Test set avg_accuracy=61.47% avg_sensitivity=51.96%, avg_specificity=64.64% avg_auc=64.54%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.198369 Test loss=0.718764 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.17279252409934998
[5/24] Train loss=0.20191924273967743
[10/24] Train loss=0.20433367788791656
[15/24] Train loss=0.19004978239536285
[20/24] Train loss=0.16942603886127472
Test set avg_accuracy=61.18% avg_sensitivity=52.58%, avg_specificity=64.05% avg_auc=64.93%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.199058 Test loss=0.714464 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1730513870716095
[5/24] Train loss=0.20916293561458588
[10/24] Train loss=0.20334884524345398
[15/24] Train loss=0.18750567734241486
[20/24] Train loss=0.1718934178352356
Test set avg_accuracy=61.28% avg_sensitivity=52.53%, avg_specificity=64.19% avg_auc=64.90%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.198619 Test loss=0.717037 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.17028482258319855
[5/24] Train loss=0.19591264426708221
[10/24] Train loss=0.2077627032995224
[15/24] Train loss=0.19127821922302246
[20/24] Train loss=0.17235679924488068
Test set avg_accuracy=60.91% avg_sensitivity=53.36%, avg_specificity=63.42% avg_auc=65.29%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.199046 Test loss=0.712170 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16993987560272217
[5/24] Train loss=0.20230679214000702
[10/24] Train loss=0.20090961456298828
[15/24] Train loss=0.19416914880275726
[20/24] Train loss=0.16642728447914124
Test set avg_accuracy=61.74% avg_sensitivity=51.49%, avg_specificity=65.16% avg_auc=64.28%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.199421 Test loss=0.723613 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.17449970543384552
[5/24] Train loss=0.1999940276145935
[10/24] Train loss=0.20248736441135406
[15/24] Train loss=0.18944105505943298
[20/24] Train loss=0.16666094958782196
Test set avg_accuracy=61.55% avg_sensitivity=51.96%, avg_specificity=64.74% avg_auc=64.50%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.198883 Test loss=0.721547 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.16998343169689178
[5/24] Train loss=0.20562277734279633
[10/24] Train loss=0.20414172112941742
[15/24] Train loss=0.1890171766281128
[20/24] Train loss=0.16447986662387848
Test set avg_accuracy=61.43% avg_sensitivity=52.27%, avg_specificity=64.48% avg_auc=64.64%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.199405 Test loss=0.720435 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=81.63% sen=44.50%, spe=93.98%, auc=83.94%!
Fold[2] Avg_overlap=0.47%(±0.3306206786678072)
[0/24] Train loss=0.7575594782829285
[5/24] Train loss=0.7529913783073425
[10/24] Train loss=0.7481722831726074
[15/24] Train loss=0.7478055357933044
[20/24] Train loss=0.7573655247688293
Test set avg_accuracy=51.11% avg_sensitivity=46.07%, avg_specificity=53.02% avg_auc=49.91%
Best model saved!! Metric=-125.90412878973198!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=0.752045 Test loss=0.702359 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7477757930755615
[5/24] Train loss=0.743513286113739
[10/24] Train loss=0.7523479461669922
[15/24] Train loss=0.7432367205619812
[20/24] Train loss=0.7385872006416321
Test set avg_accuracy=53.88% avg_sensitivity=40.62%, avg_specificity=58.90% avg_auc=49.51%
Best model saved!! Metric=-123.09057284886312!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.743514 Test loss=0.692043 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7332234978675842
[5/24] Train loss=0.7401371598243713
[10/24] Train loss=0.7330069541931152
[15/24] Train loss=0.7305379509925842
[20/24] Train loss=0.727271556854248
Test set avg_accuracy=56.35% avg_sensitivity=34.12%, avg_specificity=64.78% avg_auc=49.90%
Best model saved!! Metric=-120.84579164078609!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.733396 Test loss=0.690360 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7259594798088074
[5/24] Train loss=0.7289469838142395
[10/24] Train loss=0.7344054579734802
[15/24] Train loss=0.7289671897888184
[20/24] Train loss=0.7213855981826782
Test set avg_accuracy=56.47% avg_sensitivity=34.45%, avg_specificity=64.81% avg_auc=50.10%
Best model saved!! Metric=-120.16519743424205!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.725576 Test loss=0.686540 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.7129030227661133
[5/24] Train loss=0.7171725034713745
[10/24] Train loss=0.7191998958587646
[15/24] Train loss=0.7152854204177856
[20/24] Train loss=0.7020613551139832
Test set avg_accuracy=56.00% avg_sensitivity=35.73%, avg_specificity=63.68% avg_auc=50.59%
Best model saved!! Metric=-119.99128659885955!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.711467 Test loss=0.683021 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.7103739976882935
[5/24] Train loss=0.7129462361335754
[10/24] Train loss=0.711304247379303
[15/24] Train loss=0.709618091583252
[20/24] Train loss=0.7000538110733032
Test set avg_accuracy=65.17% avg_sensitivity=20.47%, avg_specificity=82.10% avg_auc=51.03%
Best model saved!! Metric=-107.2294843463275!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.702078 Test loss=0.674335 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6880847811698914
[5/24] Train loss=0.695937991142273
[10/24] Train loss=0.702458918094635
[15/24] Train loss=0.7043496370315552
[20/24] Train loss=0.6798598766326904
Test set avg_accuracy=60.35% avg_sensitivity=29.29%, avg_specificity=72.12% avg_auc=51.38%
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.689982 Test loss=0.668889 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6838250160217285
[5/24] Train loss=0.677119255065918
[10/24] Train loss=0.6888076066970825
[15/24] Train loss=0.6851389408111572
[20/24] Train loss=0.6743987798690796
Test set avg_accuracy=65.49% avg_sensitivity=18.15%, avg_specificity=83.43% avg_auc=52.37%
Best model saved!! Metric=-106.55355467077071!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.675357 Test loss=0.654500 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.665399968624115
[5/24] Train loss=0.6635607481002808
[10/24] Train loss=0.6710448265075684
[15/24] Train loss=0.6861437559127808
[20/24] Train loss=0.6543326377868652
Test set avg_accuracy=66.77% avg_sensitivity=16.78%, avg_specificity=85.71% avg_auc=53.99%
Best model saved!! Metric=-102.75055324166645!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.661047 Test loss=0.637646 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6446086168289185
[5/24] Train loss=0.6516358852386475
[10/24] Train loss=0.6687341928482056
[15/24] Train loss=0.6565734148025513
[20/24] Train loss=0.6360029578208923
Test set avg_accuracy=69.06% avg_sensitivity=14.50%, avg_specificity=89.73% avg_auc=55.67%
Best model saved!! Metric=-97.0357455095425!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.643965 Test loss=0.632159 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6322504878044128
[5/24] Train loss=0.6294843554496765
[10/24] Train loss=0.6492817401885986
[15/24] Train loss=0.6416804194450378
[20/24] Train loss=0.6207454204559326
Test set avg_accuracy=66.32% avg_sensitivity=20.57%, avg_specificity=83.64% avg_auc=56.13%
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.627712 Test loss=0.623089 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6103385090827942
[5/24] Train loss=0.6142446994781494
[10/24] Train loss=0.6347170472145081
[15/24] Train loss=0.6366589069366455
[20/24] Train loss=0.5998064279556274
Test set avg_accuracy=71.99% avg_sensitivity=11.37%, avg_specificity=94.96% avg_auc=59.52%
Best model saved!! Metric=-88.15968823919184!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.608792 Test loss=0.590634 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5825895667076111
[5/24] Train loss=0.592880368232727
[10/24] Train loss=0.6177787184715271
[15/24] Train loss=0.6211827993392944
[20/24] Train loss=0.5685839653015137
Test set avg_accuracy=72.27% avg_sensitivity=12.65%, avg_specificity=94.85% avg_auc=61.53%
Best model saved!! Metric=-84.70556459898576!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.586695 Test loss=0.590390 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5622557997703552
[5/24] Train loss=0.5582420229911804
[10/24] Train loss=0.5844606161117554
[15/24] Train loss=0.6035200953483582
[20/24] Train loss=0.5322978496551514
Test set avg_accuracy=72.99% avg_sensitivity=15.55%, avg_specificity=94.76% avg_auc=66.86%
Best model saved!! Metric=-75.84177780247659!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.557710 Test loss=0.588588 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5205238461494446
[5/24] Train loss=0.5329377055168152
[10/24] Train loss=0.5516578555107117
[15/24] Train loss=0.575198769569397
[20/24] Train loss=0.49729782342910767
Test set avg_accuracy=74.52% avg_sensitivity=23.93%, avg_specificity=93.68% avg_auc=72.38%
Best model saved!! Metric=-61.4878800678071!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.525354 Test loss=0.541842 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.47596317529678345
[5/24] Train loss=0.5085665583610535
[10/24] Train loss=0.5275412797927856
[15/24] Train loss=0.5531680583953857
[20/24] Train loss=0.45968928933143616
Test set avg_accuracy=75.36% avg_sensitivity=27.63%, avg_specificity=93.45% avg_auc=72.48%
Best model saved!! Metric=-57.07591970001221!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.494944 Test loss=0.548026 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4530738294124603
[5/24] Train loss=0.4863959848880768
[10/24] Train loss=0.5035405158996582
[15/24] Train loss=0.5224907994270325
[20/24] Train loss=0.4485558569431305
Test set avg_accuracy=78.39% avg_sensitivity=49.38%, avg_specificity=89.37% avg_auc=80.10%
Best model saved!! Metric=-28.75931603305341!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.471972 Test loss=0.476149 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4308061897754669
[5/24] Train loss=0.45334291458129883
[10/24] Train loss=0.47901296615600586
[15/24] Train loss=0.49707674980163574
[20/24] Train loss=0.4287512004375458
Test set avg_accuracy=73.07% avg_sensitivity=70.90%, avg_specificity=73.90% avg_auc=79.21%
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.451669 Test loss=0.551985 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4170299172401428
[5/24] Train loss=0.43319323658943176
[10/24] Train loss=0.47803887724876404
[15/24] Train loss=0.5024726390838623
[20/24] Train loss=0.41204434633255005
Test set avg_accuracy=57.96% avg_sensitivity=68.96%, avg_specificity=53.79% avg_auc=68.05%
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.440561 Test loss=0.665944 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4072972238063812
[5/24] Train loss=0.4324684143066406
[10/24] Train loss=0.4627413749694824
[15/24] Train loss=0.4781685769557953
[20/24] Train loss=0.40232986211776733
Test set avg_accuracy=54.24% avg_sensitivity=66.54%, avg_specificity=49.59% avg_auc=62.11%
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.429981 Test loss=0.692908 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.39997464418411255
[5/24] Train loss=0.42099428176879883
[10/24] Train loss=0.46567773818969727
[15/24] Train loss=0.46671783924102783
[20/24] Train loss=0.39966413378715515
Test set avg_accuracy=49.73% avg_sensitivity=72.27%, avg_specificity=41.18% avg_auc=60.43%
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.424349 Test loss=0.711427 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3900753855705261
[5/24] Train loss=0.41400447487831116
[10/24] Train loss=0.4598265588283539
[15/24] Train loss=0.47832733392715454
[20/24] Train loss=0.3881683051586151
Test set avg_accuracy=62.89% avg_sensitivity=70.81%, avg_specificity=59.89% avg_auc=71.71%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.418492 Test loss=0.627523 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3809829354286194
[5/24] Train loss=0.4129897654056549
[10/24] Train loss=0.451335608959198
[15/24] Train loss=0.471149206161499
[20/24] Train loss=0.38480958342552185
Test set avg_accuracy=54.58% avg_sensitivity=72.09%, avg_specificity=47.95% avg_auc=65.57%
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.414284 Test loss=0.681421 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3799898028373718
[5/24] Train loss=0.391937792301178
[10/24] Train loss=0.43947750329971313
[15/24] Train loss=0.4626196026802063
[20/24] Train loss=0.3838052451610565
Test set avg_accuracy=77.06% avg_sensitivity=67.25%, avg_specificity=80.77% avg_auc=81.46%
Best model saved!! Metric=-19.458147338838444!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.410017 Test loss=0.514382 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3875724971294403
[5/24] Train loss=0.39755383133888245
[10/24] Train loss=0.4510810375213623
[15/24] Train loss=0.46235474944114685
[20/24] Train loss=0.383864164352417
Test set avg_accuracy=62.97% avg_sensitivity=63.89%, avg_specificity=62.62% avg_auc=66.98%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.408012 Test loss=0.649127 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.36916491389274597
[5/24] Train loss=0.3935911953449249
[10/24] Train loss=0.4406820833683014
[15/24] Train loss=0.4564799666404724
[20/24] Train loss=0.36692607402801514
Test set avg_accuracy=50.53% avg_sensitivity=63.03%, avg_specificity=45.80% avg_auc=59.03%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.400046 Test loss=0.697900 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3704167604446411
[5/24] Train loss=0.3895713686943054
[10/24] Train loss=0.43306252360343933
[15/24] Train loss=0.4596835970878601
[20/24] Train loss=0.37007877230644226
Test set avg_accuracy=55.22% avg_sensitivity=67.39%, avg_specificity=50.61% avg_auc=64.15%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.398942 Test loss=0.672429 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3704153895378113
[5/24] Train loss=0.38678649067878723
[10/24] Train loss=0.4280758202075958
[15/24] Train loss=0.4510137140750885
[20/24] Train loss=0.3559856712818146
Test set avg_accuracy=51.24% avg_sensitivity=70.43%, avg_specificity=43.97% avg_auc=60.93%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.392454 Test loss=0.688459 Current lr=[0.000210185142098938]

[0/24] Train loss=0.361127108335495
[5/24] Train loss=0.37681451439857483
[10/24] Train loss=0.4267497658729553
[15/24] Train loss=0.4480608105659485
[20/24] Train loss=0.3699679374694824
Test set avg_accuracy=57.02% avg_sensitivity=74.55%, avg_specificity=50.38% avg_auc=68.60%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.390403 Test loss=0.665118 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3570883572101593
[5/24] Train loss=0.372495174407959
[10/24] Train loss=0.43906137347221375
[15/24] Train loss=0.44472289085388184
[20/24] Train loss=0.3584063947200775
Test set avg_accuracy=50.46% avg_sensitivity=68.63%, avg_specificity=43.57% avg_auc=58.41%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.385723 Test loss=0.719941 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3576795756816864
[5/24] Train loss=0.3737666606903076
[10/24] Train loss=0.4296409785747528
[15/24] Train loss=0.43691930174827576
[20/24] Train loss=0.3508508801460266
Test set avg_accuracy=53.58% avg_sensitivity=66.11%, avg_specificity=48.83% avg_auc=61.51%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.383330 Test loss=0.693082 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3698284924030304
[5/24] Train loss=0.35890963673591614
[10/24] Train loss=0.4291187822818756
[15/24] Train loss=0.44352126121520996
[20/24] Train loss=0.3488335907459259
Test set avg_accuracy=59.79% avg_sensitivity=72.32%, avg_specificity=55.04% avg_auc=68.61%
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.379519 Test loss=0.655665 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3518291711807251
[5/24] Train loss=0.3658222258090973
[10/24] Train loss=0.42562955617904663
[15/24] Train loss=0.45349785685539246
[20/24] Train loss=0.3484562635421753
Test set avg_accuracy=53.97% avg_sensitivity=72.09%, avg_specificity=47.11% avg_auc=64.21%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.379695 Test loss=0.679719 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35688501596450806
[5/24] Train loss=0.36342933773994446
[10/24] Train loss=0.42396482825279236
[15/24] Train loss=0.4225400686264038
[20/24] Train loss=0.34026509523391724
Test set avg_accuracy=80.53% avg_sensitivity=48.39%, avg_specificity=92.71% avg_auc=81.58%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.369855 Test loss=0.496828 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.37187647819519043
[5/24] Train loss=0.3595382273197174
[10/24] Train loss=0.41658931970596313
[15/24] Train loss=0.43041643500328064
[20/24] Train loss=0.3303433954715729
Test set avg_accuracy=58.14% avg_sensitivity=63.13%, avg_specificity=56.25% avg_auc=63.04%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.368720 Test loss=0.654188 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3352729380130768
[5/24] Train loss=0.3673373758792877
[10/24] Train loss=0.4109439253807068
[15/24] Train loss=0.4106594920158386
[20/24] Train loss=0.3231971263885498
Test set avg_accuracy=59.36% avg_sensitivity=48.34%, avg_specificity=63.54% avg_auc=60.59%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.365871 Test loss=0.656019 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.33231082558631897
[5/24] Train loss=0.3458877503871918
[10/24] Train loss=0.41996094584465027
[15/24] Train loss=0.4083097577095032
[20/24] Train loss=0.32708683609962463
Test set avg_accuracy=82.23% avg_sensitivity=53.22%, avg_specificity=93.21% avg_auc=86.67%
Best model saved!! Metric=-10.67166939564951!!
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.360307 Test loss=0.398826 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.35612058639526367
[5/24] Train loss=0.3546938896179199
[10/24] Train loss=0.39667201042175293
[15/24] Train loss=0.42841386795043945
[20/24] Train loss=0.33730611205101013
Test set avg_accuracy=64.43% avg_sensitivity=66.59%, avg_specificity=63.61% avg_auc=71.88%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.368521 Test loss=0.599831 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3348219394683838
[5/24] Train loss=0.3494202196598053
[10/24] Train loss=0.39559507369995117
[15/24] Train loss=0.4020896553993225
[20/24] Train loss=0.32585641741752625
Test set avg_accuracy=62.45% avg_sensitivity=45.73%, avg_specificity=68.78% avg_auc=63.46%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.353106 Test loss=0.630761 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.32538148760795593
[5/24] Train loss=0.3450561761856079
[10/24] Train loss=0.38827183842658997
[15/24] Train loss=0.4077763259410858
[20/24] Train loss=0.3307533264160156
Test set avg_accuracy=61.07% avg_sensitivity=55.45%, avg_specificity=63.20% avg_auc=63.79%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.349554 Test loss=0.637354 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34543946385383606
[5/24] Train loss=0.35279110074043274
[10/24] Train loss=0.39450156688690186
[15/24] Train loss=0.41075536608695984
[20/24] Train loss=0.3203599452972412
Test set avg_accuracy=65.51% avg_sensitivity=68.96%, avg_specificity=64.20% avg_auc=73.24%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.350510 Test loss=0.581491 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.328843891620636
[5/24] Train loss=0.3469582498073578
[10/24] Train loss=0.384348601102829
[15/24] Train loss=0.4004043936729431
[20/24] Train loss=0.3170982003211975
Test set avg_accuracy=55.89% avg_sensitivity=60.43%, avg_specificity=54.17% avg_auc=62.92%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.344708 Test loss=0.672798 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3312288820743561
[5/24] Train loss=0.35045546293258667
[10/24] Train loss=0.3779318630695343
[15/24] Train loss=0.3802587389945984
[20/24] Train loss=0.3198354244232178
Test set avg_accuracy=75.89% avg_sensitivity=55.07%, avg_specificity=83.77% avg_auc=78.43%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.343695 Test loss=0.508074 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3395939767360687
[5/24] Train loss=0.3487453758716583
[10/24] Train loss=0.3858516216278076
[15/24] Train loss=0.36996614933013916
[20/24] Train loss=0.3104013502597809
Test set avg_accuracy=65.46% avg_sensitivity=62.94%, avg_specificity=66.41% avg_auc=71.19%
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.342851 Test loss=0.606013 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3247910439968109
[5/24] Train loss=0.3550540506839752
[10/24] Train loss=0.38471442461013794
[15/24] Train loss=0.39610961079597473
[20/24] Train loss=0.32160618901252747
Test set avg_accuracy=67.81% avg_sensitivity=52.42%, avg_specificity=73.64% avg_auc=70.74%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.341330 Test loss=0.574825 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3196108043193817
[5/24] Train loss=0.3480018973350525
[10/24] Train loss=0.3838733732700348
[15/24] Train loss=0.3883441984653473
[20/24] Train loss=0.31238487362861633
Test set avg_accuracy=60.85% avg_sensitivity=78.91%, avg_specificity=54.00% avg_auc=72.02%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.342378 Test loss=0.628991 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.32064196467399597
[5/24] Train loss=0.3560319244861603
[10/24] Train loss=0.3843330144882202
[15/24] Train loss=0.3892911970615387
[20/24] Train loss=0.30173856019973755
Test set avg_accuracy=69.10% avg_sensitivity=71.37%, avg_specificity=68.24% avg_auc=77.87%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.340447 Test loss=0.557905 Current lr=[0.000299720220882401]

[0/24] Train loss=0.30846449732780457
[5/24] Train loss=0.33476781845092773
[10/24] Train loss=0.3739302456378937
[15/24] Train loss=0.3606242537498474
[20/24] Train loss=0.304890513420105
Test set avg_accuracy=81.94% avg_sensitivity=64.64%, avg_specificity=88.49% avg_auc=84.50%
Best model saved!! Metric=-6.42789212354748!!
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.331596 Test loss=0.447389 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.31915512681007385
[5/24] Train loss=0.3352526128292084
[10/24] Train loss=0.37242794036865234
[15/24] Train loss=0.36582452058792114
[20/24] Train loss=0.3165537118911743
Test set avg_accuracy=65.25% avg_sensitivity=42.80%, avg_specificity=73.75% avg_auc=67.55%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.334504 Test loss=0.592384 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3100033700466156
[5/24] Train loss=0.330986350774765
[10/24] Train loss=0.3736017346382141
[15/24] Train loss=0.3474242091178894
[20/24] Train loss=0.3039318919181824
Test set avg_accuracy=65.85% avg_sensitivity=42.04%, avg_specificity=74.87% avg_auc=67.54%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.329969 Test loss=0.583442 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3090408146381378
[5/24] Train loss=0.3252449929714203
[10/24] Train loss=0.3655088543891907
[15/24] Train loss=0.36390432715415955
[20/24] Train loss=0.30367138981819153
Test set avg_accuracy=68.15% avg_sensitivity=41.80%, avg_specificity=78.13% avg_auc=69.98%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.323559 Test loss=0.569699 Current lr=[0.000297555943323901]

[0/24] Train loss=0.323932409286499
[5/24] Train loss=0.31686675548553467
[10/24] Train loss=0.3597234785556793
[15/24] Train loss=0.37308943271636963
[20/24] Train loss=0.29762178659439087
Test set avg_accuracy=59.77% avg_sensitivity=66.16%, avg_specificity=57.34% avg_auc=66.47%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.325516 Test loss=0.673302 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3183634877204895
[5/24] Train loss=0.3131943643093109
[10/24] Train loss=0.3617226183414459
[15/24] Train loss=0.369510680437088
[20/24] Train loss=0.31534144282341003
Test set avg_accuracy=58.42% avg_sensitivity=63.32%, avg_specificity=56.57% avg_auc=64.90%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.328293 Test loss=0.675092 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.30436745285987854
[5/24] Train loss=0.3320688307285309
[10/24] Train loss=0.3807365894317627
[15/24] Train loss=0.36720067262649536
[20/24] Train loss=0.33655279874801636
Test set avg_accuracy=67.97% avg_sensitivity=34.98%, avg_specificity=80.47% avg_auc=67.75%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.330014 Test loss=0.564573 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.31786835193634033
[5/24] Train loss=0.3262299597263336
[10/24] Train loss=0.3697100281715393
[15/24] Train loss=0.3628675937652588
[20/24] Train loss=0.30932340025901794
Test set avg_accuracy=57.25% avg_sensitivity=80.28%, avg_specificity=48.53% avg_auc=69.05%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.331277 Test loss=0.679474 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3010961711406708
[5/24] Train loss=0.3192404806613922
[10/24] Train loss=0.3484027087688446
[15/24] Train loss=0.3710152208805084
[20/24] Train loss=0.30265796184539795
Test set avg_accuracy=67.19% avg_sensitivity=46.97%, avg_specificity=74.85% avg_auc=70.88%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.318581 Test loss=0.564421 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.31421107053756714
[5/24] Train loss=0.3260279595851898
[10/24] Train loss=0.36234959959983826
[15/24] Train loss=0.358426570892334
[20/24] Train loss=0.2900885045528412
Test set avg_accuracy=64.53% avg_sensitivity=59.57%, avg_specificity=66.41% avg_auc=69.66%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.321055 Test loss=0.604154 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.2915112376213074
[5/24] Train loss=0.309757262468338
[10/24] Train loss=0.35130825638771057
[15/24] Train loss=0.3298068344593048
[20/24] Train loss=0.296299010515213
Test set avg_accuracy=61.80% avg_sensitivity=62.09%, avg_specificity=61.69% avg_auc=67.87%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.311991 Test loss=0.641130 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3014458119869232
[5/24] Train loss=0.3107103407382965
[10/24] Train loss=0.353899747133255
[15/24] Train loss=0.3475150167942047
[20/24] Train loss=0.2867032587528229
Test set avg_accuracy=61.34% avg_sensitivity=69.24%, avg_specificity=58.35% avg_auc=68.82%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.315179 Test loss=0.646250 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.31626132130622864
[5/24] Train loss=0.3044942319393158
[10/24] Train loss=0.3710792064666748
[15/24] Train loss=0.3542289137840271
[20/24] Train loss=0.2991776764392853
Test set avg_accuracy=73.12% avg_sensitivity=64.69%, avg_specificity=76.32% avg_auc=80.17%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.320020 Test loss=0.509883 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.29750317335128784
[5/24] Train loss=0.35479435324668884
[10/24] Train loss=0.3784022033214569
[15/24] Train loss=0.359699547290802
[20/24] Train loss=0.2935270369052887
Test set avg_accuracy=61.48% avg_sensitivity=51.37%, avg_specificity=65.31% avg_auc=64.14%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.333852 Test loss=0.640276 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.2997002899646759
[5/24] Train loss=0.32577818632125854
[10/24] Train loss=0.3609289228916168
[15/24] Train loss=0.36056259274482727
[20/24] Train loss=0.2839653193950653
Test set avg_accuracy=53.01% avg_sensitivity=76.16%, avg_specificity=44.24% avg_auc=63.86%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.319094 Test loss=0.735257 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.2944064736366272
[5/24] Train loss=0.3125869929790497
[10/24] Train loss=0.3422015309333801
[15/24] Train loss=0.33825576305389404
[20/24] Train loss=0.2841288149356842
Test set avg_accuracy=59.28% avg_sensitivity=63.22%, avg_specificity=57.79% avg_auc=64.35%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.309541 Test loss=0.731146 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2877786159515381
[5/24] Train loss=0.30069708824157715
[10/24] Train loss=0.35263994336128235
[15/24] Train loss=0.3325387239456177
[20/24] Train loss=0.2819511592388153
Test set avg_accuracy=62.38% avg_sensitivity=61.33%, avg_specificity=62.78% avg_auc=67.82%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.305089 Test loss=0.633086 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2813582122325897
[5/24] Train loss=0.3175975978374481
[10/24] Train loss=0.35552194714546204
[15/24] Train loss=0.33080583810806274
[20/24] Train loss=0.2927628457546234
Test set avg_accuracy=52.97% avg_sensitivity=65.92%, avg_specificity=48.06% avg_auc=60.89%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.313240 Test loss=0.787758 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.28989464044570923
[5/24] Train loss=0.30708959698677063
[10/24] Train loss=0.3513389825820923
[15/24] Train loss=0.34424662590026855
[20/24] Train loss=0.2811300754547119
Test set avg_accuracy=61.17% avg_sensitivity=73.32%, avg_specificity=56.57% avg_auc=70.48%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.314379 Test loss=0.666121 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.28427982330322266
[5/24] Train loss=0.3140404522418976
[10/24] Train loss=0.3513907194137573
[15/24] Train loss=0.3425167500972748
[20/24] Train loss=0.2738412320613861
Test set avg_accuracy=66.88% avg_sensitivity=41.75%, avg_specificity=76.39% avg_auc=67.64%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.308027 Test loss=0.585975 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.27922746539115906
[5/24] Train loss=0.30495837330818176
[10/24] Train loss=0.34384751319885254
[15/24] Train loss=0.3406413495540619
[20/24] Train loss=0.27837073802948
Test set avg_accuracy=57.67% avg_sensitivity=69.43%, avg_specificity=53.21% avg_auc=66.13%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.304457 Test loss=0.627194 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.28345876932144165
[5/24] Train loss=0.29823774099349976
[10/24] Train loss=0.3373814821243286
[15/24] Train loss=0.3505385220050812
[20/24] Train loss=0.2697133719921112
Test set avg_accuracy=66.26% avg_sensitivity=67.96%, avg_specificity=65.62% avg_auc=73.71%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.304091 Test loss=0.583771 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.28309166431427
[5/24] Train loss=0.2956269681453705
[10/24] Train loss=0.35173845291137695
[15/24] Train loss=0.35124731063842773
[20/24] Train loss=0.2826763987541199
Test set avg_accuracy=61.35% avg_sensitivity=60.28%, avg_specificity=61.76% avg_auc=68.12%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.300614 Test loss=0.621449 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.26432347297668457
[5/24] Train loss=0.29512229561805725
[10/24] Train loss=0.3352573812007904
[15/24] Train loss=0.33583587408065796
[20/24] Train loss=0.2727561891078949
Test set avg_accuracy=65.08% avg_sensitivity=44.17%, avg_specificity=73.00% avg_auc=67.83%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.299950 Test loss=0.576951 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.27409809827804565
[5/24] Train loss=0.29910314083099365
[10/24] Train loss=0.3373538553714752
[15/24] Train loss=0.35350534319877625
[20/24] Train loss=0.27878543734550476
Test set avg_accuracy=81.64% avg_sensitivity=44.45%, avg_specificity=95.73% avg_auc=87.14%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.304143 Test loss=0.449424 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2852492928504944
[5/24] Train loss=0.29897379875183105
[10/24] Train loss=0.3410990536212921
[15/24] Train loss=0.34074968099594116
[20/24] Train loss=0.2833477854728699
Test set avg_accuracy=68.49% avg_sensitivity=55.69%, avg_specificity=73.34% avg_auc=73.58%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.300940 Test loss=0.550401 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2850092947483063
[5/24] Train loss=0.2993345558643341
[10/24] Train loss=0.33609500527381897
[15/24] Train loss=0.3293921947479248
[20/24] Train loss=0.26242753863334656
Test set avg_accuracy=63.35% avg_sensitivity=64.88%, avg_specificity=62.76% avg_auc=69.86%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.298367 Test loss=0.614534 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.27741730213165283
[5/24] Train loss=0.2938705384731293
[10/24] Train loss=0.325431764125824
[15/24] Train loss=0.3306353986263275
[20/24] Train loss=0.2744772732257843
Test set avg_accuracy=61.50% avg_sensitivity=68.39%, avg_specificity=58.89% avg_auc=68.72%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.295099 Test loss=0.651364 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.26517316699028015
[5/24] Train loss=0.30511361360549927
[10/24] Train loss=0.3303409814834595
[15/24] Train loss=0.34505000710487366
[20/24] Train loss=0.2700752317905426
Test set avg_accuracy=60.86% avg_sensitivity=68.67%, avg_specificity=57.90% avg_auc=67.84%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.294918 Test loss=0.675633 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.26509788632392883
[5/24] Train loss=0.30546435713768005
[10/24] Train loss=0.332334041595459
[15/24] Train loss=0.32308077812194824
[20/24] Train loss=0.26307833194732666
Test set avg_accuracy=58.23% avg_sensitivity=75.55%, avg_specificity=51.67% avg_auc=68.67%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.292776 Test loss=0.650804 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2672973871231079
[5/24] Train loss=0.28423091769218445
[10/24] Train loss=0.31718266010284424
[15/24] Train loss=0.3219485878944397
[20/24] Train loss=0.2587546706199646
Test set avg_accuracy=61.52% avg_sensitivity=68.10%, avg_specificity=59.03% avg_auc=69.48%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.289464 Test loss=0.666585 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.26798152923583984
[5/24] Train loss=0.2821469306945801
[10/24] Train loss=0.3261762261390686
[15/24] Train loss=0.3120645582675934
[20/24] Train loss=0.25622040033340454
Test set avg_accuracy=64.41% avg_sensitivity=65.07%, avg_specificity=64.17% avg_auc=70.74%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.287665 Test loss=0.590089 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.27102792263031006
[5/24] Train loss=0.30051448941230774
[10/24] Train loss=0.34301766753196716
[15/24] Train loss=0.3273046612739563
[20/24] Train loss=0.2589927315711975
Test set avg_accuracy=61.42% avg_sensitivity=69.53%, avg_specificity=58.35% avg_auc=69.27%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.294272 Test loss=0.620308 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2662687301635742
[5/24] Train loss=0.29034000635147095
[10/24] Train loss=0.3312312662601471
[15/24] Train loss=0.32094401121139526
[20/24] Train loss=0.2610775828361511
Test set avg_accuracy=63.82% avg_sensitivity=72.70%, avg_specificity=60.45% avg_auc=72.48%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.292593 Test loss=0.653276 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.269398957490921
[5/24] Train loss=0.2886905074119568
[10/24] Train loss=0.3267897069454193
[15/24] Train loss=0.31451666355133057
[20/24] Train loss=0.2666073441505432
Test set avg_accuracy=62.72% avg_sensitivity=76.26%, avg_specificity=57.59% avg_auc=72.44%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.286912 Test loss=0.651627 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2702215313911438
[5/24] Train loss=0.28759080171585083
[10/24] Train loss=0.2989930510520935
[15/24] Train loss=0.30837252736091614
[20/24] Train loss=0.2503929138183594
Test set avg_accuracy=66.72% avg_sensitivity=67.63%, avg_specificity=66.37% avg_auc=74.29%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.282803 Test loss=0.561005 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.27287358045578003
[5/24] Train loss=0.29158487915992737
[10/24] Train loss=0.3135533928871155
[15/24] Train loss=0.30975261330604553
[20/24] Train loss=0.26339980959892273
Test set avg_accuracy=67.96% avg_sensitivity=68.06%, avg_specificity=67.92% avg_auc=75.34%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.285112 Test loss=0.592448 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2787021994590759
[5/24] Train loss=0.29264330863952637
[10/24] Train loss=0.3214603066444397
[15/24] Train loss=0.31286996603012085
[20/24] Train loss=0.24920929968357086
Test set avg_accuracy=78.76% avg_sensitivity=52.75%, avg_specificity=88.62% avg_auc=81.04%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.284781 Test loss=0.469846 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.25877732038497925
[5/24] Train loss=0.28558874130249023
[10/24] Train loss=0.30841130018234253
[15/24] Train loss=0.32297587394714355
[20/24] Train loss=0.2670249342918396
Test set avg_accuracy=75.43% avg_sensitivity=56.73%, avg_specificity=82.51% avg_auc=78.02%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.281582 Test loss=0.502071 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2565041780471802
[5/24] Train loss=0.28512808680534363
[10/24] Train loss=0.30472102761268616
[15/24] Train loss=0.3157830834388733
[20/24] Train loss=0.25321364402770996
Test set avg_accuracy=64.52% avg_sensitivity=54.74%, avg_specificity=68.22% avg_auc=68.19%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.277005 Test loss=0.585884 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.25554394721984863
[5/24] Train loss=0.2921081781387329
[10/24] Train loss=0.30051615834236145
[15/24] Train loss=0.3177016079425812
[20/24] Train loss=0.24196915328502655
Test set avg_accuracy=69.75% avg_sensitivity=36.16%, avg_specificity=82.48% avg_auc=68.21%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.273130 Test loss=0.569942 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2630220949649811
[5/24] Train loss=0.2756423354148865
[10/24] Train loss=0.2962634265422821
[15/24] Train loss=0.3066677749156952
[20/24] Train loss=0.25296613574028015
Test set avg_accuracy=64.32% avg_sensitivity=66.16%, avg_specificity=63.63% avg_auc=72.54%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.272728 Test loss=0.621551 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2508942186832428
[5/24] Train loss=0.27118080854415894
[10/24] Train loss=0.29419562220573425
[15/24] Train loss=0.3310333788394928
[20/24] Train loss=0.239615797996521
Test set avg_accuracy=73.50% avg_sensitivity=14.83%, avg_specificity=95.73% avg_auc=67.92%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.273878 Test loss=0.562864 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.24170039594173431
[5/24] Train loss=0.2709366977214813
[10/24] Train loss=0.2880088984966278
[15/24] Train loss=0.2929854094982147
[20/24] Train loss=0.2544318437576294
Test set avg_accuracy=63.95% avg_sensitivity=73.79%, avg_specificity=60.22% avg_auc=73.03%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.265950 Test loss=0.677383 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.23671633005142212
[5/24] Train loss=0.28394728899002075
[10/24] Train loss=0.2929592430591583
[15/24] Train loss=0.30668386816978455
[20/24] Train loss=0.23909436166286469
Test set avg_accuracy=73.96% avg_sensitivity=45.92%, avg_specificity=84.58% avg_auc=74.14%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.266905 Test loss=0.526684 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.236721470952034
[5/24] Train loss=0.2659916579723358
[10/24] Train loss=0.29498612880706787
[15/24] Train loss=0.29619842767715454
[20/24] Train loss=0.24892385303974152
Test set avg_accuracy=75.70% avg_sensitivity=25.17%, avg_specificity=94.85% avg_auc=77.26%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.266139 Test loss=0.502565 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.25665169954299927
[5/24] Train loss=0.26996034383773804
[10/24] Train loss=0.29430699348449707
[15/24] Train loss=0.3096601665019989
[20/24] Train loss=0.2512357532978058
Test set avg_accuracy=71.04% avg_sensitivity=65.17%, avg_specificity=73.27% avg_auc=77.27%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.273048 Test loss=0.527975 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24270951747894287
[5/24] Train loss=0.27244341373443604
[10/24] Train loss=0.29332220554351807
[15/24] Train loss=0.304933100938797
[20/24] Train loss=0.23536203801631927
Test set avg_accuracy=65.78% avg_sensitivity=57.01%, avg_specificity=69.10% avg_auc=70.56%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.268416 Test loss=0.591965 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.23783600330352783
[5/24] Train loss=0.25478097796440125
[10/24] Train loss=0.2857646346092224
[15/24] Train loss=0.30370059609413147
[20/24] Train loss=0.24473007023334503
Test set avg_accuracy=67.10% avg_sensitivity=52.18%, avg_specificity=72.75% avg_auc=70.63%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.261878 Test loss=0.578685 Current lr=[0.000156543481933168]

[0/24] Train loss=0.22852565348148346
[5/24] Train loss=0.25721243023872375
[10/24] Train loss=0.28570446372032166
[15/24] Train loss=0.2953987717628479
[20/24] Train loss=0.2403879463672638
Test set avg_accuracy=64.06% avg_sensitivity=69.10%, avg_specificity=62.15% avg_auc=72.58%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.259698 Test loss=0.600485 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.24661025404930115
[5/24] Train loss=0.26685506105422974
[10/24] Train loss=0.2774563729763031
[15/24] Train loss=0.3035450279712677
[20/24] Train loss=0.23395875096321106
Test set avg_accuracy=69.91% avg_sensitivity=55.36%, avg_specificity=75.42% avg_auc=73.67%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.258201 Test loss=0.553507 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.23112770915031433
[5/24] Train loss=0.2549925744533539
[10/24] Train loss=0.27981576323509216
[15/24] Train loss=0.2880164682865143
[20/24] Train loss=0.2335493117570877
Test set avg_accuracy=72.54% avg_sensitivity=44.31%, avg_specificity=83.23% avg_auc=73.37%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.254378 Test loss=0.536398 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.23537935316562653
[5/24] Train loss=0.24740049242973328
[10/24] Train loss=0.26645785570144653
[15/24] Train loss=0.29872509837150574
[20/24] Train loss=0.2306736707687378
Test set avg_accuracy=69.54% avg_sensitivity=40.05%, avg_specificity=80.72% avg_auc=68.91%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.253337 Test loss=0.581735 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22240152955055237
[5/24] Train loss=0.2462356686592102
[10/24] Train loss=0.26520365476608276
[15/24] Train loss=0.2931778132915497
[20/24] Train loss=0.23125115036964417
Test set avg_accuracy=71.55% avg_sensitivity=75.40%, avg_specificity=70.09% avg_auc=80.55%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.252074 Test loss=0.537459 Current lr=[0.000134135431043539]

[0/24] Train loss=0.22656293213367462
[5/24] Train loss=0.26866570115089417
[10/24] Train loss=0.2892843782901764
[15/24] Train loss=0.29159414768218994
[20/24] Train loss=0.2399487942457199
Test set avg_accuracy=64.06% avg_sensitivity=67.30%, avg_specificity=62.84% avg_auc=72.12%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.256826 Test loss=0.603600 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2195243090391159
[5/24] Train loss=0.2490549385547638
[10/24] Train loss=0.27457013726234436
[15/24] Train loss=0.27802276611328125
[20/24] Train loss=0.23259784281253815
Test set avg_accuracy=70.08% avg_sensitivity=40.33%, avg_specificity=81.35% avg_auc=69.77%
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.249509 Test loss=0.578064 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2226165384054184
[5/24] Train loss=0.24659043550491333
[10/24] Train loss=0.2623308300971985
[15/24] Train loss=0.2875310182571411
[20/24] Train loss=0.22984035313129425
Test set avg_accuracy=64.66% avg_sensitivity=52.09%, avg_specificity=69.43% avg_auc=69.62%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.242370 Test loss=0.593200 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.21051058173179626
[5/24] Train loss=0.23975737392902374
[10/24] Train loss=0.2655983567237854
[15/24] Train loss=0.2762288451194763
[20/24] Train loss=0.22749488055706024
Test set avg_accuracy=72.25% avg_sensitivity=48.77%, avg_specificity=81.15% avg_auc=74.95%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.239533 Test loss=0.532070 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.22002097964286804
[5/24] Train loss=0.25086092948913574
[10/24] Train loss=0.2569684386253357
[15/24] Train loss=0.2776225507259369
[20/24] Train loss=0.22359052300453186
Test set avg_accuracy=73.72% avg_sensitivity=35.31%, avg_specificity=88.28% avg_auc=73.29%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.238901 Test loss=0.544416 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.21287769079208374
[5/24] Train loss=0.23572488129138947
[10/24] Train loss=0.2620905637741089
[15/24] Train loss=0.2568018436431885
[20/24] Train loss=0.21450047194957733
Test set avg_accuracy=65.42% avg_sensitivity=45.45%, avg_specificity=72.98% avg_auc=69.11%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.236741 Test loss=0.587446 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.21503892540931702
[5/24] Train loss=0.23197008669376373
[10/24] Train loss=0.2640652060508728
[15/24] Train loss=0.2682478725910187
[20/24] Train loss=0.22846563160419464
Test set avg_accuracy=67.98% avg_sensitivity=57.39%, avg_specificity=71.99% avg_auc=72.40%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.239436 Test loss=0.588632 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.20875534415245056
[5/24] Train loss=0.2353261113166809
[10/24] Train loss=0.25753748416900635
[15/24] Train loss=0.2809528410434723
[20/24] Train loss=0.21698549389839172
Test set avg_accuracy=73.82% avg_sensitivity=35.97%, avg_specificity=88.15% avg_auc=72.66%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.235583 Test loss=0.536291 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.21493807435035706
[5/24] Train loss=0.2258078008890152
[10/24] Train loss=0.26223817467689514
[15/24] Train loss=0.27124160528182983
[20/24] Train loss=0.22013913094997406
Test set avg_accuracy=64.70% avg_sensitivity=61.71%, avg_specificity=65.83% avg_auc=71.32%
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.236324 Test loss=0.597074 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.21929322183132172
[5/24] Train loss=0.2271973043680191
[10/24] Train loss=0.25315389037132263
[15/24] Train loss=0.27276739478111267
[20/24] Train loss=0.217506542801857
Test set avg_accuracy=76.82% avg_sensitivity=64.79%, avg_specificity=81.38% avg_auc=80.45%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.230718 Test loss=0.493883 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2064480185508728
[5/24] Train loss=0.22752375900745392
[10/24] Train loss=0.24597816169261932
[15/24] Train loss=0.26671484112739563
[20/24] Train loss=0.2133706957101822
Test set avg_accuracy=66.22% avg_sensitivity=75.07%, avg_specificity=62.87% avg_auc=75.77%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.227060 Test loss=0.599641 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2066957652568817
[5/24] Train loss=0.21274176239967346
[10/24] Train loss=0.25086459517478943
[15/24] Train loss=0.2621103823184967
[20/24] Train loss=0.21125318109989166
Test set avg_accuracy=63.98% avg_sensitivity=61.04%, avg_specificity=65.10% avg_auc=70.22%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.226150 Test loss=0.645270 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2029552310705185
[5/24] Train loss=0.21851038932800293
[10/24] Train loss=0.23668067157268524
[15/24] Train loss=0.25588688254356384
[20/24] Train loss=0.21303986012935638
Test set avg_accuracy=70.85% avg_sensitivity=70.62%, avg_specificity=70.93% avg_auc=77.67%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.222349 Test loss=0.555417 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.20828740298748016
[5/24] Train loss=0.21440233290195465
[10/24] Train loss=0.24829325079917908
[15/24] Train loss=0.2660716474056244
[20/24] Train loss=0.20780031383037567
Test set avg_accuracy=70.91% avg_sensitivity=57.16%, avg_specificity=76.12% avg_auc=74.73%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.221350 Test loss=0.558475 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.20452646911144257
[5/24] Train loss=0.2174386829137802
[10/24] Train loss=0.2375151664018631
[15/24] Train loss=0.2579609453678131
[20/24] Train loss=0.2093542516231537
Test set avg_accuracy=75.27% avg_sensitivity=72.56%, avg_specificity=76.30% avg_auc=81.51%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.221341 Test loss=0.507383 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1984071135520935
[5/24] Train loss=0.21686482429504395
[10/24] Train loss=0.23347291350364685
[15/24] Train loss=0.24751527607440948
[20/24] Train loss=0.21185535192489624
Test set avg_accuracy=82.54% avg_sensitivity=68.96%, avg_specificity=87.68% avg_auc=86.07%
Best model saved!! Metric=-0.7496328636185865!!
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.220651 Test loss=0.411973 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.206629678606987
[5/24] Train loss=0.20973673462867737
[10/24] Train loss=0.23528973758220673
[15/24] Train loss=0.2564864754676819
[20/24] Train loss=0.2006874829530716
Test set avg_accuracy=69.93% avg_sensitivity=70.47%, avg_specificity=69.73% avg_auc=77.81%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.218427 Test loss=0.554229 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.20229557156562805
[5/24] Train loss=0.21157565712928772
[10/24] Train loss=0.23035146296024323
[15/24] Train loss=0.2476319819688797
[20/24] Train loss=0.20205645263195038
Test set avg_accuracy=68.19% avg_sensitivity=71.75%, avg_specificity=66.84% avg_auc=77.31%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.217295 Test loss=0.566502 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.19331108033657074
[5/24] Train loss=0.21085384488105774
[10/24] Train loss=0.23570631444454193
[15/24] Train loss=0.2490583211183548
[20/24] Train loss=0.2189711630344391
Test set avg_accuracy=64.83% avg_sensitivity=63.55%, avg_specificity=65.31% avg_auc=71.50%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.217993 Test loss=0.622902 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.19776758551597595
[5/24] Train loss=0.2116032987833023
[10/24] Train loss=0.2399320751428604
[15/24] Train loss=0.2449193298816681
[20/24] Train loss=0.20569747686386108
Test set avg_accuracy=67.30% avg_sensitivity=41.71%, avg_specificity=77.00% avg_auc=66.62%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.219276 Test loss=0.639239 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.20977461338043213
[5/24] Train loss=0.20810064673423767
[10/24] Train loss=0.23516115546226501
[15/24] Train loss=0.25501352548599243
[20/24] Train loss=0.1984386295080185
Test set avg_accuracy=70.65% avg_sensitivity=27.96%, avg_specificity=86.82% avg_auc=66.45%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.217815 Test loss=0.627000 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.19978927075862885
[5/24] Train loss=0.21482108533382416
[10/24] Train loss=0.23001840710639954
[15/24] Train loss=0.2571609914302826
[20/24] Train loss=0.20737804472446442
Test set avg_accuracy=67.93% avg_sensitivity=67.73%, avg_specificity=68.01% avg_auc=75.06%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.219234 Test loss=0.603164 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1982399970293045
[5/24] Train loss=0.20505991578102112
[10/24] Train loss=0.23805882036685944
[15/24] Train loss=0.24994981288909912
[20/24] Train loss=0.20012614130973816
Test set avg_accuracy=67.50% avg_sensitivity=74.64%, avg_specificity=64.79% avg_auc=77.04%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.212165 Test loss=0.600402 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1934424489736557
[5/24] Train loss=0.19662915170192719
[10/24] Train loss=0.22497782111167908
[15/24] Train loss=0.2543402910232544
[20/24] Train loss=0.1975056380033493
Test set avg_accuracy=64.41% avg_sensitivity=61.52%, avg_specificity=65.51% avg_auc=70.80%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.207974 Test loss=0.627608 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.18729408085346222
[5/24] Train loss=0.19697479903697968
[10/24] Train loss=0.2241833359003067
[15/24] Train loss=0.24727971851825714
[20/24] Train loss=0.19164788722991943
Test set avg_accuracy=67.51% avg_sensitivity=48.10%, avg_specificity=74.87% avg_auc=69.79%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.206191 Test loss=0.602128 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.19056332111358643
[5/24] Train loss=0.19445538520812988
[10/24] Train loss=0.21864251792430878
[15/24] Train loss=0.24659349024295807
[20/24] Train loss=0.19428057968616486
Test set avg_accuracy=64.93% avg_sensitivity=67.87%, avg_specificity=63.82% avg_auc=72.43%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.205731 Test loss=0.640511 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1880227029323578
[5/24] Train loss=0.1963813304901123
[10/24] Train loss=0.21541516482830048
[15/24] Train loss=0.2388840615749359
[20/24] Train loss=0.18643854558467865
Test set avg_accuracy=63.91% avg_sensitivity=66.87%, avg_specificity=62.78% avg_auc=71.94%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.200890 Test loss=0.637089 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.18484024703502655
[5/24] Train loss=0.19213013350963593
[10/24] Train loss=0.21858654916286469
[15/24] Train loss=0.22760921716690063
[20/24] Train loss=0.1926908791065216
Test set avg_accuracy=63.14% avg_sensitivity=70.62%, avg_specificity=60.31% avg_auc=71.52%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.200337 Test loss=0.664447 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18573860824108124
[5/24] Train loss=0.190199613571167
[10/24] Train loss=0.21900318562984467
[15/24] Train loss=0.23865313827991486
[20/24] Train loss=0.18914729356765747
Test set avg_accuracy=64.36% avg_sensitivity=66.59%, avg_specificity=63.52% avg_auc=71.90%
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.199409 Test loss=0.635151 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.18224605917930603
[5/24] Train loss=0.1953163892030716
[10/24] Train loss=0.216161847114563
[15/24] Train loss=0.23251183331012726
[20/24] Train loss=0.18739639222621918
Test set avg_accuracy=65.29% avg_sensitivity=66.68%, avg_specificity=64.76% avg_auc=72.49%
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.198748 Test loss=0.628366 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.18157488107681274
[5/24] Train loss=0.18999965488910675
[10/24] Train loss=0.21574439108371735
[15/24] Train loss=0.22594310343265533
[20/24] Train loss=0.18847975134849548
Test set avg_accuracy=65.25% avg_sensitivity=67.30%, avg_specificity=64.47% avg_auc=72.61%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.196653 Test loss=0.634507 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.17787864804267883
[5/24] Train loss=0.18494130671024323
[10/24] Train loss=0.2106500267982483
[15/24] Train loss=0.2293851375579834
[20/24] Train loss=0.19035619497299194
Test set avg_accuracy=65.76% avg_sensitivity=64.27%, avg_specificity=66.32% avg_auc=72.81%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.194660 Test loss=0.618858 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.18454791605472565
[5/24] Train loss=0.1828935742378235
[10/24] Train loss=0.21397393941879272
[15/24] Train loss=0.2338007092475891
[20/24] Train loss=0.1862856149673462
Test set avg_accuracy=65.05% avg_sensitivity=65.55%, avg_specificity=64.87% avg_auc=72.44%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.194454 Test loss=0.632206 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.18200857937335968
[5/24] Train loss=0.18683943152427673
[10/24] Train loss=0.2146604061126709
[15/24] Train loss=0.23145094513893127
[20/24] Train loss=0.18730339407920837
Test set avg_accuracy=65.07% avg_sensitivity=66.87%, avg_specificity=64.38% avg_auc=73.08%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.194609 Test loss=0.629911 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.17873860895633698
[5/24] Train loss=0.18612007796764374
[10/24] Train loss=0.20521216094493866
[15/24] Train loss=0.22706462442874908
[20/24] Train loss=0.18476557731628418
Test set avg_accuracy=65.92% avg_sensitivity=65.45%, avg_specificity=66.10% avg_auc=73.30%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.193581 Test loss=0.620040 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.17637886106967926
[5/24] Train loss=0.18529720604419708
[10/24] Train loss=0.20970763266086578
[15/24] Train loss=0.24396711587905884
[20/24] Train loss=0.18449805676937103
Test set avg_accuracy=65.35% avg_sensitivity=64.74%, avg_specificity=65.58% avg_auc=72.39%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.193373 Test loss=0.634453 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1846550852060318
[5/24] Train loss=0.18181803822517395
[10/24] Train loss=0.2086818814277649
[15/24] Train loss=0.23005983233451843
[20/24] Train loss=0.1866040974855423
Test set avg_accuracy=66.15% avg_sensitivity=63.55%, avg_specificity=67.13% avg_auc=72.73%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.192133 Test loss=0.622219 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1772376298904419
[5/24] Train loss=0.18225489556789398
[10/24] Train loss=0.21054202318191528
[15/24] Train loss=0.22453774511814117
[20/24] Train loss=0.18691463768482208
Test set avg_accuracy=65.61% avg_sensitivity=62.46%, avg_specificity=66.80% avg_auc=72.11%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.191896 Test loss=0.624384 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1762622594833374
[5/24] Train loss=0.18525715172290802
[10/24] Train loss=0.2069118320941925
[15/24] Train loss=0.22818070650100708
[20/24] Train loss=0.18116618692874908
Test set avg_accuracy=65.77% avg_sensitivity=62.37%, avg_specificity=67.06% avg_auc=72.29%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.191148 Test loss=0.620526 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17636534571647644
[5/24] Train loss=0.1843883991241455
[10/24] Train loss=0.20547538995742798
[15/24] Train loss=0.22647549211978912
[20/24] Train loss=0.1819741129875183
Test set avg_accuracy=65.04% avg_sensitivity=64.03%, avg_specificity=65.42% avg_auc=72.21%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.190702 Test loss=0.627735 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1777389794588089
[5/24] Train loss=0.1851896047592163
[10/24] Train loss=0.206228569149971
[15/24] Train loss=0.22360427677631378
[20/24] Train loss=0.18629135191440582
Test set avg_accuracy=65.22% avg_sensitivity=65.69%, avg_specificity=65.04% avg_auc=72.68%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.191318 Test loss=0.629151 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.18326719105243683
[5/24] Train loss=0.18308605253696442
[10/24] Train loss=0.205313041806221
[15/24] Train loss=0.22661636769771576
[20/24] Train loss=0.1824679672718048
Test set avg_accuracy=65.34% avg_sensitivity=65.21%, avg_specificity=65.39% avg_auc=72.65%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.190299 Test loss=0.630345 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.17999841272830963
[5/24] Train loss=0.1818561851978302
[10/24] Train loss=0.21042487025260925
[15/24] Train loss=0.21804000437259674
[20/24] Train loss=0.1814030408859253
Test set avg_accuracy=65.42% avg_sensitivity=63.98%, avg_specificity=65.96% avg_auc=72.39%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.190852 Test loss=0.631693 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.17907600104808807
[5/24] Train loss=0.1805558204650879
[10/24] Train loss=0.20632080733776093
[15/24] Train loss=0.21921662986278534
[20/24] Train loss=0.1830940693616867
Test set avg_accuracy=65.95% avg_sensitivity=64.12%, avg_specificity=66.64% avg_auc=72.91%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.190179 Test loss=0.622067 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.17639708518981934
[5/24] Train loss=0.17819824814796448
[10/24] Train loss=0.2041359692811966
[15/24] Train loss=0.22504642605781555
[20/24] Train loss=0.18167293071746826
Test set avg_accuracy=65.73% avg_sensitivity=64.17%, avg_specificity=66.32% avg_auc=72.70%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.190417 Test loss=0.625670 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.17742711305618286
[5/24] Train loss=0.182844340801239
[10/24] Train loss=0.2039542943239212
[15/24] Train loss=0.22377660870552063
[20/24] Train loss=0.18325233459472656
Test set avg_accuracy=65.53% avg_sensitivity=63.89%, avg_specificity=66.16% avg_auc=72.55%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.189861 Test loss=0.627439 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1759961098432541
[5/24] Train loss=0.18345026671886444
[10/24] Train loss=0.2020418643951416
[15/24] Train loss=0.2198478877544403
[20/24] Train loss=0.1814671903848648
Test set avg_accuracy=65.64% avg_sensitivity=63.98%, avg_specificity=66.27% avg_auc=72.69%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.189321 Test loss=0.625941 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1755097657442093
[5/24] Train loss=0.18281608819961548
[10/24] Train loss=0.20706366002559662
[15/24] Train loss=0.235125333070755
[20/24] Train loss=0.18034720420837402
Test set avg_accuracy=65.59% avg_sensitivity=64.08%, avg_specificity=66.16% avg_auc=72.74%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.190449 Test loss=0.626367 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1759643852710724
[5/24] Train loss=0.17783531546592712
[10/24] Train loss=0.20678728818893433
[15/24] Train loss=0.22286245226860046
[20/24] Train loss=0.18307384848594666
Test set avg_accuracy=65.62% avg_sensitivity=64.03%, avg_specificity=66.23% avg_auc=72.75%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.189970 Test loss=0.625948 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=82.54% sen=68.96%, spe=87.68%, auc=86.07%!
Fold[3] Avg_overlap=0.64%(±0.2465828879907533)
[0/24] Train loss=0.7500806450843811
[5/24] Train loss=0.7511046528816223
[10/24] Train loss=0.7485880255699158
[15/24] Train loss=0.7478145360946655
[20/24] Train loss=0.7355548739433289
Test set avg_accuracy=54.54% avg_sensitivity=40.93%, avg_specificity=59.34% avg_auc=49.89%
Best model saved!! Metric=-121.29793695870305!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=0.746994 Test loss=0.702969 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7379637956619263
[5/24] Train loss=0.7383484244346619
[10/24] Train loss=0.7421483993530273
[15/24] Train loss=0.7411525845527649
[20/24] Train loss=0.72799152135849
Test set avg_accuracy=54.27% avg_sensitivity=41.13%, avg_specificity=58.90% avg_auc=50.67%
Best model saved!! Metric=-121.02490090907177!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.737024 Test loss=0.692304 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7269716262817383
[5/24] Train loss=0.7279105186462402
[10/24] Train loss=0.7326216101646423
[15/24] Train loss=0.7394233345985413
[20/24] Train loss=0.7233881950378418
Test set avg_accuracy=52.08% avg_sensitivity=45.68%, avg_specificity=54.34% avg_auc=50.94%
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.729338 Test loss=0.691781 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7216340899467468
[5/24] Train loss=0.7197138667106628
[10/24] Train loss=0.7220280766487122
[15/24] Train loss=0.7205279469490051
[20/24] Train loss=0.7073085308074951
Test set avg_accuracy=51.37% avg_sensitivity=48.33%, avg_specificity=52.44% avg_auc=51.42%
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.717524 Test loss=0.690325 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.7038982510566711
[5/24] Train loss=0.7041805386543274
[10/24] Train loss=0.709092378616333
[15/24] Train loss=0.7136958241462708
[20/24] Train loss=0.697734534740448
Test set avg_accuracy=54.75% avg_sensitivity=42.88%, avg_specificity=58.94% avg_auc=51.94%
Best model saved!! Metric=-117.4962207077424!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.704865 Test loss=0.688490 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6951383948326111
[5/24] Train loss=0.6961645483970642
[10/24] Train loss=0.7009298205375671
[15/24] Train loss=0.7104786038398743
[20/24] Train loss=0.684153139591217
Test set avg_accuracy=54.69% avg_sensitivity=42.63%, avg_specificity=58.94% avg_auc=52.44%
Best model saved!! Metric=-117.30694862882874!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.695145 Test loss=0.680859 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6861691474914551
[5/24] Train loss=0.6825177669525146
[10/24] Train loss=0.6865257620811462
[15/24] Train loss=0.6966928243637085
[20/24] Train loss=0.6756151914596558
Test set avg_accuracy=54.93% avg_sensitivity=44.38%, avg_specificity=58.65% avg_auc=52.67%
Best model saved!! Metric=-115.36434915589948!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.681922 Test loss=0.679159 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6678957939147949
[5/24] Train loss=0.6696881055831909
[10/24] Train loss=0.6758639216423035
[15/24] Train loss=0.6786003708839417
[20/24] Train loss=0.6556136012077332
Test set avg_accuracy=58.11% avg_sensitivity=36.98%, avg_specificity=65.56% avg_auc=53.48%
Best model saved!! Metric=-111.8729750017853!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.669411 Test loss=0.668803 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6599613428115845
[5/24] Train loss=0.6578171253204346
[10/24] Train loss=0.66481614112854
[15/24] Train loss=0.6701628565788269
[20/24] Train loss=0.646435558795929
Test set avg_accuracy=63.89% avg_sensitivity=28.24%, avg_specificity=76.46% avg_auc=53.69%
Best model saved!! Metric=-103.72059589826169!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.656892 Test loss=0.662504 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6444212198257446
[5/24] Train loss=0.6382750272750854
[10/24] Train loss=0.6535565853118896
[15/24] Train loss=0.6561408638954163
[20/24] Train loss=0.6337689757347107
Test set avg_accuracy=73.61% avg_sensitivity=14.54%, avg_specificity=94.42% avg_auc=55.16%
Best model saved!! Metric=-88.27427614097843!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.643785 Test loss=0.642157 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6292638182640076
[5/24] Train loss=0.6251075863838196
[10/24] Train loss=0.6414703726768494
[15/24] Train loss=0.6420276761054993
[20/24] Train loss=0.6215869188308716
Test set avg_accuracy=70.69% avg_sensitivity=17.14%, avg_specificity=89.56% avg_auc=56.28%
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.629198 Test loss=0.624916 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6181297898292542
[5/24] Train loss=0.6051741242408752
[10/24] Train loss=0.6210191249847412
[15/24] Train loss=0.6383036375045776
[20/24] Train loss=0.6000410318374634
Test set avg_accuracy=73.50% avg_sensitivity=14.29%, avg_specificity=94.37% avg_auc=58.55%
Best model saved!! Metric=-85.28763040437323!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.614245 Test loss=0.599126 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.597845196723938
[5/24] Train loss=0.5925300121307373
[10/24] Train loss=0.6171219944953918
[15/24] Train loss=0.6277284026145935
[20/24] Train loss=0.5929238200187683
Test set avg_accuracy=74.14% avg_sensitivity=12.04%, avg_specificity=96.02% avg_auc=61.66%
Best model saved!! Metric=-82.13529620474363!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.599179 Test loss=0.560404 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5825008749961853
[5/24] Train loss=0.5703005790710449
[10/24] Train loss=0.5996213555335999
[15/24] Train loss=0.6125546097755432
[20/24] Train loss=0.5671288371086121
Test set avg_accuracy=74.22% avg_sensitivity=16.64%, avg_specificity=94.51% avg_auc=64.93%
Best model saved!! Metric=-75.70689063099637!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.578990 Test loss=0.550946 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5475278496742249
[5/24] Train loss=0.5416033864021301
[10/24] Train loss=0.583118200302124
[15/24] Train loss=0.5850833654403687
[20/24] Train loss=0.523704469203949
Test set avg_accuracy=75.03% avg_sensitivity=23.09%, avg_specificity=93.33% avg_auc=70.92%
Best model saved!! Metric=-63.64039320886967!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.549604 Test loss=0.524327 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.5171295404434204
[5/24] Train loss=0.5289188623428345
[10/24] Train loss=0.5619267821311951
[15/24] Train loss=0.5755601525306702
[20/24] Train loss=0.4920205771923065
Test set avg_accuracy=75.79% avg_sensitivity=26.59%, avg_specificity=93.13% avg_auc=72.09%
Best model saved!! Metric=-58.39713883249759!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.519287 Test loss=0.542567 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.48165780305862427
[5/24] Train loss=0.4941785931587219
[10/24] Train loss=0.5270402431488037
[15/24] Train loss=0.5339851379394531
[20/24] Train loss=0.4731307625770569
Test set avg_accuracy=78.78% avg_sensitivity=46.48%, avg_specificity=90.16% avg_auc=78.88%
Best model saved!! Metric=-31.706980953032463!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.488396 Test loss=0.468988 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.46359983086586
[5/24] Train loss=0.4711898863315582
[10/24] Train loss=0.5154760479927063
[15/24] Train loss=0.5239036679267883
[20/24] Train loss=0.449341744184494
Test set avg_accuracy=78.46% avg_sensitivity=56.42%, avg_specificity=86.23% avg_auc=79.45%
Best model saved!! Metric=-25.435592055783587!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.468886 Test loss=0.505189 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.44133615493774414
[5/24] Train loss=0.4563550055027008
[10/24] Train loss=0.49727684259414673
[15/24] Train loss=0.5051186084747314
[20/24] Train loss=0.4386366903781891
Test set avg_accuracy=53.03% avg_sensitivity=65.27%, avg_specificity=48.72% avg_auc=59.72%
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.452779 Test loss=0.690285 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4171586036682129
[5/24] Train loss=0.4320809841156006
[10/24] Train loss=0.4811704158782959
[15/24] Train loss=0.4895077049732208
[20/24] Train loss=0.41896897554397583
Test set avg_accuracy=53.27% avg_sensitivity=65.12%, avg_specificity=49.09% avg_auc=61.59%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.436708 Test loss=0.696190 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4015367031097412
[5/24] Train loss=0.41156065464019775
[10/24] Train loss=0.4696102440357208
[15/24] Train loss=0.4805680811405182
[20/24] Train loss=0.4092652201652527
Test set avg_accuracy=52.54% avg_sensitivity=65.52%, avg_specificity=47.97% avg_auc=60.59%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.426038 Test loss=0.699266 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3869379460811615
[5/24] Train loss=0.40774914622306824
[10/24] Train loss=0.45961248874664307
[15/24] Train loss=0.4774697422981262
[20/24] Train loss=0.39497193694114685
Test set avg_accuracy=54.70% avg_sensitivity=63.42%, avg_specificity=51.63% avg_auc=61.58%
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.418398 Test loss=0.678511 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.395535945892334
[5/24] Train loss=0.39555200934410095
[10/24] Train loss=0.46824678778648376
[15/24] Train loss=0.4803861975669861
[20/24] Train loss=0.39832302927970886
Test set avg_accuracy=55.03% avg_sensitivity=65.12%, avg_specificity=51.47% avg_auc=61.80%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.416873 Test loss=0.696095 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3817426860332489
[5/24] Train loss=0.39156675338745117
[10/24] Train loss=0.45798203349113464
[15/24] Train loss=0.46641045808792114
[20/24] Train loss=0.38863158226013184
Test set avg_accuracy=60.23% avg_sensitivity=63.92%, avg_specificity=58.94% avg_auc=66.23%
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.411748 Test loss=0.662525 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3824789226055145
[5/24] Train loss=0.37330272793769836
[10/24] Train loss=0.44989654421806335
[15/24] Train loss=0.4671538174152374
[20/24] Train loss=0.3866129517555237
Test set avg_accuracy=78.18% avg_sensitivity=64.12%, avg_specificity=83.13% avg_auc=80.86%
Best model saved!! Metric=-19.713182134390635!!
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.405591 Test loss=0.490844 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3992408215999603
[5/24] Train loss=0.383993923664093
[10/24] Train loss=0.44014883041381836
[15/24] Train loss=0.45108041167259216
[20/24] Train loss=0.37859976291656494
Test set avg_accuracy=59.30% avg_sensitivity=64.47%, avg_specificity=57.47% avg_auc=66.63%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.404561 Test loss=0.642718 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.36010444164276123
[5/24] Train loss=0.37164926528930664
[10/24] Train loss=0.4362463653087616
[15/24] Train loss=0.4538169503211975
[20/24] Train loss=0.37179744243621826
Test set avg_accuracy=50.72% avg_sensitivity=68.17%, avg_specificity=44.57% avg_auc=59.70%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.397924 Test loss=0.710356 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.36416080594062805
[5/24] Train loss=0.3846715986728668
[10/24] Train loss=0.4410700798034668
[15/24] Train loss=0.445008784532547
[20/24] Train loss=0.37521496415138245
Test set avg_accuracy=53.45% avg_sensitivity=63.57%, avg_specificity=49.89% avg_auc=59.98%
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.394183 Test loss=0.706922 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3571825921535492
[5/24] Train loss=0.3601590096950531
[10/24] Train loss=0.4459645450115204
[15/24] Train loss=0.45181289315223694
[20/24] Train loss=0.36092615127563477
Test set avg_accuracy=75.16% avg_sensitivity=64.37%, avg_specificity=78.96% avg_auc=77.92%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.392878 Test loss=0.526804 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.37416383624076843
[5/24] Train loss=0.35797202587127686
[10/24] Train loss=0.43023377656936646
[15/24] Train loss=0.44465765357017517
[20/24] Train loss=0.3608306646347046
Test set avg_accuracy=50.87% avg_sensitivity=69.72%, avg_specificity=44.23% avg_auc=61.46%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.388743 Test loss=0.698419 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.35598599910736084
[5/24] Train loss=0.3506944179534912
[10/24] Train loss=0.43150338530540466
[15/24] Train loss=0.4367187023162842
[20/24] Train loss=0.3586918115615845
Test set avg_accuracy=53.72% avg_sensitivity=72.31%, avg_specificity=47.17% avg_auc=67.84%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.383538 Test loss=0.668324 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3613133728504181
[5/24] Train loss=0.35322684049606323
[10/24] Train loss=0.4178221821784973
[15/24] Train loss=0.43093088269233704
[20/24] Train loss=0.35830068588256836
Test set avg_accuracy=75.86% avg_sensitivity=58.42%, avg_specificity=82.00% avg_auc=77.03%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.382333 Test loss=0.550188 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3524438440799713
[5/24] Train loss=0.3533918559551239
[10/24] Train loss=0.43059560656547546
[15/24] Train loss=0.45220494270324707
[20/24] Train loss=0.35528045892715454
Test set avg_accuracy=62.79% avg_sensitivity=59.87%, avg_specificity=63.81% avg_auc=66.88%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.384797 Test loss=0.633624 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35655099153518677
[5/24] Train loss=0.3420126140117645
[10/24] Train loss=0.41935446858406067
[15/24] Train loss=0.4343700110912323
[20/24] Train loss=0.34543198347091675
Test set avg_accuracy=58.28% avg_sensitivity=68.22%, avg_specificity=54.78% avg_auc=66.77%
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.373741 Test loss=0.655440 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.35546860098838806
[5/24] Train loss=0.34391966462135315
[10/24] Train loss=0.4351347088813782
[15/24] Train loss=0.43593770265579224
[20/24] Train loss=0.3421992063522339
Test set avg_accuracy=81.67% avg_sensitivity=60.57%, avg_specificity=89.10% avg_auc=81.80%
Best model saved!! Metric=-12.85965302258186!!
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.375406 Test loss=0.495869 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.36382347345352173
[5/24] Train loss=0.341338187456131
[10/24] Train loss=0.4129294753074646
[15/24] Train loss=0.4477182626724243
[20/24] Train loss=0.3502303957939148
Test set avg_accuracy=71.41% avg_sensitivity=53.97%, avg_specificity=77.55% avg_auc=72.49%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.376495 Test loss=0.583411 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3497653305530548
[5/24] Train loss=0.33675721287727356
[10/24] Train loss=0.4172595739364624
[15/24] Train loss=0.43595823645591736
[20/24] Train loss=0.340617835521698
Test set avg_accuracy=52.64% avg_sensitivity=67.77%, avg_specificity=47.31% avg_auc=60.64%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.369112 Test loss=0.722952 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3346062898635864
[5/24] Train loss=0.33568841218948364
[10/24] Train loss=0.4242844581604004
[15/24] Train loss=0.43762585520744324
[20/24] Train loss=0.3309980034828186
Test set avg_accuracy=57.66% avg_sensitivity=67.57%, avg_specificity=54.16% avg_auc=63.79%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.364442 Test loss=0.675696 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.33792218565940857
[5/24] Train loss=0.34200072288513184
[10/24] Train loss=0.3991420865058899
[15/24] Train loss=0.40172070264816284
[20/24] Train loss=0.3251473903656006
Test set avg_accuracy=55.52% avg_sensitivity=65.17%, avg_specificity=52.12% avg_auc=62.56%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.356213 Test loss=0.694929 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.3327530026435852
[5/24] Train loss=0.3251623213291168
[10/24] Train loss=0.40076854825019836
[15/24] Train loss=0.405979722738266
[20/24] Train loss=0.41015103459358215
Test set avg_accuracy=81.37% avg_sensitivity=47.83%, avg_specificity=93.19% avg_auc=84.44%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.360754 Test loss=0.424099 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3689815104007721
[5/24] Train loss=0.34525007009506226
[10/24] Train loss=0.4069399833679199
[15/24] Train loss=0.41169238090515137
[20/24] Train loss=0.34606805443763733
Test set avg_accuracy=81.15% avg_sensitivity=42.58%, avg_specificity=94.73% avg_auc=83.96%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.368896 Test loss=0.480354 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.34447112679481506
[5/24] Train loss=0.33790937066078186
[10/24] Train loss=0.39714574813842773
[15/24] Train loss=0.4048269987106323
[20/24] Train loss=0.32747411727905273
Test set avg_accuracy=64.62% avg_sensitivity=53.77%, avg_specificity=68.45% avg_auc=66.60%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.357166 Test loss=0.618421 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3283379375934601
[5/24] Train loss=0.3175581395626068
[10/24] Train loss=0.39316877722740173
[15/24] Train loss=0.40160685777664185
[20/24] Train loss=0.3434571623802185
Test set avg_accuracy=82.11% avg_sensitivity=56.67%, avg_specificity=91.07% avg_auc=84.77%
Best model saved!! Metric=-11.378134986862506!!
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.351914 Test loss=0.409510 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3456108272075653
[5/24] Train loss=0.33337029814720154
[10/24] Train loss=0.38949790596961975
[15/24] Train loss=0.4040638208389282
[20/24] Train loss=0.34539249539375305
Test set avg_accuracy=70.79% avg_sensitivity=49.83%, avg_specificity=78.18% avg_auc=69.66%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.351728 Test loss=0.579522 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3179410696029663
[5/24] Train loss=0.3129728436470032
[10/24] Train loss=0.3848665952682495
[15/24] Train loss=0.41373923420906067
[20/24] Train loss=0.32255974411964417
Test set avg_accuracy=59.86% avg_sensitivity=77.46%, avg_specificity=53.65% avg_auc=71.14%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.346097 Test loss=0.651295 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3301033079624176
[5/24] Train loss=0.3182069957256317
[10/24] Train loss=0.3688336908817291
[15/24] Train loss=0.3799141049385071
[20/24] Train loss=0.3169853985309601
Test set avg_accuracy=57.46% avg_sensitivity=69.07%, avg_specificity=53.37% avg_auc=66.49%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.340914 Test loss=0.669314 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.32485106587409973
[5/24] Train loss=0.31847795844078064
[10/24] Train loss=0.3798484802246094
[15/24] Train loss=0.3758440315723419
[20/24] Train loss=0.3347896635532379
Test set avg_accuracy=83.15% avg_sensitivity=58.97%, avg_specificity=91.67% avg_auc=87.78%
Best model saved!! Metric=-4.431470475747766!!
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.340628 Test loss=0.374731 Current lr=[0.000299720220882401]

[0/24] Train loss=0.36439672112464905
[5/24] Train loss=0.32362431287765503
[10/24] Train loss=0.3726027309894562
[15/24] Train loss=0.37406712770462036
[20/24] Train loss=0.31110861897468567
Test set avg_accuracy=76.86% avg_sensitivity=68.87%, avg_specificity=79.68% avg_auc=80.94%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.339001 Test loss=0.491068 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3302563428878784
[5/24] Train loss=0.3191007673740387
[10/24] Train loss=0.3740336298942566
[15/24] Train loss=0.3749328851699829
[20/24] Train loss=0.3206537961959839
Test set avg_accuracy=54.14% avg_sensitivity=62.42%, avg_specificity=51.22% avg_auc=60.80%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.334741 Test loss=0.727332 Current lr=[0.000298904600941902]

[0/24] Train loss=0.32048091292381287
[5/24] Train loss=0.2998216152191162
[10/24] Train loss=0.37999600172042847
[15/24] Train loss=0.37206682562828064
[20/24] Train loss=0.30754339694976807
Test set avg_accuracy=81.74% avg_sensitivity=46.88%, avg_specificity=94.03% avg_auc=84.95%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.331998 Test loss=0.452620 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.33183804154396057
[5/24] Train loss=0.31619974970817566
[10/24] Train loss=0.3646908104419708
[15/24] Train loss=0.36386001110076904
[20/24] Train loss=0.311635822057724
Test set avg_accuracy=79.97% avg_sensitivity=67.37%, avg_specificity=84.42% avg_auc=82.56%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.330505 Test loss=0.476860 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3027055561542511
[5/24] Train loss=0.310202956199646
[10/24] Train loss=0.3554660975933075
[15/24] Train loss=0.3748057186603546
[20/24] Train loss=0.30604133009910583
Test set avg_accuracy=53.95% avg_sensitivity=73.41%, avg_specificity=47.09% avg_auc=63.10%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.325693 Test loss=0.700388 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.32911416888237
[5/24] Train loss=0.30546653270721436
[10/24] Train loss=0.3596774637699127
[15/24] Train loss=0.3716311454772949
[20/24] Train loss=0.30432409048080444
Test set avg_accuracy=63.16% avg_sensitivity=68.97%, avg_specificity=61.12% avg_auc=70.67%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.321266 Test loss=0.627877 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.31962597370147705
[5/24] Train loss=0.3138018548488617
[10/24] Train loss=0.3792293667793274
[15/24] Train loss=0.36918318271636963
[20/24] Train loss=0.3092506527900696
Test set avg_accuracy=71.52% avg_sensitivity=49.33%, avg_specificity=79.34% avg_auc=72.53%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.325288 Test loss=0.545642 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.31491178274154663
[5/24] Train loss=0.30353230237960815
[10/24] Train loss=0.36772826313972473
[15/24] Train loss=0.3744613528251648
[20/24] Train loss=0.2896895110607147
Test set avg_accuracy=61.24% avg_sensitivity=52.67%, avg_specificity=64.25% avg_auc=63.68%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.325141 Test loss=0.645026 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3002959191799164
[5/24] Train loss=0.3028053343296051
[10/24] Train loss=0.3745219111442566
[15/24] Train loss=0.3654220402240753
[20/24] Train loss=0.31909337639808655
Test set avg_accuracy=62.77% avg_sensitivity=54.22%, avg_specificity=65.79% avg_auc=66.54%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.326247 Test loss=0.643755 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.31500500440597534
[5/24] Train loss=0.3087451159954071
[10/24] Train loss=0.34123262763023376
[15/24] Train loss=0.3762058913707733
[20/24] Train loss=0.36276814341545105
Test set avg_accuracy=78.31% avg_sensitivity=44.73%, avg_specificity=90.14% avg_auc=80.28%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.330674 Test loss=0.453350 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.31793472170829773
[5/24] Train loss=0.32684576511383057
[10/24] Train loss=0.36280009150505066
[15/24] Train loss=0.3532378673553467
[20/24] Train loss=0.32041266560554504
Test set avg_accuracy=75.27% avg_sensitivity=71.06%, avg_specificity=76.76% avg_auc=80.94%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.322830 Test loss=0.507210 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3053014576435089
[5/24] Train loss=0.3053610622882843
[10/24] Train loss=0.3437650799751282
[15/24] Train loss=0.35336005687713623
[20/24] Train loss=0.29927533864974976
Test set avg_accuracy=83.41% avg_sensitivity=62.37%, avg_specificity=90.83% avg_auc=86.68%
Best model saved!! Metric=-2.7151916714758286!!
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.313693 Test loss=0.386846 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.315843790769577
[5/24] Train loss=0.31673136353492737
[10/24] Train loss=0.34778642654418945
[15/24] Train loss=0.34243249893188477
[20/24] Train loss=0.2896532118320465
Test set avg_accuracy=83.27% avg_sensitivity=55.12%, avg_specificity=93.19% avg_auc=86.88%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.316297 Test loss=0.381125 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3126658499240875
[5/24] Train loss=0.2858740985393524
[10/24] Train loss=0.3557162880897522
[15/24] Train loss=0.3767510950565338
[20/24] Train loss=0.3024270534515381
Test set avg_accuracy=72.10% avg_sensitivity=66.77%, avg_specificity=73.97% avg_auc=76.60%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.319871 Test loss=0.545770 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.29670360684394836
[5/24] Train loss=0.306367963552475
[10/24] Train loss=0.3547942042350769
[15/24] Train loss=0.3595883548259735
[20/24] Train loss=0.3035779893398285
Test set avg_accuracy=63.37% avg_sensitivity=62.87%, avg_specificity=63.55% avg_auc=69.11%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.321300 Test loss=0.639840 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3129846751689911
[5/24] Train loss=0.3012802302837372
[10/24] Train loss=0.344007670879364
[15/24] Train loss=0.3614331781864166
[20/24] Train loss=0.295123815536499
Test set avg_accuracy=77.67% avg_sensitivity=70.11%, avg_specificity=80.33% avg_auc=81.24%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.313165 Test loss=0.494367 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2961989641189575
[5/24] Train loss=0.3020775616168976
[10/24] Train loss=0.3405744731426239
[15/24] Train loss=0.35494914650917053
[20/24] Train loss=0.31169161200523376
Test set avg_accuracy=64.13% avg_sensitivity=71.91%, avg_specificity=61.38% avg_auc=72.94%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.315228 Test loss=0.613785 Current lr=[0.000276307469034998]

[0/24] Train loss=0.2958050072193146
[5/24] Train loss=0.2941090762615204
[10/24] Train loss=0.35171350836753845
[15/24] Train loss=0.3580651879310608
[20/24] Train loss=0.2999630570411682
Test set avg_accuracy=72.21% avg_sensitivity=56.67%, avg_specificity=77.69% avg_auc=73.25%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.305967 Test loss=0.572178 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.28635746240615845
[5/24] Train loss=0.29153597354888916
[10/24] Train loss=0.3287757933139801
[15/24] Train loss=0.3487459719181061
[20/24] Train loss=0.28742241859436035
Test set avg_accuracy=82.21% avg_sensitivity=51.72%, avg_specificity=92.96% avg_auc=83.51%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.304493 Test loss=0.428304 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2903205454349518
[5/24] Train loss=0.3035846948623657
[10/24] Train loss=0.3531128168106079
[15/24] Train loss=0.39125946164131165
[20/24] Train loss=0.29155993461608887
Test set avg_accuracy=64.32% avg_sensitivity=76.96%, avg_specificity=59.87% avg_auc=75.96%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.315209 Test loss=0.610000 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2913840711116791
[5/24] Train loss=0.2922869920730591
[10/24] Train loss=0.350361704826355
[15/24] Train loss=0.3456765413284302
[20/24] Train loss=0.2946367859840393
Test set avg_accuracy=60.60% avg_sensitivity=65.47%, avg_specificity=58.88% avg_auc=67.48%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.307936 Test loss=0.677956 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2810198664665222
[5/24] Train loss=0.2788838744163513
[10/24] Train loss=0.32805532217025757
[15/24] Train loss=0.3494007885456085
[20/24] Train loss=0.29120466113090515
Test set avg_accuracy=64.87% avg_sensitivity=77.91%, avg_specificity=60.27% avg_auc=77.14%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.298999 Test loss=0.620951 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2853730618953705
[5/24] Train loss=0.28616753220558167
[10/24] Train loss=0.32626044750213623
[15/24] Train loss=0.33588558435440063
[20/24] Train loss=0.28091612458229065
Test set avg_accuracy=64.58% avg_sensitivity=71.16%, avg_specificity=62.26% avg_auc=73.01%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.297512 Test loss=0.634844 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2899405360221863
[5/24] Train loss=0.2995545268058777
[10/24] Train loss=0.343753844499588
[15/24] Train loss=0.33021634817123413
[20/24] Train loss=0.29163840413093567
Test set avg_accuracy=66.63% avg_sensitivity=45.18%, avg_specificity=74.19% avg_auc=64.80%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.302326 Test loss=0.649573 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.27911803126335144
[5/24] Train loss=0.29242855310440063
[10/24] Train loss=0.3334169387817383
[15/24] Train loss=0.33833351731300354
[20/24] Train loss=0.2842676043510437
Test set avg_accuracy=57.36% avg_sensitivity=62.72%, avg_specificity=55.47% avg_auc=62.71%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.296349 Test loss=0.724344 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.27639642357826233
[5/24] Train loss=0.28082212805747986
[10/24] Train loss=0.3412610590457916
[15/24] Train loss=0.32574719190597534
[20/24] Train loss=0.30075913667678833
Test set avg_accuracy=64.23% avg_sensitivity=75.16%, avg_specificity=60.38% avg_auc=74.03%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.298083 Test loss=0.613101 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.26773250102996826
[5/24] Train loss=0.2863675355911255
[10/24] Train loss=0.32383039593696594
[15/24] Train loss=0.3446166515350342
[20/24] Train loss=0.28747260570526123
Test set avg_accuracy=58.59% avg_sensitivity=76.01%, avg_specificity=52.46% avg_auc=68.96%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.299737 Test loss=0.717698 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.27207159996032715
[5/24] Train loss=0.28365829586982727
[10/24] Train loss=0.3197627365589142
[15/24] Train loss=0.32839110493659973
[20/24] Train loss=0.27745020389556885
Test set avg_accuracy=62.08% avg_sensitivity=79.81%, avg_specificity=55.84% avg_auc=73.35%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.294862 Test loss=0.651276 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2886410653591156
[5/24] Train loss=0.2958543002605438
[10/24] Train loss=0.3472197353839874
[15/24] Train loss=0.34757691621780396
[20/24] Train loss=0.285710871219635
Test set avg_accuracy=60.74% avg_sensitivity=71.51%, avg_specificity=56.95% avg_auc=68.40%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.301362 Test loss=0.690190 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.25809288024902344
[5/24] Train loss=0.2788808345794678
[10/24] Train loss=0.3199540078639984
[15/24] Train loss=0.31915292143821716
[20/24] Train loss=0.28895753622055054
Test set avg_accuracy=52.89% avg_sensitivity=73.81%, avg_specificity=45.52% avg_auc=63.34%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.291696 Test loss=0.770016 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.27277085185050964
[5/24] Train loss=0.2753140926361084
[10/24] Train loss=0.3147980868816376
[15/24] Train loss=0.3316570520401001
[20/24] Train loss=0.285434365272522
Test set avg_accuracy=61.08% avg_sensitivity=67.07%, avg_specificity=58.97% avg_auc=67.76%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.292706 Test loss=0.635615 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2768733501434326
[5/24] Train loss=0.27559155225753784
[10/24] Train loss=0.31778350472450256
[15/24] Train loss=0.3242983818054199
[20/24] Train loss=0.29965680837631226
Test set avg_accuracy=84.11% avg_sensitivity=64.42%, avg_specificity=91.05% avg_auc=87.91%
Best model saved!! Metric=1.501720544794523!!
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.293063 Test loss=0.370355 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2836039364337921
[5/24] Train loss=0.27741003036499023
[10/24] Train loss=0.3127186894416809
[15/24] Train loss=0.3731037378311157
[20/24] Train loss=0.28778114914894104
Test set avg_accuracy=83.75% avg_sensitivity=61.92%, avg_specificity=91.44% avg_auc=86.27%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.302913 Test loss=0.387008 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2775735557079315
[5/24] Train loss=0.27121782302856445
[10/24] Train loss=0.323376327753067
[15/24] Train loss=0.3573535680770874
[20/24] Train loss=0.28296053409576416
Test set avg_accuracy=62.14% avg_sensitivity=74.51%, avg_specificity=57.77% avg_auc=71.78%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.294580 Test loss=0.670922 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.26881611347198486
[5/24] Train loss=0.26914986968040466
[10/24] Train loss=0.3097250461578369
[15/24] Train loss=0.3172798454761505
[20/24] Train loss=0.2975293695926666
Test set avg_accuracy=81.65% avg_sensitivity=72.86%, avg_specificity=84.75% avg_auc=85.26%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.284383 Test loss=0.441585 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.27914300560951233
[5/24] Train loss=0.26767897605895996
[10/24] Train loss=0.322449654340744
[15/24] Train loss=0.31781813502311707
[20/24] Train loss=0.2721013128757477
Test set avg_accuracy=64.26% avg_sensitivity=70.66%, avg_specificity=62.00% avg_auc=71.85%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.286425 Test loss=0.616117 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2638976573944092
[5/24] Train loss=0.273899644613266
[10/24] Train loss=0.296566903591156
[15/24] Train loss=0.32722634077072144
[20/24] Train loss=0.2706049680709839
Test set avg_accuracy=61.22% avg_sensitivity=79.51%, avg_specificity=54.78% avg_auc=73.33%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.282429 Test loss=0.678477 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2594909369945526
[5/24] Train loss=0.2696518003940582
[10/24] Train loss=0.29251474142074585
[15/24] Train loss=0.3135170340538025
[20/24] Train loss=0.2766270041465759
Test set avg_accuracy=59.86% avg_sensitivity=79.96%, avg_specificity=52.77% avg_auc=72.21%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.279206 Test loss=0.700483 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2558691203594208
[5/24] Train loss=0.26801931858062744
[10/24] Train loss=0.3136487901210785
[15/24] Train loss=0.33448371291160583
[20/24] Train loss=0.2746884226799011
Test set avg_accuracy=57.67% avg_sensitivity=77.21%, avg_specificity=50.78% avg_auc=68.58%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.282606 Test loss=0.717048 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.26228854060173035
[5/24] Train loss=0.2692033350467682
[10/24] Train loss=0.2931995093822479
[15/24] Train loss=0.3209329843521118
[20/24] Train loss=0.2742776870727539
Test set avg_accuracy=65.73% avg_sensitivity=69.82%, avg_specificity=64.29% avg_auc=72.72%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.284562 Test loss=0.646611 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.25729134678840637
[5/24] Train loss=0.2715335488319397
[10/24] Train loss=0.30276986956596375
[15/24] Train loss=0.3205808103084564
[20/24] Train loss=0.27515286207199097
Test set avg_accuracy=61.60% avg_sensitivity=80.06%, avg_specificity=55.10% avg_auc=73.54%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.285484 Test loss=0.688654 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.25745099782943726
[5/24] Train loss=0.2749136984348297
[10/24] Train loss=0.3062264323234558
[15/24] Train loss=0.3120531439781189
[20/24] Train loss=0.2739953100681305
Test set avg_accuracy=61.67% avg_sensitivity=73.56%, avg_specificity=57.47% avg_auc=70.31%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.279058 Test loss=0.718331 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.25055867433547974
[5/24] Train loss=0.2692767381668091
[10/24] Train loss=0.28768375515937805
[15/24] Train loss=0.30451178550720215
[20/24] Train loss=0.27518194913864136
Test set avg_accuracy=63.83% avg_sensitivity=66.72%, avg_specificity=62.81% avg_auc=69.55%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.276216 Test loss=0.657480 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2507501244544983
[5/24] Train loss=0.26390281319618225
[10/24] Train loss=0.30075767636299133
[15/24] Train loss=0.3272755444049835
[20/24] Train loss=0.269083172082901
Test set avg_accuracy=60.52% avg_sensitivity=75.46%, avg_specificity=55.26% avg_auc=70.06%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.277910 Test loss=0.732753 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.24912355840206146
[5/24] Train loss=0.26267972588539124
[10/24] Train loss=0.295180082321167
[15/24] Train loss=0.30516257882118225
[20/24] Train loss=0.2581275403499603
Test set avg_accuracy=60.86% avg_sensitivity=67.67%, avg_specificity=58.46% avg_auc=67.33%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.270176 Test loss=0.742136 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2574221193790436
[5/24] Train loss=0.2607334852218628
[10/24] Train loss=0.29011234641075134
[15/24] Train loss=0.2972707450389862
[20/24] Train loss=0.26444241404533386
Test set avg_accuracy=65.89% avg_sensitivity=70.36%, avg_specificity=64.31% avg_auc=73.56%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.271669 Test loss=0.667449 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2455640584230423
[5/24] Train loss=0.25981101393699646
[10/24] Train loss=0.2836359441280365
[15/24] Train loss=0.3023397922515869
[20/24] Train loss=0.26360079646110535
Test set avg_accuracy=65.89% avg_sensitivity=65.27%, avg_specificity=66.10% avg_auc=71.16%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.267145 Test loss=0.631131 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24784453213214874
[5/24] Train loss=0.2702732980251312
[10/24] Train loss=0.30959993600845337
[15/24] Train loss=0.31372973322868347
[20/24] Train loss=0.26150012016296387
Test set avg_accuracy=66.89% avg_sensitivity=71.81%, avg_specificity=65.15% avg_auc=74.55%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.270446 Test loss=0.611801 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2716825604438782
[5/24] Train loss=0.2714390754699707
[10/24] Train loss=0.31224873661994934
[15/24] Train loss=0.32434114813804626
[20/24] Train loss=0.270500510931015
Test set avg_accuracy=65.43% avg_sensitivity=68.17%, avg_specificity=64.47% avg_auc=71.46%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.274333 Test loss=0.617062 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2483479380607605
[5/24] Train loss=0.25725311040878296
[10/24] Train loss=0.28644996881484985
[15/24] Train loss=0.3066779673099518
[20/24] Train loss=0.25474512577056885
Test set avg_accuracy=65.52% avg_sensitivity=72.31%, avg_specificity=63.13% avg_auc=73.22%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.267782 Test loss=0.635175 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.24750669300556183
[5/24] Train loss=0.2694145739078522
[10/24] Train loss=0.29225268959999084
[15/24] Train loss=0.3088412880897522
[20/24] Train loss=0.2529062032699585
Test set avg_accuracy=60.98% avg_sensitivity=57.87%, avg_specificity=62.07% avg_auc=65.21%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.265388 Test loss=0.706163 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2304079830646515
[5/24] Train loss=0.25222527980804443
[10/24] Train loss=0.28489920496940613
[15/24] Train loss=0.3039914667606354
[20/24] Train loss=0.24897344410419464
Test set avg_accuracy=62.38% avg_sensitivity=75.96%, avg_specificity=57.60% avg_auc=72.13%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.262136 Test loss=0.681997 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2439420521259308
[5/24] Train loss=0.24775439500808716
[10/24] Train loss=0.28436994552612305
[15/24] Train loss=0.29935774207115173
[20/24] Train loss=0.24890828132629395
Test set avg_accuracy=70.44% avg_sensitivity=55.22%, avg_specificity=75.81% avg_auc=71.97%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.257016 Test loss=0.578651 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.23568952083587646
[5/24] Train loss=0.24814575910568237
[10/24] Train loss=0.2776753306388855
[15/24] Train loss=0.2935487926006317
[20/24] Train loss=0.24417553842067719
Test set avg_accuracy=61.22% avg_sensitivity=67.27%, avg_specificity=59.09% avg_auc=67.66%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.256642 Test loss=0.704905 Current lr=[0.000134135431043539]

[0/24] Train loss=0.23140007257461548
[5/24] Train loss=0.25011569261550903
[10/24] Train loss=0.2752096354961395
[15/24] Train loss=0.31086280941963196
[20/24] Train loss=0.2419034242630005
Test set avg_accuracy=65.43% avg_sensitivity=60.77%, avg_specificity=67.07% avg_auc=69.97%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.256864 Test loss=0.634660 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.23257961869239807
[5/24] Train loss=0.24976521730422974
[10/24] Train loss=0.28064441680908203
[15/24] Train loss=0.2916155755519867
[20/24] Train loss=0.24320447444915771
Test set avg_accuracy=65.31% avg_sensitivity=72.86%, avg_specificity=62.65% avg_auc=73.24%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.255528 Test loss=0.649065 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22862279415130615
[5/24] Train loss=0.2495872676372528
[10/24] Train loss=0.29877299070358276
[15/24] Train loss=0.2897587716579437
[20/24] Train loss=0.24729424715042114
Test set avg_accuracy=66.15% avg_sensitivity=51.87%, avg_specificity=71.17% avg_auc=68.02%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.254476 Test loss=0.637119 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2427869290113449
[5/24] Train loss=0.250224232673645
[10/24] Train loss=0.27531901001930237
[15/24] Train loss=0.2981579005718231
[20/24] Train loss=0.24500520527362823
Test set avg_accuracy=56.88% avg_sensitivity=66.72%, avg_specificity=53.41% avg_auc=64.50%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.254268 Test loss=0.781591 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.23095041513442993
[5/24] Train loss=0.25003543496131897
[10/24] Train loss=0.2766198515892029
[15/24] Train loss=0.28401827812194824
[20/24] Train loss=0.24939650297164917
Test set avg_accuracy=57.90% avg_sensitivity=62.47%, avg_specificity=56.30% avg_auc=63.83%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.250803 Test loss=0.749823 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.24365539848804474
[5/24] Train loss=0.24699603021144867
[10/24] Train loss=0.2765113413333893
[15/24] Train loss=0.3006914258003235
[20/24] Train loss=0.24377793073654175
Test set avg_accuracy=64.79% avg_sensitivity=72.01%, avg_specificity=62.25% avg_auc=73.01%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.253385 Test loss=0.650181 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2190026342868805
[5/24] Train loss=0.2645438015460968
[10/24] Train loss=0.27833521366119385
[15/24] Train loss=0.2972162961959839
[20/24] Train loss=0.24755872786045074
Test set avg_accuracy=53.68% avg_sensitivity=65.12%, avg_specificity=49.66% avg_auc=59.66%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.254962 Test loss=0.779836 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2240147888660431
[5/24] Train loss=0.24279189109802246
[10/24] Train loss=0.26653170585632324
[15/24] Train loss=0.28240251541137695
[20/24] Train loss=0.24928751587867737
Test set avg_accuracy=61.12% avg_sensitivity=66.52%, avg_specificity=59.22% avg_auc=67.40%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.248134 Test loss=0.762086 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.22267591953277588
[5/24] Train loss=0.2418774664402008
[10/24] Train loss=0.25687336921691895
[15/24] Train loss=0.2808409333229065
[20/24] Train loss=0.23121358454227448
Test set avg_accuracy=60.62% avg_sensitivity=66.82%, avg_specificity=58.44% avg_auc=67.93%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.243454 Test loss=0.720044 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.22221718728542328
[5/24] Train loss=0.2304438054561615
[10/24] Train loss=0.26621028780937195
[15/24] Train loss=0.2647365629673004
[20/24] Train loss=0.2335967868566513
Test set avg_accuracy=58.18% avg_sensitivity=70.81%, avg_specificity=53.72% avg_auc=66.06%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.241536 Test loss=0.799480 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.22894832491874695
[5/24] Train loss=0.22597049176692963
[10/24] Train loss=0.2638210654258728
[15/24] Train loss=0.2755919098854065
[20/24] Train loss=0.2290477305650711
Test set avg_accuracy=56.46% avg_sensitivity=71.06%, avg_specificity=51.31% avg_auc=65.28%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.240496 Test loss=0.818035 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.21257281303405762
[5/24] Train loss=0.23917336761951447
[10/24] Train loss=0.25769543647766113
[15/24] Train loss=0.2705332040786743
[20/24] Train loss=0.22638607025146484
Test set avg_accuracy=61.37% avg_sensitivity=68.67%, avg_specificity=58.80% avg_auc=68.49%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.238740 Test loss=0.753226 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.216134175658226
[5/24] Train loss=0.22173936665058136
[10/24] Train loss=0.2585555613040924
[15/24] Train loss=0.2826178967952728
[20/24] Train loss=0.2309214025735855
Test set avg_accuracy=59.87% avg_sensitivity=64.52%, avg_specificity=58.23% avg_auc=66.63%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.238421 Test loss=0.758401 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.21704143285751343
[5/24] Train loss=0.2359226644039154
[10/24] Train loss=0.26074010133743286
[15/24] Train loss=0.2789798974990845
[20/24] Train loss=0.23063193261623383
Test set avg_accuracy=59.60% avg_sensitivity=70.76%, avg_specificity=55.66% avg_auc=67.82%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.239422 Test loss=0.758987 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.21740688383579254
[5/24] Train loss=0.2319050133228302
[10/24] Train loss=0.2607487142086029
[15/24] Train loss=0.27311503887176514
[20/24] Train loss=0.23393835127353668
Test set avg_accuracy=57.08% avg_sensitivity=70.16%, avg_specificity=52.47% avg_auc=66.40%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.240324 Test loss=0.789508 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.23195776343345642
[5/24] Train loss=0.23595842719078064
[10/24] Train loss=0.26391303539276123
[15/24] Train loss=0.2639480233192444
[20/24] Train loss=0.24256537854671478
Test set avg_accuracy=69.02% avg_sensitivity=77.06%, avg_specificity=66.19% avg_auc=79.52%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.241900 Test loss=0.590713 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.23017941415309906
[5/24] Train loss=0.2271634191274643
[10/24] Train loss=0.26858949661254883
[15/24] Train loss=0.2725665867328644
[20/24] Train loss=0.23461107909679413
Test set avg_accuracy=79.44% avg_sensitivity=74.91%, avg_specificity=81.04% avg_auc=84.65%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.241146 Test loss=0.461738 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.231116384267807
[5/24] Train loss=0.2231265753507614
[10/24] Train loss=0.26116886734962463
[15/24] Train loss=0.272298127412796
[20/24] Train loss=0.23276066780090332
Test set avg_accuracy=68.98% avg_sensitivity=78.36%, avg_specificity=65.68% avg_auc=80.97%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.238132 Test loss=0.574495 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.2192566692829132
[5/24] Train loss=0.22379310429096222
[10/24] Train loss=0.2475806623697281
[15/24] Train loss=0.26745906472206116
[20/24] Train loss=0.22982844710350037
Test set avg_accuracy=68.32% avg_sensitivity=69.62%, avg_specificity=67.86% avg_auc=75.73%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.233764 Test loss=0.585195 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.21568886935710907
[5/24] Train loss=0.22057004272937775
[10/24] Train loss=0.25589653849601746
[15/24] Train loss=0.26487740874290466
[20/24] Train loss=0.22070755064487457
Test set avg_accuracy=64.53% avg_sensitivity=74.96%, avg_specificity=60.86% avg_auc=73.79%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.232366 Test loss=0.644986 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.20840509235858917
[5/24] Train loss=0.21863318979740143
[10/24] Train loss=0.23840594291687012
[15/24] Train loss=0.2559790015220642
[20/24] Train loss=0.2246921956539154
Test set avg_accuracy=63.45% avg_sensitivity=74.76%, avg_specificity=59.46% avg_auc=72.45%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.226185 Test loss=0.700841 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2111155241727829
[5/24] Train loss=0.22014866769313812
[10/24] Train loss=0.24131092429161072
[15/24] Train loss=0.2605600357055664
[20/24] Train loss=0.21796593070030212
Test set avg_accuracy=61.18% avg_sensitivity=76.66%, avg_specificity=55.73% avg_auc=71.81%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.223800 Test loss=0.736810 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.204630047082901
[5/24] Train loss=0.2111816555261612
[10/24] Train loss=0.23910142481327057
[15/24] Train loss=0.2541837692260742
[20/24] Train loss=0.21465365588665009
Test set avg_accuracy=62.70% avg_sensitivity=70.86%, avg_specificity=59.82% avg_auc=70.97%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.222507 Test loss=0.713906 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.20995621383190155
[5/24] Train loss=0.2094588279724121
[10/24] Train loss=0.2342338263988495
[15/24] Train loss=0.26091891527175903
[20/24] Train loss=0.21946431696414948
Test set avg_accuracy=61.20% avg_sensitivity=75.21%, avg_specificity=56.26% avg_auc=70.94%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.221845 Test loss=0.740764 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.202600359916687
[5/24] Train loss=0.21082703769207
[10/24] Train loss=0.23739081621170044
[15/24] Train loss=0.2538387179374695
[20/24] Train loss=0.21906718611717224
Test set avg_accuracy=64.90% avg_sensitivity=73.01%, avg_specificity=62.04% avg_auc=73.31%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.220414 Test loss=0.661169 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.20395280420780182
[5/24] Train loss=0.21182185411453247
[10/24] Train loss=0.23310576379299164
[15/24] Train loss=0.25324514508247375
[20/24] Train loss=0.21061848104000092
Test set avg_accuracy=68.80% avg_sensitivity=73.36%, avg_specificity=67.19% avg_auc=76.70%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.218711 Test loss=0.612237 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.20604586601257324
[5/24] Train loss=0.2063015252351761
[10/24] Train loss=0.23484256863594055
[15/24] Train loss=0.25879916548728943
[20/24] Train loss=0.21557869017124176
Test set avg_accuracy=68.24% avg_sensitivity=75.51%, avg_specificity=65.68% avg_auc=77.46%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.218128 Test loss=0.613266 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.20178644359111786
[5/24] Train loss=0.21306923031806946
[10/24] Train loss=0.2360069751739502
[15/24] Train loss=0.24392138421535492
[20/24] Train loss=0.20631900429725647
Test set avg_accuracy=58.16% avg_sensitivity=72.41%, avg_specificity=53.14% avg_auc=67.27%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.217658 Test loss=0.818724 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.19970764219760895
[5/24] Train loss=0.20560309290885925
[10/24] Train loss=0.23323479294776917
[15/24] Train loss=0.2527723014354706
[20/24] Train loss=0.21232615411281586
Test set avg_accuracy=63.72% avg_sensitivity=75.41%, avg_specificity=59.61% avg_auc=72.97%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.216934 Test loss=0.712123 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.19602859020233154
[5/24] Train loss=0.19902020692825317
[10/24] Train loss=0.22823309898376465
[15/24] Train loss=0.2558259069919586
[20/24] Train loss=0.21677835285663605
Test set avg_accuracy=62.60% avg_sensitivity=74.31%, avg_specificity=58.48% avg_auc=72.01%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.214356 Test loss=0.724235 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.19641704857349396
[5/24] Train loss=0.2015226036310196
[10/24] Train loss=0.22299765050411224
[15/24] Train loss=0.245062455534935
[20/24] Train loss=0.2068120539188385
Test set avg_accuracy=62.42% avg_sensitivity=73.66%, avg_specificity=58.46% avg_auc=71.02%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.212372 Test loss=0.739972 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.19549909234046936
[5/24] Train loss=0.20214113593101501
[10/24] Train loss=0.22584854066371918
[15/24] Train loss=0.24812106788158417
[20/24] Train loss=0.20603887736797333
Test set avg_accuracy=62.33% avg_sensitivity=75.16%, avg_specificity=57.81% avg_auc=71.68%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.211829 Test loss=0.743177 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.19881077110767365
[5/24] Train loss=0.20115453004837036
[10/24] Train loss=0.22961445152759552
[15/24] Train loss=0.24831490218639374
[20/24] Train loss=0.20851707458496094
Test set avg_accuracy=61.80% avg_sensitivity=74.61%, avg_specificity=57.28% avg_auc=71.19%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.212070 Test loss=0.754501 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1936323195695877
[5/24] Train loss=0.1966642439365387
[10/24] Train loss=0.2273026406764984
[15/24] Train loss=0.2494746595621109
[20/24] Train loss=0.21146640181541443
Test set avg_accuracy=62.77% avg_sensitivity=75.81%, avg_specificity=58.18% avg_auc=72.63%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.210618 Test loss=0.731138 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1943887174129486
[5/24] Train loss=0.20093807578086853
[10/24] Train loss=0.22307975590229034
[15/24] Train loss=0.24300722777843475
[20/24] Train loss=0.20308257639408112
Test set avg_accuracy=62.53% avg_sensitivity=75.61%, avg_specificity=57.92% avg_auc=72.06%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.209696 Test loss=0.741874 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.19412857294082642
[5/24] Train loss=0.19605688750743866
[10/24] Train loss=0.23113898932933807
[15/24] Train loss=0.24528846144676208
[20/24] Train loss=0.2058573067188263
Test set avg_accuracy=63.09% avg_sensitivity=74.76%, avg_specificity=58.97% avg_auc=71.93%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.209591 Test loss=0.736648 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1924704909324646
[5/24] Train loss=0.1936950534582138
[10/24] Train loss=0.2348518967628479
[15/24] Train loss=0.24841463565826416
[20/24] Train loss=0.20944736897945404
Test set avg_accuracy=63.36% avg_sensitivity=75.31%, avg_specificity=59.15% avg_auc=72.55%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.209551 Test loss=0.732418 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1905282586812973
[5/24] Train loss=0.1994027942419052
[10/24] Train loss=0.22112303972244263
[15/24] Train loss=0.2443714439868927
[20/24] Train loss=0.20364132523536682
Test set avg_accuracy=64.30% avg_sensitivity=74.76%, avg_specificity=60.61% avg_auc=73.30%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.208538 Test loss=0.711800 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.18760913610458374
[5/24] Train loss=0.1984654814004898
[10/24] Train loss=0.23114067316055298
[15/24] Train loss=0.24271641671657562
[20/24] Train loss=0.20571497082710266
Test set avg_accuracy=64.43% avg_sensitivity=74.61%, avg_specificity=60.84% avg_auc=73.19%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.209025 Test loss=0.712333 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1914149522781372
[5/24] Train loss=0.19761553406715393
[10/24] Train loss=0.22590278089046478
[15/24] Train loss=0.23236951231956482
[20/24] Train loss=0.20013782382011414
Test set avg_accuracy=63.29% avg_sensitivity=75.16%, avg_specificity=59.11% avg_auc=72.26%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.207617 Test loss=0.734909 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.19223548471927643
[5/24] Train loss=0.19750767946243286
[10/24] Train loss=0.22626879811286926
[15/24] Train loss=0.26234036684036255
[20/24] Train loss=0.20243990421295166
Test set avg_accuracy=62.59% avg_sensitivity=75.11%, avg_specificity=58.18% avg_auc=71.83%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.209098 Test loss=0.743923 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.19041384756565094
[5/24] Train loss=0.19883497059345245
[10/24] Train loss=0.22393304109573364
[15/24] Train loss=0.24707193672657013
[20/24] Train loss=0.2010176032781601
Test set avg_accuracy=64.18% avg_sensitivity=75.11%, avg_specificity=60.33% avg_auc=73.33%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.207376 Test loss=0.708901 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.19655349850654602
[5/24] Train loss=0.19347435235977173
[10/24] Train loss=0.22573290765285492
[15/24] Train loss=0.23410363495349884
[20/24] Train loss=0.20656386017799377
Test set avg_accuracy=63.72% avg_sensitivity=74.86%, avg_specificity=59.80% avg_auc=72.74%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.207883 Test loss=0.723194 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.193608358502388
[5/24] Train loss=0.198246031999588
[10/24] Train loss=0.22196516394615173
[15/24] Train loss=0.24367864429950714
[20/24] Train loss=0.20257888734340668
Test set avg_accuracy=62.57% avg_sensitivity=74.81%, avg_specificity=58.25% avg_auc=71.86%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.207666 Test loss=0.743038 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.19348905980587006
[5/24] Train loss=0.19421975314617157
[10/24] Train loss=0.22284479439258575
[15/24] Train loss=0.2398773580789566
[20/24] Train loss=0.20506155490875244
Test set avg_accuracy=63.85% avg_sensitivity=74.86%, avg_specificity=59.98% avg_auc=72.87%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.206313 Test loss=0.717403 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.19169560074806213
[5/24] Train loss=0.1957259476184845
[10/24] Train loss=0.22097164392471313
[15/24] Train loss=0.23833107948303223
[20/24] Train loss=0.20319756865501404
Test set avg_accuracy=62.43% avg_sensitivity=74.56%, avg_specificity=58.16% avg_auc=71.70%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.206013 Test loss=0.743611 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1902211606502533
[5/24] Train loss=0.19645927846431732
[10/24] Train loss=0.21965256333351135
[15/24] Train loss=0.2433561086654663
[20/24] Train loss=0.19789524376392365
Test set avg_accuracy=63.09% avg_sensitivity=75.16%, avg_specificity=58.83% avg_auc=72.18%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.206403 Test loss=0.736134 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.19143667817115784
[5/24] Train loss=0.195067897439003
[10/24] Train loss=0.22845777869224548
[15/24] Train loss=0.24059651792049408
[20/24] Train loss=0.2030385583639145
Test set avg_accuracy=62.08% avg_sensitivity=74.66%, avg_specificity=57.65% avg_auc=71.34%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.206325 Test loss=0.752317 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1924077868461609
[5/24] Train loss=0.19505803287029266
[10/24] Train loss=0.2221681773662567
[15/24] Train loss=0.23979957401752472
[20/24] Train loss=0.20207668840885162
Test set avg_accuracy=62.73% avg_sensitivity=74.96%, avg_specificity=58.43% avg_auc=71.87%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.206564 Test loss=0.743240 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=84.11% sen=64.42%, spe=91.05%, auc=87.91%!
Fold[4] Avg_overlap=0.65%(±0.282672044062923)
[0/24] Train loss=0.7376671433448792
[5/24] Train loss=0.7344260811805725
[10/24] Train loss=0.741218626499176
[15/24] Train loss=0.7357385158538818
[20/24] Train loss=0.7283450961112976
Test set avg_accuracy=64.70% avg_sensitivity=21.66%, avg_specificity=79.38% avg_auc=50.13%
Best model saved!! Metric=-110.13434757013205!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=0.731577 Test loss=0.666663 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7237604260444641
[5/24] Train loss=0.7216029167175293
[10/24] Train loss=0.7331660985946655
[15/24] Train loss=0.7221218347549438
[20/24] Train loss=0.723241925239563
Test set avg_accuracy=61.21% avg_sensitivity=27.91%, avg_specificity=72.57% avg_auc=50.45%
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.723296 Test loss=0.667144 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7240526080131531
[5/24] Train loss=0.7149134278297424
[10/24] Train loss=0.7228836417198181
[15/24] Train loss=0.7051178216934204
[20/24] Train loss=0.7137369513511658
Test set avg_accuracy=57.90% avg_sensitivity=34.87%, avg_specificity=65.76% avg_auc=51.01%
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.714939 Test loss=0.679824 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7163775563240051
[5/24] Train loss=0.7077780961990356
[10/24] Train loss=0.7127412557601929
[15/24] Train loss=0.6999372839927673
[20/24] Train loss=0.6988111138343811
Test set avg_accuracy=58.09% avg_sensitivity=35.69%, avg_specificity=65.72% avg_auc=50.90%
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.704513 Test loss=0.683544 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.699262261390686
[5/24] Train loss=0.6993026733398438
[10/24] Train loss=0.6928598284721375
[15/24] Train loss=0.689102828502655
[20/24] Train loss=0.6957240104675293
Test set avg_accuracy=57.99% avg_sensitivity=34.46%, avg_specificity=66.02% avg_auc=51.26%
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.695176 Test loss=0.673606 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6907608509063721
[5/24] Train loss=0.6836979389190674
[10/24] Train loss=0.6898177266120911
[15/24] Train loss=0.6815824508666992
[20/24] Train loss=0.6817865371704102
Test set avg_accuracy=58.45% avg_sensitivity=36.30%, avg_specificity=66.00% avg_auc=52.10%
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.685266 Test loss=0.668031 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6804129481315613
[5/24] Train loss=0.6819645166397095
[10/24] Train loss=0.6730571985244751
[15/24] Train loss=0.6669359803199768
[20/24] Train loss=0.6696982383728027
Test set avg_accuracy=58.35% avg_sensitivity=35.28%, avg_specificity=66.21% avg_auc=52.52%
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.672635 Test loss=0.658192 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6788129806518555
[5/24] Train loss=0.6605391502380371
[10/24] Train loss=0.666458010673523
[15/24] Train loss=0.6541733145713806
[20/24] Train loss=0.6547600030899048
Test set avg_accuracy=61.50% avg_sensitivity=30.26%, avg_specificity=72.15% avg_auc=53.67%
Best model saved!! Metric=-108.42110414221392!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.661923 Test loss=0.645181 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6594192981719971
[5/24] Train loss=0.6549221277236938
[10/24] Train loss=0.6505168080329895
[15/24] Train loss=0.6437909603118896
[20/24] Train loss=0.6414569020271301
Test set avg_accuracy=70.81% avg_sensitivity=16.69%, avg_specificity=89.26% avg_auc=54.17%
Best model saved!! Metric=-95.07086116371583!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.648989 Test loss=0.635585 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6487776041030884
[5/24] Train loss=0.6432561278343201
[10/24] Train loss=0.6423212289810181
[15/24] Train loss=0.6309634447097778
[20/24] Train loss=0.6198054552078247
Test set avg_accuracy=70.96% avg_sensitivity=14.95%, avg_specificity=90.06% avg_auc=56.42%
Best model saved!! Metric=-93.60325920855443!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.634771 Test loss=0.610561 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6323434710502625
[5/24] Train loss=0.6292635202407837
[10/24] Train loss=0.6297233700752258
[15/24] Train loss=0.6106458306312561
[20/24] Train loss=0.6136983036994934
Test set avg_accuracy=74.45% avg_sensitivity=13.57%, avg_specificity=95.22% avg_auc=56.84%
Best model saved!! Metric=-85.92430993844475!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.620340 Test loss=0.598994 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6218035817146301
[5/24] Train loss=0.6072667837142944
[10/24] Train loss=0.6181550621986389
[15/24] Train loss=0.5949057340621948
[20/24] Train loss=0.5934293270111084
Test set avg_accuracy=74.41% avg_sensitivity=14.13%, avg_specificity=94.97% avg_auc=62.43%
Best model saved!! Metric=-80.05438731385951!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.604439 Test loss=0.561763 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.6041836142539978
[5/24] Train loss=0.5932508111000061
[10/24] Train loss=0.5957387089729309
[15/24] Train loss=0.5760654807090759
[20/24] Train loss=0.5730159878730774
Test set avg_accuracy=74.61% avg_sensitivity=14.18%, avg_specificity=95.22% avg_auc=64.43%
Best model saved!! Metric=-77.56044374826719!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.585250 Test loss=0.559869 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.581976592540741
[5/24] Train loss=0.56483393907547
[10/24] Train loss=0.5613036155700684
[15/24] Train loss=0.5576643943786621
[20/24] Train loss=0.5464121699333191
Test set avg_accuracy=74.99% avg_sensitivity=12.60%, avg_specificity=96.26% avg_auc=64.61%
Best model saved!! Metric=-77.54821837006857!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.562648 Test loss=0.582835 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5455575585365295
[5/24] Train loss=0.5419825911521912
[10/24] Train loss=0.5382910966873169
[15/24] Train loss=0.516038715839386
[20/24] Train loss=0.5115417838096619
Test set avg_accuracy=75.69% avg_sensitivity=24.07%, avg_specificity=93.29% avg_auc=71.35%
Best model saved!! Metric=-61.59855097707219!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.532058 Test loss=0.557300 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.511493444442749
[5/24] Train loss=0.5106721520423889
[10/24] Train loss=0.5024084448814392
[15/24] Train loss=0.4754166007041931
[20/24] Train loss=0.48569783568382263
Test set avg_accuracy=77.83% avg_sensitivity=37.84%, avg_specificity=91.46% avg_auc=78.40%
Best model saved!! Metric=-40.47644152979939!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.499099 Test loss=0.482000 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.470665842294693
[5/24] Train loss=0.49257344007492065
[10/24] Train loss=0.477144330739975
[15/24] Train loss=0.44940441846847534
[20/24] Train loss=0.45891913771629333
Test set avg_accuracy=78.97% avg_sensitivity=66.10%, avg_specificity=83.36% avg_auc=81.73%
Best model saved!! Metric=-15.83255087222038!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.473460 Test loss=0.515031 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4532568156719208
[5/24] Train loss=0.47169265151023865
[10/24] Train loss=0.45787590742111206
[15/24] Train loss=0.4321056008338928
[20/24] Train loss=0.43788987398147583
Test set avg_accuracy=64.09% avg_sensitivity=71.58%, avg_specificity=61.53% avg_auc=72.91%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.455050 Test loss=0.632099 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.44175270199775696
[5/24] Train loss=0.45481282472610474
[10/24] Train loss=0.44605177640914917
[15/24] Train loss=0.425907164812088
[20/24] Train loss=0.4165017008781433
Test set avg_accuracy=55.21% avg_sensitivity=70.25%, avg_specificity=50.08% avg_auc=63.66%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.441448 Test loss=0.709107 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4297683835029602
[5/24] Train loss=0.4521848261356354
[10/24] Train loss=0.43873143196105957
[15/24] Train loss=0.41561776399612427
[20/24] Train loss=0.4105164110660553
Test set avg_accuracy=59.54% avg_sensitivity=74.40%, avg_specificity=54.48% avg_auc=72.59%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.432334 Test loss=0.643780 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4243625998497009
[5/24] Train loss=0.4431658387184143
[10/24] Train loss=0.42977312207221985
[15/24] Train loss=0.4078933298587799
[20/24] Train loss=0.40447697043418884
Test set avg_accuracy=64.00% avg_sensitivity=64.46%, avg_specificity=63.84% avg_auc=68.67%
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.425272 Test loss=0.636648 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.41236037015914917
[5/24] Train loss=0.43159639835357666
[10/24] Train loss=0.433719277381897
[15/24] Train loss=0.4005899727344513
[20/24] Train loss=0.3962993323802948
Test set avg_accuracy=67.01% avg_sensitivity=71.07%, avg_specificity=65.62% avg_auc=74.79%
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.417853 Test loss=0.603356 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.41472873091697693
[5/24] Train loss=0.4221721291542053
[10/24] Train loss=0.4217122495174408
[15/24] Train loss=0.4014887809753418
[20/24] Train loss=0.38802650570869446
Test set avg_accuracy=58.80% avg_sensitivity=68.10%, avg_specificity=55.63% avg_auc=67.48%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.413000 Test loss=0.654906 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.399405837059021
[5/24] Train loss=0.4212080240249634
[10/24] Train loss=0.42036694288253784
[15/24] Train loss=0.39721477031707764
[20/24] Train loss=0.37829211354255676
Test set avg_accuracy=55.27% avg_sensitivity=67.13%, avg_specificity=51.23% avg_auc=63.54%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.407383 Test loss=0.676950 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3928316831588745
[5/24] Train loss=0.42084023356437683
[10/24] Train loss=0.4196748435497284
[15/24] Train loss=0.39468684792518616
[20/24] Train loss=0.39064064621925354
Test set avg_accuracy=81.32% avg_sensitivity=55.09%, avg_specificity=90.26% avg_auc=84.38%
Best model saved!! Metric=-14.95261825131174!!
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.407730 Test loss=0.422797 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3983285427093506
[5/24] Train loss=0.4189411699771881
[10/24] Train loss=0.42047813534736633
[15/24] Train loss=0.39160898327827454
[20/24] Train loss=0.3788391351699829
Test set avg_accuracy=55.64% avg_sensitivity=65.08%, avg_specificity=52.42% avg_auc=63.41%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.404578 Test loss=0.664685 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.38549238443374634
[5/24] Train loss=0.411150187253952
[10/24] Train loss=0.4130289554595947
[15/24] Train loss=0.39400169253349304
[20/24] Train loss=0.37464454770088196
Test set avg_accuracy=79.44% avg_sensitivity=60.32%, avg_specificity=85.96% avg_auc=82.30%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.401281 Test loss=0.500204 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.4149858355522156
[5/24] Train loss=0.4141690731048584
[10/24] Train loss=0.4185895621776581
[15/24] Train loss=0.37957456707954407
[20/24] Train loss=0.36544114351272583
Test set avg_accuracy=56.94% avg_sensitivity=54.94%, avg_specificity=57.62% avg_auc=59.51%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.397169 Test loss=0.661998 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3884868919849396
[5/24] Train loss=0.4090994596481323
[10/24] Train loss=0.4153236746788025
[15/24] Train loss=0.3766908347606659
[20/24] Train loss=0.3601573705673218
Test set avg_accuracy=59.35% avg_sensitivity=51.77%, avg_specificity=61.93% avg_auc=59.66%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.393558 Test loss=0.656184 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.372543066740036
[5/24] Train loss=0.4014340043067932
[10/24] Train loss=0.4086446464061737
[15/24] Train loss=0.37031906843185425
[20/24] Train loss=0.3621161878108978
Test set avg_accuracy=52.58% avg_sensitivity=57.30%, avg_specificity=50.97% avg_auc=56.20%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.386274 Test loss=0.684209 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3818318843841553
[5/24] Train loss=0.40148046612739563
[10/24] Train loss=0.4047887325286865
[15/24] Train loss=0.37588679790496826
[20/24] Train loss=0.36216673254966736
Test set avg_accuracy=57.25% avg_sensitivity=72.50%, avg_specificity=52.05% avg_auc=69.13%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.392588 Test loss=0.658381 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3762032091617584
[5/24] Train loss=0.399178147315979
[10/24] Train loss=0.3977276682853699
[15/24] Train loss=0.3688403367996216
[20/24] Train loss=0.356658011674881
Test set avg_accuracy=66.80% avg_sensitivity=54.28%, avg_specificity=71.07% avg_auc=69.22%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.387490 Test loss=0.612194 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.37571293115615845
[5/24] Train loss=0.4147767424583435
[10/24] Train loss=0.40336501598358154
[15/24] Train loss=0.3734571933746338
[20/24] Train loss=0.3521876931190491
Test set avg_accuracy=53.50% avg_sensitivity=74.04%, avg_specificity=46.50% avg_auc=66.03%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.386997 Test loss=0.687236 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3641790449619293
[5/24] Train loss=0.40019848942756653
[10/24] Train loss=0.41466614603996277
[15/24] Train loss=0.37211528420448303
[20/24] Train loss=0.3555259108543396
Test set avg_accuracy=52.89% avg_sensitivity=65.59%, avg_specificity=48.56% avg_auc=60.51%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.380496 Test loss=0.695970 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.36869028210639954
[5/24] Train loss=0.3978936970233917
[10/24] Train loss=0.39159709215164185
[15/24] Train loss=0.37410739064216614
[20/24] Train loss=0.3589075803756714
Test set avg_accuracy=47.19% avg_sensitivity=71.58%, avg_specificity=38.87% avg_auc=59.21%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.377811 Test loss=0.752346 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.36465564370155334
[5/24] Train loss=0.38247227668762207
[10/24] Train loss=0.3878588378429413
[15/24] Train loss=0.3708731532096863
[20/24] Train loss=0.36863982677459717
Test set avg_accuracy=70.62% avg_sensitivity=58.42%, avg_specificity=74.79% avg_auc=74.37%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.379817 Test loss=0.567791 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.37891581654548645
[5/24] Train loss=0.38527968525886536
[10/24] Train loss=0.40412449836730957
[15/24] Train loss=0.36680084466934204
[20/24] Train loss=0.35334718227386475
Test set avg_accuracy=49.99% avg_sensitivity=71.43%, avg_specificity=42.68% avg_auc=61.01%
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.372798 Test loss=0.707566 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.370148628950119
[5/24] Train loss=0.38357892632484436
[10/24] Train loss=0.38534846901893616
[15/24] Train loss=0.3610890507698059
[20/24] Train loss=0.33981388807296753
Test set avg_accuracy=57.08% avg_sensitivity=68.46%, avg_specificity=53.20% avg_auc=65.66%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.365668 Test loss=0.655683 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3576584458351135
[5/24] Train loss=0.382284551858902
[10/24] Train loss=0.39141249656677246
[15/24] Train loss=0.37021568417549133
[20/24] Train loss=0.35301145911216736
Test set avg_accuracy=80.27% avg_sensitivity=37.07%, avg_specificity=95.01% avg_auc=84.25%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.370460 Test loss=0.424998 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.37269577383995056
[5/24] Train loss=0.3778272569179535
[10/24] Train loss=0.38320624828338623
[15/24] Train loss=0.34518498182296753
[20/24] Train loss=0.3332822024822235
Test set avg_accuracy=61.56% avg_sensitivity=47.16%, avg_specificity=66.47% avg_auc=62.07%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.364693 Test loss=0.639382 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3588455319404602
[5/24] Train loss=0.3722226619720459
[10/24] Train loss=0.384922057390213
[15/24] Train loss=0.34971392154693604
[20/24] Train loss=0.3337869942188263
Test set avg_accuracy=58.80% avg_sensitivity=68.82%, avg_specificity=55.39% avg_auc=67.36%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.360309 Test loss=0.647734 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.36501842737197876
[5/24] Train loss=0.3771432936191559
[10/24] Train loss=0.39839816093444824
[15/24] Train loss=0.3533248007297516
[20/24] Train loss=0.33223235607147217
Test set avg_accuracy=77.12% avg_sensitivity=32.72%, avg_specificity=92.26% avg_auc=73.74%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.358180 Test loss=0.535008 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.34147167205810547
[5/24] Train loss=0.36675164103507996
[10/24] Train loss=0.37792378664016724
[15/24] Train loss=0.3468029797077179
[20/24] Train loss=0.3207653760910034
Test set avg_accuracy=68.96% avg_sensitivity=52.38%, avg_specificity=74.61% avg_auc=69.95%
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.353624 Test loss=0.574499 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3645111322402954
[5/24] Train loss=0.37522032856941223
[10/24] Train loss=0.3796443045139313
[15/24] Train loss=0.33690956234931946
[20/24] Train loss=0.3566819727420807
Test set avg_accuracy=66.65% avg_sensitivity=43.57%, avg_specificity=74.52% avg_auc=66.72%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.358154 Test loss=0.595898 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3654121160507202
[5/24] Train loss=0.3803379535675049
[10/24] Train loss=0.3793514370918274
[15/24] Train loss=0.34321093559265137
[20/24] Train loss=0.3279269337654114
Test set avg_accuracy=82.60% avg_sensitivity=51.51%, avg_specificity=93.21% avg_auc=87.56%
Best model saved!! Metric=-11.115649573739631!!
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.357721 Test loss=0.378383 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.35182294249534607
[5/24] Train loss=0.370050311088562
[10/24] Train loss=0.37267717719078064
[15/24] Train loss=0.3703414499759674
[20/24] Train loss=0.31987127661705017
Test set avg_accuracy=80.92% avg_sensitivity=50.90%, avg_specificity=91.16% avg_auc=80.07%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.354326 Test loss=0.507269 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3323403298854828
[5/24] Train loss=0.369617223739624
[10/24] Train loss=0.36074167490005493
[15/24] Train loss=0.3406476378440857
[20/24] Train loss=0.31963101029396057
Test set avg_accuracy=62.16% avg_sensitivity=64.93%, avg_specificity=61.22% avg_auc=69.93%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.345273 Test loss=0.614150 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3469460904598236
[5/24] Train loss=0.3572297692298889
[10/24] Train loss=0.3637339770793915
[15/24] Train loss=0.36637017130851746
[20/24] Train loss=0.338360995054245
Test set avg_accuracy=61.08% avg_sensitivity=60.37%, avg_specificity=61.32% avg_auc=66.40%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.348828 Test loss=0.631547 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3508049547672272
[5/24] Train loss=0.36529168486595154
[10/24] Train loss=0.3732135593891144
[15/24] Train loss=0.33600735664367676
[20/24] Train loss=0.3135146200656891
Test set avg_accuracy=78.95% avg_sensitivity=32.21%, avg_specificity=94.88% avg_auc=81.38%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.354370 Test loss=0.445113 Current lr=[0.000298904600941902]

[0/24] Train loss=0.36927035450935364
[5/24] Train loss=0.38291603326797485
[10/24] Train loss=0.3796210289001465
[15/24] Train loss=0.3457065224647522
[20/24] Train loss=0.3259859085083008
Test set avg_accuracy=73.02% avg_sensitivity=17.31%, avg_specificity=92.02% avg_auc=62.78%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.360388 Test loss=0.589136 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3445785343647003
[5/24] Train loss=0.3469833731651306
[10/24] Train loss=0.3624872863292694
[15/24] Train loss=0.33179792761802673
[20/24] Train loss=0.3164197504520416
Test set avg_accuracy=62.93% avg_sensitivity=51.61%, avg_specificity=66.79% avg_auc=64.99%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.342489 Test loss=0.608458 Current lr=[0.000297555943323901]

[0/24] Train loss=0.335054486989975
[5/24] Train loss=0.3540613651275635
[10/24] Train loss=0.3628641664981842
[15/24] Train loss=0.3192560374736786
[20/24] Train loss=0.3349999189376831
Test set avg_accuracy=66.59% avg_sensitivity=40.19%, avg_specificity=75.59% avg_auc=67.49%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.336523 Test loss=0.588752 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3257378935813904
[5/24] Train loss=0.3498989939689636
[10/24] Train loss=0.3517722189426422
[15/24] Train loss=0.3243415057659149
[20/24] Train loss=0.3049423396587372
Test set avg_accuracy=71.30% avg_sensitivity=43.88%, avg_specificity=80.65% avg_auc=68.54%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.339782 Test loss=0.594921 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.33023741841316223
[5/24] Train loss=0.35288628935813904
[10/24] Train loss=0.35420921444892883
[15/24] Train loss=0.31756800413131714
[20/24] Train loss=0.30290675163269043
Test set avg_accuracy=59.69% avg_sensitivity=64.87%, avg_specificity=57.92% avg_auc=67.58%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.338145 Test loss=0.632037 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3400110602378845
[5/24] Train loss=0.3480724096298218
[10/24] Train loss=0.3618184030056
[15/24] Train loss=0.32947206497192383
[20/24] Train loss=0.31023460626602173
Test set avg_accuracy=67.88% avg_sensitivity=65.28%, avg_specificity=68.76% avg_auc=74.24%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.330907 Test loss=0.566006 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.32156887650489807
[5/24] Train loss=0.33610799908638
[10/24] Train loss=0.36093848943710327
[15/24] Train loss=0.3126572370529175
[20/24] Train loss=0.3140093684196472
Test set avg_accuracy=63.15% avg_sensitivity=65.54%, avg_specificity=62.34% avg_auc=69.91%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.327129 Test loss=0.620259 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3208836019039154
[5/24] Train loss=0.3312338590621948
[10/24] Train loss=0.35686856508255005
[15/24] Train loss=0.31001874804496765
[20/24] Train loss=0.3024548590183258
Test set avg_accuracy=57.34% avg_sensitivity=66.82%, avg_specificity=54.11% avg_auc=65.73%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.327003 Test loss=0.659355 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3287208378314972
[5/24] Train loss=0.34521371126174927
[10/24] Train loss=0.37605538964271545
[15/24] Train loss=0.3075542747974396
[20/24] Train loss=0.3000747561454773
Test set avg_accuracy=60.59% avg_sensitivity=58.58%, avg_specificity=61.27% avg_auc=65.43%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.327168 Test loss=0.630805 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3175981342792511
[5/24] Train loss=0.34533900022506714
[10/24] Train loss=0.35042551159858704
[15/24] Train loss=0.3203796446323395
[20/24] Train loss=0.3098348379135132
Test set avg_accuracy=75.31% avg_sensitivity=61.60%, avg_specificity=79.99% avg_auc=78.55%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.334732 Test loss=0.491089 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.33300328254699707
[5/24] Train loss=0.3472645580768585
[10/24] Train loss=0.3508218824863434
[15/24] Train loss=0.3161362409591675
[20/24] Train loss=0.3107650876045227
Test set avg_accuracy=83.15% avg_sensitivity=56.32%, avg_specificity=92.30% avg_auc=87.78%
Best model saved!! Metric=-6.44303498947594!!
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.328860 Test loss=0.376092 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.327469140291214
[5/24] Train loss=0.34220758080482483
[10/24] Train loss=0.34713682532310486
[15/24] Train loss=0.319082647562027
[20/24] Train loss=0.3151959180831909
Test set avg_accuracy=77.46% avg_sensitivity=52.38%, avg_specificity=86.01% avg_auc=79.81%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.331955 Test loss=0.475234 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3265793025493622
[5/24] Train loss=0.3409668803215027
[10/24] Train loss=0.3484518229961395
[15/24] Train loss=0.3101087510585785
[20/24] Train loss=0.29238253831863403
Test set avg_accuracy=65.01% avg_sensitivity=44.55%, avg_specificity=71.99% avg_auc=64.76%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.327995 Test loss=0.606832 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.31268635392189026
[5/24] Train loss=0.32575851678848267
[10/24] Train loss=0.3448450267314911
[15/24] Train loss=0.30330798029899597
[20/24] Train loss=0.29890984296798706
Test set avg_accuracy=67.47% avg_sensitivity=40.91%, avg_specificity=76.53% avg_auc=66.90%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.317097 Test loss=0.572078 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.30959829688072205
[5/24] Train loss=0.31691277027130127
[10/24] Train loss=0.35177525877952576
[15/24] Train loss=0.28904709219932556
[20/24] Train loss=0.2961753308773041
Test set avg_accuracy=64.49% avg_sensitivity=52.69%, avg_specificity=68.52% avg_auc=67.82%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.315321 Test loss=0.593964 Current lr=[0.000276307469034998]

[0/24] Train loss=0.30361321568489075
[5/24] Train loss=0.3196190595626831
[10/24] Train loss=0.33689969778060913
[15/24] Train loss=0.3249485194683075
[20/24] Train loss=0.3026987314224243
Test set avg_accuracy=53.36% avg_sensitivity=68.97%, avg_specificity=48.04% avg_auc=62.98%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.318309 Test loss=0.660180 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.30787208676338196
[5/24] Train loss=0.3426111936569214
[10/24] Train loss=0.3373183608055115
[15/24] Train loss=0.3407134413719177
[20/24] Train loss=0.29949671030044556
Test set avg_accuracy=74.27% avg_sensitivity=0.67%, avg_specificity=99.37% avg_auc=58.29%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.325202 Test loss=0.560899 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32394060492515564
[5/24] Train loss=0.3285643756389618
[10/24] Train loss=0.3448928892612457
[15/24] Train loss=0.2974972426891327
[20/24] Train loss=0.29485514760017395
Test set avg_accuracy=58.72% avg_sensitivity=71.43%, avg_specificity=54.39% avg_auc=67.25%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.321853 Test loss=0.749118 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3270993232727051
[5/24] Train loss=0.33453962206840515
[10/24] Train loss=0.3316906690597534
[15/24] Train loss=0.3027104139328003
[20/24] Train loss=0.2934294641017914
Test set avg_accuracy=65.17% avg_sensitivity=66.51%, avg_specificity=64.71% avg_auc=71.37%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.320341 Test loss=0.639036 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3212757706642151
[5/24] Train loss=0.3252125680446625
[10/24] Train loss=0.33012568950653076
[15/24] Train loss=0.294818252325058
[20/24] Train loss=0.2984311878681183
Test set avg_accuracy=68.24% avg_sensitivity=71.94%, avg_specificity=66.98% avg_auc=77.84%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.317029 Test loss=0.556095 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32343676686286926
[5/24] Train loss=0.3404868543148041
[10/24] Train loss=0.335109144449234
[15/24] Train loss=0.30339354276657104
[20/24] Train loss=0.3000708818435669
Test set avg_accuracy=61.86% avg_sensitivity=66.41%, avg_specificity=60.31% avg_auc=69.10%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.317967 Test loss=0.602939 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.30466049909591675
[5/24] Train loss=0.320988267660141
[10/24] Train loss=0.33815157413482666
[15/24] Train loss=0.28844153881073
[20/24] Train loss=0.2838361859321594
Test set avg_accuracy=61.29% avg_sensitivity=64.57%, avg_specificity=60.17% avg_auc=68.78%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.306419 Test loss=0.629431 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3025828003883362
[5/24] Train loss=0.3113149404525757
[10/24] Train loss=0.32193511724472046
[15/24] Train loss=0.2875302731990814
[20/24] Train loss=0.28995880484580994
Test set avg_accuracy=59.47% avg_sensitivity=71.94%, avg_specificity=55.21% avg_auc=69.22%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.304017 Test loss=0.723975 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.29607683420181274
[5/24] Train loss=0.3007351756095886
[10/24] Train loss=0.33400872349739075
[15/24] Train loss=0.30194342136383057
[20/24] Train loss=0.288257360458374
Test set avg_accuracy=58.35% avg_sensitivity=78.14%, avg_specificity=51.60% avg_auc=71.45%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.303519 Test loss=0.641036 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30666518211364746
[5/24] Train loss=0.3099272549152374
[10/24] Train loss=0.3358179032802582
[15/24] Train loss=0.3033781349658966
[20/24] Train loss=0.2787802517414093
Test set avg_accuracy=57.96% avg_sensitivity=70.56%, avg_specificity=53.66% avg_auc=68.31%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.305719 Test loss=0.645846 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3074955642223358
[5/24] Train loss=0.3081153929233551
[10/24] Train loss=0.3413997292518616
[15/24] Train loss=0.28762707114219666
[20/24] Train loss=0.2864782512187958
Test set avg_accuracy=81.03% avg_sensitivity=49.72%, avg_specificity=91.71% avg_auc=81.89%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.307275 Test loss=0.457483 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.316569060087204
[5/24] Train loss=0.3288157284259796
[10/24] Train loss=0.343450665473938
[15/24] Train loss=0.30450743436813354
[20/24] Train loss=0.29570016264915466
Test set avg_accuracy=56.02% avg_sensitivity=68.10%, avg_specificity=51.89% avg_auc=64.22%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.313598 Test loss=0.725906 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.292468786239624
[5/24] Train loss=0.33182594180107117
[10/24] Train loss=0.3327130675315857
[15/24] Train loss=0.29752546548843384
[20/24] Train loss=0.2814389765262604
Test set avg_accuracy=67.96% avg_sensitivity=65.64%, avg_specificity=68.74% avg_auc=75.43%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.306285 Test loss=0.556026 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2933928966522217
[5/24] Train loss=0.31396758556365967
[10/24] Train loss=0.3264029026031494
[15/24] Train loss=0.3037194013595581
[20/24] Train loss=0.28369924426078796
Test set avg_accuracy=71.15% avg_sensitivity=27.70%, avg_specificity=85.96% avg_auc=62.97%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.303640 Test loss=0.609268 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2936994135379791
[5/24] Train loss=0.31103837490081787
[10/24] Train loss=0.3217018246650696
[15/24] Train loss=0.29925546050071716
[20/24] Train loss=0.28255391120910645
Test set avg_accuracy=69.93% avg_sensitivity=45.52%, avg_specificity=78.26% avg_auc=70.47%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.304634 Test loss=0.553631 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2951166331768036
[5/24] Train loss=0.301250696182251
[10/24] Train loss=0.32309621572494507
[15/24] Train loss=0.2719879150390625
[20/24] Train loss=0.2801145017147064
Test set avg_accuracy=64.99% avg_sensitivity=71.43%, avg_specificity=62.79% avg_auc=73.80%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.297423 Test loss=0.596320 Current lr=[0.000224838296036774]

[0/24] Train loss=0.29336148500442505
[5/24] Train loss=0.29602912068367004
[10/24] Train loss=0.32692670822143555
[15/24] Train loss=0.2817491590976715
[20/24] Train loss=0.2846372425556183
Test set avg_accuracy=67.72% avg_sensitivity=77.93%, avg_specificity=64.24% avg_auc=80.49%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.304065 Test loss=0.567354 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.28751152753829956
[5/24] Train loss=0.31051117181777954
[10/24] Train loss=0.33719873428344727
[15/24] Train loss=0.29124587774276733
[20/24] Train loss=0.2838112413883209
Test set avg_accuracy=84.35% avg_sensitivity=61.80%, avg_specificity=92.04% avg_auc=87.92%
Best model saved!! Metric=0.11174849082431138!!
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.299756 Test loss=0.375255 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.30097898840904236
[5/24] Train loss=0.2939467132091522
[10/24] Train loss=0.31570160388946533
[15/24] Train loss=0.2783236503601074
[20/24] Train loss=0.2765609323978424
Test set avg_accuracy=59.58% avg_sensitivity=76.14%, avg_specificity=53.94% avg_auc=70.52%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.298892 Test loss=0.709316 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2838972210884094
[5/24] Train loss=0.29611068964004517
[10/24] Train loss=0.320525199174881
[15/24] Train loss=0.2769811749458313
[20/24] Train loss=0.2702139914035797
Test set avg_accuracy=73.44% avg_sensitivity=73.12%, avg_specificity=73.55% avg_auc=81.34%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.294485 Test loss=0.513492 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.3136275112628937
[5/24] Train loss=0.328113317489624
[10/24] Train loss=0.3294966220855713
[15/24] Train loss=0.29383477568626404
[20/24] Train loss=0.28333818912506104
Test set avg_accuracy=84.01% avg_sensitivity=65.80%, avg_specificity=90.22% avg_auc=88.97%
Best model saved!! Metric=3.0023794419647345!!
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.309187 Test loss=0.362171 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.3309386372566223
[5/24] Train loss=0.3127082288265228
[10/24] Train loss=0.31886884570121765
[15/24] Train loss=0.2850930392742157
[20/24] Train loss=0.2788958251476288
Test set avg_accuracy=70.09% avg_sensitivity=66.77%, avg_specificity=71.22% avg_auc=76.75%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.302784 Test loss=0.538338 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2986075282096863
[5/24] Train loss=0.3078775107860565
[10/24] Train loss=0.30622413754463196
[15/24] Train loss=0.2811785340309143
[20/24] Train loss=0.28000035881996155
Test set avg_accuracy=63.11% avg_sensitivity=66.51%, avg_specificity=61.95% avg_auc=72.59%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.296086 Test loss=0.592799 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2888507544994354
[5/24] Train loss=0.3056589663028717
[10/24] Train loss=0.31648001074790955
[15/24] Train loss=0.27365291118621826
[20/24] Train loss=0.2774167060852051
Test set avg_accuracy=60.31% avg_sensitivity=59.86%, avg_specificity=60.47% avg_auc=67.33%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.290863 Test loss=0.641376 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2743701934814453
[5/24] Train loss=0.3037821650505066
[10/24] Train loss=0.3151420056819916
[15/24] Train loss=0.270637184381485
[20/24] Train loss=0.2769354581832886
Test set avg_accuracy=60.26% avg_sensitivity=68.87%, avg_specificity=57.32% avg_auc=68.40%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.287328 Test loss=0.674878 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.28631827235221863
[5/24] Train loss=0.2955644130706787
[10/24] Train loss=0.3105631172657013
[15/24] Train loss=0.2674993574619293
[20/24] Train loss=0.27068814635276794
Test set avg_accuracy=61.52% avg_sensitivity=64.52%, avg_specificity=60.50% avg_auc=68.08%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.287188 Test loss=0.623622 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2727234661579132
[5/24] Train loss=0.29136520624160767
[10/24] Train loss=0.31119656562805176
[15/24] Train loss=0.27083075046539307
[20/24] Train loss=0.26362287998199463
Test set avg_accuracy=56.84% avg_sensitivity=68.82%, avg_specificity=52.75% avg_auc=67.01%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.285506 Test loss=0.658437 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.277900367975235
[5/24] Train loss=0.29745161533355713
[10/24] Train loss=0.296294242143631
[15/24] Train loss=0.2571962773799896
[20/24] Train loss=0.2631016671657562
Test set avg_accuracy=60.05% avg_sensitivity=68.92%, avg_specificity=57.03% avg_auc=67.06%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.283706 Test loss=0.669842 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.27075278759002686
[5/24] Train loss=0.3046053349971771
[10/24] Train loss=0.303268164396286
[15/24] Train loss=0.27661237120628357
[20/24] Train loss=0.2618931829929352
Test set avg_accuracy=70.33% avg_sensitivity=71.53%, avg_specificity=69.91% avg_auc=77.31%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.286396 Test loss=0.552814 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2746652066707611
[5/24] Train loss=0.2842329442501068
[10/24] Train loss=0.30852818489074707
[15/24] Train loss=0.2690138518810272
[20/24] Train loss=0.2596167027950287
Test set avg_accuracy=62.76% avg_sensitivity=70.71%, avg_specificity=60.05% avg_auc=70.61%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.281314 Test loss=0.681686 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.279194712638855
[5/24] Train loss=0.27872195839881897
[10/24] Train loss=0.2962741553783417
[15/24] Train loss=0.25190430879592896
[20/24] Train loss=0.2606283724308014
Test set avg_accuracy=64.97% avg_sensitivity=59.60%, avg_specificity=66.81% avg_auc=71.59%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.276728 Test loss=0.570626 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2793334722518921
[5/24] Train loss=0.2780574858188629
[10/24] Train loss=0.2951907217502594
[15/24] Train loss=0.2531753182411194
[20/24] Train loss=0.2550560235977173
Test set avg_accuracy=59.88% avg_sensitivity=77.52%, avg_specificity=53.87% avg_auc=71.90%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.276515 Test loss=0.671726 Current lr=[0.000156543481933168]

[0/24] Train loss=0.26782000064849854
[5/24] Train loss=0.27620309591293335
[10/24] Train loss=0.28512924909591675
[15/24] Train loss=0.26452380418777466
[20/24] Train loss=0.2684100568294525
Test set avg_accuracy=60.95% avg_sensitivity=63.29%, avg_specificity=60.15% avg_auc=68.19%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.274603 Test loss=0.627175 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.27298063039779663
[5/24] Train loss=0.27653956413269043
[10/24] Train loss=0.29414206743240356
[15/24] Train loss=0.2522313594818115
[20/24] Train loss=0.25464341044425964
Test set avg_accuracy=56.60% avg_sensitivity=75.52%, avg_specificity=50.15% avg_auc=66.14%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.275193 Test loss=0.805256 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2625485360622406
[5/24] Train loss=0.26848897337913513
[10/24] Train loss=0.28217726945877075
[15/24] Train loss=0.24657012522220612
[20/24] Train loss=0.2476830631494522
Test set avg_accuracy=61.59% avg_sensitivity=67.79%, avg_specificity=59.47% avg_auc=70.25%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.270630 Test loss=0.608132 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.25433000922203064
[5/24] Train loss=0.2648029327392578
[10/24] Train loss=0.281735360622406
[15/24] Train loss=0.260115385055542
[20/24] Train loss=0.2437119334936142
Test set avg_accuracy=60.66% avg_sensitivity=65.49%, avg_specificity=59.02% avg_auc=68.21%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.270027 Test loss=0.631005 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.26407477259635925
[5/24] Train loss=0.2792213559150696
[10/24] Train loss=0.2869356870651245
[15/24] Train loss=0.2503163516521454
[20/24] Train loss=0.24708418548107147
Test set avg_accuracy=55.39% avg_sensitivity=75.47%, avg_specificity=48.54% avg_auc=65.72%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.269417 Test loss=0.772072 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2587805986404419
[5/24] Train loss=0.27638933062553406
[10/24] Train loss=0.28192874789237976
[15/24] Train loss=0.2456841617822647
[20/24] Train loss=0.2524707317352295
Test set avg_accuracy=59.79% avg_sensitivity=73.02%, avg_specificity=55.28% avg_auc=68.57%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.270057 Test loss=0.754848 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24847804009914398
[5/24] Train loss=0.2699902057647705
[10/24] Train loss=0.282223641872406
[15/24] Train loss=0.26658961176872253
[20/24] Train loss=0.2577955424785614
Test set avg_accuracy=60.72% avg_sensitivity=75.99%, avg_specificity=55.51% avg_auc=72.11%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.270224 Test loss=0.643624 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2739083468914032
[5/24] Train loss=0.27644261717796326
[10/24] Train loss=0.2805006206035614
[15/24] Train loss=0.2520287036895752
[20/24] Train loss=0.24883443117141724
Test set avg_accuracy=70.90% avg_sensitivity=63.29%, avg_specificity=73.49% avg_auc=75.49%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.267282 Test loss=0.545620 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.275665819644928
[5/24] Train loss=0.2771919071674347
[10/24] Train loss=0.2787571847438812
[15/24] Train loss=0.24435023963451385
[20/24] Train loss=0.24231086671352386
Test set avg_accuracy=62.88% avg_sensitivity=59.04%, avg_specificity=64.19% avg_auc=65.09%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.269300 Test loss=0.712698 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.25672397017478943
[5/24] Train loss=0.26281851530075073
[10/24] Train loss=0.2782871425151825
[15/24] Train loss=0.23500904440879822
[20/24] Train loss=0.24767453968524933
Test set avg_accuracy=60.72% avg_sensitivity=68.10%, avg_specificity=58.20% avg_auc=69.38%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.260559 Test loss=0.650484 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.25052323937416077
[5/24] Train loss=0.27403002977371216
[10/24] Train loss=0.279308021068573
[15/24] Train loss=0.23859713971614838
[20/24] Train loss=0.24606895446777344
Test set avg_accuracy=60.44% avg_sensitivity=68.77%, avg_specificity=57.60% avg_auc=68.77%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.257696 Test loss=0.651770 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.242482990026474
[5/24] Train loss=0.266068696975708
[10/24] Train loss=0.2845786213874817
[15/24] Train loss=0.25160881876945496
[20/24] Train loss=0.24371348321437836
Test set avg_accuracy=59.51% avg_sensitivity=74.24%, avg_specificity=54.48% avg_auc=69.11%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.257774 Test loss=0.716093 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.24951694905757904
[5/24] Train loss=0.2712738811969757
[10/24] Train loss=0.2679215371608734
[15/24] Train loss=0.24449855089187622
[20/24] Train loss=0.2369583398103714
Test set avg_accuracy=76.89% avg_sensitivity=64.46%, avg_specificity=81.12% avg_auc=80.27%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.255375 Test loss=0.478961 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2519598603248596
[5/24] Train loss=0.2649060785770416
[10/24] Train loss=0.27076297998428345
[15/24] Train loss=0.23324859142303467
[20/24] Train loss=0.2437743991613388
Test set avg_accuracy=63.67% avg_sensitivity=61.85%, avg_specificity=64.29% avg_auc=68.96%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.257070 Test loss=0.613503 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2412310540676117
[5/24] Train loss=0.2625454068183899
[10/24] Train loss=0.2582615315914154
[15/24] Train loss=0.2319813370704651
[20/24] Train loss=0.2350875437259674
Test set avg_accuracy=59.04% avg_sensitivity=74.91%, avg_specificity=53.62% avg_auc=69.02%
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.251677 Test loss=0.707851 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.24317675828933716
[5/24] Train loss=0.2769486606121063
[10/24] Train loss=0.26294729113578796
[15/24] Train loss=0.23299913108348846
[20/24] Train loss=0.2344382256269455
Test set avg_accuracy=61.07% avg_sensitivity=70.20%, avg_specificity=57.95% avg_auc=70.07%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.252003 Test loss=0.636684 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.2454097867012024
[5/24] Train loss=0.24867665767669678
[10/24] Train loss=0.25950437784194946
[15/24] Train loss=0.22332675755023956
[20/24] Train loss=0.2291584014892578
Test set avg_accuracy=59.36% avg_sensitivity=75.32%, avg_specificity=53.92% avg_auc=70.11%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.248252 Test loss=0.681291 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.24125821888446808
[5/24] Train loss=0.2528489828109741
[10/24] Train loss=0.25924646854400635
[15/24] Train loss=0.22730711102485657
[20/24] Train loss=0.2296471744775772
Test set avg_accuracy=58.71% avg_sensitivity=70.56%, avg_specificity=54.67% avg_auc=68.26%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.247539 Test loss=0.677764 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.23861627280712128
[5/24] Train loss=0.25026166439056396
[10/24] Train loss=0.2658921480178833
[15/24] Train loss=0.22952954471111298
[20/24] Train loss=0.22336368262767792
Test set avg_accuracy=59.86% avg_sensitivity=75.88%, avg_specificity=54.39% avg_auc=69.80%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.245334 Test loss=0.747603 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.2315317839384079
[5/24] Train loss=0.24486584961414337
[10/24] Train loss=0.25629058480262756
[15/24] Train loss=0.21925297379493713
[20/24] Train loss=0.2256760448217392
Test set avg_accuracy=60.01% avg_sensitivity=71.22%, avg_specificity=56.19% avg_auc=68.88%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.240616 Test loss=0.695521 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.23208412528038025
[5/24] Train loss=0.24608634412288666
[10/24] Train loss=0.25700175762176514
[15/24] Train loss=0.2200925648212433
[20/24] Train loss=0.22493934631347656
Test set avg_accuracy=62.02% avg_sensitivity=66.87%, avg_specificity=60.36% avg_auc=68.42%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.240817 Test loss=0.690176 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.2293158918619156
[5/24] Train loss=0.24704203009605408
[10/24] Train loss=0.25713926553726196
[15/24] Train loss=0.2182472050189972
[20/24] Train loss=0.22499440610408783
Test set avg_accuracy=58.80% avg_sensitivity=75.17%, avg_specificity=53.22% avg_auc=69.01%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.239891 Test loss=0.700970 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.23069551587104797
[5/24] Train loss=0.24251456558704376
[10/24] Train loss=0.2537473738193512
[15/24] Train loss=0.21587331593036652
[20/24] Train loss=0.22175249457359314
Test set avg_accuracy=59.75% avg_sensitivity=71.17%, avg_specificity=55.86% avg_auc=68.68%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.238087 Test loss=0.708557 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.23297090828418732
[5/24] Train loss=0.24590344727039337
[10/24] Train loss=0.26065295934677124
[15/24] Train loss=0.2220025509595871
[20/24] Train loss=0.2182026356458664
Test set avg_accuracy=58.49% avg_sensitivity=70.05%, avg_specificity=54.55% avg_auc=67.06%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.239285 Test loss=0.698726 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.24107149243354797
[5/24] Train loss=0.2532378137111664
[10/24] Train loss=0.2691306471824646
[15/24] Train loss=0.22142045199871063
[20/24] Train loss=0.21942239999771118
Test set avg_accuracy=60.74% avg_sensitivity=66.56%, avg_specificity=58.76% avg_auc=66.85%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.239184 Test loss=0.702463 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.2338559329509735
[5/24] Train loss=0.2424597293138504
[10/24] Train loss=0.25560513138771057
[15/24] Train loss=0.22615888714790344
[20/24] Train loss=0.22125276923179626
Test set avg_accuracy=57.30% avg_sensitivity=70.51%, avg_specificity=52.80% avg_auc=66.06%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.241296 Test loss=0.756059 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.22415535151958466
[5/24] Train loss=0.25411197543144226
[10/24] Train loss=0.2567065358161926
[15/24] Train loss=0.21324564516544342
[20/24] Train loss=0.22740991413593292
Test set avg_accuracy=57.67% avg_sensitivity=78.19%, avg_specificity=50.67% avg_auc=69.94%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.241705 Test loss=0.757918 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.22988438606262207
[5/24] Train loss=0.2331787645816803
[10/24] Train loss=0.2466719150543213
[15/24] Train loss=0.21246539056301117
[20/24] Train loss=0.2194853127002716
Test set avg_accuracy=59.56% avg_sensitivity=74.65%, avg_specificity=54.41% avg_auc=69.89%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.234327 Test loss=0.731006 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.2294008731842041
[5/24] Train loss=0.2241523265838623
[10/24] Train loss=0.24828843772411346
[15/24] Train loss=0.21051234006881714
[20/24] Train loss=0.21618248522281647
Test set avg_accuracy=59.13% avg_sensitivity=75.52%, avg_specificity=53.54% avg_auc=69.55%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.229096 Test loss=0.730308 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.22070221602916718
[5/24] Train loss=0.23001456260681152
[10/24] Train loss=0.23771746456623077
[15/24] Train loss=0.20524755120277405
[20/24] Train loss=0.21447418630123138
Test set avg_accuracy=58.92% avg_sensitivity=74.55%, avg_specificity=53.59% avg_auc=69.16%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.226222 Test loss=0.724622 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.22347187995910645
[5/24] Train loss=0.23572611808776855
[10/24] Train loss=0.2378174513578415
[15/24] Train loss=0.20547200739383698
[20/24] Train loss=0.209058940410614
Test set avg_accuracy=58.61% avg_sensitivity=73.22%, avg_specificity=53.62% avg_auc=67.99%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.223945 Test loss=0.743489 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2137681394815445
[5/24] Train loss=0.22185683250427246
[10/24] Train loss=0.23459748923778534
[15/24] Train loss=0.20322638750076294
[20/24] Train loss=0.2078331708908081
Test set avg_accuracy=58.06% avg_sensitivity=74.24%, avg_specificity=52.54% avg_auc=68.40%
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.221709 Test loss=0.743038 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.2138250172138214
[5/24] Train loss=0.22854427993297577
[10/24] Train loss=0.23454418778419495
[15/24] Train loss=0.20469693839550018
[20/24] Train loss=0.20678915083408356
Test set avg_accuracy=58.45% avg_sensitivity=73.43%, avg_specificity=53.34% avg_auc=68.88%
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.222790 Test loss=0.730645 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.2144494205713272
[5/24] Train loss=0.22788263857364655
[10/24] Train loss=0.24290858209133148
[15/24] Train loss=0.2008434385061264
[20/24] Train loss=0.20622149109840393
Test set avg_accuracy=59.28% avg_sensitivity=75.32%, avg_specificity=53.82% avg_auc=69.85%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.221695 Test loss=0.730163 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.21349632740020752
[5/24] Train loss=0.22380048036575317
[10/24] Train loss=0.23462890088558197
[15/24] Train loss=0.20182493329048157
[20/24] Train loss=0.20462666451931
Test set avg_accuracy=60.65% avg_sensitivity=72.96%, avg_specificity=56.45% avg_auc=69.93%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.218797 Test loss=0.706852 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2092086523771286
[5/24] Train loss=0.2175031453371048
[10/24] Train loss=0.23180615901947021
[15/24] Train loss=0.1980922967195511
[20/24] Train loss=0.20384418964385986
Test set avg_accuracy=58.54% avg_sensitivity=73.53%, avg_specificity=53.43% avg_auc=68.24%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.218968 Test loss=0.742302 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.21225647628307343
[5/24] Train loss=0.22026655077934265
[10/24] Train loss=0.23149259388446808
[15/24] Train loss=0.1955580711364746
[20/24] Train loss=0.20383429527282715
Test set avg_accuracy=58.31% avg_sensitivity=74.60%, avg_specificity=52.75% avg_auc=68.08%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.217914 Test loss=0.773342 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.2106773853302002
[5/24] Train loss=0.2206854522228241
[10/24] Train loss=0.2294178158044815
[15/24] Train loss=0.19805572926998138
[20/24] Train loss=0.204147070646286
Test set avg_accuracy=59.01% avg_sensitivity=71.84%, avg_specificity=54.64% avg_auc=68.29%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.216676 Test loss=0.753536 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.21224328875541687
[5/24] Train loss=0.21994264423847198
[10/24] Train loss=0.22531701624393463
[15/24] Train loss=0.19996827840805054
[20/24] Train loss=0.2009265124797821
Test set avg_accuracy=59.90% avg_sensitivity=72.04%, avg_specificity=55.75% avg_auc=69.16%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.216515 Test loss=0.730939 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2088557332754135
[5/24] Train loss=0.21318380534648895
[10/24] Train loss=0.22622312605381012
[15/24] Train loss=0.1947513073682785
[20/24] Train loss=0.20302753150463104
Test set avg_accuracy=59.21% avg_sensitivity=72.81%, avg_specificity=54.57% avg_auc=68.60%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.215141 Test loss=0.745539 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.21158216893672943
[5/24] Train loss=0.21250684559345245
[10/24] Train loss=0.21883295476436615
[15/24] Train loss=0.19451527297496796
[20/24] Train loss=0.20356954634189606
Test set avg_accuracy=59.23% avg_sensitivity=74.09%, avg_specificity=54.16% avg_auc=69.36%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.215128 Test loss=0.742657 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.20985610783100128
[5/24] Train loss=0.2137538492679596
[10/24] Train loss=0.23831653594970703
[15/24] Train loss=0.19618763029575348
[20/24] Train loss=0.19933785498142242
Test set avg_accuracy=59.52% avg_sensitivity=72.91%, avg_specificity=54.95% avg_auc=69.15%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.215440 Test loss=0.739412 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.20506836473941803
[5/24] Train loss=0.21665871143341064
[10/24] Train loss=0.23097635805606842
[15/24] Train loss=0.19483201205730438
[20/24] Train loss=0.19841431081295013
Test set avg_accuracy=59.54% avg_sensitivity=73.48%, avg_specificity=54.79% avg_auc=69.26%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.213719 Test loss=0.737038 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.20758557319641113
[5/24] Train loss=0.21847479045391083
[10/24] Train loss=0.22950558364391327
[15/24] Train loss=0.19036419689655304
[20/24] Train loss=0.1962309032678604
Test set avg_accuracy=60.07% avg_sensitivity=72.56%, avg_specificity=55.81% avg_auc=69.42%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.211984 Test loss=0.726781 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.20561006665229797
[5/24] Train loss=0.2175835520029068
[10/24] Train loss=0.22775845229625702
[15/24] Train loss=0.19606222212314606
[20/24] Train loss=0.19926713407039642
Test set avg_accuracy=59.71% avg_sensitivity=72.40%, avg_specificity=55.39% avg_auc=69.23%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.213476 Test loss=0.731122 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.20647084712982178
[5/24] Train loss=0.21425403654575348
[10/24] Train loss=0.22439217567443848
[15/24] Train loss=0.1951286792755127
[20/24] Train loss=0.19568346440792084
Test set avg_accuracy=59.58% avg_sensitivity=73.22%, avg_specificity=54.93% avg_auc=69.06%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.211827 Test loss=0.739283 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.21008984744548798
[5/24] Train loss=0.21566706895828247
[10/24] Train loss=0.2241535633802414
[15/24] Train loss=0.19337721168994904
[20/24] Train loss=0.19635124504566193
Test set avg_accuracy=59.21% avg_sensitivity=73.68%, avg_specificity=54.27% avg_auc=68.99%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.211838 Test loss=0.744317 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.20698398351669312
[5/24] Train loss=0.2152959555387497
[10/24] Train loss=0.22618167102336884
[15/24] Train loss=0.1932506412267685
[20/24] Train loss=0.20157647132873535
Test set avg_accuracy=59.39% avg_sensitivity=73.63%, avg_specificity=54.53% avg_auc=69.09%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.212249 Test loss=0.740596 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.2058732658624649
[5/24] Train loss=0.21225568652153015
[10/24] Train loss=0.2264103889465332
[15/24] Train loss=0.1943836212158203
[20/24] Train loss=0.19584761559963226
Test set avg_accuracy=59.30% avg_sensitivity=73.58%, avg_specificity=54.43% avg_auc=68.96%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.211617 Test loss=0.744421 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.20769540965557098
[5/24] Train loss=0.21831974387168884
[10/24] Train loss=0.22799551486968994
[15/24] Train loss=0.19233088195323944
[20/24] Train loss=0.1995335817337036
Test set avg_accuracy=59.53% avg_sensitivity=73.99%, avg_specificity=54.60% avg_auc=69.38%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.212062 Test loss=0.741020 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.20486558973789215
[5/24] Train loss=0.22023539245128632
[10/24] Train loss=0.22538353502750397
[15/24] Train loss=0.19218991696834564
[20/24] Train loss=0.19606351852416992
Test set avg_accuracy=59.82% avg_sensitivity=73.84%, avg_specificity=55.04% avg_auc=69.58%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.211130 Test loss=0.734567 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.2083931267261505
[5/24] Train loss=0.2092602252960205
[10/24] Train loss=0.22612471878528595
[15/24] Train loss=0.19305887818336487
[20/24] Train loss=0.19636622071266174
Test set avg_accuracy=59.52% avg_sensitivity=73.68%, avg_specificity=54.69% avg_auc=69.23%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.211400 Test loss=0.738985 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.205900177359581
[5/24] Train loss=0.22193016111850739
[10/24] Train loss=0.22291041910648346
[15/24] Train loss=0.19409173727035522
[20/24] Train loss=0.1982051581144333
Test set avg_accuracy=59.31% avg_sensitivity=73.63%, avg_specificity=54.43% avg_auc=69.03%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.211563 Test loss=0.744440 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.2081541121006012
[5/24] Train loss=0.2126496136188507
[10/24] Train loss=0.22434717416763306
[15/24] Train loss=0.19354017078876495
[20/24] Train loss=0.20351535081863403
Test set avg_accuracy=59.53% avg_sensitivity=73.68%, avg_specificity=54.71% avg_auc=69.26%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.212257 Test loss=0.739943 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=84.01% sen=65.80%, spe=90.22%, auc=88.97%!
Fold[5] Avg_overlap=0.60%(±0.2821323757590595)
[0/24] Train loss=0.7412080764770508
[5/24] Train loss=0.7386438846588135
[10/24] Train loss=0.7375523447990417
[15/24] Train loss=0.7271799445152283
[20/24] Train loss=0.7327811121940613
Test set avg_accuracy=52.12% avg_sensitivity=49.52%, avg_specificity=53.09% avg_auc=52.07%
Best model saved!! Metric=-119.19961577627538!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=0.735005 Test loss=0.719140 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7303558588027954
[5/24] Train loss=0.735195517539978
[10/24] Train loss=0.7276146411895752
[15/24] Train loss=0.7241491079330444
[20/24] Train loss=0.718191921710968
Test set avg_accuracy=49.49% avg_sensitivity=54.51%, avg_specificity=47.62% avg_auc=51.96%
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.726501 Test loss=0.699501 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7172018885612488
[5/24] Train loss=0.7264602780342102
[10/24] Train loss=0.7236731648445129
[15/24] Train loss=0.7086296677589417
[20/24] Train loss=0.7222931385040283
Test set avg_accuracy=60.31% avg_sensitivity=31.14%, avg_specificity=71.18% avg_auc=51.95%
Best model saved!! Metric=-111.41718815811677!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.716614 Test loss=0.691112 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.708197832107544
[5/24] Train loss=0.7172413468360901
[10/24] Train loss=0.7083365321159363
[15/24] Train loss=0.6976667642593384
[20/24] Train loss=0.6935211420059204
Test set avg_accuracy=60.43% avg_sensitivity=28.69%, avg_specificity=72.25% avg_auc=51.98%
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.706203 Test loss=0.686574 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.7038254737854004
[5/24] Train loss=0.7079211473464966
[10/24] Train loss=0.7004793882369995
[15/24] Train loss=0.6933304071426392
[20/24] Train loss=0.6903397440910339
Test set avg_accuracy=63.14% avg_sensitivity=25.34%, avg_specificity=77.22% avg_auc=52.36%
Best model saved!! Metric=-107.9527924223648!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.696940 Test loss=0.682050 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6917160153388977
[5/24] Train loss=0.692030131816864
[10/24] Train loss=0.6878159046173096
[15/24] Train loss=0.6799367666244507
[20/24] Train loss=0.6772903800010681
Test set avg_accuracy=63.33% avg_sensitivity=25.14%, avg_specificity=77.56% avg_auc=52.93%
Best model saved!! Metric=-107.03463617875305!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.685624 Test loss=0.676775 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6811009049415588
[5/24] Train loss=0.6825729608535767
[10/24] Train loss=0.6817609071731567
[15/24] Train loss=0.6690040230751038
[20/24] Train loss=0.6681441068649292
Test set avg_accuracy=63.71% avg_sensitivity=25.29%, avg_specificity=78.02% avg_auc=53.57%
Best model saved!! Metric=-105.41317414953305!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.675552 Test loss=0.677764 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6577531099319458
[5/24] Train loss=0.667924702167511
[10/24] Train loss=0.6587365865707397
[15/24] Train loss=0.6506771445274353
[20/24] Train loss=0.6542179584503174
Test set avg_accuracy=61.07% avg_sensitivity=31.33%, avg_specificity=72.14% avg_auc=54.37%
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.662936 Test loss=0.667752 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6480824947357178
[5/24] Train loss=0.6475986838340759
[10/24] Train loss=0.645454466342926
[15/24] Train loss=0.6393621563911438
[20/24] Train loss=0.6409401297569275
Test set avg_accuracy=61.41% avg_sensitivity=32.10%, avg_specificity=72.32% avg_auc=55.36%
Best model saved!! Metric=-104.80811085413355!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.647221 Test loss=0.663819 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6356826424598694
[5/24] Train loss=0.6445407271385193
[10/24] Train loss=0.63641756772995
[15/24] Train loss=0.6208548545837402
[20/24] Train loss=0.6255296468734741
Test set avg_accuracy=65.07% avg_sensitivity=29.85%, avg_specificity=78.18% avg_auc=56.49%
Best model saved!! Metric=-96.41488033693406!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.634620 Test loss=0.650428 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6127362847328186
[5/24] Train loss=0.6288440227508545
[10/24] Train loss=0.614088237285614
[15/24] Train loss=0.6018148064613342
[20/24] Train loss=0.6069213151931763
Test set avg_accuracy=70.53% avg_sensitivity=19.87%, avg_specificity=89.40% avg_auc=59.59%
Best model saved!! Metric=-86.61068422722312!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.618464 Test loss=0.624667 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6040824055671692
[5/24] Train loss=0.6068319082260132
[10/24] Train loss=0.5972838997840881
[15/24] Train loss=0.5843424797058105
[20/24] Train loss=0.5972868800163269
Test set avg_accuracy=73.80% avg_sensitivity=20.11%, avg_specificity=93.80% avg_auc=62.18%
Best model saved!! Metric=-76.11022755777479!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.602123 Test loss=0.579848 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5765946507453918
[5/24] Train loss=0.5845869183540344
[10/24] Train loss=0.5787802934646606
[15/24] Train loss=0.5647706389427185
[20/24] Train loss=0.5624405145645142
Test set avg_accuracy=74.31% avg_sensitivity=18.38%, avg_specificity=95.14% avg_auc=68.00%
Best model saved!! Metric=-70.16843270267883!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.580410 Test loss=0.545889 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5532376766204834
[5/24] Train loss=0.5662269592285156
[10/24] Train loss=0.5380968451499939
[15/24] Train loss=0.5371268391609192
[20/24] Train loss=0.5259503126144409
Test set avg_accuracy=75.05% avg_sensitivity=23.27%, avg_specificity=94.34% avg_auc=69.58%
Best model saved!! Metric=-63.761308875798775!!
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.552690 Test loss=0.557268 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5146573781967163
[5/24] Train loss=0.5523937344551086
[10/24] Train loss=0.508192777633667
[15/24] Train loss=0.4936121702194214
[20/24] Train loss=0.4915958046913147
Test set avg_accuracy=75.90% avg_sensitivity=26.97%, avg_specificity=94.12% avg_auc=72.33%
Best model saved!! Metric=-56.683339104896014!!
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.519170 Test loss=0.553146 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4810603857040405
[5/24] Train loss=0.5236813426017761
[10/24] Train loss=0.4866939187049866
[15/24] Train loss=0.46984052658081055
[20/24] Train loss=0.453600138425827
Test set avg_accuracy=78.26% avg_sensitivity=38.53%, avg_specificity=93.05% avg_auc=77.98%
Best model saved!! Metric=-38.1849401686814!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.488460 Test loss=0.500331 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4481470286846161
[5/24] Train loss=0.4847058355808258
[10/24] Train loss=0.4502224326133728
[15/24] Train loss=0.4537353515625
[20/24] Train loss=0.43120065331459045
Test set avg_accuracy=59.18% avg_sensitivity=78.89%, avg_specificity=51.84% avg_auc=75.22%
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.463371 Test loss=0.637088 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.42588821053504944
[5/24] Train loss=0.46112117171287537
[10/24] Train loss=0.4438653588294983
[15/24] Train loss=0.4471431374549866
[20/24] Train loss=0.41908085346221924
Test set avg_accuracy=64.71% avg_sensitivity=75.82%, avg_specificity=60.58% avg_auc=76.84%
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.448537 Test loss=0.603248 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4148273766040802
[5/24] Train loss=0.4330737590789795
[10/24] Train loss=0.43107447028160095
[15/24] Train loss=0.42560985684394836
[20/24] Train loss=0.40869978070259094
Test set avg_accuracy=58.31% avg_sensitivity=75.86%, avg_specificity=51.77% avg_auc=71.35%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.434011 Test loss=0.653187 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4065122902393341
[5/24] Train loss=0.41812193393707275
[10/24] Train loss=0.4156911373138428
[15/24] Train loss=0.42668840289115906
[20/24] Train loss=0.3917389214038849
Test set avg_accuracy=55.51% avg_sensitivity=74.33%, avg_specificity=48.50% avg_auc=66.21%
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.426257 Test loss=0.685746 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.3966076076030731
[5/24] Train loss=0.4126391112804413
[10/24] Train loss=0.4106323719024658
[15/24] Train loss=0.42722976207733154
[20/24] Train loss=0.3859834372997284
Test set avg_accuracy=54.09% avg_sensitivity=73.37%, avg_specificity=46.91% avg_auc=65.24%
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.418249 Test loss=0.684922 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.3952651619911194
[5/24] Train loss=0.4017116129398346
[10/24] Train loss=0.40503913164138794
[15/24] Train loss=0.41786205768585205
[20/24] Train loss=0.3777965009212494
Test set avg_accuracy=63.79% avg_sensitivity=73.03%, avg_specificity=60.35% avg_auc=74.42%
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.414133 Test loss=0.615792 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.39188119769096375
[5/24] Train loss=0.40880516171455383
[10/24] Train loss=0.39697062969207764
[15/24] Train loss=0.41502630710601807
[20/24] Train loss=0.3902464509010315
Test set avg_accuracy=69.45% avg_sensitivity=72.50%, avg_specificity=68.32% avg_auc=76.53%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.411759 Test loss=0.590812 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3867267072200775
[5/24] Train loss=0.39526447653770447
[10/24] Train loss=0.414825439453125
[15/24] Train loss=0.4167797863483429
[20/24] Train loss=0.3736039400100708
Test set avg_accuracy=74.45% avg_sensitivity=66.41%, avg_specificity=77.45% avg_auc=79.37%
Best model saved!! Metric=-28.314456621915298!!
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.406279 Test loss=0.535404 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.38605743646621704
[5/24] Train loss=0.3983760476112366
[10/24] Train loss=0.3888538181781769
[15/24] Train loss=0.41068002581596375
[20/24] Train loss=0.36335960030555725
Test set avg_accuracy=60.52% avg_sensitivity=75.00%, avg_specificity=55.13% avg_auc=72.71%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.401122 Test loss=0.632575 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.37713611125946045
[5/24] Train loss=0.3817158639431
[10/24] Train loss=0.38970625400543213
[15/24] Train loss=0.4289098381996155
[20/24] Train loss=0.36600157618522644
Test set avg_accuracy=73.26% avg_sensitivity=65.93%, avg_specificity=75.98% avg_auc=78.62%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.399335 Test loss=0.559267 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3768918514251709
[5/24] Train loss=0.38421258330345154
[10/24] Train loss=0.3797784745693207
[15/24] Train loss=0.4072125554084778
[20/24] Train loss=0.36386606097221375
Test set avg_accuracy=60.90% avg_sensitivity=70.83%, avg_specificity=57.20% avg_auc=70.70%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.392516 Test loss=0.632758 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3732677400112152
[5/24] Train loss=0.3827257752418518
[10/24] Train loss=0.37552040815353394
[15/24] Train loss=0.40162914991378784
[20/24] Train loss=0.35652461647987366
Test set avg_accuracy=82.54% avg_sensitivity=58.30%, avg_specificity=91.57% avg_auc=87.47%
Best model saved!! Metric=-6.126298451543406!!
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.389089 Test loss=0.402774 Current lr=[0.000210185142098938]

[0/24] Train loss=0.3775038719177246
[5/24] Train loss=0.37161028385162354
[10/24] Train loss=0.37918922305107117
[15/24] Train loss=0.39722272753715515
[20/24] Train loss=0.3490549921989441
Test set avg_accuracy=56.84% avg_sensitivity=75.43%, avg_specificity=49.91% avg_auc=68.69%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.387628 Test loss=0.664974 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.35858023166656494
[5/24] Train loss=0.38131552934646606
[10/24] Train loss=0.3804478645324707
[15/24] Train loss=0.39559289813041687
[20/24] Train loss=0.3554154634475708
Test set avg_accuracy=62.83% avg_sensitivity=64.49%, avg_specificity=62.21% avg_auc=68.08%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.389033 Test loss=0.642810 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3607500195503235
[5/24] Train loss=0.37094101309776306
[10/24] Train loss=0.37323763966560364
[15/24] Train loss=0.39233431220054626
[20/24] Train loss=0.370777428150177
Test set avg_accuracy=67.59% avg_sensitivity=63.48%, avg_specificity=69.12% avg_auc=74.24%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.380924 Test loss=0.578462 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3545397222042084
[5/24] Train loss=0.3508034348487854
[10/24] Train loss=0.37325963377952576
[15/24] Train loss=0.38205957412719727
[20/24] Train loss=0.3566601574420929
Test set avg_accuracy=65.83% avg_sensitivity=67.61%, avg_specificity=65.17% avg_auc=74.12%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.373646 Test loss=0.593739 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3550625741481781
[5/24] Train loss=0.3439466059207916
[10/24] Train loss=0.4274841547012329
[15/24] Train loss=0.38794922828674316
[20/24] Train loss=0.34108495712280273
Test set avg_accuracy=55.89% avg_sensitivity=62.38%, avg_specificity=53.47% avg_auc=62.71%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.374431 Test loss=0.682998 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.3519056439399719
[5/24] Train loss=0.35407716035842896
[10/24] Train loss=0.3617246747016907
[15/24] Train loss=0.3784060478210449
[20/24] Train loss=0.3377014100551605
Test set avg_accuracy=59.84% avg_sensitivity=68.23%, avg_specificity=56.72% avg_auc=68.54%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.364171 Test loss=0.646909 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.33917444944381714
[5/24] Train loss=0.3505341112613678
[10/24] Train loss=0.35525965690612793
[15/24] Train loss=0.37453702092170715
[20/24] Train loss=0.3308430016040802
Test set avg_accuracy=68.07% avg_sensitivity=66.46%, avg_specificity=68.67% avg_auc=73.96%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.361343 Test loss=0.615731 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.33700403571128845
[5/24] Train loss=0.35141146183013916
[10/24] Train loss=0.3498844504356384
[15/24] Train loss=0.36999794840812683
[20/24] Train loss=0.333559513092041
Test set avg_accuracy=63.91% avg_sensitivity=67.85%, avg_specificity=62.44% avg_auc=71.36%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.359721 Test loss=0.628535 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.3372197151184082
[5/24] Train loss=0.34469619393348694
[10/24] Train loss=0.34966617822647095
[15/24] Train loss=0.37114182114601135
[20/24] Train loss=0.32485175132751465
Test set avg_accuracy=82.12% avg_sensitivity=50.24%, avg_specificity=94.00% avg_auc=85.54%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.357068 Test loss=0.416674 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.3787635862827301
[5/24] Train loss=0.3461628258228302
[10/24] Train loss=0.3401944637298584
[15/24] Train loss=0.35889285802841187
[20/24] Train loss=0.3283769488334656
Test set avg_accuracy=75.99% avg_sensitivity=26.06%, avg_specificity=94.59% avg_auc=70.97%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.356667 Test loss=0.578108 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3417283594608307
[5/24] Train loss=0.3318594694137573
[10/24] Train loss=0.3410283029079437
[15/24] Train loss=0.36034369468688965
[20/24] Train loss=0.32121437788009644
Test set avg_accuracy=68.70% avg_sensitivity=52.93%, avg_specificity=74.57% avg_auc=71.57%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.347732 Test loss=0.599666 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.34080538153648376
[5/24] Train loss=0.3369637131690979
[10/24] Train loss=0.3329571783542633
[15/24] Train loss=0.3501439690589905
[20/24] Train loss=0.32982295751571655
Test set avg_accuracy=80.46% avg_sensitivity=67.13%, avg_specificity=85.42% avg_auc=85.52%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.348615 Test loss=0.423428 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.345496267080307
[5/24] Train loss=0.3472791612148285
[10/24] Train loss=0.3407430052757263
[15/24] Train loss=0.37149617075920105
[20/24] Train loss=0.3313942551612854
Test set avg_accuracy=60.51% avg_sensitivity=60.75%, avg_specificity=60.42% avg_auc=65.99%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.352119 Test loss=0.674599 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.33315029740333557
[5/24] Train loss=0.3366296589374542
[10/24] Train loss=0.3298521041870117
[15/24] Train loss=0.3445800542831421
[20/24] Train loss=0.3120649456977844
Test set avg_accuracy=67.79% avg_sensitivity=38.15%, avg_specificity=78.82% avg_auc=66.58%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.339880 Test loss=0.595749 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33096060156822205
[5/24] Train loss=0.32418525218963623
[10/24] Train loss=0.3322471082210541
[15/24] Train loss=0.36088091135025024
[20/24] Train loss=0.32322773337364197
Test set avg_accuracy=66.73% avg_sensitivity=58.64%, avg_specificity=69.75% avg_auc=70.64%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.338185 Test loss=0.598379 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3195931911468506
[5/24] Train loss=0.32375815510749817
[10/24] Train loss=0.3235800564289093
[15/24] Train loss=0.34909987449645996
[20/24] Train loss=0.3167418837547302
Test set avg_accuracy=72.37% avg_sensitivity=71.07%, avg_specificity=72.86% avg_auc=80.00%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.342525 Test loss=0.534177 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3526376187801361
[5/24] Train loss=0.32577747106552124
[10/24] Train loss=0.3415384590625763
[15/24] Train loss=0.34503108263015747
[20/24] Train loss=0.30854150652885437
Test set avg_accuracy=55.44% avg_sensitivity=72.07%, avg_specificity=49.25% avg_auc=66.37%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.340001 Test loss=0.693785 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.32608047127723694
[5/24] Train loss=0.32863301038742065
[10/24] Train loss=0.3235814571380615
[15/24] Train loss=0.34947171807289124
[20/24] Train loss=0.3235475718975067
Test set avg_accuracy=65.47% avg_sensitivity=71.55%, avg_specificity=63.21% avg_auc=76.40%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.337438 Test loss=0.568201 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3235294222831726
[5/24] Train loss=0.33228105306625366
[10/24] Train loss=0.3172004818916321
[15/24] Train loss=0.33087629079818726
[20/24] Train loss=0.2976713478565216
Test set avg_accuracy=75.53% avg_sensitivity=47.22%, avg_specificity=86.08% avg_auc=76.35%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.333899 Test loss=0.520280 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3121752440929413
[5/24] Train loss=0.3244108259677887
[10/24] Train loss=0.3095499277114868
[15/24] Train loss=0.33946675062179565
[20/24] Train loss=0.3326881229877472
Test set avg_accuracy=64.36% avg_sensitivity=45.59%, avg_specificity=71.35% avg_auc=64.76%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.338787 Test loss=0.657368 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.32768648862838745
[5/24] Train loss=0.3413351774215698
[10/24] Train loss=0.32128673791885376
[15/24] Train loss=0.33911049365997314
[20/24] Train loss=0.31379732489585876
Test set avg_accuracy=77.41% avg_sensitivity=28.26%, avg_specificity=95.71% avg_auc=77.45%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.334443 Test loss=0.513968 Current lr=[0.000298904600941902]

[0/24] Train loss=0.32370415329933167
[5/24] Train loss=0.3222195506095886
[10/24] Train loss=0.3272988796234131
[15/24] Train loss=0.33797532320022583
[20/24] Train loss=0.31137916445732117
Test set avg_accuracy=79.58% avg_sensitivity=29.65%, avg_specificity=98.18% avg_auc=85.22%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.326706 Test loss=0.429488 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3204108774662018
[5/24] Train loss=0.3235122263431549
[10/24] Train loss=0.30512967705726624
[15/24] Train loss=0.3293607532978058
[20/24] Train loss=0.2872829735279083
Test set avg_accuracy=59.71% avg_sensitivity=74.90%, avg_specificity=54.06% avg_auc=70.40%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.323336 Test loss=0.628116 Current lr=[0.000297555943323901]

[0/24] Train loss=0.30255675315856934
[5/24] Train loss=0.3126479685306549
[10/24] Train loss=0.3124752640724182
[15/24] Train loss=0.3281795084476471
[20/24] Train loss=0.3047921359539032
Test set avg_accuracy=66.65% avg_sensitivity=67.51%, avg_specificity=66.33% avg_auc=73.39%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.322353 Test loss=0.585139 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3049505650997162
[5/24] Train loss=0.3182647228240967
[10/24] Train loss=0.3186735212802887
[15/24] Train loss=0.3326115608215332
[20/24] Train loss=0.31933772563934326
Test set avg_accuracy=63.09% avg_sensitivity=74.33%, avg_specificity=58.90% avg_auc=74.52%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.326688 Test loss=0.633447 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3150172829627991
[5/24] Train loss=0.31673696637153625
[10/24] Train loss=0.3184466063976288
[15/24] Train loss=0.327739417552948
[20/24] Train loss=0.3064541518688202
Test set avg_accuracy=61.12% avg_sensitivity=78.17%, avg_specificity=54.77% avg_auc=72.26%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.326352 Test loss=0.641401 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3150888979434967
[5/24] Train loss=0.3122924566268921
[10/24] Train loss=0.3157680630683899
[15/24] Train loss=0.3137492537498474
[20/24] Train loss=0.29916834831237793
Test set avg_accuracy=67.14% avg_sensitivity=60.41%, avg_specificity=69.64% avg_auc=72.63%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.318595 Test loss=0.589244 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3071901500225067
[5/24] Train loss=0.2995855510234833
[10/24] Train loss=0.3107486069202423
[15/24] Train loss=0.33194971084594727
[20/24] Train loss=0.3447265923023224
Test set avg_accuracy=61.43% avg_sensitivity=64.64%, avg_specificity=60.24% avg_auc=68.30%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.320741 Test loss=0.658432 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3042577803134918
[5/24] Train loss=0.3055768609046936
[10/24] Train loss=0.30954158306121826
[15/24] Train loss=0.31016305088996887
[20/24] Train loss=0.31639423966407776
Test set avg_accuracy=77.63% avg_sensitivity=25.14%, avg_specificity=97.18% avg_auc=76.79%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.318787 Test loss=0.520410 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.30168503522872925
[5/24] Train loss=0.33111467957496643
[10/24] Train loss=0.3028584420681
[15/24] Train loss=0.3168623149394989
[20/24] Train loss=0.30147501826286316
Test set avg_accuracy=82.55% avg_sensitivity=45.20%, avg_specificity=96.46% avg_auc=87.47%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.322699 Test loss=0.394114 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.2907477915287018
[5/24] Train loss=0.3267994225025177
[10/24] Train loss=0.3093510568141937
[15/24] Train loss=0.3277569115161896
[20/24] Train loss=0.28785794973373413
Test set avg_accuracy=66.64% avg_sensitivity=68.52%, avg_specificity=65.94% avg_auc=75.22%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.317686 Test loss=0.558961 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.292662650346756
[5/24] Train loss=0.32010728120803833
[10/24] Train loss=0.29899144172668457
[15/24] Train loss=0.3104167580604553
[20/24] Train loss=0.28789153695106506
Test set avg_accuracy=64.95% avg_sensitivity=61.85%, avg_specificity=66.10% avg_auc=70.65%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.310175 Test loss=0.611204 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2834775149822235
[5/24] Train loss=0.3150984048843384
[10/24] Train loss=0.30382096767425537
[15/24] Train loss=0.3063395917415619
[20/24] Train loss=0.28337785601615906
Test set avg_accuracy=66.63% avg_sensitivity=53.89%, avg_specificity=71.37% avg_auc=70.53%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.301927 Test loss=0.585334 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.27479639649391174
[5/24] Train loss=0.301456481218338
[10/24] Train loss=0.2970474064350128
[15/24] Train loss=0.31103742122650146
[20/24] Train loss=0.2891189157962799
Test set avg_accuracy=64.14% avg_sensitivity=63.77%, avg_specificity=64.28% avg_auc=71.85%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.301642 Test loss=0.602662 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.29245513677597046
[5/24] Train loss=0.31164586544036865
[10/24] Train loss=0.29562056064605713
[15/24] Train loss=0.3067529797554016
[20/24] Train loss=0.27824196219444275
Test set avg_accuracy=69.15% avg_sensitivity=56.77%, avg_specificity=73.77% avg_auc=73.30%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.309111 Test loss=0.568923 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2892529368400574
[5/24] Train loss=0.3000892102718353
[10/24] Train loss=0.3106248676776886
[15/24] Train loss=0.3194260895252228
[20/24] Train loss=0.2957231104373932
Test set avg_accuracy=72.30% avg_sensitivity=33.88%, avg_specificity=86.62% avg_auc=69.74%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.311563 Test loss=0.562901 Current lr=[0.000276307469034998]

[0/24] Train loss=0.29374411702156067
[5/24] Train loss=0.3152675926685333
[10/24] Train loss=0.3061369061470032
[15/24] Train loss=0.3078678846359253
[20/24] Train loss=0.31486937403678894
Test set avg_accuracy=77.24% avg_sensitivity=17.61%, avg_specificity=99.45% avg_auc=82.24%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.309735 Test loss=0.464892 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3012983500957489
[5/24] Train loss=0.30419689416885376
[10/24] Train loss=0.2909439206123352
[15/24] Train loss=0.3168178200721741
[20/24] Train loss=0.2853913903236389
Test set avg_accuracy=66.41% avg_sensitivity=54.32%, avg_specificity=70.91% avg_auc=70.43%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.304149 Test loss=0.598783 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2835198938846588
[5/24] Train loss=0.3007815182209015
[10/24] Train loss=0.2979770302772522
[15/24] Train loss=0.2992018163204193
[20/24] Train loss=0.29564329981803894
Test set avg_accuracy=80.61% avg_sensitivity=71.02%, avg_specificity=84.19% avg_auc=85.23%
Best model saved!! Metric=-4.95347168320005!!
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.297604 Test loss=0.461207 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.27500206232070923
[5/24] Train loss=0.3142431080341339
[10/24] Train loss=0.28667986392974854
[15/24] Train loss=0.2916501760482788
[20/24] Train loss=0.27651509642601013
Test set avg_accuracy=67.53% avg_sensitivity=74.71%, avg_specificity=64.85% avg_auc=76.89%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.301135 Test loss=0.572374 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2827479839324951
[5/24] Train loss=0.3033348619937897
[10/24] Train loss=0.2887643277645111
[15/24] Train loss=0.30201661586761475
[20/24] Train loss=0.28077247738838196
Test set avg_accuracy=72.25% avg_sensitivity=18.28%, avg_specificity=92.35% avg_auc=68.00%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.298642 Test loss=0.544539 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.28585097193717957
[5/24] Train loss=0.2967749536037445
[10/24] Train loss=0.28623950481414795
[15/24] Train loss=0.27939027547836304
[20/24] Train loss=0.2697540521621704
Test set avg_accuracy=67.34% avg_sensitivity=60.08%, avg_specificity=70.05% avg_auc=73.15%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.294225 Test loss=0.564447 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.27123260498046875
[5/24] Train loss=0.29276278614997864
[10/24] Train loss=0.28934675455093384
[15/24] Train loss=0.3056066036224365
[20/24] Train loss=0.2812606692314148
Test set avg_accuracy=69.36% avg_sensitivity=74.71%, avg_specificity=67.37% avg_auc=78.56%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.294349 Test loss=0.546598 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2808917462825775
[5/24] Train loss=0.2884416878223419
[10/24] Train loss=0.28636255860328674
[15/24] Train loss=0.2911820113658905
[20/24] Train loss=0.27428027987480164
Test set avg_accuracy=59.54% avg_sensitivity=81.86%, avg_specificity=51.23% avg_auc=73.35%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.289325 Test loss=0.661999 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2726050913333893
[5/24] Train loss=0.2884634733200073
[10/24] Train loss=0.2833033502101898
[15/24] Train loss=0.28170180320739746
[20/24] Train loss=0.26031434535980225
Test set avg_accuracy=57.11% avg_sensitivity=73.32%, avg_specificity=51.07% avg_auc=68.53%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.288960 Test loss=0.721785 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2563773989677429
[5/24] Train loss=0.28777015209198
[10/24] Train loss=0.3229897618293762
[15/24] Train loss=0.2932935655117035
[20/24] Train loss=0.2827330529689789
Test set avg_accuracy=73.16% avg_sensitivity=39.30%, avg_specificity=85.78% avg_auc=73.00%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.294289 Test loss=0.533079 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2675130367279053
[5/24] Train loss=0.2932250499725342
[10/24] Train loss=0.27753400802612305
[15/24] Train loss=0.2977733910083771
[20/24] Train loss=0.2805047631263733
Test set avg_accuracy=73.27% avg_sensitivity=56.77%, avg_specificity=79.41% avg_auc=75.52%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.295200 Test loss=0.528289 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2895469069480896
[5/24] Train loss=0.2938240170478821
[10/24] Train loss=0.2841491401195526
[15/24] Train loss=0.2842016816139221
[20/24] Train loss=0.2693248987197876
Test set avg_accuracy=60.83% avg_sensitivity=64.64%, avg_specificity=59.42% avg_auc=68.11%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.295149 Test loss=0.624275 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.26355883479118347
[5/24] Train loss=0.28368890285491943
[10/24] Train loss=0.29241862893104553
[15/24] Train loss=0.29746970534324646
[20/24] Train loss=0.2788313627243042
Test set avg_accuracy=71.65% avg_sensitivity=59.26%, avg_specificity=76.27% avg_auc=74.26%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.290353 Test loss=0.556993 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.25913313031196594
[5/24] Train loss=0.2931395173072815
[10/24] Train loss=0.27507051825523376
[15/24] Train loss=0.27431660890579224
[20/24] Train loss=0.2602751851081848
Test set avg_accuracy=61.51% avg_sensitivity=72.46%, avg_specificity=57.43% avg_auc=70.03%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.282236 Test loss=0.659336 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2635044455528259
[5/24] Train loss=0.2816556990146637
[10/24] Train loss=0.28065380454063416
[15/24] Train loss=0.2768135070800781
[20/24] Train loss=0.25998884439468384
Test set avg_accuracy=68.95% avg_sensitivity=74.09%, avg_specificity=67.03% avg_auc=78.60%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.285508 Test loss=0.552801 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.27411314845085144
[5/24] Train loss=0.2894827127456665
[10/24] Train loss=0.29318442940711975
[15/24] Train loss=0.2795032560825348
[20/24] Train loss=0.25517648458480835
Test set avg_accuracy=59.64% avg_sensitivity=68.57%, avg_specificity=56.31% avg_auc=67.90%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.285626 Test loss=0.701517 Current lr=[0.000224838296036774]

[0/24] Train loss=0.26163288950920105
[5/24] Train loss=0.29632899165153503
[10/24] Train loss=0.2865259349346161
[15/24] Train loss=0.29696714878082275
[20/24] Train loss=0.26177653670310974
Test set avg_accuracy=68.82% avg_sensitivity=71.02%, avg_specificity=67.99% avg_auc=75.33%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.285365 Test loss=0.578910 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2648710608482361
[5/24] Train loss=0.2910195589065552
[10/24] Train loss=0.27516254782676697
[15/24] Train loss=0.29217588901519775
[20/24] Train loss=0.25362613797187805
Test set avg_accuracy=61.71% avg_sensitivity=65.83%, avg_specificity=60.17% avg_auc=67.96%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.283557 Test loss=0.671900 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2581299841403961
[5/24] Train loss=0.2850082218647003
[10/24] Train loss=0.27081024646759033
[15/24] Train loss=0.2634912431240082
[20/24] Train loss=0.2686787545681
Test set avg_accuracy=71.21% avg_sensitivity=59.74%, avg_specificity=75.48% avg_auc=74.50%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.277383 Test loss=0.561251 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2531437277793884
[5/24] Train loss=0.2798818051815033
[10/24] Train loss=0.2758817672729492
[15/24] Train loss=0.26487356424331665
[20/24] Train loss=0.26936474442481995
Test set avg_accuracy=68.33% avg_sensitivity=71.02%, avg_specificity=67.33% avg_auc=76.66%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.281628 Test loss=0.558340 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.25015848875045776
[5/24] Train loss=0.27122193574905396
[10/24] Train loss=0.27198103070259094
[15/24] Train loss=0.2997397482395172
[20/24] Train loss=0.26297202706336975
Test set avg_accuracy=59.56% avg_sensitivity=73.75%, avg_specificity=54.27% avg_auc=70.01%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.277849 Test loss=0.655202 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2574370205402374
[5/24] Train loss=0.2706264555454254
[10/24] Train loss=0.28086405992507935
[15/24] Train loss=0.2726714611053467
[20/24] Train loss=0.2651854455471039
Test set avg_accuracy=60.21% avg_sensitivity=73.46%, avg_specificity=55.27% avg_auc=70.01%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.275943 Test loss=0.669346 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.25430023670196533
[5/24] Train loss=0.2767675518989563
[10/24] Train loss=0.2821411192417145
[15/24] Train loss=0.27367129921913147
[20/24] Train loss=0.2664109170436859
Test set avg_accuracy=63.27% avg_sensitivity=68.62%, avg_specificity=61.28% avg_auc=71.51%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.277840 Test loss=0.621888 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2656466066837311
[5/24] Train loss=0.2863805592060089
[10/24] Train loss=0.2616890072822571
[15/24] Train loss=0.2966213822364807
[20/24] Train loss=0.2537805438041687
Test set avg_accuracy=70.70% avg_sensitivity=68.91%, avg_specificity=71.37% avg_auc=77.89%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.276226 Test loss=0.537765 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2469109296798706
[5/24] Train loss=0.27204960584640503
[10/24] Train loss=0.26592838764190674
[15/24] Train loss=0.25772571563720703
[20/24] Train loss=0.2506380081176758
Test set avg_accuracy=68.54% avg_sensitivity=71.64%, avg_specificity=67.39% avg_auc=77.01%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.267495 Test loss=0.572192 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2758500874042511
[5/24] Train loss=0.26822689175605774
[10/24] Train loss=0.26863008737564087
[15/24] Train loss=0.26319366693496704
[20/24] Train loss=0.26678913831710815
Test set avg_accuracy=74.08% avg_sensitivity=67.56%, avg_specificity=76.50% avg_auc=80.38%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.272855 Test loss=0.494153 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.24705897271633148
[5/24] Train loss=0.2738277316093445
[10/24] Train loss=0.262813925743103
[15/24] Train loss=0.2510620057582855
[20/24] Train loss=0.259146511554718
Test set avg_accuracy=70.68% avg_sensitivity=67.75%, avg_specificity=71.77% avg_auc=77.57%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.266711 Test loss=0.533260 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.24599435925483704
[5/24] Train loss=0.28162017464637756
[10/24] Train loss=0.2730354368686676
[15/24] Train loss=0.2651914656162262
[20/24] Train loss=0.27265000343322754
Test set avg_accuracy=79.00% avg_sensitivity=78.31%, avg_specificity=79.25% avg_auc=86.50%
Best model saved!! Metric=-2.941861574274782!!
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.278138 Test loss=0.450810 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.27483585476875305
[5/24] Train loss=0.2961764931678772
[10/24] Train loss=0.2641543745994568
[15/24] Train loss=0.28189191222190857
[20/24] Train loss=0.25868964195251465
Test set avg_accuracy=73.66% avg_sensitivity=61.71%, avg_specificity=78.11% avg_auc=79.04%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.283925 Test loss=0.506726 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2545795440673828
[5/24] Train loss=0.2760550081729889
[10/24] Train loss=0.26636895537376404
[15/24] Train loss=0.25399869680404663
[20/24] Train loss=0.23358936607837677
Test set avg_accuracy=71.11% avg_sensitivity=71.88%, avg_specificity=70.82% avg_auc=78.80%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.268648 Test loss=0.545260 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24344852566719055
[5/24] Train loss=0.25307679176330566
[10/24] Train loss=0.25198107957839966
[15/24] Train loss=0.25075680017471313
[20/24] Train loss=0.23291614651679993
Test set avg_accuracy=60.74% avg_sensitivity=74.86%, avg_specificity=55.49% avg_auc=71.98%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.258793 Test loss=0.706354 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.23338158428668976
[5/24] Train loss=0.2636670470237732
[10/24] Train loss=0.25007355213165283
[15/24] Train loss=0.24715907871723175
[20/24] Train loss=0.23383364081382751
Test set avg_accuracy=64.28% avg_sensitivity=76.25%, avg_specificity=59.83% avg_auc=76.30%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.254031 Test loss=0.647022 Current lr=[0.000156543481933168]

[0/24] Train loss=0.22916550934314728
[5/24] Train loss=0.24989861249923706
[10/24] Train loss=0.2551864683628082
[15/24] Train loss=0.2451918125152588
[20/24] Train loss=0.2325761318206787
Test set avg_accuracy=64.84% avg_sensitivity=76.06%, avg_specificity=60.67% avg_auc=75.25%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.252214 Test loss=0.631263 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.22967401146888733
[5/24] Train loss=0.25598812103271484
[10/24] Train loss=0.24160660803318024
[15/24] Train loss=0.24702537059783936
[20/24] Train loss=0.22956813871860504
Test set avg_accuracy=65.17% avg_sensitivity=77.06%, avg_specificity=60.74% avg_auc=76.94%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.250866 Test loss=0.635422 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.23445333540439606
[5/24] Train loss=0.25712695717811584
[10/24] Train loss=0.24864834547042847
[15/24] Train loss=0.23707635700702667
[20/24] Train loss=0.23434270918369293
Test set avg_accuracy=67.15% avg_sensitivity=75.10%, avg_specificity=64.19% avg_auc=75.82%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.248573 Test loss=0.617250 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.22083070874214172
[5/24] Train loss=0.2531956434249878
[10/24] Train loss=0.24438472092151642
[15/24] Train loss=0.2363698035478592
[20/24] Train loss=0.22644174098968506
Test set avg_accuracy=66.63% avg_sensitivity=79.27%, avg_specificity=61.92% avg_auc=79.37%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.244541 Test loss=0.606390 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22582416236400604
[5/24] Train loss=0.250418484210968
[10/24] Train loss=0.24334129691123962
[15/24] Train loss=0.23631735146045685
[20/24] Train loss=0.22661177814006805
Test set avg_accuracy=68.28% avg_sensitivity=78.31%, avg_specificity=64.55% avg_auc=79.56%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.243215 Test loss=0.596461 Current lr=[0.000134135431043539]

[0/24] Train loss=0.22864185273647308
[5/24] Train loss=0.24995014071464539
[10/24] Train loss=0.2417883425951004
[15/24] Train loss=0.2312619835138321
[20/24] Train loss=0.23057566583156586
Test set avg_accuracy=68.93% avg_sensitivity=67.47%, avg_specificity=69.48% avg_auc=76.45%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.242305 Test loss=0.567735 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.23023205995559692
[5/24] Train loss=0.24869689345359802
[10/24] Train loss=0.24183565378189087
[15/24] Train loss=0.24148805439472198
[20/24] Train loss=0.22862693667411804
Test set avg_accuracy=62.93% avg_sensitivity=74.86%, avg_specificity=58.49% avg_auc=73.31%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.249456 Test loss=0.683637 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22509180009365082
[5/24] Train loss=0.2506660521030426
[10/24] Train loss=0.23446443676948547
[15/24] Train loss=0.23416279256343842
[20/24] Train loss=0.22344425320625305
Test set avg_accuracy=63.23% avg_sensitivity=73.42%, avg_specificity=59.44% avg_auc=72.66%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.246201 Test loss=0.686125 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.22611674666404724
[5/24] Train loss=0.250590443611145
[10/24] Train loss=0.2350090593099594
[15/24] Train loss=0.23041555285453796
[20/24] Train loss=0.22649958729743958
Test set avg_accuracy=67.92% avg_sensitivity=78.84%, avg_specificity=63.85% avg_auc=79.10%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.244437 Test loss=0.585951 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2244216352701187
[5/24] Train loss=0.24952705204486847
[10/24] Train loss=0.2311302274465561
[15/24] Train loss=0.2314695417881012
[20/24] Train loss=0.21739302575588226
Test set avg_accuracy=70.36% avg_sensitivity=65.79%, avg_specificity=72.07% avg_auc=77.28%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.243226 Test loss=0.553758 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2423848658800125
[5/24] Train loss=0.27063509821891785
[10/24] Train loss=0.25329822301864624
[15/24] Train loss=0.23260445892810822
[20/24] Train loss=0.21947623789310455
Test set avg_accuracy=62.75% avg_sensitivity=77.64%, avg_specificity=57.20% avg_auc=73.03%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.246411 Test loss=0.667159 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.22136953473091125
[5/24] Train loss=0.25170862674713135
[10/24] Train loss=0.2520626187324524
[15/24] Train loss=0.23443709313869476
[20/24] Train loss=0.22037144005298615
Test set avg_accuracy=61.00% avg_sensitivity=72.98%, avg_specificity=56.54% avg_auc=69.68%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.241047 Test loss=0.696971 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.22733193635940552
[5/24] Train loss=0.24927981197834015
[10/24] Train loss=0.24644505977630615
[15/24] Train loss=0.2359357476234436
[20/24] Train loss=0.2113470435142517
Test set avg_accuracy=64.90% avg_sensitivity=80.57%, avg_specificity=59.06% avg_auc=78.35%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.239179 Test loss=0.633201 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.21896947920322418
[5/24] Train loss=0.2400711178779602
[10/24] Train loss=0.2347228080034256
[15/24] Train loss=0.23341573774814606
[20/24] Train loss=0.21422843635082245
Test set avg_accuracy=67.96% avg_sensitivity=74.95%, avg_specificity=65.35% avg_auc=77.97%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.235030 Test loss=0.583473 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.21227380633354187
[5/24] Train loss=0.23589777946472168
[10/24] Train loss=0.22129684686660767
[15/24] Train loss=0.2280714511871338
[20/24] Train loss=0.21047592163085938
Test set avg_accuracy=67.43% avg_sensitivity=67.37%, avg_specificity=67.46% avg_auc=74.10%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.231329 Test loss=0.609963 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.21106374263763428
[5/24] Train loss=0.24091802537441254
[10/24] Train loss=0.22511622309684753
[15/24] Train loss=0.22870615124702454
[20/24] Train loss=0.20359376072883606
Test set avg_accuracy=67.73% avg_sensitivity=62.96%, avg_specificity=69.51% avg_auc=73.48%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.229509 Test loss=0.604385 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.21519514918327332
[5/24] Train loss=0.24188442528247833
[10/24] Train loss=0.22728967666625977
[15/24] Train loss=0.21927323937416077
[20/24] Train loss=0.21418361365795135
Test set avg_accuracy=68.11% avg_sensitivity=62.96%, avg_specificity=70.03% avg_auc=73.80%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.228048 Test loss=0.580354 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.20732365548610687
[5/24] Train loss=0.24185213446617126
[10/24] Train loss=0.22873543202877045
[15/24] Train loss=0.22546164691448212
[20/24] Train loss=0.20702122151851654
Test set avg_accuracy=68.28% avg_sensitivity=55.23%, avg_specificity=73.14% avg_auc=72.09%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.230103 Test loss=0.566819 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.21058058738708496
[5/24] Train loss=0.23342934250831604
[10/24] Train loss=0.23520690202713013
[15/24] Train loss=0.21544888615608215
[20/24] Train loss=0.2057652324438095
Test set avg_accuracy=66.67% avg_sensitivity=69.82%, avg_specificity=65.49% avg_auc=73.40%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.228762 Test loss=0.617360 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.21313732862472534
[5/24] Train loss=0.23297150433063507
[10/24] Train loss=0.2238202542066574
[15/24] Train loss=0.214303657412529
[20/24] Train loss=0.20926004648208618
Test set avg_accuracy=63.66% avg_sensitivity=73.94%, avg_specificity=59.83% avg_auc=72.78%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.226742 Test loss=0.672291 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.21731294691562653
[5/24] Train loss=0.2399132400751114
[10/24] Train loss=0.21813423931598663
[15/24] Train loss=0.2156457006931305
[20/24] Train loss=0.20737580955028534
Test set avg_accuracy=68.68% avg_sensitivity=73.08%, avg_specificity=67.05% avg_auc=76.60%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.226604 Test loss=0.588247 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.21196918189525604
[5/24] Train loss=0.2373116910457611
[10/24] Train loss=0.22352935373783112
[15/24] Train loss=0.21839632093906403
[20/24] Train loss=0.20533856749534607
Test set avg_accuracy=63.50% avg_sensitivity=65.69%, avg_specificity=62.69% avg_auc=70.50%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.226105 Test loss=0.686052 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.21119792759418488
[5/24] Train loss=0.2263486385345459
[10/24] Train loss=0.22275446355342865
[15/24] Train loss=0.21578161418437958
[20/24] Train loss=0.20265237987041473
Test set avg_accuracy=60.87% avg_sensitivity=76.58%, avg_specificity=55.02% avg_auc=71.30%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.223372 Test loss=0.703959 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.20882833003997803
[5/24] Train loss=0.22761207818984985
[10/24] Train loss=0.2151266634464264
[15/24] Train loss=0.219014510512352
[20/24] Train loss=0.20025062561035156
Test set avg_accuracy=64.48% avg_sensitivity=73.46%, avg_specificity=61.13% avg_auc=74.83%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.224802 Test loss=0.646523 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.21138465404510498
[5/24] Train loss=0.2483995258808136
[10/24] Train loss=0.21747641265392303
[15/24] Train loss=0.21928541362285614
[20/24] Train loss=0.20190857350826263
Test set avg_accuracy=67.34% avg_sensitivity=64.73%, avg_specificity=68.32% avg_auc=74.77%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.226548 Test loss=0.587000 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.20711572468280792
[5/24] Train loss=0.23248018324375153
[10/24] Train loss=0.2174319326877594
[15/24] Train loss=0.21844172477722168
[20/24] Train loss=0.1983461230993271
Test set avg_accuracy=66.51% avg_sensitivity=76.25%, avg_specificity=62.88% avg_auc=76.54%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.224904 Test loss=0.623967 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.21171437203884125
[5/24] Train loss=0.23099948465824127
[10/24] Train loss=0.21346059441566467
[15/24] Train loss=0.20681068301200867
[20/24] Train loss=0.19386541843414307
Test set avg_accuracy=65.76% avg_sensitivity=76.54%, avg_specificity=61.74% avg_auc=76.72%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.218123 Test loss=0.634461 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.20195409655570984
[5/24] Train loss=0.230431467294693
[10/24] Train loss=0.20251595973968506
[15/24] Train loss=0.2012767791748047
[20/24] Train loss=0.1921030580997467
Test set avg_accuracy=68.19% avg_sensitivity=72.79%, avg_specificity=66.48% avg_auc=76.12%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.213300 Test loss=0.612975 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.19861510396003723
[5/24] Train loss=0.22321739792823792
[10/24] Train loss=0.20116561651229858
[15/24] Train loss=0.20203830301761627
[20/24] Train loss=0.1885259747505188
Test set avg_accuracy=69.40% avg_sensitivity=73.46%, avg_specificity=67.89% avg_auc=77.98%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.209909 Test loss=0.580290 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.19437775015830994
[5/24] Train loss=0.21879629790782928
[10/24] Train loss=0.2054743766784668
[15/24] Train loss=0.19976109266281128
[20/24] Train loss=0.1875920444726944
Test set avg_accuracy=65.12% avg_sensitivity=74.52%, avg_specificity=61.62% avg_auc=74.81%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.210136 Test loss=0.649548 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.19463010132312775
[5/24] Train loss=0.22015871107578278
[10/24] Train loss=0.2130189687013626
[15/24] Train loss=0.20224884152412415
[20/24] Train loss=0.19039753079414368
Test set avg_accuracy=63.61% avg_sensitivity=74.47%, avg_specificity=59.56% avg_auc=73.34%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.209050 Test loss=0.688384 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1924060434103012
[5/24] Train loss=0.21101224422454834
[10/24] Train loss=0.20338669419288635
[15/24] Train loss=0.2002284824848175
[20/24] Train loss=0.18804730474948883
Test set avg_accuracy=64.05% avg_sensitivity=75.24%, avg_specificity=59.88% avg_auc=73.58%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.206807 Test loss=0.674933 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.19292323291301727
[5/24] Train loss=0.20840084552764893
[10/24] Train loss=0.19793647527694702
[15/24] Train loss=0.1936722993850708
[20/24] Train loss=0.18661677837371826
Test set avg_accuracy=66.45% avg_sensitivity=74.04%, avg_specificity=63.62% avg_auc=75.40%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.205459 Test loss=0.635426 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18868517875671387
[5/24] Train loss=0.2074073851108551
[10/24] Train loss=0.20506930351257324
[15/24] Train loss=0.19537004828453064
[20/24] Train loss=0.18409694731235504
Test set avg_accuracy=67.50% avg_sensitivity=74.09%, avg_specificity=65.05% avg_auc=76.29%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.204402 Test loss=0.623733 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.19353462755680084
[5/24] Train loss=0.20328646898269653
[10/24] Train loss=0.19698815047740936
[15/24] Train loss=0.1937970221042633
[20/24] Train loss=0.1840950846672058
Test set avg_accuracy=65.81% avg_sensitivity=75.43%, avg_specificity=62.22% avg_auc=75.20%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.202579 Test loss=0.647060 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.19383913278579712
[5/24] Train loss=0.2066725194454193
[10/24] Train loss=0.20003992319107056
[15/24] Train loss=0.2024655044078827
[20/24] Train loss=0.1846926361322403
Test set avg_accuracy=66.50% avg_sensitivity=74.04%, avg_specificity=63.69% avg_auc=75.82%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.202656 Test loss=0.635129 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1908026784658432
[5/24] Train loss=0.20480863749980927
[10/24] Train loss=0.19397936761379242
[15/24] Train loss=0.19264164566993713
[20/24] Train loss=0.18030323088169098
Test set avg_accuracy=64.51% avg_sensitivity=75.14%, avg_specificity=60.54% avg_auc=74.17%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.201151 Test loss=0.673551 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1848219633102417
[5/24] Train loss=0.20951876044273376
[10/24] Train loss=0.19762367010116577
[15/24] Train loss=0.19624176621437073
[20/24] Train loss=0.18044376373291016
Test set avg_accuracy=65.95% avg_sensitivity=74.62%, avg_specificity=62.72% avg_auc=75.41%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.200256 Test loss=0.652848 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1866472363471985
[5/24] Train loss=0.20244084298610687
[10/24] Train loss=0.19667868316173553
[15/24] Train loss=0.19269895553588867
[20/24] Train loss=0.18161052465438843
Test set avg_accuracy=65.21% avg_sensitivity=74.47%, avg_specificity=61.76% avg_auc=74.44%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.198609 Test loss=0.662090 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.18433746695518494
[5/24] Train loss=0.19900120794773102
[10/24] Train loss=0.19452215731143951
[15/24] Train loss=0.19620762765407562
[20/24] Train loss=0.17798563838005066
Test set avg_accuracy=64.93% avg_sensitivity=74.18%, avg_specificity=61.49% avg_auc=74.11%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.198148 Test loss=0.669327 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.18856190145015717
[5/24] Train loss=0.20309528708457947
[10/24] Train loss=0.19250072538852692
[15/24] Train loss=0.18725259602069855
[20/24] Train loss=0.1789623498916626
Test set avg_accuracy=64.96% avg_sensitivity=74.14%, avg_specificity=61.54% avg_auc=74.22%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.197275 Test loss=0.676349 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.18624429404735565
[5/24] Train loss=0.19964537024497986
[10/24] Train loss=0.19397754967212677
[15/24] Train loss=0.1894325613975525
[20/24] Train loss=0.17926658689975739
Test set avg_accuracy=65.85% avg_sensitivity=73.70%, avg_specificity=62.92% avg_auc=74.55%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.198041 Test loss=0.663589 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.18674106895923615
[5/24] Train loss=0.20122389495372772
[10/24] Train loss=0.19112388789653778
[15/24] Train loss=0.19046679139137268
[20/24] Train loss=0.17630164325237274
Test set avg_accuracy=65.36% avg_sensitivity=72.74%, avg_specificity=62.62% avg_auc=73.80%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.195896 Test loss=0.672794 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.18486982583999634
[5/24] Train loss=0.19926817715168
[10/24] Train loss=0.1934550255537033
[15/24] Train loss=0.1908157467842102
[20/24] Train loss=0.17878291010856628
Test set avg_accuracy=66.04% avg_sensitivity=73.37%, avg_specificity=63.31% avg_auc=75.14%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.196994 Test loss=0.650915 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.18503466248512268
[5/24] Train loss=0.20257574319839478
[10/24] Train loss=0.19296036660671234
[15/24] Train loss=0.18929652869701385
[20/24] Train loss=0.18030306696891785
Test set avg_accuracy=65.39% avg_sensitivity=73.66%, avg_specificity=62.31% avg_auc=74.41%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.196120 Test loss=0.669021 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.18567734956741333
[5/24] Train loss=0.20558036863803864
[10/24] Train loss=0.19255085289478302
[15/24] Train loss=0.18973268568515778
[20/24] Train loss=0.1804060935974121
Test set avg_accuracy=65.66% avg_sensitivity=73.37%, avg_specificity=62.79% avg_auc=74.59%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.196634 Test loss=0.664383 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.18501298129558563
[5/24] Train loss=0.2007654905319214
[10/24] Train loss=0.1909775286912918
[15/24] Train loss=0.18534277379512787
[20/24] Train loss=0.17887967824935913
Test set avg_accuracy=65.29% avg_sensitivity=73.03%, avg_specificity=62.40% avg_auc=74.10%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.195603 Test loss=0.673991 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.18077073991298676
[5/24] Train loss=0.20396898686885834
[10/24] Train loss=0.1962614208459854
[15/24] Train loss=0.19231155514717102
[20/24] Train loss=0.17683818936347961
Test set avg_accuracy=65.81% avg_sensitivity=73.51%, avg_specificity=62.94% avg_auc=74.65%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.195976 Test loss=0.663646 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1796947866678238
[5/24] Train loss=0.19997525215148926
[10/24] Train loss=0.1933862566947937
[15/24] Train loss=0.18968068063259125
[20/24] Train loss=0.1794140338897705
Test set avg_accuracy=65.65% avg_sensitivity=73.85%, avg_specificity=62.60% avg_auc=74.76%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.196064 Test loss=0.664254 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1835700124502182
[5/24] Train loss=0.2005733847618103
[10/24] Train loss=0.19483192265033722
[15/24] Train loss=0.18827471137046814
[20/24] Train loss=0.17332816123962402
Test set avg_accuracy=65.12% avg_sensitivity=73.85%, avg_specificity=61.87% avg_auc=73.93%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.195673 Test loss=0.682479 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.18367326259613037
[5/24] Train loss=0.20015284419059753
[10/24] Train loss=0.19205458462238312
[15/24] Train loss=0.18782034516334534
[20/24] Train loss=0.18140888214111328
Test set avg_accuracy=65.31% avg_sensitivity=73.70%, avg_specificity=62.19% avg_auc=74.43%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.195833 Test loss=0.672252 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1813088357448578
[5/24] Train loss=0.19769132137298584
[10/24] Train loss=0.18941621482372284
[15/24] Train loss=0.18828141689300537
[20/24] Train loss=0.17498362064361572
Test set avg_accuracy=65.56% avg_sensitivity=73.75%, avg_specificity=62.51% avg_auc=74.56%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.195067 Test loss=0.667976 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.18665696680545807
[5/24] Train loss=0.20152150094509125
[10/24] Train loss=0.19180859625339508
[15/24] Train loss=0.1851738691329956
[20/24] Train loss=0.17893405258655548
Test set avg_accuracy=65.36% avg_sensitivity=73.56%, avg_specificity=62.31% avg_auc=74.39%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.196055 Test loss=0.671297 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.18382520973682404
[5/24] Train loss=0.19714155793190002
[10/24] Train loss=0.18694941699504852
[15/24] Train loss=0.1927718222141266
[20/24] Train loss=0.17756396532058716
Test set avg_accuracy=65.16% avg_sensitivity=73.70%, avg_specificity=61.97% avg_auc=74.21%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.195392 Test loss=0.676609 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=79.00% sen=78.31%, spe=79.25%, auc=86.50%!
Fold[6] Avg_overlap=0.63%(±0.25526397972356857)
[0/24] Train loss=0.736524760723114
[5/24] Train loss=0.7245433330535889
[10/24] Train loss=0.720436155796051
[15/24] Train loss=0.7239505648612976
[20/24] Train loss=0.7198384404182434
Test set avg_accuracy=54.91% avg_sensitivity=38.90%, avg_specificity=61.02% avg_auc=49.97%
Best model saved!! Metric=-121.2110417948669!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=0.727167 Test loss=0.705618 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.7308578491210938
[5/24] Train loss=0.7223750352859497
[10/24] Train loss=0.7156583666801453
[15/24] Train loss=0.7167136073112488
[20/24] Train loss=0.7097598314285278
Test set avg_accuracy=57.04% avg_sensitivity=35.64%, avg_specificity=65.21% avg_auc=50.67%
Best model saved!! Metric=-117.43569280561788!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.718528 Test loss=0.693729 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7242111563682556
[5/24] Train loss=0.7069433331489563
[10/24] Train loss=0.7095812559127808
[15/24] Train loss=0.7046237587928772
[20/24] Train loss=0.7041603326797485
Test set avg_accuracy=62.34% avg_sensitivity=25.93%, avg_specificity=76.24% avg_auc=51.13%
Best model saved!! Metric=-110.35429155652633!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.711029 Test loss=0.685087 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7086485624313354
[5/24] Train loss=0.6970173120498657
[10/24] Train loss=0.7004673480987549
[15/24] Train loss=0.6986318230628967
[20/24] Train loss=0.6905391812324524
Test set avg_accuracy=62.54% avg_sensitivity=26.36%, avg_specificity=76.34% avg_auc=51.27%
Best model saved!! Metric=-109.49544419637158!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.701064 Test loss=0.680908 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6930946707725525
[5/24] Train loss=0.6971097588539124
[10/24] Train loss=0.6863834857940674
[15/24] Train loss=0.6838549375534058
[20/24] Train loss=0.681186854839325
Test set avg_accuracy=62.68% avg_sensitivity=25.74%, avg_specificity=76.78% avg_auc=51.71%
Best model saved!! Metric=-109.08511754669318!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.691951 Test loss=0.675949 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.685034453868866
[5/24] Train loss=0.6731922626495361
[10/24] Train loss=0.6834391355514526
[15/24] Train loss=0.6776581406593323
[20/24] Train loss=0.6667892932891846
Test set avg_accuracy=62.59% avg_sensitivity=26.83%, avg_specificity=76.24% avg_auc=52.01%
Best model saved!! Metric=-108.33839954584417!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.680820 Test loss=0.674749 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6735288500785828
[5/24] Train loss=0.6660626530647278
[10/24] Train loss=0.681509792804718
[15/24] Train loss=0.6652805805206299
[20/24] Train loss=0.6588521599769592
Test set avg_accuracy=62.70% avg_sensitivity=26.97%, avg_specificity=76.33% avg_auc=52.85%
Best model saved!! Metric=-107.16008838200479!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.670027 Test loss=0.671616 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6543753743171692
[5/24] Train loss=0.6519561409950256
[10/24] Train loss=0.6567405462265015
[15/24] Train loss=0.6532647609710693
[20/24] Train loss=0.6415466666221619
Test set avg_accuracy=62.89% avg_sensitivity=26.73%, avg_specificity=76.69% avg_auc=54.17%
Best model saved!! Metric=-105.51994324825185!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.658926 Test loss=0.664048 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6475644707679749
[5/24] Train loss=0.6418773531913757
[10/24] Train loss=0.6479551792144775
[15/24] Train loss=0.6364932060241699
[20/24] Train loss=0.63498854637146
Test set avg_accuracy=60.66% avg_sensitivity=33.00%, avg_specificity=71.22% avg_auc=54.91%
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.645053 Test loss=0.651482 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6399210095405579
[5/24] Train loss=0.6178624033927917
[10/24] Train loss=0.6376489996910095
[15/24] Train loss=0.6205695867538452
[20/24] Train loss=0.6221329569816589
Test set avg_accuracy=66.13% avg_sensitivity=23.57%, avg_specificity=82.37% avg_auc=56.42%
Best model saved!! Metric=-97.49858729096977!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.630519 Test loss=0.636013 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6135574579238892
[5/24] Train loss=0.6077427268028259
[10/24] Train loss=0.6156194806098938
[15/24] Train loss=0.6030672788619995
[20/24] Train loss=0.6009438633918762
Test set avg_accuracy=66.29% avg_sensitivity=24.56%, avg_specificity=82.21% avg_auc=57.38%
Best model saved!! Metric=-95.55716262825642!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.615443 Test loss=0.614649 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6053720116615295
[5/24] Train loss=0.5987908244132996
[10/24] Train loss=0.6007499098777771
[15/24] Train loss=0.5846108794212341
[20/24] Train loss=0.5714746117591858
Test set avg_accuracy=69.41% avg_sensitivity=19.28%, avg_specificity=88.54% avg_auc=60.05%
Best model saved!! Metric=-88.7154726337616!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.596757 Test loss=0.594571 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.590582549571991
[5/24] Train loss=0.5723744034767151
[10/24] Train loss=0.5766547322273254
[15/24] Train loss=0.5648941993713379
[20/24] Train loss=0.5418962836265564
Test set avg_accuracy=72.37% avg_sensitivity=15.32%, avg_specificity=94.14% avg_auc=63.51%
Best model saved!! Metric=-80.66093160456572!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.574188 Test loss=0.573327 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5536880493164062
[5/24] Train loss=0.5472598075866699
[10/24] Train loss=0.5402682423591614
[15/24] Train loss=0.5309399962425232
[20/24] Train loss=0.5168350338935852
Test set avg_accuracy=72.73% avg_sensitivity=18.34%, avg_specificity=93.49% avg_auc=67.21%
Best model saved!! Metric=-74.22512940005839!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.549240 Test loss=0.571595 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5138360261917114
[5/24] Train loss=0.525312066078186
[10/24] Train loss=0.516723096370697
[15/24] Train loss=0.4990628957748413
[20/24] Train loss=0.4835987985134125
Test set avg_accuracy=73.75% avg_sensitivity=26.59%, avg_specificity=91.74% avg_auc=72.98%
Best model saved!! Metric=-60.93791759293114!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.522143 Test loss=0.528142 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.49373894929885864
[5/24] Train loss=0.5095012784004211
[10/24] Train loss=0.4906836450099945
[15/24] Train loss=0.4914631247520447
[20/24] Train loss=0.46463194489479065
Test set avg_accuracy=74.64% avg_sensitivity=26.69%, avg_specificity=92.93% avg_auc=74.69%
Best model saved!! Metric=-57.060071932382115!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.501861 Test loss=0.523409 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.47859248518943787
[5/24] Train loss=0.48607346415519714
[10/24] Train loss=0.47574344277381897
[15/24] Train loss=0.4574621021747589
[20/24] Train loss=0.43483224511146545
Test set avg_accuracy=76.55% avg_sensitivity=38.00%, avg_specificity=91.26% avg_auc=76.36%
Best model saved!! Metric=-43.83678352868004!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.478424 Test loss=0.499140 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.468625545501709
[5/24] Train loss=0.46718698740005493
[10/24] Train loss=0.45689451694488525
[15/24] Train loss=0.44315415620803833
[20/24] Train loss=0.41286590695381165
Test set avg_accuracy=70.42% avg_sensitivity=68.22%, avg_specificity=71.25% avg_auc=75.21%
Best model saved!! Metric=-40.89284454811991!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.458604 Test loss=0.595658 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4401150941848755
[5/24] Train loss=0.43027275800704956
[10/24] Train loss=0.44425296783447266
[15/24] Train loss=0.4356217384338379
[20/24] Train loss=0.4022409915924072
Test set avg_accuracy=60.25% avg_sensitivity=63.51%, avg_specificity=59.00% avg_auc=66.63%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.444439 Test loss=0.652828 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.4302801489830017
[5/24] Train loss=0.4261413812637329
[10/24] Train loss=0.4293290972709656
[15/24] Train loss=0.43482717871665955
[20/24] Train loss=0.39533230662345886
Test set avg_accuracy=71.41% avg_sensitivity=62.85%, avg_specificity=74.67% avg_auc=76.34%
Best model saved!! Metric=-40.73100261200857!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.433140 Test loss=0.556405 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4203384518623352
[5/24] Train loss=0.41368404030799866
[10/24] Train loss=0.4264753460884094
[15/24] Train loss=0.424974262714386
[20/24] Train loss=0.3948880732059479
Test set avg_accuracy=60.83% avg_sensitivity=63.22%, avg_specificity=59.92% avg_auc=67.26%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.426545 Test loss=0.639592 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.41472920775413513
[5/24] Train loss=0.4044005870819092
[10/24] Train loss=0.4299074411392212
[15/24] Train loss=0.4234152138233185
[20/24] Train loss=0.38762354850769043
Test set avg_accuracy=51.77% avg_sensitivity=60.73%, avg_specificity=48.35% avg_auc=56.93%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.421783 Test loss=0.712537 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.4081120193004608
[5/24] Train loss=0.39012962579727173
[10/24] Train loss=0.41743355989456177
[15/24] Train loss=0.4165304899215698
[20/24] Train loss=0.3873281478881836
Test set avg_accuracy=67.08% avg_sensitivity=65.54%, avg_specificity=67.67% avg_auc=72.25%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.413742 Test loss=0.611090 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.4153343439102173
[5/24] Train loss=0.40567171573638916
[10/24] Train loss=0.4154012203216553
[15/24] Train loss=0.4129468500614166
[20/24] Train loss=0.36498719453811646
Test set avg_accuracy=57.47% avg_sensitivity=62.89%, avg_specificity=55.41% avg_auc=63.35%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.408314 Test loss=0.666512 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.3929193913936615
[5/24] Train loss=0.3961739242076874
[10/24] Train loss=0.41234925389289856
[15/24] Train loss=0.41154322028160095
[20/24] Train loss=0.35917478799819946
Test set avg_accuracy=57.08% avg_sensitivity=54.88%, avg_specificity=57.92% avg_auc=60.00%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.405968 Test loss=0.682646 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.38515034317970276
[5/24] Train loss=0.38534295558929443
[10/24] Train loss=0.4127916991710663
[15/24] Train loss=0.4027218818664551
[20/24] Train loss=0.3553568124771118
Test set avg_accuracy=55.16% avg_sensitivity=56.15%, avg_specificity=54.78% avg_auc=58.69%
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.401697 Test loss=0.693752 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.38224121928215027
[5/24] Train loss=0.37872228026390076
[10/24] Train loss=0.40441104769706726
[15/24] Train loss=0.4025706946849823
[20/24] Train loss=0.35871055722236633
Test set avg_accuracy=65.82% avg_sensitivity=59.59%, avg_specificity=68.20% avg_auc=70.93%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.400578 Test loss=0.602517 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.39181673526763916
[5/24] Train loss=0.37264859676361084
[10/24] Train loss=0.39617621898651123
[15/24] Train loss=0.4012499749660492
[20/24] Train loss=0.3628958463668823
Test set avg_accuracy=54.56% avg_sensitivity=57.57%, avg_specificity=53.41% avg_auc=58.66%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.394453 Test loss=0.718928 Current lr=[0.000210185142098938]

[0/24] Train loss=0.378025621175766
[5/24] Train loss=0.3788876533508301
[10/24] Train loss=0.4007885456085205
[15/24] Train loss=0.39490658044815063
[20/24] Train loss=0.34680089354515076
Test set avg_accuracy=66.94% avg_sensitivity=52.81%, avg_specificity=72.33% avg_auc=67.06%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.390684 Test loss=0.623811 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.37979477643966675
[5/24] Train loss=0.36034542322158813
[10/24] Train loss=0.38598495721817017
[15/24] Train loss=0.3965332806110382
[20/24] Train loss=0.3457854688167572
Test set avg_accuracy=60.78% avg_sensitivity=58.70%, avg_specificity=61.58% avg_auc=65.77%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.385678 Test loss=0.638191 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.3932304084300995
[5/24] Train loss=0.36646127700805664
[10/24] Train loss=0.39510220289230347
[15/24] Train loss=0.3809906542301178
[20/24] Train loss=0.3251160979270935
Test set avg_accuracy=51.21% avg_sensitivity=61.72%, avg_specificity=47.20% avg_auc=55.66%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.381215 Test loss=0.704756 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.36548349261283875
[5/24] Train loss=0.3652966022491455
[10/24] Train loss=0.3840525150299072
[15/24] Train loss=0.36793503165245056
[20/24] Train loss=0.3280835449695587
Test set avg_accuracy=52.93% avg_sensitivity=62.71%, avg_specificity=49.20% avg_auc=59.68%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.381289 Test loss=0.696899 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3660960793495178
[5/24] Train loss=0.3526206910610199
[10/24] Train loss=0.3765299618244171
[15/24] Train loss=0.3785010278224945
[20/24] Train loss=0.3295983672142029
Test set avg_accuracy=54.67% avg_sensitivity=58.51%, avg_specificity=53.21% avg_auc=59.99%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.378795 Test loss=0.748808 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35975348949432373
[5/24] Train loss=0.3434458076953888
[10/24] Train loss=0.36726561188697815
[15/24] Train loss=0.37010613083839417
[20/24] Train loss=0.3145431578159332
Test set avg_accuracy=58.63% avg_sensitivity=65.06%, avg_specificity=56.18% avg_auc=65.60%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.367118 Test loss=0.659364 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.3641205132007599
[5/24] Train loss=0.3266841769218445
[10/24] Train loss=0.36306318640708923
[15/24] Train loss=0.35349708795547485
[20/24] Train loss=0.3127641975879669
Test set avg_accuracy=57.59% avg_sensitivity=58.23%, avg_specificity=57.35% avg_auc=62.27%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.364661 Test loss=0.667712 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.35378891229629517
[5/24] Train loss=0.34725815057754517
[10/24] Train loss=0.36197760701179504
[15/24] Train loss=0.3653416931629181
[20/24] Train loss=0.362951397895813
Test set avg_accuracy=71.34% avg_sensitivity=65.91%, avg_specificity=73.41% avg_auc=76.84%
Best model saved!! Metric=-38.49220704940696!!
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.366487 Test loss=0.550358 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.37999898195266724
[5/24] Train loss=0.3606598377227783
[10/24] Train loss=0.35692286491394043
[15/24] Train loss=0.35607174038887024
[20/24] Train loss=0.3105742335319519
Test set avg_accuracy=75.66% avg_sensitivity=65.91%, avg_specificity=79.38% avg_auc=78.57%
Best model saved!! Metric=-26.466043764808873!!
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.366863 Test loss=0.563475 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.369179904460907
[5/24] Train loss=0.3413352370262146
[10/24] Train loss=0.36601194739341736
[15/24] Train loss=0.36013561487197876
[20/24] Train loss=0.319363534450531
Test set avg_accuracy=52.83% avg_sensitivity=67.70%, avg_specificity=47.15% avg_auc=58.80%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.361729 Test loss=0.694903 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3472409248352051
[5/24] Train loss=0.3289034068584442
[10/24] Train loss=0.37672004103660583
[15/24] Train loss=0.3537057936191559
[20/24] Train loss=0.33088231086730957
Test set avg_accuracy=49.14% avg_sensitivity=68.18%, avg_specificity=41.88% avg_auc=57.27%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.360085 Test loss=0.864706 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.36213675141334534
[5/24] Train loss=0.32389914989471436
[10/24] Train loss=0.35260719060897827
[15/24] Train loss=0.36804094910621643
[20/24] Train loss=0.31247368454933167
Test set avg_accuracy=64.90% avg_sensitivity=64.78%, avg_specificity=64.94% avg_auc=71.87%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.362037 Test loss=0.604941 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.3435496389865875
[5/24] Train loss=0.33522289991378784
[10/24] Train loss=0.3652249872684479
[15/24] Train loss=0.35842618346214294
[20/24] Train loss=0.3125656545162201
Test set avg_accuracy=59.35% avg_sensitivity=68.55%, avg_specificity=55.84% avg_auc=67.64%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.360731 Test loss=0.664261 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.3496631681919098
[5/24] Train loss=0.3347237706184387
[10/24] Train loss=0.34936419129371643
[15/24] Train loss=0.3395187258720398
[20/24] Train loss=0.31119221448898315
Test set avg_accuracy=59.73% avg_sensitivity=67.80%, avg_specificity=56.65% avg_auc=65.99%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.351035 Test loss=0.640006 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.35929223895072937
[5/24] Train loss=0.320403128862381
[10/24] Train loss=0.348553329706192
[15/24] Train loss=0.3445243239402771
[20/24] Train loss=0.3082717955112457
Test set avg_accuracy=63.09% avg_sensitivity=65.72%, avg_specificity=62.08% avg_auc=68.65%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.346833 Test loss=0.615177 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.349450021982193
[5/24] Train loss=0.33888912200927734
[10/24] Train loss=0.35560736060142517
[15/24] Train loss=0.3453235626220703
[20/24] Train loss=0.3228241801261902
Test set avg_accuracy=57.94% avg_sensitivity=70.77%, avg_specificity=53.05% avg_auc=67.09%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.352739 Test loss=0.697083 Current lr=[0.00029967723776099]

[0/24] Train loss=0.35516518354415894
[5/24] Train loss=0.309175580739975
[10/24] Train loss=0.34776681661605835
[15/24] Train loss=0.3328590393066406
[20/24] Train loss=0.2919221520423889
Test set avg_accuracy=77.88% avg_sensitivity=51.01%, avg_specificity=88.13% avg_auc=79.98%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.341692 Test loss=0.492966 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3585372865200043
[5/24] Train loss=0.3544805943965912
[10/24] Train loss=0.3399690091609955
[15/24] Train loss=0.33289557695388794
[20/24] Train loss=0.294702410697937
Test set avg_accuracy=61.26% avg_sensitivity=57.24%, avg_specificity=62.80% avg_auc=64.94%
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.346541 Test loss=0.629258 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3326667249202728
[5/24] Train loss=0.32720059156417847
[10/24] Train loss=0.34194421768188477
[15/24] Train loss=0.32482102513313293
[20/24] Train loss=0.293315589427948
Test set avg_accuracy=63.07% avg_sensitivity=75.01%, avg_specificity=58.52% avg_auc=72.79%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.337458 Test loss=0.617205 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3449097275733948
[5/24] Train loss=0.3223098814487457
[10/24] Train loss=0.3403298854827881
[15/24] Train loss=0.31961295008659363
[20/24] Train loss=0.2948541045188904
Test set avg_accuracy=61.94% avg_sensitivity=61.43%, avg_specificity=62.13% avg_auc=67.48%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.333346 Test loss=0.647134 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.31671082973480225
[5/24] Train loss=0.3064175248146057
[10/24] Train loss=0.3276611566543579
[15/24] Train loss=0.32341456413269043
[20/24] Train loss=0.28931090235710144
Test set avg_accuracy=55.03% avg_sensitivity=66.53%, avg_specificity=50.64% avg_auc=63.40%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.331915 Test loss=0.756512 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3321080803871155
[5/24] Train loss=0.3034041225910187
[10/24] Train loss=0.3496113121509552
[15/24] Train loss=0.3228027820587158
[20/24] Train loss=0.29061299562454224
Test set avg_accuracy=60.36% avg_sensitivity=72.94%, avg_specificity=55.57% avg_auc=69.01%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.329706 Test loss=0.656392 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.31705817580223083
[5/24] Train loss=0.31448671221733093
[10/24] Train loss=0.32435518503189087
[15/24] Train loss=0.329004168510437
[20/24] Train loss=0.29826629161834717
Test set avg_accuracy=57.14% avg_sensitivity=63.60%, avg_specificity=54.67% avg_auc=64.34%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.335350 Test loss=0.744468 Current lr=[0.000297555943323901]

[0/24] Train loss=0.32341185212135315
[5/24] Train loss=0.31827598810195923
[10/24] Train loss=0.349526971578598
[15/24] Train loss=0.3421371579170227
[20/24] Train loss=0.3187463581562042
Test set avg_accuracy=52.66% avg_sensitivity=76.66%, avg_specificity=43.50% avg_auc=65.62%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.347241 Test loss=0.840593 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3209005892276764
[5/24] Train loss=0.3167780041694641
[10/24] Train loss=0.32707858085632324
[15/24] Train loss=0.33043354749679565
[20/24] Train loss=0.3075703978538513
Test set avg_accuracy=72.73% avg_sensitivity=24.99%, avg_specificity=90.95% avg_auc=68.75%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.334852 Test loss=0.545849 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.34533149003982544
[5/24] Train loss=0.31102481484413147
[10/24] Train loss=0.3411945402622223
[15/24] Train loss=0.3288728892803192
[20/24] Train loss=0.2924046814441681
Test set avg_accuracy=71.64% avg_sensitivity=44.46%, avg_specificity=82.01% avg_auc=73.73%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.331036 Test loss=0.533607 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.33998560905456543
[5/24] Train loss=0.32811012864112854
[10/24] Train loss=0.3260752558708191
[15/24] Train loss=0.32040202617645264
[20/24] Train loss=0.2999469041824341
Test set avg_accuracy=49.84% avg_sensitivity=68.51%, avg_specificity=42.72% avg_auc=58.94%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.329459 Test loss=0.923673 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3175925016403198
[5/24] Train loss=0.2989991307258606
[10/24] Train loss=0.31667467951774597
[15/24] Train loss=0.3070348799228668
[20/24] Train loss=0.28659218549728394
Test set avg_accuracy=57.30% avg_sensitivity=78.41%, avg_specificity=49.25% avg_auc=69.59%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.319770 Test loss=0.704191 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3126846253871918
[5/24] Train loss=0.29179847240448
[10/24] Train loss=0.31959813833236694
[15/24] Train loss=0.30665066838264465
[20/24] Train loss=0.2777273952960968
Test set avg_accuracy=67.85% avg_sensitivity=68.65%, avg_specificity=67.55% avg_auc=73.98%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.316452 Test loss=0.580037 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3114859461784363
[5/24] Train loss=0.2910129427909851
[10/24] Train loss=0.3144930601119995
[15/24] Train loss=0.29921361804008484
[20/24] Train loss=0.28249672055244446
Test set avg_accuracy=56.98% avg_sensitivity=73.22%, avg_specificity=50.78% avg_auc=66.35%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.317501 Test loss=0.705400 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3550635278224945
[5/24] Train loss=0.30906766653060913
[10/24] Train loss=0.3144949674606323
[15/24] Train loss=0.3362574577331543
[20/24] Train loss=0.3132985234260559
Test set avg_accuracy=73.54% avg_sensitivity=76.33%, avg_specificity=72.48% avg_auc=81.58%
Best model saved!! Metric=-22.072965754867056!!
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.326901 Test loss=0.534923 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3307918608188629
[5/24] Train loss=0.293781042098999
[10/24] Train loss=0.32679158449172974
[15/24] Train loss=0.3008668124675751
[20/24] Train loss=0.27571019530296326
Test set avg_accuracy=59.01% avg_sensitivity=64.69%, avg_specificity=56.84% avg_auc=67.29%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.317196 Test loss=0.685811 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.2928638160228729
[5/24] Train loss=0.29929035902023315
[10/24] Train loss=0.31511422991752625
[15/24] Train loss=0.2907622754573822
[20/24] Train loss=0.29290473461151123
Test set avg_accuracy=67.25% avg_sensitivity=77.09%, avg_specificity=63.50% avg_auc=77.35%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.308867 Test loss=0.598134 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3096056878566742
[5/24] Train loss=0.2840383052825928
[10/24] Train loss=0.3033737242221832
[15/24] Train loss=0.2985113263130188
[20/24] Train loss=0.2710920572280884
Test set avg_accuracy=59.41% avg_sensitivity=78.22%, avg_specificity=52.24% avg_auc=70.91%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.308231 Test loss=0.677052 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3254750967025757
[5/24] Train loss=0.295462042093277
[10/24] Train loss=0.30857622623443604
[15/24] Train loss=0.30016201734542847
[20/24] Train loss=0.28259214758872986
Test set avg_accuracy=63.42% avg_sensitivity=68.60%, avg_specificity=61.45% avg_auc=70.11%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.314292 Test loss=0.662202 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3338787853717804
[5/24] Train loss=0.296434223651886
[10/24] Train loss=0.31994369626045227
[15/24] Train loss=0.3137219548225403
[20/24] Train loss=0.29412856698036194
Test set avg_accuracy=76.13% avg_sensitivity=51.39%, avg_specificity=85.57% avg_auc=78.31%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.324127 Test loss=0.506223 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3462247848510742
[5/24] Train loss=0.2971953749656677
[10/24] Train loss=0.3177697956562042
[15/24] Train loss=0.3107203543186188
[20/24] Train loss=0.29096972942352295
Test set avg_accuracy=58.50% avg_sensitivity=77.18%, avg_specificity=51.38% avg_auc=69.71%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.314213 Test loss=0.749823 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.28757244348526
[5/24] Train loss=0.28301262855529785
[10/24] Train loss=0.30096137523651123
[15/24] Train loss=0.3015097975730896
[20/24] Train loss=0.2773168087005615
Test set avg_accuracy=68.19% avg_sensitivity=50.64%, avg_specificity=74.89% avg_auc=72.21%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.305635 Test loss=0.562428 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2887914180755615
[5/24] Train loss=0.2898607850074768
[10/24] Train loss=0.31924378871917725
[15/24] Train loss=0.29765424132347107
[20/24] Train loss=0.2769801616668701
Test set avg_accuracy=57.45% avg_sensitivity=75.39%, avg_specificity=50.60% avg_auc=67.78%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.307423 Test loss=0.757900 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.30218634009361267
[5/24] Train loss=0.28908684849739075
[10/24] Train loss=0.30379754304885864
[15/24] Train loss=0.29807335138320923
[20/24] Train loss=0.29248321056365967
Test set avg_accuracy=60.35% avg_sensitivity=81.14%, avg_specificity=52.42% avg_auc=72.52%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.305408 Test loss=0.634870 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3053945302963257
[5/24] Train loss=0.2891829311847687
[10/24] Train loss=0.31777581572532654
[15/24] Train loss=0.30744242668151855
[20/24] Train loss=0.2773043215274811
Test set avg_accuracy=76.07% avg_sensitivity=48.56%, avg_specificity=86.56% avg_auc=78.02%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.312953 Test loss=0.495317 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.37122035026550293
[5/24] Train loss=0.3207084834575653
[10/24] Train loss=0.3161693513393402
[15/24] Train loss=0.2969236671924591
[20/24] Train loss=0.2873076796531677
Test set avg_accuracy=55.21% avg_sensitivity=73.83%, avg_specificity=48.10% avg_auc=64.94%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.318050 Test loss=0.857304 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.29071974754333496
[5/24] Train loss=0.28598904609680176
[10/24] Train loss=0.2957468330860138
[15/24] Train loss=0.28893187642097473
[20/24] Train loss=0.26671695709228516
Test set avg_accuracy=59.71% avg_sensitivity=80.81%, avg_specificity=51.66% avg_auc=71.41%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.298880 Test loss=0.677323 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2816028296947479
[5/24] Train loss=0.28660693764686584
[10/24] Train loss=0.3099730610847473
[15/24] Train loss=0.295904278755188
[20/24] Train loss=0.26647400856018066
Test set avg_accuracy=65.00% avg_sensitivity=66.48%, avg_specificity=64.44% avg_auc=71.47%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.296337 Test loss=0.621191 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2838725745677948
[5/24] Train loss=0.2682502269744873
[10/24] Train loss=0.2984759211540222
[15/24] Train loss=0.2906329035758972
[20/24] Train loss=0.26842910051345825
Test set avg_accuracy=65.07% avg_sensitivity=57.99%, avg_specificity=67.76% avg_auc=69.54%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.295470 Test loss=0.602384 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3070773482322693
[5/24] Train loss=0.2755894064903259
[10/24] Train loss=0.28981614112854004
[15/24] Train loss=0.28445327281951904
[20/24] Train loss=0.2641180157661438
Test set avg_accuracy=56.91% avg_sensitivity=78.83%, avg_specificity=48.55% avg_auc=68.28%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.296696 Test loss=0.712034 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.27852028608322144
[5/24] Train loss=0.29300519824028015
[10/24] Train loss=0.29784801602363586
[15/24] Train loss=0.2729972302913666
[20/24] Train loss=0.26409050822257996
Test set avg_accuracy=61.82% avg_sensitivity=53.51%, avg_specificity=64.99% avg_auc=64.07%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.296648 Test loss=0.736078 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2850780189037323
[5/24] Train loss=0.2875467538833618
[10/24] Train loss=0.3222373425960541
[15/24] Train loss=0.27327507734298706
[20/24] Train loss=0.264065682888031
Test set avg_accuracy=60.12% avg_sensitivity=81.47%, avg_specificity=51.97% avg_auc=71.19%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.303610 Test loss=0.684092 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2758473753929138
[5/24] Train loss=0.27801376581192017
[10/24] Train loss=0.28914859890937805
[15/24] Train loss=0.28826218843460083
[20/24] Train loss=0.2900235652923584
Test set avg_accuracy=75.72% avg_sensitivity=75.86%, avg_specificity=75.66% avg_auc=83.36%
Best model saved!! Metric=-15.404866691942004!!
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.301742 Test loss=0.499576 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.28783857822418213
[5/24] Train loss=0.29164066910743713
[10/24] Train loss=0.2892233431339264
[15/24] Train loss=0.27750295400619507
[20/24] Train loss=0.26348549127578735
Test set avg_accuracy=52.85% avg_sensitivity=77.18%, avg_specificity=43.57% avg_auc=69.06%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.300748 Test loss=0.809245 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.30041009187698364
[5/24] Train loss=0.3056381344795227
[10/24] Train loss=0.3026573061943054
[15/24] Train loss=0.2961706221103668
[20/24] Train loss=0.27786657214164734
Test set avg_accuracy=66.04% avg_sensitivity=72.75%, avg_specificity=63.48% avg_auc=74.19%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.305475 Test loss=0.615871 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2664337754249573
[5/24] Train loss=0.26665037870407104
[10/24] Train loss=0.2954310178756714
[15/24] Train loss=0.2776028513908386
[20/24] Train loss=0.2630373239517212
Test set avg_accuracy=63.32% avg_sensitivity=75.81%, avg_specificity=58.55% avg_auc=73.63%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.290526 Test loss=0.647048 Current lr=[0.000224838296036774]

[0/24] Train loss=0.29781875014305115
[5/24] Train loss=0.2739899754524231
[10/24] Train loss=0.290424108505249
[15/24] Train loss=0.26869335770606995
[20/24] Train loss=0.2540331780910492
Test set avg_accuracy=61.47% avg_sensitivity=70.16%, avg_specificity=58.16% avg_auc=69.88%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.289503 Test loss=0.675832 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.27174240350723267
[5/24] Train loss=0.27436596155166626
[10/24] Train loss=0.28064900636672974
[15/24] Train loss=0.2750241756439209
[20/24] Train loss=0.2562451660633087
Test set avg_accuracy=61.61% avg_sensitivity=66.81%, avg_specificity=59.63% avg_auc=68.66%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.289136 Test loss=0.677058 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2651105523109436
[5/24] Train loss=0.27128997445106506
[10/24] Train loss=0.2842729687690735
[15/24] Train loss=0.27745291590690613
[20/24] Train loss=0.27261635661125183
Test set avg_accuracy=52.16% avg_sensitivity=80.43%, avg_specificity=41.37% avg_auc=66.24%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.285226 Test loss=0.746752 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.27887046337127686
[5/24] Train loss=0.26036009192466736
[10/24] Train loss=0.2797533869743347
[15/24] Train loss=0.2547873556613922
[20/24] Train loss=0.26074451208114624
Test set avg_accuracy=63.22% avg_sensitivity=76.05%, avg_specificity=58.32% avg_auc=74.22%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.283061 Test loss=0.597608 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2738494575023651
[5/24] Train loss=0.27181047201156616
[10/24] Train loss=0.2758796513080597
[15/24] Train loss=0.26566755771636963
[20/24] Train loss=0.27100926637649536
Test set avg_accuracy=55.30% avg_sensitivity=82.84%, avg_specificity=44.79% avg_auc=67.83%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.280929 Test loss=0.755850 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2605029046535492
[5/24] Train loss=0.26192352175712585
[10/24] Train loss=0.2778511047363281
[15/24] Train loss=0.268640398979187
[20/24] Train loss=0.25341248512268066
Test set avg_accuracy=52.41% avg_sensitivity=59.74%, avg_specificity=49.61% avg_auc=59.40%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.282013 Test loss=0.820219 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.27840083837509155
[5/24] Train loss=0.267375648021698
[10/24] Train loss=0.28864264488220215
[15/24] Train loss=0.2684714198112488
[20/24] Train loss=0.26313313841819763
Test set avg_accuracy=54.15% avg_sensitivity=74.87%, avg_specificity=46.25% avg_auc=65.51%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.283611 Test loss=0.713381 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2766723334789276
[5/24] Train loss=0.2648584246635437
[10/24] Train loss=0.2759051024913788
[15/24] Train loss=0.2601836919784546
[20/24] Train loss=0.25465601682662964
Test set avg_accuracy=53.36% avg_sensitivity=81.71%, avg_specificity=42.54% avg_auc=67.75%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.283242 Test loss=0.782017 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.25536686182022095
[5/24] Train loss=0.276995986700058
[10/24] Train loss=0.2795330882072449
[15/24] Train loss=0.2580624520778656
[20/24] Train loss=0.2518780827522278
Test set avg_accuracy=60.46% avg_sensitivity=71.95%, avg_specificity=56.07% avg_auc=68.97%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.281600 Test loss=0.703049 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2611134648323059
[5/24] Train loss=0.2551723122596741
[10/24] Train loss=0.28628119826316833
[15/24] Train loss=0.257465124130249
[20/24] Train loss=0.25262704491615295
Test set avg_accuracy=70.86% avg_sensitivity=28.90%, avg_specificity=86.87% avg_auc=67.48%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.280989 Test loss=0.573188 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.26788079738616943
[5/24] Train loss=0.2590785026550293
[10/24] Train loss=0.2639292776584625
[15/24] Train loss=0.2702105641365051
[20/24] Train loss=0.2527691423892975
Test set avg_accuracy=60.92% avg_sensitivity=74.40%, avg_specificity=55.78% avg_auc=71.03%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.278559 Test loss=0.693816 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2540413439273834
[5/24] Train loss=0.25840437412261963
[10/24] Train loss=0.27485597133636475
[15/24] Train loss=0.2596920430660248
[20/24] Train loss=0.25651034712791443
Test set avg_accuracy=58.07% avg_sensitivity=79.63%, avg_specificity=49.85% avg_auc=70.05%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.274289 Test loss=0.718684 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.259696364402771
[5/24] Train loss=0.2564662992954254
[10/24] Train loss=0.2760082483291626
[15/24] Train loss=0.25834041833877563
[20/24] Train loss=0.24338942766189575
Test set avg_accuracy=47.84% avg_sensitivity=75.95%, avg_specificity=37.11% avg_auc=62.94%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.271014 Test loss=0.901600 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2486882209777832
[5/24] Train loss=0.25587713718414307
[10/24] Train loss=0.26438528299331665
[15/24] Train loss=0.2493019700050354
[20/24] Train loss=0.2431628704071045
Test set avg_accuracy=65.12% avg_sensitivity=62.28%, avg_specificity=66.20% avg_auc=71.01%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.273045 Test loss=0.604312 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2600700855255127
[5/24] Train loss=0.2538876235485077
[10/24] Train loss=0.26255926489830017
[15/24] Train loss=0.3242041766643524
[20/24] Train loss=0.25328388810157776
Test set avg_accuracy=61.20% avg_sensitivity=64.21%, avg_specificity=60.05% avg_auc=69.12%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.276637 Test loss=0.626107 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.24873480200767517
[5/24] Train loss=0.2469298243522644
[10/24] Train loss=0.2672549784183502
[15/24] Train loss=0.2398563176393509
[20/24] Train loss=0.2663915157318115
Test set avg_accuracy=62.32% avg_sensitivity=83.31%, avg_specificity=54.31% avg_auc=75.87%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.275557 Test loss=0.612310 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2816570997238159
[5/24] Train loss=0.28381621837615967
[10/24] Train loss=0.27052581310272217
[15/24] Train loss=0.2461174875497818
[20/24] Train loss=0.25554418563842773
Test set avg_accuracy=61.56% avg_sensitivity=74.73%, avg_specificity=56.54% avg_auc=71.61%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.275367 Test loss=0.682623 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.29267045855522156
[5/24] Train loss=0.2554994225502014
[10/24] Train loss=0.2584322392940521
[15/24] Train loss=0.2555704712867737
[20/24] Train loss=0.24175801873207092
Test set avg_accuracy=58.87% avg_sensitivity=80.86%, avg_specificity=50.48% avg_auc=70.81%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.268218 Test loss=0.704012 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2535795271396637
[5/24] Train loss=0.23897691071033478
[10/24] Train loss=0.2593657672405243
[15/24] Train loss=0.2393251359462738
[20/24] Train loss=0.2444499433040619
Test set avg_accuracy=64.15% avg_sensitivity=66.76%, avg_specificity=63.16% avg_auc=71.71%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.260664 Test loss=0.639928 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2577762305736542
[5/24] Train loss=0.24436715245246887
[10/24] Train loss=0.2587762773036957
[15/24] Train loss=0.2488013654947281
[20/24] Train loss=0.246174156665802
Test set avg_accuracy=57.25% avg_sensitivity=80.43%, avg_specificity=48.41% avg_auc=70.62%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.261562 Test loss=0.709256 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2463439702987671
[5/24] Train loss=0.24954387545585632
[10/24] Train loss=0.25284767150878906
[15/24] Train loss=0.2423335462808609
[20/24] Train loss=0.23445691168308258
Test set avg_accuracy=59.69% avg_sensitivity=65.72%, avg_specificity=57.38% avg_auc=67.80%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.257778 Test loss=0.688098 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2561028003692627
[5/24] Train loss=0.23476582765579224
[10/24] Train loss=0.24607446789741516
[15/24] Train loss=0.2379346489906311
[20/24] Train loss=0.2321680188179016
Test set avg_accuracy=58.91% avg_sensitivity=72.61%, avg_specificity=53.68% avg_auc=68.32%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.256034 Test loss=0.645138 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2418956458568573
[5/24] Train loss=0.23771966993808746
[10/24] Train loss=0.24735581874847412
[15/24] Train loss=0.2566794753074646
[20/24] Train loss=0.2347569465637207
Test set avg_accuracy=63.36% avg_sensitivity=67.33%, avg_specificity=61.85% avg_auc=71.16%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.262120 Test loss=0.681467 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2709401249885559
[5/24] Train loss=0.24521669745445251
[10/24] Train loss=0.2609270215034485
[15/24] Train loss=0.2433275580406189
[20/24] Train loss=0.2362697869539261
Test set avg_accuracy=62.54% avg_sensitivity=55.82%, avg_specificity=65.10% avg_auc=68.29%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.260694 Test loss=0.661641 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.25649377703666687
[5/24] Train loss=0.24446815252304077
[10/24] Train loss=0.24640800058841705
[15/24] Train loss=0.25735893845558167
[20/24] Train loss=0.2329452633857727
Test set avg_accuracy=60.23% avg_sensitivity=71.38%, avg_specificity=55.98% avg_auc=71.16%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.257578 Test loss=0.615569 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.23875093460083008
[5/24] Train loss=0.2333631068468094
[10/24] Train loss=0.2458127737045288
[15/24] Train loss=0.2346709668636322
[20/24] Train loss=0.23213696479797363
Test set avg_accuracy=60.27% avg_sensitivity=75.67%, avg_specificity=54.40% avg_auc=71.07%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.251102 Test loss=0.630059 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.23053838312625885
[5/24] Train loss=0.23165945708751678
[10/24] Train loss=0.2513062655925751
[15/24] Train loss=0.2394183874130249
[20/24] Train loss=0.22622182965278625
Test set avg_accuracy=64.43% avg_sensitivity=53.18%, avg_specificity=68.72% avg_auc=68.24%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.249766 Test loss=0.612182 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.24136391282081604
[5/24] Train loss=0.25300469994544983
[10/24] Train loss=0.2532489597797394
[15/24] Train loss=0.23992711305618286
[20/24] Train loss=0.23047247529029846
Test set avg_accuracy=62.42% avg_sensitivity=59.88%, avg_specificity=63.39% avg_auc=68.70%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.255674 Test loss=0.670861 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.25772610306739807
[5/24] Train loss=0.2369339019060135
[10/24] Train loss=0.2438117265701294
[15/24] Train loss=0.23501893877983093
[20/24] Train loss=0.23508808016777039
Test set avg_accuracy=60.31% avg_sensitivity=71.95%, avg_specificity=55.87% avg_auc=69.91%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.254676 Test loss=0.665671 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.24416787922382355
[5/24] Train loss=0.23921875655651093
[10/24] Train loss=0.24240835011005402
[15/24] Train loss=0.23096632957458496
[20/24] Train loss=0.2306017428636551
Test set avg_accuracy=70.39% avg_sensitivity=22.44%, avg_specificity=88.69% avg_auc=66.85%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.250845 Test loss=0.596642 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.22992493212223053
[5/24] Train loss=0.22697700560092926
[10/24] Train loss=0.26319101452827454
[15/24] Train loss=0.2291126847267151
[20/24] Train loss=0.23038364946842194
Test set avg_accuracy=69.44% avg_sensitivity=28.34%, avg_specificity=85.12% avg_auc=67.66%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.248560 Test loss=0.578057 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.23413865268230438
[5/24] Train loss=0.2276153713464737
[10/24] Train loss=0.254655122756958
[15/24] Train loss=0.22724498808383942
[20/24] Train loss=0.22430643439292908
Test set avg_accuracy=66.51% avg_sensitivity=45.40%, avg_specificity=74.56% avg_auc=68.17%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.246738 Test loss=0.605329 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.23716698586940765
[5/24] Train loss=0.2312963604927063
[10/24] Train loss=0.24056564271450043
[15/24] Train loss=0.22970426082611084
[20/24] Train loss=0.23165425658226013
Test set avg_accuracy=58.70% avg_sensitivity=71.10%, avg_specificity=53.97% avg_auc=67.83%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.245441 Test loss=0.700532 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2337033450603485
[5/24] Train loss=0.22345302999019623
[10/24] Train loss=0.23198838531970978
[15/24] Train loss=0.2290707379579544
[20/24] Train loss=0.21997983753681183
Test set avg_accuracy=59.84% avg_sensitivity=72.56%, avg_specificity=54.99% avg_auc=68.36%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.240650 Test loss=0.665934 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.22382239997386932
[5/24] Train loss=0.2184170037508011
[10/24] Train loss=0.23769621551036835
[15/24] Train loss=0.2213631570339203
[20/24] Train loss=0.2128503918647766
Test set avg_accuracy=60.30% avg_sensitivity=65.91%, avg_specificity=58.16% avg_auc=68.34%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.237987 Test loss=0.677668 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.22699666023254395
[5/24] Train loss=0.2194851189851761
[10/24] Train loss=0.24216672778129578
[15/24] Train loss=0.2212246060371399
[20/24] Train loss=0.218083456158638
Test set avg_accuracy=59.79% avg_sensitivity=70.63%, avg_specificity=55.66% avg_auc=68.33%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.239033 Test loss=0.656346 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.2239704579114914
[5/24] Train loss=0.21547481417655945
[10/24] Train loss=0.22960849106311798
[15/24] Train loss=0.2138843685388565
[20/24] Train loss=0.21454383432865143
Test set avg_accuracy=58.68% avg_sensitivity=74.96%, avg_specificity=52.47% avg_auc=68.15%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.232246 Test loss=0.703087 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.22711466252803802
[5/24] Train loss=0.21292880177497864
[10/24] Train loss=0.2242768406867981
[15/24] Train loss=0.21951985359191895
[20/24] Train loss=0.213893860578537
Test set avg_accuracy=60.14% avg_sensitivity=68.13%, avg_specificity=57.10% avg_auc=68.24%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.232621 Test loss=0.662937 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.21930399537086487
[5/24] Train loss=0.2175527960062027
[10/24] Train loss=0.22941334545612335
[15/24] Train loss=0.21159914135932922
[20/24] Train loss=0.21366021037101746
Test set avg_accuracy=64.57% avg_sensitivity=59.36%, avg_specificity=66.56% avg_auc=69.38%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.229854 Test loss=0.634134 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.22306755185127258
[5/24] Train loss=0.2147095650434494
[10/24] Train loss=0.21996302902698517
[15/24] Train loss=0.21416154503822327
[20/24] Train loss=0.20718254148960114
Test set avg_accuracy=60.42% avg_sensitivity=75.58%, avg_specificity=54.63% avg_auc=70.47%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.227246 Test loss=0.679781 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.22300659120082855
[5/24] Train loss=0.20581978559494019
[10/24] Train loss=0.22719435393810272
[15/24] Train loss=0.20694158971309662
[20/24] Train loss=0.20933498442173004
Test set avg_accuracy=63.84% avg_sensitivity=68.08%, avg_specificity=62.22% avg_auc=70.88%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.228058 Test loss=0.631056 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.22688665986061096
[5/24] Train loss=0.20739632844924927
[10/24] Train loss=0.2524772584438324
[15/24] Train loss=0.210585355758667
[20/24] Train loss=0.21050384640693665
Test set avg_accuracy=64.70% avg_sensitivity=66.29%, avg_specificity=64.09% avg_auc=72.87%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.231717 Test loss=0.596168 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2294100821018219
[5/24] Train loss=0.20781558752059937
[10/24] Train loss=0.22090448439121246
[15/24] Train loss=0.2366928905248642
[20/24] Train loss=0.2066899687051773
Test set avg_accuracy=61.58% avg_sensitivity=77.18%, avg_specificity=55.62% avg_auc=70.58%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.233651 Test loss=0.676288 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.22985519468784332
[5/24] Train loss=0.22976329922676086
[10/24] Train loss=0.2228119820356369
[15/24] Train loss=0.2224118709564209
[20/24] Train loss=0.23223914206027985
Test set avg_accuracy=63.55% avg_sensitivity=65.68%, avg_specificity=62.75% avg_auc=69.42%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.238961 Test loss=0.669525 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.21904905140399933
[5/24] Train loss=0.21035335958003998
[10/24] Train loss=0.23105984926223755
[15/24] Train loss=0.21546943485736847
[20/24] Train loss=0.2142079770565033
Test set avg_accuracy=59.26% avg_sensitivity=70.96%, avg_specificity=54.79% avg_auc=67.52%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.234504 Test loss=0.714221 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.2238507866859436
[5/24] Train loss=0.2080146074295044
[10/24] Train loss=0.22133231163024902
[15/24] Train loss=0.21351584792137146
[20/24] Train loss=0.21098622679710388
Test set avg_accuracy=58.49% avg_sensitivity=78.03%, avg_specificity=51.03% avg_auc=69.70%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.225483 Test loss=0.710188 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.21349510550498962
[5/24] Train loss=0.2068941444158554
[10/24] Train loss=0.2212889939546585
[15/24] Train loss=0.20036377012729645
[20/24] Train loss=0.20759455859661102
Test set avg_accuracy=60.52% avg_sensitivity=70.63%, avg_specificity=56.66% avg_auc=68.75%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.220448 Test loss=0.654778 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.21281708776950836
[5/24] Train loss=0.2000059336423874
[10/24] Train loss=0.21529705822467804
[15/24] Train loss=0.20226995646953583
[20/24] Train loss=0.20727474987506866
Test set avg_accuracy=60.36% avg_sensitivity=74.40%, avg_specificity=55.01% avg_auc=69.65%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.218612 Test loss=0.680660 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.20605680346488953
[5/24] Train loss=0.2038402408361435
[10/24] Train loss=0.21337677538394928
[15/24] Train loss=0.20259800553321838
[20/24] Train loss=0.19946956634521484
Test set avg_accuracy=60.76% avg_sensitivity=72.94%, avg_specificity=56.11% avg_auc=69.12%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.216602 Test loss=0.670052 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.20929133892059326
[5/24] Train loss=0.19523906707763672
[10/24] Train loss=0.20910006761550903
[15/24] Train loss=0.19774365425109863
[20/24] Train loss=0.20289240777492523
Test set avg_accuracy=60.92% avg_sensitivity=70.30%, avg_specificity=57.35% avg_auc=68.36%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.216002 Test loss=0.665163 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.2037845104932785
[5/24] Train loss=0.19807390868663788
[10/24] Train loss=0.21453094482421875
[15/24] Train loss=0.19738931953907013
[20/24] Train loss=0.20023787021636963
Test set avg_accuracy=60.42% avg_sensitivity=72.89%, avg_specificity=55.66% avg_auc=69.51%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.213169 Test loss=0.664129 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.20104914903640747
[5/24] Train loss=0.20475561916828156
[10/24] Train loss=0.21170102059841156
[15/24] Train loss=0.19537939131259918
[20/24] Train loss=0.2010400891304016
Test set avg_accuracy=60.42% avg_sensitivity=73.83%, avg_specificity=55.30% avg_auc=69.56%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.212481 Test loss=0.662902 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.20791564881801605
[5/24] Train loss=0.19509315490722656
[10/24] Train loss=0.20562885701656342
[15/24] Train loss=0.1950606405735016
[20/24] Train loss=0.19938932359218597
Test set avg_accuracy=59.66% avg_sensitivity=77.60%, avg_specificity=52.82% avg_auc=69.67%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.211574 Test loss=0.679164 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.20025967061519623
[5/24] Train loss=0.1951737254858017
[10/24] Train loss=0.2065596729516983
[15/24] Train loss=0.19682326912879944
[20/24] Train loss=0.1950644552707672
Test set avg_accuracy=60.59% avg_sensitivity=73.74%, avg_specificity=55.57% avg_auc=69.28%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.210747 Test loss=0.666354 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.20040474832057953
[5/24] Train loss=0.20173941552639008
[10/24] Train loss=0.20467330515384674
[15/24] Train loss=0.19205351173877716
[20/24] Train loss=0.19776977598667145
Test set avg_accuracy=60.60% avg_sensitivity=72.42%, avg_specificity=56.09% avg_auc=69.34%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.209340 Test loss=0.667961 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.2016705870628357
[5/24] Train loss=0.1939617544412613
[10/24] Train loss=0.2116825431585312
[15/24] Train loss=0.1946442723274231
[20/24] Train loss=0.19639787077903748
Test set avg_accuracy=60.89% avg_sensitivity=72.51%, avg_specificity=56.45% avg_auc=69.07%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.209986 Test loss=0.670475 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.20290401577949524
[5/24] Train loss=0.19703459739685059
[10/24] Train loss=0.20500022172927856
[15/24] Train loss=0.19089137017726898
[20/24] Train loss=0.1938832402229309
Test set avg_accuracy=60.68% avg_sensitivity=72.84%, avg_specificity=56.04% avg_auc=69.16%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.209053 Test loss=0.668605 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1947726160287857
[5/24] Train loss=0.19742190837860107
[10/24] Train loss=0.20735323429107666
[15/24] Train loss=0.19358426332473755
[20/24] Train loss=0.19712765514850616
Test set avg_accuracy=60.95% avg_sensitivity=72.23%, avg_specificity=56.65% avg_auc=69.18%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.207130 Test loss=0.670241 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.19367337226867676
[5/24] Train loss=0.19666248559951782
[10/24] Train loss=0.20538131892681122
[15/24] Train loss=0.1930231899023056
[20/24] Train loss=0.1962307244539261
Test set avg_accuracy=60.65% avg_sensitivity=73.27%, avg_specificity=55.84% avg_auc=69.46%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.207043 Test loss=0.675010 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1998434066772461
[5/24] Train loss=0.18898449838161469
[10/24] Train loss=0.20295098423957825
[15/24] Train loss=0.19124816358089447
[20/24] Train loss=0.19609391689300537
Test set avg_accuracy=60.87% avg_sensitivity=72.47%, avg_specificity=56.45% avg_auc=69.50%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.207510 Test loss=0.666507 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.19987623393535614
[5/24] Train loss=0.19621936976909637
[10/24] Train loss=0.20703060925006866
[15/24] Train loss=0.19163675606250763
[20/24] Train loss=0.19439584016799927
Test set avg_accuracy=60.62% avg_sensitivity=72.65%, avg_specificity=56.04% avg_auc=69.24%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.206750 Test loss=0.669953 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.19543439149856567
[5/24] Train loss=0.19584785401821136
[10/24] Train loss=0.2040960043668747
[15/24] Train loss=0.1926189363002777
[20/24] Train loss=0.19890426099300385
Test set avg_accuracy=60.42% avg_sensitivity=72.89%, avg_specificity=55.66% avg_auc=69.08%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.206143 Test loss=0.677850 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.19993732869625092
[5/24] Train loss=0.19741030037403107
[10/24] Train loss=0.20801647007465363
[15/24] Train loss=0.19380979239940643
[20/24] Train loss=0.1933286488056183
Test set avg_accuracy=60.38% avg_sensitivity=73.60%, avg_specificity=55.33% avg_auc=69.29%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.205237 Test loss=0.676822 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1937057375907898
[5/24] Train loss=0.18829898536205292
[10/24] Train loss=0.20581507682800293
[15/24] Train loss=0.193712055683136
[20/24] Train loss=0.18898360431194305
Test set avg_accuracy=60.31% avg_sensitivity=73.36%, avg_specificity=55.33% avg_auc=69.17%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.205711 Test loss=0.677554 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.20227089524269104
[5/24] Train loss=0.19540828466415405
[10/24] Train loss=0.20634697377681732
[15/24] Train loss=0.18941855430603027
[20/24] Train loss=0.19380134344100952
Test set avg_accuracy=60.34% avg_sensitivity=72.75%, avg_specificity=55.60% avg_auc=68.98%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.205092 Test loss=0.677294 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.19561688601970673
[5/24] Train loss=0.19631361961364746
[10/24] Train loss=0.20543338358402252
[15/24] Train loss=0.18971970677375793
[20/24] Train loss=0.18892304599285126
Test set avg_accuracy=60.36% avg_sensitivity=73.22%, avg_specificity=55.46% avg_auc=69.06%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.205434 Test loss=0.676771 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.19691292941570282
[5/24] Train loss=0.1979822963476181
[10/24] Train loss=0.20138932764530182
[15/24] Train loss=0.19197329878807068
[20/24] Train loss=0.18845151364803314
Test set avg_accuracy=60.43% avg_sensitivity=72.75%, avg_specificity=55.73% avg_auc=69.13%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.205363 Test loss=0.673600 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.19643104076385498
[5/24] Train loss=0.1889963299036026
[10/24] Train loss=0.2064720094203949
[15/24] Train loss=0.1906569004058838
[20/24] Train loss=0.1872212439775467
Test set avg_accuracy=60.53% avg_sensitivity=73.13%, avg_specificity=55.73% avg_auc=69.23%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.205013 Test loss=0.673178 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.19920700788497925
[5/24] Train loss=0.19092726707458496
[10/24] Train loss=0.2038181722164154
[15/24] Train loss=0.19133107364177704
[20/24] Train loss=0.193869486451149
Test set avg_accuracy=60.36% avg_sensitivity=72.98%, avg_specificity=55.55% avg_auc=69.14%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.204716 Test loss=0.673797 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.195703387260437
[5/24] Train loss=0.1939738392829895
[10/24] Train loss=0.20737825334072113
[15/24] Train loss=0.19423922896385193
[20/24] Train loss=0.1932886242866516
Test set avg_accuracy=60.51% avg_sensitivity=72.70%, avg_specificity=55.86% avg_auc=69.08%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.205986 Test loss=0.672937 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=75.72% sen=75.86%, spe=75.66%, auc=83.36%!
Fold[7] Avg_overlap=0.65%(±0.21654057771397323)
[0/24] Train loss=0.7550804615020752
[5/24] Train loss=0.7651661038398743
[10/24] Train loss=0.7605633735656738
[15/24] Train loss=0.7552845478057861
[20/24] Train loss=0.7508545517921448
Test set avg_accuracy=54.39% avg_sensitivity=41.69%, avg_specificity=58.65% avg_auc=50.29%
Best model saved!! Metric=-120.9811622340121!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=0.754128 Test loss=0.694957 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.744028627872467
[5/24] Train loss=0.7522232532501221
[10/24] Train loss=0.7479259371757507
[15/24] Train loss=0.7363147735595703
[20/24] Train loss=0.7363564968109131
Test set avg_accuracy=51.45% avg_sensitivity=48.42%, avg_specificity=52.46% avg_auc=50.60%
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.742048 Test loss=0.689141 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7386212944984436
[5/24] Train loss=0.7344505786895752
[10/24] Train loss=0.7329078912734985
[15/24] Train loss=0.7402083277702332
[20/24] Train loss=0.7312770485877991
Test set avg_accuracy=48.09% avg_sensitivity=54.07%, avg_specificity=46.08% avg_auc=51.56%
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.733892 Test loss=0.689359 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.7225220203399658
[5/24] Train loss=0.7345148921012878
[10/24] Train loss=0.7285467386245728
[15/24] Train loss=0.7284964919090271
[20/24] Train loss=0.7138373851776123
Test set avg_accuracy=48.33% avg_sensitivity=53.91%, avg_specificity=46.46% avg_auc=51.70%
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.724742 Test loss=0.685112 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.716949999332428
[5/24] Train loss=0.7232333421707153
[10/24] Train loss=0.7042038440704346
[15/24] Train loss=0.7188413143157959
[20/24] Train loss=0.7048688530921936
Test set avg_accuracy=51.48% avg_sensitivity=47.90%, avg_specificity=52.69% avg_auc=51.66%
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.713169 Test loss=0.680691 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.7034335136413574
[5/24] Train loss=0.7074407339096069
[10/24] Train loss=0.7041770815849304
[15/24] Train loss=0.7055627107620239
[20/24] Train loss=0.6898252367973328
Test set avg_accuracy=54.65% avg_sensitivity=43.24%, avg_specificity=58.48% avg_auc=52.10%
Best model saved!! Metric=-117.53415125364268!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.702529 Test loss=0.674759 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6929532885551453
[5/24] Train loss=0.694404661655426
[10/24] Train loss=0.6908392906188965
[15/24] Train loss=0.6869009137153625
[20/24] Train loss=0.6784172058105469
Test set avg_accuracy=60.76% avg_sensitivity=31.90%, avg_specificity=70.45% avg_auc=52.68%
Best model saved!! Metric=-110.2167630152965!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.688042 Test loss=0.659707 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6797696948051453
[5/24] Train loss=0.6803983449935913
[10/24] Train loss=0.6741248965263367
[15/24] Train loss=0.6768249869346619
[20/24] Train loss=0.6605618000030518
Test set avg_accuracy=60.79% avg_sensitivity=32.83%, avg_specificity=70.19% avg_auc=53.32%
Best model saved!! Metric=-108.86456826497563!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.675681 Test loss=0.655950 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6684163808822632
[5/24] Train loss=0.6627340912818909
[10/24] Train loss=0.6628696322441101
[15/24] Train loss=0.6617258787155151
[20/24] Train loss=0.6400774121284485
Test set avg_accuracy=69.47% avg_sensitivity=16.31%, avg_specificity=87.32% avg_auc=54.14%
Best model saved!! Metric=-98.75990856614837!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.660455 Test loss=0.644634 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6510149240493774
[5/24] Train loss=0.6410843133926392
[10/24] Train loss=0.6450850963592529
[15/24] Train loss=0.6492409110069275
[20/24] Train loss=0.627557098865509
Test set avg_accuracy=64.05% avg_sensitivity=30.55%, avg_specificity=75.30% avg_auc=55.12%
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.645404 Test loss=0.642563 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6402022242546082
[5/24] Train loss=0.6354860067367554
[10/24] Train loss=0.629144549369812
[15/24] Train loss=0.6358619928359985
[20/24] Train loss=0.606901228427887
Test set avg_accuracy=70.36% avg_sensitivity=18.54%, avg_specificity=87.77% avg_auc=56.61%
Best model saved!! Metric=-92.71319544232387!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.629179 Test loss=0.611199 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6193004846572876
[5/24] Train loss=0.6070377230644226
[10/24] Train loss=0.6092541217803955
[15/24] Train loss=0.6199962496757507
[20/24] Train loss=0.5908759236335754
Test set avg_accuracy=72.59% avg_sensitivity=15.33%, avg_specificity=91.82% avg_auc=58.77%
Best model saved!! Metric=-87.48747131116994!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.609727 Test loss=0.580342 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.6001707911491394
[5/24] Train loss=0.5872117877006531
[10/24] Train loss=0.5988828539848328
[15/24] Train loss=0.6024434566497803
[20/24] Train loss=0.5519973635673523
Test set avg_accuracy=73.31% avg_sensitivity=13.62%, avg_specificity=93.36% avg_auc=61.07%
Best model saved!! Metric=-84.64576274065196!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.589294 Test loss=0.568809 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5692725777626038
[5/24] Train loss=0.5675608515739441
[10/24] Train loss=0.5664239525794983
[15/24] Train loss=0.571955144405365
[20/24] Train loss=0.5128023028373718
Test set avg_accuracy=74.17% avg_sensitivity=13.10%, avg_specificity=94.68% avg_auc=62.24%
Best model saved!! Metric=-81.81508144812942!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.559143 Test loss=0.602109 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5323219895362854
[5/24] Train loss=0.5385360717773438
[10/24] Train loss=0.5250119566917419
[15/24] Train loss=0.5455819368362427
[20/24] Train loss=0.4660620391368866
Test set avg_accuracy=75.12% avg_sensitivity=23.15%, avg_specificity=92.57% avg_auc=69.32%
Best model saved!! Metric=-65.84363832619236!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.520149 Test loss=0.550100 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4814712107181549
[5/24] Train loss=0.5062269568443298
[10/24] Train loss=0.4967561364173889
[15/24] Train loss=0.5102351903915405
[20/24] Train loss=0.44477248191833496
Test set avg_accuracy=77.28% avg_sensitivity=35.16%, avg_specificity=91.42% avg_auc=74.49%
Best model saved!! Metric=-47.644752368267746!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.489576 Test loss=0.504397 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4480215907096863
[5/24] Train loss=0.4466753900051117
[10/24] Train loss=0.4668121039867401
[15/24] Train loss=0.4827672243118286
[20/24] Train loss=0.4134933650493622
Test set avg_accuracy=78.48% avg_sensitivity=60.69%, avg_specificity=84.45% avg_auc=81.45%
Best model saved!! Metric=-20.932137853534584!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.462940 Test loss=0.478963 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.43259212374687195
[5/24] Train loss=0.4697463810443878
[10/24] Train loss=0.4666704535484314
[15/24] Train loss=0.48339247703552246
[20/24] Train loss=0.40436482429504395
Test set avg_accuracy=75.47% avg_sensitivity=62.87%, avg_specificity=79.70% avg_auc=79.37%
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.453365 Test loss=0.527534 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4190623164176941
[5/24] Train loss=0.41902780532836914
[10/24] Train loss=0.44284695386886597
[15/24] Train loss=0.4758448898792267
[20/24] Train loss=0.39596253633499146
Test set avg_accuracy=70.34% avg_sensitivity=69.29%, avg_specificity=70.69% avg_auc=77.27%
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.436211 Test loss=0.584505 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.40584611892700195
[5/24] Train loss=0.40793657302856445
[10/24] Train loss=0.42989620566368103
[15/24] Train loss=0.4671646058559418
[20/24] Train loss=0.3786278963088989
Test set avg_accuracy=57.77% avg_sensitivity=73.64%, avg_specificity=52.44% avg_auc=69.81%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.427859 Test loss=0.662721 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.4036399722099304
[5/24] Train loss=0.39460572600364685
[10/24] Train loss=0.4252801537513733
[15/24] Train loss=0.4395444691181183
[20/24] Train loss=0.372415155172348
Test set avg_accuracy=57.27% avg_sensitivity=74.16%, avg_specificity=51.59% avg_auc=70.60%
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.419179 Test loss=0.657759 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.39507460594177246
[5/24] Train loss=0.38404566049575806
[10/24] Train loss=0.4166600704193115
[15/24] Train loss=0.43703436851501465
[20/24] Train loss=0.37016063928604126
Test set avg_accuracy=72.23% avg_sensitivity=65.41%, avg_specificity=74.52% avg_auc=76.97%
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.413022 Test loss=0.558897 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.38987231254577637
[5/24] Train loss=0.39017635583877563
[10/24] Train loss=0.4064081907272339
[15/24] Train loss=0.44384458661079407
[20/24] Train loss=0.36291277408599854
Test set avg_accuracy=60.18% avg_sensitivity=73.59%, avg_specificity=55.68% avg_auc=72.03%
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.408620 Test loss=0.638850 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3843701481819153
[5/24] Train loss=0.3743859827518463
[10/24] Train loss=0.4079296588897705
[15/24] Train loss=0.44059839844703674
[20/24] Train loss=0.3527698814868927
Test set avg_accuracy=57.27% avg_sensitivity=70.12%, avg_specificity=52.95% avg_auc=68.35%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.405517 Test loss=0.657490 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.37777209281921387
[5/24] Train loss=0.3771410584449768
[10/24] Train loss=0.40286487340927124
[15/24] Train loss=0.4244922995567322
[20/24] Train loss=0.35108619928359985
Test set avg_accuracy=53.35% avg_sensitivity=70.95%, avg_specificity=47.43% avg_auc=64.11%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.398719 Test loss=0.695657 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.38145044445991516
[5/24] Train loss=0.3591242730617523
[10/24] Train loss=0.3928068280220032
[15/24] Train loss=0.4276396334171295
[20/24] Train loss=0.34437647461891174
Test set avg_accuracy=53.91% avg_sensitivity=72.55%, avg_specificity=47.64% avg_auc=65.45%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.393867 Test loss=0.701652 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.37088778614997864
[5/24] Train loss=0.357114315032959
[10/24] Train loss=0.39510416984558105
[15/24] Train loss=0.4250488579273224
[20/24] Train loss=0.34999629855155945
Test set avg_accuracy=70.44% avg_sensitivity=66.65%, avg_specificity=71.72% avg_auc=76.35%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.391171 Test loss=0.563863 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3835972845554352
[5/24] Train loss=0.36314770579338074
[10/24] Train loss=0.387588769197464
[15/24] Train loss=0.42193686962127686
[20/24] Train loss=0.33549410104751587
Test set avg_accuracy=79.00% avg_sensitivity=64.89%, avg_specificity=83.74% avg_auc=82.09%
Best model saved!! Metric=-16.290641020665745!!
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.394892 Test loss=0.478235 Current lr=[0.000210185142098938]

[0/24] Train loss=0.37406599521636963
[5/24] Train loss=0.35336318612098694
[10/24] Train loss=0.4025634229183197
[15/24] Train loss=0.4250747859477997
[20/24] Train loss=0.33814817667007446
Test set avg_accuracy=81.63% avg_sensitivity=46.82%, avg_specificity=93.32% avg_auc=83.93%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.389488 Test loss=0.425469 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.36797577142715454
[5/24] Train loss=0.3478074073791504
[10/24] Train loss=0.36988869309425354
[15/24] Train loss=0.41442593932151794
[20/24] Train loss=0.32899510860443115
Test set avg_accuracy=54.26% avg_sensitivity=72.04%, avg_specificity=48.29% avg_auc=65.83%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.381385 Test loss=0.688229 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.35626113414764404
[5/24] Train loss=0.3473411798477173
[10/24] Train loss=0.37393859028816223
[15/24] Train loss=0.3852853775024414
[20/24] Train loss=0.3219850957393646
Test set avg_accuracy=55.79% avg_sensitivity=67.63%, avg_specificity=51.82% avg_auc=65.29%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.372138 Test loss=0.664641 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3476896584033966
[5/24] Train loss=0.33745792508125305
[10/24] Train loss=0.37721318006515503
[15/24] Train loss=0.40419936180114746
[20/24] Train loss=0.3151898682117462
Test set avg_accuracy=52.83% avg_sensitivity=70.38%, avg_specificity=46.93% avg_auc=63.16%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.371328 Test loss=0.711810 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.34940600395202637
[5/24] Train loss=0.3408476710319519
[10/24] Train loss=0.3749214708805084
[15/24] Train loss=0.4176732301712036
[20/24] Train loss=0.332720547914505
Test set avg_accuracy=66.45% avg_sensitivity=73.33%, avg_specificity=64.13% avg_auc=76.37%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.381303 Test loss=0.600633 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35053685307502747
[5/24] Train loss=0.3490072190761566
[10/24] Train loss=0.3737843930721283
[15/24] Train loss=0.3891158103942871
[20/24] Train loss=0.30913183093070984
Test set avg_accuracy=55.42% avg_sensitivity=54.22%, avg_specificity=55.82% avg_auc=60.71%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.368909 Test loss=0.682410 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.34399521350860596
[5/24] Train loss=0.3326505720615387
[10/24] Train loss=0.3649944067001343
[15/24] Train loss=0.38617467880249023
[20/24] Train loss=0.3081110715866089
Test set avg_accuracy=50.85% avg_sensitivity=70.12%, avg_specificity=44.37% avg_auc=61.58%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.364416 Test loss=0.754832 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.35149747133255005
[5/24] Train loss=0.328067809343338
[10/24] Train loss=0.3572230339050293
[15/24] Train loss=0.404867947101593
[20/24] Train loss=0.29949501156806946
Test set avg_accuracy=60.04% avg_sensitivity=68.41%, avg_specificity=57.23% avg_auc=65.94%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.361620 Test loss=0.682752 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.34094786643981934
[5/24] Train loss=0.32773712277412415
[10/24] Train loss=0.3605993390083313
[15/24] Train loss=0.37432608008384705
[20/24] Train loss=0.30844417214393616
Test set avg_accuracy=47.19% avg_sensitivity=73.80%, avg_specificity=38.25% avg_auc=61.27%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.360440 Test loss=0.789159 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34801793098449707
[5/24] Train loss=0.3237074017524719
[10/24] Train loss=0.3558010160923004
[15/24] Train loss=0.41672828793525696
[20/24] Train loss=0.3213408291339874
Test set avg_accuracy=78.74% avg_sensitivity=47.23%, avg_specificity=89.32% avg_auc=77.59%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.367229 Test loss=0.533905 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.34350040555000305
[5/24] Train loss=0.32442113757133484
[10/24] Train loss=0.3473135530948639
[15/24] Train loss=0.4037855267524719
[20/24] Train loss=0.30641576647758484
Test set avg_accuracy=55.90% avg_sensitivity=66.03%, avg_specificity=52.50% avg_auc=63.86%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.355397 Test loss=0.719027 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.33662542700767517
[5/24] Train loss=0.32200032472610474
[10/24] Train loss=0.3394536077976227
[15/24] Train loss=0.3684532940387726
[20/24] Train loss=0.28232836723327637
Test set avg_accuracy=51.28% avg_sensitivity=68.20%, avg_specificity=45.59% avg_auc=61.12%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.348096 Test loss=0.792559 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.32558366656303406
[5/24] Train loss=0.3207128047943115
[10/24] Train loss=0.3401217460632324
[15/24] Train loss=0.3867519795894623
[20/24] Train loss=0.30027079582214355
Test set avg_accuracy=60.89% avg_sensitivity=69.65%, avg_specificity=57.94% avg_auc=70.76%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.353643 Test loss=0.630450 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.33043867349624634
[5/24] Train loss=0.3141199052333832
[10/24] Train loss=0.3381956219673157
[15/24] Train loss=0.37285372614860535
[20/24] Train loss=0.28625985980033875
Test set avg_accuracy=60.22% avg_sensitivity=66.75%, avg_specificity=58.03% avg_auc=67.91%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.350412 Test loss=0.688339 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.3250318169593811
[5/24] Train loss=0.31752005219459534
[10/24] Train loss=0.33224475383758545
[15/24] Train loss=0.3818041682243347
[20/24] Train loss=0.28584107756614685
Test set avg_accuracy=70.25% avg_sensitivity=62.14%, avg_specificity=72.97% avg_auc=73.75%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.343795 Test loss=0.582406 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.32872432470321655
[5/24] Train loss=0.3175773024559021
[10/24] Train loss=0.3153066039085388
[15/24] Train loss=0.4145304560661316
[20/24] Train loss=0.2910813093185425
Test set avg_accuracy=71.25% avg_sensitivity=24.86%, avg_specificity=86.83% avg_auc=66.71%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.350509 Test loss=0.568343 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3386273682117462
[5/24] Train loss=0.3172181248664856
[10/24] Train loss=0.3278714716434479
[15/24] Train loss=0.392124205827713
[20/24] Train loss=0.28682008385658264
Test set avg_accuracy=59.17% avg_sensitivity=63.75%, avg_specificity=57.63% avg_auc=64.95%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.349894 Test loss=0.674712 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3337424397468567
[5/24] Train loss=0.3145516514778137
[10/24] Train loss=0.32570186257362366
[15/24] Train loss=0.3692016303539276
[20/24] Train loss=0.2813960611820221
Test set avg_accuracy=80.74% avg_sensitivity=47.23%, avg_specificity=92.00% avg_auc=80.66%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.345084 Test loss=0.463779 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.32026907801628113
[5/24] Train loss=0.310388445854187
[10/24] Train loss=0.3343127965927124
[15/24] Train loss=0.37603673338890076
[20/24] Train loss=0.2751142084598541
Test set avg_accuracy=63.84% avg_sensitivity=53.24%, avg_specificity=67.40% avg_auc=68.87%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.337787 Test loss=0.610723 Current lr=[0.000299720220882401]

[0/24] Train loss=0.306002676486969
[5/24] Train loss=0.3081805109977722
[10/24] Train loss=0.31771472096443176
[15/24] Train loss=0.3531758189201355
[20/24] Train loss=0.2704489529132843
Test set avg_accuracy=58.88% avg_sensitivity=76.90%, avg_specificity=52.83% avg_auc=70.13%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.331747 Test loss=0.646673 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3223828673362732
[5/24] Train loss=0.3244750499725342
[10/24] Train loss=0.32113635540008545
[15/24] Train loss=0.3872743248939514
[20/24] Train loss=0.28318750858306885
Test set avg_accuracy=47.60% avg_sensitivity=84.52%, avg_specificity=35.21% avg_auc=66.49%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.339195 Test loss=0.742312 Current lr=[0.000298904600941902]

[0/24] Train loss=0.3141293227672577
[5/24] Train loss=0.3114948868751526
[10/24] Train loss=0.3214404582977295
[15/24] Train loss=0.36822205781936646
[20/24] Train loss=0.2763981819152832
Test set avg_accuracy=67.96% avg_sensitivity=54.22%, avg_specificity=72.57% avg_auc=71.01%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.336814 Test loss=0.591142 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.31433749198913574
[5/24] Train loss=0.30821898579597473
[10/24] Train loss=0.3202391564846039
[15/24] Train loss=0.37040743231773376
[20/24] Train loss=0.27787572145462036
Test set avg_accuracy=59.92% avg_sensitivity=70.79%, avg_specificity=56.27% avg_auc=69.02%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.332353 Test loss=0.653760 Current lr=[0.000297555943323901]

[0/24] Train loss=0.2991751432418823
[5/24] Train loss=0.30671414732933044
[10/24] Train loss=0.3153620660305023
[15/24] Train loss=0.3547583222389221
[20/24] Train loss=0.27388235926628113
Test set avg_accuracy=69.40% avg_sensitivity=52.05%, avg_specificity=75.23% avg_auc=71.57%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.334859 Test loss=0.565445 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.31805363297462463
[5/24] Train loss=0.31014227867126465
[10/24] Train loss=0.32301610708236694
[15/24] Train loss=0.35220447182655334
[20/24] Train loss=0.2752250134944916
Test set avg_accuracy=76.73% avg_sensitivity=59.19%, avg_specificity=82.62% avg_auc=78.01%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.330263 Test loss=0.538673 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3073437511920929
[5/24] Train loss=0.30342304706573486
[10/24] Train loss=0.30508461594581604
[15/24] Train loss=0.34058916568756104
[20/24] Train loss=0.26594874262809753
Test set avg_accuracy=56.95% avg_sensitivity=65.87%, avg_specificity=53.96% avg_auc=64.19%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.325296 Test loss=0.708053 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.30703839659690857
[5/24] Train loss=0.295375794172287
[10/24] Train loss=0.3322533071041107
[15/24] Train loss=0.3446081280708313
[20/24] Train loss=0.27804866433143616
Test set avg_accuracy=71.15% avg_sensitivity=57.33%, avg_specificity=75.79% avg_auc=74.46%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.331141 Test loss=0.561487 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3138085901737213
[5/24] Train loss=0.3018660247325897
[10/24] Train loss=0.32631421089172363
[15/24] Train loss=0.3875918984413147
[20/24] Train loss=0.27465304732322693
Test set avg_accuracy=60.03% avg_sensitivity=83.43%, avg_specificity=52.17% avg_auc=76.58%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.335516 Test loss=0.670674 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3117404580116272
[5/24] Train loss=0.29210203886032104
[10/24] Train loss=0.31434178352355957
[15/24] Train loss=0.3452390134334564
[20/24] Train loss=0.26963433623313904
Test set avg_accuracy=72.08% avg_sensitivity=32.26%, avg_specificity=85.46% avg_auc=69.36%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.327134 Test loss=0.545268 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3070480525493622
[5/24] Train loss=0.3093021512031555
[10/24] Train loss=0.31068143248558044
[15/24] Train loss=0.33873456716537476
[20/24] Train loss=0.26708686351776123
Test set avg_accuracy=72.85% avg_sensitivity=71.31%, avg_specificity=73.37% avg_auc=80.35%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.321093 Test loss=0.524527 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.29271453619003296
[5/24] Train loss=0.29616859555244446
[10/24] Train loss=0.3100046217441559
[15/24] Train loss=0.3487367033958435
[20/24] Train loss=0.2750953137874603
Test set avg_accuracy=79.28% avg_sensitivity=26.26%, avg_specificity=97.10% avg_auc=81.80%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.321220 Test loss=0.464632 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.2997370660305023
[5/24] Train loss=0.3013521730899811
[10/24] Train loss=0.3134336769580841
[15/24] Train loss=0.33189505338668823
[20/24] Train loss=0.2621367573738098
Test set avg_accuracy=74.47% avg_sensitivity=35.53%, avg_specificity=87.55% avg_auc=75.08%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.317025 Test loss=0.505278 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.28846368193626404
[5/24] Train loss=0.2890281081199646
[10/24] Train loss=0.3023618459701538
[15/24] Train loss=0.3438115417957306
[20/24] Train loss=0.2567901611328125
Test set avg_accuracy=74.78% avg_sensitivity=5.13%, avg_specificity=98.17% avg_auc=69.72%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.316035 Test loss=0.531624 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.30471301078796387
[5/24] Train loss=0.2902055084705353
[10/24] Train loss=0.3030930459499359
[15/24] Train loss=0.3273473381996155
[20/24] Train loss=0.2702237069606781
Test set avg_accuracy=75.42% avg_sensitivity=58.78%, avg_specificity=81.01% avg_auc=77.83%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.315820 Test loss=0.507093 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.28851184248924255
[5/24] Train loss=0.28671398758888245
[10/24] Train loss=0.3038482069969177
[15/24] Train loss=0.32933828234672546
[20/24] Train loss=0.26932188868522644
Test set avg_accuracy=76.50% avg_sensitivity=26.77%, avg_specificity=93.20% avg_auc=68.49%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.313077 Test loss=0.540704 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.2959400415420532
[5/24] Train loss=0.2916063964366913
[10/24] Train loss=0.3154219090938568
[15/24] Train loss=0.3264496624469757
[20/24] Train loss=0.2519749104976654
Test set avg_accuracy=71.84% avg_sensitivity=57.74%, avg_specificity=76.57% avg_auc=75.44%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.314809 Test loss=0.532728 Current lr=[0.000276307469034998]

[0/24] Train loss=0.28682181239128113
[5/24] Train loss=0.2850937247276306
[10/24] Train loss=0.2948828339576721
[15/24] Train loss=0.3220488429069519
[20/24] Train loss=0.2589857280254364
Test set avg_accuracy=65.92% avg_sensitivity=48.11%, avg_specificity=71.91% avg_auc=67.03%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.313215 Test loss=0.622085 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.2856675088405609
[5/24] Train loss=0.29463469982147217
[10/24] Train loss=0.3024950623512268
[15/24] Train loss=0.3279622495174408
[20/24] Train loss=0.26260489225387573
Test set avg_accuracy=65.76% avg_sensitivity=69.29%, avg_specificity=64.57% avg_auc=73.59%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.310524 Test loss=0.586312 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.28304609656333923
[5/24] Train loss=0.28766781091690063
[10/24] Train loss=0.3057447075843811
[15/24] Train loss=0.3298398554325104
[20/24] Train loss=0.2560981214046478
Test set avg_accuracy=70.61% avg_sensitivity=78.40%, avg_specificity=67.99% avg_auc=81.09%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.308243 Test loss=0.547644 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.2803305983543396
[5/24] Train loss=0.29239943623542786
[10/24] Train loss=0.28591614961624146
[15/24] Train loss=0.3151637017726898
[20/24] Train loss=0.25216493010520935
Test set avg_accuracy=58.50% avg_sensitivity=80.42%, avg_specificity=51.14% avg_auc=72.32%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.304086 Test loss=0.648201 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2744830548763275
[5/24] Train loss=0.2829730212688446
[10/24] Train loss=0.29949483275413513
[15/24] Train loss=0.3687613904476166
[20/24] Train loss=0.2514418065547943
Test set avg_accuracy=73.48% avg_sensitivity=67.37%, avg_specificity=75.53% avg_auc=80.01%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.303412 Test loss=0.509059 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.2948719561100006
[5/24] Train loss=0.2990495264530182
[10/24] Train loss=0.3102289140224457
[15/24] Train loss=0.3288451135158539
[20/24] Train loss=0.2541894316673279
Test set avg_accuracy=70.16% avg_sensitivity=30.97%, avg_specificity=83.32% avg_auc=68.23%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.310366 Test loss=0.544929 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.28119009733200073
[5/24] Train loss=0.27226653695106506
[10/24] Train loss=0.3379390835762024
[15/24] Train loss=0.34919866919517517
[20/24] Train loss=0.2740832269191742
Test set avg_accuracy=65.04% avg_sensitivity=52.30%, avg_specificity=69.32% avg_auc=69.29%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.319432 Test loss=0.617228 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2998201549053192
[5/24] Train loss=0.2785860598087311
[10/24] Train loss=0.3042410910129547
[15/24] Train loss=0.3411928117275238
[20/24] Train loss=0.2638019025325775
Test set avg_accuracy=76.58% avg_sensitivity=14.76%, avg_specificity=97.34% avg_auc=72.62%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.318603 Test loss=0.501127 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.283173143863678
[5/24] Train loss=0.2772703766822815
[10/24] Train loss=0.29919856786727905
[15/24] Train loss=0.3273584544658661
[20/24] Train loss=0.2537124752998352
Test set avg_accuracy=79.96% avg_sensitivity=34.02%, avg_specificity=95.39% avg_auc=83.30%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.307393 Test loss=0.490715 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2897578775882721
[5/24] Train loss=0.30001938343048096
[10/24] Train loss=0.3096468150615692
[15/24] Train loss=0.3192826807498932
[20/24] Train loss=0.2576238214969635
Test set avg_accuracy=83.52% avg_sensitivity=46.04%, avg_specificity=96.10% avg_auc=85.29%
Best model saved!! Metric=-15.0487612679741!!
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.315838 Test loss=0.399530 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.28639456629753113
[5/24] Train loss=0.28589072823524475
[10/24] Train loss=0.2994883954524994
[15/24] Train loss=0.3532510995864868
[20/24] Train loss=0.26659294962882996
Test set avg_accuracy=76.77% avg_sensitivity=56.03%, avg_specificity=83.74% avg_auc=77.86%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.309618 Test loss=0.516539 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.28938472270965576
[5/24] Train loss=0.2996828556060791
[10/24] Train loss=0.3082987070083618
[15/24] Train loss=0.32486581802368164
[20/24] Train loss=0.26059234142303467
Test set avg_accuracy=49.10% avg_sensitivity=79.70%, avg_specificity=38.82% avg_auc=63.99%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.312041 Test loss=0.762006 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.29982930421829224
[5/24] Train loss=0.28782418370246887
[10/24] Train loss=0.2913902997970581
[15/24] Train loss=0.36485177278518677
[20/24] Train loss=0.25720396637916565
Test set avg_accuracy=74.73% avg_sensitivity=0.88%, avg_specificity=99.53% avg_auc=63.64%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.309142 Test loss=0.747407 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.29161617159843445
[5/24] Train loss=0.2866058647632599
[10/24] Train loss=0.2952233850955963
[15/24] Train loss=0.3471355438232422
[20/24] Train loss=0.2577032446861267
Test set avg_accuracy=69.92% avg_sensitivity=38.53%, avg_specificity=80.47% avg_auc=70.10%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.305000 Test loss=0.551613 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.283661425113678
[5/24] Train loss=0.2946132719516754
[10/24] Train loss=0.3222128748893738
[15/24] Train loss=0.316948801279068
[20/24] Train loss=0.25826895236968994
Test set avg_accuracy=58.39% avg_sensitivity=76.59%, avg_specificity=52.27% avg_auc=69.24%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.301088 Test loss=0.722389 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.27407100796699524
[5/24] Train loss=0.277165949344635
[10/24] Train loss=0.3093473017215729
[15/24] Train loss=0.3268572688102722
[20/24] Train loss=0.2531532943248749
Test set avg_accuracy=75.91% avg_sensitivity=32.37%, avg_specificity=90.54% avg_auc=75.48%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.300649 Test loss=0.489887 Current lr=[0.000224838296036774]

[0/24] Train loss=0.27519360184669495
[5/24] Train loss=0.2748343348503113
[10/24] Train loss=0.29051998257637024
[15/24] Train loss=0.30193236470222473
[20/24] Train loss=0.24163037538528442
Test set avg_accuracy=75.09% avg_sensitivity=5.33%, avg_specificity=98.52% avg_auc=66.66%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.291357 Test loss=0.586953 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.25633886456489563
[5/24] Train loss=0.27189522981643677
[10/24] Train loss=0.2973605692386627
[15/24] Train loss=0.2914682626724243
[20/24] Train loss=0.24425217509269714
Test set avg_accuracy=75.09% avg_sensitivity=12.48%, avg_specificity=96.12% avg_auc=71.01%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.287311 Test loss=0.529096 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2696343958377838
[5/24] Train loss=0.28225451707839966
[10/24] Train loss=0.2899787425994873
[15/24] Train loss=0.3064521849155426
[20/24] Train loss=0.24598422646522522
Test set avg_accuracy=60.12% avg_sensitivity=77.16%, avg_specificity=54.39% avg_auc=71.65%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.292350 Test loss=0.679623 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2618117034435272
[5/24] Train loss=0.2628921568393707
[10/24] Train loss=0.2879713773727417
[15/24] Train loss=0.3005633056163788
[20/24] Train loss=0.23518159985542297
Test set avg_accuracy=69.86% avg_sensitivity=65.35%, avg_specificity=71.37% avg_auc=76.21%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.289415 Test loss=0.542777 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2923951745033264
[5/24] Train loss=0.27007731795310974
[10/24] Train loss=0.29139959812164307
[15/24] Train loss=0.31939902901649475
[20/24] Train loss=0.24436230957508087
Test set avg_accuracy=72.88% avg_sensitivity=27.81%, avg_specificity=88.02% avg_auc=68.19%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.295772 Test loss=0.543828 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2695397138595581
[5/24] Train loss=0.2863055169582367
[10/24] Train loss=0.31389930844306946
[15/24] Train loss=0.3048968017101288
[20/24] Train loss=0.23942522704601288
Test set avg_accuracy=60.87% avg_sensitivity=75.87%, avg_specificity=55.84% avg_auc=72.16%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.294549 Test loss=0.691232 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2695859372615814
[5/24] Train loss=0.271235853433609
[10/24] Train loss=0.28731074929237366
[15/24] Train loss=0.3055444061756134
[20/24] Train loss=0.24417898058891296
Test set avg_accuracy=61.98% avg_sensitivity=60.12%, avg_specificity=62.60% avg_auc=67.41%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.287061 Test loss=0.623949 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.26009401679039
[5/24] Train loss=0.2735874056816101
[10/24] Train loss=0.2883068919181824
[15/24] Train loss=0.296637624502182
[20/24] Train loss=0.23494991660118103
Test set avg_accuracy=75.89% avg_sensitivity=18.28%, avg_specificity=95.23% avg_auc=69.73%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.286187 Test loss=0.525500 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2660894989967346
[5/24] Train loss=0.2633078992366791
[10/24] Train loss=0.27888375520706177
[15/24] Train loss=0.3121720254421234
[20/24] Train loss=0.23669900000095367
Test set avg_accuracy=73.48% avg_sensitivity=66.75%, avg_specificity=75.73% avg_auc=78.65%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.289432 Test loss=0.505009 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.26501595973968506
[5/24] Train loss=0.260243684053421
[10/24] Train loss=0.26971718668937683
[15/24] Train loss=0.2971268892288208
[20/24] Train loss=0.24415656924247742
Test set avg_accuracy=74.53% avg_sensitivity=29.00%, avg_specificity=89.82% avg_auc=71.50%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.282881 Test loss=0.537588 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2502819299697876
[5/24] Train loss=0.27786073088645935
[10/24] Train loss=0.27107784152030945
[15/24] Train loss=0.3015943765640259
[20/24] Train loss=0.25002315640449524
Test set avg_accuracy=68.02% avg_sensitivity=37.23%, avg_specificity=78.36% avg_auc=67.96%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.284393 Test loss=0.597634 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2659032344818115
[5/24] Train loss=0.2643930912017822
[10/24] Train loss=0.27773770689964294
[15/24] Train loss=0.325182169675827
[20/24] Train loss=0.2329881191253662
Test set avg_accuracy=71.98% avg_sensitivity=21.34%, avg_specificity=88.99% avg_auc=65.15%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.287682 Test loss=0.556009 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2593706548213959
[5/24] Train loss=0.26800721883773804
[10/24] Train loss=0.27749329805374146
[15/24] Train loss=0.30939751863479614
[20/24] Train loss=0.2395455688238144
Test set avg_accuracy=75.43% avg_sensitivity=20.66%, avg_specificity=93.83% avg_auc=71.93%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.286306 Test loss=0.514976 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2613966464996338
[5/24] Train loss=0.24789835512638092
[10/24] Train loss=0.2737065255641937
[15/24] Train loss=0.3095351755619049
[20/24] Train loss=0.23255448043346405
Test set avg_accuracy=73.23% avg_sensitivity=58.78%, avg_specificity=78.08% avg_auc=76.72%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.278998 Test loss=0.510677 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2660347521305084
[5/24] Train loss=0.26559510827064514
[10/24] Train loss=0.25860387086868286
[15/24] Train loss=0.29736489057540894
[20/24] Train loss=0.23402759432792664
Test set avg_accuracy=67.42% avg_sensitivity=69.96%, avg_specificity=66.57% avg_auc=75.24%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.275953 Test loss=0.597875 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.25333473086357117
[5/24] Train loss=0.26070350408554077
[10/24] Train loss=0.26804062724113464
[15/24] Train loss=0.2846662104129791
[20/24] Train loss=0.2378596067428589
Test set avg_accuracy=69.13% avg_sensitivity=63.80%, avg_specificity=70.92% avg_auc=74.70%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.274051 Test loss=0.546131 Current lr=[0.000156543481933168]

[0/24] Train loss=0.25196176767349243
[5/24] Train loss=0.2609206438064575
[10/24] Train loss=0.2658865451812744
[15/24] Train loss=0.2972591519355774
[20/24] Train loss=0.22203455865383148
Test set avg_accuracy=62.16% avg_sensitivity=73.38%, avg_specificity=58.39% avg_auc=72.11%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.268548 Test loss=0.653847 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.24660728871822357
[5/24] Train loss=0.27223697304725647
[10/24] Train loss=0.26204508543014526
[15/24] Train loss=0.29946616291999817
[20/24] Train loss=0.22271132469177246
Test set avg_accuracy=66.33% avg_sensitivity=48.06%, avg_specificity=72.46% avg_auc=68.52%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.270060 Test loss=0.631079 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.23978611826896667
[5/24] Train loss=0.25079768896102905
[10/24] Train loss=0.2624576985836029
[15/24] Train loss=0.29541298747062683
[20/24] Train loss=0.22484619915485382
Test set avg_accuracy=66.91% avg_sensitivity=55.46%, avg_specificity=70.76% avg_auc=70.48%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.265173 Test loss=0.594960 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.23841197788715363
[5/24] Train loss=0.2487374097108841
[10/24] Train loss=0.2577385902404785
[15/24] Train loss=0.2801644206047058
[20/24] Train loss=0.22385497391223907
Test set avg_accuracy=77.28% avg_sensitivity=57.22%, avg_specificity=84.01% avg_auc=79.69%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.266921 Test loss=0.478363 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2475045919418335
[5/24] Train loss=0.2667178809642792
[10/24] Train loss=0.2698163688182831
[15/24] Train loss=0.2841031551361084
[20/24] Train loss=0.2451772838830948
Test set avg_accuracy=69.71% avg_sensitivity=76.54%, avg_specificity=67.42% avg_auc=79.51%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.272869 Test loss=0.562660 Current lr=[0.000134135431043539]

[0/24] Train loss=0.27223944664001465
[5/24] Train loss=0.2550390362739563
[10/24] Train loss=0.2838080823421478
[15/24] Train loss=0.28588157892227173
[20/24] Train loss=0.2285146862268448
Test set avg_accuracy=59.45% avg_sensitivity=72.92%, avg_specificity=54.93% avg_auc=69.48%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.273375 Test loss=0.752167 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24596688151359558
[5/24] Train loss=0.25931599736213684
[10/24] Train loss=0.25772032141685486
[15/24] Train loss=0.2789473235607147
[20/24] Train loss=0.23087452352046967
Test set avg_accuracy=74.28% avg_sensitivity=41.12%, avg_specificity=85.42% avg_auc=74.06%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.262318 Test loss=0.528114 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2424437701702118
[5/24] Train loss=0.26222527027130127
[10/24] Train loss=0.2540706992149353
[15/24] Train loss=0.2943255305290222
[20/24] Train loss=0.21669720113277435
Test set avg_accuracy=67.37% avg_sensitivity=48.58%, avg_specificity=73.68% avg_auc=68.15%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.260418 Test loss=0.697132 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.23172231018543243
[5/24] Train loss=0.26689648628234863
[10/24] Train loss=0.25533849000930786
[15/24] Train loss=0.27425044775009155
[20/24] Train loss=0.22652560472488403
Test set avg_accuracy=71.58% avg_sensitivity=36.82%, avg_specificity=83.25% avg_auc=69.84%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.256139 Test loss=0.579255 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.22721152007579803
[5/24] Train loss=0.23635181784629822
[10/24] Train loss=0.25893473625183105
[15/24] Train loss=0.2520918548107147
[20/24] Train loss=0.21303674578666687
Test set avg_accuracy=67.86% avg_sensitivity=47.85%, avg_specificity=74.59% avg_auc=68.63%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.249228 Test loss=0.622402 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.23392555117607117
[5/24] Train loss=0.25002598762512207
[10/24] Train loss=0.25205984711647034
[15/24] Train loss=0.26994457840919495
[20/24] Train loss=0.21221640706062317
Test set avg_accuracy=73.98% avg_sensitivity=26.93%, avg_specificity=89.79% avg_auc=70.19%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.250912 Test loss=0.571538 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2353886365890503
[5/24] Train loss=0.2458936721086502
[10/24] Train loss=0.24049970507621765
[15/24] Train loss=0.27909916639328003
[20/24] Train loss=0.21318331360816956
Test set avg_accuracy=69.44% avg_sensitivity=50.96%, avg_specificity=75.65% avg_auc=71.67%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.248421 Test loss=0.634170 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.22519440948963165
[5/24] Train loss=0.23981261253356934
[10/24] Train loss=0.25188785791397095
[15/24] Train loss=0.2819136679172516
[20/24] Train loss=0.2094598263502121
Test set avg_accuracy=73.52% avg_sensitivity=49.15%, avg_specificity=81.70% avg_auc=73.49%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.247063 Test loss=0.544652 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.22446346282958984
[5/24] Train loss=0.2397240400314331
[10/24] Train loss=0.24854092299938202
[15/24] Train loss=0.2656049430370331
[20/24] Train loss=0.20683349668979645
Test set avg_accuracy=68.44% avg_sensitivity=48.16%, avg_specificity=75.25% avg_auc=69.12%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.243396 Test loss=0.605557 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.22432762384414673
[5/24] Train loss=0.24477706849575043
[10/24] Train loss=0.2494182139635086
[15/24] Train loss=0.274228036403656
[20/24] Train loss=0.20987798273563385
Test set avg_accuracy=74.70% avg_sensitivity=13.93%, avg_specificity=95.11% avg_auc=65.28%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.246847 Test loss=0.624882 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.23011553287506104
[5/24] Train loss=0.23844678699970245
[10/24] Train loss=0.2465735226869583
[15/24] Train loss=0.2680542767047882
[20/24] Train loss=0.2042345404624939
Test set avg_accuracy=72.16% avg_sensitivity=56.24%, avg_specificity=77.51% avg_auc=76.54%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.244986 Test loss=0.512481 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.22284264862537384
[5/24] Train loss=0.2369609773159027
[10/24] Train loss=0.2503407895565033
[15/24] Train loss=0.2616094946861267
[20/24] Train loss=0.20950041711330414
Test set avg_accuracy=75.65% avg_sensitivity=37.39%, avg_specificity=88.50% avg_auc=73.48%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.242490 Test loss=0.541073 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.2219160795211792
[5/24] Train loss=0.24553540349006653
[10/24] Train loss=0.24410100281238556
[15/24] Train loss=0.26670196652412415
[20/24] Train loss=0.2022237628698349
Test set avg_accuracy=69.54% avg_sensitivity=59.19%, avg_specificity=73.02% avg_auc=74.64%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.245049 Test loss=0.563478 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.2134963572025299
[5/24] Train loss=0.22863812744617462
[10/24] Train loss=0.24796947836875916
[15/24] Train loss=0.2631106972694397
[20/24] Train loss=0.19956062734127045
Test set avg_accuracy=69.22% avg_sensitivity=70.07%, avg_specificity=68.93% avg_auc=77.00%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.238717 Test loss=0.563969 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.22047436237335205
[5/24] Train loss=0.2324434518814087
[10/24] Train loss=0.238679900765419
[15/24] Train loss=0.25936809182167053
[20/24] Train loss=0.19691982865333557
Test set avg_accuracy=73.46% avg_sensitivity=47.95%, avg_specificity=82.03% avg_auc=73.94%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.236374 Test loss=0.554830 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.21796756982803345
[5/24] Train loss=0.2252940833568573
[10/24] Train loss=0.24242396652698517
[15/24] Train loss=0.2544533908367157
[20/24] Train loss=0.1966790407896042
Test set avg_accuracy=69.30% avg_sensitivity=64.73%, avg_specificity=70.83% avg_auc=75.14%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.233578 Test loss=0.590474 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.21748104691505432
[5/24] Train loss=0.2150728404521942
[10/24] Train loss=0.2404206395149231
[15/24] Train loss=0.25732526183128357
[20/24] Train loss=0.1910010725259781
Test set avg_accuracy=72.71% avg_sensitivity=64.22%, avg_specificity=75.56% avg_auc=77.47%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.231390 Test loss=0.541746 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.2092481404542923
[5/24] Train loss=0.22129300236701965
[10/24] Train loss=0.2372128665447235
[15/24] Train loss=0.24874046444892883
[20/24] Train loss=0.19176319241523743
Test set avg_accuracy=68.31% avg_sensitivity=71.36%, avg_specificity=67.28% avg_auc=76.25%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.229162 Test loss=0.616087 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.20983363687992096
[5/24] Train loss=0.22695167362689972
[10/24] Train loss=0.23356464505195618
[15/24] Train loss=0.26631495356559753
[20/24] Train loss=0.19081881642341614
Test set avg_accuracy=71.65% avg_sensitivity=69.96%, avg_specificity=72.22% avg_auc=78.16%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.229998 Test loss=0.556551 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.20751404762268066
[5/24] Train loss=0.2285078465938568
[10/24] Train loss=0.2315826117992401
[15/24] Train loss=0.2525419592857361
[20/24] Train loss=0.19596028327941895
Test set avg_accuracy=77.33% avg_sensitivity=71.88%, avg_specificity=79.16% avg_auc=84.12%
Best model saved!! Metric=-13.507259904722062!!
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.233471 Test loss=0.457617 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.207368403673172
[5/24] Train loss=0.23369288444519043
[10/24] Train loss=0.2358483076095581
[15/24] Train loss=0.25325676798820496
[20/24] Train loss=0.19644197821617126
Test set avg_accuracy=71.77% avg_sensitivity=60.59%, avg_specificity=75.53% avg_auc=74.75%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.235862 Test loss=0.580272 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2210831493139267
[5/24] Train loss=0.22999434173107147
[10/24] Train loss=0.2519509196281433
[15/24] Train loss=0.2547113001346588
[20/24] Train loss=0.19336986541748047
Test set avg_accuracy=70.30% avg_sensitivity=41.64%, avg_specificity=79.93% avg_auc=69.20%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.235940 Test loss=0.614805 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.21371501684188843
[5/24] Train loss=0.2197479009628296
[10/24] Train loss=0.2341390699148178
[15/24] Train loss=0.256727397441864
[20/24] Train loss=0.19476133584976196
Test set avg_accuracy=67.08% avg_sensitivity=52.87%, avg_specificity=71.86% avg_auc=69.56%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.231800 Test loss=0.611606 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.21931923925876617
[5/24] Train loss=0.24061205983161926
[10/24] Train loss=0.22835278511047363
[15/24] Train loss=0.24970631301403046
[20/24] Train loss=0.18697288632392883
Test set avg_accuracy=73.22% avg_sensitivity=34.70%, avg_specificity=86.15% avg_auc=70.33%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.231512 Test loss=0.562631 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.21161793172359467
[5/24] Train loss=0.21676887571811676
[10/24] Train loss=0.2257343977689743
[15/24] Train loss=0.24689319729804993
[20/24] Train loss=0.18370257318019867
Test set avg_accuracy=74.93% avg_sensitivity=44.48%, avg_specificity=85.16% avg_auc=74.88%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.224931 Test loss=0.538182 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.2094728946685791
[5/24] Train loss=0.21791909635066986
[10/24] Train loss=0.21854084730148315
[15/24] Train loss=0.24000796675682068
[20/24] Train loss=0.18333350121974945
Test set avg_accuracy=69.91% avg_sensitivity=59.55%, avg_specificity=73.39% avg_auc=73.64%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.223881 Test loss=0.587776 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.2064557522535324
[5/24] Train loss=0.2114526629447937
[10/24] Train loss=0.21888117492198944
[15/24] Train loss=0.24794498085975647
[20/24] Train loss=0.1807159185409546
Test set avg_accuracy=71.72% avg_sensitivity=42.88%, avg_specificity=81.41% avg_auc=70.98%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.220184 Test loss=0.585631 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.20512855052947998
[5/24] Train loss=0.21292567253112793
[10/24] Train loss=0.21732017397880554
[15/24] Train loss=0.23688550293445587
[20/24] Train loss=0.1778969019651413
Test set avg_accuracy=73.39% avg_sensitivity=48.06%, avg_specificity=81.89% avg_auc=73.37%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.218112 Test loss=0.554515 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.20370738208293915
[5/24] Train loss=0.21605965495109558
[10/24] Train loss=0.21497774124145508
[15/24] Train loss=0.2435539960861206
[20/24] Train loss=0.18153513967990875
Test set avg_accuracy=71.98% avg_sensitivity=46.76%, avg_specificity=80.45% avg_auc=72.22%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.217018 Test loss=0.566850 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1999415159225464
[5/24] Train loss=0.20958134531974792
[10/24] Train loss=0.21936683356761932
[15/24] Train loss=0.24596939980983734
[20/24] Train loss=0.1809556484222412
Test set avg_accuracy=75.60% avg_sensitivity=37.75%, avg_specificity=88.31% avg_auc=71.75%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.215356 Test loss=0.566479 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.2044689804315567
[5/24] Train loss=0.20376263558864594
[10/24] Train loss=0.21694296598434448
[15/24] Train loss=0.2457808256149292
[20/24] Train loss=0.17661549150943756
Test set avg_accuracy=70.62% avg_sensitivity=52.62%, avg_specificity=76.67% avg_auc=72.76%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.214025 Test loss=0.580404 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.19724681973457336
[5/24] Train loss=0.2104901373386383
[10/24] Train loss=0.21149905025959015
[15/24] Train loss=0.23131988942623138
[20/24] Train loss=0.17686018347740173
Test set avg_accuracy=72.76% avg_sensitivity=45.78%, avg_specificity=81.82% avg_auc=72.90%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.212990 Test loss=0.561853 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.19898167252540588
[5/24] Train loss=0.20514638721942902
[10/24] Train loss=0.2122197300195694
[15/24] Train loss=0.23967458307743073
[20/24] Train loss=0.17373111844062805
Test set avg_accuracy=73.31% avg_sensitivity=40.34%, avg_specificity=84.38% avg_auc=71.31%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.211171 Test loss=0.578660 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.2010207325220108
[5/24] Train loss=0.2059587836265564
[10/24] Train loss=0.21367111802101135
[15/24] Train loss=0.2360653430223465
[20/24] Train loss=0.17416894435882568
Test set avg_accuracy=72.60% avg_sensitivity=40.60%, avg_specificity=83.35% avg_auc=72.08%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.211299 Test loss=0.565896 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.19692620635032654
[5/24] Train loss=0.20636063814163208
[10/24] Train loss=0.20533905923366547
[15/24] Train loss=0.22828830778598785
[20/24] Train loss=0.17483854293823242
Test set avg_accuracy=71.86% avg_sensitivity=47.64%, avg_specificity=80.00% avg_auc=72.61%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.209653 Test loss=0.576002 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.20254947245121002
[5/24] Train loss=0.20601043105125427
[10/24] Train loss=0.21523775160312653
[15/24] Train loss=0.24310243129730225
[20/24] Train loss=0.1724347472190857
Test set avg_accuracy=71.24% avg_sensitivity=49.04%, avg_specificity=78.69% avg_auc=72.25%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.210023 Test loss=0.583393 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.19500350952148438
[5/24] Train loss=0.2020004391670227
[10/24] Train loss=0.21317186951637268
[15/24] Train loss=0.23356537520885468
[20/24] Train loss=0.17210358381271362
Test set avg_accuracy=72.21% avg_sensitivity=45.47%, avg_specificity=81.20% avg_auc=72.16%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.209681 Test loss=0.573930 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.19652870297431946
[5/24] Train loss=0.20489245653152466
[10/24] Train loss=0.21391133964061737
[15/24] Train loss=0.23234032094478607
[20/24] Train loss=0.1716873198747635
Test set avg_accuracy=72.25% avg_sensitivity=46.71%, avg_specificity=80.83% avg_auc=72.29%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.208689 Test loss=0.572266 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.19508473575115204
[5/24] Train loss=0.2034490704536438
[10/24] Train loss=0.20757724344730377
[15/24] Train loss=0.23553121089935303
[20/24] Train loss=0.17132027447223663
Test set avg_accuracy=72.94% avg_sensitivity=44.74%, avg_specificity=82.41% avg_auc=72.08%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.207972 Test loss=0.569967 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.19524304568767548
[5/24] Train loss=0.1955123096704483
[10/24] Train loss=0.209817573428154
[15/24] Train loss=0.22851450741291046
[20/24] Train loss=0.1708560287952423
Test set avg_accuracy=72.66% avg_sensitivity=44.12%, avg_specificity=82.24% avg_auc=71.85%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.208662 Test loss=0.572371 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.19602641463279724
[5/24] Train loss=0.20561416447162628
[10/24] Train loss=0.20452456176280975
[15/24] Train loss=0.22555196285247803
[20/24] Train loss=0.17155340313911438
Test set avg_accuracy=71.48% avg_sensitivity=47.75%, avg_specificity=79.46% avg_auc=72.04%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.207623 Test loss=0.578360 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.19963888823986053
[5/24] Train loss=0.19814234972000122
[10/24] Train loss=0.21092846989631653
[15/24] Train loss=0.2417086958885193
[20/24] Train loss=0.16959770023822784
Test set avg_accuracy=72.45% avg_sensitivity=45.62%, avg_specificity=81.46% avg_auc=72.15%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.208555 Test loss=0.573170 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1944534033536911
[5/24] Train loss=0.19976620376110077
[10/24] Train loss=0.20452964305877686
[15/24] Train loss=0.22665053606033325
[20/24] Train loss=0.1706075221300125
Test set avg_accuracy=72.83% avg_sensitivity=45.99%, avg_specificity=81.84% avg_auc=72.65%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.207759 Test loss=0.567407 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.19926446676254272
[5/24] Train loss=0.20002397894859314
[10/24] Train loss=0.21175891160964966
[15/24] Train loss=0.23991909623146057
[20/24] Train loss=0.17048677802085876
Test set avg_accuracy=72.42% avg_sensitivity=46.92%, avg_specificity=80.99% avg_auc=72.45%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.206947 Test loss=0.572316 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.19383567571640015
[5/24] Train loss=0.2009088695049286
[10/24] Train loss=0.20641185343265533
[15/24] Train loss=0.22825193405151367
[20/24] Train loss=0.17124077677726746
Test set avg_accuracy=72.41% avg_sensitivity=47.54%, avg_specificity=80.76% avg_auc=72.65%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.207557 Test loss=0.571108 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1964406818151474
[5/24] Train loss=0.19785284996032715
[10/24] Train loss=0.20583567023277283
[15/24] Train loss=0.2311544269323349
[20/24] Train loss=0.17440827190876007
Test set avg_accuracy=71.98% avg_sensitivity=48.27%, avg_specificity=79.94% avg_auc=72.43%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.207131 Test loss=0.575058 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.19125929474830627
[5/24] Train loss=0.1965818554162979
[10/24] Train loss=0.21082577109336853
[15/24] Train loss=0.2337198108434677
[20/24] Train loss=0.1674339771270752
Test set avg_accuracy=72.46% avg_sensitivity=47.38%, avg_specificity=80.88% avg_auc=72.65%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.207432 Test loss=0.570570 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.19324953854084015
[5/24] Train loss=0.19874067604541779
[10/24] Train loss=0.21302442252635956
[15/24] Train loss=0.230278879404068
[20/24] Train loss=0.16811934113502502
Test set avg_accuracy=72.71% avg_sensitivity=47.59%, avg_specificity=81.14% avg_auc=72.92%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.207170 Test loss=0.567756 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.19350506365299225
[5/24] Train loss=0.20342954993247986
[10/24] Train loss=0.21466653048992157
[15/24] Train loss=0.2248484045267105
[20/24] Train loss=0.17082959413528442
Test set avg_accuracy=72.46% avg_sensitivity=47.49%, avg_specificity=80.85% avg_auc=72.72%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.207789 Test loss=0.570385 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=77.33% sen=71.88%, spe=79.16%, auc=84.12%!
Fold[8] Avg_overlap=0.58%(±0.23480486031656628)
[0/23] Train loss=0.7261601090431213
[5/23] Train loss=0.7267014384269714
[10/23] Train loss=0.7269709706306458
[15/23] Train loss=0.7282430529594421
[20/23] Train loss=0.7174975275993347
Test set avg_accuracy=52.02% avg_sensitivity=47.71%, avg_specificity=53.39% avg_auc=50.78%
Best model saved!! Metric=-122.09961033450752!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=0.723183 Test loss=0.698132 Current lr=[1.23514552994466e-05]

[0/23] Train loss=0.7207949757575989
[5/23] Train loss=0.7219408750534058
[10/23] Train loss=0.7193186283111572
[15/23] Train loss=0.7115435600280762
[20/23] Train loss=0.7138645648956299
Test set avg_accuracy=55.34% avg_sensitivity=42.96%, avg_specificity=59.28% avg_auc=51.11%
Best model saved!! Metric=-117.30296313996892!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.717341 Test loss=0.686723 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=0.7091653943061829
[5/23] Train loss=0.7179409265518188
[10/23] Train loss=0.7059354782104492
[15/23] Train loss=0.7145140767097473
[20/23] Train loss=0.7038896083831787
Test set avg_accuracy=65.12% avg_sensitivity=24.80%, avg_specificity=77.96% avg_auc=51.76%
Best model saved!! Metric=-106.36755967443865!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.708982 Test loss=0.674224 Current lr=[1.515281266696464e-05]

[0/23] Train loss=0.7068420648574829
[5/23] Train loss=0.7038935422897339
[10/23] Train loss=0.7081417441368103
[15/23] Train loss=0.6975463032722473
[20/23] Train loss=0.6943382024765015
Test set avg_accuracy=64.99% avg_sensitivity=25.34%, avg_specificity=77.61% avg_auc=52.01%
Best model saved!! Metric=-106.05400275205434!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.701116 Test loss=0.673402 Current lr=[1.758904040319645e-05]

[0/23] Train loss=0.6901684999465942
[5/23] Train loss=0.6993714570999146
[10/23] Train loss=0.6947665214538574
[15/23] Train loss=0.68805992603302
[20/23] Train loss=0.6855929493904114
Test set avg_accuracy=64.75% avg_sensitivity=26.79%, avg_specificity=76.84% avg_auc=52.38%
Best model saved!! Metric=-105.23154261213556!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.693047 Test loss=0.675235 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=0.68195641040802
[5/23] Train loss=0.6927899122238159
[10/23] Train loss=0.6859119534492493
[15/23] Train loss=0.6750142574310303
[20/23] Train loss=0.6737598180770874
Test set avg_accuracy=65.04% avg_sensitivity=26.36%, avg_specificity=77.36% avg_auc=53.21%
Best model saved!! Metric=-104.03525468010712!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.681813 Test loss=0.666319 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=0.6674914360046387
[5/23] Train loss=0.6803886890411377
[10/23] Train loss=0.6771823167800903
[15/23] Train loss=0.6625764966011047
[20/23] Train loss=0.6551486253738403
Test set avg_accuracy=68.44% avg_sensitivity=20.59%, avg_specificity=83.67% avg_auc=53.73%
Best model saved!! Metric=-99.56255552792013!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.670566 Test loss=0.656835 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=0.661423921585083
[5/23] Train loss=0.6550806760787964
[10/23] Train loss=0.6614329814910889
[15/23] Train loss=0.6594955325126648
[20/23] Train loss=0.639140248298645
Test set avg_accuracy=65.73% avg_sensitivity=26.36%, avg_specificity=78.27% avg_auc=54.13%
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.659209 Test loss=0.652526 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.6471288204193115
[5/23] Train loss=0.6552499532699585
[10/23] Train loss=0.647977888584137
[15/23] Train loss=0.6377633810043335
[20/23] Train loss=0.6315433382987976
Test set avg_accuracy=62.42% avg_sensitivity=31.32%, avg_specificity=72.33% avg_auc=54.53%
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.647451 Test loss=0.649030 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.6340121626853943
[5/23] Train loss=0.6377454400062561
[10/23] Train loss=0.6406537890434265
[15/23] Train loss=0.6313109993934631
[20/23] Train loss=0.6131837964057922
Test set avg_accuracy=65.64% avg_sensitivity=25.34%, avg_specificity=78.47% avg_auc=54.92%
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.635324 Test loss=0.629064 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.6219730973243713
[5/23] Train loss=0.6211788654327393
[10/23] Train loss=0.6253554224967957
[15/23] Train loss=0.6052091717720032
[20/23] Train loss=0.5978361368179321
Test set avg_accuracy=65.52% avg_sensitivity=26.36%, avg_specificity=77.99% avg_auc=56.40%
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.621697 Test loss=0.623964 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.6079151630401611
[5/23] Train loss=0.6060320138931274
[10/23] Train loss=0.6106777787208557
[15/23] Train loss=0.5948526263237
[20/23] Train loss=0.5776498317718506
Test set avg_accuracy=71.99% avg_sensitivity=18.87%, avg_specificity=88.91% avg_auc=58.82%
Best model saved!! Metric=-87.4107068928369!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.608780 Test loss=0.599987 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.5946065783500671
[5/23] Train loss=0.5902722477912903
[10/23] Train loss=0.5947933793067932
[15/23] Train loss=0.5787787437438965
[20/23] Train loss=0.5559373497962952
Test set avg_accuracy=75.39% avg_sensitivity=14.88%, avg_specificity=94.66% avg_auc=62.71%
Best model saved!! Metric=-78.36153075581596!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.593553 Test loss=0.546153 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.5783956050872803
[5/23] Train loss=0.576465368270874
[10/23] Train loss=0.579166054725647
[15/23] Train loss=0.55841463804245
[20/23] Train loss=0.5292219519615173
Test set avg_accuracy=75.98% avg_sensitivity=18.60%, avg_specificity=94.25% avg_auc=66.09%
Best model saved!! Metric=-71.08342384938629!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.574610 Test loss=0.526903 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.549450695514679
[5/23] Train loss=0.5384297370910645
[10/23] Train loss=0.5520613789558411
[15/23] Train loss=0.5406758785247803
[20/23] Train loss=0.5009398460388184
Test set avg_accuracy=76.05% avg_sensitivity=18.33%, avg_specificity=94.44% avg_auc=66.76%
Best model saved!! Metric=-70.42079345276657!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.547448 Test loss=0.563000 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.515188992023468
[5/23] Train loss=0.5144628286361694
[10/23] Train loss=0.5231930613517761
[15/23] Train loss=0.5097749829292297
[20/23] Train loss=0.47055158019065857
Test set avg_accuracy=76.64% avg_sensitivity=19.35%, avg_specificity=94.88% avg_auc=66.48%
Best model saved!! Metric=-68.63776654124683!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.521408 Test loss=0.609107 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.49354949593544006
[5/23] Train loss=0.4938599467277527
[10/23] Train loss=0.49227800965309143
[15/23] Train loss=0.4804825186729431
[20/23] Train loss=0.4420911967754364
Test set avg_accuracy=77.06% avg_sensitivity=27.60%, avg_specificity=92.81% avg_auc=75.81%
Best model saved!! Metric=-52.72158690071298!!
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.493166 Test loss=0.495270 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.45867979526519775
[5/23] Train loss=0.47862356901168823
[10/23] Train loss=0.4649312496185303
[15/23] Train loss=0.44440919160842896
[20/23] Train loss=0.42438316345214844
Test set avg_accuracy=78.61% avg_sensitivity=41.83%, avg_specificity=90.32% avg_auc=80.26%
Best model saved!! Metric=-34.97922687613997!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.470251 Test loss=0.445883 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.44188281893730164
[5/23] Train loss=0.4596576988697052
[10/23] Train loss=0.44030770659446716
[15/23] Train loss=0.4349674582481384
[20/23] Train loss=0.40980812907218933
Test set avg_accuracy=73.71% avg_sensitivity=58.44%, avg_specificity=78.58% avg_auc=74.91%
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.451860 Test loss=0.560473 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.42861634492874146
[5/23] Train loss=0.4463955760002136
[10/23] Train loss=0.4291597902774811
[15/23] Train loss=0.424648255109787
[20/23] Train loss=0.40105342864990234
Test set avg_accuracy=76.95% avg_sensitivity=60.00%, avg_specificity=82.35% avg_auc=77.40%
Best model saved!! Metric=-29.299628837789058!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.438532 Test loss=0.544596 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.42364823818206787
[5/23] Train loss=0.4356708824634552
[10/23] Train loss=0.4225691258907318
[15/23] Train loss=0.41696375608444214
[20/23] Train loss=0.3908154368400574
Test set avg_accuracy=55.38% avg_sensitivity=65.61%, avg_specificity=52.12% avg_auc=65.17%
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.428531 Test loss=0.662501 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.40345442295074463
[5/23] Train loss=0.43288856744766235
[10/23] Train loss=0.41441991925239563
[15/23] Train loss=0.4197544455528259
[20/23] Train loss=0.3839346766471863
Test set avg_accuracy=62.19% avg_sensitivity=62.70%, avg_specificity=62.03% avg_auc=69.37%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.420836 Test loss=0.631072 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.3952765464782715
[5/23] Train loss=0.4246729016304016
[10/23] Train loss=0.41436153650283813
[15/23] Train loss=0.40643545985221863
[20/23] Train loss=0.37556126713752747
Test set avg_accuracy=57.25% avg_sensitivity=62.26%, avg_specificity=55.66% avg_auc=64.00%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.415943 Test loss=0.656635 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.39531785249710083
[5/23] Train loss=0.4179970622062683
[10/23] Train loss=0.4085232615470886
[15/23] Train loss=0.39874276518821716
[20/23] Train loss=0.37511470913887024
Test set avg_accuracy=80.38% avg_sensitivity=50.35%, avg_specificity=89.94% avg_auc=83.87%
Best model saved!! Metric=-21.45937048715146!!
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.411867 Test loss=0.415830 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.3991701006889343
[5/23] Train loss=0.4087972939014435
[10/23] Train loss=0.3996674418449402
[15/23] Train loss=0.4021178185939789
[20/23] Train loss=0.3638715445995331
Test set avg_accuracy=80.43% avg_sensitivity=50.24%, avg_specificity=90.04% avg_auc=83.04%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.409490 Test loss=0.424220 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.39853912591934204
[5/23] Train loss=0.40919673442840576
[10/23] Train loss=0.39981573820114136
[15/23] Train loss=0.41056281328201294
[20/23] Train loss=0.3538506329059601
Test set avg_accuracy=59.45% avg_sensitivity=67.17%, avg_specificity=57.00% avg_auc=67.67%
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.403646 Test loss=0.649754 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.3906218409538269
[5/23] Train loss=0.40407589077949524
[10/23] Train loss=0.39964738488197327
[15/23] Train loss=0.4057208001613617
[20/23] Train loss=0.3557404577732086
Test set avg_accuracy=69.26% avg_sensitivity=61.35%, avg_specificity=71.78% avg_auc=73.11%
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.399059 Test loss=0.564226 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.3701149523258209
[5/23] Train loss=0.40864789485931396
[10/23] Train loss=0.3874174952507019
[15/23] Train loss=0.3970641791820526
[20/23] Train loss=0.35600778460502625
Test set avg_accuracy=69.86% avg_sensitivity=67.71%, avg_specificity=70.54% avg_auc=76.39%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.397418 Test loss=0.573551 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.3717583417892456
[5/23] Train loss=0.4085397720336914
[10/23] Train loss=0.381791353225708
[15/23] Train loss=0.3983635902404785
[20/23] Train loss=0.3498847186565399
Test set avg_accuracy=70.17% avg_sensitivity=53.37%, avg_specificity=75.52% avg_auc=71.62%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.394261 Test loss=0.573469 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.3745709955692291
[5/23] Train loss=0.4014272391796112
[10/23] Train loss=0.39133420586586
[15/23] Train loss=0.3943488299846649
[20/23] Train loss=0.3409687876701355
Test set avg_accuracy=67.67% avg_sensitivity=65.82%, avg_specificity=68.26% avg_auc=73.47%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.390087 Test loss=0.597591 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.3812443017959595
[5/23] Train loss=0.38081100583076477
[10/23] Train loss=0.3853399455547333
[15/23] Train loss=0.3957083821296692
[20/23] Train loss=0.3379959464073181
Test set avg_accuracy=64.95% avg_sensitivity=64.91%, avg_specificity=64.96% avg_auc=71.31%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.387683 Test loss=0.616236 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.3620383143424988
[5/23] Train loss=0.388356477022171
[10/23] Train loss=0.3827398419380188
[15/23] Train loss=0.38625362515449524
[20/23] Train loss=0.3363155722618103
Test set avg_accuracy=81.25% avg_sensitivity=45.34%, avg_specificity=92.69% avg_auc=85.38%
Best model saved!! Metric=-21.344028434922443!!
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.379745 Test loss=0.398276 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.3569830060005188
[5/23] Train loss=0.38524317741394043
[10/23] Train loss=0.3846668303012848
[15/23] Train loss=0.3788033425807953
[20/23] Train loss=0.3447984755039215
Test set avg_accuracy=65.77% avg_sensitivity=58.33%, avg_specificity=68.14% avg_auc=69.39%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.378600 Test loss=0.600568 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.35215646028518677
[5/23] Train loss=0.3759881258010864
[10/23] Train loss=0.3754330575466156
[15/23] Train loss=0.3794346749782562
[20/23] Train loss=0.3233669698238373
Test set avg_accuracy=63.37% avg_sensitivity=66.47%, avg_specificity=62.39% avg_auc=71.43%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.373223 Test loss=0.619538 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.36237633228302
[5/23] Train loss=0.38130971789360046
[10/23] Train loss=0.3672783672809601
[15/23] Train loss=0.3687167167663574
[20/23] Train loss=0.331172376871109
Test set avg_accuracy=66.46% avg_sensitivity=70.03%, avg_specificity=65.32% avg_auc=74.87%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.371010 Test loss=0.600388 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.35264506936073303
[5/23] Train loss=0.37239381670951843
[10/23] Train loss=0.3569353222846985
[15/23] Train loss=0.3818148672580719
[20/23] Train loss=0.32498323917388916
Test set avg_accuracy=64.83% avg_sensitivity=67.28%, avg_specificity=64.05% avg_auc=73.71%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.366771 Test loss=0.594997 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.34300267696380615
[5/23] Train loss=0.3591443598270416
[10/23] Train loss=0.3639054596424103
[15/23] Train loss=0.36440256237983704
[20/23] Train loss=0.3209984004497528
Test set avg_accuracy=72.50% avg_sensitivity=43.67%, avg_specificity=81.68% avg_auc=71.43%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.359492 Test loss=0.550242 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.34362420439720154
[5/23] Train loss=0.36100780963897705
[10/23] Train loss=0.35741978883743286
[15/23] Train loss=0.36662015318870544
[20/23] Train loss=0.3189193308353424
Test set avg_accuracy=59.18% avg_sensitivity=66.74%, avg_specificity=56.77% avg_auc=66.66%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.358388 Test loss=0.695356 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.3390714228153229
[5/23] Train loss=0.36440029740333557
[10/23] Train loss=0.36122673749923706
[15/23] Train loss=0.3646667003631592
[20/23] Train loss=0.3232273757457733
Test set avg_accuracy=63.05% avg_sensitivity=58.81%, avg_specificity=64.39% avg_auc=67.77%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.362530 Test loss=0.630703 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.3439909517765045
[5/23] Train loss=0.3534746468067169
[10/23] Train loss=0.354112833738327
[15/23] Train loss=0.3675980567932129
[20/23] Train loss=0.3388805687427521
Test set avg_accuracy=65.65% avg_sensitivity=46.58%, avg_specificity=71.73% avg_auc=67.11%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.359071 Test loss=0.596199 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.3421488106250763
[5/23] Train loss=0.3760330379009247
[10/23] Train loss=0.3513103127479553
[15/23] Train loss=0.37357786297798157
[20/23] Train loss=0.3256723880767822
Test set avg_accuracy=81.72% avg_sensitivity=34.50%, avg_specificity=96.76% avg_auc=84.07%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.360971 Test loss=0.409055 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.33635154366493225
[5/23] Train loss=0.3460863530635834
[10/23] Train loss=0.3559463918209076
[15/23] Train loss=0.35017943382263184
[20/23] Train loss=0.30951792001724243
Test set avg_accuracy=80.56% avg_sensitivity=49.49%, avg_specificity=90.45% avg_auc=81.62%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.351482 Test loss=0.439651 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.3336283564567566
[5/23] Train loss=0.36620864272117615
[10/23] Train loss=0.34321001172065735
[15/23] Train loss=0.34985899925231934
[20/23] Train loss=0.3058118224143982
Test set avg_accuracy=73.02% avg_sensitivity=61.19%, avg_specificity=76.79% avg_auc=78.26%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.352984 Test loss=0.502141 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.3265015780925751
[5/23] Train loss=0.34282276034355164
[10/23] Train loss=0.34605368971824646
[15/23] Train loss=0.346752405166626
[20/23] Train loss=0.30344435572624207
Test set avg_accuracy=68.62% avg_sensitivity=60.00%, avg_specificity=71.36% avg_auc=72.87%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.344539 Test loss=0.569941 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.31544336676597595
[5/23] Train loss=0.3314061760902405
[10/23] Train loss=0.3486809730529785
[15/23] Train loss=0.3277610242366791
[20/23] Train loss=0.3005748391151428
Test set avg_accuracy=72.21% avg_sensitivity=60.70%, avg_specificity=75.88% avg_auc=75.14%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.339411 Test loss=0.552917 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.3081902861595154
[5/23] Train loss=0.32979631423950195
[10/23] Train loss=0.33896079659461975
[15/23] Train loss=0.3440830409526825
[20/23] Train loss=0.3039540648460388
Test set avg_accuracy=82.41% avg_sensitivity=41.46%, avg_specificity=95.45% avg_auc=85.10%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.340717 Test loss=0.409228 Current lr=[0.000299926900870094]

[0/23] Train loss=0.33697593212127686
[5/23] Train loss=0.3724137842655182
[10/23] Train loss=0.3588767647743225
[15/23] Train loss=0.3392215371131897
[20/23] Train loss=0.29837360978126526
Test set avg_accuracy=79.96% avg_sensitivity=41.94%, avg_specificity=92.07% avg_auc=78.30%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.346904 Test loss=0.489505 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.31489405035972595
[5/23] Train loss=0.3520388603210449
[10/23] Train loss=0.3633543848991394
[15/23] Train loss=0.3282948434352875
[20/23] Train loss=0.3069794774055481
Test set avg_accuracy=71.37% avg_sensitivity=53.32%, avg_specificity=77.12% avg_auc=74.19%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.345650 Test loss=0.535089 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.32167842984199524
[5/23] Train loss=0.3417368233203888
[10/23] Train loss=0.3422621488571167
[15/23] Train loss=0.3363364636898041
[20/23] Train loss=0.3008924126625061
Test set avg_accuracy=72.49% avg_sensitivity=36.71%, avg_specificity=83.88% avg_auc=71.03%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.341021 Test loss=0.522872 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.2966809868812561
[5/23] Train loss=0.31781598925590515
[10/23] Train loss=0.34925636649131775
[15/23] Train loss=0.32673853635787964
[20/23] Train loss=0.3097626268863678
Test set avg_accuracy=76.55% avg_sensitivity=29.38%, avg_specificity=91.57% avg_auc=72.25%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.333263 Test loss=0.535604 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.30291947722435
[5/23] Train loss=0.36210545897483826
[10/23] Train loss=0.33721885085105896
[15/23] Train loss=0.314212441444397
[20/23] Train loss=0.2911263108253479
Test set avg_accuracy=71.61% avg_sensitivity=47.98%, avg_specificity=79.14% avg_auc=73.41%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.329507 Test loss=0.523744 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3088730573654175
[5/23] Train loss=0.33430197834968567
[10/23] Train loss=0.33401092886924744
[15/23] Train loss=0.32747575640678406
[20/23] Train loss=0.29131433367729187
Test set avg_accuracy=77.81% avg_sensitivity=24.85%, avg_specificity=94.68% avg_auc=73.96%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.327417 Test loss=0.496344 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.3005969524383545
[5/23] Train loss=0.3222755491733551
[10/23] Train loss=0.34037071466445923
[15/23] Train loss=0.33013206720352173
[20/23] Train loss=0.29841870069503784
Test set avg_accuracy=69.06% avg_sensitivity=33.96%, avg_specificity=80.24% avg_auc=66.15%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.333487 Test loss=0.554739 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.31228476762771606
[5/23] Train loss=0.335893452167511
[10/23] Train loss=0.3502768874168396
[15/23] Train loss=0.3201903998851776
[20/23] Train loss=0.29320910573005676
Test set avg_accuracy=67.51% avg_sensitivity=64.26%, avg_specificity=68.55% avg_auc=72.47%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.333655 Test loss=0.597581 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.3002988398075104
[5/23] Train loss=0.3320198357105255
[10/23] Train loss=0.3357880115509033
[15/23] Train loss=0.3186417520046234
[20/23] Train loss=0.2933189570903778
Test set avg_accuracy=79.88% avg_sensitivity=46.25%, avg_specificity=90.59% avg_auc=77.09%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.325218 Test loss=0.507375 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.3038502037525177
[5/23] Train loss=0.343047559261322
[10/23] Train loss=0.3233073055744171
[15/23] Train loss=0.32117053866386414
[20/23] Train loss=0.28165945410728455
Test set avg_accuracy=69.99% avg_sensitivity=66.15%, avg_specificity=71.21% avg_auc=75.39%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.325001 Test loss=0.545367 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.341827392578125
[5/23] Train loss=0.3512941896915436
[10/23] Train loss=0.3440283238887787
[15/23] Train loss=0.3299724757671356
[20/23] Train loss=0.2884102165699005
Test set avg_accuracy=60.94% avg_sensitivity=71.43%, avg_specificity=57.60% avg_auc=69.60%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.334124 Test loss=0.685158 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.3067058026790619
[5/23] Train loss=0.33668309450149536
[10/23] Train loss=0.3242517113685608
[15/23] Train loss=0.3205738663673401
[20/23] Train loss=0.2856443524360657
Test set avg_accuracy=67.77% avg_sensitivity=49.43%, avg_specificity=73.61% avg_auc=69.74%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.321338 Test loss=0.565399 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.30011120438575745
[5/23] Train loss=0.33829957246780396
[10/23] Train loss=0.3477274775505066
[15/23] Train loss=0.3152621388435364
[20/23] Train loss=0.2802741527557373
Test set avg_accuracy=73.78% avg_sensitivity=46.52%, avg_specificity=82.45% avg_auc=74.23%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.319840 Test loss=0.506301 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.29780519008636475
[5/23] Train loss=0.3049769997596741
[10/23] Train loss=0.3289710283279419
[15/23] Train loss=0.3086265027523041
[20/23] Train loss=0.29247769713401794
Test set avg_accuracy=64.47% avg_sensitivity=66.42%, avg_specificity=63.85% avg_auc=70.42%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.316242 Test loss=0.630749 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.30288079380989075
[5/23] Train loss=0.3149702250957489
[10/23] Train loss=0.3351738452911377
[15/23] Train loss=0.3168286383152008
[20/23] Train loss=0.31340810656547546
Test set avg_accuracy=74.84% avg_sensitivity=62.32%, avg_specificity=78.83% avg_auc=78.58%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.320691 Test loss=0.504533 Current lr=[0.000283047938381597]

[0/23] Train loss=0.3087387681007385
[5/23] Train loss=0.32027214765548706
[10/23] Train loss=0.3495231866836548
[15/23] Train loss=0.316275030374527
[20/23] Train loss=0.2761983871459961
Test set avg_accuracy=79.35% avg_sensitivity=20.59%, avg_specificity=98.06% avg_auc=78.65%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.319191 Test loss=0.459622 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.30148565769195557
[5/23] Train loss=0.3039224445819855
[10/23] Train loss=0.3319689631462097
[15/23] Train loss=0.29617756605148315
[20/23] Train loss=0.27572882175445557
Test set avg_accuracy=61.46% avg_sensitivity=61.89%, avg_specificity=61.32% avg_auc=69.25%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.309136 Test loss=0.628285 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.29377830028533936
[5/23] Train loss=0.33533623814582825
[10/23] Train loss=0.3330557644367218
[15/23] Train loss=0.30204933881759644
[20/23] Train loss=0.27498090267181396
Test set avg_accuracy=68.70% avg_sensitivity=59.03%, avg_specificity=71.78% avg_auc=72.54%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.314721 Test loss=0.560007 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.2973502278327942
[5/23] Train loss=0.3124527335166931
[10/23] Train loss=0.3311105966567993
[15/23] Train loss=0.30196821689605713
[20/23] Train loss=0.28754332661628723
Test set avg_accuracy=78.19% avg_sensitivity=21.51%, avg_specificity=96.24% avg_auc=71.21%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.315322 Test loss=0.677089 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.3066800534725189
[5/23] Train loss=0.3202039897441864
[10/23] Train loss=0.33941343426704407
[15/23] Train loss=0.31723129749298096
[20/23] Train loss=0.2851773202419281
Test set avg_accuracy=79.67% avg_sensitivity=43.45%, avg_specificity=91.21% avg_auc=79.44%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.328044 Test loss=0.452492 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.30202704668045044
[5/23] Train loss=0.320448637008667
[10/23] Train loss=0.33254629373550415
[15/23] Train loss=0.3045417368412018
[20/23] Train loss=0.2761821448802948
Test set avg_accuracy=63.93% avg_sensitivity=72.13%, avg_specificity=61.32% avg_auc=73.12%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.311432 Test loss=0.610879 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.2786141335964203
[5/23] Train loss=0.30781492590904236
[10/23] Train loss=0.3188232481479645
[15/23] Train loss=0.2878152132034302
[20/23] Train loss=0.2667650580406189
Test set avg_accuracy=78.29% avg_sensitivity=15.69%, avg_specificity=98.23% avg_auc=73.03%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.307264 Test loss=0.490156 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.2831234037876129
[5/23] Train loss=0.3112298846244812
[10/23] Train loss=0.3153423070907593
[15/23] Train loss=0.29136043787002563
[20/23] Train loss=0.26601049304008484
Test set avg_accuracy=73.54% avg_sensitivity=37.95%, avg_specificity=84.88% avg_auc=72.07%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.303537 Test loss=0.521733 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.2892242968082428
[5/23] Train loss=0.30930501222610474
[10/23] Train loss=0.31975919008255005
[15/23] Train loss=0.29238182306289673
[20/23] Train loss=0.2593185603618622
Test set avg_accuracy=70.17% avg_sensitivity=53.21%, avg_specificity=75.57% avg_auc=73.76%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.303025 Test loss=0.532384 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.2754659354686737
[5/23] Train loss=0.3010391891002655
[10/23] Train loss=0.32228949666023254
[15/23] Train loss=0.2871283292770386
[20/23] Train loss=0.2661384046077728
Test set avg_accuracy=68.57% avg_sensitivity=65.23%, avg_specificity=69.63% avg_auc=74.95%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.299522 Test loss=0.548107 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.2776329219341278
[5/23] Train loss=0.2900082767009735
[10/23] Train loss=0.3181965947151184
[15/23] Train loss=0.2761777341365814
[20/23] Train loss=0.2657453417778015
Test set avg_accuracy=71.77% avg_sensitivity=53.05%, avg_specificity=77.73% avg_auc=73.52%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.294004 Test loss=0.552925 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.2678332030773163
[5/23] Train loss=0.30234000086784363
[10/23] Train loss=0.3164364695549011
[15/23] Train loss=0.29171183705329895
[20/23] Train loss=0.27323758602142334
Test set avg_accuracy=70.25% avg_sensitivity=60.38%, avg_specificity=73.39% avg_auc=73.99%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.302092 Test loss=0.559562 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.2765200734138489
[5/23] Train loss=0.2960420846939087
[10/23] Train loss=0.30881839990615845
[15/23] Train loss=0.2862069308757782
[20/23] Train loss=0.2723468244075775
Test set avg_accuracy=76.77% avg_sensitivity=6.74%, avg_specificity=99.07% avg_auc=73.64%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.304330 Test loss=0.513156 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.2735270857810974
[5/23] Train loss=0.29091009497642517
[10/23] Train loss=0.32175910472869873
[15/23] Train loss=0.2814287841320038
[20/23] Train loss=0.2548459470272064
Test set avg_accuracy=70.08% avg_sensitivity=68.52%, avg_specificity=70.58% avg_auc=75.84%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.296774 Test loss=0.547980 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.2679550349712372
[5/23] Train loss=0.29806187748908997
[10/23] Train loss=0.3096364438533783
[15/23] Train loss=0.2853642404079437
[20/23] Train loss=0.2614799439907074
Test set avg_accuracy=73.35% avg_sensitivity=64.85%, avg_specificity=76.05% avg_auc=78.79%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.294998 Test loss=0.504553 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.2557723820209503
[5/23] Train loss=0.29398927092552185
[10/23] Train loss=0.3054977357387543
[15/23] Train loss=0.2811874449253082
[20/23] Train loss=0.2512117922306061
Test set avg_accuracy=69.22% avg_sensitivity=75.31%, avg_specificity=67.28% avg_auc=77.97%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.289283 Test loss=0.598447 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.2843489646911621
[5/23] Train loss=0.2935959994792938
[10/23] Train loss=0.32499659061431885
[15/23] Train loss=0.3151324987411499
[20/23] Train loss=0.27844560146331787
Test set avg_accuracy=75.73% avg_sensitivity=17.36%, avg_specificity=94.32% avg_auc=70.49%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.308727 Test loss=0.511250 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.2811817228794098
[5/23] Train loss=0.3009469509124756
[10/23] Train loss=0.31313642859458923
[15/23] Train loss=0.2955635190010071
[20/23] Train loss=0.25179943442344666
Test set avg_accuracy=78.82% avg_sensitivity=36.01%, avg_specificity=92.45% avg_auc=77.34%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.301099 Test loss=0.475747 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.28504428267478943
[5/23] Train loss=0.29116886854171753
[10/23] Train loss=0.31351348757743835
[15/23] Train loss=0.28917196393013
[20/23] Train loss=0.24085290729999542
Test set avg_accuracy=80.00% avg_sensitivity=34.12%, avg_specificity=94.61% avg_auc=78.45%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.294079 Test loss=0.454119 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.26202085614204407
[5/23] Train loss=0.2835352122783661
[10/23] Train loss=0.3042612373828888
[15/23] Train loss=0.2663643956184387
[20/23] Train loss=0.2570481300354004
Test set avg_accuracy=80.04% avg_sensitivity=37.41%, avg_specificity=93.61% avg_auc=79.45%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.286288 Test loss=0.444390 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.27349358797073364
[5/23] Train loss=0.3018919825553894
[10/23] Train loss=0.292341947555542
[15/23] Train loss=0.2671077847480774
[20/23] Train loss=0.2516258656978607
Test set avg_accuracy=77.98% avg_sensitivity=18.38%, avg_specificity=96.96% avg_auc=74.78%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.286466 Test loss=0.484303 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.2508958578109741
[5/23] Train loss=0.2901638150215149
[10/23] Train loss=0.2909158766269684
[15/23] Train loss=0.2708246409893036
[20/23] Train loss=0.24221771955490112
Test set avg_accuracy=72.97% avg_sensitivity=62.64%, avg_specificity=76.26% avg_auc=77.87%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.283612 Test loss=0.526108 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.2572689354419708
[5/23] Train loss=0.28340715169906616
[10/23] Train loss=0.29397323727607727
[15/23] Train loss=0.26920458674430847
[20/23] Train loss=0.23911648988723755
Test set avg_accuracy=82.12% avg_sensitivity=57.95%, avg_specificity=89.82% avg_auc=84.38%
Best model saved!! Metric=-11.72467101996886!!
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.284560 Test loss=0.404418 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.2609769403934479
[5/23] Train loss=0.29882076382637024
[10/23] Train loss=0.284540593624115
[15/23] Train loss=0.26263248920440674
[20/23] Train loss=0.23603783547878265
Test set avg_accuracy=83.54% avg_sensitivity=57.25%, avg_specificity=91.91% avg_auc=86.21%
Best model saved!! Metric=-7.0808568459370065!!
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.277460 Test loss=0.379035 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.2537040412425995
[5/23] Train loss=0.2812836468219757
[10/23] Train loss=0.29171985387802124
[15/23] Train loss=0.27010175585746765
[20/23] Train loss=0.2556764483451843
Test set avg_accuracy=77.75% avg_sensitivity=32.08%, avg_specificity=92.29% avg_auc=77.50%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.278958 Test loss=0.474562 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.2505541443824768
[5/23] Train loss=0.28503870964050293
[10/23] Train loss=0.29265278577804565
[15/23] Train loss=0.2676602900028229
[20/23] Train loss=0.23921707272529602
Test set avg_accuracy=79.27% avg_sensitivity=26.09%, avg_specificity=96.21% avg_auc=77.29%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.279478 Test loss=0.460719 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.2414752095937729
[5/23] Train loss=0.2738858163356781
[10/23] Train loss=0.3165258467197418
[15/23] Train loss=0.2756679356098175
[20/23] Train loss=0.2513384222984314
Test set avg_accuracy=64.83% avg_sensitivity=60.75%, avg_specificity=66.13% avg_auc=71.02%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.282390 Test loss=0.650003 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.2498353272676468
[5/23] Train loss=0.2713765799999237
[10/23] Train loss=0.2932174801826477
[15/23] Train loss=0.26237958669662476
[20/23] Train loss=0.2443239688873291
Test set avg_accuracy=70.51% avg_sensitivity=54.82%, avg_specificity=75.50% avg_auc=74.02%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.281033 Test loss=0.540648 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.24066194891929626
[5/23] Train loss=0.27306023240089417
[10/23] Train loss=0.28298401832580566
[15/23] Train loss=0.25239667296409607
[20/23] Train loss=0.23423941433429718
Test set avg_accuracy=76.41% avg_sensitivity=11.48%, avg_specificity=97.08% avg_auc=67.26%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.275654 Test loss=0.535376 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.2554686367511749
[5/23] Train loss=0.27220532298088074
[10/23] Train loss=0.2760366201400757
[15/23] Train loss=0.26138487458229065
[20/23] Train loss=0.23371398448944092
Test set avg_accuracy=76.54% avg_sensitivity=46.25%, avg_specificity=86.18% avg_auc=76.65%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.275995 Test loss=0.481568 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.24138101935386658
[5/23] Train loss=0.2652814984321594
[10/23] Train loss=0.28158998489379883
[15/23] Train loss=0.25004497170448303
[20/23] Train loss=0.23063531517982483
Test set avg_accuracy=77.42% avg_sensitivity=47.39%, avg_specificity=86.99% avg_auc=78.06%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.269048 Test loss=0.469067 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.2426159828901291
[5/23] Train loss=0.2536666989326477
[10/23] Train loss=0.2816598415374756
[15/23] Train loss=0.24728740751743317
[20/23] Train loss=0.2277238965034485
Test set avg_accuracy=78.01% avg_sensitivity=34.56%, avg_specificity=91.85% avg_auc=75.74%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.264142 Test loss=0.481460 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.24112020432949066
[5/23] Train loss=0.2691572904586792
[10/23] Train loss=0.27339646220207214
[15/23] Train loss=0.2416614294052124
[20/23] Train loss=0.22145412862300873
Test set avg_accuracy=71.51% avg_sensitivity=44.37%, avg_specificity=80.15% avg_auc=71.56%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.259705 Test loss=0.557865 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.23397399485111237
[5/23] Train loss=0.255442351102829
[10/23] Train loss=0.2695721387863159
[15/23] Train loss=0.25332891941070557
[20/23] Train loss=0.2244049459695816
Test set avg_accuracy=70.70% avg_sensitivity=47.06%, avg_specificity=78.23% avg_auc=71.53%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.260451 Test loss=0.541093 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.22679902613162994
[5/23] Train loss=0.25047409534454346
[10/23] Train loss=0.26938968896865845
[15/23] Train loss=0.24416546523571014
[20/23] Train loss=0.23083080351352692
Test set avg_accuracy=75.10% avg_sensitivity=20.32%, avg_specificity=92.55% avg_auc=64.68%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.257637 Test loss=0.612903 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.23725809156894684
[5/23] Train loss=0.26316195726394653
[10/23] Train loss=0.26915469765663147
[15/23] Train loss=0.23273245990276337
[20/23] Train loss=0.21608054637908936
Test set avg_accuracy=75.70% avg_sensitivity=34.72%, avg_specificity=88.76% avg_auc=71.82%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.254968 Test loss=0.533668 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.22883285582065582
[5/23] Train loss=0.2488338053226471
[10/23] Train loss=0.27048933506011963
[15/23] Train loss=0.22963210940361023
[20/23] Train loss=0.21625261008739471
Test set avg_accuracy=76.52% avg_sensitivity=19.78%, avg_specificity=94.59% avg_auc=68.58%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.250155 Test loss=0.563245 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.2262466847896576
[5/23] Train loss=0.2476789653301239
[10/23] Train loss=0.2669360935688019
[15/23] Train loss=0.25210821628570557
[20/23] Train loss=0.22291399538516998
Test set avg_accuracy=78.16% avg_sensitivity=19.68%, avg_specificity=96.79% avg_auc=74.55%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.258115 Test loss=0.503193 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.23934969305992126
[5/23] Train loss=0.257616251707077
[10/23] Train loss=0.27002233266830444
[15/23] Train loss=0.2497713565826416
[20/23] Train loss=0.21965476870536804
Test set avg_accuracy=79.22% avg_sensitivity=41.67%, avg_specificity=91.18% avg_auc=79.32%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.256357 Test loss=0.452640 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.2293809950351715
[5/23] Train loss=0.2588768005371094
[10/23] Train loss=0.25730887055397034
[15/23] Train loss=0.23690186440944672
[20/23] Train loss=0.22283725440502167
Test set avg_accuracy=68.53% avg_sensitivity=71.97%, avg_specificity=67.43% avg_auc=75.90%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.254535 Test loss=0.650975 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.23701651394367218
[5/23] Train loss=0.24359287321567535
[10/23] Train loss=0.25558480620384216
[15/23] Train loss=0.2341441810131073
[20/23] Train loss=0.2156674712896347
Test set avg_accuracy=78.63% avg_sensitivity=46.52%, avg_specificity=88.86% avg_auc=77.14%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.251636 Test loss=0.486216 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.22314126789569855
[5/23] Train loss=0.24370306730270386
[10/23] Train loss=0.2571008503437042
[15/23] Train loss=0.23688870668411255
[20/23] Train loss=0.21426595747470856
Test set avg_accuracy=76.85% avg_sensitivity=23.94%, avg_specificity=93.70% avg_auc=70.95%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.247285 Test loss=0.534494 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.21514226496219635
[5/23] Train loss=0.23950143158435822
[10/23] Train loss=0.2537522315979004
[15/23] Train loss=0.22823196649551392
[20/23] Train loss=0.21700498461723328
Test set avg_accuracy=72.46% avg_sensitivity=37.30%, avg_specificity=83.66% avg_auc=70.84%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.244388 Test loss=0.549630 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.2183365672826767
[5/23] Train loss=0.2308482974767685
[10/23] Train loss=0.2552199959754944
[15/23] Train loss=0.23667310178279877
[20/23] Train loss=0.2193719893693924
Test set avg_accuracy=71.17% avg_sensitivity=60.43%, avg_specificity=74.59% avg_auc=76.41%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.245754 Test loss=0.523169 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.22808730602264404
[5/23] Train loss=0.25792407989501953
[10/23] Train loss=0.2544083297252655
[15/23] Train loss=0.2344939410686493
[20/23] Train loss=0.2307322919368744
Test set avg_accuracy=76.08% avg_sensitivity=18.54%, avg_specificity=94.40% avg_auc=67.45%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.250695 Test loss=0.574029 Current lr=[0.000112073915556435]

[0/23] Train loss=0.2275167852640152
[5/23] Train loss=0.26008763909339905
[10/23] Train loss=0.25039413571357727
[15/23] Train loss=0.22724680602550507
[20/23] Train loss=0.21718840301036835
Test set avg_accuracy=70.20% avg_sensitivity=56.12%, avg_specificity=74.68% avg_auc=72.72%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.248511 Test loss=0.579507 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.2245035171508789
[5/23] Train loss=0.26626038551330566
[10/23] Train loss=0.24304424226284027
[15/23] Train loss=0.22848403453826904
[20/23] Train loss=0.21298472583293915
Test set avg_accuracy=70.68% avg_sensitivity=39.89%, avg_specificity=80.48% avg_auc=70.36%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.246303 Test loss=0.576150 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.2238297462463379
[5/23] Train loss=0.2379610240459442
[10/23] Train loss=0.2493518590927124
[15/23] Train loss=0.2214275747537613
[20/23] Train loss=0.21406038105487823
Test set avg_accuracy=62.96% avg_sensitivity=70.03%, avg_specificity=60.70% avg_auc=71.50%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.241220 Test loss=0.631052 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.2186826765537262
[5/23] Train loss=0.24570217728614807
[10/23] Train loss=0.24484235048294067
[15/23] Train loss=0.21498560905456543
[20/23] Train loss=0.19964146614074707
Test set avg_accuracy=66.73% avg_sensitivity=65.34%, avg_specificity=67.18% avg_auc=73.81%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.236030 Test loss=0.612703 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.21027469635009766
[5/23] Train loss=0.23579484224319458
[10/23] Train loss=0.24531003832817078
[15/23] Train loss=0.22128553688526154
[20/23] Train loss=0.20070382952690125
Test set avg_accuracy=62.45% avg_sensitivity=69.54%, avg_specificity=60.19% avg_auc=71.64%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.236112 Test loss=0.627201 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.2164078950881958
[5/23] Train loss=0.23531726002693176
[10/23] Train loss=0.24059654772281647
[15/23] Train loss=0.21805386245250702
[20/23] Train loss=0.20422177016735077
Test set avg_accuracy=59.47% avg_sensitivity=73.37%, avg_specificity=55.04% avg_auc=69.81%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.236153 Test loss=0.677328 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.21553316712379456
[5/23] Train loss=0.22622151672840118
[10/23] Train loss=0.24449196457862854
[15/23] Train loss=0.21783192455768585
[20/23] Train loss=0.196992889046669
Test set avg_accuracy=68.67% avg_sensitivity=67.12%, avg_specificity=69.17% avg_auc=75.22%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.233333 Test loss=0.582595 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.22691988945007324
[5/23] Train loss=0.24239395558834076
[10/23] Train loss=0.239985853433609
[15/23] Train loss=0.22215530276298523
[20/23] Train loss=0.21044065058231354
Test set avg_accuracy=72.27% avg_sensitivity=50.40%, avg_specificity=79.23% avg_auc=72.23%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.236151 Test loss=0.563205 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.20886501669883728
[5/23] Train loss=0.23609483242034912
[10/23] Train loss=0.23438197374343872
[15/23] Train loss=0.21579179167747498
[20/23] Train loss=0.2044914960861206
Test set avg_accuracy=63.09% avg_sensitivity=64.80%, avg_specificity=62.54% avg_auc=71.40%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.233630 Test loss=0.611150 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.20676912367343903
[5/23] Train loss=0.22386574745178223
[10/23] Train loss=0.24079087376594543
[15/23] Train loss=0.21522167325019836
[20/23] Train loss=0.200669527053833
Test set avg_accuracy=65.12% avg_sensitivity=63.29%, avg_specificity=65.70% avg_auc=71.60%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.233011 Test loss=0.632500 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.21842394769191742
[5/23] Train loss=0.24573881924152374
[10/23] Train loss=0.23698516190052032
[15/23] Train loss=0.22360922396183014
[20/23] Train loss=0.20137712359428406
Test set avg_accuracy=75.07% avg_sensitivity=23.88%, avg_specificity=91.36% avg_auc=69.28%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.231603 Test loss=0.564344 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.22115075588226318
[5/23] Train loss=0.22521524131298065
[10/23] Train loss=0.24230939149856567
[15/23] Train loss=0.2242358922958374
[20/23] Train loss=0.20175553858280182
Test set avg_accuracy=66.18% avg_sensitivity=51.86%, avg_specificity=70.75% avg_auc=69.14%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.235159 Test loss=0.596975 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.20856496691703796
[5/23] Train loss=0.25227779150009155
[10/23] Train loss=0.23069073259830475
[15/23] Train loss=0.21833182871341705
[20/23] Train loss=0.1994946300983429
Test set avg_accuracy=75.60% avg_sensitivity=39.62%, avg_specificity=87.06% avg_auc=74.12%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.233444 Test loss=0.514575 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.209405317902565
[5/23] Train loss=0.22526748478412628
[10/23] Train loss=0.23816660046577454
[15/23] Train loss=0.2115173488855362
[20/23] Train loss=0.19353002309799194
Test set avg_accuracy=74.23% avg_sensitivity=41.24%, avg_specificity=84.74% avg_auc=73.05%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.229449 Test loss=0.526581 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.20143090188503265
[5/23] Train loss=0.23091019690036774
[10/23] Train loss=0.22722822427749634
[15/23] Train loss=0.203074112534523
[20/23] Train loss=0.1908751130104065
Test set avg_accuracy=72.19% avg_sensitivity=55.42%, avg_specificity=77.53% avg_auc=75.61%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.225451 Test loss=0.523599 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.20328420400619507
[5/23] Train loss=0.22081875801086426
[10/23] Train loss=0.23077377676963806
[15/23] Train loss=0.19488441944122314
[20/23] Train loss=0.1905604600906372
Test set avg_accuracy=72.80% avg_sensitivity=50.51%, avg_specificity=79.90% avg_auc=74.55%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.218422 Test loss=0.533741 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.2010137438774109
[5/23] Train loss=0.20365512371063232
[10/23] Train loss=0.2234373241662979
[15/23] Train loss=0.19961243867874146
[20/23] Train loss=0.18611249327659607
Test set avg_accuracy=74.92% avg_sensitivity=45.88%, avg_specificity=84.17% avg_auc=74.08%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.214041 Test loss=0.524021 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.203124538064003
[5/23] Train loss=0.20906013250350952
[10/23] Train loss=0.2242007702589035
[15/23] Train loss=0.2057226300239563
[20/23] Train loss=0.18035420775413513
Test set avg_accuracy=65.04% avg_sensitivity=64.47%, avg_specificity=65.22% avg_auc=72.82%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.213138 Test loss=0.589188 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.197876438498497
[5/23] Train loss=0.20891475677490234
[10/23] Train loss=0.22652709484100342
[15/23] Train loss=0.19580820202827454
[20/23] Train loss=0.18177661299705505
Test set avg_accuracy=73.42% avg_sensitivity=41.99%, avg_specificity=83.43% avg_auc=72.69%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.210949 Test loss=0.541060 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.1916220337152481
[5/23] Train loss=0.21036842465400696
[10/23] Train loss=0.21798883378505707
[15/23] Train loss=0.19349904358386993
[20/23] Train loss=0.17752139270305634
Test set avg_accuracy=73.05% avg_sensitivity=50.46%, avg_specificity=80.24% avg_auc=74.44%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.208822 Test loss=0.535024 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.1961451917886734
[5/23] Train loss=0.1973946988582611
[10/23] Train loss=0.2232416719198227
[15/23] Train loss=0.19361545145511627
[20/23] Train loss=0.18100816011428833
Test set avg_accuracy=75.03% avg_sensitivity=49.54%, avg_specificity=83.14% avg_auc=74.80%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.208438 Test loss=0.528231 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.19012683629989624
[5/23] Train loss=0.2037971466779709
[10/23] Train loss=0.2147420048713684
[15/23] Train loss=0.19441628456115723
[20/23] Train loss=0.18089452385902405
Test set avg_accuracy=71.37% avg_sensitivity=51.05%, avg_specificity=77.84% avg_auc=73.54%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.205207 Test loss=0.557938 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.1936293989419937
[5/23] Train loss=0.19263269007205963
[10/23] Train loss=0.21818900108337402
[15/23] Train loss=0.19111688435077667
[20/23] Train loss=0.1753234565258026
Test set avg_accuracy=71.54% avg_sensitivity=54.12%, avg_specificity=77.08% avg_auc=73.97%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.203408 Test loss=0.560518 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.1917290985584259
[5/23] Train loss=0.20438902080059052
[10/23] Train loss=0.21434752643108368
[15/23] Train loss=0.1873929798603058
[20/23] Train loss=0.18112148344516754
Test set avg_accuracy=76.22% avg_sensitivity=39.30%, avg_specificity=87.98% avg_auc=75.59%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.204776 Test loss=0.504547 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.19202950596809387
[5/23] Train loss=0.19589848816394806
[10/23] Train loss=0.21419595181941986
[15/23] Train loss=0.18848547339439392
[20/23] Train loss=0.1789165586233139
Test set avg_accuracy=75.77% avg_sensitivity=39.62%, avg_specificity=87.28% avg_auc=74.38%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.203018 Test loss=0.520815 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.19065457582473755
[5/23] Train loss=0.20166166126728058
[10/23] Train loss=0.21275322139263153
[15/23] Train loss=0.18879732489585876
[20/23] Train loss=0.1729634702205658
Test set avg_accuracy=71.61% avg_sensitivity=56.12%, avg_specificity=76.55% avg_auc=74.56%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.201768 Test loss=0.563447 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.18618139624595642
[5/23] Train loss=0.19409488141536713
[10/23] Train loss=0.21169835329055786
[15/23] Train loss=0.18597839772701263
[20/23] Train loss=0.1777375489473343
Test set avg_accuracy=75.47% avg_sensitivity=46.95%, avg_specificity=84.55% avg_auc=76.08%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.200418 Test loss=0.515172 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.18715420365333557
[5/23] Train loss=0.20117412507534027
[10/23] Train loss=0.21021924912929535
[15/23] Train loss=0.18477287888526917
[20/23] Train loss=0.1709994077682495
Test set avg_accuracy=74.21% avg_sensitivity=46.58%, avg_specificity=83.00% avg_auc=74.61%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.200349 Test loss=0.531082 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.18779055774211884
[5/23] Train loss=0.19092638790607452
[10/23] Train loss=0.20923487842082977
[15/23] Train loss=0.18625062704086304
[20/23] Train loss=0.17447024583816528
Test set avg_accuracy=73.74% avg_sensitivity=46.42%, avg_specificity=82.44% avg_auc=74.31%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.198928 Test loss=0.537318 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.18808181583881378
[5/23] Train loss=0.1912926435470581
[10/23] Train loss=0.21449843049049377
[15/23] Train loss=0.1863684207201004
[20/23] Train loss=0.1704072654247284
Test set avg_accuracy=73.65% avg_sensitivity=52.18%, avg_specificity=80.48% avg_auc=75.40%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.199048 Test loss=0.531879 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.18227770924568176
[5/23] Train loss=0.1965406984090805
[10/23] Train loss=0.2065339833498001
[15/23] Train loss=0.1862114816904068
[20/23] Train loss=0.17528219521045685
Test set avg_accuracy=76.05% avg_sensitivity=42.32%, avg_specificity=86.80% avg_auc=75.10%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.198086 Test loss=0.523372 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.18770502507686615
[5/23] Train loss=0.2003673017024994
[10/23] Train loss=0.2082664966583252
[15/23] Train loss=0.1880648285150528
[20/23] Train loss=0.17359599471092224
Test set avg_accuracy=75.86% avg_sensitivity=45.44%, avg_specificity=85.55% avg_auc=75.18%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.198473 Test loss=0.522534 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.18591059744358063
[5/23] Train loss=0.19831426441669464
[10/23] Train loss=0.20789675414562225
[15/23] Train loss=0.18146958947181702
[20/23] Train loss=0.17105889320373535
Test set avg_accuracy=75.18% avg_sensitivity=43.67%, avg_specificity=85.22% avg_auc=74.95%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.197059 Test loss=0.526981 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.1832963079214096
[5/23] Train loss=0.19459035992622375
[10/23] Train loss=0.20677946507930756
[15/23] Train loss=0.18298400938510895
[20/23] Train loss=0.1759238839149475
Test set avg_accuracy=74.23% avg_sensitivity=45.98%, avg_specificity=83.23% avg_auc=74.76%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.196179 Test loss=0.533656 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.18136738240718842
[5/23] Train loss=0.1898573637008667
[10/23] Train loss=0.2099042683839798
[15/23] Train loss=0.18100647628307343
[20/23] Train loss=0.17298676073551178
Test set avg_accuracy=74.52% avg_sensitivity=46.36%, avg_specificity=83.48% avg_auc=75.03%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.196125 Test loss=0.528623 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.18155980110168457
[5/23] Train loss=0.1910155564546585
[10/23] Train loss=0.2057061642408371
[15/23] Train loss=0.18171079456806183
[20/23] Train loss=0.17011748254299164
Test set avg_accuracy=75.46% avg_sensitivity=43.99%, avg_specificity=85.48% avg_auc=75.62%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.196051 Test loss=0.519165 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.1835869550704956
[5/23] Train loss=0.19337305426597595
[10/23] Train loss=0.2087460607290268
[15/23] Train loss=0.18171775341033936
[20/23] Train loss=0.16840580105781555
Test set avg_accuracy=75.78% avg_sensitivity=43.67%, avg_specificity=86.01% avg_auc=75.80%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.195360 Test loss=0.516566 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.18224036693572998
[5/23] Train loss=0.1948252171278
[10/23] Train loss=0.20742082595825195
[15/23] Train loss=0.17979921400547028
[20/23] Train loss=0.16616494953632355
Test set avg_accuracy=75.76% avg_sensitivity=43.34%, avg_specificity=86.08% avg_auc=75.83%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.196023 Test loss=0.516334 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.18102014064788818
[5/23] Train loss=0.18607020378112793
[10/23] Train loss=0.20883941650390625
[15/23] Train loss=0.182635098695755
[20/23] Train loss=0.171170175075531
Test set avg_accuracy=76.09% avg_sensitivity=42.80%, avg_specificity=86.70% avg_auc=75.71%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.195251 Test loss=0.517013 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.18081383407115936
[5/23] Train loss=0.19454635679721832
[10/23] Train loss=0.2041667252779007
[15/23] Train loss=0.18210160732269287
[20/23] Train loss=0.1728811413049698
Test set avg_accuracy=75.20% avg_sensitivity=44.04%, avg_specificity=85.12% avg_auc=75.43%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.195450 Test loss=0.522332 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.1819770336151123
[5/23] Train loss=0.19237112998962402
[10/23] Train loss=0.20427784323692322
[15/23] Train loss=0.18226651847362518
[20/23] Train loss=0.16577616333961487
Test set avg_accuracy=74.86% avg_sensitivity=44.74%, avg_specificity=84.45% avg_auc=75.31%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.195620 Test loss=0.524528 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.1822851300239563
[5/23] Train loss=0.19184167683124542
[10/23] Train loss=0.20431004464626312
[15/23] Train loss=0.1831117570400238
[20/23] Train loss=0.1730109006166458
Test set avg_accuracy=75.64% avg_sensitivity=44.10%, avg_specificity=85.68% avg_auc=75.79%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.196134 Test loss=0.517457 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.18453706800937653
[5/23] Train loss=0.18769457936286926
[10/23] Train loss=0.20774032175540924
[15/23] Train loss=0.18134929239749908
[20/23] Train loss=0.16842950880527496
Test set avg_accuracy=75.13% avg_sensitivity=44.37%, avg_specificity=84.93% avg_auc=75.38%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.194708 Test loss=0.523519 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.18401604890823364
[5/23] Train loss=0.19252580404281616
[10/23] Train loss=0.2047203779220581
[15/23] Train loss=0.17853747308254242
[20/23] Train loss=0.1686558872461319
Test set avg_accuracy=76.00% avg_sensitivity=43.61%, avg_specificity=86.32% avg_auc=75.92%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.195237 Test loss=0.515973 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=83.54% sen=57.25%, spe=91.91%, auc=86.21%!
Fold[9] Avg_overlap=0.54%(±0.3105422960137081)
[0/24] Train loss=0.7154152393341064
[5/24] Train loss=0.7252141237258911
[10/24] Train loss=0.7196261882781982
[15/24] Train loss=0.7225015163421631
[20/24] Train loss=0.7130606770515442
Test set avg_accuracy=59.18% avg_sensitivity=34.76%, avg_specificity=66.26% avg_auc=49.46%
Best model saved!! Metric=-116.33933162343806!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=0.719831 Test loss=0.674142 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=0.715294361114502
[5/24] Train loss=0.7130411267280579
[10/24] Train loss=0.7086668014526367
[15/24] Train loss=0.7218145132064819
[20/24] Train loss=0.7051586508750916
Test set avg_accuracy=55.13% avg_sensitivity=43.22%, avg_specificity=58.58% avg_auc=50.12%
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.712143 Test loss=0.680345 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=0.7023199200630188
[5/24] Train loss=0.7019137144088745
[10/24] Train loss=0.6995759606361389
[15/24] Train loss=0.7107613682746887
[20/24] Train loss=0.7089360952377319
Test set avg_accuracy=66.41% avg_sensitivity=24.68%, avg_specificity=78.50% avg_auc=51.08%
Best model saved!! Metric=-105.33120373471627!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.704447 Test loss=0.669649 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=0.6999761462211609
[5/24] Train loss=0.7005653977394104
[10/24] Train loss=0.6927396655082703
[15/24] Train loss=0.6940003037452698
[20/24] Train loss=0.689707338809967
Test set avg_accuracy=69.80% avg_sensitivity=17.79%, avg_specificity=84.88% avg_auc=51.45%
Best model saved!! Metric=-102.07619396628984!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.695952 Test loss=0.663683 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=0.6866846084594727
[5/24] Train loss=0.691598653793335
[10/24] Train loss=0.6815991997718811
[15/24] Train loss=0.6887253522872925
[20/24] Train loss=0.6815477013587952
Test set avg_accuracy=66.37% avg_sensitivity=22.83%, avg_specificity=78.99% avg_auc=52.00%
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.686269 Test loss=0.654951 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=0.6759967803955078
[5/24] Train loss=0.6822730302810669
[10/24] Train loss=0.6757044792175293
[15/24] Train loss=0.6772773861885071
[20/24] Train loss=0.6745267510414124
Test set avg_accuracy=69.78% avg_sensitivity=17.44%, avg_specificity=84.95% avg_auc=52.28%
Best model saved!! Metric=-101.550633177515!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.676235 Test loss=0.655649 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=0.6729413270950317
[5/24] Train loss=0.6771963834762573
[10/24] Train loss=0.662790060043335
[15/24] Train loss=0.6683882474899292
[20/24] Train loss=0.660119891166687
Test set avg_accuracy=69.97% avg_sensitivity=18.08%, avg_specificity=85.02% avg_auc=52.65%
Best model saved!! Metric=-100.27661802438175!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.666970 Test loss=0.650389 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.6636826395988464
[5/24] Train loss=0.6544588804244995
[10/24] Train loss=0.6436316967010498
[15/24] Train loss=0.6625732779502869
[20/24] Train loss=0.6577926874160767
Test set avg_accuracy=73.41% avg_sensitivity=14.14%, avg_specificity=90.59% avg_auc=53.42%
Best model saved!! Metric=-94.43431094998246!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.655959 Test loss=0.646025 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.6506126523017883
[5/24] Train loss=0.6497789025306702
[10/24] Train loss=0.6484079360961914
[15/24] Train loss=0.6449011564254761
[20/24] Train loss=0.6414487361907959
Test set avg_accuracy=73.84% avg_sensitivity=12.57%, avg_specificity=91.60% avg_auc=54.38%
Best model saved!! Metric=-93.60212667186391!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.644740 Test loss=0.613992 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.6424891352653503
[5/24] Train loss=0.6351380348205566
[10/24] Train loss=0.6329582333564758
[15/24] Train loss=0.6348777413368225
[20/24] Train loss=0.6297430992126465
Test set avg_accuracy=73.62% avg_sensitivity=11.82%, avg_specificity=91.54% avg_auc=56.10%
Best model saved!! Metric=-92.9273044362872!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.632165 Test loss=0.594406 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.6260658502578735
[5/24] Train loss=0.6228878498077393
[10/24] Train loss=0.616651713848114
[15/24] Train loss=0.6120463609695435
[20/24] Train loss=0.6095792055130005
Test set avg_accuracy=73.83% avg_sensitivity=12.92%, avg_specificity=91.48% avg_auc=56.42%
Best model saved!! Metric=-91.34302044843801!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.618058 Test loss=0.575843 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.6175702810287476
[5/24] Train loss=0.6152047514915466
[10/24] Train loss=0.6054378151893616
[15/24] Train loss=0.6103185415267944
[20/24] Train loss=0.6034393906593323
Test set avg_accuracy=73.78% avg_sensitivity=14.66%, avg_specificity=90.91% avg_auc=59.44%
Best model saved!! Metric=-87.2071541439338!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.605697 Test loss=0.550997 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.5999348163604736
[5/24] Train loss=0.6055558919906616
[10/24] Train loss=0.5850385427474976
[15/24] Train loss=0.5929476618766785
[20/24] Train loss=0.5764287114143372
Test set avg_accuracy=77.21% avg_sensitivity=12.17%, avg_specificity=96.07% avg_auc=63.33%
Best model saved!! Metric=-77.21849191174115!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.585755 Test loss=0.519238 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.5643280148506165
[5/24] Train loss=0.579511284828186
[10/24] Train loss=0.5608704686164856
[15/24] Train loss=0.5576987266540527
[20/24] Train loss=0.5445849299430847
Test set avg_accuracy=77.58% avg_sensitivity=14.31%, avg_specificity=95.92% avg_auc=63.13%
Best model saved!! Metric=-75.06109842439196!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.560820 Test loss=0.545577 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.5392510890960693
[5/24] Train loss=0.5536966323852539
[10/24] Train loss=0.5320391654968262
[15/24] Train loss=0.5335490107536316
[20/24] Train loss=0.5075088739395142
Test set avg_accuracy=78.09% avg_sensitivity=17.38%, avg_specificity=95.68% avg_auc=63.45%
Best model saved!! Metric=-71.39549177371727!!
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.530367 Test loss=0.578495 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.4937750995159149
[5/24] Train loss=0.522925853729248
[10/24] Train loss=0.5006411075592041
[15/24] Train loss=0.49644288420677185
[20/24] Train loss=0.4794285297393799
Test set avg_accuracy=79.35% avg_sensitivity=25.26%, avg_specificity=95.03% avg_auc=73.06%
Best model saved!! Metric=-53.30167742143546!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.501974 Test loss=0.511735 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.4542687237262726
[5/24] Train loss=0.4886283576488495
[10/24] Train loss=0.48136427998542786
[15/24] Train loss=0.47553369402885437
[20/24] Train loss=0.4597760736942291
Test set avg_accuracy=79.93% avg_sensitivity=65.93%, avg_specificity=83.99% avg_auc=81.11%
Best model saved!! Metric=-15.031408599531858!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.477942 Test loss=0.506599 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.4290517270565033
[5/24] Train loss=0.46184059977531433
[10/24] Train loss=0.4574935734272003
[15/24] Train loss=0.4668947458267212
[20/24] Train loss=0.44853663444519043
Test set avg_accuracy=55.87% avg_sensitivity=68.71%, avg_specificity=52.15% avg_auc=69.95%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.461390 Test loss=0.650585 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.4100719094276428
[5/24] Train loss=0.447276771068573
[10/24] Train loss=0.44887739419937134
[15/24] Train loss=0.4660256803035736
[20/24] Train loss=0.4355567395687103
Test set avg_accuracy=52.84% avg_sensitivity=73.23%, avg_specificity=46.93% avg_auc=68.41%
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.449119 Test loss=0.678070 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.41051989793777466
[5/24] Train loss=0.4334239661693573
[10/24] Train loss=0.445098340511322
[15/24] Train loss=0.45850706100463867
[20/24] Train loss=0.4414726495742798
Test set avg_accuracy=61.78% avg_sensitivity=72.31%, avg_specificity=58.73% avg_auc=71.77%
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.442618 Test loss=0.627444 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.40728095173835754
[5/24] Train loss=0.4225336015224457
[10/24] Train loss=0.4339330196380615
[15/24] Train loss=0.4584272801876068
[20/24] Train loss=0.4312523603439331
Test set avg_accuracy=56.02% avg_sensitivity=70.28%, avg_specificity=51.88% avg_auc=67.53%
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.435119 Test loss=0.675483 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.39225447177886963
[5/24] Train loss=0.4171602427959442
[10/24] Train loss=0.4292844235897064
[15/24] Train loss=0.4501541554927826
[20/24] Train loss=0.42156752943992615
Test set avg_accuracy=58.84% avg_sensitivity=74.04%, avg_specificity=54.43% avg_auc=71.10%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.430599 Test loss=0.657429 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.3952663242816925
[5/24] Train loss=0.4175296425819397
[10/24] Train loss=0.4194885194301605
[15/24] Train loss=0.4308643043041229
[20/24] Train loss=0.41061410307884216
Test set avg_accuracy=54.97% avg_sensitivity=68.66%, avg_specificity=51.01% avg_auc=67.84%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.421393 Test loss=0.659450 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.3794676959514618
[5/24] Train loss=0.40282830595970154
[10/24] Train loss=0.4167049527168274
[15/24] Train loss=0.43229740858078003
[20/24] Train loss=0.40686848759651184
Test set avg_accuracy=64.43% avg_sensitivity=72.19%, avg_specificity=62.18% avg_auc=74.27%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.416746 Test loss=0.611225 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.39059552550315857
[5/24] Train loss=0.42083218693733215
[10/24] Train loss=0.42397961020469666
[15/24] Train loss=0.4292028546333313
[20/24] Train loss=0.4068538248538971
Test set avg_accuracy=57.37% avg_sensitivity=71.55%, avg_specificity=53.26% avg_auc=71.00%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.419801 Test loss=0.644019 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.3770228922367096
[5/24] Train loss=0.40063005685806274
[10/24] Train loss=0.41422218084335327
[15/24] Train loss=0.4202006757259369
[20/24] Train loss=0.3891153037548065
Test set avg_accuracy=61.76% avg_sensitivity=68.54%, avg_specificity=59.79% avg_auc=71.75%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.407253 Test loss=0.623826 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.3748634159564972
[5/24] Train loss=0.3972911834716797
[10/24] Train loss=0.40966537594795227
[15/24] Train loss=0.4108603298664093
[20/24] Train loss=0.38760054111480713
Test set avg_accuracy=61.54% avg_sensitivity=70.51%, avg_specificity=58.94% avg_auc=73.09%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.400609 Test loss=0.623398 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.3678152859210968
[5/24] Train loss=0.37746483087539673
[10/24] Train loss=0.4061749577522278
[15/24] Train loss=0.4142339825630188
[20/24] Train loss=0.38288167119026184
Test set avg_accuracy=66.07% avg_sensitivity=70.45%, avg_specificity=64.80% avg_auc=74.84%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.396420 Test loss=0.604318 Current lr=[0.000210185142098938]

[0/24] Train loss=0.37317711114883423
[5/24] Train loss=0.39145708084106445
[10/24] Train loss=0.4049932658672333
[15/24] Train loss=0.4094802439212799
[20/24] Train loss=0.38044270873069763
Test set avg_accuracy=64.35% avg_sensitivity=63.67%, avg_specificity=64.54% avg_auc=71.28%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.398218 Test loss=0.614203 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.3670121431350708
[5/24] Train loss=0.3876802623271942
[10/24] Train loss=0.3966313302516937
[15/24] Train loss=0.39757832884788513
[20/24] Train loss=0.3827196955680847
Test set avg_accuracy=75.94% avg_sensitivity=59.85%, avg_specificity=80.60% avg_auc=78.50%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.392126 Test loss=0.534267 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.37559974193573
[5/24] Train loss=0.39790886640548706
[10/24] Train loss=0.3944622874259949
[15/24] Train loss=0.4000038504600525
[20/24] Train loss=0.3622804582118988
Test set avg_accuracy=72.16% avg_sensitivity=64.83%, avg_specificity=74.29% avg_auc=75.86%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.390844 Test loss=0.596954 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.3849220871925354
[5/24] Train loss=0.38939473032951355
[10/24] Train loss=0.38669300079345703
[15/24] Train loss=0.39873358607292175
[20/24] Train loss=0.3856258690357208
Test set avg_accuracy=70.89% avg_sensitivity=61.70%, avg_specificity=73.55% avg_auc=76.69%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.387252 Test loss=0.538072 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.3589222729206085
[5/24] Train loss=0.3806068003177643
[10/24] Train loss=0.39233723282814026
[15/24] Train loss=0.398992657661438
[20/24] Train loss=0.35890936851501465
Test set avg_accuracy=73.12% avg_sensitivity=65.47%, avg_specificity=75.34% avg_auc=78.11%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.380670 Test loss=0.562664 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.35340774059295654
[5/24] Train loss=0.36540332436561584
[10/24] Train loss=0.392965704202652
[15/24] Train loss=0.38292205333709717
[20/24] Train loss=0.35751616954803467
Test set avg_accuracy=63.44% avg_sensitivity=51.45%, avg_specificity=66.91% avg_auc=66.87%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.378734 Test loss=0.635586 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.35992440581321716
[5/24] Train loss=0.37106311321258545
[10/24] Train loss=0.38057905435562134
[15/24] Train loss=0.3752058148384094
[20/24] Train loss=0.34884512424468994
Test set avg_accuracy=74.91% avg_sensitivity=71.26%, avg_specificity=75.97% avg_auc=81.27%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.376073 Test loss=0.533903 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.3537966012954712
[5/24] Train loss=0.36801010370254517
[10/24] Train loss=0.3797987997531891
[15/24] Train loss=0.38021329045295715
[20/24] Train loss=0.3606604039669037
Test set avg_accuracy=74.56% avg_sensitivity=61.76%, avg_specificity=78.27% avg_auc=76.89%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.374454 Test loss=0.578963 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.34948885440826416
[5/24] Train loss=0.3640096187591553
[10/24] Train loss=0.37684544920921326
[15/24] Train loss=0.3991844952106476
[20/24] Train loss=0.3519930839538574
Test set avg_accuracy=81.12% avg_sensitivity=26.83%, avg_specificity=96.86% avg_auc=77.57%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.372728 Test loss=0.476229 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.34128305315971375
[5/24] Train loss=0.3713337481021881
[10/24] Train loss=0.3715369701385498
[15/24] Train loss=0.3933745324611664
[20/24] Train loss=0.3477380871772766
Test set avg_accuracy=66.97% avg_sensitivity=63.04%, avg_specificity=68.11% avg_auc=72.70%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.371018 Test loss=0.590261 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.3412068486213684
[5/24] Train loss=0.3682992160320282
[10/24] Train loss=0.37163257598876953
[15/24] Train loss=0.37664180994033813
[20/24] Train loss=0.411075234413147
Test set avg_accuracy=82.94% avg_sensitivity=33.49%, avg_specificity=97.28% avg_auc=86.02%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.369216 Test loss=0.380703 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.343180775642395
[5/24] Train loss=0.38138607144355774
[10/24] Train loss=0.3769998252391815
[15/24] Train loss=0.3794908821582794
[20/24] Train loss=0.34479498863220215
Test set avg_accuracy=69.11% avg_sensitivity=58.81%, avg_specificity=72.10% avg_auc=74.48%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.371213 Test loss=0.552231 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.34344160556793213
[5/24] Train loss=0.35843485593795776
[10/24] Train loss=0.36653852462768555
[15/24] Train loss=0.40313994884490967
[20/24] Train loss=0.34383127093315125
Test set avg_accuracy=71.99% avg_sensitivity=45.71%, avg_specificity=79.61% avg_auc=72.42%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.364507 Test loss=0.533869 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.34099307656288147
[5/24] Train loss=0.35881510376930237
[10/24] Train loss=0.3608105480670929
[15/24] Train loss=0.37138018012046814
[20/24] Train loss=0.34566742181777954
Test set avg_accuracy=63.53% avg_sensitivity=69.35%, avg_specificity=61.84% avg_auc=72.22%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.360671 Test loss=0.624603 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.33312487602233887
[5/24] Train loss=0.3511621654033661
[10/24] Train loss=0.3627961575984955
[15/24] Train loss=0.3885380029678345
[20/24] Train loss=0.35043448209762573
Test set avg_accuracy=64.40% avg_sensitivity=57.01%, avg_specificity=66.54% avg_auc=69.69%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.363861 Test loss=0.608644 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.3405894339084625
[5/24] Train loss=0.3664517402648926
[10/24] Train loss=0.3687869906425476
[15/24] Train loss=0.3787248134613037
[20/24] Train loss=0.3422263562679291
Test set avg_accuracy=67.37% avg_sensitivity=55.21%, avg_specificity=70.89% avg_auc=70.42%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.364028 Test loss=0.570182 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3480164706707001
[5/24] Train loss=0.36919423937797546
[10/24] Train loss=0.3540269434452057
[15/24] Train loss=0.3611636161804199
[20/24] Train loss=0.3502381443977356
Test set avg_accuracy=80.26% avg_sensitivity=31.69%, avg_specificity=94.34% avg_auc=77.45%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.356083 Test loss=0.495767 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.33182746171951294
[5/24] Train loss=0.35552510619163513
[10/24] Train loss=0.3614802956581116
[15/24] Train loss=0.358236163854599
[20/24] Train loss=0.3532593250274658
Test set avg_accuracy=81.16% avg_sensitivity=21.21%, avg_specificity=98.54% avg_auc=76.61%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.354601 Test loss=0.479693 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.34373748302459717
[5/24] Train loss=0.3472948968410492
[10/24] Train loss=0.34841597080230713
[15/24] Train loss=0.3518110513687134
[20/24] Train loss=0.32980024814605713
Test set avg_accuracy=68.95% avg_sensitivity=49.83%, avg_specificity=74.49% avg_auc=71.42%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.349488 Test loss=0.549776 Current lr=[0.000299720220882401]

[0/24] Train loss=0.33266666531562805
[5/24] Train loss=0.34482741355895996
[10/24] Train loss=0.35157784819602966
[15/24] Train loss=0.34966686367988586
[20/24] Train loss=0.32883140444755554
Test set avg_accuracy=67.24% avg_sensitivity=57.88%, avg_specificity=69.95% avg_auc=71.68%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.342032 Test loss=0.558927 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3288295865058899
[5/24] Train loss=0.3392036557197571
[10/24] Train loss=0.3430579602718353
[15/24] Train loss=0.34487590193748474
[20/24] Train loss=0.31258222460746765
Test set avg_accuracy=62.55% avg_sensitivity=82.39%, avg_specificity=56.80% avg_auc=77.62%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.340763 Test loss=0.608969 Current lr=[0.000298904600941902]

[0/24] Train loss=0.32074040174484253
[5/24] Train loss=0.3432912230491638
[10/24] Train loss=0.35997775197029114
[15/24] Train loss=0.34605637192726135
[20/24] Train loss=0.3272141218185425
Test set avg_accuracy=73.22% avg_sensitivity=43.51%, avg_specificity=81.83% avg_auc=74.13%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.344846 Test loss=0.503622 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3395079970359802
[5/24] Train loss=0.3296213448047638
[10/24] Train loss=0.3481595814228058
[15/24] Train loss=0.35115447640419006
[20/24] Train loss=0.3262708783149719
Test set avg_accuracy=74.86% avg_sensitivity=37.43%, avg_specificity=85.71% avg_auc=73.23%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.346539 Test loss=0.522507 Current lr=[0.000297555943323901]

[0/24] Train loss=0.348392516374588
[5/24] Train loss=0.3427775204181671
[10/24] Train loss=0.35067617893218994
[15/24] Train loss=0.3466786742210388
[20/24] Train loss=0.3200347125530243
Test set avg_accuracy=73.84% avg_sensitivity=48.03%, avg_specificity=81.32% avg_auc=75.68%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.345778 Test loss=0.495375 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3307746350765228
[5/24] Train loss=0.3537713885307312
[10/24] Train loss=0.3394855260848999
[15/24] Train loss=0.3465709686279297
[20/24] Train loss=0.3253631591796875
Test set avg_accuracy=78.42% avg_sensitivity=37.72%, avg_specificity=90.23% avg_auc=75.66%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.338964 Test loss=0.467235 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.31343477964401245
[5/24] Train loss=0.33900076150894165
[10/24] Train loss=0.3437002897262573
[15/24] Train loss=0.34310680627822876
[20/24] Train loss=0.3174438774585724
Test set avg_accuracy=77.97% avg_sensitivity=57.82%, avg_specificity=83.81% avg_auc=79.52%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.332256 Test loss=0.480173 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3113321363925934
[5/24] Train loss=0.32935836911201477
[10/24] Train loss=0.3399135172367096
[15/24] Train loss=0.34406206011772156
[20/24] Train loss=0.3125627636909485
Test set avg_accuracy=71.82% avg_sensitivity=64.54%, avg_specificity=73.93% avg_auc=75.63%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.331548 Test loss=0.534808 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.33207055926322937
[5/24] Train loss=0.3418169915676117
[10/24] Train loss=0.3359352946281433
[15/24] Train loss=0.3469504415988922
[20/24] Train loss=0.32409581542015076
Test set avg_accuracy=61.88% avg_sensitivity=78.27%, avg_specificity=57.12% avg_auc=74.34%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.339335 Test loss=0.629542 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3104599118232727
[5/24] Train loss=0.3361918330192566
[10/24] Train loss=0.3349527418613434
[15/24] Train loss=0.3411654233932495
[20/24] Train loss=0.31453999876976013
Test set avg_accuracy=72.30% avg_sensitivity=63.90%, avg_specificity=74.74% avg_auc=76.18%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.331894 Test loss=0.532035 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3158337473869324
[5/24] Train loss=0.33975985646247864
[10/24] Train loss=0.33582067489624023
[15/24] Train loss=0.3300526440143585
[20/24] Train loss=0.3085407316684723
Test set avg_accuracy=70.83% avg_sensitivity=51.62%, avg_specificity=76.40% avg_auc=73.11%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.326737 Test loss=0.532171 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.31898289918899536
[5/24] Train loss=0.31458887457847595
[10/24] Train loss=0.3361097574234009
[15/24] Train loss=0.32271474599838257
[20/24] Train loss=0.31300416588783264
Test set avg_accuracy=73.76% avg_sensitivity=61.82%, avg_specificity=77.23% avg_auc=77.80%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.323537 Test loss=0.499569 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.32170259952545166
[5/24] Train loss=0.32632675766944885
[10/24] Train loss=0.32213160395622253
[15/24] Train loss=0.35281917452812195
[20/24] Train loss=0.3139216899871826
Test set avg_accuracy=83.52% avg_sensitivity=41.54%, avg_specificity=95.68% avg_auc=84.29%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.327039 Test loss=0.402551 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3354424238204956
[5/24] Train loss=0.3534849286079407
[10/24] Train loss=0.3215405344963074
[15/24] Train loss=0.3425038754940033
[20/24] Train loss=0.3092190623283386
Test set avg_accuracy=69.08% avg_sensitivity=63.73%, avg_specificity=70.62% avg_auc=73.94%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.327922 Test loss=0.551607 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3106076419353485
[5/24] Train loss=0.3245689570903778
[10/24] Train loss=0.3291623294353485
[15/24] Train loss=0.3183938264846802
[20/24] Train loss=0.308234840631485
Test set avg_accuracy=60.14% avg_sensitivity=63.96%, avg_specificity=59.04% avg_auc=67.11%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.319205 Test loss=0.640866 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3113619089126587
[5/24] Train loss=0.32512736320495605
[10/24] Train loss=0.3233621120452881
[15/24] Train loss=0.3389173448085785
[20/24] Train loss=0.30942633748054504
Test set avg_accuracy=81.28% avg_sensitivity=25.67%, avg_specificity=97.40% avg_auc=78.80%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.322837 Test loss=0.433828 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3162521421909332
[5/24] Train loss=0.33152106404304504
[10/24] Train loss=0.3311842083930969
[15/24] Train loss=0.33048415184020996
[20/24] Train loss=0.3056539297103882
Test set avg_accuracy=77.12% avg_sensitivity=13.27%, avg_specificity=95.63% avg_auc=70.76%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.320963 Test loss=0.490380 Current lr=[0.000276307469034998]

[0/24] Train loss=0.31143733859062195
[5/24] Train loss=0.3179060220718384
[10/24] Train loss=0.32064375281333923
[15/24] Train loss=0.30741190910339355
[20/24] Train loss=0.30458205938339233
Test set avg_accuracy=62.14% avg_sensitivity=67.38%, avg_specificity=60.61% avg_auc=69.14%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.311015 Test loss=0.595039 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.30907461047172546
[5/24] Train loss=0.32154160737991333
[10/24] Train loss=0.32681167125701904
[15/24] Train loss=0.3200165629386902
[20/24] Train loss=0.3066428601741791
Test set avg_accuracy=71.86% avg_sensitivity=57.30%, avg_specificity=76.08% avg_auc=75.09%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.314678 Test loss=0.508195 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.2989271879196167
[5/24] Train loss=0.3162068724632263
[10/24] Train loss=0.3158058822154999
[15/24] Train loss=0.3168158233165741
[20/24] Train loss=0.30363044142723083
Test set avg_accuracy=67.15% avg_sensitivity=58.17%, avg_specificity=69.75% avg_auc=70.54%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.311025 Test loss=0.572833 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3018372654914856
[5/24] Train loss=0.3131842017173767
[10/24] Train loss=0.3054073750972748
[15/24] Train loss=0.30634352564811707
[20/24] Train loss=0.29614943265914917
Test set avg_accuracy=60.96% avg_sensitivity=65.12%, avg_specificity=59.76% avg_auc=65.79%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.305765 Test loss=0.727438 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3034602105617523
[5/24] Train loss=0.3349333703517914
[10/24] Train loss=0.33190977573394775
[15/24] Train loss=0.31379008293151855
[20/24] Train loss=0.29629719257354736
Test set avg_accuracy=64.97% avg_sensitivity=61.53%, avg_specificity=65.97% avg_auc=70.56%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.314143 Test loss=0.607594 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.29025784134864807
[5/24] Train loss=0.30860647559165955
[10/24] Train loss=0.32046395540237427
[15/24] Train loss=0.3106653392314911
[20/24] Train loss=0.28831779956817627
Test set avg_accuracy=69.82% avg_sensitivity=68.25%, avg_specificity=70.27% avg_auc=75.91%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.304321 Test loss=0.535071 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2940848171710968
[5/24] Train loss=0.32348769903182983
[10/24] Train loss=0.32293397188186646
[15/24] Train loss=0.3119536340236664
[20/24] Train loss=0.3102700114250183
Test set avg_accuracy=77.90% avg_sensitivity=13.85%, avg_specificity=96.47% avg_auc=74.71%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.314912 Test loss=0.469134 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.29445064067840576
[5/24] Train loss=0.3317299783229828
[10/24] Train loss=0.3211023211479187
[15/24] Train loss=0.3198084533214569
[20/24] Train loss=0.3199920952320099
Test set avg_accuracy=66.46% avg_sensitivity=57.94%, avg_specificity=68.93% avg_auc=69.95%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.317688 Test loss=0.566143 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2951623201370239
[5/24] Train loss=0.32850322127342224
[10/24] Train loss=0.31075403094291687
[15/24] Train loss=0.3109133541584015
[20/24] Train loss=0.29623326659202576
Test set avg_accuracy=71.61% avg_sensitivity=49.54%, avg_specificity=78.01% avg_auc=72.43%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.310953 Test loss=0.532065 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30682462453842163
[5/24] Train loss=0.31122666597366333
[10/24] Train loss=0.3186505138874054
[15/24] Train loss=0.3130106031894684
[20/24] Train loss=0.3108971118927002
Test set avg_accuracy=75.87% avg_sensitivity=33.72%, avg_specificity=88.09% avg_auc=72.75%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.314481 Test loss=0.512809 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.29579272866249084
[5/24] Train loss=0.30906158685684204
[10/24] Train loss=0.3058338463306427
[15/24] Train loss=0.312991738319397
[20/24] Train loss=0.2907027006149292
Test set avg_accuracy=66.56% avg_sensitivity=69.52%, avg_specificity=65.70% avg_auc=74.28%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.308066 Test loss=0.574406 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2800171375274658
[5/24] Train loss=0.336281418800354
[10/24] Train loss=0.3042508065700531
[15/24] Train loss=0.31170663237571716
[20/24] Train loss=0.286082923412323
Test set avg_accuracy=73.61% avg_sensitivity=40.96%, avg_specificity=83.07% avg_auc=73.42%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.301461 Test loss=0.509171 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.29063281416893005
[5/24] Train loss=0.30450281500816345
[10/24] Train loss=0.30473652482032776
[15/24] Train loss=0.29158660769462585
[20/24] Train loss=0.2897317409515381
Test set avg_accuracy=74.60% avg_sensitivity=42.00%, avg_specificity=84.04% avg_auc=73.77%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.301076 Test loss=0.502746 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.273477703332901
[5/24] Train loss=0.2968503534793854
[10/24] Train loss=0.30523261427879333
[15/24] Train loss=0.30845192074775696
[20/24] Train loss=0.29205524921417236
Test set avg_accuracy=76.94% avg_sensitivity=7.59%, avg_specificity=97.04% avg_auc=71.52%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.301597 Test loss=0.486781 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2879525423049927
[5/24] Train loss=0.2973335385322571
[10/24] Train loss=0.3009621500968933
[15/24] Train loss=0.29551538825035095
[20/24] Train loss=0.28382235765457153
Test set avg_accuracy=69.18% avg_sensitivity=47.80%, avg_specificity=75.38% avg_auc=70.53%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.293590 Test loss=0.548356 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2730148434638977
[5/24] Train loss=0.2887420058250427
[10/24] Train loss=0.29689326882362366
[15/24] Train loss=0.29707375168800354
[20/24] Train loss=0.27817225456237793
Test set avg_accuracy=79.28% avg_sensitivity=27.81%, avg_specificity=94.21% avg_auc=75.62%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.288039 Test loss=0.461996 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2856123745441437
[5/24] Train loss=0.30294716358184814
[10/24] Train loss=0.2878716289997101
[15/24] Train loss=0.30177560448646545
[20/24] Train loss=0.28430449962615967
Test set avg_accuracy=63.95% avg_sensitivity=70.92%, avg_specificity=61.92% avg_auc=73.28%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.292902 Test loss=0.565959 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.30039703845977783
[5/24] Train loss=0.30032879114151
[10/24] Train loss=0.28975462913513184
[15/24] Train loss=0.2900964319705963
[20/24] Train loss=0.27505671977996826
Test set avg_accuracy=85.60% avg_sensitivity=60.31%, avg_specificity=92.93% avg_auc=86.81%
Best model saved!! Metric=-0.3475619373708696!!
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.294227 Test loss=0.359075 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2848988175392151
[5/24] Train loss=0.29732653498649597
[10/24] Train loss=0.2896616756916046
[15/24] Train loss=0.2787489593029022
[20/24] Train loss=0.2706211805343628
Test set avg_accuracy=71.46% avg_sensitivity=47.74%, avg_specificity=78.33% avg_auc=72.85%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.285705 Test loss=0.512742 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.27978453040122986
[5/24] Train loss=0.2850162088871002
[10/24] Train loss=0.2866115868091583
[15/24] Train loss=0.2858942151069641
[20/24] Train loss=0.2699680030345917
Test set avg_accuracy=63.37% avg_sensitivity=62.98%, avg_specificity=63.49% avg_auc=70.08%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.285598 Test loss=0.589267 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.26912373304367065
[5/24] Train loss=0.3062141537666321
[10/24] Train loss=0.2749435603618622
[15/24] Train loss=0.29091519117355347
[20/24] Train loss=0.29534000158309937
Test set avg_accuracy=83.36% avg_sensitivity=65.18%, avg_specificity=88.63% avg_auc=85.66%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.288613 Test loss=0.391893 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.30010703206062317
[5/24] Train loss=0.2904733717441559
[10/24] Train loss=0.2887899577617645
[15/24] Train loss=0.2845446467399597
[20/24] Train loss=0.2791580855846405
Test set avg_accuracy=76.28% avg_sensitivity=23.23%, avg_specificity=91.65% avg_auc=72.41%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.286616 Test loss=0.489780 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.26756757497787476
[5/24] Train loss=0.2858988046646118
[10/24] Train loss=0.27377861738204956
[15/24] Train loss=0.28029265999794006
[20/24] Train loss=0.2746119499206543
Test set avg_accuracy=76.32% avg_sensitivity=30.19%, avg_specificity=89.69% avg_auc=72.64%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.277586 Test loss=0.497272 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.27207642793655396
[5/24] Train loss=0.28342312574386597
[10/24] Train loss=0.2814646363258362
[15/24] Train loss=0.2884606122970581
[20/24] Train loss=0.26439300179481506
Test set avg_accuracy=71.15% avg_sensitivity=36.67%, avg_specificity=81.14% avg_auc=69.22%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.275954 Test loss=0.526787 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2587479054927826
[5/24] Train loss=0.2853425145149231
[10/24] Train loss=0.2616644501686096
[15/24] Train loss=0.2788454294204712
[20/24] Train loss=0.26146751642227173
Test set avg_accuracy=69.40% avg_sensitivity=43.11%, avg_specificity=77.02% avg_auc=69.46%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.272163 Test loss=0.556721 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2609092593193054
[5/24] Train loss=0.274350643157959
[10/24] Train loss=0.2735767960548401
[15/24] Train loss=0.27852723002433777
[20/24] Train loss=0.2591678500175476
Test set avg_accuracy=72.89% avg_sensitivity=52.72%, avg_specificity=78.74% avg_auc=74.36%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.275719 Test loss=0.517589 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.27994075417518616
[5/24] Train loss=0.2740980386734009
[10/24] Train loss=0.2782168984413147
[15/24] Train loss=0.2726447582244873
[20/24] Train loss=0.2710416615009308
Test set avg_accuracy=57.02% avg_sensitivity=76.54%, avg_specificity=51.36% avg_auc=68.05%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.278087 Test loss=0.833265 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2726389765739441
[5/24] Train loss=0.2762283384799957
[10/24] Train loss=0.264222651720047
[15/24] Train loss=0.28359872102737427
[20/24] Train loss=0.27143779397010803
Test set avg_accuracy=69.34% avg_sensitivity=70.97%, avg_specificity=68.86% avg_auc=76.87%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.272924 Test loss=0.595839 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.28529077768325806
[5/24] Train loss=0.27630946040153503
[10/24] Train loss=0.27372509241104126
[15/24] Train loss=0.27841195464134216
[20/24] Train loss=0.26692819595336914
Test set avg_accuracy=77.15% avg_sensitivity=9.15%, avg_specificity=96.86% avg_auc=71.77%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.274752 Test loss=0.527435 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2660543620586395
[5/24] Train loss=0.2841450572013855
[10/24] Train loss=0.2816724181175232
[15/24] Train loss=0.2901725172996521
[20/24] Train loss=0.25701695680618286
Test set avg_accuracy=76.42% avg_sensitivity=14.31%, avg_specificity=94.42% avg_auc=70.57%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.279314 Test loss=0.494326 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2720053791999817
[5/24] Train loss=0.28596121072769165
[10/24] Train loss=0.269032746553421
[15/24] Train loss=0.2736276686191559
[20/24] Train loss=0.2734540104866028
Test set avg_accuracy=61.46% avg_sensitivity=68.95%, avg_specificity=59.29% avg_auc=69.26%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.278661 Test loss=0.723397 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2530011832714081
[5/24] Train loss=0.2788635790348053
[10/24] Train loss=0.2587515115737915
[15/24] Train loss=0.2653280198574066
[20/24] Train loss=0.2592047154903412
Test set avg_accuracy=84.62% avg_sensitivity=46.23%, avg_specificity=95.75% avg_auc=84.37%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.271027 Test loss=0.380204 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2683864235877991
[5/24] Train loss=0.2771870493888855
[10/24] Train loss=0.2642640471458435
[15/24] Train loss=0.26026803255081177
[20/24] Train loss=0.24064716696739197
Test set avg_accuracy=75.86% avg_sensitivity=11.59%, avg_specificity=94.49% avg_auc=70.95%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.262238 Test loss=0.515654 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2548615336418152
[5/24] Train loss=0.27312859892845154
[10/24] Train loss=0.25255274772644043
[15/24] Train loss=0.25763803720474243
[20/24] Train loss=0.2395624965429306
Test set avg_accuracy=76.69% avg_sensitivity=41.71%, avg_specificity=86.83% avg_auc=75.33%
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.255395 Test loss=0.488520 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.24581027030944824
[5/24] Train loss=0.24877560138702393
[10/24] Train loss=0.24430441856384277
[15/24] Train loss=0.24687014520168304
[20/24] Train loss=0.24061723053455353
Test set avg_accuracy=75.77% avg_sensitivity=25.96%, avg_specificity=90.21% avg_auc=70.23%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.248461 Test loss=0.526182 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.23525038361549377
[5/24] Train loss=0.2533762753009796
[10/24] Train loss=0.24510788917541504
[15/24] Train loss=0.23776641488075256
[20/24] Train loss=0.23030783236026764
Test set avg_accuracy=72.92% avg_sensitivity=43.51%, avg_specificity=81.44% avg_auc=73.17%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.244740 Test loss=0.519159 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.23809564113616943
[5/24] Train loss=0.2506197690963745
[10/24] Train loss=0.24737754464149475
[15/24] Train loss=0.2367280125617981
[20/24] Train loss=0.22839319705963135
Test set avg_accuracy=74.36% avg_sensitivity=41.60%, avg_specificity=83.86% avg_auc=74.02%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.246893 Test loss=0.515380 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2379959225654602
[5/24] Train loss=0.24323953688144684
[10/24] Train loss=0.24378974735736847
[15/24] Train loss=0.22982946038246155
[20/24] Train loss=0.23257823288440704
Test set avg_accuracy=68.57% avg_sensitivity=68.13%, avg_specificity=68.69% avg_auc=75.23%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.245885 Test loss=0.598923 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.23838572204113007
[5/24] Train loss=0.253850519657135
[10/24] Train loss=0.2423105388879776
[15/24] Train loss=0.23991118371486664
[20/24] Train loss=0.2304048091173172
Test set avg_accuracy=76.95% avg_sensitivity=32.62%, avg_specificity=89.81% avg_auc=75.46%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.248070 Test loss=0.480470 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2384369969367981
[5/24] Train loss=0.2511829137802124
[10/24] Train loss=0.244630828499794
[15/24] Train loss=0.23614607751369476
[20/24] Train loss=0.2346556931734085
Test set avg_accuracy=77.16% avg_sensitivity=7.18%, avg_specificity=97.45% avg_auc=64.75%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.246153 Test loss=0.596624 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2309238612651825
[5/24] Train loss=0.2543545961380005
[10/24] Train loss=0.260672390460968
[15/24] Train loss=0.23920117318630219
[20/24] Train loss=0.23250864446163177
Test set avg_accuracy=77.55% avg_sensitivity=7.47%, avg_specificity=97.87% avg_auc=67.54%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.252729 Test loss=0.646867 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2522311806678772
[5/24] Train loss=0.25413668155670166
[10/24] Train loss=0.2496129274368286
[15/24] Train loss=0.24220947921276093
[20/24] Train loss=0.23209932446479797
Test set avg_accuracy=77.58% avg_sensitivity=10.49%, avg_specificity=97.03% avg_auc=71.89%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.252934 Test loss=0.555824 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2435121089220047
[5/24] Train loss=0.2634901702404022
[10/24] Train loss=0.2538973093032837
[15/24] Train loss=0.23413164913654327
[20/24] Train loss=0.23442815244197845
Test set avg_accuracy=76.68% avg_sensitivity=19.70%, avg_specificity=93.20% avg_auc=66.71%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.251173 Test loss=0.557899 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.2380240559577942
[5/24] Train loss=0.25088974833488464
[10/24] Train loss=0.24397492408752441
[15/24] Train loss=0.2355443388223648
[20/24] Train loss=0.22865302860736847
Test set avg_accuracy=76.09% avg_sensitivity=29.49%, avg_specificity=89.60% avg_auc=71.60%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.242510 Test loss=0.506999 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2335967719554901
[5/24] Train loss=0.2376590520143509
[10/24] Train loss=0.23797495663166046
[15/24] Train loss=0.22964546084403992
[20/24] Train loss=0.22098393738269806
Test set avg_accuracy=75.39% avg_sensitivity=29.61%, avg_specificity=88.66% avg_auc=72.09%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.236143 Test loss=0.525622 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2260127067565918
[5/24] Train loss=0.22746355831623077
[10/24] Train loss=0.23152850568294525
[15/24] Train loss=0.22942769527435303
[20/24] Train loss=0.21701841056346893
Test set avg_accuracy=75.99% avg_sensitivity=6.95%, avg_specificity=96.00% avg_auc=67.41%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.233861 Test loss=0.576855 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.23587431013584137
[5/24] Train loss=0.22677740454673767
[10/24] Train loss=0.22943146526813507
[15/24] Train loss=0.22077736258506775
[20/24] Train loss=0.22422848641872406
Test set avg_accuracy=75.47% avg_sensitivity=12.28%, avg_specificity=93.79% avg_auc=68.84%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.231256 Test loss=0.576712 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2225712090730667
[5/24] Train loss=0.22402557730674744
[10/24] Train loss=0.227395161986351
[15/24] Train loss=0.2150065302848816
[20/24] Train loss=0.21868515014648438
Test set avg_accuracy=74.41% avg_sensitivity=51.33%, avg_specificity=81.11% avg_auc=74.26%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.227734 Test loss=0.519500 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.22365352511405945
[5/24] Train loss=0.2216668277978897
[10/24] Train loss=0.23718956112861633
[15/24] Train loss=0.221279576420784
[20/24] Train loss=0.21363438665866852
Test set avg_accuracy=75.21% avg_sensitivity=31.29%, avg_specificity=87.94% avg_auc=71.90%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.227002 Test loss=0.521103 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.21985821425914764
[5/24] Train loss=0.22068679332733154
[10/24] Train loss=0.21996590495109558
[15/24] Train loss=0.21937432885169983
[20/24] Train loss=0.22100256383419037
Test set avg_accuracy=76.46% avg_sensitivity=41.31%, avg_specificity=86.65% avg_auc=74.20%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.226381 Test loss=0.506424 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.21182338893413544
[5/24] Train loss=0.22992001473903656
[10/24] Train loss=0.2165224403142929
[15/24] Train loss=0.21554440259933472
[20/24] Train loss=0.20824478566646576
Test set avg_accuracy=76.03% avg_sensitivity=16.86%, avg_specificity=93.18% avg_auc=69.88%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.224732 Test loss=0.530323 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.2237311452627182
[5/24] Train loss=0.2302568554878235
[10/24] Train loss=0.2143838107585907
[15/24] Train loss=0.21366986632347107
[20/24] Train loss=0.2062024474143982
Test set avg_accuracy=76.34% avg_sensitivity=16.51%, avg_specificity=93.68% avg_auc=69.27%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.223017 Test loss=0.548354 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.22514672577381134
[5/24] Train loss=0.21544606983661652
[10/24] Train loss=0.2253110110759735
[15/24] Train loss=0.2194995880126953
[20/24] Train loss=0.2054065763950348
Test set avg_accuracy=75.00% avg_sensitivity=24.80%, avg_specificity=89.55% avg_auc=70.27%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.221916 Test loss=0.523438 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.21354684233665466
[5/24] Train loss=0.23039814829826355
[10/24] Train loss=0.21600934863090515
[15/24] Train loss=0.23073232173919678
[20/24] Train loss=0.21250033378601074
Test set avg_accuracy=73.85% avg_sensitivity=31.81%, avg_specificity=86.04% avg_auc=68.64%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.226960 Test loss=0.559700 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.20878785848617554
[5/24] Train loss=0.22191676497459412
[10/24] Train loss=0.21467044949531555
[15/24] Train loss=0.22440281510353088
[20/24] Train loss=0.21950963139533997
Test set avg_accuracy=74.62% avg_sensitivity=44.61%, avg_specificity=83.32% avg_auc=74.21%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.226076 Test loss=0.528758 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.2178507000207901
[5/24] Train loss=0.228438138961792
[10/24] Train loss=0.2330169975757599
[15/24] Train loss=0.214518204331398
[20/24] Train loss=0.21122455596923828
Test set avg_accuracy=74.11% avg_sensitivity=46.23%, avg_specificity=82.20% avg_auc=75.47%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.227640 Test loss=0.499713 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.21952445805072784
[5/24] Train loss=0.24396894872188568
[10/24] Train loss=0.23262199759483337
[15/24] Train loss=0.2178594321012497
[20/24] Train loss=0.21157364547252655
Test set avg_accuracy=76.12% avg_sensitivity=43.97%, avg_specificity=85.44% avg_auc=75.16%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.225792 Test loss=0.512461 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.22085700929164886
[5/24] Train loss=0.22649140655994415
[10/24] Train loss=0.21185821294784546
[15/24] Train loss=0.20545732975006104
[20/24] Train loss=0.2085791379213333
Test set avg_accuracy=74.43% avg_sensitivity=39.92%, avg_specificity=84.43% avg_auc=73.11%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.221297 Test loss=0.541869 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.2150120586156845
[5/24] Train loss=0.20813465118408203
[10/24] Train loss=0.21516670286655426
[15/24] Train loss=0.20076708495616913
[20/24] Train loss=0.20008233189582825
Test set avg_accuracy=75.27% avg_sensitivity=35.63%, avg_specificity=86.77% avg_auc=73.33%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.213500 Test loss=0.504328 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.2122991681098938
[5/24] Train loss=0.20566219091415405
[10/24] Train loss=0.20258523523807526
[15/24] Train loss=0.20558412373065948
[20/24] Train loss=0.19432659447193146
Test set avg_accuracy=74.15% avg_sensitivity=47.28%, avg_specificity=81.94% avg_auc=73.64%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.209776 Test loss=0.533461 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.19827841222286224
[5/24] Train loss=0.20466622710227966
[10/24] Train loss=0.20357787609100342
[15/24] Train loss=0.20082950592041016
[20/24] Train loss=0.1937500536441803
Test set avg_accuracy=75.85% avg_sensitivity=37.89%, avg_specificity=86.85% avg_auc=74.45%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.207375 Test loss=0.504224 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.20373593270778656
[5/24] Train loss=0.20617561042308807
[10/24] Train loss=0.19762209057807922
[15/24] Train loss=0.19793172180652618
[20/24] Train loss=0.19270195066928864
Test set avg_accuracy=76.65% avg_sensitivity=24.51%, avg_specificity=91.77% avg_auc=73.69%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.204887 Test loss=0.525185 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.208456352353096
[5/24] Train loss=0.20055341720581055
[10/24] Train loss=0.20453888177871704
[15/24] Train loss=0.1956413835287094
[20/24] Train loss=0.19537879526615143
Test set avg_accuracy=75.91% avg_sensitivity=35.17%, avg_specificity=87.72% avg_auc=73.70%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.205112 Test loss=0.515554 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.19909293949604034
[5/24] Train loss=0.20105555653572083
[10/24] Train loss=0.19811685383319855
[15/24] Train loss=0.2000078558921814
[20/24] Train loss=0.18773750960826874
Test set avg_accuracy=75.68% avg_sensitivity=27.58%, avg_specificity=89.62% avg_auc=72.82%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.202907 Test loss=0.525463 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.19677035510540009
[5/24] Train loss=0.1971004605293274
[10/24] Train loss=0.19421112537384033
[15/24] Train loss=0.19574885070323944
[20/24] Train loss=0.18751659989356995
Test set avg_accuracy=76.03% avg_sensitivity=39.63%, avg_specificity=86.58% avg_auc=74.42%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.200636 Test loss=0.510248 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.19872026145458221
[5/24] Train loss=0.20463187992572784
[10/24] Train loss=0.19351227581501007
[15/24] Train loss=0.19213546812534332
[20/24] Train loss=0.18636712431907654
Test set avg_accuracy=76.03% avg_sensitivity=21.67%, avg_specificity=91.79% avg_auc=72.34%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.201264 Test loss=0.543512 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.19371774792671204
[5/24] Train loss=0.20315752923488617
[10/24] Train loss=0.19409207999706268
[15/24] Train loss=0.19177138805389404
[20/24] Train loss=0.1864319145679474
Test set avg_accuracy=75.81% avg_sensitivity=32.21%, avg_specificity=88.44% avg_auc=73.73%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.199511 Test loss=0.528605 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.19749677181243896
[5/24] Train loss=0.1992129236459732
[10/24] Train loss=0.18998321890830994
[15/24] Train loss=0.19182784855365753
[20/24] Train loss=0.18812228739261627
Test set avg_accuracy=76.29% avg_sensitivity=32.91%, avg_specificity=88.86% avg_auc=74.34%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.197626 Test loss=0.510557 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1956469565629959
[5/24] Train loss=0.1949479579925537
[10/24] Train loss=0.1972385048866272
[15/24] Train loss=0.19435876607894897
[20/24] Train loss=0.18542751669883728
Test set avg_accuracy=76.09% avg_sensitivity=23.87%, avg_specificity=91.23% avg_auc=73.25%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.198353 Test loss=0.530073 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.19602887332439423
[5/24] Train loss=0.18752838671207428
[10/24] Train loss=0.1869979351758957
[15/24] Train loss=0.19012798368930817
[20/24] Train loss=0.18446922302246094
Test set avg_accuracy=76.29% avg_sensitivity=26.01%, avg_specificity=90.86% avg_auc=73.16%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.197186 Test loss=0.528223 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.19715942442417145
[5/24] Train loss=0.19584116339683533
[10/24] Train loss=0.18743573129177094
[15/24] Train loss=0.18929772078990936
[20/24] Train loss=0.18408669531345367
Test set avg_accuracy=76.29% avg_sensitivity=21.84%, avg_specificity=92.07% avg_auc=72.19%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.196055 Test loss=0.554968 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.19263945519924164
[5/24] Train loss=0.1949521154165268
[10/24] Train loss=0.19269908964633942
[15/24] Train loss=0.19191502034664154
[20/24] Train loss=0.18262962996959686
Test set avg_accuracy=75.72% avg_sensitivity=28.85%, avg_specificity=89.30% avg_auc=73.32%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.195534 Test loss=0.528317 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1960567981004715
[5/24] Train loss=0.1891520619392395
[10/24] Train loss=0.1861734837293625
[15/24] Train loss=0.1863841861486435
[20/24] Train loss=0.18259631097316742
Test set avg_accuracy=76.09% avg_sensitivity=27.58%, avg_specificity=90.16% avg_auc=73.53%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.194759 Test loss=0.531946 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.19650092720985413
[5/24] Train loss=0.1885881870985031
[10/24] Train loss=0.19257670640945435
[15/24] Train loss=0.18707047402858734
[20/24] Train loss=0.18148845434188843
Test set avg_accuracy=76.22% avg_sensitivity=26.48%, avg_specificity=90.64% avg_auc=73.29%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.193853 Test loss=0.529526 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.19109892845153809
[5/24] Train loss=0.19243311882019043
[10/24] Train loss=0.1907777190208435
[15/24] Train loss=0.18697984516620636
[20/24] Train loss=0.1787809282541275
Test set avg_accuracy=76.07% avg_sensitivity=26.48%, avg_specificity=90.44% avg_auc=73.32%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.194017 Test loss=0.527416 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1878441870212555
[5/24] Train loss=0.19155988097190857
[10/24] Train loss=0.18822279572486877
[15/24] Train loss=0.1908770054578781
[20/24] Train loss=0.17733778059482574
Test set avg_accuracy=76.02% avg_sensitivity=28.10%, avg_specificity=89.91% avg_auc=73.52%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.193476 Test loss=0.531503 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1903170347213745
[5/24] Train loss=0.18828506767749786
[10/24] Train loss=0.1864863783121109
[15/24] Train loss=0.1851956844329834
[20/24] Train loss=0.18047714233398438
Test set avg_accuracy=76.04% avg_sensitivity=25.72%, avg_specificity=90.63% avg_auc=73.01%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.193130 Test loss=0.543059 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.19199690222740173
[5/24] Train loss=0.1866036057472229
[10/24] Train loss=0.1902066469192505
[15/24] Train loss=0.1882777363061905
[20/24] Train loss=0.18480771780014038
Test set avg_accuracy=76.15% avg_sensitivity=25.78%, avg_specificity=90.75% avg_auc=73.12%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.192600 Test loss=0.539426 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.19197067618370056
[5/24] Train loss=0.18936604261398315
[10/24] Train loss=0.1877892017364502
[15/24] Train loss=0.18702562153339386
[20/24] Train loss=0.17792148888111115
Test set avg_accuracy=76.09% avg_sensitivity=27.98%, avg_specificity=90.04% avg_auc=73.41%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.192972 Test loss=0.530065 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.18771395087242126
[5/24] Train loss=0.18384088575839996
[10/24] Train loss=0.18473154306411743
[15/24] Train loss=0.19071239233016968
[20/24] Train loss=0.17948609590530396
Test set avg_accuracy=75.96% avg_sensitivity=27.17%, avg_specificity=90.11% avg_auc=73.17%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.192486 Test loss=0.532902 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1900511533021927
[5/24] Train loss=0.1843123883008957
[10/24] Train loss=0.18281613290309906
[15/24] Train loss=0.18550065159797668
[20/24] Train loss=0.17837733030319214
Test set avg_accuracy=76.17% avg_sensitivity=26.88%, avg_specificity=90.46% avg_auc=73.33%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.192256 Test loss=0.533524 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.18950383365154266
[5/24] Train loss=0.19494187831878662
[10/24] Train loss=0.18372324109077454
[15/24] Train loss=0.18447743356227875
[20/24] Train loss=0.17852675914764404
Test set avg_accuracy=76.02% avg_sensitivity=26.25%, avg_specificity=90.44% avg_auc=72.97%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.192785 Test loss=0.538834 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1836719661951065
[5/24] Train loss=0.186986044049263
[10/24] Train loss=0.18137109279632568
[15/24] Train loss=0.18644239008426666
[20/24] Train loss=0.18095271289348602
Test set avg_accuracy=76.09% avg_sensitivity=26.19%, avg_specificity=90.56% avg_auc=73.14%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.191605 Test loss=0.538339 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1898384541273117
[5/24] Train loss=0.1889393925666809
[10/24] Train loss=0.18266025185585022
[15/24] Train loss=0.18637388944625854
[20/24] Train loss=0.1779336929321289
Test set avg_accuracy=76.05% avg_sensitivity=26.36%, avg_specificity=90.46% avg_auc=73.04%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.191715 Test loss=0.537843 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.18554869294166565
[5/24] Train loss=0.18581566214561462
[10/24] Train loss=0.18651114404201508
[15/24] Train loss=0.18590869009494781
[20/24] Train loss=0.17712992429733276
Test set avg_accuracy=76.11% avg_sensitivity=26.13%, avg_specificity=90.59% avg_auc=73.02%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.191531 Test loss=0.538577 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.19223333895206451
[5/24] Train loss=0.1904066503047943
[10/24] Train loss=0.1884993314743042
[15/24] Train loss=0.18554987013339996
[20/24] Train loss=0.17846611142158508
Test set avg_accuracy=76.12% avg_sensitivity=26.30%, avg_specificity=90.56% avg_auc=73.03%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.192051 Test loss=0.538011 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=85.60% sen=60.31%, spe=92.93%, auc=86.81%!
Fold[10] Avg_overlap=0.57%(±0.3125004017032916)
Final Avg Result: avg_acc=81.61%(±3.2215461460167396) avg_sen=64.55% (±10.028950434548554) avg_spe=87.32% (±6.690479009428211) avg_auc=85.83% (±1.8383197219158787) avg_overlap=0.59% (±0.0554721467129303)
