/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=1.5081186294555664
[5/24] Train loss=1.4841530323028564
[10/24] Train loss=1.4509316682815552
[15/24] Train loss=1.4214739799499512
[20/24] Train loss=1.424495816230774
Test set avg_accuracy=59.88% avg_sensitivity=51.16%, avg_specificity=63.00% avg_auc=60.08%
Best model saved!! Metric=-91.87558105612158!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=1.447514 Test loss=0.686100 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4092776775360107
[5/24] Train loss=1.405081033706665
[10/24] Train loss=1.3980698585510254
[15/24] Train loss=1.3536555767059326
[20/24] Train loss=1.3315603733062744
Test set avg_accuracy=63.83% avg_sensitivity=73.18%, avg_specificity=60.49% avg_auc=72.61%
Best model saved!! Metric=-55.89195359864076!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=1.376822 Test loss=0.639714 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3346314430236816
[5/24] Train loss=1.31300687789917
[10/24] Train loss=1.3207858800888062
[15/24] Train loss=1.2650740146636963
[20/24] Train loss=1.271700143814087
Test set avg_accuracy=66.51% avg_sensitivity=79.17%, avg_specificity=61.99% avg_auc=77.78%
Best model saved!! Metric=-40.55026802077188!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=1.299939 Test loss=0.610282 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.23988676071167
[5/24] Train loss=1.2282952070236206
[10/24] Train loss=1.2405396699905396
[15/24] Train loss=1.1904973983764648
[20/24] Train loss=1.1572134494781494
Test set avg_accuracy=69.54% avg_sensitivity=83.77%, avg_specificity=64.46% avg_auc=81.02%
Best model saved!! Metric=-27.203817864951205!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=1.221752 Test loss=0.586228 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1485133171081543
[5/24] Train loss=1.1379120349884033
[10/24] Train loss=1.1800469160079956
[15/24] Train loss=1.107508659362793
[20/24] Train loss=1.0876760482788086
Test set avg_accuracy=70.22% avg_sensitivity=87.09%, avg_specificity=64.20% avg_auc=83.12%
Best model saved!! Metric=-21.369518451195674!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=1.147965 Test loss=0.577949 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.062712550163269
[5/24] Train loss=1.0758622884750366
[10/24] Train loss=1.1198543310165405
[15/24] Train loss=1.0397415161132812
[20/24] Train loss=1.032731294631958
Test set avg_accuracy=70.72% avg_sensitivity=88.77%, avg_specificity=64.27% avg_auc=85.07%
Best model saved!! Metric=-17.179374423618796!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=1.081526 Test loss=0.566232 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.010035753250122
[5/24] Train loss=1.0039584636688232
[10/24] Train loss=1.0680644512176514
[15/24] Train loss=0.9836628437042236
[20/24] Train loss=0.9746613502502441
Test set avg_accuracy=73.87% avg_sensitivity=87.48%, avg_specificity=69.01% avg_auc=86.51%
Best model saved!! Metric=-9.132985362449134!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=1.020021 Test loss=0.528286 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9420275688171387
[5/24] Train loss=0.9527939558029175
[10/24] Train loss=1.0075616836547852
[15/24] Train loss=0.9322779178619385
[20/24] Train loss=0.9064702987670898
Test set avg_accuracy=76.21% avg_sensitivity=87.23%, avg_specificity=72.27% avg_auc=88.44%
Best model saved!! Metric=-1.843270835012845!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.960212 Test loss=0.500205 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.8860294222831726
[5/24] Train loss=0.8970575332641602
[10/24] Train loss=0.9394924640655518
[15/24] Train loss=0.8850948810577393
[20/24] Train loss=0.8558343648910522
Test set avg_accuracy=77.98% avg_sensitivity=87.73%, avg_specificity=74.50% avg_auc=89.74%
Best model saved!! Metric=3.95445314529033!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.906246 Test loss=0.478411 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8222024440765381
[5/24] Train loss=0.844856321811676
[10/24] Train loss=0.9183478355407715
[15/24] Train loss=0.8400580286979675
[20/24] Train loss=0.8203574419021606
Test set avg_accuracy=78.97% avg_sensitivity=88.22%, avg_specificity=75.67% avg_auc=90.52%
Best model saved!! Metric=7.382183942271595!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.861016 Test loss=0.464213 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.7867136001586914
[5/24] Train loss=0.7969157099723816
[10/24] Train loss=0.8679996728897095
[15/24] Train loss=0.8115240931510925
[20/24] Train loss=0.7562556266784668
Test set avg_accuracy=81.30% avg_sensitivity=87.43%, avg_specificity=79.11% avg_auc=91.24%
Best model saved!! Metric=13.086520099471258!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.820403 Test loss=0.434639 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7466613054275513
[5/24] Train loss=0.7699437737464905
[10/24] Train loss=0.8404875993728638
[15/24] Train loss=0.777930736541748
[20/24] Train loss=0.704392671585083
Test set avg_accuracy=81.90% avg_sensitivity=88.22%, avg_specificity=79.64% avg_auc=91.83%
Best model saved!! Metric=15.596898187861015!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.782960 Test loss=0.424207 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7225252389907837
[5/24] Train loss=0.7303912043571472
[10/24] Train loss=0.8062738180160522
[15/24] Train loss=0.7633617520332336
[20/24] Train loss=0.699547290802002
Test set avg_accuracy=83.85% avg_sensitivity=85.50%, avg_specificity=83.27% avg_auc=92.12%
Best model saved!! Metric=18.74346046541646!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.754675 Test loss=0.387051 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.6921277046203613
[5/24] Train loss=0.7014352679252625
[10/24] Train loss=0.7930359244346619
[15/24] Train loss=0.7403981685638428
[20/24] Train loss=0.685789167881012
Test set avg_accuracy=84.47% avg_sensitivity=86.00%, avg_specificity=83.92% avg_auc=92.49%
Best model saved!! Metric=20.877201895239935!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.731236 Test loss=0.374715 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.662998378276825
[5/24] Train loss=0.6796205043792725
[10/24] Train loss=0.7538396716117859
[15/24] Train loss=0.7188358902931213
[20/24] Train loss=0.6570855975151062
Test set avg_accuracy=85.39% avg_sensitivity=83.87%, avg_specificity=85.93% avg_auc=92.67%
Best model saved!! Metric=21.859153235817615!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.710409 Test loss=0.355845 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6484745144844055
[5/24] Train loss=0.6586501002311707
[10/24] Train loss=0.7718892693519592
[15/24] Train loss=0.7155081629753113
[20/24] Train loss=0.6378782987594604
Test set avg_accuracy=85.01% avg_sensitivity=86.74%, avg_specificity=84.40% avg_auc=92.93%
Best model saved!! Metric=23.07643031212376!!
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.694721 Test loss=0.362730 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6213257312774658
[5/24] Train loss=0.6343924403190613
[10/24] Train loss=0.7442687153816223
[15/24] Train loss=0.6910854578018188
[20/24] Train loss=0.6008124351501465
Test set avg_accuracy=85.49% avg_sensitivity=86.59%, avg_specificity=85.10% avg_auc=93.19%
Best model saved!! Metric=24.377627737017903!!
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.675028 Test loss=0.351053 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6170010566711426
[5/24] Train loss=0.6163346767425537
[10/24] Train loss=0.7419264912605286
[15/24] Train loss=0.6684410572052002
[20/24] Train loss=0.6059260368347168
Test set avg_accuracy=85.43% avg_sensitivity=87.18%, avg_specificity=84.80% avg_auc=93.34%
Best model saved!! Metric=24.753908641873196!!
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.662054 Test loss=0.351704 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.5914443135261536
[5/24] Train loss=0.6182766556739807
[10/24] Train loss=0.7112191915512085
[15/24] Train loss=0.6753395199775696
[20/24] Train loss=0.6065671443939209
Test set avg_accuracy=85.52% avg_sensitivity=87.78%, avg_specificity=84.71% avg_auc=93.53%
Best model saved!! Metric=25.54871044168469!!
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.648123 Test loss=0.349673 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5925845503807068
[5/24] Train loss=0.6021311283111572
[10/24] Train loss=0.6997091174125671
[15/24] Train loss=0.6443943381309509
[20/24] Train loss=0.5778602957725525
Test set avg_accuracy=83.67% avg_sensitivity=90.30%, avg_specificity=81.30% avg_auc=93.64%
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.635619 Test loss=0.383655 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.591791570186615
[5/24] Train loss=0.5822870135307312
[10/24] Train loss=0.6873087286949158
[15/24] Train loss=0.6417156457901001
[20/24] Train loss=0.5684320330619812
Test set avg_accuracy=84.77% avg_sensitivity=89.31%, avg_specificity=83.14% avg_auc=93.76%
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.622139 Test loss=0.360870 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5704490542411804
[5/24] Train loss=0.5731168389320374
[10/24] Train loss=0.6817384362220764
[15/24] Train loss=0.6183049082756042
[20/24] Train loss=0.5351920127868652
Test set avg_accuracy=85.52% avg_sensitivity=88.77%, avg_specificity=84.36% avg_auc=93.88%
Best model saved!! Metric=26.528631554502653!!
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.609969 Test loss=0.344579 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5656840205192566
[5/24] Train loss=0.5538856983184814
[10/24] Train loss=0.6696828603744507
[15/24] Train loss=0.6187222003936768
[20/24] Train loss=0.5403755307197571
Test set avg_accuracy=86.08% avg_sensitivity=87.38%, avg_specificity=85.62% avg_auc=93.99%
Best model saved!! Metric=27.07327841913056!!
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.597630 Test loss=0.329430 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5571202635765076
[5/24] Train loss=0.5334696769714355
[10/24] Train loss=0.6504508256912231
[15/24] Train loss=0.6053200364112854
[20/24] Train loss=0.5200009346008301
Test set avg_accuracy=83.46% avg_sensitivity=91.84%, avg_specificity=80.47% avg_auc=93.98%
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.585466 Test loss=0.392729 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5373275876045227
[5/24] Train loss=0.5281599164009094
[10/24] Train loss=0.6520348191261292
[15/24] Train loss=0.6034508347511292
[20/24] Train loss=0.5057271122932434
Test set avg_accuracy=86.32% avg_sensitivity=87.18%, avg_specificity=86.00% avg_auc=93.89%
Best model saved!! Metric=27.39309660845936!!
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.573402 Test loss=0.326961 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.521869957447052
[5/24] Train loss=0.5109393000602722
[10/24] Train loss=0.6436570882797241
[15/24] Train loss=0.584516167640686
[20/24] Train loss=0.5109462738037109
Test set avg_accuracy=82.66% avg_sensitivity=90.75%, avg_specificity=79.77% avg_auc=93.38%
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.562329 Test loss=0.401089 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5300629734992981
[5/24] Train loss=0.4910675883293152
[10/24] Train loss=0.6137482523918152
[15/24] Train loss=0.5695340633392334
[20/24] Train loss=0.5043662786483765
Test set avg_accuracy=85.48% avg_sensitivity=86.49%, avg_specificity=85.12% avg_auc=93.72%
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.548165 Test loss=0.336227 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.519777238368988
[5/24] Train loss=0.5185730457305908
[10/24] Train loss=0.617611825466156
[15/24] Train loss=0.5594033598899841
[20/24] Train loss=0.48686131834983826
Test set avg_accuracy=86.51% avg_sensitivity=87.18%, avg_specificity=86.27% avg_auc=93.93%
Best model saved!! Metric=27.892422306511747!!
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.546671 Test loss=0.325198 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5121469497680664
[5/24] Train loss=0.4655856192111969
[10/24] Train loss=0.6040638089179993
[15/24] Train loss=0.5530132055282593
[20/24] Train loss=0.4768950045108795
Test set avg_accuracy=82.58% avg_sensitivity=91.44%, avg_specificity=79.41% avg_auc=93.67%
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.535274 Test loss=0.397972 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.508525550365448
[5/24] Train loss=0.4849087595939636
[10/24] Train loss=0.5898831486701965
[15/24] Train loss=0.5575317740440369
[20/24] Train loss=0.46187421679496765
Test set avg_accuracy=85.23% avg_sensitivity=86.79%, avg_specificity=84.68% avg_auc=93.52%
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.526367 Test loss=0.342921 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4923410713672638
[5/24] Train loss=0.4793819487094879
[10/24] Train loss=0.5290964245796204
[15/24] Train loss=0.5428667068481445
[20/24] Train loss=0.4577452838420868
Test set avg_accuracy=85.73% avg_sensitivity=85.35%, avg_specificity=85.86% avg_auc=93.47%
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.507444 Test loss=0.329849 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.4796690344810486
[5/24] Train loss=0.4504748284816742
[10/24] Train loss=0.5237295031547546
[15/24] Train loss=0.5281643271446228
[20/24] Train loss=0.4452109932899475
Test set avg_accuracy=84.26% avg_sensitivity=86.89%, avg_specificity=83.32% avg_auc=92.90%
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.499597 Test loss=0.358424 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4839940369129181
[5/24] Train loss=0.4870162308216095
[10/24] Train loss=0.5285018682479858
[15/24] Train loss=0.5579581260681152
[20/24] Train loss=0.45150408148765564
Test set avg_accuracy=85.12% avg_sensitivity=83.82%, avg_specificity=85.58% avg_auc=92.96%
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.501033 Test loss=0.341602 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4800766110420227
[5/24] Train loss=0.4477260708808899
[10/24] Train loss=0.4966040849685669
[15/24] Train loss=0.4997316002845764
[20/24] Train loss=0.4102611839771271
Test set avg_accuracy=84.51% avg_sensitivity=86.00%, avg_specificity=83.97% avg_auc=93.21%
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.479170 Test loss=0.353986 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.47285088896751404
[5/24] Train loss=0.4360526502132416
[10/24] Train loss=0.4954172372817993
[15/24] Train loss=0.5182009935379028
[20/24] Train loss=0.42200198769569397
Test set avg_accuracy=71.03% avg_sensitivity=94.76%, avg_specificity=62.56% avg_auc=89.77%
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.473535 Test loss=0.688905 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4418870508670807
[5/24] Train loss=0.42314308881759644
[10/24] Train loss=0.5163676142692566
[15/24] Train loss=0.5151976346969604
[20/24] Train loss=0.42931613326072693
Test set avg_accuracy=73.35% avg_sensitivity=95.50%, avg_specificity=65.44% avg_auc=91.38%
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.471383 Test loss=0.618852 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4642559885978699
[5/24] Train loss=0.42837151885032654
[10/24] Train loss=0.4780803322792053
[15/24] Train loss=0.4868128001689911
[20/24] Train loss=0.4174892008304596
Test set avg_accuracy=83.72% avg_sensitivity=89.21%, avg_specificity=81.76% avg_auc=93.12%
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.452829 Test loss=0.378634 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.44442662596702576
[5/24] Train loss=0.44623130559921265
[10/24] Train loss=0.5120793581008911
[15/24] Train loss=0.47700732946395874
[20/24] Train loss=0.3946119546890259
Test set avg_accuracy=84.70% avg_sensitivity=83.72%, avg_specificity=85.05% avg_auc=92.46%
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.455624 Test loss=0.345606 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4491976797580719
[5/24] Train loss=0.436662495136261
[10/24] Train loss=0.5134684443473816
[15/24] Train loss=0.5303573608398438
[20/24] Train loss=0.42052072286605835
Test set avg_accuracy=87.11% avg_sensitivity=80.60%, avg_specificity=89.43% avg_auc=92.75%
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.462716 Test loss=0.305870 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.48337483406066895
[5/24] Train loss=0.39402303099632263
[10/24] Train loss=0.4869578182697296
[15/24] Train loss=0.5211083292961121
[20/24] Train loss=0.3877251446247101
Test set avg_accuracy=81.81% avg_sensitivity=88.22%, avg_specificity=79.52% avg_auc=92.45%
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.455693 Test loss=0.408658 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.41429221630096436
[5/24] Train loss=0.3866238594055176
[10/24] Train loss=0.4837455749511719
[15/24] Train loss=0.4922500252723694
[20/24] Train loss=0.43236756324768066
Test set avg_accuracy=87.14% avg_sensitivity=83.13%, avg_specificity=88.57% avg_auc=93.15%
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.446857 Test loss=0.311445 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.42479389905929565
[5/24] Train loss=0.36812257766723633
[10/24] Train loss=0.45463475584983826
[15/24] Train loss=0.4662872552871704
[20/24] Train loss=0.3989265561103821
Test set avg_accuracy=86.50% avg_sensitivity=70.21%, avg_specificity=92.31% avg_auc=91.29%
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.436685 Test loss=0.322935 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.43560990691185
[5/24] Train loss=0.36746808886528015
[10/24] Train loss=0.4682072699069977
[15/24] Train loss=0.46735885739326477
[20/24] Train loss=0.3939874470233917
Test set avg_accuracy=86.25% avg_sensitivity=77.88%, avg_specificity=89.24% avg_auc=92.11%
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.432329 Test loss=0.320740 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4278624653816223
[5/24] Train loss=0.37413260340690613
[10/24] Train loss=0.4611135721206665
[15/24] Train loss=0.4820643365383148
[20/24] Train loss=0.40035322308540344
Test set avg_accuracy=85.99% avg_sensitivity=77.04%, avg_specificity=89.19% avg_auc=91.42%
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.435157 Test loss=0.328717 Current lr=[0.00029967723776099]

[0/24] Train loss=0.39920559525489807
[5/24] Train loss=0.35700082778930664
[10/24] Train loss=0.5107322931289673
[15/24] Train loss=0.4492802023887634
[20/24] Train loss=0.4251858592033386
Test set avg_accuracy=79.87% avg_sensitivity=86.44%, avg_specificity=77.52% avg_auc=90.57%
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.436444 Test loss=0.439087 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.44571200013160706
[5/24] Train loss=0.3931180238723755
[10/24] Train loss=0.4553754925727844
[15/24] Train loss=0.4682080149650574
[20/24] Train loss=0.37943151593208313
Test set avg_accuracy=75.68% avg_sensitivity=94.41%, avg_specificity=68.99% avg_auc=91.14%
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.435713 Test loss=0.588780 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.428242951631546
[5/24] Train loss=0.3626921772956848
[10/24] Train loss=0.42909738421440125
[15/24] Train loss=0.46593788266181946
[20/24] Train loss=0.3694184422492981
Test set avg_accuracy=86.71% avg_sensitivity=81.49%, avg_specificity=88.57% avg_auc=93.08%
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.423248 Test loss=0.319062 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3959142863750458
[5/24] Train loss=0.35265305638313293
[10/24] Train loss=0.43367311358451843
[15/24] Train loss=0.46848827600479126
[20/24] Train loss=0.3625117838382721
Test set avg_accuracy=87.43% avg_sensitivity=75.80%, avg_specificity=91.59% avg_auc=91.88%
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.413842 Test loss=0.309348 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.41109681129455566
[5/24] Train loss=0.405335396528244
[10/24] Train loss=0.43952664732933044
[15/24] Train loss=0.4493042230606079
[20/24] Train loss=0.3988816738128662
Test set avg_accuracy=82.64% avg_sensitivity=85.70%, avg_specificity=81.55% avg_auc=91.74%
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.418729 Test loss=0.394574 Current lr=[0.000298904600941902]

[0/24] Train loss=0.41010087728500366
[5/24] Train loss=0.3243691325187683
[10/24] Train loss=0.43174007534980774
[15/24] Train loss=0.43412715196609497
[20/24] Train loss=0.37418049573898315
Test set avg_accuracy=81.74% avg_sensitivity=83.42%, avg_specificity=81.15% avg_auc=90.95%
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.394130 Test loss=0.424968 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.38315922021865845
[5/24] Train loss=0.3407691419124603
[10/24] Train loss=0.3805485963821411
[15/24] Train loss=0.4378293454647064
[20/24] Train loss=0.3592153787612915
Test set avg_accuracy=77.42% avg_sensitivity=94.46%, avg_specificity=71.34% avg_auc=92.29%
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.389211 Test loss=0.544180 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3794651925563812
[5/24] Train loss=0.3294937014579773
[10/24] Train loss=0.40603169798851013
[15/24] Train loss=0.43156155943870544
[20/24] Train loss=0.3638256788253784
Test set avg_accuracy=85.68% avg_sensitivity=85.35%, avg_specificity=85.79% avg_auc=92.62%
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.389930 Test loss=0.351693 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3816749155521393
[5/24] Train loss=0.33085575699806213
[10/24] Train loss=0.39797744154930115
[15/24] Train loss=0.41495853662490845
[20/24] Train loss=0.34927523136138916
Test set avg_accuracy=84.57% avg_sensitivity=88.17%, avg_specificity=83.28% avg_auc=93.41%
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.384812 Test loss=0.364551 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.37727391719818115
[5/24] Train loss=0.32721784710884094
[10/24] Train loss=0.35921186208724976
[15/24] Train loss=0.4086464047431946
[20/24] Train loss=0.32675760984420776
Test set avg_accuracy=85.76% avg_sensitivity=82.29%, avg_specificity=86.99% avg_auc=91.98%
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.369056 Test loss=0.344644 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.36623600125312805
[5/24] Train loss=0.31661611795425415
[10/24] Train loss=0.3760297894477844
[15/24] Train loss=0.3902907967567444
[20/24] Train loss=0.3499656915664673
Test set avg_accuracy=83.87% avg_sensitivity=82.98%, avg_specificity=84.18% avg_auc=90.98%
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.365044 Test loss=0.392970 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3648566007614136
[5/24] Train loss=0.3377363383769989
[10/24] Train loss=0.3923228085041046
[15/24] Train loss=0.41902169585227966
[20/24] Train loss=0.3459838926792145
Test set avg_accuracy=71.90% avg_sensitivity=92.78%, avg_specificity=64.45% avg_auc=89.52%
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.364817 Test loss=0.656154 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.36599040031433105
[5/24] Train loss=0.3274212181568146
[10/24] Train loss=0.381537526845932
[15/24] Train loss=0.39960914850234985
[20/24] Train loss=0.3650782108306885
Test set avg_accuracy=83.91% avg_sensitivity=86.64%, avg_specificity=82.93% avg_auc=92.52%
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.370258 Test loss=0.389186 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3631659746170044
[5/24] Train loss=0.31956472992897034
[10/24] Train loss=0.33464720845222473
[15/24] Train loss=0.39440128207206726
[20/24] Train loss=0.3521217405796051
Test set avg_accuracy=85.26% avg_sensitivity=82.14%, avg_specificity=86.38% avg_auc=91.62%
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.365704 Test loss=0.372619 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.36930355429649353
[5/24] Train loss=0.3112194836139679
[10/24] Train loss=0.3763563930988312
[15/24] Train loss=0.3806449770927429
[20/24] Train loss=0.32199758291244507
Test set avg_accuracy=85.17% avg_sensitivity=84.22%, avg_specificity=85.51% avg_auc=92.68%
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.354273 Test loss=0.354160 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.33992865681648254
[5/24] Train loss=0.34288492798805237
[10/24] Train loss=0.36690208315849304
[15/24] Train loss=0.4092739224433899
[20/24] Train loss=0.3379356563091278
Test set avg_accuracy=86.84% avg_sensitivity=78.38%, avg_specificity=89.86% avg_auc=92.51%
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.359166 Test loss=0.322456 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.322925329208374
[5/24] Train loss=0.3083480894565582
[10/24] Train loss=0.3880115747451782
[15/24] Train loss=0.3906532824039459
[20/24] Train loss=0.3420071601867676
Test set avg_accuracy=86.09% avg_sensitivity=72.04%, avg_specificity=91.11% avg_auc=90.68%
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.361525 Test loss=0.347962 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3487060070037842
[5/24] Train loss=0.3749242424964905
[10/24] Train loss=0.3587345480918884
[15/24] Train loss=0.38349127769470215
[20/24] Train loss=0.3447691798210144
Test set avg_accuracy=84.92% avg_sensitivity=58.09%, avg_specificity=94.50% avg_auc=87.01%
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.357543 Test loss=0.396219 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3274417817592621
[5/24] Train loss=0.2986738085746765
[10/24] Train loss=0.3532314598560333
[15/24] Train loss=0.4022121727466583
[20/24] Train loss=0.3486202359199524
Test set avg_accuracy=86.65% avg_sensitivity=75.21%, avg_specificity=90.74% avg_auc=91.47%
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.348979 Test loss=0.334732 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3388991355895996
[5/24] Train loss=0.2878190279006958
[10/24] Train loss=0.3338269591331482
[15/24] Train loss=0.35803478956222534
[20/24] Train loss=0.32042595744132996
Test set avg_accuracy=85.34% avg_sensitivity=83.77%, avg_specificity=85.90% avg_auc=93.01%
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.340415 Test loss=0.343962 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3053189814090729
[5/24] Train loss=0.3151560127735138
[10/24] Train loss=0.337706595659256
[15/24] Train loss=0.34955886006355286
[20/24] Train loss=0.3121137320995331
Test set avg_accuracy=87.53% avg_sensitivity=78.38%, avg_specificity=90.79% avg_auc=92.15%
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.335016 Test loss=0.316851 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3115904629230499
[5/24] Train loss=0.2894510328769684
[10/24] Train loss=0.35761263966560364
[15/24] Train loss=0.34903883934020996
[20/24] Train loss=0.28922513127326965
Test set avg_accuracy=82.33% avg_sensitivity=88.67%, avg_specificity=80.07% avg_auc=92.51%
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.337787 Test loss=0.437984 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3231811821460724
[5/24] Train loss=0.3141716718673706
[10/24] Train loss=0.3293071985244751
[15/24] Train loss=0.3344137668609619
[20/24] Train loss=0.2904575765132904
Test set avg_accuracy=84.69% avg_sensitivity=85.16%, avg_specificity=84.52% avg_auc=92.77%
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.319913 Test loss=0.372366 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3142864406108856
[5/24] Train loss=0.26697227358818054
[10/24] Train loss=0.31947067379951477
[15/24] Train loss=0.3502797484397888
[20/24] Train loss=0.29137492179870605
Test set avg_accuracy=85.76% avg_sensitivity=83.42%, avg_specificity=86.59% avg_auc=91.96%
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.311301 Test loss=0.361122 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.31559959053993225
[5/24] Train loss=0.29083773493766785
[10/24] Train loss=0.3307718336582184
[15/24] Train loss=0.34638285636901855
[20/24] Train loss=0.30415359139442444
Test set avg_accuracy=86.03% avg_sensitivity=85.21%, avg_specificity=86.32% avg_auc=93.05%
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.317057 Test loss=0.353967 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3110347390174866
[5/24] Train loss=0.26447540521621704
[10/24] Train loss=0.30179038643836975
[15/24] Train loss=0.33382660150527954
[20/24] Train loss=0.28674033284187317
Test set avg_accuracy=85.89% avg_sensitivity=83.87%, avg_specificity=86.61% avg_auc=92.25%
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.306657 Test loss=0.368133 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2970812916755676
[5/24] Train loss=0.2717231810092926
[10/24] Train loss=0.292523056268692
[15/24] Train loss=0.31875818967819214
[20/24] Train loss=0.2737358808517456
Test set avg_accuracy=86.76% avg_sensitivity=76.79%, avg_specificity=90.32% avg_auc=91.58%
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.299041 Test loss=0.340054 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.27789849042892456
[5/24] Train loss=0.26943308115005493
[10/24] Train loss=0.3040674328804016
[15/24] Train loss=0.3495171368122101
[20/24] Train loss=0.3267711102962494
Test set avg_accuracy=86.91% avg_sensitivity=74.52%, avg_specificity=91.34% avg_auc=91.65%
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.317041 Test loss=0.327782 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.2922222316265106
[5/24] Train loss=0.32691821455955505
[10/24] Train loss=0.36326414346694946
[15/24] Train loss=0.3406245708465576
[20/24] Train loss=0.28403180837631226
Test set avg_accuracy=85.89% avg_sensitivity=84.02%, avg_specificity=86.55% avg_auc=92.97%
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.322675 Test loss=0.351937 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.29645806550979614
[5/24] Train loss=0.2780010998249054
[10/24] Train loss=0.2990035116672516
[15/24] Train loss=0.31758517026901245
[20/24] Train loss=0.3142140209674835
Test set avg_accuracy=83.79% avg_sensitivity=87.28%, avg_specificity=82.54% avg_auc=91.92%
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.308004 Test loss=0.437947 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.28922563791275024
[5/24] Train loss=0.25353389978408813
[10/24] Train loss=0.32589855790138245
[15/24] Train loss=0.32039159536361694
[20/24] Train loss=0.2816585600376129
Test set avg_accuracy=85.40% avg_sensitivity=82.58%, avg_specificity=86.41% avg_auc=91.87%
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.299470 Test loss=0.377748 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.27815935015678406
[5/24] Train loss=0.2585647404193878
[10/24] Train loss=0.2883980870246887
[15/24] Train loss=0.32635483145713806
[20/24] Train loss=0.27162376046180725
Test set avg_accuracy=85.98% avg_sensitivity=86.84%, avg_specificity=85.67% avg_auc=93.17%
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.291177 Test loss=0.364128 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.288534551858902
[5/24] Train loss=0.2634831666946411
[10/24] Train loss=0.3015160858631134
[15/24] Train loss=0.30853235721588135
[20/24] Train loss=0.2668451964855194
Test set avg_accuracy=87.59% avg_sensitivity=73.82%, avg_specificity=92.51% avg_auc=90.85%
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.293218 Test loss=0.336657 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.28604209423065186
[5/24] Train loss=0.25478339195251465
[10/24] Train loss=0.2626994252204895
[15/24] Train loss=0.3082680404186249
[20/24] Train loss=0.2525721788406372
Test set avg_accuracy=85.85% avg_sensitivity=67.05%, avg_specificity=92.56% avg_auc=88.51%
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.279989 Test loss=0.373884 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2726733684539795
[5/24] Train loss=0.25826573371887207
[10/24] Train loss=0.2728898823261261
[15/24] Train loss=0.27832502126693726
[20/24] Train loss=0.27571985125541687
Test set avg_accuracy=86.00% avg_sensitivity=78.28%, avg_specificity=88.76% avg_auc=90.63%
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.277413 Test loss=0.358569 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.27444931864738464
[5/24] Train loss=0.2353695183992386
[10/24] Train loss=0.2824018895626068
[15/24] Train loss=0.2913161814212799
[20/24] Train loss=0.27738532423973083
Test set avg_accuracy=85.76% avg_sensitivity=71.70%, avg_specificity=90.78% avg_auc=88.94%
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.277122 Test loss=0.375807 Current lr=[0.000224838296036774]

[0/24] Train loss=0.26865682005882263
[5/24] Train loss=0.27002525329589844
[10/24] Train loss=0.2682100534439087
[15/24] Train loss=0.2968023419380188
[20/24] Train loss=0.27065879106521606
Test set avg_accuracy=86.60% avg_sensitivity=76.30%, avg_specificity=90.28% avg_auc=90.74%
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.277925 Test loss=0.351045 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2677189111709595
[5/24] Train loss=0.2427479773759842
[10/24] Train loss=0.30360111594200134
[15/24] Train loss=0.2984831631183624
[20/24] Train loss=0.2543165683746338
Test set avg_accuracy=86.00% avg_sensitivity=82.63%, avg_specificity=87.21% avg_auc=92.38%
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.276308 Test loss=0.351647 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.26890864968299866
[5/24] Train loss=0.2546405494213104
[10/24] Train loss=0.2744242548942566
[15/24] Train loss=0.28513312339782715
[20/24] Train loss=0.26030024886131287
Test set avg_accuracy=85.40% avg_sensitivity=80.46%, avg_specificity=87.17% avg_auc=91.65%
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.270636 Test loss=0.364848 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.25528252124786377
[5/24] Train loss=0.23687981069087982
[10/24] Train loss=0.2684825658798218
[15/24] Train loss=0.2909215986728668
[20/24] Train loss=0.26418864727020264
Test set avg_accuracy=87.01% avg_sensitivity=76.74%, avg_specificity=90.67% avg_auc=90.60%
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.276380 Test loss=0.348820 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2703871428966522
[5/24] Train loss=0.23458300530910492
[10/24] Train loss=0.28870341181755066
[15/24] Train loss=0.295963853597641
[20/24] Train loss=0.2591482698917389
Test set avg_accuracy=87.19% avg_sensitivity=78.82%, avg_specificity=90.17% avg_auc=92.33%
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.267261 Test loss=0.335307 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.23739582300186157
[5/24] Train loss=0.244154691696167
[10/24] Train loss=0.2678643465042114
[15/24] Train loss=0.28342318534851074
[20/24] Train loss=0.25799891352653503
Test set avg_accuracy=85.34% avg_sensitivity=85.75%, avg_specificity=85.19% avg_auc=92.79%
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.268571 Test loss=0.369204 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.27244508266448975
[5/24] Train loss=0.23444749414920807
[10/24] Train loss=0.2532840967178345
[15/24] Train loss=0.2707139551639557
[20/24] Train loss=0.24172526597976685
Test set avg_accuracy=85.13% avg_sensitivity=83.52%, avg_specificity=85.70% avg_auc=91.40%
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.260985 Test loss=0.396303 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.24112671613693237
[5/24] Train loss=0.24025629460811615
[10/24] Train loss=0.24861572682857513
[15/24] Train loss=0.2470986545085907
[20/24] Train loss=0.24268656969070435
Test set avg_accuracy=86.02% avg_sensitivity=84.51%, avg_specificity=86.55% avg_auc=92.41%
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.255239 Test loss=0.377522 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.24007689952850342
[5/24] Train loss=0.22776035964488983
[10/24] Train loss=0.26894500851631165
[15/24] Train loss=0.27984488010406494
[20/24] Train loss=0.2588341236114502
Test set avg_accuracy=85.01% avg_sensitivity=80.06%, avg_specificity=86.78% avg_auc=90.94%
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.257011 Test loss=0.393645 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.26170215010643005
[5/24] Train loss=0.23321378231048584
[10/24] Train loss=0.2531217336654663
[15/24] Train loss=0.28864559531211853
[20/24] Train loss=0.2464703470468521
Test set avg_accuracy=87.07% avg_sensitivity=75.85%, avg_specificity=91.08% avg_auc=90.47%
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.256021 Test loss=0.354484 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.25468721985816956
[5/24] Train loss=0.22232995927333832
[10/24] Train loss=0.25760430097579956
[15/24] Train loss=0.260219931602478
[20/24] Train loss=0.2435939759016037
Test set avg_accuracy=86.54% avg_sensitivity=77.73%, avg_specificity=89.68% avg_auc=90.61%
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.252634 Test loss=0.356686 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.25358372926712036
[5/24] Train loss=0.250122606754303
[10/24] Train loss=0.23636020720005035
[15/24] Train loss=0.26181691884994507
[20/24] Train loss=0.2589268982410431
Test set avg_accuracy=84.10% avg_sensitivity=82.09%, avg_specificity=84.82% avg_auc=90.77%
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.252894 Test loss=0.421056 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.24710379540920258
[5/24] Train loss=0.21662785112857819
[10/24] Train loss=0.24754974246025085
[15/24] Train loss=0.2522141635417938
[20/24] Train loss=0.23858286440372467
Test set avg_accuracy=85.35% avg_sensitivity=85.01%, avg_specificity=85.47% avg_auc=92.20%
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.246753 Test loss=0.380019 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.22920188307762146
[5/24] Train loss=0.22987981140613556
[10/24] Train loss=0.24382084608078003
[15/24] Train loss=0.25591081380844116
[20/24] Train loss=0.2589608430862427
Test set avg_accuracy=84.78% avg_sensitivity=76.65%, avg_specificity=87.68% avg_auc=90.10%
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.247239 Test loss=0.402861 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.23104457557201385
[5/24] Train loss=0.23415233194828033
[10/24] Train loss=0.24740782380104065
[15/24] Train loss=0.25755786895751953
[20/24] Train loss=0.23801720142364502
Test set avg_accuracy=87.60% avg_sensitivity=81.64%, avg_specificity=89.73% avg_auc=92.03%
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.240667 Test loss=0.339745 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2282702773809433
[5/24] Train loss=0.21048620343208313
[10/24] Train loss=0.23193779587745667
[15/24] Train loss=0.2481505274772644
[20/24] Train loss=0.23244118690490723
Test set avg_accuracy=85.98% avg_sensitivity=82.78%, avg_specificity=87.12% avg_auc=92.10%
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.235309 Test loss=0.365296 Current lr=[0.000156543481933168]

[0/24] Train loss=0.21195943653583527
[5/24] Train loss=0.21182414889335632
[10/24] Train loss=0.2369191199541092
[15/24] Train loss=0.24406173825263977
[20/24] Train loss=0.2384481132030487
Test set avg_accuracy=87.32% avg_sensitivity=76.65%, avg_specificity=91.13% avg_auc=91.78%
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.231655 Test loss=0.340091 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2184828370809555
[5/24] Train loss=0.22044014930725098
[10/24] Train loss=0.2562529146671295
[15/24] Train loss=0.2583855390548706
[20/24] Train loss=0.23577293753623962
Test set avg_accuracy=85.99% avg_sensitivity=80.80%, avg_specificity=87.84% avg_auc=91.61%
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.232779 Test loss=0.360082 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.22126618027687073
[5/24] Train loss=0.22357690334320068
[10/24] Train loss=0.23787915706634521
[15/24] Train loss=0.24809882044792175
[20/24] Train loss=0.22601592540740967
Test set avg_accuracy=87.63% avg_sensitivity=82.68%, avg_specificity=89.40% avg_auc=92.84%
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.232729 Test loss=0.335083 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.22943885624408722
[5/24] Train loss=0.20799016952514648
[10/24] Train loss=0.23266185820102692
[15/24] Train loss=0.2534297704696655
[20/24] Train loss=0.24249838292598724
Test set avg_accuracy=87.21% avg_sensitivity=73.63%, avg_specificity=92.07% avg_auc=90.64%
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.233725 Test loss=0.344205 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.21888448297977448
[5/24] Train loss=0.2142193466424942
[10/24] Train loss=0.23182637989521027
[15/24] Train loss=0.22682853043079376
[20/24] Train loss=0.22561605274677277
Test set avg_accuracy=87.55% avg_sensitivity=81.54%, avg_specificity=89.70% avg_auc=93.00%
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.223647 Test loss=0.332483 Current lr=[0.000134135431043539]

[0/24] Train loss=0.21063077449798584
[5/24] Train loss=0.19754880666732788
[10/24] Train loss=0.23048515617847443
[15/24] Train loss=0.22739151120185852
[20/24] Train loss=0.2255752980709076
Test set avg_accuracy=87.71% avg_sensitivity=77.68%, avg_specificity=91.29% avg_auc=92.83%
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.221277 Test loss=0.326207 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.21135057508945465
[5/24] Train loss=0.20551544427871704
[10/24] Train loss=0.21955105662345886
[15/24] Train loss=0.2296021580696106
[20/24] Train loss=0.22164411842823029
Test set avg_accuracy=86.42% avg_sensitivity=81.54%, avg_specificity=88.16% avg_auc=92.79%
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.216845 Test loss=0.350489 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.21628686785697937
[5/24] Train loss=0.19924485683441162
[10/24] Train loss=0.2129613161087036
[15/24] Train loss=0.22448742389678955
[20/24] Train loss=0.22318685054779053
Test set avg_accuracy=82.32% avg_sensitivity=88.92%, avg_specificity=79.96% avg_auc=91.97%
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.218351 Test loss=0.488456 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.20371247828006744
[5/24] Train loss=0.19030651450157166
[10/24] Train loss=0.21617986261844635
[15/24] Train loss=0.22266916930675507
[20/24] Train loss=0.21299949288368225
Test set avg_accuracy=83.80% avg_sensitivity=87.68%, avg_specificity=82.42% avg_auc=92.71%
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.214970 Test loss=0.435718 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.20979087054729462
[5/24] Train loss=0.19041495025157928
[10/24] Train loss=0.20706109702587128
[15/24] Train loss=0.23755328357219696
[20/24] Train loss=0.20893533527851105
Test set avg_accuracy=87.34% avg_sensitivity=83.23%, avg_specificity=88.81% avg_auc=93.14%
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.213205 Test loss=0.353911 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2012639194726944
[5/24] Train loss=0.20561178028583527
[10/24] Train loss=0.20272158086299896
[15/24] Train loss=0.21755409240722656
[20/24] Train loss=0.20794421434402466
Test set avg_accuracy=88.24% avg_sensitivity=81.79%, avg_specificity=90.55% avg_auc=93.20%
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.209774 Test loss=0.320872 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.20867744088172913
[5/24] Train loss=0.185678631067276
[10/24] Train loss=0.20737995207309723
[15/24] Train loss=0.21457450091838837
[20/24] Train loss=0.203797847032547
Test set avg_accuracy=88.10% avg_sensitivity=80.65%, avg_specificity=90.76% avg_auc=92.73%
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.205374 Test loss=0.329235 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.19853204488754272
[5/24] Train loss=0.1898508220911026
[10/24] Train loss=0.20181415975093842
[15/24] Train loss=0.20431284606456757
[20/24] Train loss=0.20491132140159607
Test set avg_accuracy=87.57% avg_sensitivity=84.17%, avg_specificity=88.78% avg_auc=92.71%
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.204966 Test loss=0.352216 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.19000467658042908
[5/24] Train loss=0.19005762040615082
[10/24] Train loss=0.19585442543029785
[15/24] Train loss=0.21524366736412048
[20/24] Train loss=0.2060120850801468
Test set avg_accuracy=87.32% avg_sensitivity=80.11%, avg_specificity=89.89% avg_auc=92.25%
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.199613 Test loss=0.343578 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.18136891722679138
[5/24] Train loss=0.18013392388820648
[10/24] Train loss=0.19722223281860352
[15/24] Train loss=0.21241764724254608
[20/24] Train loss=0.20011648535728455
Test set avg_accuracy=87.75% avg_sensitivity=82.24%, avg_specificity=89.72% avg_auc=92.78%
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.196752 Test loss=0.333843 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.18608678877353668
[5/24] Train loss=0.17282448709011078
[10/24] Train loss=0.1921616941690445
[15/24] Train loss=0.2023773342370987
[20/24] Train loss=0.20053771138191223
Test set avg_accuracy=88.55% avg_sensitivity=79.66%, avg_specificity=91.73% avg_auc=93.02%
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.193326 Test loss=0.318154 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.19009609520435333
[5/24] Train loss=0.17309598624706268
[10/24] Train loss=0.18641968071460724
[15/24] Train loss=0.19526124000549316
[20/24] Train loss=0.19664302468299866
Test set avg_accuracy=87.51% avg_sensitivity=81.44%, avg_specificity=89.68% avg_auc=93.08%
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.189622 Test loss=0.333638 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.18673595786094666
[5/24] Train loss=0.17041997611522675
[10/24] Train loss=0.17891789972782135
[15/24] Train loss=0.19294476509094238
[20/24] Train loss=0.18887244164943695
Test set avg_accuracy=88.26% avg_sensitivity=79.76%, avg_specificity=91.29% avg_auc=92.83%
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.186978 Test loss=0.325264 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.17748503386974335
[5/24] Train loss=0.16462914645671844
[10/24] Train loss=0.18547624349594116
[15/24] Train loss=0.19591167569160461
[20/24] Train loss=0.19236181676387787
Test set avg_accuracy=87.73% avg_sensitivity=79.52%, avg_specificity=90.67% avg_auc=92.39%
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.185636 Test loss=0.336943 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1790516972541809
[5/24] Train loss=0.17414505779743195
[10/24] Train loss=0.18574896454811096
[15/24] Train loss=0.1934669315814972
[20/24] Train loss=0.18889206647872925
Test set avg_accuracy=87.45% avg_sensitivity=80.60%, avg_specificity=89.89% avg_auc=92.56%
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.185429 Test loss=0.345804 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.17934566736221313
[5/24] Train loss=0.1752384603023529
[10/24] Train loss=0.1829805225133896
[15/24] Train loss=0.19345106184482574
[20/24] Train loss=0.18827944993972778
Test set avg_accuracy=86.85% avg_sensitivity=85.11%, avg_specificity=87.47% avg_auc=93.19%
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.185235 Test loss=0.355139 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.17091085016727448
[5/24] Train loss=0.17239755392074585
[10/24] Train loss=0.17388306558132172
[15/24] Train loss=0.19264353811740875
[20/24] Train loss=0.19019673764705658
Test set avg_accuracy=86.54% avg_sensitivity=83.52%, avg_specificity=87.61% avg_auc=92.78%
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.182776 Test loss=0.365953 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.17623604834079742
[5/24] Train loss=0.1689017117023468
[10/24] Train loss=0.17483384907245636
[15/24] Train loss=0.1857447773218155
[20/24] Train loss=0.18177099525928497
Test set avg_accuracy=87.58% avg_sensitivity=81.20%, avg_specificity=89.86% avg_auc=92.80%
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.181481 Test loss=0.341966 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1698630303144455
[5/24] Train loss=0.1652451455593109
[10/24] Train loss=0.17483286559581757
[15/24] Train loss=0.18327681720256805
[20/24] Train loss=0.1874665468931198
Test set avg_accuracy=87.66% avg_sensitivity=81.15%, avg_specificity=89.98% avg_auc=92.65%
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.179932 Test loss=0.345392 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.17592519521713257
[5/24] Train loss=0.1663210391998291
[10/24] Train loss=0.1756097823381424
[15/24] Train loss=0.17659986019134521
[20/24] Train loss=0.17949894070625305
Test set avg_accuracy=86.69% avg_sensitivity=84.91%, avg_specificity=87.33% avg_auc=93.12%
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.176787 Test loss=0.364000 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.16987885534763336
[5/24] Train loss=0.1624823659658432
[10/24] Train loss=0.1667453795671463
[15/24] Train loss=0.18444441258907318
[20/24] Train loss=0.176381453871727
Test set avg_accuracy=87.67% avg_sensitivity=82.29%, avg_specificity=89.59% avg_auc=92.97%
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.175971 Test loss=0.344687 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.17053568363189697
[5/24] Train loss=0.1660359799861908
[10/24] Train loss=0.16970403492450714
[15/24] Train loss=0.18580012023448944
[20/24] Train loss=0.1792491376399994
Test set avg_accuracy=86.89% avg_sensitivity=84.96%, avg_specificity=87.58% avg_auc=93.00%
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.178122 Test loss=0.365836 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.16936197876930237
[5/24] Train loss=0.16776922345161438
[10/24] Train loss=0.17300426959991455
[15/24] Train loss=0.1895623356103897
[20/24] Train loss=0.1804722249507904
Test set avg_accuracy=85.31% avg_sensitivity=87.78%, avg_specificity=84.43% avg_auc=92.95%
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.178844 Test loss=0.394698 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.17325538396835327
[5/24] Train loss=0.16161222755908966
[10/24] Train loss=0.1817091554403305
[15/24] Train loss=0.18950997292995453
[20/24] Train loss=0.180810809135437
Test set avg_accuracy=86.37% avg_sensitivity=86.94%, avg_specificity=86.16% avg_auc=93.14%
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.178851 Test loss=0.376780 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1730908751487732
[5/24] Train loss=0.1673312932252884
[10/24] Train loss=0.1705455482006073
[15/24] Train loss=0.18695701658725739
[20/24] Train loss=0.18259991705417633
Test set avg_accuracy=86.41% avg_sensitivity=86.99%, avg_specificity=86.20% avg_auc=93.14%
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.179612 Test loss=0.376520 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.16971127688884735
[5/24] Train loss=0.1684272587299347
[10/24] Train loss=0.17904135584831238
[15/24] Train loss=0.1856715977191925
[20/24] Train loss=0.1830550730228424
Test set avg_accuracy=86.56% avg_sensitivity=86.05%, avg_specificity=86.75% avg_auc=92.89%
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.180194 Test loss=0.379835 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.17260825634002686
[5/24] Train loss=0.15920107066631317
[10/24] Train loss=0.1796298772096634
[15/24] Train loss=0.17875033617019653
[20/24] Train loss=0.17718587815761566
Test set avg_accuracy=87.76% avg_sensitivity=80.50%, avg_specificity=90.35% avg_auc=92.99%
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.177492 Test loss=0.333924 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.18553416430950165
[5/24] Train loss=0.1568707674741745
[10/24] Train loss=0.17481982707977295
[15/24] Train loss=0.1828645020723343
[20/24] Train loss=0.1722521334886551
Test set avg_accuracy=87.59% avg_sensitivity=82.88%, avg_specificity=89.27% avg_auc=93.11%
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.174692 Test loss=0.341877 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1670936644077301
[5/24] Train loss=0.16630761325359344
[10/24] Train loss=0.164019376039505
[15/24] Train loss=0.17534634470939636
[20/24] Train loss=0.17597806453704834
Test set avg_accuracy=87.49% avg_sensitivity=82.48%, avg_specificity=89.27% avg_auc=93.10%
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.170026 Test loss=0.345195 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.16418787837028503
[5/24] Train loss=0.15846124291419983
[10/24] Train loss=0.16095617413520813
[15/24] Train loss=0.17068152129650116
[20/24] Train loss=0.16865140199661255
Test set avg_accuracy=87.38% avg_sensitivity=83.72%, avg_specificity=88.69% avg_auc=93.07%
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.166036 Test loss=0.351395 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.16042357683181763
[5/24] Train loss=0.1569402813911438
[10/24] Train loss=0.16596093773841858
[15/24] Train loss=0.16706985235214233
[20/24] Train loss=0.1698479950428009
Test set avg_accuracy=87.36% avg_sensitivity=83.03%, avg_specificity=88.90% avg_auc=93.05%
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.165573 Test loss=0.347266 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1578160971403122
[5/24] Train loss=0.15344560146331787
[10/24] Train loss=0.1645612120628357
[15/24] Train loss=0.1691339612007141
[20/24] Train loss=0.16946135461330414
Test set avg_accuracy=87.71% avg_sensitivity=82.63%, avg_specificity=89.52% avg_auc=92.95%
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.165036 Test loss=0.342248 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.15968506038188934
[5/24] Train loss=0.15053702890872955
[10/24] Train loss=0.15978899598121643
[15/24] Train loss=0.1681128293275833
[20/24] Train loss=0.16520683467388153
Test set avg_accuracy=87.40% avg_sensitivity=83.13%, avg_specificity=88.92% avg_auc=93.00%
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.164595 Test loss=0.345871 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1570998579263687
[5/24] Train loss=0.150155708193779
[10/24] Train loss=0.1609329730272293
[15/24] Train loss=0.168502539396286
[20/24] Train loss=0.1669386476278305
Test set avg_accuracy=87.41% avg_sensitivity=82.98%, avg_specificity=88.99% avg_auc=93.02%
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.163291 Test loss=0.345553 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1580439805984497
[5/24] Train loss=0.1529475897550583
[10/24] Train loss=0.15863661468029022
[15/24] Train loss=0.17411988973617554
[20/24] Train loss=0.16752071678638458
Test set avg_accuracy=87.68% avg_sensitivity=82.93%, avg_specificity=89.38% avg_auc=92.95%
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.163200 Test loss=0.342714 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.16035141050815582
[5/24] Train loss=0.1495363563299179
[10/24] Train loss=0.1621750444173813
[15/24] Train loss=0.1700114756822586
[20/24] Train loss=0.16657137870788574
Test set avg_accuracy=87.54% avg_sensitivity=83.23%, avg_specificity=89.08% avg_auc=93.06%
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.163224 Test loss=0.344753 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16027779877185822
[5/24] Train loss=0.14985866844654083
[10/24] Train loss=0.15961797535419464
[15/24] Train loss=0.16864587366580963
[20/24] Train loss=0.1679856777191162
Test set avg_accuracy=87.62% avg_sensitivity=82.98%, avg_specificity=89.27% avg_auc=93.07%
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.163291 Test loss=0.342203 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.15519468486309052
[5/24] Train loss=0.14899353682994843
[10/24] Train loss=0.15648289024829865
[15/24] Train loss=0.16708268225193024
[20/24] Train loss=0.17052781581878662
Test set avg_accuracy=87.55% avg_sensitivity=83.08%, avg_specificity=89.15% avg_auc=93.01%
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.161843 Test loss=0.344903 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16004712879657745
[5/24] Train loss=0.14737927913665771
[10/24] Train loss=0.15491187572479248
[15/24] Train loss=0.1701694130897522
[20/24] Train loss=0.16441303491592407
Test set avg_accuracy=87.54% avg_sensitivity=83.08%, avg_specificity=89.13% avg_auc=93.02%
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.161807 Test loss=0.343877 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.15849168598651886
[5/24] Train loss=0.15166708827018738
[10/24] Train loss=0.15877611935138702
[15/24] Train loss=0.1659971922636032
[20/24] Train loss=0.16530261933803558
Test set avg_accuracy=87.64% avg_sensitivity=82.68%, avg_specificity=89.42% avg_auc=93.00%
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.161733 Test loss=0.342738 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1559031456708908
[5/24] Train loss=0.1481703817844391
[10/24] Train loss=0.15711864829063416
[15/24] Train loss=0.16567617654800415
[20/24] Train loss=0.1608724296092987
Test set avg_accuracy=87.70% avg_sensitivity=82.73%, avg_specificity=89.47% avg_auc=93.08%
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.160330 Test loss=0.340978 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.15379010140895844
[5/24] Train loss=0.14574311673641205
[10/24] Train loss=0.15930917859077454
[15/24] Train loss=0.16710250079631805
[20/24] Train loss=0.16436147689819336
Test set avg_accuracy=87.62% avg_sensitivity=82.88%, avg_specificity=89.31% avg_auc=93.11%
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.160864 Test loss=0.341829 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.15558326244354248
[5/24] Train loss=0.15081144869327545
[10/24] Train loss=0.15818467736244202
[15/24] Train loss=0.16669301688671112
[20/24] Train loss=0.1632588654756546
Test set avg_accuracy=87.55% avg_sensitivity=83.08%, avg_specificity=89.15% avg_auc=93.13%
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.160794 Test loss=0.343381 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.15543998777866364
[5/24] Train loss=0.1482461392879486
[10/24] Train loss=0.154917374253273
[15/24] Train loss=0.16646167635917664
[20/24] Train loss=0.16600896418094635
Test set avg_accuracy=87.62% avg_sensitivity=82.88%, avg_specificity=89.31% avg_auc=93.13%
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.161114 Test loss=0.342304 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1535521298646927
[5/24] Train loss=0.15003402531147003
[10/24] Train loss=0.15609104931354523
[15/24] Train loss=0.16457834839820862
[20/24] Train loss=0.16177204251289368
Test set avg_accuracy=87.63% avg_sensitivity=82.88%, avg_specificity=89.33% avg_auc=93.12%
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.160897 Test loss=0.342048 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.15932372212409973
[5/24] Train loss=0.14890223741531372
[10/24] Train loss=0.15677990019321442
[15/24] Train loss=0.16651107370853424
[20/24] Train loss=0.16424965858459473
Test set avg_accuracy=87.64% avg_sensitivity=82.98%, avg_specificity=89.31% avg_auc=93.13%
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.160659 Test loss=0.341860 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.15704476833343506
[5/24] Train loss=0.14833025634288788
[10/24] Train loss=0.15678611397743225
[15/24] Train loss=0.1653384566307068
[20/24] Train loss=0.16574519872665405
Test set avg_accuracy=87.62% avg_sensitivity=82.98%, avg_specificity=89.27% avg_auc=93.13%
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.160917 Test loss=0.341695 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1550474464893341
[5/24] Train loss=0.14534366130828857
[10/24] Train loss=0.16023536026477814
[15/24] Train loss=0.16623720526695251
[20/24] Train loss=0.16344204545021057
Test set avg_accuracy=87.60% avg_sensitivity=82.98%, avg_specificity=89.26% avg_auc=93.13%
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.160895 Test loss=0.342028 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.15632174909114838
[5/24] Train loss=0.1472286880016327
[10/24] Train loss=0.15543197095394135
[15/24] Train loss=0.16966643929481506
[20/24] Train loss=0.1646389216184616
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.60% avg_sensitivity=82.98%, avg_specificity=89.26% avg_auc=93.13%
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.160222 Test loss=0.342017 Current lr=[1.3165623068326024e-09]

Fold[1] Result: acc=86.51% sen=87.18%, spe=86.27%, auc=93.93%!
Fold[1] Avg_overlap=0.67%(0.21311796331882474)
[0/24] Train loss=1.4810880422592163
[5/24] Train loss=1.4774870872497559
[10/24] Train loss=1.445616602897644
[15/24] Train loss=1.4387571811676025
[20/24] Train loss=1.3928930759429932
Test set avg_accuracy=51.52% avg_sensitivity=59.89%, avg_specificity=48.74% avg_auc=56.81%
Best model saved!! Metric=-109.0427755959548!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=1.445259 Test loss=0.701887 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3997927904129028
[5/24] Train loss=1.3875030279159546
[10/24] Train loss=1.355312466621399
[15/24] Train loss=1.3466441631317139
[20/24] Train loss=1.3572746515274048
Test set avg_accuracy=65.23% avg_sensitivity=71.10%, avg_specificity=63.28% avg_auc=73.12%
Best model saved!! Metric=-53.263464589900906!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=1.370934 Test loss=0.625504 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3216664791107178
[5/24] Train loss=1.3033361434936523
[10/24] Train loss=1.2800307273864746
[15/24] Train loss=1.2588411569595337
[20/24] Train loss=1.251458764076233
Test set avg_accuracy=68.83% avg_sensitivity=76.53%, avg_specificity=66.27% avg_auc=78.32%
Best model saved!! Metric=-36.06111328379754!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=1.296361 Test loss=0.593954 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2313778400421143
[5/24] Train loss=1.208185076713562
[10/24] Train loss=1.203815221786499
[15/24] Train loss=1.1798912286758423
[20/24] Train loss=1.1734116077423096
Test set avg_accuracy=70.77% avg_sensitivity=79.50%, avg_specificity=67.86% avg_auc=80.84%
Best model saved!! Metric=-27.03012996260138!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=1.218384 Test loss=0.576331 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1527173519134521
[5/24] Train loss=1.1285693645477295
[10/24] Train loss=1.1296958923339844
[15/24] Train loss=1.1228892803192139
[20/24] Train loss=1.1035678386688232
Test set avg_accuracy=71.43% avg_sensitivity=82.84%, avg_specificity=67.64% avg_auc=82.73%
Best model saved!! Metric=-21.364239475508015!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=1.148476 Test loss=0.562768 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.0788824558258057
[5/24] Train loss=1.055566668510437
[10/24] Train loss=1.0521875619888306
[15/24] Train loss=1.044023036956787
[20/24] Train loss=1.0303285121917725
Test set avg_accuracy=73.79% avg_sensitivity=83.99%, avg_specificity=70.40% avg_auc=84.54%
Best model saved!! Metric=-13.288543811773778!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=1.077565 Test loss=0.537920 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0000786781311035
[5/24] Train loss=0.9848198294639587
[10/24] Train loss=0.9922291040420532
[15/24] Train loss=0.9663076400756836
[20/24] Train loss=0.9856190085411072
Test set avg_accuracy=74.91% avg_sensitivity=83.99%, avg_specificity=71.89% avg_auc=86.14%
Best model saved!! Metric=-9.074443851531015!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=1.018977 Test loss=0.516444 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9584952592849731
[5/24] Train loss=0.9190260767936707
[10/24] Train loss=0.9411839842796326
[15/24] Train loss=0.9157254099845886
[20/24] Train loss=0.9207958579063416
Test set avg_accuracy=77.76% avg_sensitivity=84.04%, avg_specificity=75.67% avg_auc=87.58%
Best model saved!! Metric=-0.9492811510905597!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.963131 Test loss=0.484622 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9015989303588867
[5/24] Train loss=0.8767237663269043
[10/24] Train loss=0.8828644752502441
[15/24] Train loss=0.8602507710456848
[20/24] Train loss=0.8491600751876831
Test set avg_accuracy=78.75% avg_sensitivity=84.82%, avg_specificity=76.73% avg_auc=88.86%
Best model saved!! Metric=3.157321144882033!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.908781 Test loss=0.467620 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8505929708480835
[5/24] Train loss=0.8144721388816833
[10/24] Train loss=0.8305947184562683
[15/24] Train loss=0.8211774826049805
[20/24] Train loss=0.809912383556366
Test set avg_accuracy=80.09% avg_sensitivity=85.81%, avg_specificity=78.19% avg_auc=89.65%
Best model saved!! Metric=7.737511660121626!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.862931 Test loss=0.453579 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8041126132011414
[5/24] Train loss=0.7700471878051758
[10/24] Train loss=0.8132663369178772
[15/24] Train loss=0.7791593670845032
[20/24] Train loss=0.7640527486801147
Test set avg_accuracy=79.95% avg_sensitivity=87.32%, avg_specificity=77.49% avg_auc=90.32%
Best model saved!! Metric=9.08677353523197!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.820343 Test loss=0.453952 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7538511753082275
[5/24] Train loss=0.7312008738517761
[10/24] Train loss=0.7710725665092468
[15/24] Train loss=0.7495036125183105
[20/24] Train loss=0.7212269306182861
Test set avg_accuracy=81.35% avg_sensitivity=86.85%, avg_specificity=79.52% avg_auc=90.92%
Best model saved!! Metric=12.653764020715315!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.785185 Test loss=0.428796 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7274250388145447
[5/24] Train loss=0.7127520442008972
[10/24] Train loss=0.7597214579582214
[15/24] Train loss=0.716351330280304
[20/24] Train loss=0.6928238868713379
Test set avg_accuracy=81.90% avg_sensitivity=86.49%, avg_specificity=80.37% avg_auc=91.37%
Best model saved!! Metric=14.137202935408283!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.756799 Test loss=0.416818 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.689447820186615
[5/24] Train loss=0.6758475303649902
[10/24] Train loss=0.7275941967964172
[15/24] Train loss=0.6837425231933594
[20/24] Train loss=0.6781451106071472
Test set avg_accuracy=81.89% avg_sensitivity=87.53%, avg_specificity=80.01% avg_auc=91.72%
Best model saved!! Metric=15.147298195955727!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.728928 Test loss=0.415970 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.6823161244392395
[5/24] Train loss=0.6524807810783386
[10/24] Train loss=0.712128758430481
[15/24] Train loss=0.6776242852210999
[20/24] Train loss=0.648658037185669
Test set avg_accuracy=81.73% avg_sensitivity=87.79%, avg_specificity=79.72% avg_auc=91.92%
Best model saved!! Metric=15.163527988302903!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.709414 Test loss=0.416843 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6321691274642944
[5/24] Train loss=0.6417437195777893
[10/24] Train loss=0.7029262781143188
[15/24] Train loss=0.6466439962387085
[20/24] Train loss=0.6173853278160095
Test set avg_accuracy=82.49% avg_sensitivity=86.44%, avg_specificity=81.17% avg_auc=92.13%
Best model saved!! Metric=16.228294779704015!!
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.690497 Test loss=0.394993 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6255354881286621
[5/24] Train loss=0.6111656427383423
[10/24] Train loss=0.6727495193481445
[15/24] Train loss=0.6244788765907288
[20/24] Train loss=0.6007165312767029
Test set avg_accuracy=82.99% avg_sensitivity=86.02%, avg_specificity=81.99% avg_auc=92.26%
Best model saved!! Metric=17.267223747600312!!
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.671492 Test loss=0.385167 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6167072653770447
[5/24] Train loss=0.5807542204856873
[10/24] Train loss=0.65018630027771
[15/24] Train loss=0.6195558309555054
[20/24] Train loss=0.5697940587997437
Test set avg_accuracy=80.78% avg_sensitivity=89.57%, avg_specificity=77.86% avg_auc=92.30%
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.654709 Test loss=0.423459 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6015236973762512
[5/24] Train loss=0.5820044875144958
[10/24] Train loss=0.6500869989395142
[15/24] Train loss=0.6120049953460693
[20/24] Train loss=0.5604384541511536
Test set avg_accuracy=82.84% avg_sensitivity=87.06%, avg_specificity=81.43% avg_auc=92.48%
Best model saved!! Metric=17.815601899542884!!
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.643510 Test loss=0.387072 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5778954029083252
[5/24] Train loss=0.5533376336097717
[10/24] Train loss=0.6439307928085327
[15/24] Train loss=0.5961186289787292
[20/24] Train loss=0.5663488507270813
Test set avg_accuracy=83.68% avg_sensitivity=86.80%, avg_specificity=82.65% avg_auc=92.76%
Best model saved!! Metric=19.891536490898147!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.631248 Test loss=0.370397 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.578283965587616
[5/24] Train loss=0.5337346792221069
[10/24] Train loss=0.6292484998703003
[15/24] Train loss=0.5668460726737976
[20/24] Train loss=0.5364202857017517
Test set avg_accuracy=83.71% avg_sensitivity=86.28%, avg_specificity=82.86% avg_auc=92.69%
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.619224 Test loss=0.366666 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5648300051689148
[5/24] Train loss=0.5366267561912537
[10/24] Train loss=0.618108332157135
[15/24] Train loss=0.5700017213821411
[20/24] Train loss=0.5203131437301636
Test set avg_accuracy=82.07% avg_sensitivity=89.10%, avg_specificity=79.73% avg_auc=92.62%
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.606270 Test loss=0.402652 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5653198957443237
[5/24] Train loss=0.5327044129371643
[10/24] Train loss=0.6022481322288513
[15/24] Train loss=0.5435951948165894
[20/24] Train loss=0.500082790851593
Test set avg_accuracy=82.97% avg_sensitivity=88.11%, avg_specificity=81.26% avg_auc=92.84%
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.593880 Test loss=0.376569 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5574809908866882
[5/24] Train loss=0.5129382610321045
[10/24] Train loss=0.5835290551185608
[15/24] Train loss=0.5348618626594543
[20/24] Train loss=0.5074785351753235
Test set avg_accuracy=86.07% avg_sensitivity=83.20%, avg_specificity=87.02% avg_auc=92.81%
Best model saved!! Metric=23.097273569300285!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.578000 Test loss=0.328731 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5376651287078857
[5/24] Train loss=0.506659209728241
[10/24] Train loss=0.5641008019447327
[15/24] Train loss=0.5154216289520264
[20/24] Train loss=0.4914025664329529
Test set avg_accuracy=86.43% avg_sensitivity=81.79%, avg_specificity=87.98% avg_auc=92.97%
Best model saved!! Metric=23.16709794393543!!
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.566173 Test loss=0.313484 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5011253356933594
[5/24] Train loss=0.5131213665008545
[10/24] Train loss=0.5585301518440247
[15/24] Train loss=0.5279657244682312
[20/24] Train loss=0.5056895017623901
Test set avg_accuracy=86.15% avg_sensitivity=83.67%, avg_specificity=86.97% avg_auc=92.97%
Best model saved!! Metric=23.7542355024421!!
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.558273 Test loss=0.323367 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5070235133171082
[5/24] Train loss=0.498374342918396
[10/24] Train loss=0.5533003807067871
[15/24] Train loss=0.5121094584465027
[20/24] Train loss=0.49953654408454895
Test set avg_accuracy=86.88% avg_sensitivity=68.39%, avg_specificity=93.02% avg_auc=91.85%
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.549871 Test loss=0.302913 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5197953581809998
[5/24] Train loss=0.5102491974830627
[10/24] Train loss=0.5448731780052185
[15/24] Train loss=0.5170742869377136
[20/24] Train loss=0.4572242200374603
Test set avg_accuracy=87.21% avg_sensitivity=78.51%, avg_specificity=90.11% avg_auc=92.97%
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.539446 Test loss=0.299585 Current lr=[0.000210185142098938]

[0/24] Train loss=0.49705973267555237
[5/24] Train loss=0.4783628582954407
[10/24] Train loss=0.5329921841621399
[15/24] Train loss=0.5074331164360046
[20/24] Train loss=0.47223100066185
Test set avg_accuracy=86.95% avg_sensitivity=66.15%, avg_specificity=93.87% avg_auc=92.15%
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.528624 Test loss=0.299233 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.48364967107772827
[5/24] Train loss=0.4764564335346222
[10/24] Train loss=0.5663127303123474
[15/24] Train loss=0.5009644627571106
[20/24] Train loss=0.46387287974357605
Test set avg_accuracy=86.22% avg_sensitivity=82.16%, avg_specificity=87.58% avg_auc=92.65%
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.529166 Test loss=0.322443 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.46370795369148254
[5/24] Train loss=0.47248944640159607
[10/24] Train loss=0.519074022769928
[15/24] Train loss=0.5037914514541626
[20/24] Train loss=0.4500707685947418
Test set avg_accuracy=86.84% avg_sensitivity=79.13%, avg_specificity=89.40% avg_auc=92.30%
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.518510 Test loss=0.312933 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.47085192799568176
[5/24] Train loss=0.47606125473976135
[10/24] Train loss=0.5207485556602478
[15/24] Train loss=0.518655002117157
[20/24] Train loss=0.45648470520973206
Test set avg_accuracy=84.23% avg_sensitivity=85.76%, avg_specificity=83.72% avg_auc=92.21%
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.513655 Test loss=0.362046 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.45622795820236206
[5/24] Train loss=0.4469655454158783
[10/24] Train loss=0.5127620100975037
[15/24] Train loss=0.5135285258293152
[20/24] Train loss=0.4409118890762329
Test set avg_accuracy=86.68% avg_sensitivity=80.96%, avg_specificity=88.58% avg_auc=92.66%
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.506139 Test loss=0.312409 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4759182333946228
[5/24] Train loss=0.464790940284729
[10/24] Train loss=0.5016807913780212
[15/24] Train loss=0.46188727021217346
[20/24] Train loss=0.4409295618534088
Test set avg_accuracy=83.66% avg_sensitivity=86.85%, avg_specificity=82.60% avg_auc=92.40%
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.503328 Test loss=0.370896 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.45294299721717834
[5/24] Train loss=0.435564249753952
[10/24] Train loss=0.4937986731529236
[15/24] Train loss=0.4595344066619873
[20/24] Train loss=0.4102567434310913
Test set avg_accuracy=83.80% avg_sensitivity=88.84%, avg_specificity=82.13% avg_auc=92.63%
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.486949 Test loss=0.382092 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.43524613976478577
[5/24] Train loss=0.4709137976169586
[10/24] Train loss=0.5258784890174866
[15/24] Train loss=0.4751525819301605
[20/24] Train loss=0.4151484966278076
Test set avg_accuracy=81.78% avg_sensitivity=88.73%, avg_specificity=79.47% avg_auc=91.77%
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.485867 Test loss=0.423191 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.43173348903656006
[5/24] Train loss=0.4134289026260376
[10/24] Train loss=0.48426300287246704
[15/24] Train loss=0.4959676265716553
[20/24] Train loss=0.4141252934932709
Test set avg_accuracy=84.23% avg_sensitivity=89.10%, avg_specificity=82.61% avg_auc=92.82%
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.474405 Test loss=0.368810 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4254264533519745
[5/24] Train loss=0.46983224153518677
[10/24] Train loss=0.4810619652271271
[15/24] Train loss=0.47862115502357483
[20/24] Train loss=0.40500351786613464
Test set avg_accuracy=84.23% avg_sensitivity=85.65%, avg_specificity=83.76% avg_auc=92.18%
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.474133 Test loss=0.372463 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.397828072309494
[5/24] Train loss=0.40474733710289
[10/24] Train loss=0.47847023606300354
[15/24] Train loss=0.4233092963695526
[20/24] Train loss=0.40317919850349426
Test set avg_accuracy=85.26% avg_sensitivity=86.12%, avg_specificity=84.97% avg_auc=92.64%
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.456162 Test loss=0.349965 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4129316508769989
[5/24] Train loss=0.3904803693294525
[10/24] Train loss=0.4844965934753418
[15/24] Train loss=0.4441753029823303
[20/24] Train loss=0.40427714586257935
Test set avg_accuracy=85.47% avg_sensitivity=84.04%, avg_specificity=85.94% avg_auc=92.18%
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.461735 Test loss=0.348519 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4281514585018158
[5/24] Train loss=0.3877304792404175
[10/24] Train loss=0.4749765992164612
[15/24] Train loss=0.44168373942375183
[20/24] Train loss=0.387637734413147
Test set avg_accuracy=84.05% avg_sensitivity=87.90%, avg_specificity=82.77% avg_auc=92.27%
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.447030 Test loss=0.380836 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4285295903682709
[5/24] Train loss=0.44512343406677246
[10/24] Train loss=0.4637909233570099
[15/24] Train loss=0.40173450112342834
[20/24] Train loss=0.39197930693626404
Test set avg_accuracy=71.09% avg_sensitivity=95.10%, avg_specificity=63.11% avg_auc=89.30%
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.437172 Test loss=0.679818 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.40973883867263794
[5/24] Train loss=0.41384702920913696
[10/24] Train loss=0.47556522488594055
[15/24] Train loss=0.45539140701293945
[20/24] Train loss=0.3656690716743469
Test set avg_accuracy=76.99% avg_sensitivity=91.03%, avg_specificity=72.32% avg_auc=90.67%
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.447083 Test loss=0.541505 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4037417769432068
[5/24] Train loss=0.4214038550853729
[10/24] Train loss=0.47300586104393005
[15/24] Train loss=0.42221376299858093
[20/24] Train loss=0.37002119421958923
Test set avg_accuracy=82.07% avg_sensitivity=89.25%, avg_specificity=79.68% avg_auc=91.63%
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.433030 Test loss=0.431950 Current lr=[0.00029967723776099]

[0/24] Train loss=0.3945341408252716
[5/24] Train loss=0.3973253071308136
[10/24] Train loss=0.44595396518707275
[15/24] Train loss=0.4286235570907593
[20/24] Train loss=0.36840179562568665
Test set avg_accuracy=84.73% avg_sensitivity=80.96%, avg_specificity=85.98% avg_auc=91.14%
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.424693 Test loss=0.374736 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4328900873661041
[5/24] Train loss=0.3595231771469116
[10/24] Train loss=0.4640030264854431
[15/24] Train loss=0.44761958718299866
[20/24] Train loss=0.3887115716934204
Test set avg_accuracy=84.86% avg_sensitivity=84.40%, avg_specificity=85.01% avg_auc=91.63%
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.452032 Test loss=0.368579 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.39447417855262756
[5/24] Train loss=0.4021172523498535
[10/24] Train loss=0.4410073757171631
[15/24] Train loss=0.4073435068130493
[20/24] Train loss=0.3803119957447052
Test set avg_accuracy=86.86% avg_sensitivity=71.15%, avg_specificity=92.09% avg_auc=90.23%
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.426857 Test loss=0.345727 Current lr=[0.000299720220882401]

[0/24] Train loss=0.3891052007675171
[5/24] Train loss=0.3461332619190216
[10/24] Train loss=0.4401128590106964
[15/24] Train loss=0.41438645124435425
[20/24] Train loss=0.385165810585022
Test set avg_accuracy=85.98% avg_sensitivity=74.02%, avg_specificity=89.95% avg_auc=90.52%
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.426980 Test loss=0.353047 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.38534027338027954
[5/24] Train loss=0.40527212619781494
[10/24] Train loss=0.4330374300479889
[15/24] Train loss=0.4166143536567688
[20/24] Train loss=0.3705234229564667
Test set avg_accuracy=82.45% avg_sensitivity=86.75%, avg_specificity=81.02% avg_auc=91.86%
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.437913 Test loss=0.404186 Current lr=[0.000298904600941902]

[0/24] Train loss=0.38666513562202454
[5/24] Train loss=0.3771575093269348
[10/24] Train loss=0.4032694697380066
[15/24] Train loss=0.4206047058105469
[20/24] Train loss=0.36128509044647217
Test set avg_accuracy=85.36% avg_sensitivity=80.07%, avg_specificity=87.12% avg_auc=91.11%
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.416267 Test loss=0.360065 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.39253535866737366
[5/24] Train loss=0.4367571473121643
[10/24] Train loss=0.42619064450263977
[15/24] Train loss=0.39559775590896606
[20/24] Train loss=0.3395458161830902
Test set avg_accuracy=84.77% avg_sensitivity=83.57%, avg_specificity=85.16% avg_auc=91.20%
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.419178 Test loss=0.399349 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3638024926185608
[5/24] Train loss=0.4016559422016144
[10/24] Train loss=0.41884979605674744
[15/24] Train loss=0.38437363505363464
[20/24] Train loss=0.35591942071914673
Test set avg_accuracy=86.60% avg_sensitivity=75.12%, avg_specificity=90.42% avg_auc=91.57%
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.401477 Test loss=0.337854 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3682851493358612
[5/24] Train loss=0.34592336416244507
[10/24] Train loss=0.40238332748413086
[15/24] Train loss=0.36204615235328674
[20/24] Train loss=0.3314237892627716
Test set avg_accuracy=86.28% avg_sensitivity=77.88%, avg_specificity=89.07% avg_auc=91.28%
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.389856 Test loss=0.345636 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3620278835296631
[5/24] Train loss=0.36063051223754883
[10/24] Train loss=0.3990139067173004
[15/24] Train loss=0.4080597758293152
[20/24] Train loss=0.3350866436958313
Test set avg_accuracy=80.05% avg_sensitivity=89.05%, avg_specificity=77.06% avg_auc=91.16%
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.388337 Test loss=0.501340 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.33826595544815063
[5/24] Train loss=0.3452788293361664
[10/24] Train loss=0.3939340114593506
[15/24] Train loss=0.40002113580703735
[20/24] Train loss=0.3637452721595764
Test set avg_accuracy=85.36% avg_sensitivity=80.33%, avg_specificity=87.04% avg_auc=91.56%
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.386646 Test loss=0.362510 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3557490110397339
[5/24] Train loss=0.34407272934913635
[10/24] Train loss=0.4107252061367035
[15/24] Train loss=0.37905189394950867
[20/24] Train loss=0.3233799338340759
Test set avg_accuracy=83.07% avg_sensitivity=88.52%, avg_specificity=81.26% avg_auc=92.04%
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.374466 Test loss=0.434289 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3696272671222687
[5/24] Train loss=0.32383713126182556
[10/24] Train loss=0.3917244076728821
[15/24] Train loss=0.38853636384010315
[20/24] Train loss=0.3401615619659424
Test set avg_accuracy=83.98% avg_sensitivity=86.28%, avg_specificity=83.22% avg_auc=91.84%
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.380939 Test loss=0.407458 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3661179542541504
[5/24] Train loss=0.3445160686969757
[10/24] Train loss=0.386045902967453
[15/24] Train loss=0.35966238379478455
[20/24] Train loss=0.3116254210472107
Test set avg_accuracy=84.56% avg_sensitivity=84.66%, avg_specificity=84.52% avg_auc=91.05%
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.366499 Test loss=0.416756 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.36595404148101807
[5/24] Train loss=0.3139914274215698
[10/24] Train loss=0.35440802574157715
[15/24] Train loss=0.36228466033935547
[20/24] Train loss=0.31241557002067566
Test set avg_accuracy=86.45% avg_sensitivity=68.96%, avg_specificity=92.26% avg_auc=90.71%
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.357402 Test loss=0.338911 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.34705933928489685
[5/24] Train loss=0.33700233697891235
[10/24] Train loss=0.3655663728713989
[15/24] Train loss=0.3566822409629822
[20/24] Train loss=0.32062506675720215
Test set avg_accuracy=81.69% avg_sensitivity=83.20%, avg_specificity=81.19% avg_auc=89.44%
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.362469 Test loss=0.451233 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3521924316883087
[5/24] Train loss=0.33554893732070923
[10/24] Train loss=0.37192225456237793
[15/24] Train loss=0.3742857873439789
[20/24] Train loss=0.3332954943180084
Test set avg_accuracy=82.92% avg_sensitivity=79.34%, avg_specificity=84.11% avg_auc=90.03%
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.374687 Test loss=0.418456 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3586166501045227
[5/24] Train loss=0.33147165179252625
[10/24] Train loss=0.33961501717567444
[15/24] Train loss=0.34284359216690063
[20/24] Train loss=0.29577288031578064
Test set avg_accuracy=87.10% avg_sensitivity=79.60%, avg_specificity=89.59% avg_auc=91.96%
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.351211 Test loss=0.329429 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.33238139748573303
[5/24] Train loss=0.31802675127983093
[10/24] Train loss=0.35420337319374084
[15/24] Train loss=0.3293288052082062
[20/24] Train loss=0.319982647895813
Test set avg_accuracy=77.85% avg_sensitivity=92.96%, avg_specificity=72.83% avg_auc=91.63%
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.355622 Test loss=0.504243 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3459394872188568
[5/24] Train loss=0.3160015344619751
[10/24] Train loss=0.33956828713417053
[15/24] Train loss=0.337238073348999
[20/24] Train loss=0.2975047826766968
Test set avg_accuracy=86.16% avg_sensitivity=81.17%, avg_specificity=87.82% avg_auc=92.00%
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.354120 Test loss=0.350157 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3302706480026245
[5/24] Train loss=0.34325143694877625
[10/24] Train loss=0.34489157795906067
[15/24] Train loss=0.3306936025619507
[20/24] Train loss=0.2867896556854248
Test set avg_accuracy=84.93% avg_sensitivity=64.11%, avg_specificity=91.86% avg_auc=87.53%
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.343156 Test loss=0.380128 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.32572638988494873
[5/24] Train loss=0.3179892301559448
[10/24] Train loss=0.34621304273605347
[15/24] Train loss=0.3322109580039978
[20/24] Train loss=0.29867276549339294
Test set avg_accuracy=82.47% avg_sensitivity=89.88%, avg_specificity=80.01% avg_auc=92.06%
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.337998 Test loss=0.435748 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.32265132665634155
[5/24] Train loss=0.29711952805519104
[10/24] Train loss=0.31924790143966675
[15/24] Train loss=0.31997936964035034
[20/24] Train loss=0.293010413646698
Test set avg_accuracy=85.85% avg_sensitivity=81.43%, avg_specificity=87.32% avg_auc=91.53%
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.331699 Test loss=0.358086 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.30733874440193176
[5/24] Train loss=0.31048592925071716
[10/24] Train loss=0.31895574927330017
[15/24] Train loss=0.30099695920944214
[20/24] Train loss=0.27801838517189026
Test set avg_accuracy=84.79% avg_sensitivity=87.12%, avg_specificity=84.02% avg_auc=92.44%
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.321788 Test loss=0.385153 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.2929585874080658
[5/24] Train loss=0.28815653920173645
[10/24] Train loss=0.3008320927619934
[15/24] Train loss=0.3139137327671051
[20/24] Train loss=0.28191977739334106
Test set avg_accuracy=84.51% avg_sensitivity=85.19%, avg_specificity=84.28% avg_auc=92.24%
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.318031 Test loss=0.378820 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.3241475820541382
[5/24] Train loss=0.291701078414917
[10/24] Train loss=0.30751311779022217
[15/24] Train loss=0.3060082197189331
[20/24] Train loss=0.3186122477054596
Test set avg_accuracy=82.21% avg_sensitivity=85.19%, avg_specificity=81.23% avg_auc=91.06%
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.327602 Test loss=0.420053 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.35850271582603455
[5/24] Train loss=0.3265620172023773
[10/24] Train loss=0.31759876012802124
[15/24] Train loss=0.31147268414497375
[20/24] Train loss=0.2976396381855011
Test set avg_accuracy=85.60% avg_sensitivity=76.37%, avg_specificity=88.67% avg_auc=90.51%
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.328329 Test loss=0.353676 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3138282299041748
[5/24] Train loss=0.32957887649536133
[10/24] Train loss=0.34784582257270813
[15/24] Train loss=0.3316957950592041
[20/24] Train loss=0.27549877762794495
Test set avg_accuracy=85.46% avg_sensitivity=77.78%, avg_specificity=88.01% avg_auc=91.67%
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.324557 Test loss=0.344782 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30889931321144104
[5/24] Train loss=0.31361162662506104
[10/24] Train loss=0.32674169540405273
[15/24] Train loss=0.3163384795188904
[20/24] Train loss=0.2862902581691742
Test set avg_accuracy=84.66% avg_sensitivity=88.11%, avg_specificity=83.52% avg_auc=92.10%
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.321806 Test loss=0.411281 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.30299049615859985
[5/24] Train loss=0.32751157879829407
[10/24] Train loss=0.32604095339775085
[15/24] Train loss=0.3014068901538849
[20/24] Train loss=0.27990609407424927
Test set avg_accuracy=86.50% avg_sensitivity=71.26%, avg_specificity=91.57% avg_auc=90.98%
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.316716 Test loss=0.336264 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.30940306186676025
[5/24] Train loss=0.2999546527862549
[10/24] Train loss=0.3166133463382721
[15/24] Train loss=0.2870504856109619
[20/24] Train loss=0.26512956619262695
Test set avg_accuracy=85.85% avg_sensitivity=82.94%, avg_specificity=86.81% avg_auc=91.65%
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.309468 Test loss=0.369665 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.29213443398475647
[5/24] Train loss=0.2853165864944458
[10/24] Train loss=0.31684401631355286
[15/24] Train loss=0.2800789475440979
[20/24] Train loss=0.27919530868530273
Test set avg_accuracy=84.69% avg_sensitivity=85.03%, avg_specificity=84.57% avg_auc=91.87%
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.300549 Test loss=0.387096 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3060742914676666
[5/24] Train loss=0.3045509457588196
[10/24] Train loss=0.29688042402267456
[15/24] Train loss=0.2884232997894287
[20/24] Train loss=0.25358542799949646
Test set avg_accuracy=82.07% avg_sensitivity=90.66%, avg_specificity=79.21% avg_auc=92.14%
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.300952 Test loss=0.460010 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.29636308550834656
[5/24] Train loss=0.2752021849155426
[10/24] Train loss=0.2928182780742645
[15/24] Train loss=0.29169172048568726
[20/24] Train loss=0.2622205913066864
Test set avg_accuracy=86.21% avg_sensitivity=81.01%, avg_specificity=87.94% avg_auc=92.09%
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.296039 Test loss=0.340110 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.32094645500183105
[5/24] Train loss=0.2915508449077606
[10/24] Train loss=0.3038468062877655
[15/24] Train loss=0.29371994733810425
[20/24] Train loss=0.2776724100112915
Test set avg_accuracy=81.54% avg_sensitivity=89.20%, avg_specificity=78.99% avg_auc=91.36%
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.300101 Test loss=0.470244 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.274429589509964
[5/24] Train loss=0.28145161271095276
[10/24] Train loss=0.29206565022468567
[15/24] Train loss=0.2870938777923584
[20/24] Train loss=0.2578762173652649
Test set avg_accuracy=85.90% avg_sensitivity=71.67%, avg_specificity=90.63% avg_auc=90.26%
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.297002 Test loss=0.358179 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2804151475429535
[5/24] Train loss=0.27126771211624146
[10/24] Train loss=0.297847181558609
[15/24] Train loss=0.2759789824485779
[20/24] Train loss=0.24137945473194122
Test set avg_accuracy=83.97% avg_sensitivity=83.15%, avg_specificity=84.24% avg_auc=90.18%
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.289699 Test loss=0.422423 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.27448582649230957
[5/24] Train loss=0.278850793838501
[10/24] Train loss=0.308139830827713
[15/24] Train loss=0.2545625567436218
[20/24] Train loss=0.2575676143169403
Test set avg_accuracy=86.41% avg_sensitivity=75.85%, avg_specificity=89.92% avg_auc=91.05%
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.281982 Test loss=0.349690 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.27260807156562805
[5/24] Train loss=0.2759372293949127
[10/24] Train loss=0.2829549312591553
[15/24] Train loss=0.255028635263443
[20/24] Train loss=0.22641529142856598
Test set avg_accuracy=85.44% avg_sensitivity=56.55%, avg_specificity=95.05% avg_auc=86.18%
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.273584 Test loss=0.395520 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2733091413974762
[5/24] Train loss=0.2671266496181488
[10/24] Train loss=0.26292672753334045
[15/24] Train loss=0.27279648184776306
[20/24] Train loss=0.23394635319709778
Test set avg_accuracy=85.34% avg_sensitivity=62.13%, avg_specificity=93.06% avg_auc=88.86%
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.271725 Test loss=0.368819 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2632826268672943
[5/24] Train loss=0.2567726671695709
[10/24] Train loss=0.2760358452796936
[15/24] Train loss=0.2790045738220215
[20/24] Train loss=0.2343197613954544
Test set avg_accuracy=85.16% avg_sensitivity=60.62%, avg_specificity=93.32% avg_auc=86.44%
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.269411 Test loss=0.399083 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.26412928104400635
[5/24] Train loss=0.2586459815502167
[10/24] Train loss=0.2782049775123596
[15/24] Train loss=0.28636476397514343
[20/24] Train loss=0.253921240568161
Test set avg_accuracy=86.45% avg_sensitivity=70.79%, avg_specificity=91.65% avg_auc=89.45%
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.278564 Test loss=0.354376 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2627984881401062
[5/24] Train loss=0.2717532217502594
[10/24] Train loss=0.2657676041126251
[15/24] Train loss=0.2619918882846832
[20/24] Train loss=0.23387226462364197
Test set avg_accuracy=86.58% avg_sensitivity=66.67%, avg_specificity=93.20% avg_auc=89.03%
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.275173 Test loss=0.357512 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2691318094730377
[5/24] Train loss=0.26140469312667847
[10/24] Train loss=0.28495752811431885
[15/24] Train loss=0.2549404799938202
[20/24] Train loss=0.2314041554927826
Test set avg_accuracy=86.50% avg_sensitivity=80.70%, avg_specificity=88.43% avg_auc=91.33%
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.265780 Test loss=0.372169 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2439117133617401
[5/24] Train loss=0.26538020372390747
[10/24] Train loss=0.25336262583732605
[15/24] Train loss=0.26305994391441345
[20/24] Train loss=0.2240046262741089
Test set avg_accuracy=87.06% avg_sensitivity=74.02%, avg_specificity=91.39% avg_auc=90.45%
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.262683 Test loss=0.348768 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2656080424785614
[5/24] Train loss=0.2526136040687561
[10/24] Train loss=0.24784725904464722
[15/24] Train loss=0.25226539373397827
[20/24] Train loss=0.22253309190273285
Test set avg_accuracy=85.62% avg_sensitivity=58.53%, avg_specificity=94.64% avg_auc=85.49%
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.257787 Test loss=0.392693 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.24630655348300934
[5/24] Train loss=0.24907921254634857
[10/24] Train loss=0.247035413980484
[15/24] Train loss=0.247192844748497
[20/24] Train loss=0.21494747698307037
Test set avg_accuracy=85.40% avg_sensitivity=67.14%, avg_specificity=91.48% avg_auc=87.81%
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.248951 Test loss=0.370961 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2236955761909485
[5/24] Train loss=0.2531786561012268
[10/24] Train loss=0.2430131882429123
[15/24] Train loss=0.2362821102142334
[20/24] Train loss=0.21344174444675446
Test set avg_accuracy=87.60% avg_sensitivity=73.66%, avg_specificity=92.24% avg_auc=91.32%
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.243979 Test loss=0.327047 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.22125403583049774
[5/24] Train loss=0.25444653630256653
[10/24] Train loss=0.24604785442352295
[15/24] Train loss=0.2328416258096695
[20/24] Train loss=0.21594223380088806
Test set avg_accuracy=86.16% avg_sensitivity=59.94%, avg_specificity=94.88% avg_auc=88.76%
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.246856 Test loss=0.385693 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.23515240848064423
[5/24] Train loss=0.23635542392730713
[10/24] Train loss=0.2269742786884308
[15/24] Train loss=0.22482368350028992
[20/24] Train loss=0.20375129580497742
Test set avg_accuracy=87.33% avg_sensitivity=70.37%, avg_specificity=92.97% avg_auc=90.91%
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.239128 Test loss=0.338035 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.22084368765354156
[5/24] Train loss=0.23483410477638245
[10/24] Train loss=0.23926232755184174
[15/24] Train loss=0.2257535457611084
[20/24] Train loss=0.21286225318908691
Test set avg_accuracy=87.17% avg_sensitivity=74.33%, avg_specificity=91.45% avg_auc=90.98%
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.235470 Test loss=0.348725 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.22312207520008087
[5/24] Train loss=0.23625171184539795
[10/24] Train loss=0.23889552056789398
[15/24] Train loss=0.2417885661125183
[20/24] Train loss=0.21651127934455872
Test set avg_accuracy=85.55% avg_sensitivity=61.24%, avg_specificity=93.63% avg_auc=88.00%
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.236564 Test loss=0.369066 Current lr=[0.000156543481933168]

[0/24] Train loss=0.23504334688186646
[5/24] Train loss=0.23501409590244293
[10/24] Train loss=0.24062001705169678
[15/24] Train loss=0.22796711325645447
[20/24] Train loss=0.2141570895910263
Test set avg_accuracy=87.27% avg_sensitivity=77.62%, avg_specificity=90.47% avg_auc=91.17%
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.234951 Test loss=0.350220 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.218533456325531
[5/24] Train loss=0.23535758256912231
[10/24] Train loss=0.2332606166601181
[15/24] Train loss=0.23930329084396362
[20/24] Train loss=0.2072598934173584
Test set avg_accuracy=84.82% avg_sensitivity=84.45%, avg_specificity=84.94% avg_auc=91.69%
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.233600 Test loss=0.404148 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.22897319495677948
[5/24] Train loss=0.24667727947235107
[10/24] Train loss=0.23767176270484924
[15/24] Train loss=0.22399823367595673
[20/24] Train loss=0.21467648446559906
Test set avg_accuracy=87.43% avg_sensitivity=70.84%, avg_specificity=92.96% avg_auc=90.38%
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.237118 Test loss=0.345051 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.21813690662384033
[5/24] Train loss=0.23650196194648743
[10/24] Train loss=0.2275208681821823
[15/24] Train loss=0.22240357100963593
[20/24] Train loss=0.20791982114315033
Test set avg_accuracy=87.07% avg_sensitivity=77.15%, avg_specificity=90.37% avg_auc=91.34%
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.234834 Test loss=0.356000 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22181686758995056
[5/24] Train loss=0.2315642088651657
[10/24] Train loss=0.2336476743221283
[15/24] Train loss=0.2338007092475891
[20/24] Train loss=0.22150148451328278
Test set avg_accuracy=87.37% avg_sensitivity=72.20%, avg_specificity=92.42% avg_auc=90.74%
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.237010 Test loss=0.353173 Current lr=[0.000134135431043539]

[0/24] Train loss=0.21106158196926117
[5/24] Train loss=0.22802051901817322
[10/24] Train loss=0.23227925598621368
[15/24] Train loss=0.23950985074043274
[20/24] Train loss=0.20607890188694
Test set avg_accuracy=86.98% avg_sensitivity=76.47%, avg_specificity=90.47% avg_auc=91.13%
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.235330 Test loss=0.370857 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.23224930465221405
[5/24] Train loss=0.24244548380374908
[10/24] Train loss=0.24779941141605377
[15/24] Train loss=0.22396411001682281
[20/24] Train loss=0.20865032076835632
Test set avg_accuracy=84.88% avg_sensitivity=81.69%, avg_specificity=85.94% avg_auc=91.23%
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.232007 Test loss=0.393824 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.22417905926704407
[5/24] Train loss=0.2304583489894867
[10/24] Train loss=0.23458532989025116
[15/24] Train loss=0.2115841656923294
[20/24] Train loss=0.19878792762756348
Test set avg_accuracy=85.79% avg_sensitivity=81.53%, avg_specificity=87.21% avg_auc=91.67%
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.227062 Test loss=0.376871 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.23064668476581573
[5/24] Train loss=0.21641236543655396
[10/24] Train loss=0.23025009036064148
[15/24] Train loss=0.2072964608669281
[20/24] Train loss=0.19117292761802673
Test set avg_accuracy=86.61% avg_sensitivity=77.99%, avg_specificity=89.48% avg_auc=91.78%
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.224989 Test loss=0.362290 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.20850048959255219
[5/24] Train loss=0.21331514418125153
[10/24] Train loss=0.21833650767803192
[15/24] Train loss=0.21151423454284668
[20/24] Train loss=0.18717458844184875
Test set avg_accuracy=85.95% avg_sensitivity=80.07%, avg_specificity=87.91% avg_auc=92.15%
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.214907 Test loss=0.358137 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2039487063884735
[5/24] Train loss=0.21270136535167694
[10/24] Train loss=0.20405027270317078
[15/24] Train loss=0.20080271363258362
[20/24] Train loss=0.1844726949930191
Test set avg_accuracy=86.47% avg_sensitivity=81.90%, avg_specificity=87.99% avg_auc=91.67%
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.213251 Test loss=0.366212 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.20483332872390747
[5/24] Train loss=0.21236920356750488
[10/24] Train loss=0.21189209818840027
[15/24] Train loss=0.19151881337165833
[20/24] Train loss=0.18584690988063812
Test set avg_accuracy=86.86% avg_sensitivity=81.74%, avg_specificity=88.56% avg_auc=92.27%
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.209912 Test loss=0.352045 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.19425244629383087
[5/24] Train loss=0.20170438289642334
[10/24] Train loss=0.21960975229740143
[15/24] Train loss=0.18747444450855255
[20/24] Train loss=0.18382064998149872
Test set avg_accuracy=86.84% avg_sensitivity=77.67%, avg_specificity=89.88% avg_auc=91.29%
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.208191 Test loss=0.356940 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.19731761515140533
[5/24] Train loss=0.19427411258220673
[10/24] Train loss=0.2039286494255066
[15/24] Train loss=0.19324029982089996
[20/24] Train loss=0.17509989440441132
Test set avg_accuracy=86.09% avg_sensitivity=81.01%, avg_specificity=87.78% avg_auc=91.60%
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.204865 Test loss=0.381487 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.20042480528354645
[5/24] Train loss=0.20243369042873383
[10/24] Train loss=0.19511139392852783
[15/24] Train loss=0.1912318915128708
[20/24] Train loss=0.17644593119621277
Test set avg_accuracy=85.76% avg_sensitivity=83.15%, avg_specificity=86.62% avg_auc=91.83%
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.202215 Test loss=0.386262 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.1940954327583313
[5/24] Train loss=0.19308249652385712
[10/24] Train loss=0.19598564505577087
[15/24] Train loss=0.19280479848384857
[20/24] Train loss=0.1818738728761673
Test set avg_accuracy=86.71% avg_sensitivity=82.79%, avg_specificity=88.01% avg_auc=91.79%
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.199665 Test loss=0.377610 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1841670423746109
[5/24] Train loss=0.20091919600963593
[10/24] Train loss=0.20080554485321045
[15/24] Train loss=0.18480372428894043
[20/24] Train loss=0.1745009571313858
Test set avg_accuracy=86.54% avg_sensitivity=78.66%, avg_specificity=89.15% avg_auc=91.67%
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.196266 Test loss=0.362762 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1797267347574234
[5/24] Train loss=0.19553206861019135
[10/24] Train loss=0.18597523868083954
[15/24] Train loss=0.1841636747121811
[20/24] Train loss=0.16863588988780975
Test set avg_accuracy=86.84% avg_sensitivity=81.01%, avg_specificity=88.77% avg_auc=91.45%
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.193165 Test loss=0.371942 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1813526600599289
[5/24] Train loss=0.19291739165782928
[10/24] Train loss=0.1858157366514206
[15/24] Train loss=0.18590261042118073
[20/24] Train loss=0.16746030747890472
Test set avg_accuracy=86.46% avg_sensitivity=81.85%, avg_specificity=87.99% avg_auc=92.04%
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.191047 Test loss=0.373347 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.17713713645935059
[5/24] Train loss=0.19567380845546722
[10/24] Train loss=0.18889176845550537
[15/24] Train loss=0.18233737349510193
[20/24] Train loss=0.16477671265602112
Test set avg_accuracy=87.21% avg_sensitivity=77.15%, avg_specificity=90.56% avg_auc=91.36%
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.188923 Test loss=0.349722 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.1744987964630127
[5/24] Train loss=0.19315741956233978
[10/24] Train loss=0.18723778426647186
[15/24] Train loss=0.17913998663425446
[20/24] Train loss=0.16267529129981995
Test set avg_accuracy=86.42% avg_sensitivity=81.06%, avg_specificity=88.20% avg_auc=91.55%
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.185926 Test loss=0.379434 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1756134182214737
[5/24] Train loss=0.19045360386371613
[10/24] Train loss=0.1799219250679016
[15/24] Train loss=0.17908644676208496
[20/24] Train loss=0.16550999879837036
Test set avg_accuracy=86.55% avg_sensitivity=80.39%, avg_specificity=88.60% avg_auc=91.63%
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.185974 Test loss=0.375713 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1777673065662384
[5/24] Train loss=0.18654079735279083
[10/24] Train loss=0.18470285832881927
[15/24] Train loss=0.17374259233474731
[20/24] Train loss=0.16395632922649384
Test set avg_accuracy=87.50% avg_sensitivity=78.51%, avg_specificity=90.49% avg_auc=91.49%
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.183581 Test loss=0.347145 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.16651511192321777
[5/24] Train loss=0.19292080402374268
[10/24] Train loss=0.1825931817293167
[15/24] Train loss=0.16966451704502106
[20/24] Train loss=0.16547806560993195
Test set avg_accuracy=86.63% avg_sensitivity=78.87%, avg_specificity=89.21% avg_auc=91.35%
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.181500 Test loss=0.367977 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.17129504680633545
[5/24] Train loss=0.1860627979040146
[10/24] Train loss=0.18158207833766937
[15/24] Train loss=0.1663559377193451
[20/24] Train loss=0.1623581349849701
Test set avg_accuracy=87.49% avg_sensitivity=77.99%, avg_specificity=90.65% avg_auc=91.05%
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.179793 Test loss=0.353826 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.16374018788337708
[5/24] Train loss=0.17786471545696259
[10/24] Train loss=0.18168380856513977
[15/24] Train loss=0.1682765781879425
[20/24] Train loss=0.15715982019901276
Test set avg_accuracy=86.98% avg_sensitivity=79.76%, avg_specificity=89.38% avg_auc=91.49%
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.178883 Test loss=0.366271 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.1652437299489975
[5/24] Train loss=0.18084460496902466
[10/24] Train loss=0.1780880093574524
[15/24] Train loss=0.16558241844177246
[20/24] Train loss=0.15951065719127655
Test set avg_accuracy=87.16% avg_sensitivity=75.43%, avg_specificity=91.06% avg_auc=90.69%
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.177053 Test loss=0.355522 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.16323357820510864
[5/24] Train loss=0.18041428923606873
[10/24] Train loss=0.17285911738872528
[15/24] Train loss=0.1675291806459427
[20/24] Train loss=0.15596380829811096
Test set avg_accuracy=87.32% avg_sensitivity=76.26%, avg_specificity=90.99% avg_auc=91.20%
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.177065 Test loss=0.351261 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.16478392481803894
[5/24] Train loss=0.1824973225593567
[10/24] Train loss=0.1754087209701538
[15/24] Train loss=0.16964128613471985
[20/24] Train loss=0.15827660262584686
Test set avg_accuracy=87.07% avg_sensitivity=74.96%, avg_specificity=91.10% avg_auc=90.99%
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.177384 Test loss=0.351100 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.16560472548007965
[5/24] Train loss=0.17597466707229614
[10/24] Train loss=0.16944347321987152
[15/24] Train loss=0.16756337881088257
[20/24] Train loss=0.15774662792682648
Test set avg_accuracy=86.41% avg_sensitivity=79.39%, avg_specificity=88.74% avg_auc=91.54%
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.176808 Test loss=0.370654 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.16035570204257965
[5/24] Train loss=0.18584422767162323
[10/24] Train loss=0.17432846128940582
[15/24] Train loss=0.16862906515598297
[20/24] Train loss=0.1625293791294098
Test set avg_accuracy=86.86% avg_sensitivity=77.41%, avg_specificity=90.01% avg_auc=91.18%
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.178084 Test loss=0.362404 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1620352566242218
[5/24] Train loss=0.18355421721935272
[10/24] Train loss=0.18350906670093536
[15/24] Train loss=0.16010263562202454
[20/24] Train loss=0.1657789647579193
Test set avg_accuracy=85.98% avg_sensitivity=82.06%, avg_specificity=87.28% avg_auc=92.10%
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.179894 Test loss=0.377593 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.167434960603714
[5/24] Train loss=0.1712767481803894
[10/24] Train loss=0.17857065796852112
[15/24] Train loss=0.17204007506370544
[20/24] Train loss=0.15820075571537018
Test set avg_accuracy=86.54% avg_sensitivity=79.55%, avg_specificity=88.86% avg_auc=91.42%
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.177455 Test loss=0.370287 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.16705231368541718
[5/24] Train loss=0.1727234274148941
[10/24] Train loss=0.17584967613220215
[15/24] Train loss=0.17206084728240967
[20/24] Train loss=0.15295401215553284
Test set avg_accuracy=87.30% avg_sensitivity=75.95%, avg_specificity=91.08% avg_auc=91.23%
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.175588 Test loss=0.353714 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1627521961927414
[5/24] Train loss=0.1804899275302887
[10/24] Train loss=0.17013436555862427
[15/24] Train loss=0.174257293343544
[20/24] Train loss=0.14986000955104828
Test set avg_accuracy=87.08% avg_sensitivity=78.09%, avg_specificity=90.07% avg_auc=91.29%
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.174416 Test loss=0.356420 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.16012181341648102
[5/24] Train loss=0.17216098308563232
[10/24] Train loss=0.17097342014312744
[15/24] Train loss=0.16307874023914337
[20/24] Train loss=0.15392716228961945
Test set avg_accuracy=86.89% avg_sensitivity=80.13%, avg_specificity=89.14% avg_auc=91.65%
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.170411 Test loss=0.360903 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.15603749454021454
[5/24] Train loss=0.16977018117904663
[10/24] Train loss=0.16505099833011627
[15/24] Train loss=0.15938109159469604
[20/24] Train loss=0.15000468492507935
Test set avg_accuracy=87.36% avg_sensitivity=78.82%, avg_specificity=90.20% avg_auc=91.43%
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.167316 Test loss=0.353320 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.15242508053779602
[5/24] Train loss=0.1659630537033081
[10/24] Train loss=0.17041577398777008
[15/24] Train loss=0.15763935446739197
[20/24] Train loss=0.1482808142900467
Test set avg_accuracy=87.19% avg_sensitivity=79.19%, avg_specificity=89.85% avg_auc=91.34%
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.166179 Test loss=0.358310 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1552153080701828
[5/24] Train loss=0.16784970462322235
[10/24] Train loss=0.16769777238368988
[15/24] Train loss=0.15553255379199982
[20/24] Train loss=0.147569477558136
Test set avg_accuracy=87.06% avg_sensitivity=79.86%, avg_specificity=89.45% avg_auc=91.55%
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.165435 Test loss=0.359206 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.1531282514333725
[5/24] Train loss=0.17071890830993652
[10/24] Train loss=0.16513901948928833
[15/24] Train loss=0.15672457218170166
[20/24] Train loss=0.14817845821380615
Test set avg_accuracy=87.15% avg_sensitivity=78.72%, avg_specificity=89.95% avg_auc=91.54%
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.165595 Test loss=0.357034 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1557813137769699
[5/24] Train loss=0.1673123985528946
[10/24] Train loss=0.16368012130260468
[15/24] Train loss=0.16049951314926147
[20/24] Train loss=0.14625284075737
Test set avg_accuracy=87.03% avg_sensitivity=78.93%, avg_specificity=89.73% avg_auc=91.47%
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.164539 Test loss=0.357348 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.14857330918312073
[5/24] Train loss=0.16617350280284882
[10/24] Train loss=0.16692611575126648
[15/24] Train loss=0.1565064936876297
[20/24] Train loss=0.1462983787059784
Test set avg_accuracy=87.14% avg_sensitivity=79.03%, avg_specificity=89.83% avg_auc=91.55%
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.164271 Test loss=0.356202 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.15315105020999908
[5/24] Train loss=0.16610296070575714
[10/24] Train loss=0.16561713814735413
[15/24] Train loss=0.15501445531845093
[20/24] Train loss=0.14575493335723877
Test set avg_accuracy=87.21% avg_sensitivity=79.39%, avg_specificity=89.81% avg_auc=91.52%
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.163896 Test loss=0.357191 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.15151123702526093
[5/24] Train loss=0.17009440064430237
[10/24] Train loss=0.1643272191286087
[15/24] Train loss=0.15493863821029663
[20/24] Train loss=0.14647987484931946
Test set avg_accuracy=87.07% avg_sensitivity=79.50%, avg_specificity=89.59% avg_auc=91.50%
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.163435 Test loss=0.360038 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.14947064220905304
[5/24] Train loss=0.1714806705713272
[10/24] Train loss=0.16128510236740112
[15/24] Train loss=0.15748244524002075
[20/24] Train loss=0.14806579053401947
Test set avg_accuracy=87.29% avg_sensitivity=78.98%, avg_specificity=90.06% avg_auc=91.55%
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.164065 Test loss=0.354221 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.15355201065540314
[5/24] Train loss=0.1686212569475174
[10/24] Train loss=0.16397668421268463
[15/24] Train loss=0.1523369997739792
[20/24] Train loss=0.1438858062028885
Test set avg_accuracy=87.16% avg_sensitivity=79.55%, avg_specificity=89.69% avg_auc=91.62%
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.162686 Test loss=0.356001 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1558789610862732
[5/24] Train loss=0.16477856040000916
[10/24] Train loss=0.16465802490711212
[15/24] Train loss=0.15701459348201752
[20/24] Train loss=0.14880339801311493
Test set avg_accuracy=87.17% avg_sensitivity=79.34%, avg_specificity=89.78% avg_auc=91.58%
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.162927 Test loss=0.356451 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.1512700766324997
[5/24] Train loss=0.16763411462306976
[10/24] Train loss=0.1614687293767929
[15/24] Train loss=0.15105661749839783
[20/24] Train loss=0.14824146032333374
Test set avg_accuracy=87.24% avg_sensitivity=79.19%, avg_specificity=89.92% avg_auc=91.54%
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.162686 Test loss=0.356516 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1510878950357437
[5/24] Train loss=0.16379563510417938
[10/24] Train loss=0.15933305025100708
[15/24] Train loss=0.15039294958114624
[20/24] Train loss=0.150384783744812
Test set avg_accuracy=87.20% avg_sensitivity=79.19%, avg_specificity=89.87% avg_auc=91.54%
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.162879 Test loss=0.357221 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.15053711831569672
[5/24] Train loss=0.16734157502651215
[10/24] Train loss=0.16498365998268127
[15/24] Train loss=0.15132246911525726
[20/24] Train loss=0.14699441194534302
Test set avg_accuracy=87.12% avg_sensitivity=79.34%, avg_specificity=89.71% avg_auc=91.55%
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.163075 Test loss=0.357730 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.14951573312282562
[5/24] Train loss=0.16594083607196808
[10/24] Train loss=0.16590313613414764
[15/24] Train loss=0.15012162923812866
[20/24] Train loss=0.14587435126304626
Test set avg_accuracy=87.20% avg_sensitivity=79.34%, avg_specificity=89.81% avg_auc=91.55%
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.161945 Test loss=0.357449 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.14931730926036835
[5/24] Train loss=0.1660291850566864
[10/24] Train loss=0.16035965085029602
[15/24] Train loss=0.151313915848732
[20/24] Train loss=0.1435980498790741
Test set avg_accuracy=87.20% avg_sensitivity=79.34%, avg_specificity=89.81% avg_auc=91.56%
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.161558 Test loss=0.357118 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.14806661009788513
[5/24] Train loss=0.1619691550731659
[10/24] Train loss=0.16326351463794708
[15/24] Train loss=0.15219390392303467
[20/24] Train loss=0.1435532420873642
Test set avg_accuracy=87.19% avg_sensitivity=79.29%, avg_specificity=89.81% avg_auc=91.56%
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.162735 Test loss=0.356958 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.14660577476024628
[5/24] Train loss=0.16728593409061432
[10/24] Train loss=0.16495387256145477
[15/24] Train loss=0.15404297411441803
[20/24] Train loss=0.14379432797431946
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=87.17% avg_sensitivity=79.29%, avg_specificity=89.80% avg_auc=91.56%
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.162464 Test loss=0.357383 Current lr=[1.3165623068326024e-09]

Fold[2] Result: acc=86.15% sen=83.67%, spe=86.97%, auc=92.97%!
Fold[2] Avg_overlap=0.67%(0.22466610298722264)
[0/24] Train loss=1.5317823886871338
[5/24] Train loss=1.4909652471542358
[10/24] Train loss=1.4991785287857056
[15/24] Train loss=1.4512131214141846
[20/24] Train loss=1.434004783630371
Test set avg_accuracy=55.13% avg_sensitivity=51.42%, avg_specificity=56.54% avg_auc=57.59%
Best model saved!! Metric=-105.32198137626531!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=1.470549 Test loss=0.673099 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4369499683380127
[5/24] Train loss=1.4072556495666504
[10/24] Train loss=1.406904935836792
[15/24] Train loss=1.3513481616973877
[20/24] Train loss=1.3574646711349487
Test set avg_accuracy=65.04% avg_sensitivity=64.69%, avg_specificity=65.17% avg_auc=69.83%
Best model saved!! Metric=-61.26746706341949!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=1.390428 Test loss=0.621731 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3575973510742188
[5/24] Train loss=1.3402451276779175
[10/24] Train loss=1.3480284214019775
[15/24] Train loss=1.2833096981048584
[20/24] Train loss=1.2718374729156494
Test set avg_accuracy=69.23% avg_sensitivity=75.83%, avg_specificity=66.73% avg_auc=77.17%
Best model saved!! Metric=-37.0362229042759!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=1.321540 Test loss=0.594521 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2576758861541748
[5/24] Train loss=1.2679474353790283
[10/24] Train loss=1.2972054481506348
[15/24] Train loss=1.2304104566574097
[20/24] Train loss=1.182834506034851
Test set avg_accuracy=71.35% avg_sensitivity=82.04%, avg_specificity=67.31% avg_auc=81.09%
Best model saved!! Metric=-24.209133681338486!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=1.247134 Test loss=0.572904 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1743570566177368
[5/24] Train loss=1.2065175771713257
[10/24] Train loss=1.2249847650527954
[15/24] Train loss=1.1442713737487793
[20/24] Train loss=1.1175955533981323
Test set avg_accuracy=72.96% avg_sensitivity=84.55%, avg_specificity=68.56% avg_auc=83.66%
Best model saved!! Metric=-16.267513152119648!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=1.176604 Test loss=0.550464 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1055448055267334
[5/24] Train loss=1.1265956163406372
[10/24] Train loss=1.167952060699463
[15/24] Train loss=1.0770409107208252
[20/24] Train loss=1.0579286813735962
Test set avg_accuracy=74.47% avg_sensitivity=85.50%, avg_specificity=70.29% avg_auc=85.39%
Best model saved!! Metric=-10.355601509830379!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=1.111238 Test loss=0.529790 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0443074703216553
[5/24] Train loss=1.0625907182693481
[10/24] Train loss=1.1125664710998535
[15/24] Train loss=1.0303467512130737
[20/24] Train loss=0.9877498149871826
Test set avg_accuracy=76.33% avg_sensitivity=85.40%, avg_specificity=72.89% avg_auc=86.91%
Best model saved!! Metric=-4.470040527921242!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=1.052621 Test loss=0.505132 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9925889372825623
[5/24] Train loss=1.0234628915786743
[10/24] Train loss=1.0748995542526245
[15/24] Train loss=0.9926174283027649
[20/24] Train loss=0.930503785610199
Test set avg_accuracy=77.83% avg_sensitivity=85.17%, avg_specificity=75.04% avg_auc=88.09%
Best model saved!! Metric=0.12509454830947675!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=1.000783 Test loss=0.481683 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9451560974121094
[5/24] Train loss=0.9620065689086914
[10/24] Train loss=0.9907369613647461
[15/24] Train loss=0.9240269660949707
[20/24] Train loss=0.8801053166389465
Test set avg_accuracy=80.01% avg_sensitivity=84.60%, avg_specificity=78.28% avg_auc=89.22%
Best model saved!! Metric=6.108671194526934!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.943506 Test loss=0.454428 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8963936567306519
[5/24] Train loss=0.9080151319503784
[10/24] Train loss=0.9473448991775513
[15/24] Train loss=0.8849478960037231
[20/24] Train loss=0.8114145994186401
Test set avg_accuracy=81.51% avg_sensitivity=85.78%, avg_specificity=79.89% avg_auc=90.38%
Best model saved!! Metric=11.565578459276026!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.894559 Test loss=0.435850 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8452875018119812
[5/24] Train loss=0.8708555102348328
[10/24] Train loss=0.8954142928123474
[15/24] Train loss=0.8576216101646423
[20/24] Train loss=0.7728760242462158
Test set avg_accuracy=82.59% avg_sensitivity=86.35%, avg_specificity=81.17% avg_auc=91.03%
Best model saved!! Metric=15.138577487336235!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.850760 Test loss=0.426541 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7926105856895447
[5/24] Train loss=0.8345386981964111
[10/24] Train loss=0.8615998029708862
[15/24] Train loss=0.8086519241333008
[20/24] Train loss=0.7320194840431213
Test set avg_accuracy=82.93% avg_sensitivity=87.30%, avg_specificity=81.27% avg_auc=91.53%
Best model saved!! Metric=17.03495267310916!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.812715 Test loss=0.418682 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7553087472915649
[5/24] Train loss=0.8088530898094177
[10/24] Train loss=0.8449356555938721
[15/24] Train loss=0.7957345843315125
[20/24] Train loss=0.6936591267585754
Test set avg_accuracy=83.28% avg_sensitivity=86.97%, avg_specificity=81.89% avg_auc=91.97%
Best model saved!! Metric=18.098300550086392!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.777893 Test loss=0.407106 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7362046837806702
[5/24] Train loss=0.779333233833313
[10/24] Train loss=0.8257729411125183
[15/24] Train loss=0.7559719085693359
[20/24] Train loss=0.6666536331176758
Test set avg_accuracy=83.76% avg_sensitivity=86.82%, avg_specificity=82.60% avg_auc=92.24%
Best model saved!! Metric=19.42801696188252!!
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.751815 Test loss=0.397598 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7036768794059753
[5/24] Train loss=0.7513960003852844
[10/24] Train loss=0.7781292796134949
[15/24] Train loss=0.7385886311531067
[20/24] Train loss=0.6419237852096558
Test set avg_accuracy=84.41% avg_sensitivity=86.97%, avg_specificity=83.45% avg_auc=92.53%
Best model saved!! Metric=21.35690967554264!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.724817 Test loss=0.387797 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6739489436149597
[5/24] Train loss=0.7278122305870056
[10/24] Train loss=0.7727072834968567
[15/24] Train loss=0.7111772298812866
[20/24] Train loss=0.6285297870635986
Test set avg_accuracy=85.08% avg_sensitivity=86.26%, avg_specificity=84.63% avg_auc=92.75%
Best model saved!! Metric=22.71922874637316!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.706221 Test loss=0.367873 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6519775986671448
[5/24] Train loss=0.6996098160743713
[10/24] Train loss=0.7402076125144958
[15/24] Train loss=0.7149785757064819
[20/24] Train loss=0.5998578667640686
Test set avg_accuracy=84.78% avg_sensitivity=87.25%, avg_specificity=83.84% avg_auc=92.70%
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.684796 Test loss=0.375669 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6439526677131653
[5/24] Train loss=0.6903947591781616
[10/24] Train loss=0.7452202439308167
[15/24] Train loss=0.7020112872123718
[20/24] Train loss=0.5774555802345276
Test set avg_accuracy=83.48% avg_sensitivity=88.82%, avg_specificity=81.45% avg_auc=92.82%
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.674541 Test loss=0.392678 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6256940364837646
[5/24] Train loss=0.6721375584602356
[10/24] Train loss=0.721196174621582
[15/24] Train loss=0.674366295337677
[20/24] Train loss=0.5652667880058289
Test set avg_accuracy=84.65% avg_sensitivity=88.53%, avg_specificity=83.18% avg_auc=93.09%
Best model saved!! Metric=23.450295796391487!!
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.656234 Test loss=0.372479 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6088681221008301
[5/24] Train loss=0.6491637229919434
[10/24] Train loss=0.703559935092926
[15/24] Train loss=0.6641160845756531
[20/24] Train loss=0.5539909601211548
Test set avg_accuracy=85.31% avg_sensitivity=87.54%, avg_specificity=84.47% avg_auc=93.22%
Best model saved!! Metric=24.54330228373057!!
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.643776 Test loss=0.355879 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5896406769752502
[5/24] Train loss=0.6140732765197754
[10/24] Train loss=0.6922827959060669
[15/24] Train loss=0.6562974452972412
[20/24] Train loss=0.5392011404037476
Test set avg_accuracy=86.47% avg_sensitivity=84.83%, avg_specificity=87.09% avg_auc=93.29%
Best model saved!! Metric=25.686245212979443!!
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.627566 Test loss=0.330884 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5913243293762207
[5/24] Train loss=0.6168093681335449
[10/24] Train loss=0.7036534547805786
[15/24] Train loss=0.6431534886360168
[20/24] Train loss=0.5196632146835327
Test set avg_accuracy=87.08% avg_sensitivity=75.21%, avg_specificity=91.58% avg_auc=93.15%
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.617896 Test loss=0.300629 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5767716765403748
[5/24] Train loss=0.5782725811004639
[10/24] Train loss=0.6830158829689026
[15/24] Train loss=0.6180294156074524
[20/24] Train loss=0.5224841833114624
Test set avg_accuracy=86.91% avg_sensitivity=83.89%, avg_specificity=88.06% avg_auc=93.49%
Best model saved!! Metric=26.353646595569543!!
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.601658 Test loss=0.318117 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.569092333316803
[5/24] Train loss=0.5793116092681885
[10/24] Train loss=0.666815996170044
[15/24] Train loss=0.6072371602058411
[20/24] Train loss=0.5186054110527039
Test set avg_accuracy=87.63% avg_sensitivity=81.42%, avg_specificity=89.98% avg_auc=93.41%
Best model saved!! Metric=26.440898642794167!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.596504 Test loss=0.305532 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5442203879356384
[5/24] Train loss=0.5565679669380188
[10/24] Train loss=0.6620115637779236
[15/24] Train loss=0.6020761132240295
[20/24] Train loss=0.5010059475898743
Test set avg_accuracy=85.17% avg_sensitivity=89.10%, avg_specificity=83.68% avg_auc=93.69%
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.583857 Test loss=0.352027 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5513049960136414
[5/24] Train loss=0.5577502846717834
[10/24] Train loss=0.6499740481376648
[15/24] Train loss=0.5896138548851013
[20/24] Train loss=0.4979182481765747
Test set avg_accuracy=87.51% avg_sensitivity=70.05%, avg_specificity=94.13% avg_auc=92.91%
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.571127 Test loss=0.300515 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5500502586364746
[5/24] Train loss=0.5277749300003052
[10/24] Train loss=0.6657017469406128
[15/24] Train loss=0.5698499083518982
[20/24] Train loss=0.4955137372016907
Test set avg_accuracy=86.35% avg_sensitivity=82.89%, avg_specificity=87.67% avg_auc=93.39%
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.560241 Test loss=0.319952 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5214588642120361
[5/24] Train loss=0.5221550464630127
[10/24] Train loss=0.6319409012794495
[15/24] Train loss=0.5472732782363892
[20/24] Train loss=0.4789511561393738
Test set avg_accuracy=88.09% avg_sensitivity=79.53%, avg_specificity=91.33% avg_auc=93.44%
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.552077 Test loss=0.296710 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5308173298835754
[5/24] Train loss=0.49912387132644653
[10/24] Train loss=0.6122178435325623
[15/24] Train loss=0.5552211999893188
[20/24] Train loss=0.46671628952026367
Test set avg_accuracy=88.01% avg_sensitivity=75.02%, avg_specificity=92.93% avg_auc=93.27%
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.538993 Test loss=0.292458 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5180716514587402
[5/24] Train loss=0.5089445114135742
[10/24] Train loss=0.6125849485397339
[15/24] Train loss=0.5318073630332947
[20/24] Train loss=0.45538389682769775
Test set avg_accuracy=88.06% avg_sensitivity=79.43%, avg_specificity=91.33% avg_auc=93.44%
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.529520 Test loss=0.297342 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.5199114680290222
[5/24] Train loss=0.48869916796684265
[10/24] Train loss=0.6249123811721802
[15/24] Train loss=0.5158566832542419
[20/24] Train loss=0.4649152457714081
Test set avg_accuracy=88.07% avg_sensitivity=73.55%, avg_specificity=93.57% avg_auc=92.86%
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.525339 Test loss=0.298522 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.47993898391723633
[5/24] Train loss=0.4908239543437958
[10/24] Train loss=0.5749122500419617
[15/24] Train loss=0.5212541818618774
[20/24] Train loss=0.44291070103645325
Test set avg_accuracy=88.09% avg_sensitivity=79.67%, avg_specificity=91.27% avg_auc=93.43%
Best model saved!! Metric=26.459583555799924!!
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.505994 Test loss=0.295342 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.4843863546848297
[5/24] Train loss=0.45395103096961975
[10/24] Train loss=0.5696883201599121
[15/24] Train loss=0.5479855537414551
[20/24] Train loss=0.4548201858997345
Test set avg_accuracy=83.66% avg_sensitivity=90.24%, avg_specificity=81.17% avg_auc=93.18%
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.500583 Test loss=0.391260 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.45854616165161133
[5/24] Train loss=0.5283504724502563
[10/24] Train loss=0.6092668771743774
[15/24] Train loss=0.5128304958343506
[20/24] Train loss=0.4481448233127594
Test set avg_accuracy=87.96% avg_sensitivity=77.44%, avg_specificity=91.94% avg_auc=93.03%
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.511631 Test loss=0.299314 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.4844890832901001
[5/24] Train loss=0.4371229410171509
[10/24] Train loss=0.5606211423873901
[15/24] Train loss=0.4974898397922516
[20/24] Train loss=0.41697797179222107
Test set avg_accuracy=88.11% avg_sensitivity=79.05%, avg_specificity=91.54% avg_auc=93.58%
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.487586 Test loss=0.291196 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4768868386745453
[5/24] Train loss=0.4121319353580475
[10/24] Train loss=0.583423912525177
[15/24] Train loss=0.4981957972049713
[20/24] Train loss=0.4037192165851593
Test set avg_accuracy=84.13% avg_sensitivity=86.97%, avg_specificity=83.05% avg_auc=92.65%
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.479589 Test loss=0.372549 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4458036720752716
[5/24] Train loss=0.42384740710258484
[10/24] Train loss=0.5510385632514954
[15/24] Train loss=0.4888792335987091
[20/24] Train loss=0.41800814867019653
Test set avg_accuracy=81.86% avg_sensitivity=84.88%, avg_specificity=80.72% avg_auc=90.76%
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.471383 Test loss=0.433088 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4463850259780884
[5/24] Train loss=0.4829087257385254
[10/24] Train loss=0.5615096092224121
[15/24] Train loss=0.4869966506958008
[20/24] Train loss=0.40985867381095886
Test set avg_accuracy=84.62% avg_sensitivity=55.45%, avg_specificity=95.67% avg_auc=90.44%
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.479376 Test loss=0.385103 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4527161121368408
[5/24] Train loss=0.41018423438072205
[10/24] Train loss=0.531546950340271
[15/24] Train loss=0.4896053373813629
[20/24] Train loss=0.39657673239707947
Test set avg_accuracy=86.93% avg_sensitivity=84.03%, avg_specificity=88.03% avg_auc=93.37%
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.458381 Test loss=0.320211 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.433307021856308
[5/24] Train loss=0.38270998001098633
[10/24] Train loss=0.5562960505485535
[15/24] Train loss=0.46915319561958313
[20/24] Train loss=0.40397781133651733
Test set avg_accuracy=85.87% avg_sensitivity=77.58%, avg_specificity=89.01% avg_auc=91.84%
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.456455 Test loss=0.337242 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4319813847541809
[5/24] Train loss=0.3778109848499298
[10/24] Train loss=0.49715399742126465
[15/24] Train loss=0.48318541049957275
[20/24] Train loss=0.3850787580013275
Test set avg_accuracy=86.47% avg_sensitivity=85.36%, avg_specificity=86.89% avg_auc=92.91%
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.445057 Test loss=0.337283 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4317585825920105
[5/24] Train loss=0.3646630048751831
[10/24] Train loss=0.4945782721042633
[15/24] Train loss=0.46927309036254883
[20/24] Train loss=0.3925156593322754
Test set avg_accuracy=84.23% avg_sensitivity=86.73%, avg_specificity=83.29% avg_auc=92.74%
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.440293 Test loss=0.366673 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4314625859260559
[5/24] Train loss=0.4027189016342163
[10/24] Train loss=0.5122244954109192
[15/24] Train loss=0.44718092679977417
[20/24] Train loss=0.38710612058639526
Test set avg_accuracy=87.21% avg_sensitivity=76.68%, avg_specificity=91.20% avg_auc=92.55%
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.444592 Test loss=0.310247 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.42224374413490295
[5/24] Train loss=0.38118693232536316
[10/24] Train loss=0.46956372261047363
[15/24] Train loss=0.4402103126049042
[20/24] Train loss=0.3729683458805084
Test set avg_accuracy=85.53% avg_sensitivity=89.57%, avg_specificity=84.00% avg_auc=93.73%
Best model saved!! Metric=26.843068219607716!!
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.423145 Test loss=0.349794 Current lr=[0.00029967723776099]

[0/24] Train loss=0.39753827452659607
[5/24] Train loss=0.41151055693626404
[10/24] Train loss=0.5351430773735046
[15/24] Train loss=0.4410611689090729
[20/24] Train loss=0.37857067584991455
Test set avg_accuracy=84.27% avg_sensitivity=87.49%, avg_specificity=83.05% avg_auc=92.65%
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.431594 Test loss=0.392802 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.41299450397491455
[5/24] Train loss=0.3636597692966461
[10/24] Train loss=0.49651530385017395
[15/24] Train loss=0.4389559030532837
[20/24] Train loss=0.364326149225235
Test set avg_accuracy=85.78% avg_sensitivity=88.58%, avg_specificity=84.72% avg_auc=93.52%
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.409093 Test loss=0.345424 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.38159704208374023
[5/24] Train loss=0.3529721796512604
[10/24] Train loss=0.48452702164649963
[15/24] Train loss=0.4228288531303406
[20/24] Train loss=0.357653945684433
Test set avg_accuracy=79.31% avg_sensitivity=92.13%, avg_specificity=74.45% avg_auc=92.04%
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.408915 Test loss=0.503692 Current lr=[0.000299720220882401]

[0/24] Train loss=0.42665955424308777
[5/24] Train loss=0.3527919352054596
[10/24] Train loss=0.4782644808292389
[15/24] Train loss=0.44810545444488525
[20/24] Train loss=0.36178553104400635
Test set avg_accuracy=84.48% avg_sensitivity=90.81%, avg_specificity=82.08% avg_auc=93.37%
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.413450 Test loss=0.385948 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.41283565759658813
[5/24] Train loss=0.3511113226413727
[10/24] Train loss=0.47104915976524353
[15/24] Train loss=0.4618986248970032
[20/24] Train loss=0.3609394133090973
Test set avg_accuracy=85.25% avg_sensitivity=86.35%, avg_specificity=84.83% avg_auc=93.04%
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.404904 Test loss=0.347888 Current lr=[0.000298904600941902]

[0/24] Train loss=0.398454487323761
[5/24] Train loss=0.3500283658504486
[10/24] Train loss=0.4436658024787903
[15/24] Train loss=0.430797278881073
[20/24] Train loss=0.34152090549468994
Test set avg_accuracy=86.17% avg_sensitivity=86.35%, avg_specificity=86.10% avg_auc=93.00%
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.390557 Test loss=0.340529 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3924267590045929
[5/24] Train loss=0.368063747882843
[10/24] Train loss=0.45648500323295593
[15/24] Train loss=0.4078284800052643
[20/24] Train loss=0.3587205708026886
Test set avg_accuracy=85.96% avg_sensitivity=86.02%, avg_specificity=85.94% avg_auc=92.95%
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.396388 Test loss=0.349517 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3701353371143341
[5/24] Train loss=0.34833642840385437
[10/24] Train loss=0.4394885003566742
[15/24] Train loss=0.4367534816265106
[20/24] Train loss=0.34367403388023376
Test set avg_accuracy=86.08% avg_sensitivity=87.58%, avg_specificity=85.51% avg_auc=93.49%
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.388087 Test loss=0.346022 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3593437075614929
[5/24] Train loss=0.35794252157211304
[10/24] Train loss=0.4887377619743347
[15/24] Train loss=0.3960219919681549
[20/24] Train loss=0.3737471401691437
Test set avg_accuracy=85.85% avg_sensitivity=71.04%, avg_specificity=91.45% avg_auc=90.39%
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.393503 Test loss=0.364635 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3652738034725189
[5/24] Train loss=0.36042076349258423
[10/24] Train loss=0.44269418716430664
[15/24] Train loss=0.4351944923400879
[20/24] Train loss=0.34688928723335266
Test set avg_accuracy=86.02% avg_sensitivity=83.60%, avg_specificity=86.93% avg_auc=92.11%
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.381800 Test loss=0.354401 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3669217526912689
[5/24] Train loss=0.3140121102333069
[10/24] Train loss=0.41336506605148315
[15/24] Train loss=0.38107001781463623
[20/24] Train loss=0.3248418867588043
Test set avg_accuracy=86.05% avg_sensitivity=68.77%, avg_specificity=92.60% avg_auc=89.74%
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.369326 Test loss=0.375105 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3620947599411011
[5/24] Train loss=0.3475038707256317
[10/24] Train loss=0.3902990520000458
[15/24] Train loss=0.38766634464263916
[20/24] Train loss=0.35199838876724243
Test set avg_accuracy=86.26% avg_sensitivity=70.28%, avg_specificity=92.32% avg_auc=91.23%
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.372758 Test loss=0.350913 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.375179260969162
[5/24] Train loss=0.33035674691200256
[10/24] Train loss=0.4227929413318634
[15/24] Train loss=0.3979145884513855
[20/24] Train loss=0.3425532877445221
Test set avg_accuracy=86.00% avg_sensitivity=84.22%, avg_specificity=86.68% avg_auc=93.12%
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.372729 Test loss=0.338689 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.35825178027153015
[5/24] Train loss=0.3120153546333313
[10/24] Train loss=0.37357470393180847
[15/24] Train loss=0.4003162086009979
[20/24] Train loss=0.35457873344421387
Test set avg_accuracy=87.84% avg_sensitivity=77.06%, avg_specificity=91.92% avg_auc=92.63%
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.361747 Test loss=0.320083 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.34889698028564453
[5/24] Train loss=0.30559343099594116
[10/24] Train loss=0.4051312208175659
[15/24] Train loss=0.38456952571868896
[20/24] Train loss=0.35209575295448303
Test set avg_accuracy=85.76% avg_sensitivity=84.93%, avg_specificity=86.07% avg_auc=92.72%
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.360992 Test loss=0.349907 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.35666704177856445
[5/24] Train loss=0.29240840673446655
[10/24] Train loss=0.4015685021877289
[15/24] Train loss=0.39069104194641113
[20/24] Train loss=0.3254949450492859
Test set avg_accuracy=87.42% avg_sensitivity=69.53%, avg_specificity=94.20% avg_auc=91.51%
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.359508 Test loss=0.332062 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.34656596183776855
[5/24] Train loss=0.311151385307312
[10/24] Train loss=0.3894508183002472
[15/24] Train loss=0.3933204114437103
[20/24] Train loss=0.351047545671463
Test set avg_accuracy=85.96% avg_sensitivity=64.36%, avg_specificity=94.15% avg_auc=90.51%
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.355213 Test loss=0.358601 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.32471248507499695
[5/24] Train loss=0.3014462888240814
[10/24] Train loss=0.4046202003955841
[15/24] Train loss=0.378335565328598
[20/24] Train loss=0.3286620080471039
Test set avg_accuracy=86.85% avg_sensitivity=77.68%, avg_specificity=90.32% avg_auc=92.48%
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.350373 Test loss=0.323203 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.34842348098754883
[5/24] Train loss=0.2961154580116272
[10/24] Train loss=0.4160029888153076
[15/24] Train loss=0.35370954871177673
[20/24] Train loss=0.3484947979450226
Test set avg_accuracy=86.72% avg_sensitivity=77.96%, avg_specificity=90.04% avg_auc=92.58%
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.350293 Test loss=0.321419 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.31988170742988586
[5/24] Train loss=0.30570757389068604
[10/24] Train loss=0.3919518291950226
[15/24] Train loss=0.34315618872642517
[20/24] Train loss=0.3252657353878021
Test set avg_accuracy=87.32% avg_sensitivity=73.89%, avg_specificity=92.41% avg_auc=91.40%
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.345247 Test loss=0.329608 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3104502558708191
[5/24] Train loss=0.2713826596736908
[10/24] Train loss=0.3607271909713745
[15/24] Train loss=0.348330020904541
[20/24] Train loss=0.327291876077652
Test set avg_accuracy=86.90% avg_sensitivity=77.87%, avg_specificity=90.32% avg_auc=92.01%
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.347244 Test loss=0.328553 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3418727219104767
[5/24] Train loss=0.3317657709121704
[10/24] Train loss=0.3604724109172821
[15/24] Train loss=0.3324214220046997
[20/24] Train loss=0.3151756823062897
Test set avg_accuracy=84.99% avg_sensitivity=85.88%, avg_specificity=84.65% avg_auc=91.93%
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.342101 Test loss=0.379644 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3456961512565613
[5/24] Train loss=0.27978515625
[10/24] Train loss=0.4040163457393646
[15/24] Train loss=0.35297465324401855
[20/24] Train loss=0.3250386118888855
Test set avg_accuracy=86.50% avg_sensitivity=79.43%, avg_specificity=89.17% avg_auc=92.28%
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.350042 Test loss=0.332043 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.34252047538757324
[5/24] Train loss=0.3192417323589325
[10/24] Train loss=0.36541488766670227
[15/24] Train loss=0.37622740864753723
[20/24] Train loss=0.30354565382003784
Test set avg_accuracy=86.89% avg_sensitivity=73.55%, avg_specificity=91.94% avg_auc=91.54%
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.344365 Test loss=0.343261 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.33430519700050354
[5/24] Train loss=0.29385894536972046
[10/24] Train loss=0.34620121121406555
[15/24] Train loss=0.3551156520843506
[20/24] Train loss=0.3038770854473114
Test set avg_accuracy=85.27% avg_sensitivity=81.61%, avg_specificity=86.66% avg_auc=91.59%
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.334787 Test loss=0.370203 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.334480881690979
[5/24] Train loss=0.28414657711982727
[10/24] Train loss=0.40637537837028503
[15/24] Train loss=0.34116679430007935
[20/24] Train loss=0.2953449487686157
Test set avg_accuracy=85.09% avg_sensitivity=82.75%, avg_specificity=85.98% avg_auc=91.99%
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.332700 Test loss=0.370038 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.31976643204689026
[5/24] Train loss=0.3177754282951355
[10/24] Train loss=0.3564900755882263
[15/24] Train loss=0.3428479731082916
[20/24] Train loss=0.2979300022125244
Test set avg_accuracy=85.29% avg_sensitivity=83.89%, avg_specificity=85.82% avg_auc=92.04%
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.330969 Test loss=0.368886 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.33088433742523193
[5/24] Train loss=0.33742204308509827
[10/24] Train loss=0.37320807576179504
[15/24] Train loss=0.32837286591529846
[20/24] Train loss=0.2950480878353119
Test set avg_accuracy=85.96% avg_sensitivity=78.91%, avg_specificity=88.64% avg_auc=91.17%
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.325583 Test loss=0.361483 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30209052562713623
[5/24] Train loss=0.2589721083641052
[10/24] Train loss=0.36045312881469727
[15/24] Train loss=0.31628209352493286
[20/24] Train loss=0.280588835477829
Test set avg_accuracy=87.55% avg_sensitivity=79.00%, avg_specificity=90.79% avg_auc=92.29%
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.307714 Test loss=0.329231 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2880580425262451
[5/24] Train loss=0.2621479630470276
[10/24] Train loss=0.3134975731372833
[15/24] Train loss=0.3109080195426941
[20/24] Train loss=0.2843589782714844
Test set avg_accuracy=85.70% avg_sensitivity=85.73%, avg_specificity=85.69% avg_auc=92.85%
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.308252 Test loss=0.359865 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.29840001463890076
[5/24] Train loss=0.2798621654510498
[10/24] Train loss=0.3267482817173004
[15/24] Train loss=0.31470224261283875
[20/24] Train loss=0.2539409399032593
Test set avg_accuracy=84.61% avg_sensitivity=86.21%, avg_specificity=84.00% avg_auc=91.97%
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.304683 Test loss=0.386125 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.29537227749824524
[5/24] Train loss=0.2589452862739563
[10/24] Train loss=0.3088105618953705
[15/24] Train loss=0.2956477105617523
[20/24] Train loss=0.29645219445228577
Test set avg_accuracy=83.78% avg_sensitivity=91.99%, avg_specificity=80.66% avg_auc=92.87%
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.300458 Test loss=0.421443 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2962868809700012
[5/24] Train loss=0.2784777581691742
[10/24] Train loss=0.3124651610851288
[15/24] Train loss=0.32975852489471436
[20/24] Train loss=0.289846807718277
Test set avg_accuracy=85.81% avg_sensitivity=82.80%, avg_specificity=86.95% avg_auc=92.12%
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.303741 Test loss=0.363076 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2958873212337494
[5/24] Train loss=0.24374808371067047
[10/24] Train loss=0.29385581612586975
[15/24] Train loss=0.3184090554714203
[20/24] Train loss=0.27321887016296387
Test set avg_accuracy=86.82% avg_sensitivity=83.51%, avg_specificity=88.08% avg_auc=92.75%
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.285967 Test loss=0.346628 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.26748400926589966
[5/24] Train loss=0.2574012279510498
[10/24] Train loss=0.2958597242832184
[15/24] Train loss=0.30945104360580444
[20/24] Train loss=0.30693569779396057
Test set avg_accuracy=86.11% avg_sensitivity=78.63%, avg_specificity=88.94% avg_auc=92.44%
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.281318 Test loss=0.349879 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2758616805076599
[5/24] Train loss=0.24221107363700867
[10/24] Train loss=0.3173995614051819
[15/24] Train loss=0.31649941205978394
[20/24] Train loss=0.26637259125709534
Test set avg_accuracy=85.47% avg_sensitivity=84.27%, avg_specificity=85.92% avg_auc=92.21%
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.289058 Test loss=0.372510 Current lr=[0.000224838296036774]

[0/24] Train loss=0.27010759711265564
[5/24] Train loss=0.28480544686317444
[10/24] Train loss=0.3211272060871124
[15/24] Train loss=0.33417749404907227
[20/24] Train loss=0.26232996582984924
Test set avg_accuracy=88.06% avg_sensitivity=74.98%, avg_specificity=93.02% avg_auc=91.77%
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.298820 Test loss=0.324911 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.26879677176475525
[5/24] Train loss=0.2364095002412796
[10/24] Train loss=0.31408971548080444
[15/24] Train loss=0.2891961336135864
[20/24] Train loss=0.2713909149169922
Test set avg_accuracy=87.30% avg_sensitivity=77.49%, avg_specificity=91.02% avg_auc=91.98%
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.277855 Test loss=0.335058 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.26857224106788635
[5/24] Train loss=0.2584659457206726
[10/24] Train loss=0.30089184641838074
[15/24] Train loss=0.3116987943649292
[20/24] Train loss=0.25344565510749817
Test set avg_accuracy=84.57% avg_sensitivity=75.50%, avg_specificity=88.01% avg_auc=89.76%
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.280395 Test loss=0.399316 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.253952294588089
[5/24] Train loss=0.2636374235153198
[10/24] Train loss=0.3022169768810272
[15/24] Train loss=0.31670862436294556
[20/24] Train loss=0.27668076753616333
Test set avg_accuracy=84.30% avg_sensitivity=87.39%, avg_specificity=83.12% avg_auc=92.22%
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.286087 Test loss=0.418548 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2771959900856018
[5/24] Train loss=0.24402761459350586
[10/24] Train loss=0.2952938377857208
[15/24] Train loss=0.29778772592544556
[20/24] Train loss=0.260567843914032
Test set avg_accuracy=87.07% avg_sensitivity=69.00%, avg_specificity=93.91% avg_auc=90.46%
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.271907 Test loss=0.348629 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2494099885225296
[5/24] Train loss=0.24923987686634064
[10/24] Train loss=0.27694621682167053
[15/24] Train loss=0.2829485535621643
[20/24] Train loss=0.2639857232570648
Test set avg_accuracy=85.77% avg_sensitivity=75.55%, avg_specificity=89.64% avg_auc=89.48%
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.269271 Test loss=0.386285 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2570001482963562
[5/24] Train loss=0.2419559359550476
[10/24] Train loss=0.26875489950180054
[15/24] Train loss=0.29605355858802795
[20/24] Train loss=0.25573551654815674
Test set avg_accuracy=87.90% avg_sensitivity=80.24%, avg_specificity=90.81% avg_auc=92.17%
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.263626 Test loss=0.335872 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.25279033184051514
[5/24] Train loss=0.2394881397485733
[10/24] Train loss=0.28269970417022705
[15/24] Train loss=0.2920841872692108
[20/24] Train loss=0.24240094423294067
Test set avg_accuracy=88.09% avg_sensitivity=80.57%, avg_specificity=90.93% avg_auc=93.04%
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.264168 Test loss=0.313284 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.26011353731155396
[5/24] Train loss=0.23265674710273743
[10/24] Train loss=0.2629019021987915
[15/24] Train loss=0.28258344531059265
[20/24] Train loss=0.2553667426109314
Test set avg_accuracy=86.38% avg_sensitivity=66.26%, avg_specificity=94.00% avg_auc=88.74%
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.262777 Test loss=0.369124 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.24676522612571716
[5/24] Train loss=0.23013369739055634
[10/24] Train loss=0.26449063420295715
[15/24] Train loss=0.2778027355670929
[20/24] Train loss=0.2341492772102356
Test set avg_accuracy=87.55% avg_sensitivity=71.04%, avg_specificity=93.81% avg_auc=90.97%
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.252221 Test loss=0.334949 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.23015902936458588
[5/24] Train loss=0.22638528048992157
[10/24] Train loss=0.25776708126068115
[15/24] Train loss=0.26936349272727966
[20/24] Train loss=0.24304991960525513
Test set avg_accuracy=87.04% avg_sensitivity=67.82%, avg_specificity=94.33% avg_auc=90.50%
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.246295 Test loss=0.354508 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.22925813496112823
[5/24] Train loss=0.23159146308898926
[10/24] Train loss=0.2751932144165039
[15/24] Train loss=0.25764650106430054
[20/24] Train loss=0.2775323987007141
Test set avg_accuracy=87.97% avg_sensitivity=77.01%, avg_specificity=92.12% avg_auc=91.89%
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.247681 Test loss=0.326196 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2497701197862625
[5/24] Train loss=0.2208399623632431
[10/24] Train loss=0.24713832139968872
[15/24] Train loss=0.27413585782051086
[20/24] Train loss=0.22852621972560883
Test set avg_accuracy=88.42% avg_sensitivity=77.77%, avg_specificity=92.46% avg_auc=92.32%
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.244061 Test loss=0.315813 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2258085012435913
[5/24] Train loss=0.22351033985614777
[10/24] Train loss=0.24908317625522614
[15/24] Train loss=0.27441415190696716
[20/24] Train loss=0.23314009606838226
Test set avg_accuracy=87.15% avg_sensitivity=75.45%, avg_specificity=91.58% avg_auc=91.73%
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.241345 Test loss=0.344841 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.22765836119651794
[5/24] Train loss=0.21246996521949768
[10/24] Train loss=0.2618119418621063
[15/24] Train loss=0.26901811361312866
[20/24] Train loss=0.23783862590789795
Test set avg_accuracy=87.06% avg_sensitivity=76.97%, avg_specificity=90.88% avg_auc=91.58%
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.242733 Test loss=0.350716 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.23595686256885529
[5/24] Train loss=0.22483061254024506
[10/24] Train loss=0.25372639298439026
[15/24] Train loss=0.2720396816730499
[20/24] Train loss=0.23066850006580353
Test set avg_accuracy=87.21% avg_sensitivity=75.78%, avg_specificity=91.54% avg_auc=91.81%
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.241426 Test loss=0.342457 Current lr=[0.000156543481933168]

[0/24] Train loss=0.22933714091777802
[5/24] Train loss=0.2121044546365738
[10/24] Train loss=0.23631583154201508
[15/24] Train loss=0.2606929838657379
[20/24] Train loss=0.22737565636634827
Test set avg_accuracy=86.77% avg_sensitivity=79.10%, avg_specificity=89.68% avg_auc=92.00%
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.231512 Test loss=0.347711 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.23075111210346222
[5/24] Train loss=0.2098652720451355
[10/24] Train loss=0.22922314703464508
[15/24] Train loss=0.25108933448791504
[20/24] Train loss=0.22387492656707764
Test set avg_accuracy=87.21% avg_sensitivity=81.94%, avg_specificity=89.21% avg_auc=92.27%
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.228025 Test loss=0.345583 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2166813164949417
[5/24] Train loss=0.21798215806484222
[10/24] Train loss=0.23685045540332794
[15/24] Train loss=0.2535656988620758
[20/24] Train loss=0.2209061086177826
Test set avg_accuracy=86.46% avg_sensitivity=81.94%, avg_specificity=88.17% avg_auc=92.08%
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.231238 Test loss=0.363792 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.21412380039691925
[5/24] Train loss=0.19603633880615234
[10/24] Train loss=0.2302078753709793
[15/24] Train loss=0.23874448239803314
[20/24] Train loss=0.21903908252716064
Test set avg_accuracy=87.85% avg_sensitivity=76.02%, avg_specificity=92.33% avg_auc=92.05%
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.225367 Test loss=0.328878 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22048182785511017
[5/24] Train loss=0.19439123570919037
[10/24] Train loss=0.25057774782180786
[15/24] Train loss=0.24696113169193268
[20/24] Train loss=0.2292388677597046
Test set avg_accuracy=87.89% avg_sensitivity=77.01%, avg_specificity=92.01% avg_auc=92.39%
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.227414 Test loss=0.334318 Current lr=[0.000134135431043539]

[0/24] Train loss=0.22036384046077728
[5/24] Train loss=0.20062902569770813
[10/24] Train loss=0.2643798589706421
[15/24] Train loss=0.2581580877304077
[20/24] Train loss=0.22414562106132507
Test set avg_accuracy=88.11% avg_sensitivity=76.68%, avg_specificity=92.44% avg_auc=92.29%
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.225950 Test loss=0.324059 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2164229154586792
[5/24] Train loss=0.20505516231060028
[10/24] Train loss=0.226003959774971
[15/24] Train loss=0.23886650800704956
[20/24] Train loss=0.21504348516464233
Test set avg_accuracy=87.96% avg_sensitivity=82.94%, avg_specificity=89.86% avg_auc=93.18%
Best model saved!! Metric=27.92903317340557!!
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.221761 Test loss=0.331709 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.216415673494339
[5/24] Train loss=0.1921316683292389
[10/24] Train loss=0.21884183585643768
[15/24] Train loss=0.24333663284778595
[20/24] Train loss=0.2154635488986969
Test set avg_accuracy=87.23% avg_sensitivity=82.09%, avg_specificity=89.17% avg_auc=92.67%
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.217345 Test loss=0.349684 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.20426928997039795
[5/24] Train loss=0.18889854848384857
[10/24] Train loss=0.22461725771427155
[15/24] Train loss=0.23001478612422943
[20/24] Train loss=0.20288045704364777
Test set avg_accuracy=87.11% avg_sensitivity=84.41%, avg_specificity=88.13% avg_auc=93.27%
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.212185 Test loss=0.344963 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.1961287260055542
[5/24] Train loss=0.18982334434986115
[10/24] Train loss=0.21982920169830322
[15/24] Train loss=0.22147969901561737
[20/24] Train loss=0.20433008670806885
Test set avg_accuracy=87.03% avg_sensitivity=82.27%, avg_specificity=88.83% avg_auc=92.67%
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.205714 Test loss=0.347690 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.19788174331188202
[5/24] Train loss=0.192376047372818
[10/24] Train loss=0.21010121703147888
[15/24] Train loss=0.22363482415676117
[20/24] Train loss=0.19829466938972473
Test set avg_accuracy=86.20% avg_sensitivity=87.49%, avg_specificity=85.71% avg_auc=93.11%
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.202836 Test loss=0.375797 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.19398534297943115
[5/24] Train loss=0.19085679948329926
[10/24] Train loss=0.2100609987974167
[15/24] Train loss=0.21207714080810547
[20/24] Train loss=0.20052406191825867
Test set avg_accuracy=87.38% avg_sensitivity=82.99%, avg_specificity=89.05% avg_auc=93.06%
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.200554 Test loss=0.347247 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1944679170846939
[5/24] Train loss=0.17849408090114594
[10/24] Train loss=0.20792438089847565
[15/24] Train loss=0.22875650227069855
[20/24] Train loss=0.19600166380405426
Test set avg_accuracy=86.54% avg_sensitivity=85.88%, avg_specificity=86.79% avg_auc=93.07%
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.199576 Test loss=0.374971 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.19287580251693726
[5/24] Train loss=0.18663324415683746
[10/24] Train loss=0.2033178210258484
[15/24] Train loss=0.23140071332454681
[20/24] Train loss=0.19034405052661896
Test set avg_accuracy=87.94% avg_sensitivity=82.70%, avg_specificity=89.93% avg_auc=93.36%
Best model saved!! Metric=27.930523899118214!!
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.197427 Test loss=0.331813 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.19273895025253296
[5/24] Train loss=0.17706985771656036
[10/24] Train loss=0.20188526809215546
[15/24] Train loss=0.232573002576828
[20/24] Train loss=0.19805678725242615
Test set avg_accuracy=87.28% avg_sensitivity=83.36%, avg_specificity=88.76% avg_auc=93.08%
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.198257 Test loss=0.348229 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.19553275406360626
[5/24] Train loss=0.18060395121574402
[10/24] Train loss=0.20372524857521057
[15/24] Train loss=0.22385576367378235
[20/24] Train loss=0.1941186785697937
Test set avg_accuracy=86.48% avg_sensitivity=85.59%, avg_specificity=86.82% avg_auc=92.68%
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.197092 Test loss=0.375416 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1887093335390091
[5/24] Train loss=0.17676334083080292
[10/24] Train loss=0.20171529054641724
[15/24] Train loss=0.2131011188030243
[20/24] Train loss=0.19484247267246246
Test set avg_accuracy=88.62% avg_sensitivity=78.77%, avg_specificity=92.35% avg_auc=93.02%
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.193851 Test loss=0.311576 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1848522424697876
[5/24] Train loss=0.17538627982139587
[10/24] Train loss=0.1921810507774353
[15/24] Train loss=0.21560826897621155
[20/24] Train loss=0.1915138214826584
Test set avg_accuracy=87.34% avg_sensitivity=82.61%, avg_specificity=89.14% avg_auc=93.17%
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.190760 Test loss=0.339870 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1874130815267563
[5/24] Train loss=0.17266881465911865
[10/24] Train loss=0.20236919820308685
[15/24] Train loss=0.1994166225194931
[20/24] Train loss=0.1895030438899994
Test set avg_accuracy=87.37% avg_sensitivity=80.05%, avg_specificity=90.14% avg_auc=92.84%
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.189184 Test loss=0.341591 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.1789606511592865
[5/24] Train loss=0.17054963111877441
[10/24] Train loss=0.19559159874916077
[15/24] Train loss=0.20220638811588287
[20/24] Train loss=0.18456822633743286
Test set avg_accuracy=86.90% avg_sensitivity=81.33%, avg_specificity=89.01% avg_auc=92.71%
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.186972 Test loss=0.351631 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.17302002012729645
[5/24] Train loss=0.1710132360458374
[10/24] Train loss=0.19223617017269135
[15/24] Train loss=0.19498257339000702
[20/24] Train loss=0.18441569805145264
Test set avg_accuracy=87.57% avg_sensitivity=83.55%, avg_specificity=89.08% avg_auc=93.22%
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.183011 Test loss=0.340992 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.17837552726268768
[5/24] Train loss=0.16655468940734863
[10/24] Train loss=0.19012373685836792
[15/24] Train loss=0.1919233202934265
[20/24] Train loss=0.18238873779773712
Test set avg_accuracy=87.92% avg_sensitivity=78.25%, avg_specificity=91.58% avg_auc=92.63%
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.181881 Test loss=0.327754 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.17293377220630646
[5/24] Train loss=0.16623450815677643
[10/24] Train loss=0.18932348489761353
[15/24] Train loss=0.19808557629585266
[20/24] Train loss=0.18165691196918488
Test set avg_accuracy=87.77% avg_sensitivity=80.85%, avg_specificity=90.39% avg_auc=93.08%
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.181109 Test loss=0.335184 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.17382046580314636
[5/24] Train loss=0.16377632319927216
[10/24] Train loss=0.18984247744083405
[15/24] Train loss=0.19031471014022827
[20/24] Train loss=0.1798495650291443
Test set avg_accuracy=87.85% avg_sensitivity=80.28%, avg_specificity=90.72% avg_auc=92.96%
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.180220 Test loss=0.328253 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.1709633618593216
[5/24] Train loss=0.16133230924606323
[10/24] Train loss=0.18705613911151886
[15/24] Train loss=0.1991933286190033
[20/24] Train loss=0.1837346851825714
Test set avg_accuracy=86.76% avg_sensitivity=85.97%, avg_specificity=87.06% avg_auc=92.89%
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.180966 Test loss=0.377876 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.17428074777126312
[5/24] Train loss=0.16218438744544983
[10/24] Train loss=0.1902066022157669
[15/24] Train loss=0.19204926490783691
[20/24] Train loss=0.18463605642318726
Test set avg_accuracy=86.98% avg_sensitivity=82.70%, avg_specificity=88.60% avg_auc=93.19%
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.180311 Test loss=0.344092 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.17175337672233582
[5/24] Train loss=0.16268709301948547
[10/24] Train loss=0.18286213278770447
[15/24] Train loss=0.18690800666809082
[20/24] Train loss=0.17771419882774353
Test set avg_accuracy=86.71% avg_sensitivity=86.21%, avg_specificity=86.89% avg_auc=93.17%
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.177650 Test loss=0.367524 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.167534738779068
[5/24] Train loss=0.16045407950878143
[10/24] Train loss=0.1850491613149643
[15/24] Train loss=0.1904655247926712
[20/24] Train loss=0.18174093961715698
Test set avg_accuracy=87.83% avg_sensitivity=80.57%, avg_specificity=90.57% avg_auc=93.05%
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.175050 Test loss=0.332362 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.16433574259281158
[5/24] Train loss=0.1580139547586441
[10/24] Train loss=0.17765916883945465
[15/24] Train loss=0.18570856750011444
[20/24] Train loss=0.17491847276687622
Test set avg_accuracy=88.03% avg_sensitivity=81.23%, avg_specificity=90.61% avg_auc=93.00%
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.173508 Test loss=0.336015 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1676376760005951
[5/24] Train loss=0.15612930059432983
[10/24] Train loss=0.17575140297412872
[15/24] Train loss=0.18854498863220215
[20/24] Train loss=0.17986635863780975
Test set avg_accuracy=88.29% avg_sensitivity=79.48%, avg_specificity=91.63% avg_auc=93.07%
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.172958 Test loss=0.328777 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.16736607253551483
[5/24] Train loss=0.15052272379398346
[10/24] Train loss=0.1814012974500656
[15/24] Train loss=0.1820899099111557
[20/24] Train loss=0.16812194883823395
Test set avg_accuracy=88.32% avg_sensitivity=79.57%, avg_specificity=91.63% avg_auc=93.05%
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.169643 Test loss=0.328037 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1608356237411499
[5/24] Train loss=0.1582002341747284
[10/24] Train loss=0.17331454157829285
[15/24] Train loss=0.17919571697711945
[20/24] Train loss=0.1741827130317688
Test set avg_accuracy=88.27% avg_sensitivity=79.53%, avg_specificity=91.58% avg_auc=93.00%
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.169892 Test loss=0.327431 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.15992890298366547
[5/24] Train loss=0.1529475450515747
[10/24] Train loss=0.17211681604385376
[15/24] Train loss=0.1833488941192627
[20/24] Train loss=0.16973821818828583
Test set avg_accuracy=88.07% avg_sensitivity=81.04%, avg_specificity=90.74% avg_auc=93.10%
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.168031 Test loss=0.329826 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.16451111435890198
[5/24] Train loss=0.15282271802425385
[10/24] Train loss=0.1743718385696411
[15/24] Train loss=0.17807719111442566
[20/24] Train loss=0.1685146689414978
Test set avg_accuracy=88.33% avg_sensitivity=81.56%, avg_specificity=90.90% avg_auc=93.19%
Best model saved!! Metric=27.985877004149415!!
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.168166 Test loss=0.328955 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1579948365688324
[5/24] Train loss=0.1491689831018448
[10/24] Train loss=0.17636875808238983
[15/24] Train loss=0.1823386549949646
[20/24] Train loss=0.16924554109573364
Test set avg_accuracy=87.81% avg_sensitivity=83.60%, avg_specificity=89.41% avg_auc=93.32%
Best model saved!! Metric=28.14450881499569!!
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.166071 Test loss=0.337507 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1608443409204483
[5/24] Train loss=0.15307317674160004
[10/24] Train loss=0.17490863800048828
[15/24] Train loss=0.18318110704421997
[20/24] Train loss=0.17304714024066925
Test set avg_accuracy=88.20% avg_sensitivity=81.42%, avg_specificity=90.77% avg_auc=93.07%
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.167099 Test loss=0.334497 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.15869969129562378
[5/24] Train loss=0.1503991186618805
[10/24] Train loss=0.17606884241104126
[15/24] Train loss=0.17501428723335266
[20/24] Train loss=0.17811636626720428
Test set avg_accuracy=88.07% avg_sensitivity=82.09%, avg_specificity=90.34% avg_auc=93.22%
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.166472 Test loss=0.335394 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.15942685306072235
[5/24] Train loss=0.14813312888145447
[10/24] Train loss=0.17491264641284943
[15/24] Train loss=0.17478246986865997
[20/24] Train loss=0.16616113483905792
Test set avg_accuracy=87.77% avg_sensitivity=82.61%, avg_specificity=89.73% avg_auc=93.21%
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.165875 Test loss=0.337496 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.1632334291934967
[5/24] Train loss=0.1503138393163681
[10/24] Train loss=0.1715855598449707
[15/24] Train loss=0.17106091976165771
[20/24] Train loss=0.16480495035648346
Test set avg_accuracy=88.24% avg_sensitivity=81.75%, avg_specificity=90.70% avg_auc=93.21%
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.164569 Test loss=0.329405 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.15728971362113953
[5/24] Train loss=0.15100747346878052
[10/24] Train loss=0.16996294260025024
[15/24] Train loss=0.17177541553974152
[20/24] Train loss=0.16640889644622803
Test set avg_accuracy=88.37% avg_sensitivity=81.14%, avg_specificity=91.11% avg_auc=93.19%
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.162708 Test loss=0.326994 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1578742265701294
[5/24] Train loss=0.14879047870635986
[10/24] Train loss=0.16963498294353485
[15/24] Train loss=0.1745140701532364
[20/24] Train loss=0.16530312597751617
Test set avg_accuracy=88.02% avg_sensitivity=81.42%, avg_specificity=90.52% avg_auc=93.24%
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.162021 Test loss=0.331328 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.15687596797943115
[5/24] Train loss=0.14883652329444885
[10/24] Train loss=0.17160196602344513
[15/24] Train loss=0.17084664106369019
[20/24] Train loss=0.1682787388563156
Test set avg_accuracy=88.28% avg_sensitivity=81.00%, avg_specificity=91.04% avg_auc=93.19%
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.162080 Test loss=0.329731 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.15772973001003265
[5/24] Train loss=0.14727185666561127
[10/24] Train loss=0.1692078411579132
[15/24] Train loss=0.17372208833694458
[20/24] Train loss=0.16308508813381195
Test set avg_accuracy=88.22% avg_sensitivity=81.85%, avg_specificity=90.63% avg_auc=93.32%
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.161598 Test loss=0.332558 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.15742143988609314
[5/24] Train loss=0.14657382667064667
[10/24] Train loss=0.16753487288951874
[15/24] Train loss=0.17049776017665863
[20/24] Train loss=0.16575691103935242
Test set avg_accuracy=88.29% avg_sensitivity=81.47%, avg_specificity=90.88% avg_auc=93.27%
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.161275 Test loss=0.330117 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1541956067085266
[5/24] Train loss=0.142645463347435
[10/24] Train loss=0.17165113985538483
[15/24] Train loss=0.17049165070056915
[20/24] Train loss=0.16256298124790192
Test set avg_accuracy=88.14% avg_sensitivity=81.28%, avg_specificity=90.74% avg_auc=93.30%
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.160371 Test loss=0.330619 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1552560180425644
[5/24] Train loss=0.14947590231895447
[10/24] Train loss=0.164620041847229
[15/24] Train loss=0.17076422274112701
[20/24] Train loss=0.16311821341514587
Test set avg_accuracy=88.15% avg_sensitivity=81.37%, avg_specificity=90.72% avg_auc=93.31%
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.160480 Test loss=0.330027 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1544097363948822
[5/24] Train loss=0.14732180535793304
[10/24] Train loss=0.16653060913085938
[15/24] Train loss=0.16929496824741364
[20/24] Train loss=0.16198940575122833
Test set avg_accuracy=88.10% avg_sensitivity=81.52%, avg_specificity=90.59% avg_auc=93.30%
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.160456 Test loss=0.331446 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.15390819311141968
[5/24] Train loss=0.14734160900115967
[10/24] Train loss=0.16941773891448975
[15/24] Train loss=0.17359717190265656
[20/24] Train loss=0.1630989909172058
Test set avg_accuracy=88.20% avg_sensitivity=81.56%, avg_specificity=90.72% avg_auc=93.29%
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.160813 Test loss=0.330903 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.15591296553611755
[5/24] Train loss=0.14639730751514435
[10/24] Train loss=0.165118008852005
[15/24] Train loss=0.16762036085128784
[20/24] Train loss=0.1633278727531433
Test set avg_accuracy=88.29% avg_sensitivity=81.66%, avg_specificity=90.81% avg_auc=93.31%
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.160137 Test loss=0.330539 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1586417853832245
[5/24] Train loss=0.14678101241588593
[10/24] Train loss=0.1693069189786911
[15/24] Train loss=0.17302003502845764
[20/24] Train loss=0.162298783659935
Test set avg_accuracy=88.22% avg_sensitivity=81.47%, avg_specificity=90.77% avg_auc=93.32%
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.160332 Test loss=0.330499 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1533563882112503
[5/24] Train loss=0.14392124116420746
[10/24] Train loss=0.16530530154705048
[15/24] Train loss=0.1671680063009262
[20/24] Train loss=0.1612573117017746
Test set avg_accuracy=88.19% avg_sensitivity=81.28%, avg_specificity=90.81% avg_auc=93.31%
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.159461 Test loss=0.330827 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.15514981746673584
[5/24] Train loss=0.14452597498893738
[10/24] Train loss=0.1675577461719513
[15/24] Train loss=0.17095932364463806
[20/24] Train loss=0.1639472246170044
Test set avg_accuracy=88.24% avg_sensitivity=81.47%, avg_specificity=90.81% avg_auc=93.31%
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.159831 Test loss=0.331017 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.15414921939373016
[5/24] Train loss=0.1454651802778244
[10/24] Train loss=0.16534653306007385
[15/24] Train loss=0.17182497680187225
[20/24] Train loss=0.1646045744419098
Test set avg_accuracy=88.23% avg_sensitivity=81.42%, avg_specificity=90.81% avg_auc=93.31%
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.159498 Test loss=0.330781 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1548723578453064
[5/24] Train loss=0.14681068062782288
[10/24] Train loss=0.16745860874652863
[15/24] Train loss=0.16812506318092346
[20/24] Train loss=0.166774183511734
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.24% avg_sensitivity=81.56%, avg_specificity=90.77% avg_auc=93.30%
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.159558 Test loss=0.331168 Current lr=[1.3165623068326024e-09]

Fold[3] Result: acc=87.81% sen=83.60%, spe=89.41%, auc=93.32%!
Fold[3] Avg_overlap=0.68%(0.2284981959036769)
[0/24] Train loss=1.4640986919403076
[5/24] Train loss=1.4560796022415161
[10/24] Train loss=1.4538633823394775
[15/24] Train loss=1.429088830947876
[20/24] Train loss=1.3854973316192627
Test set avg_accuracy=58.19% avg_sensitivity=57.82%, avg_specificity=58.32% avg_auc=61.14%
Best model saved!! Metric=-90.52715139819045!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=1.440253 Test loss=0.684434 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3912228345870972
[5/24] Train loss=1.393643856048584
[10/24] Train loss=1.3831133842468262
[15/24] Train loss=1.3500511646270752
[20/24] Train loss=1.3308254480361938
Test set avg_accuracy=63.39% avg_sensitivity=74.96%, avg_specificity=59.31% avg_auc=73.27%
Best model saved!! Metric=-55.079008806808964!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=1.368908 Test loss=0.632385 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3110685348510742
[5/24] Train loss=1.3225350379943848
[10/24] Train loss=1.3271535634994507
[15/24] Train loss=1.2836711406707764
[20/24] Train loss=1.2688883543014526
Test set avg_accuracy=67.81% avg_sensitivity=81.46%, avg_specificity=63.00% avg_auc=78.98%
Best model saved!! Metric=-34.74692234904734!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=1.301442 Test loss=0.597984 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2406678199768066
[5/24] Train loss=1.2602648735046387
[10/24] Train loss=1.2861601114273071
[15/24] Train loss=1.210012674331665
[20/24] Train loss=1.1877855062484741
Test set avg_accuracy=69.70% avg_sensitivity=84.41%, avg_specificity=64.52% avg_auc=81.89%
Best model saved!! Metric=-25.48451598440853!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=1.234978 Test loss=0.575527 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.178133487701416
[5/24] Train loss=1.185657024383545
[10/24] Train loss=1.2214953899383545
[15/24] Train loss=1.1520267724990845
[20/24] Train loss=1.1155297756195068
Test set avg_accuracy=71.28% avg_sensitivity=85.96%, avg_specificity=66.10% avg_auc=83.90%
Best model saved!! Metric=-18.760539268081672!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=1.164164 Test loss=0.557341 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.093494176864624
[5/24] Train loss=1.1107325553894043
[10/24] Train loss=1.1724363565444946
[15/24] Train loss=1.0986101627349854
[20/24] Train loss=1.055202841758728
Test set avg_accuracy=72.25% avg_sensitivity=87.71%, avg_specificity=66.81% avg_auc=85.74%
Best model saved!! Metric=-13.493777264910193!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=1.102682 Test loss=0.543453 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0285778045654297
[5/24] Train loss=1.0540692806243896
[10/24] Train loss=1.1247507333755493
[15/24] Train loss=1.0432417392730713
[20/24] Train loss=0.9882569909095764
Test set avg_accuracy=74.99% avg_sensitivity=87.36%, avg_specificity=70.63% avg_auc=87.18%
Best model saved!! Metric=-5.84789869287161!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=1.042620 Test loss=0.514912 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9738209247589111
[5/24] Train loss=0.9770315289497375
[10/24] Train loss=1.052324652671814
[15/24] Train loss=0.9721793532371521
[20/24] Train loss=0.9475933313369751
Test set avg_accuracy=77.27% avg_sensitivity=86.91%, avg_specificity=73.87% avg_auc=88.42%
Best model saved!! Metric=0.45753723194528106!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.983586 Test loss=0.491938 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9150801301002502
[5/24] Train loss=0.9258979558944702
[10/24] Train loss=1.0127493143081665
[15/24] Train loss=0.9104737043380737
[20/24] Train loss=0.8935070633888245
Test set avg_accuracy=79.62% avg_sensitivity=86.11%, avg_specificity=77.34% avg_auc=89.40%
Best model saved!! Metric=6.465757565040107!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.931836 Test loss=0.466729 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8551409840583801
[5/24] Train loss=0.8588749170303345
[10/24] Train loss=0.955167293548584
[15/24] Train loss=0.8744473457336426
[20/24] Train loss=0.8373280763626099
Test set avg_accuracy=81.11% avg_sensitivity=85.51%, avg_specificity=79.56% avg_auc=90.15%
Best model saved!! Metric=10.321134069042472!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.882163 Test loss=0.447079 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8278118371963501
[5/24] Train loss=0.8199100494384766
[10/24] Train loss=0.8900864720344543
[15/24] Train loss=0.8355045318603516
[20/24] Train loss=0.8003220558166504
Test set avg_accuracy=82.54% avg_sensitivity=83.76%, avg_specificity=82.11% avg_auc=90.66%
Best model saved!! Metric=13.062486824111943!!
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.841085 Test loss=0.417282 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7783501148223877
[5/24] Train loss=0.7772269248962402
[10/24] Train loss=0.8588138818740845
[15/24] Train loss=0.8047619462013245
[20/24] Train loss=0.7591409683227539
Test set avg_accuracy=83.46% avg_sensitivity=84.01%, avg_specificity=83.27% avg_auc=91.18%
Best model saved!! Metric=15.923794723797187!!
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.805275 Test loss=0.402482 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7619922757148743
[5/24] Train loss=0.7369828820228577
[10/24] Train loss=0.8440173268318176
[15/24] Train loss=0.7675473690032959
[20/24] Train loss=0.739015519618988
Test set avg_accuracy=84.67% avg_sensitivity=82.91%, avg_specificity=85.30% avg_auc=91.55%
Best model saved!! Metric=18.426730176220886!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.774702 Test loss=0.378315 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.728146493434906
[5/24] Train loss=0.7079801559448242
[10/24] Train loss=0.8092799186706543
[15/24] Train loss=0.737873375415802
[20/24] Train loss=0.700422465801239
Test set avg_accuracy=85.34% avg_sensitivity=81.91%, avg_specificity=86.55% avg_auc=91.79%
Best model saved!! Metric=19.58920960616058!!
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.745466 Test loss=0.363275 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7009503841400146
[5/24] Train loss=0.6724634170532227
[10/24] Train loss=0.7884688377380371
[15/24] Train loss=0.7150961756706238
[20/24] Train loss=0.6836896538734436
Test set avg_accuracy=85.53% avg_sensitivity=82.41%, avg_specificity=86.63% avg_auc=92.14%
Best model saved!! Metric=20.71945259830136!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.722149 Test loss=0.355225 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6728993058204651
[5/24] Train loss=0.6552831530570984
[10/24] Train loss=0.7588651180267334
[15/24] Train loss=0.692325234413147
[20/24] Train loss=0.6526494026184082
Test set avg_accuracy=85.30% avg_sensitivity=84.36%, avg_specificity=85.63% avg_auc=92.53%
Best model saved!! Metric=21.82208298185715!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.698006 Test loss=0.359837 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6537900567054749
[5/24] Train loss=0.6499922871589661
[10/24] Train loss=0.7378199696540833
[15/24] Train loss=0.6870201826095581
[20/24] Train loss=0.6400790214538574
Test set avg_accuracy=85.23% avg_sensitivity=85.81%, avg_specificity=85.03% avg_auc=92.72%
Best model saved!! Metric=22.798930105789225!!
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.681252 Test loss=0.358018 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.626578152179718
[5/24] Train loss=0.6304783225059509
[10/24] Train loss=0.7322039008140564
[15/24] Train loss=0.687247097492218
[20/24] Train loss=0.6039106249809265
Test set avg_accuracy=85.31% avg_sensitivity=86.41%, avg_specificity=84.93% avg_auc=92.96%
Best model saved!! Metric=23.609335558272974!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.663884 Test loss=0.354058 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6205831170082092
[5/24] Train loss=0.6126455068588257
[10/24] Train loss=0.6899405717849731
[15/24] Train loss=0.6637014150619507
[20/24] Train loss=0.6109248995780945
Test set avg_accuracy=85.40% avg_sensitivity=86.81%, avg_specificity=84.91% avg_auc=93.08%
Best model saved!! Metric=24.19712512819902!!
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.650371 Test loss=0.351820 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.5946573615074158
[5/24] Train loss=0.6092988848686218
[10/24] Train loss=0.6828012466430664
[15/24] Train loss=0.6518433094024658
[20/24] Train loss=0.5841238498687744
Test set avg_accuracy=84.86% avg_sensitivity=88.01%, avg_specificity=83.75% avg_auc=93.10%
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.632979 Test loss=0.361777 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.599708080291748
[5/24] Train loss=0.5895158052444458
[10/24] Train loss=0.6847267150878906
[15/24] Train loss=0.6306073665618896
[20/24] Train loss=0.564462423324585
Test set avg_accuracy=83.66% avg_sensitivity=89.86%, avg_specificity=81.48% avg_auc=93.22%
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.621812 Test loss=0.382102 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5721952319145203
[5/24] Train loss=0.5682288408279419
[10/24] Train loss=0.6589546799659729
[15/24] Train loss=0.6057542562484741
[20/24] Train loss=0.5545932054519653
Test set avg_accuracy=85.48% avg_sensitivity=88.76%, avg_specificity=84.33% avg_auc=93.51%
Best model saved!! Metric=26.07716656740854!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.601920 Test loss=0.349673 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5705875754356384
[5/24] Train loss=0.5547159314155579
[10/24] Train loss=0.65912926197052
[15/24] Train loss=0.6014077663421631
[20/24] Train loss=0.5493108630180359
Test set avg_accuracy=83.89% avg_sensitivity=90.30%, avg_specificity=81.63% avg_auc=93.51%
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.593017 Test loss=0.377914 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5606696009635925
[5/24] Train loss=0.521189272403717
[10/24] Train loss=0.6274278163909912
[15/24] Train loss=0.5948441624641418
[20/24] Train loss=0.545754611492157
Test set avg_accuracy=86.29% avg_sensitivity=87.91%, avg_specificity=85.72% avg_auc=93.55%
Best model saved!! Metric=27.46220246637884!!
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.577909 Test loss=0.334466 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5562008619308472
[5/24] Train loss=0.5144585371017456
[10/24] Train loss=0.6343769431114197
[15/24] Train loss=0.5783621668815613
[20/24] Train loss=0.5213861465454102
Test set avg_accuracy=83.74% avg_sensitivity=89.66%, avg_specificity=81.65% avg_auc=93.15%
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.564143 Test loss=0.388101 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5436944961547852
[5/24] Train loss=0.5051212310791016
[10/24] Train loss=0.6070349812507629
[15/24] Train loss=0.5730469226837158
[20/24] Train loss=0.5071797370910645
Test set avg_accuracy=84.91% avg_sensitivity=90.45%, avg_specificity=82.95% avg_auc=93.46%
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.555636 Test loss=0.361051 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5287134647369385
[5/24] Train loss=0.48305174708366394
[10/24] Train loss=0.6197686791419983
[15/24] Train loss=0.5566043853759766
[20/24] Train loss=0.5081417560577393
Test set avg_accuracy=86.17% avg_sensitivity=87.16%, avg_specificity=85.82% avg_auc=93.37%
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.540154 Test loss=0.340222 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5307093858718872
[5/24] Train loss=0.5076367259025574
[10/24] Train loss=0.5994693040847778
[15/24] Train loss=0.5621266961097717
[20/24] Train loss=0.48588576912879944
Test set avg_accuracy=86.69% avg_sensitivity=87.01%, avg_specificity=86.58% avg_auc=93.48%
Best model saved!! Metric=27.76040709532758!!
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.534982 Test loss=0.327852 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5021539926528931
[5/24] Train loss=0.47421857714653015
[10/24] Train loss=0.6152518391609192
[15/24] Train loss=0.5410188436508179
[20/24] Train loss=0.4829809367656708
Test set avg_accuracy=86.76% avg_sensitivity=82.11%, avg_specificity=88.40% avg_auc=92.62%
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.519918 Test loss=0.326897 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.4966742992401123
[5/24] Train loss=0.4463779032230377
[10/24] Train loss=0.5903627872467041
[15/24] Train loss=0.5225003361701965
[20/24] Train loss=0.47855451703071594
Test set avg_accuracy=87.80% avg_sensitivity=80.61%, avg_specificity=90.33% avg_auc=93.22%
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.512553 Test loss=0.300956 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.4713490307331085
[5/24] Train loss=0.4590821862220764
[10/24] Train loss=0.5923157930374146
[15/24] Train loss=0.5165440440177917
[20/24] Train loss=0.4744924008846283
Test set avg_accuracy=82.11% avg_sensitivity=91.05%, avg_specificity=78.96% avg_auc=93.05%
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.508147 Test loss=0.407823 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5015679597854614
[5/24] Train loss=0.4590732157230377
[10/24] Train loss=0.5587283372879028
[15/24] Train loss=0.5049711465835571
[20/24] Train loss=0.48205164074897766
Test set avg_accuracy=86.85% avg_sensitivity=82.86%, avg_specificity=88.25% avg_auc=92.52%
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.498349 Test loss=0.328690 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.48760291934013367
[5/24] Train loss=0.4443263113498688
[10/24] Train loss=0.5402258634567261
[15/24] Train loss=0.4940855801105499
[20/24] Train loss=0.44082897901535034
Test set avg_accuracy=87.21% avg_sensitivity=81.96%, avg_specificity=89.06% avg_auc=92.49%
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.483516 Test loss=0.321084 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4728909432888031
[5/24] Train loss=0.4449811577796936
[10/24] Train loss=0.5279170274734497
[15/24] Train loss=0.4827960729598999
[20/24] Train loss=0.4480333626270294
Test set avg_accuracy=87.07% avg_sensitivity=86.31%, avg_specificity=87.34% avg_auc=93.28%
Best model saved!! Metric=27.999235782679833!!
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.485411 Test loss=0.329108 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.44267573952674866
[5/24] Train loss=0.42331621050834656
[10/24] Train loss=0.5216229557991028
[15/24] Train loss=0.48636114597320557
[20/24] Train loss=0.42881831526756287
Test set avg_accuracy=76.63% avg_sensitivity=93.70%, avg_specificity=70.61% avg_auc=92.30%
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.468644 Test loss=0.535374 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4537995755672455
[5/24] Train loss=0.39610159397125244
[10/24] Train loss=0.4901488423347473
[15/24] Train loss=0.48585665225982666
[20/24] Train loss=0.41059935092926025
Test set avg_accuracy=84.83% avg_sensitivity=88.21%, avg_specificity=83.64% avg_auc=93.10%
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.453418 Test loss=0.366964 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.43808019161224365
[5/24] Train loss=0.3727702796459198
[10/24] Train loss=0.5046545267105103
[15/24] Train loss=0.5019298195838928
[20/24] Train loss=0.45013487339019775
Test set avg_accuracy=83.53% avg_sensitivity=87.16%, avg_specificity=82.25% avg_auc=92.68%
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.453455 Test loss=0.384980 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.43913933634757996
[5/24] Train loss=0.40780702233314514
[10/24] Train loss=0.49134302139282227
[15/24] Train loss=0.48210960626602173
[20/24] Train loss=0.41883140802383423
Test set avg_accuracy=84.84% avg_sensitivity=79.91%, avg_specificity=86.58% avg_auc=91.58%
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.448996 Test loss=0.352359 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.42975351214408875
[5/24] Train loss=0.378542423248291
[10/24] Train loss=0.4765453040599823
[15/24] Train loss=0.4585311710834503
[20/24] Train loss=0.4493459165096283
Test set avg_accuracy=87.02% avg_sensitivity=82.36%, avg_specificity=88.66% avg_auc=92.92%
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.442913 Test loss=0.313556 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4639872610569
[5/24] Train loss=0.39901456236839294
[10/24] Train loss=0.495802640914917
[15/24] Train loss=0.45346885919570923
[20/24] Train loss=0.4015387296676636
Test set avg_accuracy=87.58% avg_sensitivity=73.96%, avg_specificity=92.38% avg_auc=91.44%
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.438566 Test loss=0.313885 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4379774034023285
[5/24] Train loss=0.42242515087127686
[10/24] Train loss=0.49141401052474976
[15/24] Train loss=0.5062479376792908
[20/24] Train loss=0.42712709307670593
Test set avg_accuracy=86.97% avg_sensitivity=75.86%, avg_specificity=90.88% avg_auc=91.87%
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.450084 Test loss=0.328301 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.41569197177886963
[5/24] Train loss=0.38916340470314026
[10/24] Train loss=0.47046932578086853
[15/24] Train loss=0.4632510840892792
[20/24] Train loss=0.40790748596191406
Test set avg_accuracy=84.74% avg_sensitivity=85.91%, avg_specificity=84.33% avg_auc=92.49%
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.430319 Test loss=0.355873 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4333125650882721
[5/24] Train loss=0.3655243217945099
[10/24] Train loss=0.4642130732536316
[15/24] Train loss=0.4297914206981659
[20/24] Train loss=0.375808984041214
Test set avg_accuracy=86.59% avg_sensitivity=80.11%, avg_specificity=88.87% avg_auc=92.41%
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.424733 Test loss=0.328556 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4161192774772644
[5/24] Train loss=0.35510262846946716
[10/24] Train loss=0.43124210834503174
[15/24] Train loss=0.44316795468330383
[20/24] Train loss=0.4155375063419342
Test set avg_accuracy=86.38% avg_sensitivity=82.51%, avg_specificity=87.74% avg_auc=92.70%
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.420653 Test loss=0.319229 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4101160168647766
[5/24] Train loss=0.3663371503353119
[10/24] Train loss=0.4440459907054901
[15/24] Train loss=0.4252356290817261
[20/24] Train loss=0.4115429222583771
Test set avg_accuracy=85.00% avg_sensitivity=86.21%, avg_specificity=84.57% avg_auc=92.92%
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.413876 Test loss=0.355607 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3920668065547943
[5/24] Train loss=0.3737346827983856
[10/24] Train loss=0.4365450143814087
[15/24] Train loss=0.4437961280345917
[20/24] Train loss=0.4022704064846039
Test set avg_accuracy=86.82% avg_sensitivity=72.31%, avg_specificity=91.94% avg_auc=90.90%
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.413776 Test loss=0.328934 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4140217900276184
[5/24] Train loss=0.39228561520576477
[10/24] Train loss=0.4587874710559845
[15/24] Train loss=0.41658398509025574
[20/24] Train loss=0.36256423592567444
Test set avg_accuracy=86.30% avg_sensitivity=71.41%, avg_specificity=91.55% avg_auc=90.71%
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.402531 Test loss=0.333130 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4128637909889221
[5/24] Train loss=0.3326073884963989
[10/24] Train loss=0.4299708604812622
[15/24] Train loss=0.41041988134384155
[20/24] Train loss=0.37617555260658264
Test set avg_accuracy=85.51% avg_sensitivity=85.31%, avg_specificity=85.58% avg_auc=92.79%
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.392903 Test loss=0.350077 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3926239609718323
[5/24] Train loss=0.33438971638679504
[10/24] Train loss=0.3906235694885254
[15/24] Train loss=0.4002324342727661
[20/24] Train loss=0.376509428024292
Test set avg_accuracy=83.68% avg_sensitivity=85.66%, avg_specificity=82.99% avg_auc=92.08%
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.384146 Test loss=0.371783 Current lr=[0.000298904600941902]

[0/24] Train loss=0.37526795268058777
[5/24] Train loss=0.32125741243362427
[10/24] Train loss=0.40156495571136475
[15/24] Train loss=0.4049474596977234
[20/24] Train loss=0.38695451617240906
Test set avg_accuracy=83.40% avg_sensitivity=89.16%, avg_specificity=81.37% avg_auc=92.77%
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.376271 Test loss=0.388314 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3767402768135071
[5/24] Train loss=0.33782827854156494
[10/24] Train loss=0.38975027203559875
[15/24] Train loss=0.4120967388153076
[20/24] Train loss=0.34643104672431946
Test set avg_accuracy=84.82% avg_sensitivity=84.26%, avg_specificity=85.01% avg_auc=92.26%
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.382127 Test loss=0.362744 Current lr=[0.000297555943323901]

[0/24] Train loss=0.38018372654914856
[5/24] Train loss=0.311396986246109
[10/24] Train loss=0.36866798996925354
[15/24] Train loss=0.3887439966201782
[20/24] Train loss=0.36605510115623474
Test set avg_accuracy=86.43% avg_sensitivity=70.91%, avg_specificity=91.90% avg_auc=89.82%
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.368320 Test loss=0.342348 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3790425956249237
[5/24] Train loss=0.3098680078983307
[10/24] Train loss=0.39799264073371887
[15/24] Train loss=0.3728598356246948
[20/24] Train loss=0.3372868597507477
Test set avg_accuracy=85.35% avg_sensitivity=69.32%, avg_specificity=91.00% avg_auc=88.84%
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.365734 Test loss=0.365356 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3700621426105499
[5/24] Train loss=0.3481188416481018
[10/24] Train loss=0.3893672823905945
[15/24] Train loss=0.40560805797576904
[20/24] Train loss=0.3767622709274292
Test set avg_accuracy=85.94% avg_sensitivity=74.16%, avg_specificity=90.09% avg_auc=89.64%
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.384892 Test loss=0.360179 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.35129690170288086
[5/24] Train loss=0.3010142743587494
[10/24] Train loss=0.3884508013725281
[15/24] Train loss=0.3799557387828827
[20/24] Train loss=0.3487985134124756
Test set avg_accuracy=87.63% avg_sensitivity=72.51%, avg_specificity=92.96% avg_auc=91.62%
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.363645 Test loss=0.307359 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.38142499327659607
[5/24] Train loss=0.3200039565563202
[10/24] Train loss=0.39143624901771545
[15/24] Train loss=0.3614465296268463
[20/24] Train loss=0.3499707579612732
Test set avg_accuracy=86.16% avg_sensitivity=81.91%, avg_specificity=87.66% avg_auc=92.24%
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.357815 Test loss=0.334908 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3564830422401428
[5/24] Train loss=0.30604666471481323
[10/24] Train loss=0.35367992520332336
[15/24] Train loss=0.334674596786499
[20/24] Train loss=0.33610522747039795
Test set avg_accuracy=86.50% avg_sensitivity=75.56%, avg_specificity=90.35% avg_auc=91.41%
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.354625 Test loss=0.330956 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.33823394775390625
[5/24] Train loss=0.32047387957572937
[10/24] Train loss=0.43165892362594604
[15/24] Train loss=0.38919010758399963
[20/24] Train loss=0.3529576063156128
Test set avg_accuracy=85.64% avg_sensitivity=76.36%, avg_specificity=88.91% avg_auc=90.61%
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.366514 Test loss=0.353589 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.36766064167022705
[5/24] Train loss=0.34017595648765564
[10/24] Train loss=0.3942823112010956
[15/24] Train loss=0.3703814148902893
[20/24] Train loss=0.3602575361728668
Test set avg_accuracy=86.25% avg_sensitivity=77.71%, avg_specificity=89.26% avg_auc=90.84%
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.361774 Test loss=0.359996 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.34779852628707886
[5/24] Train loss=0.3201407790184021
[10/24] Train loss=0.3719187378883362
[15/24] Train loss=0.3452593684196472
[20/24] Train loss=0.3510776162147522
Test set avg_accuracy=76.90% avg_sensitivity=91.15%, avg_specificity=71.88% avg_auc=90.82%
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.360130 Test loss=0.518562 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.34809303283691406
[5/24] Train loss=0.3369520902633667
[10/24] Train loss=0.37792134284973145
[15/24] Train loss=0.37555304169654846
[20/24] Train loss=0.3350975811481476
Test set avg_accuracy=86.45% avg_sensitivity=85.16%, avg_specificity=86.90% avg_auc=93.04%
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.349791 Test loss=0.340902 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3497772812843323
[5/24] Train loss=0.29481735825538635
[10/24] Train loss=0.35989126563072205
[15/24] Train loss=0.3258233666419983
[20/24] Train loss=0.32470810413360596
Test set avg_accuracy=86.63% avg_sensitivity=78.96%, avg_specificity=89.33% avg_auc=92.27%
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.345806 Test loss=0.325331 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3399665951728821
[5/24] Train loss=0.3043762445449829
[10/24] Train loss=0.3681008517742157
[15/24] Train loss=0.37277355790138245
[20/24] Train loss=0.3177553117275238
Test set avg_accuracy=87.71% avg_sensitivity=76.11%, avg_specificity=91.79% avg_auc=92.46%
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.341032 Test loss=0.305343 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3364162743091583
[5/24] Train loss=0.29873770475387573
[10/24] Train loss=0.35012710094451904
[15/24] Train loss=0.3496774435043335
[20/24] Train loss=0.32813435792922974
Test set avg_accuracy=86.46% avg_sensitivity=84.21%, avg_specificity=87.25% avg_auc=92.66%
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.331068 Test loss=0.354317 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3310977518558502
[5/24] Train loss=0.28154632449150085
[10/24] Train loss=0.34575992822647095
[15/24] Train loss=0.3276456594467163
[20/24] Train loss=0.3267482817173004
Test set avg_accuracy=86.56% avg_sensitivity=76.21%, avg_specificity=90.21% avg_auc=91.17%
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.318960 Test loss=0.344234 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3087368309497833
[5/24] Train loss=0.2838903069496155
[10/24] Train loss=0.33011749386787415
[15/24] Train loss=0.33172982931137085
[20/24] Train loss=0.3058629631996155
Test set avg_accuracy=86.77% avg_sensitivity=77.31%, avg_specificity=90.10% avg_auc=92.14%
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.316401 Test loss=0.323644 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.33144399523735046
[5/24] Train loss=0.2988431751728058
[10/24] Train loss=0.34228217601776123
[15/24] Train loss=0.301322340965271
[20/24] Train loss=0.29531994462013245
Test set avg_accuracy=86.98% avg_sensitivity=83.01%, avg_specificity=88.38% avg_auc=93.05%
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.309930 Test loss=0.323677 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3093738853931427
[5/24] Train loss=0.2998504936695099
[10/24] Train loss=0.36326366662979126
[15/24] Train loss=0.3515757918357849
[20/24] Train loss=0.30319273471832275
Test set avg_accuracy=87.76% avg_sensitivity=74.41%, avg_specificity=92.46% avg_auc=92.61%
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.323480 Test loss=0.311374 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.32443803548812866
[5/24] Train loss=0.2723923623561859
[10/24] Train loss=0.3355332612991333
[15/24] Train loss=0.3275158405303955
[20/24] Train loss=0.3215814232826233
Test set avg_accuracy=86.59% avg_sensitivity=83.76%, avg_specificity=87.59% avg_auc=92.43%
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.318758 Test loss=0.337006 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.29512712359428406
[5/24] Train loss=0.2624956965446472
[10/24] Train loss=0.33244389295578003
[15/24] Train loss=0.311186820268631
[20/24] Train loss=0.3032824993133545
Test set avg_accuracy=86.88% avg_sensitivity=81.71%, avg_specificity=88.70% avg_auc=92.85%
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.302414 Test loss=0.332097 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.2967815101146698
[5/24] Train loss=0.26450929045677185
[10/24] Train loss=0.2896255850791931
[15/24] Train loss=0.31565529108047485
[20/24] Train loss=0.29148250818252563
Test set avg_accuracy=86.91% avg_sensitivity=70.81%, avg_specificity=92.59% avg_auc=90.70%
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.297719 Test loss=0.352302 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.2987158000469208
[5/24] Train loss=0.2612548768520355
[10/24] Train loss=0.3152278661727905
[15/24] Train loss=0.2884557843208313
[20/24] Train loss=0.3072689473628998
Test set avg_accuracy=85.44% avg_sensitivity=75.76%, avg_specificity=88.85% avg_auc=90.15%
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.306280 Test loss=0.362313 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3071105480194092
[5/24] Train loss=0.25206923484802246
[10/24] Train loss=0.29357409477233887
[15/24] Train loss=0.2982713282108307
[20/24] Train loss=0.29109346866607666
Test set avg_accuracy=86.69% avg_sensitivity=79.71%, avg_specificity=89.15% avg_auc=91.81%
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.295950 Test loss=0.336376 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.2933772802352905
[5/24] Train loss=0.24683406949043274
[10/24] Train loss=0.297384649515152
[15/24] Train loss=0.2931515574455261
[20/24] Train loss=0.2894897758960724
Test set avg_accuracy=87.58% avg_sensitivity=82.66%, avg_specificity=89.31% avg_auc=93.03%
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.290502 Test loss=0.316298 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.28847232460975647
[5/24] Train loss=0.2503637373447418
[10/24] Train loss=0.28173431754112244
[15/24] Train loss=0.3195030689239502
[20/24] Train loss=0.278084397315979
Test set avg_accuracy=87.25% avg_sensitivity=80.16%, avg_specificity=89.75% avg_auc=92.32%
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.294953 Test loss=0.337194 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2908634841442108
[5/24] Train loss=0.26840338110923767
[10/24] Train loss=0.2796911895275116
[15/24] Train loss=0.28510788083076477
[20/24] Train loss=0.3026455044746399
Test set avg_accuracy=83.79% avg_sensitivity=87.46%, avg_specificity=82.50% avg_auc=91.65%
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.286161 Test loss=0.440613 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2979424297809601
[5/24] Train loss=0.24344803392887115
[10/24] Train loss=0.288694828748703
[15/24] Train loss=0.30109912157058716
[20/24] Train loss=0.2866085469722748
Test set avg_accuracy=86.13% avg_sensitivity=84.01%, avg_specificity=86.88% avg_auc=92.52%
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.293568 Test loss=0.356372 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.286062628030777
[5/24] Train loss=0.23808379471302032
[10/24] Train loss=0.2703246772289276
[15/24] Train loss=0.2941511869430542
[20/24] Train loss=0.31645336747169495
Test set avg_accuracy=83.48% avg_sensitivity=86.21%, avg_specificity=82.51% avg_auc=91.84%
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.280664 Test loss=0.408179 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.28905609250068665
[5/24] Train loss=0.23352786898612976
[10/24] Train loss=0.26990461349487305
[15/24] Train loss=0.271648108959198
[20/24] Train loss=0.2751035690307617
Test set avg_accuracy=84.75% avg_sensitivity=85.11%, avg_specificity=84.63% avg_auc=92.13%
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.272739 Test loss=0.396491 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2652982175350189
[5/24] Train loss=0.23530462384223938
[10/24] Train loss=0.2947031557559967
[15/24] Train loss=0.2785216271877289
[20/24] Train loss=0.26968902349472046
Test set avg_accuracy=86.15% avg_sensitivity=83.91%, avg_specificity=86.93% avg_auc=92.00%
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.277134 Test loss=0.354599 Current lr=[0.000224838296036774]

[0/24] Train loss=0.27391529083251953
[5/24] Train loss=0.24378228187561035
[10/24] Train loss=0.2799948453903198
[15/24] Train loss=0.2858613133430481
[20/24] Train loss=0.2891845107078552
Test set avg_accuracy=84.90% avg_sensitivity=85.51%, avg_specificity=84.68% avg_auc=91.90%
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.277863 Test loss=0.403929 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2682781219482422
[5/24] Train loss=0.2365134358406067
[10/24] Train loss=0.2687842547893524
[15/24] Train loss=0.282336950302124
[20/24] Train loss=0.266497403383255
Test set avg_accuracy=83.87% avg_sensitivity=89.61%, avg_specificity=81.85% avg_auc=92.30%
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.272027 Test loss=0.430624 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2800366282463074
[5/24] Train loss=0.2287081629037857
[10/24] Train loss=0.2734285891056061
[15/24] Train loss=0.29460451006889343
[20/24] Train loss=0.2843799591064453
Test set avg_accuracy=86.90% avg_sensitivity=83.96%, avg_specificity=87.94% avg_auc=92.74%
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.283848 Test loss=0.340157 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.27778512239456177
[5/24] Train loss=0.251768559217453
[10/24] Train loss=0.296950101852417
[15/24] Train loss=0.28858014941215515
[20/24] Train loss=0.2599237263202667
Test set avg_accuracy=86.60% avg_sensitivity=85.01%, avg_specificity=87.16% avg_auc=92.40%
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.275830 Test loss=0.365793 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2504669725894928
[5/24] Train loss=0.2238028347492218
[10/24] Train loss=0.2793167531490326
[15/24] Train loss=0.2756454646587372
[20/24] Train loss=0.2764665186405182
Test set avg_accuracy=86.84% avg_sensitivity=81.46%, avg_specificity=88.73% avg_auc=91.89%
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.261342 Test loss=0.348034 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.25368064641952515
[5/24] Train loss=0.2304636389017105
[10/24] Train loss=0.2736288011074066
[15/24] Train loss=0.2571442723274231
[20/24] Train loss=0.2521887719631195
Test set avg_accuracy=86.56% avg_sensitivity=81.76%, avg_specificity=88.25% avg_auc=91.85%
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.261915 Test loss=0.351074 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2615726888179779
[5/24] Train loss=0.23182892799377441
[10/24] Train loss=0.27804261445999146
[15/24] Train loss=0.2774582803249359
[20/24] Train loss=0.28016766905784607
Test set avg_accuracy=86.29% avg_sensitivity=83.21%, avg_specificity=87.37% avg_auc=92.33%
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.261652 Test loss=0.347243 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.265620619058609
[5/24] Train loss=0.236018568277359
[10/24] Train loss=0.2615267038345337
[15/24] Train loss=0.2675831615924835
[20/24] Train loss=0.25715839862823486
Test set avg_accuracy=86.55% avg_sensitivity=80.66%, avg_specificity=88.62% avg_auc=92.46%
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.259450 Test loss=0.344769 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.25193753838539124
[5/24] Train loss=0.22997449338436127
[10/24] Train loss=0.24294626712799072
[15/24] Train loss=0.26124587655067444
[20/24] Train loss=0.25521397590637207
Test set avg_accuracy=86.15% avg_sensitivity=81.61%, avg_specificity=87.74% avg_auc=91.67%
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.248269 Test loss=0.364686 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2508883774280548
[5/24] Train loss=0.216212660074234
[10/24] Train loss=0.2522543668746948
[15/24] Train loss=0.2597278654575348
[20/24] Train loss=0.2671283483505249
Test set avg_accuracy=87.62% avg_sensitivity=75.96%, avg_specificity=91.72% avg_auc=91.27%
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.246488 Test loss=0.338076 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2427276074886322
[5/24] Train loss=0.2274048775434494
[10/24] Train loss=0.2596844434738159
[15/24] Train loss=0.2399207502603531
[20/24] Train loss=0.23355163633823395
Test set avg_accuracy=86.46% avg_sensitivity=79.81%, avg_specificity=88.80% avg_auc=91.60%
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.242682 Test loss=0.364349 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.250769704580307
[5/24] Train loss=0.21303801238536835
[10/24] Train loss=0.24592754244804382
[15/24] Train loss=0.25967302918434143
[20/24] Train loss=0.2502458691596985
Test set avg_accuracy=86.94% avg_sensitivity=82.21%, avg_specificity=88.61% avg_auc=92.47%
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.241361 Test loss=0.352842 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.24326249957084656
[5/24] Train loss=0.2258414924144745
[10/24] Train loss=0.23527905344963074
[15/24] Train loss=0.251083105802536
[20/24] Train loss=0.24678125977516174
Test set avg_accuracy=87.27% avg_sensitivity=75.91%, avg_specificity=91.27% avg_auc=91.24%
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.240890 Test loss=0.339979 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.23653258383274078
[5/24] Train loss=0.19559241831302643
[10/24] Train loss=0.24586206674575806
[15/24] Train loss=0.2464608997106552
[20/24] Train loss=0.24157357215881348
Test set avg_accuracy=86.86% avg_sensitivity=81.11%, avg_specificity=88.89% avg_auc=91.88%
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.234814 Test loss=0.355400 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24159465730190277
[5/24] Train loss=0.20320934057235718
[10/24] Train loss=0.23796795308589935
[15/24] Train loss=0.24340032041072845
[20/24] Train loss=0.23944906890392303
Test set avg_accuracy=87.15% avg_sensitivity=80.91%, avg_specificity=89.35% avg_auc=92.50%
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.233205 Test loss=0.337740 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2283390313386917
[5/24] Train loss=0.2025185078382492
[10/24] Train loss=0.23923712968826294
[15/24] Train loss=0.26127368211746216
[20/24] Train loss=0.23717086017131805
Test set avg_accuracy=86.58% avg_sensitivity=82.71%, avg_specificity=87.94% avg_auc=92.31%
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.239278 Test loss=0.351547 Current lr=[0.000156543481933168]

[0/24] Train loss=0.23672358691692352
[5/24] Train loss=0.19626714289188385
[10/24] Train loss=0.2291853278875351
[15/24] Train loss=0.24529102444648743
[20/24] Train loss=0.23109234869480133
Test set avg_accuracy=86.03% avg_sensitivity=85.66%, avg_specificity=86.16% avg_auc=92.54%
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.228815 Test loss=0.371929 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.2268916517496109
[5/24] Train loss=0.1925681233406067
[10/24] Train loss=0.22566695511341095
[15/24] Train loss=0.24093219637870789
[20/24] Train loss=0.223384290933609
Test set avg_accuracy=87.24% avg_sensitivity=82.66%, avg_specificity=88.85% avg_auc=92.51%
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.225009 Test loss=0.339470 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.23382557928562164
[5/24] Train loss=0.20143532752990723
[10/24] Train loss=0.22949494421482086
[15/24] Train loss=0.24095872044563293
[20/24] Train loss=0.2338816076517105
Test set avg_accuracy=87.89% avg_sensitivity=74.71%, avg_specificity=92.53% avg_auc=92.05%
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.223889 Test loss=0.328862 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.22907347977161407
[5/24] Train loss=0.20432111620903015
[10/24] Train loss=0.23812635242938995
[15/24] Train loss=0.24170346558094025
[20/24] Train loss=0.22121524810791016
Test set avg_accuracy=87.23% avg_sensitivity=79.91%, avg_specificity=89.80% avg_auc=92.23%
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.222563 Test loss=0.336964 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22733505070209503
[5/24] Train loss=0.1960233449935913
[10/24] Train loss=0.23164832592010498
[15/24] Train loss=0.2192479819059372
[20/24] Train loss=0.22113263607025146
Test set avg_accuracy=87.80% avg_sensitivity=78.76%, avg_specificity=90.98% avg_auc=91.78%
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.217065 Test loss=0.339159 Current lr=[0.000134135431043539]

[0/24] Train loss=0.22209540009498596
[5/24] Train loss=0.1818038672208786
[10/24] Train loss=0.21887890994548798
[15/24] Train loss=0.22014790773391724
[20/24] Train loss=0.21337033808231354
Test set avg_accuracy=87.24% avg_sensitivity=75.46%, avg_specificity=91.39% avg_auc=90.90%
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.212143 Test loss=0.343602 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.21676050126552582
[5/24] Train loss=0.18337827920913696
[10/24] Train loss=0.21326476335525513
[15/24] Train loss=0.22784073650836945
[20/24] Train loss=0.22156456112861633
Test set avg_accuracy=87.64% avg_sensitivity=79.21%, avg_specificity=90.61% avg_auc=92.44%
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.210469 Test loss=0.331513 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2091546654701233
[5/24] Train loss=0.186217799782753
[10/24] Train loss=0.21293139457702637
[15/24] Train loss=0.21363790333271027
[20/24] Train loss=0.21719497442245483
Test set avg_accuracy=87.71% avg_sensitivity=78.01%, avg_specificity=91.13% avg_auc=91.64%
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.206609 Test loss=0.334144 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2101931869983673
[5/24] Train loss=0.17616474628448486
[10/24] Train loss=0.2004776895046234
[15/24] Train loss=0.21525263786315918
[20/24] Train loss=0.202065572142601
Test set avg_accuracy=87.47% avg_sensitivity=78.26%, avg_specificity=90.72% avg_auc=92.09%
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.205338 Test loss=0.335128 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2083846777677536
[5/24] Train loss=0.16840367019176483
[10/24] Train loss=0.1957065612077713
[15/24] Train loss=0.21207639575004578
[20/24] Train loss=0.20236927270889282
Test set avg_accuracy=86.84% avg_sensitivity=83.51%, avg_specificity=88.01% avg_auc=92.65%
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.199985 Test loss=0.351289 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.20666539669036865
[5/24] Train loss=0.18625536561012268
[10/24] Train loss=0.2012266218662262
[15/24] Train loss=0.20668596029281616
[20/24] Train loss=0.21097330749034882
Test set avg_accuracy=87.80% avg_sensitivity=81.46%, avg_specificity=90.03% avg_auc=92.32%
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.200731 Test loss=0.342709 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.19299422204494476
[5/24] Train loss=0.17219077050685883
[10/24] Train loss=0.2021702229976654
[15/24] Train loss=0.2216959446668625
[20/24] Train loss=0.20239607989788055
Test set avg_accuracy=87.62% avg_sensitivity=77.41%, avg_specificity=91.21% avg_auc=92.18%
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.198085 Test loss=0.335516 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.1968664973974228
[5/24] Train loss=0.17868845164775848
[10/24] Train loss=0.20010656118392944
[15/24] Train loss=0.21599845588207245
[20/24] Train loss=0.20420466363430023
Test set avg_accuracy=87.51% avg_sensitivity=80.46%, avg_specificity=90.00% avg_auc=92.12%
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.199708 Test loss=0.339366 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.19557861983776093
[5/24] Train loss=0.1669260561466217
[10/24] Train loss=0.19646814465522766
[15/24] Train loss=0.21112337708473206
[20/24] Train loss=0.20441822707653046
Test set avg_accuracy=86.77% avg_sensitivity=82.96%, avg_specificity=88.11% avg_auc=92.25%
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.199424 Test loss=0.358699 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.19791145622730255
[5/24] Train loss=0.173454150557518
[10/24] Train loss=0.20524054765701294
[15/24] Train loss=0.20578846335411072
[20/24] Train loss=0.199498251080513
Test set avg_accuracy=88.07% avg_sensitivity=77.36%, avg_specificity=91.85% avg_auc=92.31%
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.196149 Test loss=0.321954 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.19578014314174652
[5/24] Train loss=0.17793433368206024
[10/24] Train loss=0.2021525651216507
[15/24] Train loss=0.2069494128227234
[20/24] Train loss=0.19689500331878662
Test set avg_accuracy=87.54% avg_sensitivity=79.41%, avg_specificity=90.40% avg_auc=92.21%
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.195450 Test loss=0.345552 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.19209221005439758
[5/24] Train loss=0.1675286442041397
[10/24] Train loss=0.1938129961490631
[15/24] Train loss=0.19795459508895874
[20/24] Train loss=0.2005099356174469
Test set avg_accuracy=87.77% avg_sensitivity=81.46%, avg_specificity=90.00% avg_auc=92.75%
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.191972 Test loss=0.334026 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1902856081724167
[5/24] Train loss=0.16507510840892792
[10/24] Train loss=0.1928652822971344
[15/24] Train loss=0.2031029909849167
[20/24] Train loss=0.1945432424545288
Test set avg_accuracy=87.84% avg_sensitivity=83.06%, avg_specificity=89.52% avg_auc=92.31%
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.187523 Test loss=0.346859 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.18882155418395996
[5/24] Train loss=0.1596721112728119
[10/24] Train loss=0.1837666630744934
[15/24] Train loss=0.19631236791610718
[20/24] Train loss=0.18279889225959778
Test set avg_accuracy=87.36% avg_sensitivity=80.61%, avg_specificity=89.73% avg_auc=92.69%
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.183351 Test loss=0.337580 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.19227531552314758
[5/24] Train loss=0.1576671451330185
[10/24] Train loss=0.1818385273218155
[15/24] Train loss=0.19347423315048218
[20/24] Train loss=0.18327099084854126
Test set avg_accuracy=87.72% avg_sensitivity=80.71%, avg_specificity=90.19% avg_auc=92.35%
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.183616 Test loss=0.339852 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18104559183120728
[5/24] Train loss=0.1576453298330307
[10/24] Train loss=0.18609721958637238
[15/24] Train loss=0.19398732483386993
[20/24] Train loss=0.18423256278038025
Test set avg_accuracy=88.24% avg_sensitivity=81.91%, avg_specificity=90.47% avg_auc=92.92%
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.181815 Test loss=0.326354 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.17411522567272186
[5/24] Train loss=0.16043631732463837
[10/24] Train loss=0.18377207219600677
[15/24] Train loss=0.18733838200569153
[20/24] Train loss=0.18647131323814392
Test set avg_accuracy=88.03% avg_sensitivity=78.81%, avg_specificity=91.28% avg_auc=92.39%
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.179648 Test loss=0.327381 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.1809670478105545
[5/24] Train loss=0.15703144669532776
[10/24] Train loss=0.18005532026290894
[15/24] Train loss=0.18582217395305634
[20/24] Train loss=0.18111096322536469
Test set avg_accuracy=88.41% avg_sensitivity=78.61%, avg_specificity=91.86% avg_auc=92.53%
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.177891 Test loss=0.320099 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1748274862766266
[5/24] Train loss=0.1543273776769638
[10/24] Train loss=0.18179160356521606
[15/24] Train loss=0.18857581913471222
[20/24] Train loss=0.17524529993534088
Test set avg_accuracy=88.09% avg_sensitivity=77.76%, avg_specificity=91.72% avg_auc=92.12%
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.175649 Test loss=0.330810 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.17846262454986572
[5/24] Train loss=0.1591220647096634
[10/24] Train loss=0.18072402477264404
[15/24] Train loss=0.19101741909980774
[20/24] Train loss=0.1757936179637909
Test set avg_accuracy=88.41% avg_sensitivity=78.56%, avg_specificity=91.88% avg_auc=92.27%
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.174769 Test loss=0.322577 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.17030566930770874
[5/24] Train loss=0.15129385888576508
[10/24] Train loss=0.1753348708152771
[15/24] Train loss=0.1842203587293625
[20/24] Train loss=0.17163772881031036
Test set avg_accuracy=87.73% avg_sensitivity=79.91%, avg_specificity=90.49% avg_auc=92.29%
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.174219 Test loss=0.337971 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.16978074610233307
[5/24] Train loss=0.1561388522386551
[10/24] Train loss=0.18000638484954834
[15/24] Train loss=0.18682894110679626
[20/24] Train loss=0.176829531788826
Test set avg_accuracy=87.67% avg_sensitivity=81.31%, avg_specificity=89.91% avg_auc=92.83%
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.175012 Test loss=0.334175 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1775292456150055
[5/24] Train loss=0.15592297911643982
[10/24] Train loss=0.17098939418792725
[15/24] Train loss=0.18089035153388977
[20/24] Train loss=0.17267876863479614
Test set avg_accuracy=87.83% avg_sensitivity=78.51%, avg_specificity=91.11% avg_auc=92.44%
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.174368 Test loss=0.334513 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.16917100548744202
[5/24] Train loss=0.1546943038702011
[10/24] Train loss=0.17789489030838013
[15/24] Train loss=0.18746128678321838
[20/24] Train loss=0.177744522690773
Test set avg_accuracy=87.79% avg_sensitivity=78.31%, avg_specificity=91.13% avg_auc=92.09%
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.173231 Test loss=0.341232 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1720278561115265
[5/24] Train loss=0.15145067870616913
[10/24] Train loss=0.16950471699237823
[15/24] Train loss=0.1846088171005249
[20/24] Train loss=0.18256938457489014
Test set avg_accuracy=88.11% avg_sensitivity=81.56%, avg_specificity=90.42% avg_auc=92.59%
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.172479 Test loss=0.335885 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.17188593745231628
[5/24] Train loss=0.15407618880271912
[10/24] Train loss=0.17600297927856445
[15/24] Train loss=0.18196982145309448
[20/24] Train loss=0.17911311984062195
Test set avg_accuracy=87.88% avg_sensitivity=81.01%, avg_specificity=90.30% avg_auc=92.46%
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.172088 Test loss=0.337358 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.17094720900058746
[5/24] Train loss=0.15395410358905792
[10/24] Train loss=0.1752452403306961
[15/24] Train loss=0.1805187165737152
[20/24] Train loss=0.1732797771692276
Test set avg_accuracy=87.64% avg_sensitivity=82.96%, avg_specificity=89.29% avg_auc=92.72%
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.171349 Test loss=0.345446 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.175838440656662
[5/24] Train loss=0.1483176201581955
[10/24] Train loss=0.17269672453403473
[15/24] Train loss=0.1781909018754959
[20/24] Train loss=0.17147329449653625
Test set avg_accuracy=87.62% avg_sensitivity=83.36%, avg_specificity=89.12% avg_auc=92.77%
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.169045 Test loss=0.344616 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.16854004561901093
[5/24] Train loss=0.15071994066238403
[10/24] Train loss=0.16736046969890594
[15/24] Train loss=0.17971402406692505
[20/24] Train loss=0.17200767993927002
Test set avg_accuracy=88.23% avg_sensitivity=82.41%, avg_specificity=90.28% avg_auc=92.69%
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.169478 Test loss=0.335014 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.16504976153373718
[5/24] Train loss=0.14993245899677277
[10/24] Train loss=0.1707734316587448
[15/24] Train loss=0.17762160301208496
[20/24] Train loss=0.17765215039253235
Test set avg_accuracy=88.10% avg_sensitivity=80.36%, avg_specificity=90.83% avg_auc=92.61%
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.168357 Test loss=0.332018 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.17174465954303741
[5/24] Train loss=0.14889760315418243
[10/24] Train loss=0.17901678383350372
[15/24] Train loss=0.17599354684352875
[20/24] Train loss=0.171259343624115
Test set avg_accuracy=88.11% avg_sensitivity=81.66%, avg_specificity=90.39% avg_auc=92.66%
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.167464 Test loss=0.334482 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.16803576052188873
[5/24] Train loss=0.14286957681179047
[10/24] Train loss=0.16564039885997772
[15/24] Train loss=0.17959754168987274
[20/24] Train loss=0.16494819521903992
Test set avg_accuracy=88.11% avg_sensitivity=80.86%, avg_specificity=90.67% avg_auc=92.55%
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.165731 Test loss=0.332724 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.16761237382888794
[5/24] Train loss=0.14584778249263763
[10/24] Train loss=0.16507582366466522
[15/24] Train loss=0.1772163212299347
[20/24] Train loss=0.16656292974948883
Test set avg_accuracy=87.92% avg_sensitivity=82.06%, avg_specificity=89.98% avg_auc=92.62%
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.164034 Test loss=0.336105 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.16490261256694794
[5/24] Train loss=0.14511550962924957
[10/24] Train loss=0.16366901993751526
[15/24] Train loss=0.17221982777118683
[20/24] Train loss=0.17046868801116943
Test set avg_accuracy=88.28% avg_sensitivity=80.76%, avg_specificity=90.93% avg_auc=92.59%
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.163180 Test loss=0.329417 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16560596227645874
[5/24] Train loss=0.14564405381679535
[10/24] Train loss=0.1625518500804901
[15/24] Train loss=0.17051590979099274
[20/24] Train loss=0.16398835182189941
Test set avg_accuracy=88.28% avg_sensitivity=81.91%, avg_specificity=90.53% avg_auc=92.58%
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.162177 Test loss=0.331553 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.16639667749404907
[5/24] Train loss=0.14531606435775757
[10/24] Train loss=0.1633499264717102
[15/24] Train loss=0.17309808731079102
[20/24] Train loss=0.1649329960346222
Test set avg_accuracy=88.22% avg_sensitivity=81.01%, avg_specificity=90.76% avg_auc=92.54%
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.161327 Test loss=0.331597 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16232545673847198
[5/24] Train loss=0.14352665841579437
[10/24] Train loss=0.16261374950408936
[15/24] Train loss=0.16935791075229645
[20/24] Train loss=0.16234910488128662
Test set avg_accuracy=88.11% avg_sensitivity=82.36%, avg_specificity=90.14% avg_auc=92.66%
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.161275 Test loss=0.334712 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.16295678913593292
[5/24] Train loss=0.1429305225610733
[10/24] Train loss=0.16234484314918518
[15/24] Train loss=0.1685807704925537
[20/24] Train loss=0.1628488451242447
Test set avg_accuracy=88.23% avg_sensitivity=81.56%, avg_specificity=90.58% avg_auc=92.64%
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.160698 Test loss=0.331883 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16001565754413605
[5/24] Train loss=0.1433458775281906
[10/24] Train loss=0.159303680062294
[15/24] Train loss=0.17120057344436646
[20/24] Train loss=0.16241729259490967
Test set avg_accuracy=88.29% avg_sensitivity=81.41%, avg_specificity=90.72% avg_auc=92.56%
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.159708 Test loss=0.330852 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1603403240442276
[5/24] Train loss=0.144257590174675
[10/24] Train loss=0.1620609313249588
[15/24] Train loss=0.17077717185020447
[20/24] Train loss=0.1662273108959198
Test set avg_accuracy=88.24% avg_sensitivity=81.06%, avg_specificity=90.77% avg_auc=92.58%
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.159314 Test loss=0.331553 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.15555962920188904
[5/24] Train loss=0.14178241789340973
[10/24] Train loss=0.1630590260028839
[15/24] Train loss=0.1701580435037613
[20/24] Train loss=0.16467009484767914
Test set avg_accuracy=88.22% avg_sensitivity=81.11%, avg_specificity=90.72% avg_auc=92.59%
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.158899 Test loss=0.332319 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1657852828502655
[5/24] Train loss=0.14027808606624603
[10/24] Train loss=0.16272978484630585
[15/24] Train loss=0.16692256927490234
[20/24] Train loss=0.162393718957901
Test set avg_accuracy=88.28% avg_sensitivity=81.51%, avg_specificity=90.67% avg_auc=92.61%
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.159678 Test loss=0.331691 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.15941299498081207
[5/24] Train loss=0.14152854681015015
[10/24] Train loss=0.1605168730020523
[15/24] Train loss=0.17027005553245544
[20/24] Train loss=0.16586005687713623
Test set avg_accuracy=88.20% avg_sensitivity=81.56%, avg_specificity=90.54% avg_auc=92.62%
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.159274 Test loss=0.331183 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1617354303598404
[5/24] Train loss=0.14378276467323303
[10/24] Train loss=0.16458000242710114
[15/24] Train loss=0.16383016109466553
[20/24] Train loss=0.1615847945213318
Test set avg_accuracy=88.29% avg_sensitivity=81.21%, avg_specificity=90.79% avg_auc=92.60%
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.159333 Test loss=0.331250 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16400620341300964
[5/24] Train loss=0.14313024282455444
[10/24] Train loss=0.16247238218784332
[15/24] Train loss=0.1694902628660202
[20/24] Train loss=0.16004391014575958
Test set avg_accuracy=88.28% avg_sensitivity=81.01%, avg_specificity=90.84% avg_auc=92.61%
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.159257 Test loss=0.330513 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1620703488588333
[5/24] Train loss=0.14008373022079468
[10/24] Train loss=0.1657094657421112
[15/24] Train loss=0.1694362759590149
[20/24] Train loss=0.1637447476387024
Test set avg_accuracy=88.28% avg_sensitivity=81.26%, avg_specificity=90.76% avg_auc=92.61%
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.159278 Test loss=0.330967 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.15807963907718658
[5/24] Train loss=0.14186634123325348
[10/24] Train loss=0.16334186494350433
[15/24] Train loss=0.17045798897743225
[20/24] Train loss=0.16359740495681763
Test set avg_accuracy=88.28% avg_sensitivity=81.26%, avg_specificity=90.76% avg_auc=92.63%
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.158945 Test loss=0.330677 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1589176058769226
[5/24] Train loss=0.14078481495380402
[10/24] Train loss=0.1664983183145523
[15/24] Train loss=0.1654137223958969
[20/24] Train loss=0.16560357809066772
Test set avg_accuracy=88.29% avg_sensitivity=81.26%, avg_specificity=90.77% avg_auc=92.61%
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.159400 Test loss=0.331090 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1606166511774063
[5/24] Train loss=0.14385665953159332
[10/24] Train loss=0.1633155643939972
[15/24] Train loss=0.16783703863620758
[20/24] Train loss=0.1584298461675644
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.35% avg_sensitivity=81.26%, avg_specificity=90.84% avg_auc=92.61%
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.158605 Test loss=0.330962 Current lr=[1.3165623068326024e-09]

Fold[4] Result: acc=87.07% sen=86.31%, spe=87.34%, auc=93.28%!
Fold[4] Avg_overlap=0.67%(0.21657885629428703)
[0/24] Train loss=1.481307029724121
[5/24] Train loss=1.448804259300232
[10/24] Train loss=1.4396471977233887
[15/24] Train loss=1.427632451057434
[20/24] Train loss=1.4071210622787476
Test set avg_accuracy=60.29% avg_sensitivity=51.41%, avg_specificity=63.31% avg_auc=61.70%
Best model saved!! Metric=-89.29237356855236!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=1.444663 Test loss=0.651017 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3989061117172241
[5/24] Train loss=1.3888064622879028
[10/24] Train loss=1.3909437656402588
[15/24] Train loss=1.360084056854248
[20/24] Train loss=1.3390185832977295
Test set avg_accuracy=68.88% avg_sensitivity=68.77%, avg_specificity=68.92% avg_auc=75.28%
Best model saved!! Metric=-44.15460694460873!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=1.371529 Test loss=0.597607 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3320491313934326
[5/24] Train loss=1.3134822845458984
[10/24] Train loss=1.3363978862762451
[15/24] Train loss=1.261260747909546
[20/24] Train loss=1.254052758216858
Test set avg_accuracy=70.61% avg_sensitivity=76.04%, avg_specificity=68.76% avg_auc=79.69%
Best model saved!! Metric=-30.903886920178977!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=1.298597 Test loss=0.567254 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2540398836135864
[5/24] Train loss=1.2262316942214966
[10/24] Train loss=1.2467023134231567
[15/24] Train loss=1.1748405694961548
[20/24] Train loss=1.157289981842041
Test set avg_accuracy=71.64% avg_sensitivity=82.33%, avg_specificity=67.99% avg_auc=82.71%
Best model saved!! Metric=-21.32549634774321!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=1.217836 Test loss=0.552759 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1758337020874023
[5/24] Train loss=1.1628215312957764
[10/24] Train loss=1.186110496520996
[15/24] Train loss=1.094964861869812
[20/24] Train loss=1.1001615524291992
Test set avg_accuracy=73.06% avg_sensitivity=85.51%, avg_specificity=68.81% avg_auc=85.12%
Best model saved!! Metric=-13.501220378435988!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=1.146998 Test loss=0.536629 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1132787466049194
[5/24] Train loss=1.0818696022033691
[10/24] Train loss=1.1292340755462646
[15/24] Train loss=1.0257700681686401
[20/24] Train loss=1.0394691228866577
Test set avg_accuracy=74.64% avg_sensitivity=87.30%, avg_specificity=70.32% avg_auc=87.08%
Best model saved!! Metric=-6.670425683566435!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=1.082550 Test loss=0.515026 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0440051555633545
[5/24] Train loss=1.029502511024475
[10/24] Train loss=1.0845783948898315
[15/24] Train loss=0.9554685950279236
[20/24] Train loss=0.9902165532112122
Test set avg_accuracy=76.26% avg_sensitivity=87.86%, avg_specificity=72.31% avg_auc=88.74%
Best model saved!! Metric=-0.8291324589247466!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=1.027923 Test loss=0.492194 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9875729084014893
[5/24] Train loss=0.9670692682266235
[10/24] Train loss=1.0226945877075195
[15/24] Train loss=0.9080364108085632
[20/24] Train loss=0.9285717606544495
Test set avg_accuracy=78.28% avg_sensitivity=86.94%, avg_specificity=75.33% avg_auc=89.92%
Best model saved!! Metric=4.476361396855253!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.974340 Test loss=0.461426 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9430964589118958
[5/24] Train loss=0.9153066873550415
[10/24] Train loss=0.977749228477478
[15/24] Train loss=0.8529015779495239
[20/24] Train loss=0.8810104727745056
Test set avg_accuracy=80.14% avg_sensitivity=87.25%, avg_specificity=77.72% avg_auc=90.98%
Best model saved!! Metric=10.092433942313264!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.924533 Test loss=0.439461 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8939353227615356
[5/24] Train loss=0.8650983572006226
[10/24] Train loss=0.94195556640625
[15/24] Train loss=0.8106029033660889
[20/24] Train loss=0.8317957520484924
Test set avg_accuracy=82.16% avg_sensitivity=86.84%, avg_specificity=80.57% avg_auc=91.81%
Best model saved!! Metric=15.381932920745541!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.880387 Test loss=0.416373 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8529225587844849
[5/24] Train loss=0.823786199092865
[10/24] Train loss=0.8890958428382874
[15/24] Train loss=0.7765606045722961
[20/24] Train loss=0.782703697681427
Test set avg_accuracy=82.67% avg_sensitivity=87.97%, avg_specificity=80.86% avg_auc=92.54%
Best model saved!! Metric=18.0427775050032!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.839824 Test loss=0.409813 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.8092880845069885
[5/24] Train loss=0.794104814529419
[10/24] Train loss=0.8735104203224182
[15/24] Train loss=0.738233208656311
[20/24] Train loss=0.7455745935440063
Test set avg_accuracy=83.83% avg_sensitivity=88.17%, avg_specificity=82.35% avg_auc=92.97%
Best model saved!! Metric=21.314202706493745!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.806664 Test loss=0.392677 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7743093371391296
[5/24] Train loss=0.7420616149902344
[10/24] Train loss=0.8363720774650574
[15/24] Train loss=0.7042708396911621
[20/24] Train loss=0.7321555614471436
Test set avg_accuracy=84.35% avg_sensitivity=87.40%, avg_specificity=83.31% avg_auc=93.32%
Best model saved!! Metric=22.384870006920536!!
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.772947 Test loss=0.378229 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7423953413963318
[5/24] Train loss=0.703734278678894
[10/24] Train loss=0.8035187721252441
[15/24] Train loss=0.6842741966247559
[20/24] Train loss=0.6849770545959473
Test set avg_accuracy=84.45% avg_sensitivity=87.56%, avg_specificity=83.39% avg_auc=93.49%
Best model saved!! Metric=22.893741045070342!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.741706 Test loss=0.368685 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7223562598228455
[5/24] Train loss=0.6797662377357483
[10/24] Train loss=0.8021615743637085
[15/24] Train loss=0.6490553617477417
[20/24] Train loss=0.6586450338363647
Test set avg_accuracy=84.53% avg_sensitivity=87.92%, avg_specificity=83.38% avg_auc=93.64%
Best model saved!! Metric=23.46118501645219!!
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.720203 Test loss=0.364383 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6896863579750061
[5/24] Train loss=0.6544634699821472
[10/24] Train loss=0.772843599319458
[15/24] Train loss=0.6340311765670776
[20/24] Train loss=0.6395019888877869
Test set avg_accuracy=83.88% avg_sensitivity=89.96%, avg_specificity=81.81% avg_auc=93.87%
Best model saved!! Metric=23.518821916319055!!
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.699368 Test loss=0.372728 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6736426949501038
[5/24] Train loss=0.6340117454528809
[10/24] Train loss=0.7713713645935059
[15/24] Train loss=0.6227443814277649
[20/24] Train loss=0.6272513270378113
Test set avg_accuracy=85.39% avg_sensitivity=86.38%, avg_specificity=85.05% avg_auc=93.82%
Best model saved!! Metric=24.64236192834518!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.681650 Test loss=0.338121 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6538974046707153
[5/24] Train loss=0.6152123212814331
[10/24] Train loss=0.7568667531013489
[15/24] Train loss=0.5947751402854919
[20/24] Train loss=0.609516978263855
Test set avg_accuracy=83.36% avg_sensitivity=92.32%, avg_specificity=80.30% avg_auc=94.19%
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.667121 Test loss=0.383600 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6450397372245789
[5/24] Train loss=0.6047133207321167
[10/24] Train loss=0.7367493510246277
[15/24] Train loss=0.5843237042427063
[20/24] Train loss=0.589414656162262
Test set avg_accuracy=83.45% avg_sensitivity=91.40%, avg_specificity=80.74% avg_auc=94.26%
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.653404 Test loss=0.374632 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6286442279815674
[5/24] Train loss=0.5797457695007324
[10/24] Train loss=0.7049530148506165
[15/24] Train loss=0.567833423614502
[20/24] Train loss=0.567753255367279
Test set avg_accuracy=84.26% avg_sensitivity=89.45%, avg_specificity=82.49% avg_auc=94.24%
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.638271 Test loss=0.352145 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.6077438592910767
[5/24] Train loss=0.5714102983474731
[10/24] Train loss=0.7082815170288086
[15/24] Train loss=0.5681666135787964
[20/24] Train loss=0.5715314745903015
Test set avg_accuracy=84.48% avg_sensitivity=89.96%, avg_specificity=82.61% avg_auc=94.39%
Best model saved!! Metric=25.44695545131617!!
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.626517 Test loss=0.350227 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5937127470970154
[5/24] Train loss=0.5556601285934448
[10/24] Train loss=0.6877679824829102
[15/24] Train loss=0.5466612577438354
[20/24] Train loss=0.5543248653411865
Test set avg_accuracy=85.91% avg_sensitivity=87.25%, avg_specificity=85.45% avg_auc=94.25%
Best model saved!! Metric=26.87044948840753!!
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.611951 Test loss=0.329642 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5866007804870605
[5/24] Train loss=0.5515207052230835
[10/24] Train loss=0.6963635087013245
[15/24] Train loss=0.5335037708282471
[20/24] Train loss=0.555886447429657
Test set avg_accuracy=82.83% avg_sensitivity=92.52%, avg_specificity=79.52% avg_auc=94.37%
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.607678 Test loss=0.381541 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5890846848487854
[5/24] Train loss=0.5497337579727173
[10/24] Train loss=0.6876778602600098
[15/24] Train loss=0.5282043814659119
[20/24] Train loss=0.5358285307884216
Test set avg_accuracy=84.17% avg_sensitivity=90.94%, avg_specificity=81.86% avg_auc=94.55%
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.596291 Test loss=0.352941 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5608164072036743
[5/24] Train loss=0.517287015914917
[10/24] Train loss=0.6549943685531616
[15/24] Train loss=0.5202304124832153
[20/24] Train loss=0.5292202234268188
Test set avg_accuracy=82.46% avg_sensitivity=91.04%, avg_specificity=79.54% avg_auc=94.11%
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.582847 Test loss=0.389446 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5604156851768494
[5/24] Train loss=0.5107800364494324
[10/24] Train loss=0.6394444108009338
[15/24] Train loss=0.5088343024253845
[20/24] Train loss=0.5177333950996399
Test set avg_accuracy=82.66% avg_sensitivity=92.47%, avg_specificity=79.31% avg_auc=94.48%
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.570176 Test loss=0.382552 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5436643362045288
[5/24] Train loss=0.5159857869148254
[10/24] Train loss=0.6287409663200378
[15/24] Train loss=0.503216564655304
[20/24] Train loss=0.5233033299446106
Test set avg_accuracy=79.58% avg_sensitivity=95.44%, avg_specificity=74.17% avg_auc=94.30%
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.557366 Test loss=0.454808 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5276788473129272
[5/24] Train loss=0.5130974650382996
[10/24] Train loss=0.6417249441146851
[15/24] Train loss=0.48382940888404846
[20/24] Train loss=0.5202292799949646
Test set avg_accuracy=78.39% avg_sensitivity=96.67%, avg_specificity=72.15% avg_auc=94.12%
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.550464 Test loss=0.492880 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5417463779449463
[5/24] Train loss=0.48452073335647583
[10/24] Train loss=0.6150627732276917
[15/24] Train loss=0.48725253343582153
[20/24] Train loss=0.5228011608123779
Test set avg_accuracy=81.97% avg_sensitivity=93.86%, avg_specificity=77.91% avg_auc=94.31%
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.540367 Test loss=0.415586 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5149357318878174
[5/24] Train loss=0.48455092310905457
[10/24] Train loss=0.6088659167289734
[15/24] Train loss=0.45195284485816956
[20/24] Train loss=0.48950764536857605
Test set avg_accuracy=84.44% avg_sensitivity=90.94%, avg_specificity=82.22% avg_auc=94.47%
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.526683 Test loss=0.349549 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.5021606087684631
[5/24] Train loss=0.45217522978782654
[10/24] Train loss=0.59855717420578
[15/24] Train loss=0.4582461714744568
[20/24] Train loss=0.4709149897098541
Test set avg_accuracy=84.39% avg_sensitivity=88.12%, avg_specificity=83.12% avg_auc=93.95%
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.518739 Test loss=0.346577 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5039536356925964
[5/24] Train loss=0.4675768315792084
[10/24] Train loss=0.5963252186775208
[15/24] Train loss=0.46152010560035706
[20/24] Train loss=0.4686753749847412
Test set avg_accuracy=86.46% avg_sensitivity=84.90%, avg_specificity=86.99% avg_auc=93.84%
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.515121 Test loss=0.306552 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.5098168849945068
[5/24] Train loss=0.47075921297073364
[10/24] Train loss=0.622003436088562
[15/24] Train loss=0.4515892267227173
[20/24] Train loss=0.4571112096309662
Test set avg_accuracy=82.11% avg_sensitivity=92.17%, avg_specificity=78.68% avg_auc=94.06%
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.516714 Test loss=0.406305 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4918093979358673
[5/24] Train loss=0.4455142915248871
[10/24] Train loss=0.5532605648040771
[15/24] Train loss=0.448293000459671
[20/24] Train loss=0.4637015163898468
Test set avg_accuracy=82.96% avg_sensitivity=91.24%, avg_specificity=80.13% avg_auc=93.99%
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.496523 Test loss=0.391834 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.5005152225494385
[5/24] Train loss=0.4222957193851471
[10/24] Train loss=0.5270791053771973
[15/24] Train loss=0.42815259099006653
[20/24] Train loss=0.44681426882743835
Test set avg_accuracy=86.91% avg_sensitivity=82.18%, avg_specificity=88.53% avg_auc=93.18%
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.486336 Test loss=0.303775 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.46383136510849
[5/24] Train loss=0.39365828037261963
[10/24] Train loss=0.5098764896392822
[15/24] Train loss=0.45131373405456543
[20/24] Train loss=0.43814969062805176
Test set avg_accuracy=86.68% avg_sensitivity=81.87%, avg_specificity=88.32% avg_auc=93.17%
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.478712 Test loss=0.310373 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4520866274833679
[5/24] Train loss=0.45896056294441223
[10/24] Train loss=0.5595396161079407
[15/24] Train loss=0.45105305314064026
[20/24] Train loss=0.4272850751876831
Test set avg_accuracy=85.60% avg_sensitivity=89.50%, avg_specificity=84.27% avg_auc=94.53%
Best model saved!! Metric=27.899891981772!!
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.489125 Test loss=0.324270 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4694635272026062
[5/24] Train loss=0.4041898846626282
[10/24] Train loss=0.5365814566612244
[15/24] Train loss=0.45663198828697205
[20/24] Train loss=0.4123668372631073
Test set avg_accuracy=72.75% avg_sensitivity=96.11%, avg_specificity=64.78% avg_auc=92.36%
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.480308 Test loss=0.588533 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.47276970744132996
[5/24] Train loss=0.42498356103897095
[10/24] Train loss=0.47791916131973267
[15/24] Train loss=0.4245815575122833
[20/24] Train loss=0.42368078231811523
Test set avg_accuracy=70.72% avg_sensitivity=95.80%, avg_specificity=62.16% avg_auc=91.41%
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.464635 Test loss=0.653744 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4867749810218811
[5/24] Train loss=0.38687846064567566
[10/24] Train loss=0.47668376564979553
[15/24] Train loss=0.40500178933143616
[20/24] Train loss=0.39822083711624146
Test set avg_accuracy=81.86% avg_sensitivity=94.62%, avg_specificity=77.51% avg_auc=94.09%
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.449463 Test loss=0.427656 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.43941953778266907
[5/24] Train loss=0.3904416561126709
[10/24] Train loss=0.5201636552810669
[15/24] Train loss=0.3948114812374115
[20/24] Train loss=0.41105830669403076
Test set avg_accuracy=71.24% avg_sensitivity=97.18%, avg_specificity=62.39% avg_auc=92.45%
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.443197 Test loss=0.693178 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4439537227153778
[5/24] Train loss=0.3878013789653778
[10/24] Train loss=0.45678281784057617
[15/24] Train loss=0.42043378949165344
[20/24] Train loss=0.41079312562942505
Test set avg_accuracy=84.53% avg_sensitivity=89.20%, avg_specificity=82.94% avg_auc=93.58%
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.444295 Test loss=0.378572 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.46201619505882263
[5/24] Train loss=0.35827523469924927
[10/24] Train loss=0.48322030901908875
[15/24] Train loss=0.41478872299194336
[20/24] Train loss=0.3784390985965729
Test set avg_accuracy=86.98% avg_sensitivity=86.69%, avg_specificity=87.08% avg_auc=94.39%
Best model saved!! Metric=29.13208735004578!!
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.434265 Test loss=0.301863 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4338476359844208
[5/24] Train loss=0.3460519313812256
[10/24] Train loss=0.4770652949810028
[15/24] Train loss=0.40205034613609314
[20/24] Train loss=0.36953049898147583
Test set avg_accuracy=85.72% avg_sensitivity=84.49%, avg_specificity=86.14% avg_auc=93.69%
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.435798 Test loss=0.333309 Current lr=[0.00029967723776099]

[0/24] Train loss=0.41222313046455383
[5/24] Train loss=0.36509254574775696
[10/24] Train loss=0.48215457797050476
[15/24] Train loss=0.3787066340446472
[20/24] Train loss=0.3708645701408386
Test set avg_accuracy=80.59% avg_sensitivity=95.24%, avg_specificity=75.59% avg_auc=93.90%
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.426859 Test loss=0.462846 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4063188433647156
[5/24] Train loss=0.36362019181251526
[10/24] Train loss=0.4404500126838684
[15/24] Train loss=0.379040390253067
[20/24] Train loss=0.41000717878341675
Test set avg_accuracy=86.84% avg_sensitivity=76.45%, avg_specificity=90.38% avg_auc=92.26%
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.416436 Test loss=0.305379 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4304168224334717
[5/24] Train loss=0.3678324222564697
[10/24] Train loss=0.46254613995552063
[15/24] Train loss=0.3811866343021393
[20/24] Train loss=0.36643490195274353
Test set avg_accuracy=84.78% avg_sensitivity=89.30%, avg_specificity=83.24% avg_auc=94.23%
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.418030 Test loss=0.352841 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4124135673046112
[5/24] Train loss=0.33893290162086487
[10/24] Train loss=0.46334001421928406
[15/24] Train loss=0.3615623116493225
[20/24] Train loss=0.3530755043029785
Test set avg_accuracy=83.89% avg_sensitivity=90.17%, avg_specificity=81.75% avg_auc=94.01%
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.402361 Test loss=0.370383 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.4089130759239197
[5/24] Train loss=0.3642828166484833
[10/24] Train loss=0.4482438564300537
[15/24] Train loss=0.38679665327072144
[20/24] Train loss=0.34764817357063293
Test set avg_accuracy=85.82% avg_sensitivity=89.04%, avg_specificity=84.72% avg_auc=94.46%
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.403164 Test loss=0.339024 Current lr=[0.000298904600941902]

[0/24] Train loss=0.38586995005607605
[5/24] Train loss=0.34175366163253784
[10/24] Train loss=0.5244483351707458
[15/24] Train loss=0.40954074263572693
[20/24] Train loss=0.36374151706695557
Test set avg_accuracy=83.84% avg_sensitivity=90.42%, avg_specificity=81.60% avg_auc=94.05%
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.425489 Test loss=0.362692 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.39465150237083435
[5/24] Train loss=0.31773149967193604
[10/24] Train loss=0.4161689877510071
[15/24] Train loss=0.35681667923927307
[20/24] Train loss=0.39057445526123047
Test set avg_accuracy=64.86% avg_sensitivity=96.06%, avg_specificity=54.22% avg_auc=89.73%
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.399167 Test loss=0.836291 Current lr=[0.000297555943323901]

[0/24] Train loss=0.40602409839630127
[5/24] Train loss=0.3351435661315918
[10/24] Train loss=0.41074037551879883
[15/24] Train loss=0.3414064645767212
[20/24] Train loss=0.35481080412864685
Test set avg_accuracy=61.45% avg_sensitivity=95.34%, avg_specificity=49.89% avg_auc=88.23%
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.381709 Test loss=0.881170 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.388137549161911
[5/24] Train loss=0.3111201822757721
[10/24] Train loss=0.42882871627807617
[15/24] Train loss=0.3443475663661957
[20/24] Train loss=0.3430478572845459
Test set avg_accuracy=72.90% avg_sensitivity=95.80%, avg_specificity=65.10% avg_auc=92.14%
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.383021 Test loss=0.660443 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.37597599625587463
[5/24] Train loss=0.3155471384525299
[10/24] Train loss=0.38483926653862
[15/24] Train loss=0.3523237407207489
[20/24] Train loss=0.3624664545059204
Test set avg_accuracy=81.80% avg_sensitivity=90.73%, avg_specificity=78.75% avg_auc=92.64%
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.378111 Test loss=0.436887 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3684590756893158
[5/24] Train loss=0.30277425050735474
[10/24] Train loss=0.4011460840702057
[15/24] Train loss=0.3644038140773773
[20/24] Train loss=0.3363178074359894
Test set avg_accuracy=87.93% avg_sensitivity=80.13%, avg_specificity=90.59% avg_auc=93.53%
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.371455 Test loss=0.297357 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.4001235365867615
[5/24] Train loss=0.32968956232070923
[10/24] Train loss=0.39935189485549927
[15/24] Train loss=0.3416707515716553
[20/24] Train loss=0.35083532333374023
Test set avg_accuracy=85.85% avg_sensitivity=84.43%, avg_specificity=86.33% avg_auc=93.68%
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.378296 Test loss=0.334182 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3562699258327484
[5/24] Train loss=0.32797637581825256
[10/24] Train loss=0.4065719246864319
[15/24] Train loss=0.33666887879371643
[20/24] Train loss=0.328579843044281
Test set avg_accuracy=85.00% avg_sensitivity=89.71%, avg_specificity=83.39% avg_auc=94.04%
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.374729 Test loss=0.372251 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3704319894313812
[5/24] Train loss=0.3130207359790802
[10/24] Train loss=0.3901170790195465
[15/24] Train loss=0.3342114984989166
[20/24] Train loss=0.36603376269340515
Test set avg_accuracy=83.28% avg_sensitivity=84.23%, avg_specificity=82.96% avg_auc=91.26%
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.364702 Test loss=0.411698 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3814789354801178
[5/24] Train loss=0.31907978653907776
[10/24] Train loss=0.3575432002544403
[15/24] Train loss=0.3145081400871277
[20/24] Train loss=0.31371381878852844
Test set avg_accuracy=83.28% avg_sensitivity=91.35%, avg_specificity=80.53% avg_auc=93.59%
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.352924 Test loss=0.423088 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.3593337833881378
[5/24] Train loss=0.30893149971961975
[10/24] Train loss=0.3660009801387787
[15/24] Train loss=0.3257156014442444
[20/24] Train loss=0.30722886323928833
Test set avg_accuracy=87.32% avg_sensitivity=83.26%, avg_specificity=88.70% avg_auc=93.59%
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.349502 Test loss=0.322088 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3310086727142334
[5/24] Train loss=0.2809021770954132
[10/24] Train loss=0.36458322405815125
[15/24] Train loss=0.34868907928466797
[20/24] Train loss=0.3279608190059662
Test set avg_accuracy=85.70% avg_sensitivity=86.53%, avg_specificity=85.42% avg_auc=93.30%
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.350972 Test loss=0.347842 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.376238077878952
[5/24] Train loss=0.3003171384334564
[10/24] Train loss=0.370076447725296
[15/24] Train loss=0.3417438268661499
[20/24] Train loss=0.31093332171440125
Test set avg_accuracy=83.40% avg_sensitivity=88.07%, avg_specificity=81.81% avg_auc=92.31%
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.362972 Test loss=0.404612 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.36717262864112854
[5/24] Train loss=0.32001128792762756
[10/24] Train loss=0.3370307981967926
[15/24] Train loss=0.333172082901001
[20/24] Train loss=0.33041080832481384
Test set avg_accuracy=78.03% avg_sensitivity=92.01%, avg_specificity=73.27% avg_auc=91.90%
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.353813 Test loss=0.565984 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3539374768733978
[5/24] Train loss=0.31852471828460693
[10/24] Train loss=0.33640021085739136
[15/24] Train loss=0.33866509795188904
[20/24] Train loss=0.3129737973213196
Test set avg_accuracy=85.64% avg_sensitivity=89.86%, avg_specificity=84.20% avg_auc=93.88%
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.348312 Test loss=0.365084 Current lr=[0.000276307469034998]

[0/24] Train loss=0.34595370292663574
[5/24] Train loss=0.30624625086784363
[10/24] Train loss=0.3720545768737793
[15/24] Train loss=0.34658604860305786
[20/24] Train loss=0.3065199553966522
Test set avg_accuracy=85.94% avg_sensitivity=56.22%, avg_specificity=96.07% avg_auc=88.75%
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.352654 Test loss=0.363332 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3839907646179199
[5/24] Train loss=0.2894640564918518
[10/24] Train loss=0.3291553258895874
[15/24] Train loss=0.3161281943321228
[20/24] Train loss=0.31150346994400024
Test set avg_accuracy=85.57% avg_sensitivity=86.33%, avg_specificity=85.32% avg_auc=93.19%
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.347966 Test loss=0.359957 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.33634960651397705
[5/24] Train loss=0.30084866285324097
[10/24] Train loss=0.334775447845459
[15/24] Train loss=0.29857760667800903
[20/24] Train loss=0.3100139796733856
Test set avg_accuracy=86.76% avg_sensitivity=71.94%, avg_specificity=91.81% avg_auc=91.02%
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.326429 Test loss=0.329090 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3448605537414551
[5/24] Train loss=0.29917609691619873
[10/24] Train loss=0.34115901589393616
[15/24] Train loss=0.29941171407699585
[20/24] Train loss=0.3078753352165222
Test set avg_accuracy=86.89% avg_sensitivity=82.95%, avg_specificity=88.23% avg_auc=93.08%
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.333123 Test loss=0.322791 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.32868877053260803
[5/24] Train loss=0.3040626645088196
[10/24] Train loss=0.30747663974761963
[15/24] Train loss=0.30396559834480286
[20/24] Train loss=0.2908826172351837
Test set avg_accuracy=86.78% avg_sensitivity=64.93%, avg_specificity=94.24% avg_auc=89.42%
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.330202 Test loss=0.344656 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.38172659277915955
[5/24] Train loss=0.28316137194633484
[10/24] Train loss=0.33273226022720337
[15/24] Train loss=0.31290629506111145
[20/24] Train loss=0.3135579526424408
Test set avg_accuracy=86.80% avg_sensitivity=68.00%, avg_specificity=93.21% avg_auc=90.36%
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.330479 Test loss=0.331116 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3364897072315216
[5/24] Train loss=0.27308541536331177
[10/24] Train loss=0.29797008633613586
[15/24] Train loss=0.2984776198863983
[20/24] Train loss=0.3028471767902374
Test set avg_accuracy=86.78% avg_sensitivity=68.36%, avg_specificity=93.07% avg_auc=90.40%
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.313967 Test loss=0.350100 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3537135124206543
[5/24] Train loss=0.25545674562454224
[10/24] Train loss=0.30090975761413574
[15/24] Train loss=0.2962763011455536
[20/24] Train loss=0.315109521150589
Test set avg_accuracy=86.05% avg_sensitivity=79.83%, avg_specificity=88.18% avg_auc=91.41%
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.320059 Test loss=0.353167 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3227929472923279
[5/24] Train loss=0.2976861298084259
[10/24] Train loss=0.31435874104499817
[15/24] Train loss=0.3147881329059601
[20/24] Train loss=0.30502116680145264
Test set avg_accuracy=88.45% avg_sensitivity=78.70%, avg_specificity=91.78% avg_auc=93.57%
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.328734 Test loss=0.286067 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3294662535190582
[5/24] Train loss=0.25750166177749634
[10/24] Train loss=0.32194003462791443
[15/24] Train loss=0.3317331373691559
[20/24] Train loss=0.2970625162124634
Test set avg_accuracy=87.92% avg_sensitivity=71.33%, avg_specificity=93.57% avg_auc=92.30%
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.320076 Test loss=0.307161 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.3403167128562927
[5/24] Train loss=0.2773098051548004
[10/24] Train loss=0.35180336236953735
[15/24] Train loss=0.29501739144325256
[20/24] Train loss=0.31369858980178833
Test set avg_accuracy=87.37% avg_sensitivity=68.92%, avg_specificity=93.66% avg_auc=91.40%
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.323281 Test loss=0.319541 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.3211372494697571
[5/24] Train loss=0.26656419038772583
[10/24] Train loss=0.3339858651161194
[15/24] Train loss=0.2807219326496124
[20/24] Train loss=0.3030945062637329
Test set avg_accuracy=86.47% avg_sensitivity=80.90%, avg_specificity=88.37% avg_auc=92.28%
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.309978 Test loss=0.346624 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3362760841846466
[5/24] Train loss=0.25713038444519043
[10/24] Train loss=0.3100779354572296
[15/24] Train loss=0.2703236937522888
[20/24] Train loss=0.2786290645599365
Test set avg_accuracy=85.25% avg_sensitivity=87.76%, avg_specificity=84.39% avg_auc=93.60%
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.298446 Test loss=0.373672 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2995380461215973
[5/24] Train loss=0.28183597326278687
[10/24] Train loss=0.3142645061016083
[15/24] Train loss=0.26653945446014404
[20/24] Train loss=0.2693001329898834
Test set avg_accuracy=82.99% avg_sensitivity=88.38%, avg_specificity=81.16% avg_auc=92.64%
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.301555 Test loss=0.430270 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.30897441506385803
[5/24] Train loss=0.2643697261810303
[10/24] Train loss=0.317998468875885
[15/24] Train loss=0.2861325740814209
[20/24] Train loss=0.2591770589351654
Test set avg_accuracy=87.89% avg_sensitivity=79.06%, avg_specificity=90.90% avg_auc=92.78%
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.292005 Test loss=0.308176 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.28478318452835083
[5/24] Train loss=0.24744777381420135
[10/24] Train loss=0.2695974111557007
[15/24] Train loss=0.2734331786632538
[20/24] Train loss=0.2601417303085327
Test set avg_accuracy=87.12% avg_sensitivity=84.13%, avg_specificity=88.14% avg_auc=93.21%
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.275017 Test loss=0.334755 Current lr=[0.000224838296036774]

[0/24] Train loss=0.3062365651130676
[5/24] Train loss=0.24376849830150604
[10/24] Train loss=0.27429282665252686
[15/24] Train loss=0.26924142241477966
[20/24] Train loss=0.2515782415866852
Test set avg_accuracy=85.49% avg_sensitivity=88.33%, avg_specificity=84.53% avg_auc=93.48%
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.275803 Test loss=0.375275 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2982148230075836
[5/24] Train loss=0.25541800260543823
[10/24] Train loss=0.2668403089046478
[15/24] Train loss=0.24458608031272888
[20/24] Train loss=0.24929533898830414
Test set avg_accuracy=85.94% avg_sensitivity=86.69%, avg_specificity=85.68% avg_auc=93.27%
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.277012 Test loss=0.369646 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.28517425060272217
[5/24] Train loss=0.252207487821579
[10/24] Train loss=0.2739966809749603
[15/24] Train loss=0.24545836448669434
[20/24] Train loss=0.24351465702056885
Test set avg_accuracy=85.21% avg_sensitivity=87.81%, avg_specificity=84.32% avg_auc=93.46%
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.268888 Test loss=0.394596 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.26718175411224365
[5/24] Train loss=0.23768125474452972
[10/24] Train loss=0.2515179514884949
[15/24] Train loss=0.24411225318908691
[20/24] Train loss=0.23958855867385864
Test set avg_accuracy=86.46% avg_sensitivity=82.74%, avg_specificity=87.72% avg_auc=93.01%
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.258174 Test loss=0.345564 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.30595627427101135
[5/24] Train loss=0.23171444237232208
[10/24] Train loss=0.2500791847705841
[15/24] Train loss=0.2586190700531006
[20/24] Train loss=0.2574065923690796
Test set avg_accuracy=87.76% avg_sensitivity=76.04%, avg_specificity=91.76% avg_auc=92.29%
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.266400 Test loss=0.312593 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2729318141937256
[5/24] Train loss=0.23884999752044678
[10/24] Train loss=0.2733910381793976
[15/24] Train loss=0.23765288293361664
[20/24] Train loss=0.22797022759914398
Test set avg_accuracy=86.97% avg_sensitivity=82.54%, avg_specificity=88.48% avg_auc=92.69%
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.261107 Test loss=0.337728 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2866367995738983
[5/24] Train loss=0.22286589443683624
[10/24] Train loss=0.24769239127635956
[15/24] Train loss=0.22585664689540863
[20/24] Train loss=0.23926806449890137
Test set avg_accuracy=86.80% avg_sensitivity=83.41%, avg_specificity=87.95% avg_auc=93.03%
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.254325 Test loss=0.335275 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.26058751344680786
[5/24] Train loss=0.2314784973859787
[10/24] Train loss=0.24382150173187256
[15/24] Train loss=0.22531770169734955
[20/24] Train loss=0.23331747949123383
Test set avg_accuracy=88.03% avg_sensitivity=82.64%, avg_specificity=89.87% avg_auc=93.28%
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.252025 Test loss=0.313640 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2610216736793518
[5/24] Train loss=0.22436676919460297
[10/24] Train loss=0.24603617191314697
[15/24] Train loss=0.2178357094526291
[20/24] Train loss=0.2255708873271942
Test set avg_accuracy=87.83% avg_sensitivity=78.49%, avg_specificity=91.01% avg_auc=91.91%
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.248359 Test loss=0.317556 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.25356605648994446
[5/24] Train loss=0.22285990417003632
[10/24] Train loss=0.23715119063854218
[15/24] Train loss=0.2351188212633133
[20/24] Train loss=0.2304692417383194
Test set avg_accuracy=88.46% avg_sensitivity=81.82%, avg_specificity=90.73% avg_auc=93.02%
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.243661 Test loss=0.321242 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.259414404630661
[5/24] Train loss=0.21952201426029205
[10/24] Train loss=0.23202385008335114
[15/24] Train loss=0.2174803465604782
[20/24] Train loss=0.22397001087665558
Test set avg_accuracy=88.33% avg_sensitivity=77.93%, avg_specificity=91.88% avg_auc=92.44%
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.242286 Test loss=0.308312 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.24691687524318695
[5/24] Train loss=0.22775226831436157
[10/24] Train loss=0.23589791357517242
[15/24] Train loss=0.2209543138742447
[20/24] Train loss=0.22580258548259735
Test set avg_accuracy=87.36% avg_sensitivity=80.34%, avg_specificity=89.75% avg_auc=93.01%
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.246211 Test loss=0.333943 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2637726068496704
[5/24] Train loss=0.21780480444431305
[10/24] Train loss=0.24477291107177734
[15/24] Train loss=0.22121602296829224
[20/24] Train loss=0.24886454641819
Test set avg_accuracy=87.51% avg_sensitivity=78.49%, avg_specificity=90.59% avg_auc=92.74%
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.243822 Test loss=0.318991 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.272653728723526
[5/24] Train loss=0.2334861308336258
[10/24] Train loss=0.2452947497367859
[15/24] Train loss=0.22800011932849884
[20/24] Train loss=0.21957039833068848
Test set avg_accuracy=87.08% avg_sensitivity=77.88%, avg_specificity=90.22% avg_auc=91.90%
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.249399 Test loss=0.343579 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.26367947459220886
[5/24] Train loss=0.2250937521457672
[10/24] Train loss=0.22413550317287445
[15/24] Train loss=0.22456975281238556
[20/24] Train loss=0.230281263589859
Test set avg_accuracy=87.83% avg_sensitivity=70.35%, avg_specificity=93.78% avg_auc=90.38%
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.243359 Test loss=0.335881 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.2747064232826233
[5/24] Train loss=0.22365079820156097
[10/24] Train loss=0.2286069095134735
[15/24] Train loss=0.22708989679813385
[20/24] Train loss=0.23413503170013428
Test set avg_accuracy=87.28% avg_sensitivity=65.54%, avg_specificity=94.69% avg_auc=89.93%
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.245981 Test loss=0.360552 Current lr=[0.000156543481933168]

[0/24] Train loss=0.2575003206729889
[5/24] Train loss=0.21191515028476715
[10/24] Train loss=0.24161440134048462
[15/24] Train loss=0.22528159618377686
[20/24] Train loss=0.23057375848293304
Test set avg_accuracy=87.16% avg_sensitivity=71.53%, avg_specificity=92.49% avg_auc=90.32%
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.244422 Test loss=0.336730 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.25689396262168884
[5/24] Train loss=0.2423681616783142
[10/24] Train loss=0.2390909492969513
[15/24] Train loss=0.2326572984457016
[20/24] Train loss=0.22585320472717285
Test set avg_accuracy=87.37% avg_sensitivity=78.96%, avg_specificity=90.24% avg_auc=91.68%
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.243854 Test loss=0.340826 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2657487094402313
[5/24] Train loss=0.23655752837657928
[10/24] Train loss=0.24737244844436646
[15/24] Train loss=0.22988253831863403
[20/24] Train loss=0.2370912730693817
Test set avg_accuracy=87.89% avg_sensitivity=72.96%, avg_specificity=92.98% avg_auc=91.84%
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.248969 Test loss=0.328542 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.24608114361763
[5/24] Train loss=0.2387361079454422
[10/24] Train loss=0.26663142442703247
[15/24] Train loss=0.22366738319396973
[20/24] Train loss=0.22246186435222626
Test set avg_accuracy=87.38% avg_sensitivity=82.90%, avg_specificity=88.91% avg_auc=93.22%
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.241494 Test loss=0.334068 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.23949328064918518
[5/24] Train loss=0.21968983113765717
[10/24] Train loss=0.2349928766489029
[15/24] Train loss=0.21553203463554382
[20/24] Train loss=0.2328251302242279
Test set avg_accuracy=88.52% avg_sensitivity=78.70%, avg_specificity=91.86% avg_auc=93.49%
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.237707 Test loss=0.299394 Current lr=[0.000134135431043539]

[0/24] Train loss=0.24371901154518127
[5/24] Train loss=0.2275170087814331
[10/24] Train loss=0.22697345912456512
[15/24] Train loss=0.21933932602405548
[20/24] Train loss=0.2181021273136139
Test set avg_accuracy=88.44% avg_sensitivity=81.31%, avg_specificity=90.87% avg_auc=93.51%
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.232977 Test loss=0.309650 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24729081988334656
[5/24] Train loss=0.21763372421264648
[10/24] Train loss=0.2200990468263626
[15/24] Train loss=0.20630833506584167
[20/24] Train loss=0.2339697629213333
Test set avg_accuracy=88.72% avg_sensitivity=77.98%, avg_specificity=92.39% avg_auc=92.71%
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.229920 Test loss=0.309655 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.23641271889209747
[5/24] Train loss=0.22021719813346863
[10/24] Train loss=0.22210508584976196
[15/24] Train loss=0.22017942368984222
[20/24] Train loss=0.2129162847995758
Test set avg_accuracy=88.01% avg_sensitivity=83.56%, avg_specificity=89.52% avg_auc=93.63%
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.225688 Test loss=0.322618 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.22949066758155823
[5/24] Train loss=0.2045103758573532
[10/24] Train loss=0.21141384541988373
[15/24] Train loss=0.21619778871536255
[20/24] Train loss=0.2262556403875351
Test set avg_accuracy=88.68% avg_sensitivity=80.95%, avg_specificity=91.32% avg_auc=93.05%
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.219034 Test loss=0.314118 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2433847188949585
[5/24] Train loss=0.20465919375419617
[10/24] Train loss=0.21173693239688873
[15/24] Train loss=0.19673007726669312
[20/24] Train loss=0.19902990758419037
Test set avg_accuracy=88.66% avg_sensitivity=80.65%, avg_specificity=91.39% avg_auc=93.56%
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.212887 Test loss=0.303590 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.24086381494998932
[5/24] Train loss=0.1937764585018158
[10/24] Train loss=0.2120213359594345
[15/24] Train loss=0.1941789984703064
[20/24] Train loss=0.20961180329322815
Test set avg_accuracy=88.62% avg_sensitivity=77.27%, avg_specificity=92.49% avg_auc=93.28%
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.212474 Test loss=0.305658 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.22623009979724884
[5/24] Train loss=0.20400525629520416
[10/24] Train loss=0.21049658954143524
[15/24] Train loss=0.1942833662033081
[20/24] Train loss=0.19681528210639954
Test set avg_accuracy=88.31% avg_sensitivity=82.18%, avg_specificity=90.40% avg_auc=93.07%
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.209607 Test loss=0.318736 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.21653792262077332
[5/24] Train loss=0.19433020055294037
[10/24] Train loss=0.20202994346618652
[15/24] Train loss=0.19867904484272003
[20/24] Train loss=0.19918031990528107
Test set avg_accuracy=88.96% avg_sensitivity=77.68%, avg_specificity=92.81% avg_auc=93.06%
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.206362 Test loss=0.295526 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.21293266117572784
[5/24] Train loss=0.19301563501358032
[10/24] Train loss=0.18793798983097076
[15/24] Train loss=0.18498088419437408
[20/24] Train loss=0.19644461572170258
Test set avg_accuracy=88.40% avg_sensitivity=81.93%, avg_specificity=90.61% avg_auc=93.71%
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.201497 Test loss=0.302338 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2116336226463318
[5/24] Train loss=0.18774063885211945
[10/24] Train loss=0.18987005949020386
[15/24] Train loss=0.18547898530960083
[20/24] Train loss=0.1834469586610794
Test set avg_accuracy=88.88% avg_sensitivity=81.87%, avg_specificity=91.27% avg_auc=93.73%
Best model saved!! Metric=29.75361482467862!!
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.196081 Test loss=0.294927 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2071773111820221
[5/24] Train loss=0.1879817098379135
[10/24] Train loss=0.18599015474319458
[15/24] Train loss=0.17497995495796204
[20/24] Train loss=0.19095711410045624
Test set avg_accuracy=88.89% avg_sensitivity=81.87%, avg_specificity=91.29% avg_auc=93.51%
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.195166 Test loss=0.300544 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.21479246020317078
[5/24] Train loss=0.18267367780208588
[10/24] Train loss=0.19331273436546326
[15/24] Train loss=0.17920488119125366
[20/24] Train loss=0.1880601942539215
Test set avg_accuracy=87.96% avg_sensitivity=83.10%, avg_specificity=89.61% avg_auc=93.59%
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.195375 Test loss=0.316980 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.20609086751937866
[5/24] Train loss=0.17182424664497375
[10/24] Train loss=0.18486328423023224
[15/24] Train loss=0.17926496267318726
[20/24] Train loss=0.18057890236377716
Test set avg_accuracy=88.76% avg_sensitivity=82.28%, avg_specificity=90.97% avg_auc=93.48%
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.192069 Test loss=0.305828 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.20523463189601898
[5/24] Train loss=0.17392626404762268
[10/24] Train loss=0.18446044623851776
[15/24] Train loss=0.18366935849189758
[20/24] Train loss=0.18739160895347595
Test set avg_accuracy=87.86% avg_sensitivity=84.69%, avg_specificity=88.95% avg_auc=93.67%
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.193237 Test loss=0.326571 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.20783326029777527
[5/24] Train loss=0.17717686295509338
[10/24] Train loss=0.1935112029314041
[15/24] Train loss=0.18573418259620667
[20/24] Train loss=0.20079194009304047
Test set avg_accuracy=88.09% avg_sensitivity=84.02%, avg_specificity=89.47% avg_auc=93.65%
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.195622 Test loss=0.326804 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.20384813845157623
[5/24] Train loss=0.1743081510066986
[10/24] Train loss=0.19827774167060852
[15/24] Train loss=0.17662954330444336
[20/24] Train loss=0.18897858262062073
Test set avg_accuracy=86.73% avg_sensitivity=86.02%, avg_specificity=86.97% avg_auc=93.65%
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.192188 Test loss=0.346402 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.21034783124923706
[5/24] Train loss=0.17797334492206573
[10/24] Train loss=0.19427388906478882
[15/24] Train loss=0.1809310019016266
[20/24] Train loss=0.18248441815376282
Test set avg_accuracy=88.33% avg_sensitivity=81.46%, avg_specificity=90.68% avg_auc=93.37%
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.192947 Test loss=0.313489 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.2053779810667038
[5/24] Train loss=0.17260673642158508
[10/24] Train loss=0.18383243680000305
[15/24] Train loss=0.1814289540052414
[20/24] Train loss=0.1753844916820526
Test set avg_accuracy=87.75% avg_sensitivity=84.02%, avg_specificity=89.02% avg_auc=93.50%
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.187862 Test loss=0.330450 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.2071865200996399
[5/24] Train loss=0.18024222552776337
[10/24] Train loss=0.1797998696565628
[15/24] Train loss=0.1762871891260147
[20/24] Train loss=0.18155156075954437
Test set avg_accuracy=88.84% avg_sensitivity=81.46%, avg_specificity=91.36% avg_auc=93.63%
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.184836 Test loss=0.299577 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.19967865943908691
[5/24] Train loss=0.17183320224285126
[10/24] Train loss=0.1732824146747589
[15/24] Train loss=0.17458520829677582
[20/24] Train loss=0.17985449731349945
Test set avg_accuracy=87.88% avg_sensitivity=83.31%, avg_specificity=89.44% avg_auc=93.30%
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.183476 Test loss=0.324767 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.1931409239768982
[5/24] Train loss=0.17157699167728424
[10/24] Train loss=0.17640168964862823
[15/24] Train loss=0.16724126040935516
[20/24] Train loss=0.17926551401615143
Test set avg_accuracy=88.53% avg_sensitivity=79.88%, avg_specificity=91.48% avg_auc=92.94%
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.180846 Test loss=0.308167 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.19415335357189178
[5/24] Train loss=0.16945435106754303
[10/24] Train loss=0.17485909163951874
[15/24] Train loss=0.16955120861530304
[20/24] Train loss=0.1723291575908661
Test set avg_accuracy=88.80% avg_sensitivity=79.83%, avg_specificity=91.86% avg_auc=92.85%
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.177705 Test loss=0.304170 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.18775224685668945
[5/24] Train loss=0.16860444843769073
[10/24] Train loss=0.17465268075466156
[15/24] Train loss=0.16720610857009888
[20/24] Train loss=0.17413438856601715
Test set avg_accuracy=88.59% avg_sensitivity=80.13%, avg_specificity=91.48% avg_auc=93.43%
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.176941 Test loss=0.303268 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.19114838540554047
[5/24] Train loss=0.16979146003723145
[10/24] Train loss=0.16732046008110046
[15/24] Train loss=0.16883298754692078
[20/24] Train loss=0.17260289192199707
Test set avg_accuracy=88.88% avg_sensitivity=80.65%, avg_specificity=91.69% avg_auc=93.36%
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.176473 Test loss=0.299331 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1898864060640335
[5/24] Train loss=0.16478240489959717
[10/24] Train loss=0.17026352882385254
[15/24] Train loss=0.1664751172065735
[20/24] Train loss=0.17250338196754456
Test set avg_accuracy=88.78% avg_sensitivity=79.67%, avg_specificity=91.88% avg_auc=92.93%
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.175599 Test loss=0.304387 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.18887899816036224
[5/24] Train loss=0.16878491640090942
[10/24] Train loss=0.1663990467786789
[15/24] Train loss=0.1677757054567337
[20/24] Train loss=0.1699547916650772
Test set avg_accuracy=88.20% avg_sensitivity=83.61%, avg_specificity=89.77% avg_auc=93.25%
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.174789 Test loss=0.319804 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.19042158126831055
[5/24] Train loss=0.1701909303665161
[10/24] Train loss=0.16826121509075165
[15/24] Train loss=0.16640718281269073
[20/24] Train loss=0.17067675292491913
Test set avg_accuracy=88.67% avg_sensitivity=83.31%, avg_specificity=90.50% avg_auc=93.47%
Best model saved!! Metric=29.948805693007344!!
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.176985 Test loss=0.308741 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.18746733665466309
[5/24] Train loss=0.16789481043815613
[10/24] Train loss=0.1726464331150055
[15/24] Train loss=0.16063961386680603
[20/24] Train loss=0.17613431811332703
Test set avg_accuracy=88.40% avg_sensitivity=85.00%, avg_specificity=89.56% avg_auc=93.51%
Best model saved!! Metric=30.466962630151713!!
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.176998 Test loss=0.321079 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1861506551504135
[5/24] Train loss=0.1598542034626007
[10/24] Train loss=0.17190323770046234
[15/24] Train loss=0.1624777466058731
[20/24] Train loss=0.17521092295646667
Test set avg_accuracy=88.76% avg_sensitivity=82.08%, avg_specificity=91.04% avg_auc=93.27%
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.174275 Test loss=0.309506 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.19156736135482788
[5/24] Train loss=0.16156011819839478
[10/24] Train loss=0.16979622840881348
[15/24] Train loss=0.16426534950733185
[20/24] Train loss=0.17135824263095856
Test set avg_accuracy=88.40% avg_sensitivity=82.95%, avg_specificity=90.26% avg_auc=93.20%
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.174190 Test loss=0.319771 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.19380176067352295
[5/24] Train loss=0.16622573137283325
[10/24] Train loss=0.16500236093997955
[15/24] Train loss=0.16388654708862305
[20/24] Train loss=0.1719348430633545
Test set avg_accuracy=88.79% avg_sensitivity=80.95%, avg_specificity=91.46% avg_auc=93.11%
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.172019 Test loss=0.306465 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.18449829518795013
[5/24] Train loss=0.15759046375751495
[10/24] Train loss=0.16391214728355408
[15/24] Train loss=0.1563253253698349
[20/24] Train loss=0.16553491353988647
Test set avg_accuracy=89.00% avg_sensitivity=81.41%, avg_specificity=91.58% avg_auc=93.08%
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.167942 Test loss=0.305076 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.18348576128482819
[5/24] Train loss=0.16025136411190033
[10/24] Train loss=0.1624641865491867
[15/24] Train loss=0.15805253386497498
[20/24] Train loss=0.16869378089904785
Test set avg_accuracy=88.76% avg_sensitivity=81.98%, avg_specificity=91.08% avg_auc=93.30%
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.167508 Test loss=0.306582 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.18194198608398438
[5/24] Train loss=0.15900935232639313
[10/24] Train loss=0.16370880603790283
[15/24] Train loss=0.1522202342748642
[20/24] Train loss=0.16526933014392853
Test set avg_accuracy=88.79% avg_sensitivity=81.82%, avg_specificity=91.16% avg_auc=93.24%
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.166584 Test loss=0.307985 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.17738893628120422
[5/24] Train loss=0.15927651524543762
[10/24] Train loss=0.15970012545585632
[15/24] Train loss=0.1546262502670288
[20/24] Train loss=0.16227926313877106
Test set avg_accuracy=88.61% avg_sensitivity=82.59%, avg_specificity=90.66% avg_auc=93.42%
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.165877 Test loss=0.308582 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1811857670545578
[5/24] Train loss=0.15581363439559937
[10/24] Train loss=0.16079244017601013
[15/24] Train loss=0.15536782145500183
[20/24] Train loss=0.16015279293060303
Test set avg_accuracy=88.95% avg_sensitivity=81.52%, avg_specificity=91.48% avg_auc=93.31%
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.165264 Test loss=0.302282 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.18388672173023224
[5/24] Train loss=0.160049706697464
[10/24] Train loss=0.16000831127166748
[15/24] Train loss=0.15677669644355774
[20/24] Train loss=0.16036584973335266
Test set avg_accuracy=88.68% avg_sensitivity=81.93%, avg_specificity=90.99% avg_auc=93.32%
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.165481 Test loss=0.306772 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.17823919653892517
[5/24] Train loss=0.15360024571418762
[10/24] Train loss=0.16082067787647247
[15/24] Train loss=0.15114079415798187
[20/24] Train loss=0.16278910636901855
Test set avg_accuracy=88.82% avg_sensitivity=82.28%, avg_specificity=91.04% avg_auc=93.37%
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.165468 Test loss=0.306243 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1747026890516281
[5/24] Train loss=0.15472105145454407
[10/24] Train loss=0.1568523794412613
[15/24] Train loss=0.15572379529476166
[20/24] Train loss=0.16309361159801483
Test set avg_accuracy=88.95% avg_sensitivity=81.67%, avg_specificity=91.43% avg_auc=93.25%
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.164966 Test loss=0.304750 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17825810611248016
[5/24] Train loss=0.15601347386837006
[10/24] Train loss=0.1624273955821991
[15/24] Train loss=0.154143825173378
[20/24] Train loss=0.161493182182312
Test set avg_accuracy=88.96% avg_sensitivity=81.98%, avg_specificity=91.34% avg_auc=93.32%
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.164920 Test loss=0.305308 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.17878562211990356
[5/24] Train loss=0.15561868250370026
[10/24] Train loss=0.15773172676563263
[15/24] Train loss=0.15528777241706848
[20/24] Train loss=0.1612182855606079
Test set avg_accuracy=88.89% avg_sensitivity=82.18%, avg_specificity=91.18% avg_auc=93.37%
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.164925 Test loss=0.304601 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.17379911243915558
[5/24] Train loss=0.15469078719615936
[10/24] Train loss=0.15901172161102295
[15/24] Train loss=0.15199629962444305
[20/24] Train loss=0.16199703514575958
Test set avg_accuracy=89.00% avg_sensitivity=82.13%, avg_specificity=91.34% avg_auc=93.32%
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.164270 Test loss=0.303534 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.17551173269748688
[5/24] Train loss=0.15668052434921265
[10/24] Train loss=0.16036950051784515
[15/24] Train loss=0.15479816496372223
[20/24] Train loss=0.16483646631240845
Test set avg_accuracy=88.97% avg_sensitivity=82.03%, avg_specificity=91.34% avg_auc=93.27%
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.163900 Test loss=0.304705 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1758756786584854
[5/24] Train loss=0.15904539823532104
[10/24] Train loss=0.15870051085948944
[15/24] Train loss=0.15598337352275848
[20/24] Train loss=0.16172392666339874
Test set avg_accuracy=88.95% avg_sensitivity=82.03%, avg_specificity=91.30% avg_auc=93.30%
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.163538 Test loss=0.304973 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1783035397529602
[5/24] Train loss=0.1539985090494156
[10/24] Train loss=0.15565423667430878
[15/24] Train loss=0.15537597239017487
[20/24] Train loss=0.16887888312339783
Test set avg_accuracy=88.97% avg_sensitivity=82.03%, avg_specificity=91.34% avg_auc=93.29%
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.164291 Test loss=0.304265 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.17924706637859344
[5/24] Train loss=0.15145893394947052
[10/24] Train loss=0.1593964844942093
[15/24] Train loss=0.15493708848953247
[20/24] Train loss=0.16222859919071198
Test set avg_accuracy=88.96% avg_sensitivity=82.08%, avg_specificity=91.30% avg_auc=93.28%
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.164046 Test loss=0.304982 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.1805141717195511
[5/24] Train loss=0.15378378331661224
[10/24] Train loss=0.16210517287254333
[15/24] Train loss=0.15621167421340942
[20/24] Train loss=0.16301420331001282
Test set avg_accuracy=88.95% avg_sensitivity=81.98%, avg_specificity=91.32% avg_auc=93.29%
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.164252 Test loss=0.304845 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.17501816153526306
[5/24] Train loss=0.1577330082654953
[10/24] Train loss=0.1583622545003891
[15/24] Train loss=0.1535094678401947
[20/24] Train loss=0.15926812589168549
Test set avg_accuracy=88.93% avg_sensitivity=81.87%, avg_specificity=91.34% avg_auc=93.28%
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.163411 Test loss=0.304592 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1806483417749405
[5/24] Train loss=0.1542539745569229
[10/24] Train loss=0.1582375317811966
[15/24] Train loss=0.1570410132408142
[20/24] Train loss=0.1638781577348709
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.96% avg_sensitivity=81.98%, avg_specificity=91.34% avg_auc=93.28%
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.164948 Test loss=0.304870 Current lr=[1.3165623068326024e-09]

Fold[5] Result: acc=88.40% sen=85.00%, spe=89.56%, auc=93.51%!
Fold[5] Avg_overlap=0.68%(0.2225383153719682)
[0/24] Train loss=1.4560514688491821
[5/24] Train loss=1.4647711515426636
[10/24] Train loss=1.4322538375854492
[15/24] Train loss=1.4189786911010742
[20/24] Train loss=1.3848146200180054
Test set avg_accuracy=60.40% avg_sensitivity=47.50%, avg_specificity=65.21% avg_auc=58.16%
Best model saved!! Metric=-94.72271636121475!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=1.430580 Test loss=0.678947 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3772631883621216
[5/24] Train loss=1.3604669570922852
[10/24] Train loss=1.3682280778884888
[15/24] Train loss=1.323239803314209
[20/24] Train loss=1.307777762413025
Test set avg_accuracy=68.03% avg_sensitivity=62.19%, avg_specificity=70.21% avg_auc=72.56%
Best model saved!! Metric=-53.01078801674102!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=1.356416 Test loss=0.605873 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.2789068222045898
[5/24] Train loss=1.3058083057403564
[10/24] Train loss=1.304547905921936
[15/24] Train loss=1.2274389266967773
[20/24] Train loss=1.2412934303283691
Test set avg_accuracy=71.26% avg_sensitivity=73.32%, avg_specificity=70.50% avg_auc=79.04%
Best model saved!! Metric=-31.877612248426487!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=1.282002 Test loss=0.573605 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.219353199005127
[5/24] Train loss=1.238167405128479
[10/24] Train loss=1.2211116552352905
[15/24] Train loss=1.1775801181793213
[20/24] Train loss=1.1578211784362793
Test set avg_accuracy=73.85% avg_sensitivity=79.89%, avg_specificity=71.60% avg_auc=82.64%
Best model saved!! Metric=-18.00421397675973!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=1.213427 Test loss=0.548645 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1317336559295654
[5/24] Train loss=1.1321147680282593
[10/24] Train loss=1.147550106048584
[15/24] Train loss=1.0914589166641235
[20/24] Train loss=1.098414659500122
Test set avg_accuracy=76.04% avg_sensitivity=81.33%, avg_specificity=74.07% avg_auc=84.82%
Best model saved!! Metric=-9.730780131773145!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=1.136653 Test loss=0.522640 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.0540151596069336
[5/24] Train loss=1.0383316278457642
[10/24] Train loss=1.0945971012115479
[15/24] Train loss=1.0191017389297485
[20/24] Train loss=1.0079140663146973
Test set avg_accuracy=77.51% avg_sensitivity=83.49%, avg_specificity=75.29% avg_auc=86.92%
Best model saved!! Metric=-2.792426298495158!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=1.069285 Test loss=0.501284 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0016320943832397
[5/24] Train loss=0.992174506187439
[10/24] Train loss=1.0327504873275757
[15/24] Train loss=0.9636657238006592
[20/24] Train loss=0.9633917808532715
Test set avg_accuracy=79.48% avg_sensitivity=83.78%, avg_specificity=77.88% avg_auc=88.56%
Best model saved!! Metric=3.69366128785893!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=1.010671 Test loss=0.468487 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9548420310020447
[5/24] Train loss=0.9411472678184509
[10/24] Train loss=0.9883149862289429
[15/24] Train loss=0.9198755025863647
[20/24] Train loss=0.8945198059082031
Test set avg_accuracy=81.35% avg_sensitivity=85.65%, avg_specificity=79.75% avg_auc=90.06%
Best model saved!! Metric=10.82087907709419!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.956926 Test loss=0.444720 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.8889648914337158
[5/24] Train loss=0.9065387845039368
[10/24] Train loss=0.9291953444480896
[15/24] Train loss=0.8846802115440369
[20/24] Train loss=0.8548851609230042
Test set avg_accuracy=82.96% avg_sensitivity=86.04%, avg_specificity=81.81% avg_auc=91.11%
Best model saved!! Metric=15.908994214774793!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.908313 Test loss=0.420440 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8680568933486938
[5/24] Train loss=0.8632757663726807
[10/24] Train loss=0.8876475691795349
[15/24] Train loss=0.8262897729873657
[20/24] Train loss=0.8081571459770203
Test set avg_accuracy=84.01% avg_sensitivity=86.28%, avg_specificity=83.17% avg_auc=91.92%
Best model saved!! Metric=19.371535933376236!!
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.867618 Test loss=0.399499 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8450097441673279
[5/24] Train loss=0.8260027766227722
[10/24] Train loss=0.8532291650772095
[15/24] Train loss=0.7998744249343872
[20/24] Train loss=0.7738028168678284
Test set avg_accuracy=84.73% avg_sensitivity=87.52%, avg_specificity=83.68% avg_auc=92.52%
Best model saved!! Metric=22.45377236610946!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.832241 Test loss=0.387035 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7970218658447266
[5/24] Train loss=0.7847093343734741
[10/24] Train loss=0.8130938410758972
[15/24] Train loss=0.763864278793335
[20/24] Train loss=0.7218583226203918
Test set avg_accuracy=85.64% avg_sensitivity=87.86%, avg_specificity=84.81% avg_auc=93.06%
Best model saved!! Metric=25.37338294419122!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.797620 Test loss=0.368788 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7430537343025208
[5/24] Train loss=0.7688917517662048
[10/24] Train loss=0.7784506678581238
[15/24] Train loss=0.7481228113174438
[20/24] Train loss=0.703963577747345
Test set avg_accuracy=86.28% avg_sensitivity=87.57%, avg_specificity=85.79% avg_auc=93.43%
Best model saved!! Metric=27.070152897748926!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.768581 Test loss=0.351823 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7162337303161621
[5/24] Train loss=0.7351723313331604
[10/24] Train loss=0.7571669220924377
[15/24] Train loss=0.7252971529960632
[20/24] Train loss=0.6693107485771179
Test set avg_accuracy=84.93% avg_sensitivity=89.68%, avg_specificity=83.17% avg_auc=93.71%
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.744922 Test loss=0.365601 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7000299096107483
[5/24] Train loss=0.7175023555755615
[10/24] Train loss=0.7323963046073914
[15/24] Train loss=0.7047998309135437
[20/24] Train loss=0.6506096124649048
Test set avg_accuracy=85.36% avg_sensitivity=89.59%, avg_specificity=83.79% avg_auc=93.95%
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.719728 Test loss=0.353232 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6874170303344727
[5/24] Train loss=0.6948357224464417
[10/24] Train loss=0.7078040242195129
[15/24] Train loss=0.6908448934555054
[20/24] Train loss=0.6251358389854431
Test set avg_accuracy=86.25% avg_sensitivity=88.72%, avg_specificity=85.33% avg_auc=94.08%
Best model saved!! Metric=28.379843910992108!!
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.700065 Test loss=0.335999 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6628670692443848
[5/24] Train loss=0.6880146265029907
[10/24] Train loss=0.6903825402259827
[15/24] Train loss=0.684272050857544
[20/24] Train loss=0.6004366874694824
Test set avg_accuracy=86.00% avg_sensitivity=89.25%, avg_specificity=84.79% avg_auc=94.23%
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.682439 Test loss=0.336913 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6432778835296631
[5/24] Train loss=0.6664217710494995
[10/24] Train loss=0.6967799067497253
[15/24] Train loss=0.6523554921150208
[20/24] Train loss=0.578892171382904
Test set avg_accuracy=85.78% avg_sensitivity=90.12%, avg_specificity=84.17% avg_auc=94.33%
Best model saved!! Metric=28.39502197038192!!
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.667419 Test loss=0.340679 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6329640746116638
[5/24] Train loss=0.6675653457641602
[10/24] Train loss=0.6705996990203857
[15/24] Train loss=0.6514572501182556
[20/24] Train loss=0.5723965167999268
Test set avg_accuracy=85.62% avg_sensitivity=90.55%, avg_specificity=83.79% avg_auc=94.40%
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.652911 Test loss=0.342401 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6209099888801575
[5/24] Train loss=0.6338757872581482
[10/24] Train loss=0.6448091864585876
[15/24] Train loss=0.6351224780082703
[20/24] Train loss=0.553598940372467
Test set avg_accuracy=85.86% avg_sensitivity=89.68%, avg_specificity=84.44% avg_auc=94.29%
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.635632 Test loss=0.336156 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5921455025672913
[5/24] Train loss=0.6200363636016846
[10/24] Train loss=0.6554999351501465
[15/24] Train loss=0.6394022703170776
[20/24] Train loss=0.5560416579246521
Test set avg_accuracy=86.47% avg_sensitivity=89.16%, avg_specificity=85.47% avg_auc=94.40%
Best model saved!! Metric=29.500640063228374!!
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.625656 Test loss=0.323202 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.6086254715919495
[5/24] Train loss=0.6057913899421692
[10/24] Train loss=0.6298379302024841
[15/24] Train loss=0.6122614741325378
[20/24] Train loss=0.5257346034049988
Test set avg_accuracy=88.89% avg_sensitivity=85.75%, avg_specificity=90.06% avg_auc=94.18%
Best model saved!! Metric=32.883618517985596!!
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.609684 Test loss=0.284784 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5857149958610535
[5/24] Train loss=0.5949258208274841
[10/24] Train loss=0.6332963705062866
[15/24] Train loss=0.6151283383369446
[20/24] Train loss=0.5089308619499207
Test set avg_accuracy=88.91% avg_sensitivity=82.53%, avg_specificity=91.28% avg_auc=94.05%
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.596372 Test loss=0.275646 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5651414394378662
[5/24] Train loss=0.5954474806785583
[10/24] Train loss=0.6219512224197388
[15/24] Train loss=0.5860130786895752
[20/24] Train loss=0.501934289932251
Test set avg_accuracy=88.36% avg_sensitivity=87.38%, avg_specificity=88.72% avg_auc=94.63%
Best model saved!! Metric=33.09278891369486!!
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.586332 Test loss=0.289244 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.55645751953125
[5/24] Train loss=0.5900536179542542
[10/24] Train loss=0.6114014387130737
[15/24] Train loss=0.5915521383285522
[20/24] Train loss=0.49248701333999634
Test set avg_accuracy=88.78% avg_sensitivity=85.36%, avg_specificity=90.05% avg_auc=94.42%
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.573024 Test loss=0.278031 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5393529534339905
[5/24] Train loss=0.5614465475082397
[10/24] Train loss=0.6002429127693176
[15/24] Train loss=0.5475287437438965
[20/24] Train loss=0.47213295102119446
Test set avg_accuracy=88.87% avg_sensitivity=79.85%, avg_specificity=92.23% avg_auc=93.89%
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.561394 Test loss=0.271922 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5262976288795471
[5/24] Train loss=0.5503221154212952
[10/24] Train loss=0.6008718609809875
[15/24] Train loss=0.5416248440742493
[20/24] Train loss=0.4628334641456604
Test set avg_accuracy=87.99% avg_sensitivity=69.34%, avg_specificity=94.94% avg_auc=93.09%
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.550985 Test loss=0.287498 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5256866216659546
[5/24] Train loss=0.529855489730835
[10/24] Train loss=0.5605021715164185
[15/24] Train loss=0.5406870245933533
[20/24] Train loss=0.45409226417541504
Test set avg_accuracy=88.63% avg_sensitivity=81.81%, avg_specificity=91.17% avg_auc=93.66%
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.541575 Test loss=0.278895 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5041324496269226
[5/24] Train loss=0.5167736411094666
[10/24] Train loss=0.5598820447921753
[15/24] Train loss=0.5418097376823425
[20/24] Train loss=0.4385720193386078
Test set avg_accuracy=88.16% avg_sensitivity=72.89%, avg_specificity=93.85% avg_auc=92.88%
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.526454 Test loss=0.288102 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5041859745979309
[5/24] Train loss=0.4964652955532074
[10/24] Train loss=0.5599074363708496
[15/24] Train loss=0.5324251055717468
[20/24] Train loss=0.43866294622421265
Test set avg_accuracy=88.68% avg_sensitivity=74.42%, avg_specificity=94.00% avg_auc=93.41%
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.514184 Test loss=0.275443 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.49791091680526733
[5/24] Train loss=0.5527740716934204
[10/24] Train loss=0.547544002532959
[15/24] Train loss=0.5086085200309753
[20/24] Train loss=0.43468567728996277
Test set avg_accuracy=86.90% avg_sensitivity=62.86%, avg_specificity=95.85% avg_auc=91.91%
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.513420 Test loss=0.314838 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5304951667785645
[5/24] Train loss=0.5059769153594971
[10/24] Train loss=0.5364371538162231
[15/24] Train loss=0.5240362882614136
[20/24] Train loss=0.41462790966033936
Test set avg_accuracy=88.35% avg_sensitivity=75.53%, avg_specificity=93.12% avg_auc=92.44%
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.503764 Test loss=0.293914 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.47227734327316284
[5/24] Train loss=0.4901343286037445
[10/24] Train loss=0.5207658410072327
[15/24] Train loss=0.5338915586471558
[20/24] Train loss=0.42478251457214355
Test set avg_accuracy=88.32% avg_sensitivity=72.22%, avg_specificity=94.32% avg_auc=92.74%
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.498258 Test loss=0.288998 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4897814393043518
[5/24] Train loss=0.47161829471588135
[10/24] Train loss=0.4872232675552368
[15/24] Train loss=0.48212069272994995
[20/24] Train loss=0.4389822781085968
Test set avg_accuracy=88.91% avg_sensitivity=75.62%, avg_specificity=93.85% avg_auc=92.74%
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.483880 Test loss=0.287847 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.46846944093704224
[5/24] Train loss=0.47139987349510193
[10/24] Train loss=0.4996233284473419
[15/24] Train loss=0.48940446972846985
[20/24] Train loss=0.40581291913986206
Test set avg_accuracy=87.25% avg_sensitivity=66.27%, avg_specificity=95.07% avg_auc=91.33%
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.471970 Test loss=0.314994 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4863367974758148
[5/24] Train loss=0.4445158839225769
[10/24] Train loss=0.49196621775627136
[15/24] Train loss=0.501895546913147
[20/24] Train loss=0.387241929769516
Test set avg_accuracy=88.27% avg_sensitivity=85.65%, avg_specificity=89.24% avg_auc=93.93%
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.468426 Test loss=0.292051 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.44332975149154663
[5/24] Train loss=0.45663920044898987
[10/24] Train loss=0.49051156640052795
[15/24] Train loss=0.47142282128334045
[20/24] Train loss=0.399322509765625
Test set avg_accuracy=85.89% avg_sensitivity=88.24%, avg_specificity=85.01% avg_auc=93.63%
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.463845 Test loss=0.333969 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.438863068819046
[5/24] Train loss=0.45642367005348206
[10/24] Train loss=0.48631376028060913
[15/24] Train loss=0.4890381097793579
[20/24] Train loss=0.4066105782985687
Test set avg_accuracy=88.79% avg_sensitivity=73.27%, avg_specificity=94.57% avg_auc=92.14%
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.464252 Test loss=0.295049 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.461759477853775
[5/24] Train loss=0.5026864409446716
[10/24] Train loss=0.49169212579727173
[15/24] Train loss=0.4574328660964966
[20/24] Train loss=0.3834875822067261
Test set avg_accuracy=88.49% avg_sensitivity=76.10%, avg_specificity=93.10% avg_auc=92.51%
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.455162 Test loss=0.295144 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.44041821360588074
[5/24] Train loss=0.44630464911460876
[10/24] Train loss=0.46700677275657654
[15/24] Train loss=0.4400329291820526
[20/24] Train loss=0.38889747858047485
Test set avg_accuracy=88.19% avg_sensitivity=69.72%, avg_specificity=95.07% avg_auc=92.00%
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.450152 Test loss=0.309221 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.42788052558898926
[5/24] Train loss=0.4067642390727997
[10/24] Train loss=0.42005667090415955
[15/24] Train loss=0.4449370503425598
[20/24] Train loss=0.3724806010723114
Test set avg_accuracy=86.61% avg_sensitivity=85.94%, avg_specificity=86.87% avg_auc=93.32%
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.426352 Test loss=0.326979 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4353371560573578
[5/24] Train loss=0.42395147681236267
[10/24] Train loss=0.4796532392501831
[15/24] Train loss=0.460617333650589
[20/24] Train loss=0.37637388706207275
Test set avg_accuracy=86.25% avg_sensitivity=85.94%, avg_specificity=86.37% avg_auc=93.10%
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.442372 Test loss=0.334949 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.43240219354629517
[5/24] Train loss=0.41834771633148193
[10/24] Train loss=0.4530063569545746
[15/24] Train loss=0.44707217812538147
[20/24] Train loss=0.3891451358795166
Test set avg_accuracy=88.93% avg_sensitivity=74.42%, avg_specificity=94.34% avg_auc=92.79%
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.432788 Test loss=0.291128 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.41583436727523804
[5/24] Train loss=0.4680768549442291
[10/24] Train loss=0.514753520488739
[15/24] Train loss=0.4223904013633728
[20/24] Train loss=0.4024996757507324
Test set avg_accuracy=88.91% avg_sensitivity=76.63%, avg_specificity=93.48% avg_auc=93.02%
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.445952 Test loss=0.284486 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4200476408004761
[5/24] Train loss=0.4300488233566284
[10/24] Train loss=0.4692058861255646
[15/24] Train loss=0.4274485409259796
[20/24] Train loss=0.36171913146972656
Test set avg_accuracy=88.72% avg_sensitivity=76.25%, avg_specificity=93.37% avg_auc=92.44%
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.425962 Test loss=0.293996 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.3840968906879425
[5/24] Train loss=0.39586392045021057
[10/24] Train loss=0.43410515785217285
[15/24] Train loss=0.41204649209976196
[20/24] Train loss=0.3416460156440735
Test set avg_accuracy=86.24% avg_sensitivity=80.71%, avg_specificity=88.30% avg_auc=91.37%
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.410287 Test loss=0.343303 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3796199858188629
[5/24] Train loss=0.3684770166873932
[10/24] Train loss=0.40308278799057007
[15/24] Train loss=0.42774561047554016
[20/24] Train loss=0.328604519367218
Test set avg_accuracy=88.72% avg_sensitivity=81.67%, avg_specificity=91.35% avg_auc=93.40%
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.401924 Test loss=0.285222 Current lr=[0.000299720220882401]

[0/24] Train loss=0.39487817883491516
[5/24] Train loss=0.408288836479187
[10/24] Train loss=0.3972867429256439
[15/24] Train loss=0.40807703137397766
[20/24] Train loss=0.33281052112579346
Test set avg_accuracy=88.02% avg_sensitivity=83.30%, avg_specificity=89.78% avg_auc=93.33%
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.400443 Test loss=0.300428 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.3666445016860962
[5/24] Train loss=0.36326849460601807
[10/24] Train loss=0.3910595178604126
[15/24] Train loss=0.39545881748199463
[20/24] Train loss=0.3450924754142761
Test set avg_accuracy=87.36% avg_sensitivity=83.01%, avg_specificity=88.97% avg_auc=92.74%
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.385546 Test loss=0.324993 Current lr=[0.000298904600941902]

[0/24] Train loss=0.38953128457069397
[5/24] Train loss=0.36301106214523315
[10/24] Train loss=0.41635847091674805
[15/24] Train loss=0.38156118988990784
[20/24] Train loss=0.35927942395210266
Test set avg_accuracy=85.25% avg_sensitivity=84.07%, avg_specificity=85.69% avg_auc=91.69%
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.392516 Test loss=0.371349 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.40343940258026123
[5/24] Train loss=0.4250418245792389
[10/24] Train loss=0.4786776602268219
[15/24] Train loss=0.4042211174964905
[20/24] Train loss=0.339629203081131
Test set avg_accuracy=88.01% avg_sensitivity=76.30%, avg_specificity=92.37% avg_auc=92.55%
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.406561 Test loss=0.308507 Current lr=[0.000297555943323901]

[0/24] Train loss=0.4115616977214813
[5/24] Train loss=0.3798390030860901
[10/24] Train loss=0.4198327660560608
[15/24] Train loss=0.38552019000053406
[20/24] Train loss=0.35140299797058105
Test set avg_accuracy=88.03% avg_sensitivity=71.79%, avg_specificity=94.09% avg_auc=91.83%
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.398318 Test loss=0.306459 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3782450556755066
[5/24] Train loss=0.34016644954681396
[10/24] Train loss=0.4004640579223633
[15/24] Train loss=0.4035860002040863
[20/24] Train loss=0.33715173602104187
Test set avg_accuracy=87.75% avg_sensitivity=82.92%, avg_specificity=89.55% avg_auc=93.04%
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.381876 Test loss=0.307708 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.364026814699173
[5/24] Train loss=0.33862489461898804
[10/24] Train loss=0.39446038007736206
[15/24] Train loss=0.3799784481525421
[20/24] Train loss=0.3401096761226654
Test set avg_accuracy=79.01% avg_sensitivity=92.42%, avg_specificity=74.02% avg_auc=91.78%
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.374186 Test loss=0.495753 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3522665202617645
[5/24] Train loss=0.31138506531715393
[10/24] Train loss=0.37699776887893677
[15/24] Train loss=0.36645612120628357
[20/24] Train loss=0.3244740068912506
Test set avg_accuracy=86.45% avg_sensitivity=83.97%, avg_specificity=87.37% avg_auc=92.54%
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.363176 Test loss=0.334730 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.37837398052215576
[5/24] Train loss=0.33041876554489136
[10/24] Train loss=0.3417626917362213
[15/24] Train loss=0.35537269711494446
[20/24] Train loss=0.324008047580719
Test set avg_accuracy=82.02% avg_sensitivity=91.36%, avg_specificity=78.54% avg_auc=93.12%
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.356062 Test loss=0.442163 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3478913903236389
[5/24] Train loss=0.3420419991016388
[10/24] Train loss=0.3479488790035248
[15/24] Train loss=0.3352123498916626
[20/24] Train loss=0.30937618017196655
Test set avg_accuracy=89.02% avg_sensitivity=79.61%, avg_specificity=92.53% avg_auc=92.67%
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.349514 Test loss=0.289916 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3332349359989166
[5/24] Train loss=0.31361690163612366
[10/24] Train loss=0.34495681524276733
[15/24] Train loss=0.35838446021080017
[20/24] Train loss=0.35394614934921265
Test set avg_accuracy=85.08% avg_sensitivity=86.56%, avg_specificity=84.52% avg_auc=92.43%
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.353968 Test loss=0.387890 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.34221071004867554
[5/24] Train loss=0.3490917980670929
[10/24] Train loss=0.35729172825813293
[15/24] Train loss=0.36843904852867126
[20/24] Train loss=0.33529579639434814
Test set avg_accuracy=56.50% avg_sensitivity=95.39%, avg_specificity=42.01% avg_auc=85.73%
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.355878 Test loss=0.934094 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.35747092962265015
[5/24] Train loss=0.34131157398223877
[10/24] Train loss=0.4034130275249481
[15/24] Train loss=0.36080941557884216
[20/24] Train loss=0.3315792977809906
Test set avg_accuracy=85.98% avg_sensitivity=87.91%, avg_specificity=85.26% avg_auc=93.73%
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.367297 Test loss=0.333465 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3695216774940491
[5/24] Train loss=0.3514246344566345
[10/24] Train loss=0.3342401087284088
[15/24] Train loss=0.35384249687194824
[20/24] Train loss=0.300712525844574
Test set avg_accuracy=80.90% avg_sensitivity=91.79%, avg_specificity=76.84% avg_auc=92.95%
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.354359 Test loss=0.449694 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.32201865315437317
[5/24] Train loss=0.2977718710899353
[10/24] Train loss=0.3377336263656616
[15/24] Train loss=0.3434813320636749
[20/24] Train loss=0.3038608729839325
Test set avg_accuracy=85.91% avg_sensitivity=84.69%, avg_specificity=86.37% avg_auc=92.43%
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.346683 Test loss=0.354798 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3272317945957184
[5/24] Train loss=0.3067198693752289
[10/24] Train loss=0.33834972977638245
[15/24] Train loss=0.35590696334838867
[20/24] Train loss=0.29145726561546326
Test set avg_accuracy=87.33% avg_sensitivity=68.43%, avg_specificity=94.37% avg_auc=90.60%
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.339866 Test loss=0.325843 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3270765244960785
[5/24] Train loss=0.2841508984565735
[10/24] Train loss=0.35894206166267395
[15/24] Train loss=0.3211159408092499
[20/24] Train loss=0.2869163155555725
Test set avg_accuracy=88.66% avg_sensitivity=82.10%, avg_specificity=91.10% avg_auc=92.15%
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.336744 Test loss=0.312549 Current lr=[0.000276307469034998]

[0/24] Train loss=0.31012770533561707
[5/24] Train loss=0.2928100526332855
[10/24] Train loss=0.3086470365524292
[15/24] Train loss=0.33099740743637085
[20/24] Train loss=0.30738064646720886
Test set avg_accuracy=86.39% avg_sensitivity=84.79%, avg_specificity=86.99% avg_auc=93.05%
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.340445 Test loss=0.328024 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.36218491196632385
[5/24] Train loss=0.3093680143356323
[10/24] Train loss=0.3430390954017639
[15/24] Train loss=0.3493398427963257
[20/24] Train loss=0.28963109850883484
Test set avg_accuracy=88.48% avg_sensitivity=73.90%, avg_specificity=93.91% avg_auc=92.42%
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.349801 Test loss=0.307889 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3516847789287567
[5/24] Train loss=0.35136282444000244
[10/24] Train loss=0.33829301595687866
[15/24] Train loss=0.37222689390182495
[20/24] Train loss=0.31972536444664
Test set avg_accuracy=85.49% avg_sensitivity=89.88%, avg_specificity=83.86% avg_auc=94.00%
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.351804 Test loss=0.355015 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3305247128009796
[5/24] Train loss=0.2961784899234772
[10/24] Train loss=0.3392212688922882
[15/24] Train loss=0.3207620084285736
[20/24] Train loss=0.2860950529575348
Test set avg_accuracy=88.02% avg_sensitivity=79.22%, avg_specificity=91.30% avg_auc=91.98%
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.328434 Test loss=0.310379 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.33357107639312744
[5/24] Train loss=0.3062112331390381
[10/24] Train loss=0.3602147102355957
[15/24] Train loss=0.32563281059265137
[20/24] Train loss=0.29924634099006653
Test set avg_accuracy=77.45% avg_sensitivity=89.11%, avg_specificity=73.11% avg_auc=89.88%
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.331804 Test loss=0.547440 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32210129499435425
[5/24] Train loss=0.28473231196403503
[10/24] Train loss=0.321210116147995
[15/24] Train loss=0.3163749873638153
[20/24] Train loss=0.28090158104896545
Test set avg_accuracy=88.42% avg_sensitivity=80.52%, avg_specificity=91.37% avg_auc=92.31%
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.321665 Test loss=0.306076 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3110418915748596
[5/24] Train loss=0.30259162187576294
[10/24] Train loss=0.311383992433548
[15/24] Train loss=0.32844895124435425
[20/24] Train loss=0.30218517780303955
Test set avg_accuracy=88.45% avg_sensitivity=80.90%, avg_specificity=91.26% avg_auc=92.69%
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.321397 Test loss=0.294390 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3223002254962921
[5/24] Train loss=0.279110312461853
[10/24] Train loss=0.3128862679004669
[15/24] Train loss=0.3160172700881958
[20/24] Train loss=0.27391287684440613
Test set avg_accuracy=88.23% avg_sensitivity=84.50%, avg_specificity=89.62% avg_auc=93.25%
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.310528 Test loss=0.306927 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3042646646499634
[5/24] Train loss=0.27780839800834656
[10/24] Train loss=0.28386807441711426
[15/24] Train loss=0.2922655940055847
[20/24] Train loss=0.27939000725746155
Test set avg_accuracy=86.28% avg_sensitivity=87.81%, avg_specificity=85.70% avg_auc=92.99%
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.300512 Test loss=0.362903 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.31494128704071045
[5/24] Train loss=0.2666283845901489
[10/24] Train loss=0.2919112741947174
[15/24] Train loss=0.31277015805244446
[20/24] Train loss=0.2765602469444275
Test set avg_accuracy=88.09% avg_sensitivity=75.91%, avg_specificity=92.62% avg_auc=91.18%
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.312957 Test loss=0.321255 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.31675031781196594
[5/24] Train loss=0.28627949953079224
[10/24] Train loss=0.3252865672111511
[15/24] Train loss=0.30963966250419617
[20/24] Train loss=0.2854832410812378
Test set avg_accuracy=88.28% avg_sensitivity=83.88%, avg_specificity=89.92% avg_auc=93.17%
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.309424 Test loss=0.305766 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.30270707607269287
[5/24] Train loss=0.2990249991416931
[10/24] Train loss=0.28643056750297546
[15/24] Train loss=0.3146743178367615
[20/24] Train loss=0.2747221887111664
Test set avg_accuracy=88.12% avg_sensitivity=75.72%, avg_specificity=92.74% avg_auc=91.87%
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.301450 Test loss=0.306010 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2986510396003723
[5/24] Train loss=0.29826420545578003
[10/24] Train loss=0.3311154246330261
[15/24] Train loss=0.308499276638031
[20/24] Train loss=0.2734734117984772
Test set avg_accuracy=88.36% avg_sensitivity=82.25%, avg_specificity=90.64% avg_auc=92.35%
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.301227 Test loss=0.306068 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.29065775871276855
[5/24] Train loss=0.26271119713783264
[10/24] Train loss=0.27144134044647217
[15/24] Train loss=0.275233656167984
[20/24] Train loss=0.2736546993255615
Test set avg_accuracy=88.87% avg_sensitivity=82.44%, avg_specificity=91.26% avg_auc=93.27%
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.284843 Test loss=0.298021 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.30328497290611267
[5/24] Train loss=0.2634456157684326
[10/24] Train loss=0.29948025941848755
[15/24] Train loss=0.3066945970058441
[20/24] Train loss=0.26771804690361023
Test set avg_accuracy=88.48% avg_sensitivity=74.90%, avg_specificity=93.53% avg_auc=91.20%
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.289809 Test loss=0.313765 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.28633061051368713
[5/24] Train loss=0.2945573627948761
[10/24] Train loss=0.27780672907829285
[15/24] Train loss=0.28126347064971924
[20/24] Train loss=0.25560855865478516
Test set avg_accuracy=87.89% avg_sensitivity=82.39%, avg_specificity=89.94% avg_auc=92.83%
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.278941 Test loss=0.318960 Current lr=[0.000224838296036774]

[0/24] Train loss=0.2770911157131195
[5/24] Train loss=0.26724445819854736
[10/24] Train loss=0.28072866797447205
[15/24] Train loss=0.2903096079826355
[20/24] Train loss=0.2686424255371094
Test set avg_accuracy=86.09% avg_sensitivity=85.36%, avg_specificity=86.37% avg_auc=92.21%
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.285152 Test loss=0.353997 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.28421446681022644
[5/24] Train loss=0.2734776735305786
[10/24] Train loss=0.29052793979644775
[15/24] Train loss=0.26965925097465515
[20/24] Train loss=0.24821627140045166
Test set avg_accuracy=86.81% avg_sensitivity=83.73%, avg_specificity=87.96% avg_auc=92.35%
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.281480 Test loss=0.341722 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.27564796805381775
[5/24] Train loss=0.2553991973400116
[10/24] Train loss=0.27863797545433044
[15/24] Train loss=0.26637861132621765
[20/24] Train loss=0.2673156261444092
Test set avg_accuracy=88.59% avg_sensitivity=81.19%, avg_specificity=91.35% avg_auc=92.54%
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.281724 Test loss=0.314085 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.28500404953956604
[5/24] Train loss=0.2650418281555176
[10/24] Train loss=0.250009149312973
[15/24] Train loss=0.2818889021873474
[20/24] Train loss=0.2506674826145172
Test set avg_accuracy=87.03% avg_sensitivity=85.84%, avg_specificity=87.47% avg_auc=92.95%
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.278341 Test loss=0.345015 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.27718585729599
[5/24] Train loss=0.2488856017589569
[10/24] Train loss=0.25717514753341675
[15/24] Train loss=0.2804977297782898
[20/24] Train loss=0.24462077021598816
Test set avg_accuracy=88.24% avg_sensitivity=82.87%, avg_specificity=90.24% avg_auc=93.19%
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.272911 Test loss=0.309315 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2552490830421448
[5/24] Train loss=0.25173330307006836
[10/24] Train loss=0.2692759335041046
[15/24] Train loss=0.27060431241989136
[20/24] Train loss=0.2690660357475281
Test set avg_accuracy=85.13% avg_sensitivity=88.10%, avg_specificity=84.02% avg_auc=92.77%
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.274013 Test loss=0.391526 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2671370506286621
[5/24] Train loss=0.2420009970664978
[10/24] Train loss=0.2666967809200287
[15/24] Train loss=0.28127166628837585
[20/24] Train loss=0.27468013763427734
Test set avg_accuracy=87.47% avg_sensitivity=81.81%, avg_specificity=89.58% avg_auc=92.41%
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.272888 Test loss=0.332117 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.27829742431640625
[5/24] Train loss=0.2570750415325165
[10/24] Train loss=0.2678418755531311
[15/24] Train loss=0.26977866888046265
[20/24] Train loss=0.25365740060806274
Test set avg_accuracy=88.06% avg_sensitivity=81.81%, avg_specificity=90.39% avg_auc=92.82%
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.268823 Test loss=0.315553 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.27519094944000244
[5/24] Train loss=0.2400340735912323
[10/24] Train loss=0.2643521726131439
[15/24] Train loss=0.27323850989341736
[20/24] Train loss=0.2362363338470459
Test set avg_accuracy=89.08% avg_sensitivity=82.68%, avg_specificity=91.46% avg_auc=93.11%
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.265198 Test loss=0.303677 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.255481094121933
[5/24] Train loss=0.23977993428707123
[10/24] Train loss=0.24809345602989197
[15/24] Train loss=0.24961620569229126
[20/24] Train loss=0.2411482334136963
Test set avg_accuracy=87.50% avg_sensitivity=83.11%, avg_specificity=89.14% avg_auc=92.13%
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.258181 Test loss=0.338601 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2659442126750946
[5/24] Train loss=0.23972095549106598
[10/24] Train loss=0.25508689880371094
[15/24] Train loss=0.24399876594543457
[20/24] Train loss=0.23602788150310516
Test set avg_accuracy=88.49% avg_sensitivity=81.81%, avg_specificity=90.98% avg_auc=92.78%
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.257511 Test loss=0.310410 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2549392879009247
[5/24] Train loss=0.23872686922550201
[10/24] Train loss=0.2596624195575714
[15/24] Train loss=0.24490170180797577
[20/24] Train loss=0.23743532598018646
Test set avg_accuracy=88.24% avg_sensitivity=79.41%, avg_specificity=91.53% avg_auc=91.82%
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.257759 Test loss=0.318502 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.24489805102348328
[5/24] Train loss=0.24683476984500885
[10/24] Train loss=0.2335762232542038
[15/24] Train loss=0.24326713383197784
[20/24] Train loss=0.2379445880651474
Test set avg_accuracy=87.41% avg_sensitivity=73.13%, avg_specificity=92.73% avg_auc=91.76%
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.253237 Test loss=0.325010 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.259592741727829
[5/24] Train loss=0.22513101994991302
[10/24] Train loss=0.2316284030675888
[15/24] Train loss=0.25456932187080383
[20/24] Train loss=0.23429368436336517
Test set avg_accuracy=88.75% avg_sensitivity=80.09%, avg_specificity=91.98% avg_auc=92.76%
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.251090 Test loss=0.299638 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24980448186397552
[5/24] Train loss=0.2598062753677368
[10/24] Train loss=0.25468602776527405
[15/24] Train loss=0.24338126182556152
[20/24] Train loss=0.23498110473155975
Test set avg_accuracy=88.57% avg_sensitivity=82.97%, avg_specificity=90.65% avg_auc=93.13%
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.256056 Test loss=0.313981 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.24354170262813568
[5/24] Train loss=0.24474790692329407
[10/24] Train loss=0.23270611464977264
[15/24] Train loss=0.24478062987327576
[20/24] Train loss=0.23257382214069366
Test set avg_accuracy=88.07% avg_sensitivity=72.17%, avg_specificity=94.00% avg_auc=91.93%
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.256229 Test loss=0.313404 Current lr=[0.000156543481933168]

[0/24] Train loss=0.24831299483776093
[5/24] Train loss=0.24684736132621765
[10/24] Train loss=0.2604052722454071
[15/24] Train loss=0.22801844775676727
[20/24] Train loss=0.23834875226020813
Test set avg_accuracy=88.55% avg_sensitivity=85.03%, avg_specificity=89.87% avg_auc=93.37%
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.258425 Test loss=0.308537 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.25083377957344055
[5/24] Train loss=0.23021425306797028
[10/24] Train loss=0.2307755947113037
[15/24] Train loss=0.2541288435459137
[20/24] Train loss=0.23214827477931976
Test set avg_accuracy=89.10% avg_sensitivity=79.80%, avg_specificity=92.57% avg_auc=92.95%
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.245254 Test loss=0.292325 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.2417604923248291
[5/24] Train loss=0.24666307866573334
[10/24] Train loss=0.22324788570404053
[15/24] Train loss=0.22152772545814514
[20/24] Train loss=0.2301694005727768
Test set avg_accuracy=89.21% avg_sensitivity=82.05%, avg_specificity=91.87% avg_auc=93.06%
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.235829 Test loss=0.300556 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2500183880329132
[5/24] Train loss=0.22476904094219208
[10/24] Train loss=0.24078577756881714
[15/24] Train loss=0.22190579771995544
[20/24] Train loss=0.22337259352207184
Test set avg_accuracy=88.89% avg_sensitivity=85.17%, avg_specificity=90.28% avg_auc=93.33%
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.237687 Test loss=0.309442 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.24923284351825714
[5/24] Train loss=0.2129770666360855
[10/24] Train loss=0.21086332201957703
[15/24] Train loss=0.21727964282035828
[20/24] Train loss=0.2118317037820816
Test set avg_accuracy=87.84% avg_sensitivity=86.18%, avg_specificity=88.46% avg_auc=93.56%
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.233413 Test loss=0.324951 Current lr=[0.000134135431043539]

[0/24] Train loss=0.23855239152908325
[5/24] Train loss=0.21823346614837646
[10/24] Train loss=0.21285204589366913
[15/24] Train loss=0.23300758004188538
[20/24] Train loss=0.21860039234161377
Test set avg_accuracy=88.29% avg_sensitivity=81.43%, avg_specificity=90.85% avg_auc=91.93%
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.232698 Test loss=0.330663 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.24020153284072876
[5/24] Train loss=0.22517457604408264
[10/24] Train loss=0.2181844860315323
[15/24] Train loss=0.21281951665878296
[20/24] Train loss=0.21006225049495697
Test set avg_accuracy=88.79% avg_sensitivity=83.40%, avg_specificity=90.80% avg_auc=93.50%
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.225647 Test loss=0.308299 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2234986573457718
[5/24] Train loss=0.22340960800647736
[10/24] Train loss=0.2153170108795166
[15/24] Train loss=0.2122224122285843
[20/24] Train loss=0.2089272290468216
Test set avg_accuracy=88.98% avg_sensitivity=81.57%, avg_specificity=91.74% avg_auc=92.91%
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.223747 Test loss=0.304107 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.22094403207302094
[5/24] Train loss=0.19933831691741943
[10/24] Train loss=0.2310875952243805
[15/24] Train loss=0.20353254675865173
[20/24] Train loss=0.20990146696567535
Test set avg_accuracy=88.58% avg_sensitivity=83.54%, avg_specificity=90.46% avg_auc=93.13%
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.217100 Test loss=0.310648 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.2163345068693161
[5/24] Train loss=0.20984092354774475
[10/24] Train loss=0.20320232212543488
[15/24] Train loss=0.19646693766117096
[20/24] Train loss=0.21237927675247192
Test set avg_accuracy=88.72% avg_sensitivity=84.50%, avg_specificity=90.30% avg_auc=93.29%
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.212759 Test loss=0.310702 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.21580007672309875
[5/24] Train loss=0.20055727660655975
[10/24] Train loss=0.20402741432189941
[15/24] Train loss=0.2000926285982132
[20/24] Train loss=0.20333823561668396
Test set avg_accuracy=88.26% avg_sensitivity=84.50%, avg_specificity=89.65% avg_auc=93.02%
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.210581 Test loss=0.323762 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.21111172437667847
[5/24] Train loss=0.20618866384029388
[10/24] Train loss=0.2016666829586029
[15/24] Train loss=0.19302988052368164
[20/24] Train loss=0.2014656662940979
Test set avg_accuracy=88.97% avg_sensitivity=81.05%, avg_specificity=91.92% avg_auc=92.36%
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.208510 Test loss=0.305101 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.22568847239017487
[5/24] Train loss=0.20258815586566925
[10/24] Train loss=0.20428615808486938
[15/24] Train loss=0.19666068255901337
[20/24] Train loss=0.1959361881017685
Test set avg_accuracy=89.44% avg_sensitivity=80.81%, avg_specificity=92.66% avg_auc=92.65%
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.211516 Test loss=0.302403 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.2086823284626007
[5/24] Train loss=0.20132507383823395
[10/24] Train loss=0.19966132938861847
[15/24] Train loss=0.1947994977235794
[20/24] Train loss=0.1998506635427475
Test set avg_accuracy=88.68% avg_sensitivity=84.40%, avg_specificity=90.28% avg_auc=93.21%
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.205841 Test loss=0.312857 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.21253998577594757
[5/24] Train loss=0.19573791325092316
[10/24] Train loss=0.18638677895069122
[15/24] Train loss=0.18539808690547943
[20/24] Train loss=0.19380322098731995
Test set avg_accuracy=88.88% avg_sensitivity=83.40%, avg_specificity=90.92% avg_auc=93.06%
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.202867 Test loss=0.311918 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2055184692144394
[5/24] Train loss=0.20144310593605042
[10/24] Train loss=0.1947408765554428
[15/24] Train loss=0.19277030229568481
[20/24] Train loss=0.19799475371837616
Test set avg_accuracy=88.49% avg_sensitivity=85.22%, avg_specificity=89.71% avg_auc=92.98%
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.198610 Test loss=0.321520 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.1985730528831482
[5/24] Train loss=0.19097355008125305
[10/24] Train loss=0.18817737698554993
[15/24] Train loss=0.18247662484645844
[20/24] Train loss=0.19208933413028717
Test set avg_accuracy=88.95% avg_sensitivity=83.93%, avg_specificity=90.81% avg_auc=93.01%
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.196285 Test loss=0.312589 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.20007680356502533
[5/24] Train loss=0.18472272157669067
[10/24] Train loss=0.17874664068222046
[15/24] Train loss=0.1855555772781372
[20/24] Train loss=0.1954224407672882
Test set avg_accuracy=88.55% avg_sensitivity=85.56%, avg_specificity=89.67% avg_auc=93.31%
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.192650 Test loss=0.316722 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.20008553564548492
[5/24] Train loss=0.18280132114887238
[10/24] Train loss=0.1824352741241455
[15/24] Train loss=0.18330565094947815
[20/24] Train loss=0.1795085072517395
Test set avg_accuracy=88.75% avg_sensitivity=83.01%, avg_specificity=90.89% avg_auc=92.68%
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.192133 Test loss=0.315098 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.18963976204395294
[5/24] Train loss=0.18659961223602295
[10/24] Train loss=0.18675494194030762
[15/24] Train loss=0.17545866966247559
[20/24] Train loss=0.19375698268413544
Test set avg_accuracy=88.57% avg_sensitivity=84.26%, avg_specificity=90.17% avg_auc=92.95%
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.189828 Test loss=0.318464 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18759362399578094
[5/24] Train loss=0.18785636126995087
[10/24] Train loss=0.17914406955242157
[15/24] Train loss=0.1790640950202942
[20/24] Train loss=0.18464910984039307
Test set avg_accuracy=88.41% avg_sensitivity=83.59%, avg_specificity=90.21% avg_auc=92.95%
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.189299 Test loss=0.321007 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.18882498145103455
[5/24] Train loss=0.18997567892074585
[10/24] Train loss=0.1757649928331375
[15/24] Train loss=0.17671361565589905
[20/24] Train loss=0.1819472461938858
Test set avg_accuracy=88.29% avg_sensitivity=83.16%, avg_specificity=90.21% avg_auc=92.65%
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.187121 Test loss=0.320642 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.18391861021518707
[5/24] Train loss=0.17509666085243225
[10/24] Train loss=0.18457891047000885
[15/24] Train loss=0.17108303308486938
[20/24] Train loss=0.18516185879707336
Test set avg_accuracy=88.63% avg_sensitivity=83.97%, avg_specificity=90.37% avg_auc=92.87%
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.183125 Test loss=0.320357 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.18918514251708984
[5/24] Train loss=0.18286888301372528
[10/24] Train loss=0.1785689741373062
[15/24] Train loss=0.1725083440542221
[20/24] Train loss=0.1768907904624939
Test set avg_accuracy=88.88% avg_sensitivity=83.21%, avg_specificity=90.99% avg_auc=92.71%
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.184131 Test loss=0.314131 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.18615812063217163
[5/24] Train loss=0.1819951832294464
[10/24] Train loss=0.17559023201465607
[15/24] Train loss=0.17334026098251343
[20/24] Train loss=0.17570215463638306
Test set avg_accuracy=88.31% avg_sensitivity=85.08%, avg_specificity=89.51% avg_auc=92.76%
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.183622 Test loss=0.333700 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18258191645145416
[5/24] Train loss=0.16798020899295807
[10/24] Train loss=0.17123863101005554
[15/24] Train loss=0.17137576639652252
[20/24] Train loss=0.17088715732097626
Test set avg_accuracy=88.39% avg_sensitivity=84.74%, avg_specificity=89.74% avg_auc=92.73%
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.180930 Test loss=0.326242 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.18051396310329437
[5/24] Train loss=0.17444729804992676
[10/24] Train loss=0.1709343045949936
[15/24] Train loss=0.16744691133499146
[20/24] Train loss=0.17077617347240448
Test set avg_accuracy=88.49% avg_sensitivity=85.03%, avg_specificity=89.78% avg_auc=92.65%
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.180180 Test loss=0.326276 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.18040695786476135
[5/24] Train loss=0.17575962841510773
[10/24] Train loss=0.1703362762928009
[15/24] Train loss=0.16978462040424347
[20/24] Train loss=0.17315813899040222
Test set avg_accuracy=88.96% avg_sensitivity=84.02%, avg_specificity=90.80% avg_auc=92.60%
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.178493 Test loss=0.315588 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.17495658993721008
[5/24] Train loss=0.17280519008636475
[10/24] Train loss=0.17195813357830048
[15/24] Train loss=0.1732548177242279
[20/24] Train loss=0.16644181311130524
Test set avg_accuracy=88.79% avg_sensitivity=83.11%, avg_specificity=90.90% avg_auc=92.45%
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.177659 Test loss=0.317559 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.17468830943107605
[5/24] Train loss=0.1847112625837326
[10/24] Train loss=0.16858945786952972
[15/24] Train loss=0.17309489846229553
[20/24] Train loss=0.17195190489292145
Test set avg_accuracy=89.15% avg_sensitivity=82.68%, avg_specificity=91.57% avg_auc=92.80%
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.177237 Test loss=0.309676 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.17437522113323212
[5/24] Train loss=0.1790744960308075
[10/24] Train loss=0.16772636771202087
[15/24] Train loss=0.17322909832000732
[20/24] Train loss=0.16598567366600037
Test set avg_accuracy=88.93% avg_sensitivity=83.35%, avg_specificity=91.01% avg_auc=92.92%
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.176390 Test loss=0.309317 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.16948962211608887
[5/24] Train loss=0.17682933807373047
[10/24] Train loss=0.16639459133148193
[15/24] Train loss=0.16755959391593933
[20/24] Train loss=0.17031854391098022
Test set avg_accuracy=89.11% avg_sensitivity=84.21%, avg_specificity=90.94% avg_auc=92.77%
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.177037 Test loss=0.310626 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.16875013709068298
[5/24] Train loss=0.17145761847496033
[10/24] Train loss=0.1776576191186905
[15/24] Train loss=0.15944239497184753
[20/24] Train loss=0.17740871012210846
Test set avg_accuracy=89.02% avg_sensitivity=83.64%, avg_specificity=91.03% avg_auc=93.10%
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.178927 Test loss=0.310823 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.17998576164245605
[5/24] Train loss=0.16533178091049194
[10/24] Train loss=0.1884012222290039
[15/24] Train loss=0.16726961731910706
[20/24] Train loss=0.18154218792915344
Test set avg_accuracy=88.85% avg_sensitivity=83.16%, avg_specificity=90.98% avg_auc=92.94%
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.181711 Test loss=0.315797 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.18591278791427612
[5/24] Train loss=0.16516005992889404
[10/24] Train loss=0.17101697623729706
[15/24] Train loss=0.17756523191928864
[20/24] Train loss=0.16493746638298035
Test set avg_accuracy=89.21% avg_sensitivity=83.35%, avg_specificity=91.39% avg_auc=93.19%
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.178637 Test loss=0.307212 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1686878502368927
[5/24] Train loss=0.17507964372634888
[10/24] Train loss=0.16479486227035522
[15/24] Train loss=0.16657812893390656
[20/24] Train loss=0.16136951744556427
Test set avg_accuracy=89.17% avg_sensitivity=83.16%, avg_specificity=91.40% avg_auc=92.94%
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.174769 Test loss=0.305984 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1676938831806183
[5/24] Train loss=0.16678127646446228
[10/24] Train loss=0.1641840636730194
[15/24] Train loss=0.16130253672599792
[20/24] Train loss=0.16191509366035461
Test set avg_accuracy=89.08% avg_sensitivity=83.78%, avg_specificity=91.05% avg_auc=93.19%
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.169702 Test loss=0.308089 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1613469421863556
[5/24] Train loss=0.16149719059467316
[10/24] Train loss=0.15937861800193787
[15/24] Train loss=0.1627759337425232
[20/24] Train loss=0.15788285434246063
Test set avg_accuracy=89.31% avg_sensitivity=83.73%, avg_specificity=91.39% avg_auc=92.83%
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.168685 Test loss=0.308764 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.16412663459777832
[5/24] Train loss=0.16263097524642944
[10/24] Train loss=0.1619500368833542
[15/24] Train loss=0.15807951986789703
[20/24] Train loss=0.15767940878868103
Test set avg_accuracy=89.09% avg_sensitivity=84.21%, avg_specificity=90.90% avg_auc=93.01%
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.167674 Test loss=0.310612 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16817812621593475
[5/24] Train loss=0.16552624106407166
[10/24] Train loss=0.16189876198768616
[15/24] Train loss=0.1605524718761444
[20/24] Train loss=0.1603153944015503
Test set avg_accuracy=89.17% avg_sensitivity=83.78%, avg_specificity=91.17% avg_auc=92.96%
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.167018 Test loss=0.309072 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.17199701070785522
[5/24] Train loss=0.16764679551124573
[10/24] Train loss=0.15844590961933136
[15/24] Train loss=0.15711495280265808
[20/24] Train loss=0.16000884771347046
Test set avg_accuracy=89.30% avg_sensitivity=84.40%, avg_specificity=91.12% avg_auc=92.94%
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.167801 Test loss=0.309059 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16391701996326447
[5/24] Train loss=0.16062191128730774
[10/24] Train loss=0.1576155722141266
[15/24] Train loss=0.15840394794940948
[20/24] Train loss=0.15809005498886108
Test set avg_accuracy=89.17% avg_sensitivity=84.12%, avg_specificity=91.05% avg_auc=92.95%
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.166306 Test loss=0.309162 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.16592563688755035
[5/24] Train loss=0.16177819669246674
[10/24] Train loss=0.16110627353191376
[15/24] Train loss=0.15215016901493073
[20/24] Train loss=0.15769395232200623
Test set avg_accuracy=89.13% avg_sensitivity=84.55%, avg_specificity=90.83% avg_auc=93.00%
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.165465 Test loss=0.312014 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.1595076024532318
[5/24] Train loss=0.1583259403705597
[10/24] Train loss=0.16236381232738495
[15/24] Train loss=0.15393559634685516
[20/24] Train loss=0.15640218555927277
Test set avg_accuracy=89.21% avg_sensitivity=83.78%, avg_specificity=91.23% avg_auc=92.93%
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.164970 Test loss=0.309560 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.16589029133319855
[5/24] Train loss=0.1619836390018463
[10/24] Train loss=0.1581415981054306
[15/24] Train loss=0.15477842092514038
[20/24] Train loss=0.15850092470645905
Test set avg_accuracy=89.15% avg_sensitivity=83.93%, avg_specificity=91.10% avg_auc=92.99%
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.165614 Test loss=0.309196 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1641760766506195
[5/24] Train loss=0.15698793530464172
[10/24] Train loss=0.15717628598213196
[15/24] Train loss=0.15628720819950104
[20/24] Train loss=0.1560484915971756
Test set avg_accuracy=89.26% avg_sensitivity=83.69%, avg_specificity=91.33% avg_auc=92.97%
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.164607 Test loss=0.308459 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.16376376152038574
[5/24] Train loss=0.16067549586296082
[10/24] Train loss=0.15889832377433777
[15/24] Train loss=0.1587621122598648
[20/24] Train loss=0.16149447858333588
Test set avg_accuracy=89.21% avg_sensitivity=83.97%, avg_specificity=91.15% avg_auc=93.01%
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.164690 Test loss=0.309919 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.15964572131633759
[5/24] Train loss=0.15780815482139587
[10/24] Train loss=0.15557268261909485
[15/24] Train loss=0.15334361791610718
[20/24] Train loss=0.15534083545207977
Test set avg_accuracy=89.14% avg_sensitivity=83.93%, avg_specificity=91.08% avg_auc=92.99%
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.163437 Test loss=0.310033 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.16734439134597778
[5/24] Train loss=0.16015347838401794
[10/24] Train loss=0.15993615984916687
[15/24] Train loss=0.15762192010879517
[20/24] Train loss=0.1527995467185974
Test set avg_accuracy=89.15% avg_sensitivity=83.69%, avg_specificity=91.19% avg_auc=93.00%
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.164418 Test loss=0.309243 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16232959926128387
[5/24] Train loss=0.1584295928478241
[10/24] Train loss=0.1622951626777649
[15/24] Train loss=0.1561773121356964
[20/24] Train loss=0.15563911199569702
Test set avg_accuracy=89.23% avg_sensitivity=83.69%, avg_specificity=91.30% avg_auc=93.00%
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.164069 Test loss=0.308656 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1606609970331192
[5/24] Train loss=0.15701282024383545
[10/24] Train loss=0.15576888620853424
[15/24] Train loss=0.15133102238178253
[20/24] Train loss=0.15710727870464325
Test set avg_accuracy=89.19% avg_sensitivity=83.69%, avg_specificity=91.24% avg_auc=93.00%
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.163544 Test loss=0.308769 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16064898669719696
[5/24] Train loss=0.1608351469039917
[10/24] Train loss=0.15893828868865967
[15/24] Train loss=0.15213076770305634
[20/24] Train loss=0.15389636158943176
Test set avg_accuracy=89.15% avg_sensitivity=83.64%, avg_specificity=91.21% avg_auc=93.00%
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.163382 Test loss=0.309267 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.1648227423429489
[5/24] Train loss=0.15922144055366516
[10/24] Train loss=0.1592588871717453
[15/24] Train loss=0.15550775825977325
[20/24] Train loss=0.157021164894104
Test set avg_accuracy=89.17% avg_sensitivity=83.69%, avg_specificity=91.21% avg_auc=93.00%
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.163819 Test loss=0.309024 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1607423573732376
[5/24] Train loss=0.15811268985271454
[10/24] Train loss=0.15622998774051666
[15/24] Train loss=0.15777607262134552
[20/24] Train loss=0.15699848532676697
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.15% avg_sensitivity=83.69%, avg_specificity=91.19% avg_auc=93.00%
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.163298 Test loss=0.309047 Current lr=[1.3165623068326024e-09]

Fold[6] Result: acc=88.36% sen=87.38%, spe=88.72%, auc=94.63%!
Fold[6] Avg_overlap=0.69%(0.22339167747258196)
[0/24] Train loss=1.4870960712432861
[5/24] Train loss=1.4656721353530884
[10/24] Train loss=1.456548810005188
[15/24] Train loss=1.416351079940796
[20/24] Train loss=1.3993847370147705
Test set avg_accuracy=56.60% avg_sensitivity=49.79%, avg_specificity=59.20% avg_auc=57.21%
Best model saved!! Metric=-103.20232209013969!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=1.448325 Test loss=0.674759 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.4195233583450317
[5/24] Train loss=1.3981372117996216
[10/24] Train loss=1.3846896886825562
[15/24] Train loss=1.3547559976577759
[20/24] Train loss=1.3314504623413086
Test set avg_accuracy=65.42% avg_sensitivity=63.74%, avg_specificity=66.06% avg_auc=70.80%
Best model saved!! Metric=-59.98657178376845!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=1.377799 Test loss=0.623522 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.32262122631073
[5/24] Train loss=1.3200737237930298
[10/24] Train loss=1.3299307823181152
[15/24] Train loss=1.2753336429595947
[20/24] Train loss=1.257838487625122
Test set avg_accuracy=69.05% avg_sensitivity=73.31%, avg_specificity=67.42% avg_auc=77.36%
Best model saved!! Metric=-38.855136011526795!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=1.308447 Test loss=0.591964 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2692643404006958
[5/24] Train loss=1.2431467771530151
[10/24] Train loss=1.251400351524353
[15/24] Train loss=1.1975558996200562
[20/24] Train loss=1.172075867652893
Test set avg_accuracy=71.80% avg_sensitivity=78.36%, avg_specificity=69.29% avg_auc=80.96%
Best model saved!! Metric=-25.594925732767763!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=1.235784 Test loss=0.565390 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1840732097625732
[5/24] Train loss=1.1825083494186401
[10/24] Train loss=1.2026658058166504
[15/24] Train loss=1.1205010414123535
[20/24] Train loss=1.1092329025268555
Test set avg_accuracy=74.39% avg_sensitivity=82.08%, avg_specificity=71.45% avg_auc=83.83%
Best model saved!! Metric=-14.243529500791894!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=1.166517 Test loss=0.539644 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1093730926513672
[5/24] Train loss=1.0968084335327148
[10/24] Train loss=1.1414955854415894
[15/24] Train loss=1.038299322128296
[20/24] Train loss=1.0338488817214966
Test set avg_accuracy=76.54% avg_sensitivity=84.11%, avg_specificity=73.65% avg_auc=86.20%
Best model saved!! Metric=-5.507832395947759!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=1.098763 Test loss=0.512365 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0403437614440918
[5/24] Train loss=1.0257112979888916
[10/24] Train loss=1.0738739967346191
[15/24] Train loss=0.9782146215438843
[20/24] Train loss=0.9623700976371765
Test set avg_accuracy=78.76% avg_sensitivity=85.53%, avg_specificity=76.18% avg_auc=88.39%
Best model saved!! Metric=2.8599833474091128!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=1.040561 Test loss=0.481507 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9823586940765381
[5/24] Train loss=0.9791427850723267
[10/24] Train loss=1.027956485748291
[15/24] Train loss=0.9241254925727844
[20/24] Train loss=0.9116361737251282
Test set avg_accuracy=80.42% avg_sensitivity=86.85%, avg_specificity=77.96% avg_auc=90.22%
Best model saved!! Metric=9.447895254023138!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.982723 Test loss=0.451065 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9336557388305664
[5/24] Train loss=0.9053734540939331
[10/24] Train loss=0.9591206312179565
[15/24] Train loss=0.8691169023513794
[20/24] Train loss=0.8564256429672241
Test set avg_accuracy=82.37% avg_sensitivity=86.47%, avg_specificity=80.81% avg_auc=91.61%
Best model saved!! Metric=15.25394544323467!!
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.929557 Test loss=0.419019 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8969706892967224
[5/24] Train loss=0.8546464443206787
[10/24] Train loss=0.909648597240448
[15/24] Train loss=0.828901469707489
[20/24] Train loss=0.8020140528678894
Test set avg_accuracy=83.98% avg_sensitivity=86.47%, avg_specificity=83.04% avg_auc=92.68%
Best model saved!! Metric=20.170652605480072!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.881319 Test loss=0.391866 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8374993801116943
[5/24] Train loss=0.8158903121948242
[10/24] Train loss=0.8698329329490662
[15/24] Train loss=0.7929826378822327
[20/24] Train loss=0.7508987784385681
Test set avg_accuracy=85.16% avg_sensitivity=86.56%, avg_specificity=84.62% avg_auc=93.40%
Best model saved!! Metric=23.738441007629007!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.839074 Test loss=0.375036 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7932493090629578
[5/24] Train loss=0.7747692465782166
[10/24] Train loss=0.8186202049255371
[15/24] Train loss=0.7593019008636475
[20/24] Train loss=0.7148839235305786
Test set avg_accuracy=86.24% avg_sensitivity=86.04%, avg_specificity=86.31% avg_auc=93.99%
Best model saved!! Metric=26.586669798361882!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.799184 Test loss=0.350064 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7598418593406677
[5/24] Train loss=0.7347595691680908
[10/24] Train loss=0.7967897653579712
[15/24] Train loss=0.7262835502624512
[20/24] Train loss=0.689011812210083
Test set avg_accuracy=87.30% avg_sensitivity=83.50%, avg_specificity=88.76% avg_auc=94.22%
Best model saved!! Metric=27.784409252145934!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.769490 Test loss=0.327851 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7313151955604553
[5/24] Train loss=0.6993570327758789
[10/24] Train loss=0.7785181999206543
[15/24] Train loss=0.7072886228561401
[20/24] Train loss=0.6543973088264465
Test set avg_accuracy=87.92% avg_sensitivity=84.54%, avg_specificity=89.21% avg_auc=94.58%
Best model saved!! Metric=30.2353981620504!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.742759 Test loss=0.315640 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7100534439086914
[5/24] Train loss=0.6991930603981018
[10/24] Train loss=0.760011613368988
[15/24] Train loss=0.6945000290870667
[20/24] Train loss=0.6550073623657227
Test set avg_accuracy=88.22% avg_sensitivity=85.48%, avg_specificity=89.26% avg_auc=94.86%
Best model saved!! Metric=31.810618193991644!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.722755 Test loss=0.305014 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6737897396087646
[5/24] Train loss=0.6603348255157471
[10/24] Train loss=0.741499662399292
[15/24] Train loss=0.66915363073349
[20/24] Train loss=0.6177259087562561
Test set avg_accuracy=88.22% avg_sensitivity=86.00%, avg_specificity=89.06% avg_auc=95.17%
Best model saved!! Metric=32.44229727431971!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.699214 Test loss=0.299778 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6753585934638977
[5/24] Train loss=0.6454283595085144
[10/24] Train loss=0.7064267992973328
[15/24] Train loss=0.6515021324157715
[20/24] Train loss=0.590548038482666
Test set avg_accuracy=88.49% avg_sensitivity=84.96%, avg_specificity=89.84% avg_auc=95.20%
Best model saved!! Metric=32.48528500819589!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.682775 Test loss=0.289617 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6416070461273193
[5/24] Train loss=0.6196861863136292
[10/24] Train loss=0.7083656787872314
[15/24] Train loss=0.6437744498252869
[20/24] Train loss=0.5848524570465088
Test set avg_accuracy=87.66% avg_sensitivity=88.40%, avg_specificity=87.37% avg_auc=95.32%
Best model saved!! Metric=32.74816452643067!!
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.667750 Test loss=0.304388 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6351646780967712
[5/24] Train loss=0.6105095148086548
[10/24] Train loss=0.6819071173667908
[15/24] Train loss=0.6323482394218445
[20/24] Train loss=0.5571224689483643
Test set avg_accuracy=88.49% avg_sensitivity=84.58%, avg_specificity=89.98% avg_auc=95.23%
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.653424 Test loss=0.283256 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6260108351707458
[5/24] Train loss=0.5893794298171997
[10/24] Train loss=0.7040209770202637
[15/24] Train loss=0.6153619289398193
[20/24] Train loss=0.5596232414245605
Test set avg_accuracy=87.51% avg_sensitivity=88.50%, avg_specificity=87.14% avg_auc=95.22%
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.640039 Test loss=0.304392 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.61334627866745
[5/24] Train loss=0.5962056517601013
[10/24] Train loss=0.6516934037208557
[15/24] Train loss=0.6138567924499512
[20/24] Train loss=0.5420525670051575
Test set avg_accuracy=88.23% avg_sensitivity=86.09%, avg_specificity=89.04% avg_auc=95.18%
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.631831 Test loss=0.285976 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.6007700562477112
[5/24] Train loss=0.5689929127693176
[10/24] Train loss=0.6571018099784851
[15/24] Train loss=0.6008111834526062
[20/24] Train loss=0.5320016741752625
Test set avg_accuracy=87.51% avg_sensitivity=87.65%, avg_specificity=87.46% avg_auc=95.26%
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.617394 Test loss=0.298683 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5955995321273804
[5/24] Train loss=0.5598281025886536
[10/24] Train loss=0.6502300500869751
[15/24] Train loss=0.5889914631843567
[20/24] Train loss=0.5231490731239319
Test set avg_accuracy=87.37% avg_sensitivity=88.64%, avg_specificity=86.89% avg_auc=95.29%
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.608051 Test loss=0.300210 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5760328769683838
[5/24] Train loss=0.5419132709503174
[10/24] Train loss=0.6210504174232483
[15/24] Train loss=0.5690963864326477
[20/24] Train loss=0.5111445784568787
Test set avg_accuracy=88.31% avg_sensitivity=85.71%, avg_specificity=89.30% avg_auc=95.24%
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.592325 Test loss=0.275858 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5651081204414368
[5/24] Train loss=0.5298306941986084
[10/24] Train loss=0.6219715476036072
[15/24] Train loss=0.5574728846549988
[20/24] Train loss=0.5034787654876709
Test set avg_accuracy=88.80% avg_sensitivity=84.06%, avg_specificity=90.61% avg_auc=95.10%
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.582945 Test loss=0.270487 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5621017217636108
[5/24] Train loss=0.5197927355766296
[10/24] Train loss=0.6134854555130005
[15/24] Train loss=0.5509243011474609
[20/24] Train loss=0.4909110963344574
Test set avg_accuracy=88.71% avg_sensitivity=86.56%, avg_specificity=89.53% avg_auc=95.58%
Best model saved!! Metric=34.380598491232135!!
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.573833 Test loss=0.271243 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5328996181488037
[5/24] Train loss=0.4926152229309082
[10/24] Train loss=0.6001461148262024
[15/24] Train loss=0.5454286932945251
[20/24] Train loss=0.4923849403858185
Test set avg_accuracy=87.79% avg_sensitivity=85.67%, avg_specificity=88.60% avg_auc=94.71%
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.562349 Test loss=0.296312 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.529008150100708
[5/24] Train loss=0.4971004128456116
[10/24] Train loss=0.6102264523506165
[15/24] Train loss=0.5382062792778015
[20/24] Train loss=0.5032342672348022
Test set avg_accuracy=88.62% avg_sensitivity=84.02%, avg_specificity=90.38% avg_auc=95.31%
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.554103 Test loss=0.264375 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5173530578613281
[5/24] Train loss=0.47485601902008057
[10/24] Train loss=0.5855656266212463
[15/24] Train loss=0.5206956267356873
[20/24] Train loss=0.48208683729171753
Test set avg_accuracy=87.68% avg_sensitivity=67.00%, avg_specificity=95.57% avg_auc=93.65%
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.544036 Test loss=0.286254 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.5501304864883423
[5/24] Train loss=0.47991952300071716
[10/24] Train loss=0.5731704831123352
[15/24] Train loss=0.5104180574417114
[20/24] Train loss=0.46708500385284424
Test set avg_accuracy=88.88% avg_sensitivity=82.08%, avg_specificity=91.47% avg_auc=94.99%
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.538060 Test loss=0.262863 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.5112069845199585
[5/24] Train loss=0.4581248462200165
[10/24] Train loss=0.5757920145988464
[15/24] Train loss=0.5403998494148254
[20/24] Train loss=0.4376145005226135
Test set avg_accuracy=89.14% avg_sensitivity=79.59%, avg_specificity=92.79% avg_auc=95.16%
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.521050 Test loss=0.255214 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5097038745880127
[5/24] Train loss=0.4585248529911041
[10/24] Train loss=0.5311859846115112
[15/24] Train loss=0.5330860614776611
[20/24] Train loss=0.45771342515945435
Test set avg_accuracy=87.51% avg_sensitivity=66.81%, avg_specificity=95.41% avg_auc=93.48%
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.513120 Test loss=0.295633 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.5025774836540222
[5/24] Train loss=0.46104153990745544
[10/24] Train loss=0.5726580023765564
[15/24] Train loss=0.5279544591903687
[20/24] Train loss=0.45807960629463196
Test set avg_accuracy=87.19% avg_sensitivity=91.28%, avg_specificity=85.63% avg_auc=95.59%
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.511940 Test loss=0.303161 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.477890282869339
[5/24] Train loss=0.4303492307662964
[10/24] Train loss=0.4997588098049164
[15/24] Train loss=0.5172998905181885
[20/24] Train loss=0.4630412459373474
Test set avg_accuracy=86.37% avg_sensitivity=90.10%, avg_specificity=84.94% avg_auc=95.30%
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.493591 Test loss=0.307756 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.47383859753608704
[5/24] Train loss=0.39644792675971985
[10/24] Train loss=0.4852093756198883
[15/24] Train loss=0.496233195066452
[20/24] Train loss=0.45131224393844604
Test set avg_accuracy=85.03% avg_sensitivity=92.60%, avg_specificity=82.14% avg_auc=95.00%
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.482088 Test loss=0.343836 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.4654579162597656
[5/24] Train loss=0.4142741858959198
[10/24] Train loss=0.4868412911891937
[15/24] Train loss=0.4946466088294983
[20/24] Train loss=0.4378686547279358
Test set avg_accuracy=87.98% avg_sensitivity=87.03%, avg_specificity=88.34% avg_auc=95.23%
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.475697 Test loss=0.276105 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4524666666984558
[5/24] Train loss=0.3973311185836792
[10/24] Train loss=0.504353404045105
[15/24] Train loss=0.49648305773735046
[20/24] Train loss=0.4261857867240906
Test set avg_accuracy=87.80% avg_sensitivity=74.02%, avg_specificity=93.06% avg_auc=93.76%
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.472471 Test loss=0.282377 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4336473047733307
[5/24] Train loss=0.37455931305885315
[10/24] Train loss=0.5070533156394958
[15/24] Train loss=0.4667089879512787
[20/24] Train loss=0.4346695840358734
Test set avg_accuracy=84.17% avg_sensitivity=52.48%, avg_specificity=96.26% avg_auc=87.16%
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.463464 Test loss=0.414610 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.4564441740512848
[5/24] Train loss=0.3865349292755127
[10/24] Train loss=0.4916057586669922
[15/24] Train loss=0.49555519223213196
[20/24] Train loss=0.4338812530040741
Test set avg_accuracy=86.17% avg_sensitivity=69.07%, avg_specificity=92.70% avg_auc=90.89%
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.451041 Test loss=0.329962 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.46538209915161133
[5/24] Train loss=0.3703831434249878
[10/24] Train loss=0.48479461669921875
[15/24] Train loss=0.44864293932914734
[20/24] Train loss=0.4059368669986725
Test set avg_accuracy=87.86% avg_sensitivity=75.53%, avg_specificity=92.57% avg_auc=93.43%
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.445213 Test loss=0.285253 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4492950439453125
[5/24] Train loss=0.37307074666023254
[10/24] Train loss=0.4825725257396698
[15/24] Train loss=0.4826267957687378
[20/24] Train loss=0.40577080845832825
Test set avg_accuracy=88.12% avg_sensitivity=85.43%, avg_specificity=89.15% avg_auc=94.87%
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.449888 Test loss=0.278678 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.43749749660491943
[5/24] Train loss=0.4067865014076233
[10/24] Train loss=0.4800850749015808
[15/24] Train loss=0.4761961102485657
[20/24] Train loss=0.4111318290233612
Test set avg_accuracy=87.01% avg_sensitivity=68.22%, avg_specificity=94.17% avg_auc=91.56%
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.449847 Test loss=0.320335 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.42990678548812866
[5/24] Train loss=0.3708142042160034
[10/24] Train loss=0.44146808981895447
[15/24] Train loss=0.43103912472724915
[20/24] Train loss=0.4145365059375763
Test set avg_accuracy=88.19% avg_sensitivity=78.55%, avg_specificity=91.87% avg_auc=94.20%
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.438279 Test loss=0.276337 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4099603295326233
[5/24] Train loss=0.36346355080604553
[10/24] Train loss=0.5097388625144958
[15/24] Train loss=0.43784111738204956
[20/24] Train loss=0.39158686995506287
Test set avg_accuracy=87.54% avg_sensitivity=75.81%, avg_specificity=92.01% avg_auc=93.25%
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.445354 Test loss=0.293773 Current lr=[0.00029967723776099]

[0/24] Train loss=0.4338277280330658
[5/24] Train loss=0.38703227043151855
[10/24] Train loss=0.45435184240341187
[15/24] Train loss=0.44410043954849243
[20/24] Train loss=0.3943699300289154
Test set avg_accuracy=88.92% avg_sensitivity=84.11%, avg_specificity=90.75% avg_auc=95.05%
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.432169 Test loss=0.270931 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4116775095462799
[5/24] Train loss=0.3755321204662323
[10/24] Train loss=0.41112956404685974
[15/24] Train loss=0.4598601162433624
[20/24] Train loss=0.39733701944351196
Test set avg_accuracy=88.96% avg_sensitivity=86.37%, avg_specificity=89.94% avg_auc=95.28%
Best model saved!! Metric=34.55620008169193!!
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.411998 Test loss=0.269236 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.40571340918540955
[5/24] Train loss=0.34507739543914795
[10/24] Train loss=0.4250659644603729
[15/24] Train loss=0.3996022641658783
[20/24] Train loss=0.3665008842945099
Test set avg_accuracy=88.68% avg_sensitivity=81.42%, avg_specificity=91.46% avg_auc=94.63%
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.396459 Test loss=0.276635 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4031263589859009
[5/24] Train loss=0.34972047805786133
[10/24] Train loss=0.4114907383918762
[15/24] Train loss=0.39764106273651123
[20/24] Train loss=0.36595413088798523
Test set avg_accuracy=86.93% avg_sensitivity=69.54%, avg_specificity=93.56% avg_auc=92.71%
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.415546 Test loss=0.302006 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.41533681750297546
[5/24] Train loss=0.3480665981769562
[10/24] Train loss=0.4002744257450104
[15/24] Train loss=0.4365790784358978
[20/24] Train loss=0.37651029229164124
Test set avg_accuracy=88.41% avg_sensitivity=84.58%, avg_specificity=89.87% avg_auc=94.92%
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.402705 Test loss=0.276547 Current lr=[0.000298904600941902]

[0/24] Train loss=0.396534264087677
[5/24] Train loss=0.33698713779449463
[10/24] Train loss=0.39722755551338196
[15/24] Train loss=0.4046459496021271
[20/24] Train loss=0.3695921003818512
Test set avg_accuracy=87.94% avg_sensitivity=84.25%, avg_specificity=89.35% avg_auc=94.20%
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.395326 Test loss=0.286524 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.38090968132019043
[5/24] Train loss=0.3251909613609314
[10/24] Train loss=0.4504496455192566
[15/24] Train loss=0.41017287969589233
[20/24] Train loss=0.37829431891441345
Test set avg_accuracy=88.20% avg_sensitivity=72.47%, avg_specificity=94.21% avg_auc=93.16%
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.390340 Test loss=0.294301 Current lr=[0.000297555943323901]

[0/24] Train loss=0.39507123827934265
[5/24] Train loss=0.31866544485092163
[10/24] Train loss=0.409616619348526
[15/24] Train loss=0.39655840396881104
[20/24] Train loss=0.3767753839492798
Test set avg_accuracy=88.22% avg_sensitivity=88.68%, avg_specificity=88.04% avg_auc=95.34%
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.386570 Test loss=0.283798 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.3936541974544525
[5/24] Train loss=0.3372151255607605
[10/24] Train loss=0.39206433296203613
[15/24] Train loss=0.37617358565330505
[20/24] Train loss=0.34683045744895935
Test set avg_accuracy=88.48% avg_sensitivity=84.91%, avg_specificity=89.84% avg_auc=95.16%
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.384301 Test loss=0.271273 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.37714120745658875
[5/24] Train loss=0.348553329706192
[10/24] Train loss=0.4134359657764435
[15/24] Train loss=0.3934262990951538
[20/24] Train loss=0.3420392572879791
Test set avg_accuracy=87.55% avg_sensitivity=76.28%, avg_specificity=91.85% avg_auc=93.30%
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.390893 Test loss=0.300889 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.3648347556591034
[5/24] Train loss=0.3128312826156616
[10/24] Train loss=0.3980046808719635
[15/24] Train loss=0.35916048288345337
[20/24] Train loss=0.35021281242370605
Test set avg_accuracy=88.06% avg_sensitivity=86.37%, avg_specificity=88.70% avg_auc=95.06%
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.368991 Test loss=0.289121 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.36188775300979614
[5/24] Train loss=0.321637362241745
[10/24] Train loss=0.4097473919391632
[15/24] Train loss=0.3567834496498108
[20/24] Train loss=0.3300134539604187
Test set avg_accuracy=88.01% avg_sensitivity=84.77%, avg_specificity=89.24% avg_auc=94.71%
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.367128 Test loss=0.295125 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3691362142562866
[5/24] Train loss=0.3078615367412567
[10/24] Train loss=0.36676955223083496
[15/24] Train loss=0.36665472388267517
[20/24] Train loss=0.32981428503990173
Test set avg_accuracy=85.96% avg_sensitivity=89.16%, avg_specificity=84.75% avg_auc=94.70%
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.361730 Test loss=0.326180 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.363905668258667
[5/24] Train loss=0.31826460361480713
[10/24] Train loss=0.3748457729816437
[15/24] Train loss=0.37864431738853455
[20/24] Train loss=0.3378525674343109
Test set avg_accuracy=86.90% avg_sensitivity=65.21%, avg_specificity=95.18% avg_auc=91.40%
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.357856 Test loss=0.335173 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3655571937561035
[5/24] Train loss=0.31354111433029175
[10/24] Train loss=0.3748762309551239
[15/24] Train loss=0.3744092285633087
[20/24] Train loss=0.3330763876438141
Test set avg_accuracy=76.93% avg_sensitivity=91.47%, avg_specificity=71.38% avg_auc=90.87%
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.355467 Test loss=0.561401 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.39709219336509705
[5/24] Train loss=0.30732259154319763
[10/24] Train loss=0.4460202157497406
[15/24] Train loss=0.39615824818611145
[20/24] Train loss=0.33846741914749146
Test set avg_accuracy=89.23% avg_sensitivity=80.15%, avg_specificity=92.70% avg_auc=95.17%
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.373862 Test loss=0.259636 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3609403669834137
[5/24] Train loss=0.30728575587272644
[10/24] Train loss=0.3741774559020996
[15/24] Train loss=0.38162872195243835
[20/24] Train loss=0.35718417167663574
Test set avg_accuracy=83.29% avg_sensitivity=90.33%, avg_specificity=80.61% avg_auc=93.49%
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.362697 Test loss=0.392227 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3369627296924591
[5/24] Train loss=0.2940852642059326
[10/24] Train loss=0.37994927167892456
[15/24] Train loss=0.3441941738128662
[20/24] Train loss=0.33976516127586365
Test set avg_accuracy=88.36% avg_sensitivity=82.51%, avg_specificity=90.59% avg_auc=94.58%
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.350079 Test loss=0.278576 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3511544167995453
[5/24] Train loss=0.3105257749557495
[10/24] Train loss=0.3642638027667999
[15/24] Train loss=0.36331090331077576
[20/24] Train loss=0.33938807249069214
Test set avg_accuracy=87.80% avg_sensitivity=73.03%, avg_specificity=93.43% avg_auc=92.34%
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.356442 Test loss=0.315730 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3421843945980072
[5/24] Train loss=0.2912903130054474
[10/24] Train loss=0.3444732427597046
[15/24] Train loss=0.36220404505729675
[20/24] Train loss=0.31935667991638184
Test set avg_accuracy=88.19% avg_sensitivity=84.91%, avg_specificity=89.44% avg_auc=94.59%
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.352357 Test loss=0.284175 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3299397826194763
[5/24] Train loss=0.2972088158130646
[10/24] Train loss=0.3504987359046936
[15/24] Train loss=0.33938202261924744
[20/24] Train loss=0.3210090398788452
Test set avg_accuracy=87.94% avg_sensitivity=70.25%, avg_specificity=94.69% avg_auc=92.93%
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.338366 Test loss=0.310072 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3180384337902069
[5/24] Train loss=0.2813967764377594
[10/24] Train loss=0.3151995539665222
[15/24] Train loss=0.3397041857242584
[20/24] Train loss=0.29941219091415405
Test set avg_accuracy=87.55% avg_sensitivity=81.57%, avg_specificity=89.84% avg_auc=93.96%
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.331417 Test loss=0.296613 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3514483571052551
[5/24] Train loss=0.282254695892334
[10/24] Train loss=0.35616952180862427
[15/24] Train loss=0.3389090895652771
[20/24] Train loss=0.3092728555202484
Test set avg_accuracy=86.32% avg_sensitivity=68.69%, avg_specificity=93.04% avg_auc=90.98%
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.329309 Test loss=0.333031 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3311697840690613
[5/24] Train loss=0.27844348549842834
[10/24] Train loss=0.30239367485046387
[15/24] Train loss=0.3091273009777069
[20/24] Train loss=0.3149724304676056
Test set avg_accuracy=85.65% avg_sensitivity=60.58%, avg_specificity=95.21% avg_auc=89.86%
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.320477 Test loss=0.359650 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.31205663084983826
[5/24] Train loss=0.2730514705181122
[10/24] Train loss=0.30347374081611633
[15/24] Train loss=0.3272389769554138
[20/24] Train loss=0.3376868665218353
Test set avg_accuracy=86.39% avg_sensitivity=68.18%, avg_specificity=93.34% avg_auc=90.65%
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.334606 Test loss=0.332827 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.329535573720932
[5/24] Train loss=0.28717437386512756
[10/24] Train loss=0.34632083773612976
[15/24] Train loss=0.3332335948944092
[20/24] Train loss=0.31627944111824036
Test set avg_accuracy=85.79% avg_sensitivity=59.83%, avg_specificity=95.70% avg_auc=87.29%
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.330996 Test loss=0.386932 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.31022849678993225
[5/24] Train loss=0.2519436478614807
[10/24] Train loss=0.3299216628074646
[15/24] Train loss=0.32509538531303406
[20/24] Train loss=0.30499207973480225
Test set avg_accuracy=87.98% avg_sensitivity=70.01%, avg_specificity=94.84% avg_auc=92.10%
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.325083 Test loss=0.312979 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.3195309340953827
[5/24] Train loss=0.2622275948524475
[10/24] Train loss=0.32163241505622864
[15/24] Train loss=0.3238492012023926
[20/24] Train loss=0.3079102337360382
Test set avg_accuracy=86.64% avg_sensitivity=65.30%, avg_specificity=94.78% avg_auc=89.73%
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.317104 Test loss=0.347868 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.3048650324344635
[5/24] Train loss=0.25448620319366455
[10/24] Train loss=0.3478855490684509
[15/24] Train loss=0.30199116468429565
[20/24] Train loss=0.2938578128814697
Test set avg_accuracy=87.70% avg_sensitivity=81.75%, avg_specificity=89.96% avg_auc=93.49%
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.316668 Test loss=0.303461 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3161146938800812
[5/24] Train loss=0.2581617832183838
[10/24] Train loss=0.3080815076828003
[15/24] Train loss=0.3046284019947052
[20/24] Train loss=0.2893761098384857
Test set avg_accuracy=88.05% avg_sensitivity=75.72%, avg_specificity=92.75% avg_auc=92.97%
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.309274 Test loss=0.305477 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.29356345534324646
[5/24] Train loss=0.2741575837135315
[10/24] Train loss=0.30710023641586304
[15/24] Train loss=0.28964248299598694
[20/24] Train loss=0.2764696180820465
Test set avg_accuracy=88.05% avg_sensitivity=78.22%, avg_specificity=91.80% avg_auc=92.49%
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.307984 Test loss=0.301845 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.2979894280433655
[5/24] Train loss=0.2437368482351303
[10/24] Train loss=0.2895320951938629
[15/24] Train loss=0.294942170381546
[20/24] Train loss=0.28824561834335327
Test set avg_accuracy=84.84% avg_sensitivity=68.74%, avg_specificity=90.99% avg_auc=88.30%
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.302929 Test loss=0.379709 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.3079432249069214
[5/24] Train loss=0.2590975761413574
[10/24] Train loss=0.3150021433830261
[15/24] Train loss=0.29785487055778503
[20/24] Train loss=0.3075329065322876
Test set avg_accuracy=88.59% avg_sensitivity=73.79%, avg_specificity=94.24% avg_auc=92.50%
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.302665 Test loss=0.303824 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.31128719449043274
[5/24] Train loss=0.2331961691379547
[10/24] Train loss=0.28386926651000977
[15/24] Train loss=0.24949440360069275
[20/24] Train loss=0.2814718186855316
Test set avg_accuracy=88.23% avg_sensitivity=85.34%, avg_specificity=89.33% avg_auc=95.06%
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.290050 Test loss=0.283837 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.2904697060585022
[5/24] Train loss=0.2639663815498352
[10/24] Train loss=0.3107975721359253
[15/24] Train loss=0.27838024497032166
[20/24] Train loss=0.2749747037887573
Test set avg_accuracy=88.70% avg_sensitivity=82.13%, avg_specificity=91.20% avg_auc=93.58%
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.290964 Test loss=0.300478 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.29359373450279236
[5/24] Train loss=0.24612262845039368
[10/24] Train loss=0.28341683745384216
[15/24] Train loss=0.2737182676792145
[20/24] Train loss=0.2676704525947571
Test set avg_accuracy=88.03% avg_sensitivity=76.38%, avg_specificity=92.48% avg_auc=93.07%
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.283442 Test loss=0.300689 Current lr=[0.000224838296036774]

[0/24] Train loss=0.30145031213760376
[5/24] Train loss=0.23493485152721405
[10/24] Train loss=0.27951139211654663
[15/24] Train loss=0.2653583884239197
[20/24] Train loss=0.2714992165565491
Test set avg_accuracy=88.09% avg_sensitivity=87.18%, avg_specificity=88.43% avg_auc=94.74%
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.276965 Test loss=0.305183 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.28078699111938477
[5/24] Train loss=0.22055651247501373
[10/24] Train loss=0.2512454390525818
[15/24] Train loss=0.25757595896720886
[20/24] Train loss=0.269357830286026
Test set avg_accuracy=88.22% avg_sensitivity=85.01%, avg_specificity=89.44% avg_auc=94.72%
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.272642 Test loss=0.301306 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.273965984582901
[5/24] Train loss=0.24473991990089417
[10/24] Train loss=0.27348366379737854
[15/24] Train loss=0.23634760081768036
[20/24] Train loss=0.2515149414539337
Test set avg_accuracy=88.65% avg_sensitivity=80.53%, avg_specificity=91.74% avg_auc=93.40%
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.263856 Test loss=0.299347 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2823113203048706
[5/24] Train loss=0.22614789009094238
[10/24] Train loss=0.27483242750167847
[15/24] Train loss=0.2535228729248047
[20/24] Train loss=0.26301494240760803
Test set avg_accuracy=85.98% avg_sensitivity=83.64%, avg_specificity=86.87% avg_auc=92.52%
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.267963 Test loss=0.354117 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2719098627567291
[5/24] Train loss=0.2171648144721985
[10/24] Train loss=0.2376856654882431
[15/24] Train loss=0.2599835991859436
[20/24] Train loss=0.2680079936981201
Test set avg_accuracy=87.73% avg_sensitivity=82.70%, avg_specificity=89.66% avg_auc=93.56%
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.260206 Test loss=0.316780 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2825251519680023
[5/24] Train loss=0.2139141857624054
[10/24] Train loss=0.27046138048171997
[15/24] Train loss=0.2498604953289032
[20/24] Train loss=0.2556493580341339
Test set avg_accuracy=88.96% avg_sensitivity=81.52%, avg_specificity=91.80% avg_auc=94.45%
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.261252 Test loss=0.289493 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.2569856345653534
[5/24] Train loss=0.21951699256896973
[10/24] Train loss=0.2496260106563568
[15/24] Train loss=0.2590874433517456
[20/24] Train loss=0.25164681673049927
Test set avg_accuracy=88.83% avg_sensitivity=76.43%, avg_specificity=93.56% avg_auc=93.92%
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.252009 Test loss=0.288935 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2656985819339752
[5/24] Train loss=0.222318634390831
[10/24] Train loss=0.25391697883605957
[15/24] Train loss=0.2457062155008316
[20/24] Train loss=0.2577500641345978
Test set avg_accuracy=87.03% avg_sensitivity=79.07%, avg_specificity=90.07% avg_auc=91.94%
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.254913 Test loss=0.345487 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.25243479013442993
[5/24] Train loss=0.21798408031463623
[10/24] Train loss=0.23793645203113556
[15/24] Train loss=0.24615183472633362
[20/24] Train loss=0.2566045820713043
Test set avg_accuracy=88.36% avg_sensitivity=72.70%, avg_specificity=94.33% avg_auc=92.76%
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.253027 Test loss=0.305628 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.24584370851516724
[5/24] Train loss=0.20801973342895508
[10/24] Train loss=0.26425066590309143
[15/24] Train loss=0.2270447164773941
[20/24] Train loss=0.24099014699459076
Test set avg_accuracy=89.22% avg_sensitivity=78.50%, avg_specificity=93.31% avg_auc=93.71%
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.248867 Test loss=0.286205 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.23333777487277985
[5/24] Train loss=0.22790782153606415
[10/24] Train loss=0.23641374707221985
[15/24] Train loss=0.25486478209495544
[20/24] Train loss=0.24265144765377045
Test set avg_accuracy=86.08% avg_sensitivity=89.58%, avg_specificity=84.75% avg_auc=94.07%
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.245533 Test loss=0.354561 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.24847757816314697
[5/24] Train loss=0.2213096171617508
[10/24] Train loss=0.23808938264846802
[15/24] Train loss=0.2435818612575531
[20/24] Train loss=0.2411033660173416
Test set avg_accuracy=86.11% avg_sensitivity=67.94%, avg_specificity=93.04% avg_auc=88.38%
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.253645 Test loss=0.374184 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.29444441199302673
[5/24] Train loss=0.2167007029056549
[10/24] Train loss=0.26163774728775024
[15/24] Train loss=0.24325193464756012
[20/24] Train loss=0.23999498784542084
Test set avg_accuracy=88.24% avg_sensitivity=70.63%, avg_specificity=94.96% avg_auc=92.00%
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.251868 Test loss=0.319291 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2617253065109253
[5/24] Train loss=0.21846376359462738
[10/24] Train loss=0.25280603766441345
[15/24] Train loss=0.25008001923561096
[20/24] Train loss=0.24371103942394257
Test set avg_accuracy=88.16% avg_sensitivity=78.60%, avg_specificity=91.82% avg_auc=93.13%
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.251324 Test loss=0.304905 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2406030148267746
[5/24] Train loss=0.20972244441509247
[10/24] Train loss=0.22956238687038422
[15/24] Train loss=0.23627009987831116
[20/24] Train loss=0.2395172417163849
Test set avg_accuracy=88.55% avg_sensitivity=78.41%, avg_specificity=92.43% avg_auc=93.88%
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.242012 Test loss=0.291092 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.23586508631706238
[5/24] Train loss=0.2099073827266693
[10/24] Train loss=0.22578531503677368
[15/24] Train loss=0.24482999742031097
[20/24] Train loss=0.22976405918598175
Test set avg_accuracy=88.66% avg_sensitivity=80.86%, avg_specificity=91.64% avg_auc=94.18%
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.236572 Test loss=0.298334 Current lr=[0.000156543481933168]

[0/24] Train loss=0.23506160080432892
[5/24] Train loss=0.20380663871765137
[10/24] Train loss=0.22572579979896545
[15/24] Train loss=0.21770614385604858
[20/24] Train loss=0.22060653567314148
Test set avg_accuracy=88.71% avg_sensitivity=84.11%, avg_specificity=90.47% avg_auc=94.64%
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.230077 Test loss=0.288018 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.22057247161865234
[5/24] Train loss=0.1920858919620514
[10/24] Train loss=0.2315068393945694
[15/24] Train loss=0.21155999600887299
[20/24] Train loss=0.22580966353416443
Test set avg_accuracy=88.18% avg_sensitivity=82.13%, avg_specificity=90.48% avg_auc=93.57%
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.225872 Test loss=0.301732 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.22046500444412231
[5/24] Train loss=0.19408521056175232
[10/24] Train loss=0.223299041390419
[15/24] Train loss=0.21482883393764496
[20/24] Train loss=0.22331412136554718
Test set avg_accuracy=88.22% avg_sensitivity=84.44%, avg_specificity=89.66% avg_auc=94.18%
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.226188 Test loss=0.309175 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2442452609539032
[5/24] Train loss=0.21011583507061005
[10/24] Train loss=0.22566404938697815
[15/24] Train loss=0.22485296428203583
[20/24] Train loss=0.22180065512657166
Test set avg_accuracy=88.88% avg_sensitivity=82.27%, avg_specificity=91.40% avg_auc=94.05%
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.229416 Test loss=0.299628 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2247975468635559
[5/24] Train loss=0.19853496551513672
[10/24] Train loss=0.20086991786956787
[15/24] Train loss=0.22129489481449127
[20/24] Train loss=0.22082266211509705
Test set avg_accuracy=88.37% avg_sensitivity=81.71%, avg_specificity=90.92% avg_auc=93.42%
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.225048 Test loss=0.310775 Current lr=[0.000134135431043539]

[0/24] Train loss=0.23525428771972656
[5/24] Train loss=0.19834738969802856
[10/24] Train loss=0.21992671489715576
[15/24] Train loss=0.2086288183927536
[20/24] Train loss=0.2282564342021942
Test set avg_accuracy=88.33% avg_sensitivity=81.38%, avg_specificity=90.99% avg_auc=93.65%
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.225809 Test loss=0.309142 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.21843284368515015
[5/24] Train loss=0.19714203476905823
[10/24] Train loss=0.2229311764240265
[15/24] Train loss=0.20561257004737854
[20/24] Train loss=0.21915817260742188
Test set avg_accuracy=88.71% avg_sensitivity=79.63%, avg_specificity=92.17% avg_auc=93.68%
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.222923 Test loss=0.302496 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.2290116846561432
[5/24] Train loss=0.20161673426628113
[10/24] Train loss=0.20746415853500366
[15/24] Train loss=0.21364571154117584
[20/24] Train loss=0.21021023392677307
Test set avg_accuracy=88.61% avg_sensitivity=76.00%, avg_specificity=93.42% avg_auc=92.95%
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.219713 Test loss=0.309189 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.2190379947423935
[5/24] Train loss=0.18903116881847382
[10/24] Train loss=0.21890228986740112
[15/24] Train loss=0.20826824009418488
[20/24] Train loss=0.2349265217781067
Test set avg_accuracy=88.98% avg_sensitivity=80.62%, avg_specificity=92.17% avg_auc=94.08%
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.222487 Test loss=0.296550 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.22757400572299957
[5/24] Train loss=0.1924535483121872
[10/24] Train loss=0.21496200561523438
[15/24] Train loss=0.20226351916790009
[20/24] Train loss=0.226030632853508
Test set avg_accuracy=89.36% avg_sensitivity=85.01%, avg_specificity=91.02% avg_auc=95.04%
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.224350 Test loss=0.280273 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.23121458292007446
[5/24] Train loss=0.20130881667137146
[10/24] Train loss=0.2250053584575653
[15/24] Train loss=0.22500230371952057
[20/24] Train loss=0.21304237842559814
Test set avg_accuracy=87.38% avg_sensitivity=85.05%, avg_specificity=88.27% avg_auc=93.66%
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.228454 Test loss=0.325560 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.22788560390472412
[5/24] Train loss=0.2021515965461731
[10/24] Train loss=0.21795964241027832
[15/24] Train loss=0.19628754258155823
[20/24] Train loss=0.20969246327877045
Test set avg_accuracy=89.18% avg_sensitivity=78.60%, avg_specificity=93.22% avg_auc=93.35%
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.217729 Test loss=0.294734 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.2167254239320755
[5/24] Train loss=0.18514451384544373
[10/24] Train loss=0.2001662701368332
[15/24] Train loss=0.19474153220653534
[20/24] Train loss=0.20043615996837616
Test set avg_accuracy=87.28% avg_sensitivity=85.81%, avg_specificity=87.84% avg_auc=93.93%
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.207361 Test loss=0.327719 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.19978968799114227
[5/24] Train loss=0.18585386872291565
[10/24] Train loss=0.19772730767726898
[15/24] Train loss=0.1978958547115326
[20/24] Train loss=0.1976674199104309
Test set avg_accuracy=89.18% avg_sensitivity=81.71%, avg_specificity=92.03% avg_auc=94.34%
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.203105 Test loss=0.291718 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.2046169489622116
[5/24] Train loss=0.17635086178779602
[10/24] Train loss=0.1940900683403015
[15/24] Train loss=0.18333597481250763
[20/24] Train loss=0.19510851800441742
Test set avg_accuracy=88.71% avg_sensitivity=82.79%, avg_specificity=90.97% avg_auc=94.08%
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.197081 Test loss=0.301508 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.20272032916545868
[5/24] Train loss=0.1628347486257553
[10/24] Train loss=0.19396747648715973
[15/24] Train loss=0.1827619969844818
[20/24] Train loss=0.18863941729068756
Test set avg_accuracy=88.84% avg_sensitivity=84.25%, avg_specificity=90.59% avg_auc=94.20%
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.195356 Test loss=0.291496 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.19862376153469086
[5/24] Train loss=0.18155226111412048
[10/24] Train loss=0.18541906774044037
[15/24] Train loss=0.17733749747276306
[20/24] Train loss=0.18852591514587402
Test set avg_accuracy=89.13% avg_sensitivity=81.14%, avg_specificity=92.17% avg_auc=94.06%
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.196409 Test loss=0.290787 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1989702582359314
[5/24] Train loss=0.17370851337909698
[10/24] Train loss=0.18108201026916504
[15/24] Train loss=0.18620675802230835
[20/24] Train loss=0.18808722496032715
Test set avg_accuracy=89.52% avg_sensitivity=81.47%, avg_specificity=92.59% avg_auc=94.32%
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.194957 Test loss=0.286139 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1897534877061844
[5/24] Train loss=0.16583116352558136
[10/24] Train loss=0.1860145628452301
[15/24] Train loss=0.18666446208953857
[20/24] Train loss=0.18437685072422028
Test set avg_accuracy=89.38% avg_sensitivity=82.98%, avg_specificity=91.82% avg_auc=94.41%
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.191483 Test loss=0.283859 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.19432733952999115
[5/24] Train loss=0.16155694425106049
[10/24] Train loss=0.18642890453338623
[15/24] Train loss=0.1850380301475525
[20/24] Train loss=0.18330875039100647
Test set avg_accuracy=89.05% avg_sensitivity=79.82%, avg_specificity=92.57% avg_auc=93.64%
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.190719 Test loss=0.296694 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18812526762485504
[5/24] Train loss=0.1608247458934784
[10/24] Train loss=0.1771436482667923
[15/24] Train loss=0.17879612743854523
[20/24] Train loss=0.18253660202026367
Test set avg_accuracy=89.06% avg_sensitivity=78.60%, avg_specificity=93.06% avg_auc=93.25%
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.185744 Test loss=0.298984 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.19059710204601288
[5/24] Train loss=0.16017630696296692
[10/24] Train loss=0.17671820521354675
[15/24] Train loss=0.17401529848575592
[20/24] Train loss=0.18212178349494934
Test set avg_accuracy=89.26% avg_sensitivity=79.49%, avg_specificity=92.98% avg_auc=93.38%
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.185211 Test loss=0.295582 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.18647125363349915
[5/24] Train loss=0.16469377279281616
[10/24] Train loss=0.17224720120429993
[15/24] Train loss=0.17638808488845825
[20/24] Train loss=0.17963100969791412
Test set avg_accuracy=89.32% avg_sensitivity=81.14%, avg_specificity=92.44% avg_auc=94.36%
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.185337 Test loss=0.286300 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.18916131556034088
[5/24] Train loss=0.1606188714504242
[10/24] Train loss=0.18391580879688263
[15/24] Train loss=0.17985306680202484
[20/24] Train loss=0.18880589306354523
Test set avg_accuracy=88.67% avg_sensitivity=80.91%, avg_specificity=91.64% avg_auc=93.76%
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.185676 Test loss=0.302670 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.19026394188404083
[5/24] Train loss=0.16177785396575928
[10/24] Train loss=0.1758769452571869
[15/24] Train loss=0.1713133007287979
[20/24] Train loss=0.18601511418819427
Test set avg_accuracy=89.61% avg_sensitivity=80.86%, avg_specificity=92.95% avg_auc=94.15%
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.182547 Test loss=0.284585 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18594297766685486
[5/24] Train loss=0.16167570650577545
[10/24] Train loss=0.1764759123325348
[15/24] Train loss=0.17049913108348846
[20/24] Train loss=0.18693174421787262
Test set avg_accuracy=89.48% avg_sensitivity=81.94%, avg_specificity=92.35% avg_auc=94.18%
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.182983 Test loss=0.285290 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.18074306845664978
[5/24] Train loss=0.16374528408050537
[10/24] Train loss=0.1765570193529129
[15/24] Train loss=0.1664315164089203
[20/24] Train loss=0.1843940168619156
Test set avg_accuracy=89.13% avg_sensitivity=81.47%, avg_specificity=92.05% avg_auc=93.64%
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.181785 Test loss=0.297519 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.18523640930652618
[5/24] Train loss=0.1618962436914444
[10/24] Train loss=0.17299532890319824
[15/24] Train loss=0.17037169635295868
[20/24] Train loss=0.1688620001077652
Test set avg_accuracy=88.85% avg_sensitivity=82.08%, avg_specificity=91.44% avg_auc=93.67%
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.177811 Test loss=0.301877 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.18352729082107544
[5/24] Train loss=0.15791408717632294
[10/24] Train loss=0.16943326592445374
[15/24] Train loss=0.17261235415935516
[20/24] Train loss=0.17547555267810822
Test set avg_accuracy=88.58% avg_sensitivity=81.00%, avg_specificity=91.47% avg_auc=93.63%
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.178130 Test loss=0.299329 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.18324211239814758
[5/24] Train loss=0.15577815473079681
[10/24] Train loss=0.1685604453086853
[15/24] Train loss=0.17717492580413818
[20/24] Train loss=0.16988413035869598
Test set avg_accuracy=89.27% avg_sensitivity=82.37%, avg_specificity=91.91% avg_auc=94.06%
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.179122 Test loss=0.294555 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.18124248087406158
[5/24] Train loss=0.16822801530361176
[10/24] Train loss=0.1697622835636139
[15/24] Train loss=0.17725960910320282
[20/24] Train loss=0.17775315046310425
Test set avg_accuracy=89.24% avg_sensitivity=80.48%, avg_specificity=92.59% avg_auc=93.62%
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.181102 Test loss=0.294417 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.1812068372964859
[5/24] Train loss=0.16594086587429047
[10/24] Train loss=0.1749216914176941
[15/24] Train loss=0.17673291265964508
[20/24] Train loss=0.19099797308444977
Test set avg_accuracy=89.82% avg_sensitivity=82.32%, avg_specificity=92.68% avg_auc=94.30%
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.184170 Test loss=0.281042 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.18413501977920532
[5/24] Train loss=0.1637052297592163
[10/24] Train loss=0.1823127567768097
[15/24] Train loss=0.16552141308784485
[20/24] Train loss=0.18206585943698883
Test set avg_accuracy=89.79% avg_sensitivity=82.98%, avg_specificity=92.39% avg_auc=94.31%
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.182214 Test loss=0.283782 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.1830090880393982
[5/24] Train loss=0.1503889411687851
[10/24] Train loss=0.17412665486335754
[15/24] Train loss=0.16970786452293396
[20/24] Train loss=0.16879066824913025
Test set avg_accuracy=89.51% avg_sensitivity=82.70%, avg_specificity=92.10% avg_auc=94.09%
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.177392 Test loss=0.286778 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1834561675786972
[5/24] Train loss=0.14992180466651917
[10/24] Train loss=0.16541968286037445
[15/24] Train loss=0.1640826165676117
[20/24] Train loss=0.17088472843170166
Test set avg_accuracy=89.87% avg_sensitivity=82.79%, avg_specificity=92.57% avg_auc=94.53%
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.173222 Test loss=0.278385 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.1722908616065979
[5/24] Train loss=0.15706199407577515
[10/24] Train loss=0.16197635233402252
[15/24] Train loss=0.15782111883163452
[20/24] Train loss=0.16846007108688354
Test set avg_accuracy=89.77% avg_sensitivity=82.08%, avg_specificity=92.70% avg_auc=94.26%
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.169511 Test loss=0.279959 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.17040148377418518
[5/24] Train loss=0.1470428854227066
[10/24] Train loss=0.16082344949245453
[15/24] Train loss=0.1570131927728653
[20/24] Train loss=0.16152901947498322
Test set avg_accuracy=89.83% avg_sensitivity=82.41%, avg_specificity=92.66% avg_auc=94.32%
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.168021 Test loss=0.279650 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.17129471898078918
[5/24] Train loss=0.1474890261888504
[10/24] Train loss=0.1627727597951889
[15/24] Train loss=0.16043031215667725
[20/24] Train loss=0.16510625183582306
Test set avg_accuracy=90.00% avg_sensitivity=82.60%, avg_specificity=92.82% avg_auc=94.22%
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.166632 Test loss=0.281004 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.17055076360702515
[5/24] Train loss=0.14939363300800323
[10/24] Train loss=0.15875740349292755
[15/24] Train loss=0.15766777098178864
[20/24] Train loss=0.16206574440002441
Test set avg_accuracy=89.83% avg_sensitivity=81.28%, avg_specificity=93.09% avg_auc=94.05%
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.166210 Test loss=0.281847 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16909688711166382
[5/24] Train loss=0.14766143262386322
[10/24] Train loss=0.16006895899772644
[15/24] Train loss=0.15706866979599
[20/24] Train loss=0.16323527693748474
Test set avg_accuracy=89.77% avg_sensitivity=83.73%, avg_specificity=92.07% avg_auc=94.44%
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.166905 Test loss=0.281888 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.1695108860731125
[5/24] Train loss=0.1477331817150116
[10/24] Train loss=0.1595962792634964
[15/24] Train loss=0.15502196550369263
[20/24] Train loss=0.15820865333080292
Test set avg_accuracy=89.80% avg_sensitivity=81.66%, avg_specificity=92.91% avg_auc=94.08%
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.165640 Test loss=0.281549 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.16783492267131805
[5/24] Train loss=0.14533087611198425
[10/24] Train loss=0.15843762457370758
[15/24] Train loss=0.15377594530582428
[20/24] Train loss=0.15978854894638062
Test set avg_accuracy=89.69% avg_sensitivity=81.90%, avg_specificity=92.66% avg_auc=94.12%
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.164920 Test loss=0.282367 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.16705624759197235
[5/24] Train loss=0.14507447183132172
[10/24] Train loss=0.1600930243730545
[15/24] Train loss=0.15781106054782867
[20/24] Train loss=0.163003072142601
Test set avg_accuracy=89.80% avg_sensitivity=81.99%, avg_specificity=92.79% avg_auc=94.29%
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.164893 Test loss=0.280218 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16250303387641907
[5/24] Train loss=0.14545266330242157
[10/24] Train loss=0.1561579555273056
[15/24] Train loss=0.1607860028743744
[20/24] Train loss=0.15599285066127777
Test set avg_accuracy=89.82% avg_sensitivity=82.37%, avg_specificity=92.66% avg_auc=94.24%
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.163999 Test loss=0.281231 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.1662135273218155
[5/24] Train loss=0.14296679198741913
[10/24] Train loss=0.16359898447990417
[15/24] Train loss=0.15470513701438904
[20/24] Train loss=0.1614445596933365
Test set avg_accuracy=89.67% avg_sensitivity=81.99%, avg_specificity=92.61% avg_auc=94.20%
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.164650 Test loss=0.282535 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.16771069169044495
[5/24] Train loss=0.14420674741268158
[10/24] Train loss=0.15603755414485931
[15/24] Train loss=0.15320438146591187
[20/24] Train loss=0.1637185961008072
Test set avg_accuracy=89.65% avg_sensitivity=82.27%, avg_specificity=92.46% avg_auc=94.21%
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.163804 Test loss=0.281694 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.16748598217964172
[5/24] Train loss=0.14527232944965363
[10/24] Train loss=0.1555686891078949
[15/24] Train loss=0.1571405529975891
[20/24] Train loss=0.16201363503932953
Test set avg_accuracy=89.79% avg_sensitivity=82.41%, avg_specificity=92.61% avg_auc=94.23%
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.164638 Test loss=0.281092 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.16316305100917816
[5/24] Train loss=0.1448759287595749
[10/24] Train loss=0.1557401865720749
[15/24] Train loss=0.15107667446136475
[20/24] Train loss=0.15983088314533234
Test set avg_accuracy=89.92% avg_sensitivity=82.41%, avg_specificity=92.79% avg_auc=94.18%
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.163640 Test loss=0.281137 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1642349362373352
[5/24] Train loss=0.14982262253761292
[10/24] Train loss=0.15767447650432587
[15/24] Train loss=0.1560470461845398
[20/24] Train loss=0.16149890422821045
Test set avg_accuracy=89.87% avg_sensitivity=82.23%, avg_specificity=92.79% avg_auc=94.18%
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.163730 Test loss=0.281114 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16511549055576324
[5/24] Train loss=0.14581023156642914
[10/24] Train loss=0.15646280348300934
[15/24] Train loss=0.15208137035369873
[20/24] Train loss=0.15910844504833221
Test set avg_accuracy=89.84% avg_sensitivity=82.60%, avg_specificity=92.61% avg_auc=94.18%
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.162754 Test loss=0.281255 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.1642494946718216
[5/24] Train loss=0.14388635754585266
[10/24] Train loss=0.15468032658100128
[15/24] Train loss=0.15205056965351105
[20/24] Train loss=0.1627630889415741
Test set avg_accuracy=89.86% avg_sensitivity=82.56%, avg_specificity=92.64% avg_auc=94.16%
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.162515 Test loss=0.281545 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16532841324806213
[5/24] Train loss=0.14671768248081207
[10/24] Train loss=0.1589564085006714
[15/24] Train loss=0.1537972241640091
[20/24] Train loss=0.16527505218982697
Test set avg_accuracy=89.91% avg_sensitivity=82.51%, avg_specificity=92.73% avg_auc=94.15%
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.163340 Test loss=0.281649 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.16098599135875702
[5/24] Train loss=0.14590390026569366
[10/24] Train loss=0.15483954548835754
[15/24] Train loss=0.15710607171058655
[20/24] Train loss=0.16114844381809235
Test set avg_accuracy=89.86% avg_sensitivity=82.46%, avg_specificity=92.68% avg_auc=94.16%
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.162749 Test loss=0.281520 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.16359180212020874
[5/24] Train loss=0.14845934510231018
[10/24] Train loss=0.15617038309574127
[15/24] Train loss=0.1487969607114792
[20/24] Train loss=0.1620359867811203
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.90% avg_sensitivity=82.41%, avg_specificity=92.75% avg_auc=94.15%
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.163442 Test loss=0.281427 Current lr=[1.3165623068326024e-09]

Fold[7] Result: acc=88.96% sen=86.37%, spe=89.94%, auc=95.28%!
Fold[7] Avg_overlap=0.70%(0.21588432336924743)
[0/24] Train loss=1.4859949350357056
[5/24] Train loss=1.4725805521011353
[10/24] Train loss=1.4791851043701172
[15/24] Train loss=1.4311163425445557
[20/24] Train loss=1.423030972480774
Test set avg_accuracy=55.34% avg_sensitivity=51.53%, avg_specificity=56.62% avg_auc=56.30%
Best model saved!! Metric=-106.21966092169242!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=1.450326 Test loss=0.685978 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.3868629932403564
[5/24] Train loss=1.3799281120300293
[10/24] Train loss=1.3833308219909668
[15/24] Train loss=1.3689830303192139
[20/24] Train loss=1.3237025737762451
Test set avg_accuracy=61.29% avg_sensitivity=71.72%, avg_specificity=57.78% avg_auc=68.69%
Best model saved!! Metric=-66.51599327760624!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=1.374053 Test loss=0.656307 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3320666551589966
[5/24] Train loss=1.3094888925552368
[10/24] Train loss=1.3105705976486206
[15/24] Train loss=1.2645137310028076
[20/24] Train loss=1.277451992034912
Test set avg_accuracy=66.80% avg_sensitivity=79.34%, avg_specificity=62.58% avg_auc=76.84%
Best model saved!! Metric=-40.443020907864636!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=1.302751 Test loss=0.623078 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.247641921043396
[5/24] Train loss=1.2449308633804321
[10/24] Train loss=1.2527505159378052
[15/24] Train loss=1.1920992136001587
[20/24] Train loss=1.1594301462173462
Test set avg_accuracy=69.38% avg_sensitivity=84.57%, avg_specificity=64.27% avg_auc=81.22%
Best model saved!! Metric=-26.56672494277484!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=1.227905 Test loss=0.601895 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1490076780319214
[5/24] Train loss=1.1560091972351074
[10/24] Train loss=1.173499345779419
[15/24] Train loss=1.0959354639053345
[20/24] Train loss=1.0884997844696045
Test set avg_accuracy=70.98% avg_sensitivity=87.47%, avg_specificity=65.44% avg_auc=83.88%
Best model saved!! Metric=-18.236052145160627!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=1.149359 Test loss=0.584481 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.0800780057907104
[5/24] Train loss=1.0791858434677124
[10/24] Train loss=1.1108918190002441
[15/24] Train loss=1.0405263900756836
[20/24] Train loss=1.0025535821914673
Test set avg_accuracy=72.47% avg_sensitivity=89.33%, avg_specificity=66.81% avg_auc=86.15%
Best model saved!! Metric=-11.232743005489553!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=1.081442 Test loss=0.566019 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0147738456726074
[5/24] Train loss=1.0134910345077515
[10/24] Train loss=1.0568147897720337
[15/24] Train loss=0.9892802238464355
[20/24] Train loss=0.9397013187408447
Test set avg_accuracy=75.00% avg_sensitivity=89.59%, avg_specificity=70.10% avg_auc=88.10%
Best model saved!! Metric=-3.206363946482398!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=1.023762 Test loss=0.527258 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9586145281791687
[5/24] Train loss=0.9588473439216614
[10/24] Train loss=0.9957208633422852
[15/24] Train loss=0.936074435710907
[20/24] Train loss=0.9010588526725769
Test set avg_accuracy=77.62% avg_sensitivity=89.07%, avg_specificity=73.77% avg_auc=89.97%
Best model saved!! Metric=4.425642062921753!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.971956 Test loss=0.489782 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9035791158676147
[5/24] Train loss=0.9302462935447693
[10/24] Train loss=0.9512553215026855
[15/24] Train loss=0.9003376364707947
[20/24] Train loss=0.8350139260292053
Test set avg_accuracy=79.13% avg_sensitivity=89.23%, avg_specificity=75.73% avg_auc=91.16%
Best model saved!! Metric=9.255646248873305!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.926507 Test loss=0.468997 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.8723689317703247
[5/24] Train loss=0.871375322341919
[10/24] Train loss=0.9138045310974121
[15/24] Train loss=0.8645767569541931
[20/24] Train loss=0.7883607745170593
Test set avg_accuracy=81.16% avg_sensitivity=89.28%, avg_specificity=78.43% avg_auc=92.18%
Best model saved!! Metric=15.046854862800174!!
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.880978 Test loss=0.440996 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8385401964187622
[5/24] Train loss=0.8367724418640137
[10/24] Train loss=0.8503180742263794
[15/24] Train loss=0.828763484954834
[20/24] Train loss=0.745756208896637
Test set avg_accuracy=83.39% avg_sensitivity=88.66%, avg_specificity=81.61% avg_auc=93.02%
Best model saved!! Metric=20.68161597415437!!
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.842309 Test loss=0.404219 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.7948867082595825
[5/24] Train loss=0.7925363183021545
[10/24] Train loss=0.8494030237197876
[15/24] Train loss=0.7946934103965759
[20/24] Train loss=0.715916633605957
Test set avg_accuracy=84.80% avg_sensitivity=88.97%, avg_specificity=83.41% avg_auc=93.59%
Best model saved!! Metric=24.769902984754538!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.807198 Test loss=0.385267 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.767038881778717
[5/24] Train loss=0.7555069327354431
[10/24] Train loss=0.8159050345420837
[15/24] Train loss=0.7749016284942627
[20/24] Train loss=0.6839268803596497
Test set avg_accuracy=85.77% avg_sensitivity=88.81%, avg_specificity=84.75% avg_auc=93.91%
Best model saved!! Metric=27.238112700326056!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.774023 Test loss=0.370694 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7303662896156311
[5/24] Train loss=0.7415971159934998
[10/24] Train loss=0.7693092226982117
[15/24] Train loss=0.751594603061676
[20/24] Train loss=0.6664477586746216
Test set avg_accuracy=87.15% avg_sensitivity=86.59%, avg_specificity=87.34% avg_auc=94.13%
Best model saved!! Metric=29.202057975188595!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.749126 Test loss=0.338372 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7074460983276367
[5/24] Train loss=0.6997262835502625
[10/24] Train loss=0.7494513392448425
[15/24] Train loss=0.7206068634986877
[20/24] Train loss=0.6111096739768982
Test set avg_accuracy=87.93% avg_sensitivity=85.14%, avg_specificity=88.87% avg_auc=94.28%
Best model saved!! Metric=30.215077731557173!!
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.722880 Test loss=0.317689 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.6841289401054382
[5/24] Train loss=0.6941704154014587
[10/24] Train loss=0.728791356086731
[15/24] Train loss=0.7070527672767639
[20/24] Train loss=0.6066306233406067
Test set avg_accuracy=87.57% avg_sensitivity=86.33%, avg_specificity=87.98% avg_auc=94.40%
Best model saved!! Metric=30.26948965455327!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.703614 Test loss=0.319519 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6524953842163086
[5/24] Train loss=0.6654907464981079
[10/24] Train loss=0.7025921940803528
[15/24] Train loss=0.6930002570152283
[20/24] Train loss=0.5813978314399719
Test set avg_accuracy=87.04% avg_sensitivity=88.40%, avg_specificity=86.59% avg_auc=94.52%
Best model saved!! Metric=30.55213742107844!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.686701 Test loss=0.329971 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6368973255157471
[5/24] Train loss=0.6539803147315979
[10/24] Train loss=0.6830943822860718
[15/24] Train loss=0.6760010123252869
[20/24] Train loss=0.5662851333618164
Test set avg_accuracy=87.73% avg_sensitivity=87.52%, avg_specificity=87.81% avg_auc=94.60%
Best model saved!! Metric=31.656057279376!!
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.666908 Test loss=0.311972 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6244702935218811
[5/24] Train loss=0.6141257286071777
[10/24] Train loss=0.6689330339431763
[15/24] Train loss=0.6780805587768555
[20/24] Train loss=0.548496425151825
Test set avg_accuracy=87.25% avg_sensitivity=89.18%, avg_specificity=86.61% avg_auc=94.68%
Best model saved!! Metric=31.719545977815443!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.650144 Test loss=0.324431 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6130381226539612
[5/24] Train loss=0.6246413588523865
[10/24] Train loss=0.6488195061683655
[15/24] Train loss=0.6545695066452026
[20/24] Train loss=0.5421425700187683
Test set avg_accuracy=86.22% avg_sensitivity=90.89%, avg_specificity=84.66% avg_auc=94.87%
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.638933 Test loss=0.336899 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.5864156484603882
[5/24] Train loss=0.5945348143577576
[10/24] Train loss=0.6344452500343323
[15/24] Train loss=0.6692557334899902
[20/24] Train loss=0.5177532434463501
Test set avg_accuracy=88.07% avg_sensitivity=89.23%, avg_specificity=87.68% avg_auc=94.98%
Best model saved!! Metric=33.969211152033694!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.623560 Test loss=0.304071 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.5881937146186829
[5/24] Train loss=0.5842181444168091
[10/24] Train loss=0.6269986033439636
[15/24] Train loss=0.6484081149101257
[20/24] Train loss=0.5115485787391663
Test set avg_accuracy=87.98% avg_sensitivity=89.75%, avg_specificity=87.39% avg_auc=95.16%
Best model saved!! Metric=34.27416239509279!!
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.612093 Test loss=0.304869 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5786733031272888
[5/24] Train loss=0.5691356658935547
[10/24] Train loss=0.6149387955665588
[15/24] Train loss=0.6082152724266052
[20/24] Train loss=0.49118056893348694
Test set avg_accuracy=89.31% avg_sensitivity=86.90%, avg_specificity=90.12% avg_auc=95.18%
Best model saved!! Metric=35.507118523718134!!
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.594508 Test loss=0.276577 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.5594257712364197
[5/24] Train loss=0.5383197069168091
[10/24] Train loss=0.6087071895599365
[15/24] Train loss=0.612632155418396
[20/24] Train loss=0.5015523433685303
Test set avg_accuracy=86.76% avg_sensitivity=90.47%, avg_specificity=85.51% avg_auc=95.05%
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.581409 Test loss=0.322289 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5475939512252808
[5/24] Train loss=0.5220227837562561
[10/24] Train loss=0.5806246399879456
[15/24] Train loss=0.5807397365570068
[20/24] Train loss=0.4768548011779785
Test set avg_accuracy=89.15% avg_sensitivity=84.98%, avg_specificity=90.55% avg_auc=94.90%
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.565050 Test loss=0.273322 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5248303413391113
[5/24] Train loss=0.5129306316375732
[10/24] Train loss=0.5923700928688049
[15/24] Train loss=0.5894801020622253
[20/24] Train loss=0.46647074818611145
Test set avg_accuracy=89.32% avg_sensitivity=85.34%, avg_specificity=90.66% avg_auc=95.04%
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.553971 Test loss=0.270973 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5215948224067688
[5/24] Train loss=0.5007650852203369
[10/24] Train loss=0.5633321404457092
[15/24] Train loss=0.5766633749008179
[20/24] Train loss=0.4539002478122711
Test set avg_accuracy=86.94% avg_sensitivity=87.93%, avg_specificity=86.61% avg_auc=94.64%
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.542855 Test loss=0.312186 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5146600008010864
[5/24] Train loss=0.48723363876342773
[10/24] Train loss=0.5451948642730713
[15/24] Train loss=0.5622233748435974
[20/24] Train loss=0.4339735209941864
Test set avg_accuracy=88.80% avg_sensitivity=84.88%, avg_specificity=90.12% avg_auc=94.72%
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.530407 Test loss=0.279056 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5078105926513672
[5/24] Train loss=0.4784395396709442
[10/24] Train loss=0.5546919107437134
[15/24] Train loss=0.5727882981300354
[20/24] Train loss=0.449645459651947
Test set avg_accuracy=88.39% avg_sensitivity=81.72%, avg_specificity=90.62% avg_auc=93.46%
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.522788 Test loss=0.292108 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.49015122652053833
[5/24] Train loss=0.45137178897857666
[10/24] Train loss=0.5380436182022095
[15/24] Train loss=0.5101024508476257
[20/24] Train loss=0.4301494061946869
Test set avg_accuracy=88.27% avg_sensitivity=74.11%, avg_specificity=93.02% avg_auc=91.72%
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.504977 Test loss=0.298790 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.49933189153671265
[5/24] Train loss=0.4874509572982788
[10/24] Train loss=0.5441566109657288
[15/24] Train loss=0.536747932434082
[20/24] Train loss=0.44085928797721863
Test set avg_accuracy=86.63% avg_sensitivity=84.72%, avg_specificity=87.27% avg_auc=93.04%
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.517488 Test loss=0.327709 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.47534647583961487
[5/24] Train loss=0.4381678104400635
[10/24] Train loss=0.5281091928482056
[15/24] Train loss=0.5310726761817932
[20/24] Train loss=0.418758749961853
Test set avg_accuracy=80.60% avg_sensitivity=92.75%, avg_specificity=76.52% avg_auc=94.06%
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.493717 Test loss=0.432268 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.47203466296195984
[5/24] Train loss=0.4306762218475342
[10/24] Train loss=0.5024268627166748
[15/24] Train loss=0.5071346759796143
[20/24] Train loss=0.40589120984077454
Test set avg_accuracy=86.34% avg_sensitivity=83.64%, avg_specificity=87.25% avg_auc=91.72%
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.481257 Test loss=0.344809 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.4755522608757019
[5/24] Train loss=0.39994722604751587
[10/24] Train loss=0.4905742406845093
[15/24] Train loss=0.49935194849967957
[20/24] Train loss=0.4046921133995056
Test set avg_accuracy=86.76% avg_sensitivity=77.78%, avg_specificity=89.77% avg_auc=91.99%
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.472051 Test loss=0.320103 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.46691790223121643
[5/24] Train loss=0.41682887077331543
[10/24] Train loss=0.47130393981933594
[15/24] Train loss=0.4919724762439728
[20/24] Train loss=0.4077041447162628
Test set avg_accuracy=87.79% avg_sensitivity=80.06%, avg_specificity=90.38% avg_auc=92.92%
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.472177 Test loss=0.296752 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.465567409992218
[5/24] Train loss=0.4462447762489319
[10/24] Train loss=0.4936244487762451
[15/24] Train loss=0.49524927139282227
[20/24] Train loss=0.39090877771377563
Test set avg_accuracy=81.94% avg_sensitivity=90.42%, avg_specificity=79.09% avg_auc=93.65%
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.472265 Test loss=0.402924 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.4507947862148285
[5/24] Train loss=0.39637136459350586
[10/24] Train loss=0.4600551724433899
[15/24] Train loss=0.5104450583457947
[20/24] Train loss=0.3859405517578125
Test set avg_accuracy=81.43% avg_sensitivity=92.96%, avg_specificity=77.56% avg_auc=93.48%
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.456920 Test loss=0.448002 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.426369845867157
[5/24] Train loss=0.39904990792274475
[10/24] Train loss=0.4554089605808258
[15/24] Train loss=0.48070475459098816
[20/24] Train loss=0.37690505385398865
Test set avg_accuracy=73.75% avg_sensitivity=94.82%, avg_specificity=66.67% avg_auc=92.20%
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.451034 Test loss=0.607144 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.45083722472190857
[5/24] Train loss=0.38236796855926514
[10/24] Train loss=0.5019540190696716
[15/24] Train loss=0.4804753363132477
[20/24] Train loss=0.3611357808113098
Test set avg_accuracy=86.72% avg_sensitivity=82.86%, avg_specificity=88.02% avg_auc=92.58%
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.444135 Test loss=0.341321 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4495399296283722
[5/24] Train loss=0.39101076126098633
[10/24] Train loss=0.45893535017967224
[15/24] Train loss=0.5044118762016296
[20/24] Train loss=0.39404550194740295
Test set avg_accuracy=86.37% avg_sensitivity=85.66%, avg_specificity=86.61% avg_auc=92.83%
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.437059 Test loss=0.335907 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.4417947232723236
[5/24] Train loss=0.41894060373306274
[10/24] Train loss=0.45181888341903687
[15/24] Train loss=0.47551679611206055
[20/24] Train loss=0.3609412908554077
Test set avg_accuracy=83.75% avg_sensitivity=83.17%, avg_specificity=83.95% avg_auc=90.76%
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.439981 Test loss=0.381692 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4453287422657013
[5/24] Train loss=0.37923431396484375
[10/24] Train loss=0.4209617078304291
[15/24] Train loss=0.43603047728538513
[20/24] Train loss=0.36098751425743103
Test set avg_accuracy=84.99% avg_sensitivity=86.74%, avg_specificity=84.40% avg_auc=93.21%
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.419736 Test loss=0.358376 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4325138330459595
[5/24] Train loss=0.365020751953125
[10/24] Train loss=0.42895135283470154
[15/24] Train loss=0.43787431716918945
[20/24] Train loss=0.36717045307159424
Test set avg_accuracy=87.97% avg_sensitivity=75.76%, avg_specificity=92.07% avg_auc=91.21%
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.418487 Test loss=0.318512 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.4383738934993744
[5/24] Train loss=0.40988242626190186
[10/24] Train loss=0.4564609229564667
[15/24] Train loss=0.4479365646839142
[20/24] Train loss=0.3573167622089386
Test set avg_accuracy=86.68% avg_sensitivity=86.22%, avg_specificity=86.83% avg_auc=94.15%
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.430341 Test loss=0.324510 Current lr=[0.00029967723776099]

[0/24] Train loss=0.43404456973075867
[5/24] Train loss=0.3793264627456665
[10/24] Train loss=0.4942316710948944
[15/24] Train loss=0.46578264236450195
[20/24] Train loss=0.3715423047542572
Test set avg_accuracy=86.68% avg_sensitivity=72.76%, avg_specificity=91.36% avg_auc=91.66%
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.440387 Test loss=0.315950 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.42256873846054077
[5/24] Train loss=0.3724524676799774
[10/24] Train loss=0.43018069863319397
[15/24] Train loss=0.44470176100730896
[20/24] Train loss=0.35764384269714355
Test set avg_accuracy=87.51% avg_sensitivity=80.74%, avg_specificity=89.79% avg_auc=92.47%
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.413266 Test loss=0.315485 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.3977848291397095
[5/24] Train loss=0.3425169885158539
[10/24] Train loss=0.4233666956424713
[15/24] Train loss=0.41294533014297485
[20/24] Train loss=0.34348949790000916
Test set avg_accuracy=81.09% avg_sensitivity=89.44%, avg_specificity=78.29% avg_auc=92.17%
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.404624 Test loss=0.443415 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4141271412372589
[5/24] Train loss=0.3259183466434479
[10/24] Train loss=0.4101255238056183
[15/24] Train loss=0.43093422055244446
[20/24] Train loss=0.3407290279865265
Test set avg_accuracy=85.53% avg_sensitivity=87.47%, avg_specificity=84.88% avg_auc=93.47%
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.395495 Test loss=0.353007 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.40406814217567444
[5/24] Train loss=0.3360975980758667
[10/24] Train loss=0.3973331153392792
[15/24] Train loss=0.4625515341758728
[20/24] Train loss=0.3158690333366394
Test set avg_accuracy=75.87% avg_sensitivity=92.70%, avg_specificity=70.22% avg_auc=91.22%
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.399392 Test loss=0.570914 Current lr=[0.000298904600941902]

[0/24] Train loss=0.40185630321502686
[5/24] Train loss=0.3188016414642334
[10/24] Train loss=0.38769468665122986
[15/24] Train loss=0.4057086408138275
[20/24] Train loss=0.3177569806575775
Test set avg_accuracy=83.98% avg_sensitivity=67.84%, avg_specificity=89.41% avg_auc=86.18%
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.387064 Test loss=0.383956 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.3803648054599762
[5/24] Train loss=0.3140776753425598
[10/24] Train loss=0.3856939375400543
[15/24] Train loss=0.3986557722091675
[20/24] Train loss=0.3357388377189636
Test set avg_accuracy=86.47% avg_sensitivity=58.52%, avg_specificity=95.86% avg_auc=86.89%
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.387061 Test loss=0.372241 Current lr=[0.000297555943323901]

[0/24] Train loss=0.3892594575881958
[5/24] Train loss=0.3633105158805847
[10/24] Train loss=0.42435401678085327
[15/24] Train loss=0.395992636680603
[20/24] Train loss=0.35374826192855835
Test set avg_accuracy=87.59% avg_sensitivity=77.58%, avg_specificity=90.95% avg_auc=92.48%
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.398757 Test loss=0.308216 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.396898478269577
[5/24] Train loss=0.35765567421913147
[10/24] Train loss=0.4226765036582947
[15/24] Train loss=0.4209415912628174
[20/24] Train loss=0.3393001854419708
Test set avg_accuracy=81.84% avg_sensitivity=89.07%, avg_specificity=79.41% avg_auc=92.75%
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.394392 Test loss=0.408773 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3959099054336548
[5/24] Train loss=0.32633712887763977
[10/24] Train loss=0.370738685131073
[15/24] Train loss=0.38030457496643066
[20/24] Train loss=0.30934998393058777
Test set avg_accuracy=83.92% avg_sensitivity=87.93%, avg_specificity=82.57% avg_auc=93.05%
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.374220 Test loss=0.387371 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.38398998975753784
[5/24] Train loss=0.32281845808029175
[10/24] Train loss=0.37617412209510803
[15/24] Train loss=0.3697827160358429
[20/24] Train loss=0.31951671838760376
Test set avg_accuracy=87.49% avg_sensitivity=83.58%, avg_specificity=88.80% avg_auc=92.88%
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.361878 Test loss=0.325310 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.37965789437294006
[5/24] Train loss=0.32465308904647827
[10/24] Train loss=0.3491266965866089
[15/24] Train loss=0.39662301540374756
[20/24] Train loss=0.2989223897457123
Test set avg_accuracy=87.49% avg_sensitivity=81.82%, avg_specificity=89.39% avg_auc=92.50%
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.354317 Test loss=0.325924 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3519183099269867
[5/24] Train loss=0.31832969188690186
[10/24] Train loss=0.3802327811717987
[15/24] Train loss=0.37651902437210083
[20/24] Train loss=0.2953736186027527
Test set avg_accuracy=83.92% avg_sensitivity=86.90%, avg_specificity=82.92% avg_auc=92.26%
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.353727 Test loss=0.405246 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.3565923869609833
[5/24] Train loss=0.28153252601623535
[10/24] Train loss=0.3505021631717682
[15/24] Train loss=0.35690563917160034
[20/24] Train loss=0.2905547618865967
Test set avg_accuracy=84.88% avg_sensitivity=82.34%, avg_specificity=85.74% avg_auc=91.50%
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.343385 Test loss=0.375503 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3647703230381012
[5/24] Train loss=0.2786444425582886
[10/24] Train loss=0.34515851736068726
[15/24] Train loss=0.3481954038143158
[20/24] Train loss=0.33380815386772156
Test set avg_accuracy=86.07% avg_sensitivity=65.10%, avg_specificity=93.11% avg_auc=88.41%
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.345839 Test loss=0.375172 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.37268468737602234
[5/24] Train loss=0.2889884114265442
[10/24] Train loss=0.34734758734703064
[15/24] Train loss=0.3572203516960144
[20/24] Train loss=0.2921800911426544
Test set avg_accuracy=83.80% avg_sensitivity=84.77%, avg_specificity=83.48% avg_auc=91.90%
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.342872 Test loss=0.410811 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.37166717648506165
[5/24] Train loss=0.2884187400341034
[10/24] Train loss=0.35184815526008606
[15/24] Train loss=0.35020411014556885
[20/24] Train loss=0.2797238528728485
Test set avg_accuracy=83.97% avg_sensitivity=83.12%, avg_specificity=84.26% avg_auc=91.55%
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.339402 Test loss=0.387287 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.3460373878479004
[5/24] Train loss=0.3082955479621887
[10/24] Train loss=0.34166818857192993
[15/24] Train loss=0.35080471634864807
[20/24] Train loss=0.2924179136753082
Test set avg_accuracy=87.79% avg_sensitivity=70.43%, avg_specificity=93.62% avg_auc=90.92%
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.333062 Test loss=0.314124 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.32816287875175476
[5/24] Train loss=0.29755523800849915
[10/24] Train loss=0.4108419716358185
[15/24] Train loss=0.3963848948478699
[20/24] Train loss=0.31137287616729736
Test set avg_accuracy=87.99% avg_sensitivity=80.94%, avg_specificity=90.36% avg_auc=93.23%
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.356853 Test loss=0.292566 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3399760127067566
[5/24] Train loss=0.31977641582489014
[10/24] Train loss=0.3475664258003235
[15/24] Train loss=0.3563176095485687
[20/24] Train loss=0.2972866892814636
Test set avg_accuracy=79.80% avg_sensitivity=90.63%, avg_specificity=76.17% avg_auc=92.12%
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.341570 Test loss=0.493679 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3261260390281677
[5/24] Train loss=0.2794237732887268
[10/24] Train loss=0.3231394588947296
[15/24] Train loss=0.3294263482093811
[20/24] Train loss=0.28952327370643616
Test set avg_accuracy=87.85% avg_sensitivity=80.01%, avg_specificity=90.49% avg_auc=92.39%
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.331649 Test loss=0.330362 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.3410041928291321
[5/24] Train loss=0.3066665828227997
[10/24] Train loss=0.33932027220726013
[15/24] Train loss=0.3286704421043396
[20/24] Train loss=0.27355343103408813
Test set avg_accuracy=88.53% avg_sensitivity=79.96%, avg_specificity=91.41% avg_auc=92.97%
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.333863 Test loss=0.302950 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.34321779012680054
[5/24] Train loss=0.2700720429420471
[10/24] Train loss=0.31984105706214905
[15/24] Train loss=0.3157317340373993
[20/24] Train loss=0.2977012097835541
Test set avg_accuracy=87.68% avg_sensitivity=73.54%, avg_specificity=92.43% avg_auc=90.80%
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.313538 Test loss=0.325455 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3090592920780182
[5/24] Train loss=0.26317304372787476
[10/24] Train loss=0.3176559507846832
[15/24] Train loss=0.3081780672073364
[20/24] Train loss=0.28161630034446716
Test set avg_accuracy=87.23% avg_sensitivity=80.84%, avg_specificity=89.37% avg_auc=92.05%
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.312191 Test loss=0.331662 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3094399869441986
[5/24] Train loss=0.2612142264842987
[10/24] Train loss=0.3132249414920807
[15/24] Train loss=0.30529507994651794
[20/24] Train loss=0.28735482692718506
Test set avg_accuracy=86.07% avg_sensitivity=83.38%, avg_specificity=86.97% avg_auc=91.86%
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.306807 Test loss=0.357955 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.29088032245635986
[5/24] Train loss=0.26138606667518616
[10/24] Train loss=0.2899380028247833
[15/24] Train loss=0.29314878582954407
[20/24] Train loss=0.2820575535297394
Test set avg_accuracy=86.56% avg_sensitivity=80.53%, avg_specificity=88.59% avg_auc=91.08%
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.298539 Test loss=0.356717 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.3030485510826111
[5/24] Train loss=0.27787989377975464
[10/24] Train loss=0.29454031586647034
[15/24] Train loss=0.322750985622406
[20/24] Train loss=0.2541128098964691
Test set avg_accuracy=85.66% avg_sensitivity=81.05%, avg_specificity=87.22% avg_auc=91.67%
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.301256 Test loss=0.371743 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.324806272983551
[5/24] Train loss=0.2623327970504761
[10/24] Train loss=0.3208945095539093
[15/24] Train loss=0.2969345152378082
[20/24] Train loss=0.26396963000297546
Test set avg_accuracy=87.90% avg_sensitivity=83.79%, avg_specificity=89.29% avg_auc=93.36%
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.299383 Test loss=0.319313 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.30441826581954956
[5/24] Train loss=0.24486342072486877
[10/24] Train loss=0.29777228832244873
[15/24] Train loss=0.31948307156562805
[20/24] Train loss=0.2647327780723572
Test set avg_accuracy=86.58% avg_sensitivity=83.95%, avg_specificity=87.46% avg_auc=92.22%
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.302524 Test loss=0.365043 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3122633695602417
[5/24] Train loss=0.2719961404800415
[10/24] Train loss=0.3142089247703552
[15/24] Train loss=0.30172502994537354
[20/24] Train loss=0.25248876214027405
Test set avg_accuracy=83.65% avg_sensitivity=87.00%, avg_specificity=82.52% avg_auc=91.90%
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.306456 Test loss=0.416496 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.28592631220817566
[5/24] Train loss=0.26034271717071533
[10/24] Train loss=0.296021044254303
[15/24] Train loss=0.2872188687324524
[20/24] Train loss=0.2734561562538147
Test set avg_accuracy=87.27% avg_sensitivity=72.92%, avg_specificity=92.09% avg_auc=90.61%
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.297577 Test loss=0.331389 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.30698326230049133
[5/24] Train loss=0.24826784431934357
[10/24] Train loss=0.32300594449043274
[15/24] Train loss=0.3293802738189697
[20/24] Train loss=0.25917214155197144
Test set avg_accuracy=86.02% avg_sensitivity=82.96%, avg_specificity=87.04% avg_auc=91.59%
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.301230 Test loss=0.364126 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.2985402047634125
[5/24] Train loss=0.24098823964595795
[10/24] Train loss=0.2978433072566986
[15/24] Train loss=0.28368091583251953
[20/24] Train loss=0.25634142756462097
Test set avg_accuracy=88.44% avg_sensitivity=76.80%, avg_specificity=92.35% avg_auc=91.92%
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.295109 Test loss=0.316509 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.29372677206993103
[5/24] Train loss=0.23518872261047363
[10/24] Train loss=0.2676311135292053
[15/24] Train loss=0.2738036513328552
[20/24] Train loss=0.23452740907669067
Test set avg_accuracy=85.57% avg_sensitivity=80.79%, avg_specificity=87.18% avg_auc=90.61%
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.281776 Test loss=0.378315 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.31222420930862427
[5/24] Train loss=0.2420669049024582
[10/24] Train loss=0.27813300490379333
[15/24] Train loss=0.27889618277549744
[20/24] Train loss=0.24014079570770264
Test set avg_accuracy=88.32% avg_sensitivity=77.68%, avg_specificity=91.89% avg_auc=91.82%
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.284488 Test loss=0.315247 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.2959423363208771
[5/24] Train loss=0.2620006203651428
[10/24] Train loss=0.2935764491558075
[15/24] Train loss=0.26257744431495667
[20/24] Train loss=0.24123108386993408
Test set avg_accuracy=84.44% avg_sensitivity=86.48%, avg_specificity=83.75% avg_auc=92.22%
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.286892 Test loss=0.395615 Current lr=[0.000224838296036774]

[0/24] Train loss=0.31427595019340515
[5/24] Train loss=0.2457130253314972
[10/24] Train loss=0.2775895595550537
[15/24] Train loss=0.26891428232192993
[20/24] Train loss=0.22533051669597626
Test set avg_accuracy=85.79% avg_sensitivity=83.12%, avg_specificity=86.69% avg_auc=92.07%
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.280451 Test loss=0.373199 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.277096688747406
[5/24] Train loss=0.23734650015830994
[10/24] Train loss=0.2607112526893616
[15/24] Train loss=0.27798593044281006
[20/24] Train loss=0.22993768751621246
Test set avg_accuracy=88.16% avg_sensitivity=77.52%, avg_specificity=91.74% avg_auc=91.82%
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.272264 Test loss=0.325217 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.2626502811908722
[5/24] Train loss=0.22379831969738007
[10/24] Train loss=0.26414933800697327
[15/24] Train loss=0.24402077496051788
[20/24] Train loss=0.22826282680034637
Test set avg_accuracy=87.20% avg_sensitivity=72.71%, avg_specificity=92.07% avg_auc=90.31%
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.261301 Test loss=0.343684 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2616482377052307
[5/24] Train loss=0.224431574344635
[10/24] Train loss=0.26725465059280396
[15/24] Train loss=0.265699177980423
[20/24] Train loss=0.22540245950222015
Test set avg_accuracy=88.67% avg_sensitivity=82.60%, avg_specificity=90.71% avg_auc=93.72%
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.267461 Test loss=0.301106 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.2690685987472534
[5/24] Train loss=0.21650639176368713
[10/24] Train loss=0.26539167761802673
[15/24] Train loss=0.26977431774139404
[20/24] Train loss=0.2247258573770523
Test set avg_accuracy=85.00% avg_sensitivity=81.72%, avg_specificity=86.10% avg_auc=91.08%
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.259290 Test loss=0.395884 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2598353624343872
[5/24] Train loss=0.21920107305049896
[10/24] Train loss=0.24785341322422028
[15/24] Train loss=0.27278533577919006
[20/24] Train loss=0.22072483599185944
Test set avg_accuracy=86.04% avg_sensitivity=74.62%, avg_specificity=89.88% avg_auc=90.50%
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.261982 Test loss=0.359041 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.28035402297973633
[5/24] Train loss=0.23208428919315338
[10/24] Train loss=0.2567422091960907
[15/24] Train loss=0.2576524019241333
[20/24] Train loss=0.2180028110742569
Test set avg_accuracy=87.92% avg_sensitivity=81.72%, avg_specificity=90.00% avg_auc=93.09%
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.264474 Test loss=0.323377 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2703057825565338
[5/24] Train loss=0.24466007947921753
[10/24] Train loss=0.2805631160736084
[15/24] Train loss=0.2712872624397278
[20/24] Train loss=0.22473469376564026
Test set avg_accuracy=86.97% avg_sensitivity=78.30%, avg_specificity=89.88% avg_auc=91.43%
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.266193 Test loss=0.351923 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2829917371273041
[5/24] Train loss=0.2233358770608902
[10/24] Train loss=0.2473028600215912
[15/24] Train loss=0.24751149117946625
[20/24] Train loss=0.216350719332695
Test set avg_accuracy=87.30% avg_sensitivity=83.69%, avg_specificity=88.52% avg_auc=92.59%
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.252784 Test loss=0.337160 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.2588781416416168
[5/24] Train loss=0.22026120126247406
[10/24] Train loss=0.24254851043224335
[15/24] Train loss=0.242984339594841
[20/24] Train loss=0.19998005032539368
Test set avg_accuracy=87.80% avg_sensitivity=79.96%, avg_specificity=90.43% avg_auc=92.84%
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.242897 Test loss=0.322151 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.2443278282880783
[5/24] Train loss=0.20422250032424927
[10/24] Train loss=0.2262261062860489
[15/24] Train loss=0.23271135985851288
[20/24] Train loss=0.2161918431520462
Test set avg_accuracy=84.27% avg_sensitivity=85.24%, avg_specificity=83.95% avg_auc=91.58%
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.241876 Test loss=0.407024 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.26019713282585144
[5/24] Train loss=0.2206088751554489
[10/24] Train loss=0.23697958886623383
[15/24] Train loss=0.22937585413455963
[20/24] Train loss=0.22770282626152039
Test set avg_accuracy=87.37% avg_sensitivity=82.29%, avg_specificity=89.08% avg_auc=92.61%
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.244754 Test loss=0.339154 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2557956278324127
[5/24] Train loss=0.2008536159992218
[10/24] Train loss=0.22883178293704987
[15/24] Train loss=0.23010079562664032
[20/24] Train loss=0.21754388511180878
Test set avg_accuracy=88.71% avg_sensitivity=81.15%, avg_specificity=91.25% avg_auc=92.68%
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.241897 Test loss=0.314082 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.24632497131824493
[5/24] Train loss=0.2117466777563095
[10/24] Train loss=0.22132043540477753
[15/24] Train loss=0.2295096218585968
[20/24] Train loss=0.19863368570804596
Test set avg_accuracy=88.66% avg_sensitivity=82.96%, avg_specificity=90.57% avg_auc=93.09%
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.231908 Test loss=0.322412 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.2335338592529297
[5/24] Train loss=0.1996420919895172
[10/24] Train loss=0.20697332918643951
[15/24] Train loss=0.23389111459255219
[20/24] Train loss=0.20287472009658813
Test set avg_accuracy=88.20% avg_sensitivity=76.85%, avg_specificity=92.02% avg_auc=92.08%
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.227459 Test loss=0.312897 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.24705210328102112
[5/24] Train loss=0.2030390352010727
[10/24] Train loss=0.2213383913040161
[15/24] Train loss=0.21538293361663818
[20/24] Train loss=0.20156651735305786
Test set avg_accuracy=88.55% avg_sensitivity=82.50%, avg_specificity=90.59% avg_auc=93.25%
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.227369 Test loss=0.318099 Current lr=[0.000156543481933168]

[0/24] Train loss=0.24017110466957092
[5/24] Train loss=0.20243018865585327
[10/24] Train loss=0.2215532809495926
[15/24] Train loss=0.23783980309963226
[20/24] Train loss=0.1962047517299652
Test set avg_accuracy=87.19% avg_sensitivity=83.32%, avg_specificity=88.48% avg_auc=92.83%
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.225708 Test loss=0.344158 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.23186570405960083
[5/24] Train loss=0.19946308434009552
[10/24] Train loss=0.24424447119235992
[15/24] Train loss=0.21744951605796814
[20/24] Train loss=0.2008177936077118
Test set avg_accuracy=88.27% avg_sensitivity=83.48%, avg_specificity=89.88% avg_auc=93.56%
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.223789 Test loss=0.321788 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.22613054513931274
[5/24] Train loss=0.19521141052246094
[10/24] Train loss=0.2203110158443451
[15/24] Train loss=0.22454512119293213
[20/24] Train loss=0.19272887706756592
Test set avg_accuracy=86.58% avg_sensitivity=84.98%, avg_specificity=87.11% avg_auc=92.49%
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.218630 Test loss=0.367654 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.2186531275510788
[5/24] Train loss=0.19022858142852783
[10/24] Train loss=0.22480711340904236
[15/24] Train loss=0.21099911630153656
[20/24] Train loss=0.18812979757785797
Test set avg_accuracy=88.87% avg_sensitivity=78.82%, avg_specificity=92.24% avg_auc=93.17%
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.214470 Test loss=0.300043 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.22645218670368195
[5/24] Train loss=0.1849052906036377
[10/24] Train loss=0.20589850842952728
[15/24] Train loss=0.2065383344888687
[20/24] Train loss=0.18490658700466156
Test set avg_accuracy=87.11% avg_sensitivity=84.21%, avg_specificity=88.08% avg_auc=92.93%
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.211792 Test loss=0.344912 Current lr=[0.000134135431043539]

[0/24] Train loss=0.21861201524734497
[5/24] Train loss=0.18538928031921387
[10/24] Train loss=0.20638419687747955
[15/24] Train loss=0.20720823109149933
[20/24] Train loss=0.17926155030727386
Test set avg_accuracy=86.91% avg_sensitivity=83.32%, avg_specificity=88.12% avg_auc=93.09%
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.207614 Test loss=0.340820 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.2144419103860855
[5/24] Train loss=0.18761785328388214
[10/24] Train loss=0.1990404576063156
[15/24] Train loss=0.20575575530529022
[20/24] Train loss=0.1799563467502594
Test set avg_accuracy=87.99% avg_sensitivity=77.94%, avg_specificity=91.37% avg_auc=92.71%
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.204817 Test loss=0.314236 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.20704500377178192
[5/24] Train loss=0.18176263570785522
[10/24] Train loss=0.20854191482067108
[15/24] Train loss=0.20861010253429413
[20/24] Train loss=0.1787101775407791
Test set avg_accuracy=87.80% avg_sensitivity=81.67%, avg_specificity=89.86% avg_auc=92.87%
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.204802 Test loss=0.326817 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.21190112829208374
[5/24] Train loss=0.17781884968280792
[10/24] Train loss=0.19363601505756378
[15/24] Train loss=0.2018754631280899
[20/24] Train loss=0.17827658355236053
Test set avg_accuracy=88.72% avg_sensitivity=77.78%, avg_specificity=92.40% avg_auc=93.15%
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.201162 Test loss=0.304092 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.21186700463294983
[5/24] Train loss=0.17973443865776062
[10/24] Train loss=0.18892823159694672
[15/24] Train loss=0.20373092591762543
[20/24] Train loss=0.18505190312862396
Test set avg_accuracy=87.53% avg_sensitivity=83.69%, avg_specificity=88.82% avg_auc=93.09%
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.203117 Test loss=0.338857 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.21726632118225098
[5/24] Train loss=0.19765876233577728
[10/24] Train loss=0.2025865614414215
[15/24] Train loss=0.21048253774642944
[20/24] Train loss=0.18529260158538818
Test set avg_accuracy=87.96% avg_sensitivity=82.03%, avg_specificity=89.95% avg_auc=93.30%
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.207607 Test loss=0.327250 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.20604118704795837
[5/24] Train loss=0.18149138987064362
[10/24] Train loss=0.19487768411636353
[15/24] Train loss=0.2116912603378296
[20/24] Train loss=0.1846667230129242
Test set avg_accuracy=88.54% avg_sensitivity=73.95%, avg_specificity=93.44% avg_auc=92.12%
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.209400 Test loss=0.321757 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.20854642987251282
[5/24] Train loss=0.1856825351715088
[10/24] Train loss=0.2174534648656845
[15/24] Train loss=0.20074494183063507
[20/24] Train loss=0.17143981158733368
Test set avg_accuracy=88.48% avg_sensitivity=78.61%, avg_specificity=91.79% avg_auc=92.43%
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.206449 Test loss=0.313586 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.21509724855422974
[5/24] Train loss=0.17563821375370026
[10/24] Train loss=0.1920105665922165
[15/24] Train loss=0.19644321501255035
[20/24] Train loss=0.17149683833122253
Test set avg_accuracy=88.19% avg_sensitivity=73.17%, avg_specificity=93.23% avg_auc=91.59%
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.199886 Test loss=0.317381 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.21285231411457062
[5/24] Train loss=0.1668713539838791
[10/24] Train loss=0.1930997520685196
[15/24] Train loss=0.19684389233589172
[20/24] Train loss=0.16503900289535522
Test set avg_accuracy=88.52% avg_sensitivity=74.37%, avg_specificity=93.27% avg_auc=91.80%
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.194771 Test loss=0.316535 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.2014537900686264
[5/24] Train loss=0.1706070452928543
[10/24] Train loss=0.18232859671115875
[15/24] Train loss=0.200016051530838
[20/24] Train loss=0.16599993407726288
Test set avg_accuracy=88.27% avg_sensitivity=76.54%, avg_specificity=92.21% avg_auc=92.12%
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.191155 Test loss=0.317436 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.18924027681350708
[5/24] Train loss=0.17235973477363586
[10/24] Train loss=0.17879392206668854
[15/24] Train loss=0.1895369589328766
[20/24] Train loss=0.1701146811246872
Test set avg_accuracy=88.87% avg_sensitivity=76.95%, avg_specificity=92.87% avg_auc=92.56%
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.191444 Test loss=0.302365 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.19106757640838623
[5/24] Train loss=0.1643572747707367
[10/24] Train loss=0.1829761564731598
[15/24] Train loss=0.19196249544620514
[20/24] Train loss=0.16733711957931519
Test set avg_accuracy=88.89% avg_sensitivity=77.47%, avg_specificity=92.73% avg_auc=92.45%
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.188163 Test loss=0.306370 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.1886509358882904
[5/24] Train loss=0.16092748939990997
[10/24] Train loss=0.1845020204782486
[15/24] Train loss=0.18436458706855774
[20/24] Train loss=0.16169030964374542
Test set avg_accuracy=88.71% avg_sensitivity=83.01%, avg_specificity=90.62% avg_auc=92.68%
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.184673 Test loss=0.315034 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.19302764534950256
[5/24] Train loss=0.15370073914527893
[10/24] Train loss=0.17248614132404327
[15/24] Train loss=0.17701353132724762
[20/24] Train loss=0.15610508620738983
Test set avg_accuracy=88.58% avg_sensitivity=79.60%, avg_specificity=91.60% avg_auc=92.41%
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.182017 Test loss=0.316905 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.18354690074920654
[5/24] Train loss=0.15816253423690796
[10/24] Train loss=0.1738155484199524
[15/24] Train loss=0.1833406239748001
[20/24] Train loss=0.15744730830192566
Test set avg_accuracy=88.62% avg_sensitivity=82.65%, avg_specificity=90.62% avg_auc=92.82%
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.179730 Test loss=0.317478 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.1853027194738388
[5/24] Train loss=0.1587456911802292
[10/24] Train loss=0.1726466417312622
[15/24] Train loss=0.18036380410194397
[20/24] Train loss=0.1617097556591034
Test set avg_accuracy=88.89% avg_sensitivity=81.56%, avg_specificity=91.36% avg_auc=92.43%
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.176904 Test loss=0.316209 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.18434719741344452
[5/24] Train loss=0.15623754262924194
[10/24] Train loss=0.17180529236793518
[15/24] Train loss=0.17377491295337677
[20/24] Train loss=0.15584082901477814
Test set avg_accuracy=88.97% avg_sensitivity=80.48%, avg_specificity=91.82% avg_auc=92.64%
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.175948 Test loss=0.310336 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.1849725842475891
[5/24] Train loss=0.15638908743858337
[10/24] Train loss=0.16697148978710175
[15/24] Train loss=0.17828713357448578
[20/24] Train loss=0.15503066778182983
Test set avg_accuracy=88.62% avg_sensitivity=80.01%, avg_specificity=91.51% avg_auc=92.60%
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.176734 Test loss=0.313752 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.17654849588871002
[5/24] Train loss=0.1595657616853714
[10/24] Train loss=0.1704297512769699
[15/24] Train loss=0.18493828177452087
[20/24] Train loss=0.15395928919315338
Test set avg_accuracy=88.32% avg_sensitivity=75.50%, avg_specificity=92.62% avg_auc=91.88%
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.176799 Test loss=0.318211 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18350906670093536
[5/24] Train loss=0.16088591516017914
[10/24] Train loss=0.16224658489227295
[15/24] Train loss=0.18733841180801392
[20/24] Train loss=0.15277720987796783
Test set avg_accuracy=89.00% avg_sensitivity=79.70%, avg_specificity=92.12% avg_auc=92.71%
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.174098 Test loss=0.309473 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.178201362490654
[5/24] Train loss=0.15874116122722626
[10/24] Train loss=0.16819500923156738
[15/24] Train loss=0.17814329266548157
[20/24] Train loss=0.1568455994129181
Test set avg_accuracy=88.33% avg_sensitivity=76.75%, avg_specificity=92.22% avg_auc=91.72%
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.174933 Test loss=0.324429 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.1767316609621048
[5/24] Train loss=0.16280877590179443
[10/24] Train loss=0.16505619883537292
[15/24] Train loss=0.17944778501987457
[20/24] Train loss=0.15605375170707703
Test set avg_accuracy=88.53% avg_sensitivity=82.50%, avg_specificity=90.55% avg_auc=92.58%
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.177312 Test loss=0.321714 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.1787322759628296
[5/24] Train loss=0.1573634296655655
[10/24] Train loss=0.17583879828453064
[15/24] Train loss=0.1732972115278244
[20/24] Train loss=0.1547425389289856
Test set avg_accuracy=87.57% avg_sensitivity=85.19%, avg_specificity=88.36% avg_auc=92.63%
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.176287 Test loss=0.350170 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.1798439621925354
[5/24] Train loss=0.15894487500190735
[10/24] Train loss=0.17260701954364777
[15/24] Train loss=0.173723965883255
[20/24] Train loss=0.15465766191482544
Test set avg_accuracy=88.50% avg_sensitivity=80.94%, avg_specificity=91.04% avg_auc=92.17%
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.175329 Test loss=0.321382 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.1798545867204666
[5/24] Train loss=0.15386302769184113
[10/24] Train loss=0.1663106232881546
[15/24] Train loss=0.16861118376255035
[20/24] Train loss=0.15276025235652924
Test set avg_accuracy=88.33% avg_sensitivity=82.55%, avg_specificity=90.28% avg_auc=92.37%
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.173174 Test loss=0.329187 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.17407287657260895
[5/24] Train loss=0.16060906648635864
[10/24] Train loss=0.16527514159679413
[15/24] Train loss=0.1710856556892395
[20/24] Train loss=0.1537124067544937
Test set avg_accuracy=89.27% avg_sensitivity=81.41%, avg_specificity=91.91% avg_auc=92.56%
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.173136 Test loss=0.308674 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.17278410494327545
[5/24] Train loss=0.16111035645008087
[10/24] Train loss=0.1680392622947693
[15/24] Train loss=0.16687484085559845
[20/24] Train loss=0.16376672685146332
Test set avg_accuracy=88.53% avg_sensitivity=82.19%, avg_specificity=90.66% avg_auc=92.78%
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.173508 Test loss=0.317675 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.17249587178230286
[5/24] Train loss=0.1500769704580307
[10/24] Train loss=0.16993173956871033
[15/24] Train loss=0.1681295484304428
[20/24] Train loss=0.1521819829940796
Test set avg_accuracy=88.01% avg_sensitivity=81.98%, avg_specificity=90.03% avg_auc=92.66%
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.172472 Test loss=0.330007 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1790846884250641
[5/24] Train loss=0.147618368268013
[10/24] Train loss=0.16356612741947174
[15/24] Train loss=0.17299553751945496
[20/24] Train loss=0.14239372313022614
Test set avg_accuracy=88.57% avg_sensitivity=81.31%, avg_specificity=91.01% avg_auc=92.53%
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.170006 Test loss=0.321399 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.17516285181045532
[5/24] Train loss=0.14888307452201843
[10/24] Train loss=0.15717503428459167
[15/24] Train loss=0.1673150509595871
[20/24] Train loss=0.1479853093624115
Test set avg_accuracy=88.95% avg_sensitivity=80.63%, avg_specificity=91.74% avg_auc=92.83%
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.167252 Test loss=0.307214 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.1701088398694992
[5/24] Train loss=0.14658358693122864
[10/24] Train loss=0.16161629557609558
[15/24] Train loss=0.1618693619966507
[20/24] Train loss=0.14265452325344086
Test set avg_accuracy=88.72% avg_sensitivity=81.87%, avg_specificity=91.02% avg_auc=92.81%
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.164349 Test loss=0.313911 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.16587863862514496
[5/24] Train loss=0.15116046369075775
[10/24] Train loss=0.1579904407262802
[15/24] Train loss=0.16232256591320038
[20/24] Train loss=0.14468976855278015
Test set avg_accuracy=88.91% avg_sensitivity=81.10%, avg_specificity=91.53% avg_auc=92.74%
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.163155 Test loss=0.309937 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.16743189096450806
[5/24] Train loss=0.14840641617774963
[10/24] Train loss=0.15719376504421234
[15/24] Train loss=0.16328957676887512
[20/24] Train loss=0.14285677671432495
Test set avg_accuracy=88.89% avg_sensitivity=81.46%, avg_specificity=91.39% avg_auc=92.77%
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.163056 Test loss=0.311585 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16929849982261658
[5/24] Train loss=0.14641065895557404
[10/24] Train loss=0.1549726277589798
[15/24] Train loss=0.16092361509799957
[20/24] Train loss=0.14408816397190094
Test set avg_accuracy=89.02% avg_sensitivity=81.10%, avg_specificity=91.69% avg_auc=92.66%
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.160965 Test loss=0.311437 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.16547375917434692
[5/24] Train loss=0.14367206394672394
[10/24] Train loss=0.15455296635627747
[15/24] Train loss=0.1595197468996048
[20/24] Train loss=0.1434577852487564
Test set avg_accuracy=88.65% avg_sensitivity=81.15%, avg_specificity=91.16% avg_auc=92.62%
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.161658 Test loss=0.314814 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.1640487164258957
[5/24] Train loss=0.1464761346578598
[10/24] Train loss=0.1531515270471573
[15/24] Train loss=0.15581029653549194
[20/24] Train loss=0.14448633790016174
Test set avg_accuracy=89.00% avg_sensitivity=81.05%, avg_specificity=91.67% avg_auc=92.69%
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.160665 Test loss=0.309854 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.1641063392162323
[5/24] Train loss=0.1461547315120697
[10/24] Train loss=0.15458352863788605
[15/24] Train loss=0.15437720715999603
[20/24] Train loss=0.14265955984592438
Test set avg_accuracy=88.78% avg_sensitivity=81.51%, avg_specificity=91.22% avg_auc=92.91%
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.161469 Test loss=0.312098 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16227039694786072
[5/24] Train loss=0.14780882000923157
[10/24] Train loss=0.15310056507587433
[15/24] Train loss=0.15568962693214417
[20/24] Train loss=0.1412278562784195
Test set avg_accuracy=88.87% avg_sensitivity=80.94%, avg_specificity=91.53% avg_auc=92.80%
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.160816 Test loss=0.309354 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.16332586109638214
[5/24] Train loss=0.14207430183887482
[10/24] Train loss=0.1532248556613922
[15/24] Train loss=0.1578575223684311
[20/24] Train loss=0.141402468085289
Test set avg_accuracy=88.93% avg_sensitivity=81.10%, avg_specificity=91.56% avg_auc=92.75%
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.160801 Test loss=0.310532 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.16327480971813202
[5/24] Train loss=0.14239263534545898
[10/24] Train loss=0.1558259129524231
[15/24] Train loss=0.15929776430130005
[20/24] Train loss=0.14233236014842987
Test set avg_accuracy=88.92% avg_sensitivity=81.20%, avg_specificity=91.51% avg_auc=92.76%
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.159818 Test loss=0.311348 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.1653222292661667
[5/24] Train loss=0.1446649730205536
[10/24] Train loss=0.1517656445503235
[15/24] Train loss=0.15789204835891724
[20/24] Train loss=0.14097781479358673
Test set avg_accuracy=88.76% avg_sensitivity=81.20%, avg_specificity=91.30% avg_auc=92.72%
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.159723 Test loss=0.312854 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.16896042227745056
[5/24] Train loss=0.1434754878282547
[10/24] Train loss=0.15283377468585968
[15/24] Train loss=0.15641266107559204
[20/24] Train loss=0.14106270670890808
Test set avg_accuracy=88.88% avg_sensitivity=80.99%, avg_specificity=91.53% avg_auc=92.71%
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.159189 Test loss=0.311715 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.1600993573665619
[5/24] Train loss=0.14307233691215515
[10/24] Train loss=0.15219134092330933
[15/24] Train loss=0.15736691653728485
[20/24] Train loss=0.14208094775676727
Test set avg_accuracy=88.89% avg_sensitivity=80.79%, avg_specificity=91.62% avg_auc=92.73%
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.158751 Test loss=0.310441 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.1623007208108902
[5/24] Train loss=0.14450061321258545
[10/24] Train loss=0.14952099323272705
[15/24] Train loss=0.1553550660610199
[20/24] Train loss=0.13988563418388367
Test set avg_accuracy=88.87% avg_sensitivity=80.94%, avg_specificity=91.53% avg_auc=92.73%
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.159036 Test loss=0.310737 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.16242535412311554
[5/24] Train loss=0.14305342733860016
[10/24] Train loss=0.15470759570598602
[15/24] Train loss=0.15329135954380035
[20/24] Train loss=0.13886335492134094
Test set avg_accuracy=88.92% avg_sensitivity=80.94%, avg_specificity=91.60% avg_auc=92.72%
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.158349 Test loss=0.310463 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16374050080776215
[5/24] Train loss=0.143651083111763
[10/24] Train loss=0.1551550030708313
[15/24] Train loss=0.1578780859708786
[20/24] Train loss=0.14291277527809143
Test set avg_accuracy=88.91% avg_sensitivity=80.89%, avg_specificity=91.60% avg_auc=92.72%
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.159228 Test loss=0.310293 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.16244351863861084
[5/24] Train loss=0.14287836849689484
[10/24] Train loss=0.15140406787395477
[15/24] Train loss=0.16006328165531158
[20/24] Train loss=0.13940246403217316
Test set avg_accuracy=88.84% avg_sensitivity=80.89%, avg_specificity=91.51% avg_auc=92.72%
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.158790 Test loss=0.310780 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.1640426069498062
[5/24] Train loss=0.14234048128128052
[10/24] Train loss=0.1530037820339203
[15/24] Train loss=0.15650522708892822
[20/24] Train loss=0.1439104825258255
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=88.92% avg_sensitivity=80.94%, avg_specificity=91.60% avg_auc=92.72%
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.158872 Test loss=0.310566 Current lr=[1.3165623068326024e-09]

Fold[8] Result: acc=89.31% sen=86.90%, spe=90.12%, auc=95.18%!
Fold[8] Avg_overlap=0.68%(0.24667479477979018)
[0/23] Train loss=1.4828077554702759
[5/23] Train loss=1.4801443815231323
[10/23] Train loss=1.4811124801635742
[15/23] Train loss=1.447646975517273
[20/23] Train loss=1.416993260383606
Test set avg_accuracy=60.57% avg_sensitivity=49.38%, avg_specificity=64.14% avg_auc=59.09%
Best model saved!! Metric=-92.8201076383667!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=1.461934 Test loss=0.672069 Current lr=[1.23514552994466e-05]

[0/23] Train loss=1.421494483947754
[5/23] Train loss=1.389231562614441
[10/23] Train loss=1.4115502834320068
[15/23] Train loss=1.3757684230804443
[20/23] Train loss=1.351185917854309
Test set avg_accuracy=63.31% avg_sensitivity=62.48%, avg_specificity=63.57% avg_auc=68.93%
Best model saved!! Metric=-67.71273771685773!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=1.394494 Test loss=0.638135 Current lr=[1.3404105630737565e-05]

[0/23] Train loss=1.3351255655288696
[5/23] Train loss=1.3516979217529297
[10/23] Train loss=1.343288540840149
[15/23] Train loss=1.2941162586212158
[20/23] Train loss=1.2905879020690918
Test set avg_accuracy=66.45% avg_sensitivity=70.24%, avg_specificity=65.24% avg_auc=74.38%
Best model saved!! Metric=-49.69241062390823!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=1.330072 Test loss=0.611410 Current lr=[1.515281266696464e-05]

[0/23] Train loss=1.281477689743042
[5/23] Train loss=1.2817915678024292
[10/23] Train loss=1.2870029211044312
[15/23] Train loss=1.2388168573379517
[20/23] Train loss=1.2025617361068726
Test set avg_accuracy=68.48% avg_sensitivity=77.84%, avg_specificity=65.49% avg_auc=78.30%
Best model saved!! Metric=-35.882656869989475!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=1.265264 Test loss=0.597537 Current lr=[1.758904040319645e-05]

[0/23] Train loss=1.2098422050476074
[5/23] Train loss=1.1952215433120728
[10/23] Train loss=1.2304881811141968
[15/23] Train loss=1.1570096015930176
[20/23] Train loss=1.1502894163131714
Test set avg_accuracy=70.61% avg_sensitivity=82.16%, avg_specificity=66.94% avg_auc=81.39%
Best model saved!! Metric=-24.909763484560145!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=1.196120 Test loss=0.576761 Current lr=[2.0700896823480782e-05]

[0/23] Train loss=1.1275930404663086
[5/23] Train loss=1.1318694353103638
[10/23] Train loss=1.1645997762680054
[15/23] Train loss=1.0747178792953491
[20/23] Train loss=1.0802096128463745
Test set avg_accuracy=71.02% avg_sensitivity=85.50%, avg_specificity=66.40% avg_auc=83.80%
Best model saved!! Metric=-19.28384632792705!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=1.128025 Test loss=0.565668 Current lr=[2.4473191949622817e-05]

[0/23] Train loss=1.0619840621948242
[5/23] Train loss=1.0730379819869995
[10/23] Train loss=1.0945326089859009
[15/23] Train loss=1.0214226245880127
[20/23] Train loss=1.0216079950332642
Test set avg_accuracy=73.66% avg_sensitivity=87.12%, avg_specificity=69.37% avg_auc=86.17%
Best model saved!! Metric=-9.682251533042972!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=1.063843 Test loss=0.529890 Current lr=[2.8887511988384316e-05]

[0/23] Train loss=1.010477066040039
[5/23] Train loss=0.9907470941543579
[10/23] Train loss=1.0370917320251465
[15/23] Train loss=0.9656456708908081
[20/23] Train loss=0.962070643901825
Test set avg_accuracy=75.72% avg_sensitivity=88.03%, avg_specificity=71.79% avg_auc=88.37%
Best model saved!! Metric=-2.087405639891813!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=1.007420 Test loss=0.500046 Current lr=[3.3922309215166904e-05]

[0/23] Train loss=0.9511685371398926
[5/23] Train loss=0.9508902430534363
[10/23] Train loss=0.9790022969245911
[15/23] Train loss=0.9178145527839661
[20/23] Train loss=0.9027512669563293
Test set avg_accuracy=78.87% avg_sensitivity=86.58%, avg_specificity=76.41% avg_auc=90.18%
Best model saved!! Metric=6.0396410242876755!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.950927 Test loss=0.461997 Current lr=[3.955300715542903e-05]

[0/23] Train loss=0.8839002251625061
[5/23] Train loss=0.9160552024841309
[10/23] Train loss=0.9283294081687927
[15/23] Train loss=0.8745189905166626
[20/23] Train loss=0.8496891260147095
Test set avg_accuracy=81.03% avg_sensitivity=87.01%, avg_specificity=79.12% avg_auc=91.29%
Best model saved!! Metric=12.450632576042395!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.899195 Test loss=0.435409 Current lr=[4.575212055041121e-05]

[0/23] Train loss=0.8484987020492554
[5/23] Train loss=0.8365358710289001
[10/23] Train loss=0.8968432545661926
[15/23] Train loss=0.8249840140342712
[20/23] Train loss=0.8126882910728455
Test set avg_accuracy=82.86% avg_sensitivity=86.20%, avg_specificity=81.80% avg_auc=91.99%
Best model saved!! Metric=16.853190855052844!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.853428 Test loss=0.409626 Current lr=[5.2489389521578206e-05]

[0/23] Train loss=0.8056038618087769
[5/23] Train loss=0.7963590621948242
[10/23] Train loss=0.8530192375183105
[15/23] Train loss=0.7945480942726135
[20/23] Train loss=0.7574965357780457
Test set avg_accuracy=84.24% avg_sensitivity=85.82%, avg_specificity=83.74% avg_auc=92.65%
Best model saved!! Metric=20.462160337351392!!
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.813514 Test loss=0.383703 Current lr=[5.9731927278878344e-05]

[0/23] Train loss=0.7738176584243774
[5/23] Train loss=0.7663711905479431
[10/23] Train loss=0.830573558807373
[15/23] Train loss=0.75809645652771
[20/23] Train loss=0.7258743643760681
Test set avg_accuracy=85.61% avg_sensitivity=83.88%, avg_specificity=86.16% avg_auc=92.89%
Best model saved!! Metric=22.54514900112403!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.777202 Test loss=0.359461 Current lr=[6.744438065180833e-05]

[0/23] Train loss=0.7262623310089111
[5/23] Train loss=0.7345046997070312
[10/23] Train loss=0.8130679130554199
[15/23] Train loss=0.7170999646186829
[20/23] Train loss=0.6939205527305603
Test set avg_accuracy=86.43% avg_sensitivity=82.53%, avg_specificity=87.67% avg_auc=93.06%
Best model saved!! Metric=23.701562747031772!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.751063 Test loss=0.339783 Current lr=[7.558910265967854e-05]

[0/23] Train loss=0.7043099999427795
[5/23] Train loss=0.685126543045044
[10/23] Train loss=0.7738565802574158
[15/23] Train loss=0.6907482147216797
[20/23] Train loss=0.66804039478302
Test set avg_accuracy=85.94% avg_sensitivity=84.96%, avg_specificity=86.25% avg_auc=93.29%
Best model saved!! Metric=24.436705256643094!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.723753 Test loss=0.345574 Current lr=[8.412633627870859e-05]

[0/23] Train loss=0.6935955286026001
[5/23] Train loss=0.6737352609634399
[10/23] Train loss=0.7618456482887268
[15/23] Train loss=0.6651926040649414
[20/23] Train loss=0.6238836646080017
Test set avg_accuracy=86.97% avg_sensitivity=83.29%, avg_specificity=88.14% avg_auc=93.53%
Best model saved!! Metric=25.923530468295112!!
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.697364 Test loss=0.321164 Current lr=[9.301440850892597e-05]

[0/23] Train loss=0.6545900106430054
[5/23] Train loss=0.6592822670936584
[10/23] Train loss=0.7530750632286072
[15/23] Train loss=0.6559445261955261
[20/23] Train loss=0.6003002524375916
Test set avg_accuracy=86.26% avg_sensitivity=85.66%, avg_specificity=86.45% avg_auc=93.52%
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.682495 Test loss=0.332485 Current lr=[0.00010220993379356441]

[0/23] Train loss=0.655157744884491
[5/23] Train loss=0.6206897497177124
[10/23] Train loss=0.7308216094970703
[15/23] Train loss=0.628983199596405
[20/23] Train loss=0.6005130410194397
Test set avg_accuracy=87.50% avg_sensitivity=82.16%, avg_specificity=89.20% avg_auc=93.55%
Best model saved!! Metric=26.406956028828247!!
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.667618 Test loss=0.304976 Current lr=[0.00011166802579800605]

[0/23] Train loss=0.6283730864524841
[5/23] Train loss=0.5995928645133972
[10/23] Train loss=0.717085063457489
[15/23] Train loss=0.6256496906280518
[20/23] Train loss=0.5822618007659912
Test set avg_accuracy=85.77% avg_sensitivity=87.82%, avg_specificity=85.12% avg_auc=93.92%
Best model saved!! Metric=26.62434475728709!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.651182 Test loss=0.334147 Current lr=[0.00012134251651450635]

[0/23] Train loss=0.61898273229599
[5/23] Train loss=0.5849053859710693
[10/23] Train loss=0.6965845823287964
[15/23] Train loss=0.5970069169998169
[20/23] Train loss=0.5516475439071655
Test set avg_accuracy=87.88% avg_sensitivity=83.40%, avg_specificity=89.30% avg_auc=93.88%
Best model saved!! Metric=28.457681211655867!!
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.633627 Test loss=0.299413 Current lr=[0.0001311861816231797]

[0/23] Train loss=0.5932976603507996
[5/23] Train loss=0.5768893361091614
[10/23] Train loss=0.7061697244644165
[15/23] Train loss=0.5962885618209839
[20/23] Train loss=0.5455656051635742
Test set avg_accuracy=88.16% avg_sensitivity=83.34%, avg_specificity=89.70% avg_auc=94.13%
Best model saved!! Metric=29.334216242928875!!
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.624977 Test loss=0.289324 Current lr=[0.00014115097100918686]

[0/23] Train loss=0.5889691114425659
[5/23] Train loss=0.5635584592819214
[10/23] Train loss=0.7172757387161255
[15/23] Train loss=0.5832489132881165
[20/23] Train loss=0.5418822169303894
Test set avg_accuracy=89.66% avg_sensitivity=74.77%, avg_specificity=94.40% avg_auc=93.60%
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.615275 Test loss=0.266253 Current lr=[0.00015118824331089486]

[0/23] Train loss=0.5785227417945862
[5/23] Train loss=0.5292723178863525
[10/23] Train loss=0.6733638048171997
[15/23] Train loss=0.5664528012275696
[20/23] Train loss=0.5228182673454285
Test set avg_accuracy=88.89% avg_sensitivity=79.46%, avg_specificity=91.90% avg_auc=93.87%
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.597414 Test loss=0.272823 Current lr=[0.00016124900335410332]

[0/23] Train loss=0.5645219683647156
[5/23] Train loss=0.5364903807640076
[10/23] Train loss=0.6793997883796692
[15/23] Train loss=0.5633590817451477
[20/23] Train loss=0.5098832249641418
Test set avg_accuracy=89.43% avg_sensitivity=75.80%, avg_specificity=93.77% avg_auc=93.68%
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.588053 Test loss=0.266170 Current lr=[0.0001712841413133449]

[0/23] Train loss=0.5610129237174988
[5/23] Train loss=0.5256397128105164
[10/23] Train loss=0.6409497857093811
[15/23] Train loss=0.537384033203125
[20/23] Train loss=0.5035691261291504
Test set avg_accuracy=89.31% avg_sensitivity=77.74%, avg_specificity=93.00% avg_auc=93.86%
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.574816 Test loss=0.264373 Current lr=[0.00018124467243283562]

[0/23] Train loss=0.5331482291221619
[5/23] Train loss=0.5082098841667175
[10/23] Train loss=0.6304140686988831
[15/23] Train loss=0.5380052328109741
[20/23] Train loss=0.4937076270580292
Test set avg_accuracy=87.37% avg_sensitivity=85.66%, avg_specificity=87.91% avg_auc=94.41%
Best model saved!! Metric=29.35789943710499!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.564559 Test loss=0.293521 Current lr=[0.00019108197613691916]

[0/23] Train loss=0.5293926000595093
[5/23] Train loss=0.5076383352279663
[10/23] Train loss=0.631630003452301
[15/23] Train loss=0.5149295926094055
[20/23] Train loss=0.490197092294693
Test set avg_accuracy=88.36% avg_sensitivity=85.18%, avg_specificity=89.37% avg_auc=94.51%
Best model saved!! Metric=31.414072314993675!!
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.554668 Test loss=0.283051 Current lr=[0.0002007480333628308]

[0/23] Train loss=0.5095701217651367
[5/23] Train loss=0.4903627038002014
[10/23] Train loss=0.6126763224601746
[15/23] Train loss=0.5081548094749451
[20/23] Train loss=0.4649881422519684
Test set avg_accuracy=89.31% avg_sensitivity=80.97%, avg_specificity=91.97% avg_auc=94.41%
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.541528 Test loss=0.259431 Current lr=[0.00021019566095728168]

[0/23] Train loss=0.4912491738796234
[5/23] Train loss=0.4930289089679718
[10/23] Train loss=0.587026059627533
[15/23] Train loss=0.5218958258628845
[20/23] Train loss=0.4707261919975281
Test set avg_accuracy=80.68% avg_sensitivity=92.13%, avg_specificity=77.03% avg_auc=93.83%
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.530900 Test loss=0.427231 Current lr=[0.00021937874199269854]

[0/23] Train loss=0.5099055767059326
[5/23] Train loss=0.4629531502723694
[10/23] Train loss=0.5733495354652405
[15/23] Train loss=0.4962104558944702
[20/23] Train loss=0.46296265721321106
Test set avg_accuracy=85.21% avg_sensitivity=89.54%, avg_specificity=83.83% avg_auc=94.50%
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.521624 Test loss=0.342273 Current lr=[0.00022825245087887105]

[0/23] Train loss=0.4798130989074707
[5/23] Train loss=0.4638194441795349
[10/23] Train loss=0.5405497550964355
[15/23] Train loss=0.488237589597702
[20/23] Train loss=0.4577963948249817
Test set avg_accuracy=89.40% avg_sensitivity=76.01%, avg_specificity=93.67% avg_auc=93.47%
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.512292 Test loss=0.266600 Current lr=[0.0002367734721711633]

[0/23] Train loss=0.49621108174324036
[5/23] Train loss=0.4571998119354248
[10/23] Train loss=0.528862714767456
[15/23] Train loss=0.47703033685684204
[20/23] Train loss=0.45105382800102234
Test set avg_accuracy=88.82% avg_sensitivity=78.38%, avg_specificity=92.14% avg_auc=93.49%
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.505796 Test loss=0.273160 Current lr=[0.00024490021200721586]

[0/23] Train loss=0.48111093044281006
[5/23] Train loss=0.4517078399658203
[10/23] Train loss=0.5037857890129089
[15/23] Train loss=0.47202759981155396
[20/23] Train loss=0.462395042181015
Test set avg_accuracy=89.86% avg_sensitivity=77.20%, avg_specificity=93.89% avg_auc=93.97%
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.487202 Test loss=0.252923 Current lr=[0.00025259300114004814]

[0/23] Train loss=0.4689607620239258
[5/23] Train loss=0.46291300654411316
[10/23] Train loss=0.519143283367157
[15/23] Train loss=0.4939894676208496
[20/23] Train loss=0.4226829707622528
Test set avg_accuracy=88.61% avg_sensitivity=82.86%, avg_specificity=90.44% avg_auc=94.18%
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.486676 Test loss=0.278084 Current lr=[0.0002598142885764899]

[0/23] Train loss=0.4625827968120575
[5/23] Train loss=0.4197656214237213
[10/23] Train loss=0.4964006245136261
[15/23] Train loss=0.46521180868148804
[20/23] Train loss=0.4343510866165161
Test set avg_accuracy=85.39% avg_sensitivity=88.14%, avg_specificity=84.52% avg_auc=93.85%
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.475347 Test loss=0.347864 Current lr=[0.0002665288248757305]

[0/23] Train loss=0.43618065118789673
[5/23] Train loss=0.4203985035419464
[10/23] Train loss=0.4914499521255493
[15/23] Train loss=0.47480103373527527
[20/23] Train loss=0.41720473766326904
Test set avg_accuracy=85.96% avg_sensitivity=89.06%, avg_specificity=84.98% avg_auc=94.08%
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.469210 Test loss=0.342094 Current lr=[0.00027270383421324645]

[0/23] Train loss=0.4530567526817322
[5/23] Train loss=0.3783453106880188
[10/23] Train loss=0.46578460931777954
[15/23] Train loss=0.44252079725265503
[20/23] Train loss=0.4151487946510315
Test set avg_accuracy=85.16% avg_sensitivity=89.60%, avg_specificity=83.74% avg_auc=93.99%
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.458449 Test loss=0.353158 Current lr=[0.0002783091743702071]

[0/23] Train loss=0.4401669204235077
[5/23] Train loss=0.4012604057788849
[10/23] Train loss=0.5050220489501953
[15/23] Train loss=0.44639769196510315
[20/23] Train loss=0.42190641164779663
Test set avg_accuracy=88.31% avg_sensitivity=77.09%, avg_specificity=91.88% avg_auc=93.43%
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.473404 Test loss=0.279206 Current lr=[0.0002833174838673991]

[0/23] Train loss=0.43558746576309204
[5/23] Train loss=0.3912908732891083
[10/23] Train loss=0.469041109085083
[15/23] Train loss=0.44105008244514465
[20/23] Train loss=0.3985229730606079
Test set avg_accuracy=86.45% avg_sensitivity=86.15%, avg_specificity=86.54% avg_auc=94.05%
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.461960 Test loss=0.310634 Current lr=[0.0002877043155254605]

[0/23] Train loss=0.419100284576416
[5/23] Train loss=0.366188645362854
[10/23] Train loss=0.4487612545490265
[15/23] Train loss=0.4530926048755646
[20/23] Train loss=0.39354559779167175
Test set avg_accuracy=89.04% avg_sensitivity=78.33%, avg_specificity=92.45% avg_auc=93.30%
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.443906 Test loss=0.273517 Current lr=[0.0002914482557994746]

[0/23] Train loss=0.4104387164115906
[5/23] Train loss=0.3609314560890198
[10/23] Train loss=0.44998541474342346
[15/23] Train loss=0.4491139352321625
[20/23] Train loss=0.366539865732193
Test set avg_accuracy=85.95% avg_sensitivity=83.77%, avg_specificity=86.64% avg_auc=92.67%
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.431262 Test loss=0.337302 Current lr=[0.00029453102930541205]

[0/23] Train loss=0.3977874219417572
[5/23] Train loss=0.3539535105228424
[10/23] Train loss=0.3857789635658264
[15/23] Train loss=0.43269702792167664
[20/23] Train loss=0.37188783288002014
Test set avg_accuracy=82.83% avg_sensitivity=92.78%, avg_specificity=79.66% avg_auc=94.33%
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.420401 Test loss=0.400538 Current lr=[0.00029693758802819427]

[0/23] Train loss=0.38261592388153076
[5/23] Train loss=0.3534185290336609
[10/23] Train loss=0.43251675367355347
[15/23] Train loss=0.41635411977767944
[20/23] Train loss=0.38154712319374084
Test set avg_accuracy=88.76% avg_sensitivity=68.73%, avg_specificity=95.14% avg_auc=91.73%
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.412880 Test loss=0.292490 Current lr=[0.00029865618477592477]

[0/23] Train loss=0.37712135910987854
[5/23] Train loss=0.34592345356941223
[10/23] Train loss=0.4106273353099823
[15/23] Train loss=0.4230353832244873
[20/23] Train loss=0.36278489232063293
Test set avg_accuracy=86.77% avg_sensitivity=79.30%, avg_specificity=89.15% avg_auc=92.54%
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.403659 Test loss=0.319321 Current lr=[0.00029967843052173404]

[0/23] Train loss=0.3783628046512604
[5/23] Train loss=0.36744216084480286
[10/23] Train loss=0.4363255500793457
[15/23] Train loss=0.4108322262763977
[20/23] Train loss=0.38320139050483704
Test set avg_accuracy=82.80% avg_sensitivity=91.32%, avg_specificity=80.09% avg_auc=93.98%
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.424294 Test loss=0.402531 Current lr=[0.0002999998730814972]

[0/23] Train loss=0.403897762298584
[5/23] Train loss=0.35205113887786865
[10/23] Train loss=0.3991190195083618
[15/23] Train loss=0.415587455034256
[20/23] Train loss=0.3774641156196594
Test set avg_accuracy=87.19% avg_sensitivity=83.83%, avg_specificity=88.26% avg_auc=93.46%
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.408427 Test loss=0.308223 Current lr=[0.000299926900870094]

[0/23] Train loss=0.39602547883987427
[5/23] Train loss=0.32380908727645874
[10/23] Train loss=0.4275886118412018
[15/23] Train loss=0.4115425944328308
[20/23] Train loss=0.35301610827445984
Test set avg_accuracy=83.93% avg_sensitivity=89.16%, avg_specificity=82.27% avg_auc=93.19%
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.403346 Test loss=0.387746 Current lr=[0.00029971972431444435]

[0/23] Train loss=0.3697877526283264
[5/23] Train loss=0.33354464173316956
[10/23] Train loss=0.3952658474445343
[15/23] Train loss=0.4081946313381195
[20/23] Train loss=0.3229057788848877
Test set avg_accuracy=88.88% avg_sensitivity=73.53%, avg_specificity=93.77% avg_auc=92.33%
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.388167 Test loss=0.282470 Current lr=[0.00029937852886562414]

[0/23] Train loss=0.3727763593196869
[5/23] Train loss=0.2994481325149536
[10/23] Train loss=0.37827926874160767
[15/23] Train loss=0.3782114088535309
[20/23] Train loss=0.3216818571090698
Test set avg_accuracy=88.92% avg_sensitivity=71.91%, avg_specificity=94.33% avg_auc=91.19%
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.377615 Test loss=0.302853 Current lr=[0.00029890361993976916]

[0/23] Train loss=0.3432047665119171
[5/23] Train loss=0.31069567799568176
[10/23] Train loss=0.3549889922142029
[15/23] Train loss=0.36752602458000183
[20/23] Train loss=0.35098350048065186
Test set avg_accuracy=88.92% avg_sensitivity=65.23%, avg_specificity=96.46% avg_auc=90.26%
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.373629 Test loss=0.309567 Current lr=[0.00029829542264468635]

[0/23] Train loss=0.3718467354774475
[5/23] Train loss=0.32688969373703003
[10/23] Train loss=0.38103657960891724
[15/23] Train loss=0.3782680928707123
[20/23] Train loss=0.33533990383148193
Test set avg_accuracy=87.59% avg_sensitivity=58.71%, avg_specificity=96.79% avg_auc=89.44%
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.375381 Test loss=0.348240 Current lr=[0.00029755448139932487]

[0/23] Train loss=0.3525733947753906
[5/23] Train loss=0.3041868507862091
[10/23] Train loss=0.4004099667072296
[15/23] Train loss=0.39472776651382446
[20/23] Train loss=0.3323844373226166
Test set avg_accuracy=88.16% avg_sensitivity=67.17%, avg_specificity=94.85% avg_auc=90.12%
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.376325 Test loss=0.315001 Current lr=[0.00029668145944644717]

[0/23] Train loss=0.34902697801589966
[5/23] Train loss=0.294928640127182
[10/23] Train loss=0.3826637268066406
[15/23] Train loss=0.3552532196044922
[20/23] Train loss=0.3563216030597687
Test set avg_accuracy=88.70% avg_sensitivity=78.38%, avg_specificity=91.98% avg_auc=92.27%
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.368472 Test loss=0.295696 Current lr=[0.00029567713825893706]

[0/23] Train loss=0.3813764154911041
[5/23] Train loss=0.31028273701667786
[10/23] Train loss=0.3600275218486786
[15/23] Train loss=0.3644172251224518
[20/23] Train loss=0.3296642601490021
Test set avg_accuracy=88.19% avg_sensitivity=73.42%, avg_specificity=92.89% avg_auc=91.42%
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.362128 Test loss=0.301090 Current lr=[0.0002945424168402755]

[0/23] Train loss=0.3266542851924896
[5/23] Train loss=0.3169092833995819
[10/23] Train loss=0.3492854833602905
[15/23] Train loss=0.3490869104862213
[20/23] Train loss=0.3513428568840027
Test set avg_accuracy=87.81% avg_sensitivity=70.73%, avg_specificity=93.25% avg_auc=90.72%
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.368814 Test loss=0.316491 Current lr=[0.00029327831091981106]

[0/23] Train loss=0.3563154935836792
[5/23] Train loss=0.28856348991394043
[10/23] Train loss=0.3751261234283447
[15/23] Train loss=0.33693721890449524
[20/23] Train loss=0.3316890299320221
Test set avg_accuracy=86.80% avg_sensitivity=83.29%, avg_specificity=87.91% avg_auc=92.64%
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.355529 Test loss=0.321994 Current lr=[0.0002918859520435441]

[0/23] Train loss=0.3667364716529846
[5/23] Train loss=0.28358349204063416
[10/23] Train loss=0.34167876839637756
[15/23] Train loss=0.34409481287002563
[20/23] Train loss=0.30801379680633545
Test set avg_accuracy=85.42% avg_sensitivity=81.99%, avg_specificity=86.51% avg_auc=91.88%
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.351874 Test loss=0.350742 Current lr=[0.00029036658656124024]

[0/23] Train loss=0.34478506445884705
[5/23] Train loss=0.3053759038448334
[10/23] Train loss=0.34481287002563477
[15/23] Train loss=0.33065176010131836
[20/23] Train loss=0.33568647503852844
Test set avg_accuracy=88.48% avg_sensitivity=71.32%, avg_specificity=93.94% avg_auc=91.00%
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.357160 Test loss=0.303573 Current lr=[0.00028872157451077834]

[0/23] Train loss=0.3386297821998596
[5/23] Train loss=0.3001194894313812
[10/23] Train loss=0.34031423926353455
[15/23] Train loss=0.3654947876930237
[20/23] Train loss=0.30961158871650696
Test set avg_accuracy=86.47% avg_sensitivity=51.54%, avg_specificity=97.60% avg_auc=85.59%
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.356877 Test loss=0.398620 Current lr=[0.0002869523884007325]

[0/23] Train loss=0.3764679729938507
[5/23] Train loss=0.3170558512210846
[10/23] Train loss=0.3744337856769562
[15/23] Train loss=0.3693302869796753
[20/23] Train loss=0.3404201865196228
Test set avg_accuracy=86.18% avg_sensitivity=54.66%, avg_specificity=96.22% avg_auc=87.81%
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.362317 Test loss=0.364506 Current lr=[0.0002850606118922774]

[0/23] Train loss=0.3304426372051239
[5/23] Train loss=0.2872031331062317
[10/23] Train loss=0.3254006803035736
[15/23] Train loss=0.31889909505844116
[20/23] Train loss=0.3009189963340759
Test set avg_accuracy=86.81% avg_sensitivity=80.81%, avg_specificity=88.72% avg_auc=92.24%
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.344605 Test loss=0.314261 Current lr=[0.000283047938381597]

[0/23] Train loss=0.3486708998680115
[5/23] Train loss=0.2662922143936157
[10/23] Train loss=0.36192360520362854
[15/23] Train loss=0.35464879870414734
[20/23] Train loss=0.32624197006225586
Test set avg_accuracy=88.37% avg_sensitivity=69.49%, avg_specificity=94.39% avg_auc=90.82%
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.348771 Test loss=0.300426 Current lr=[0.0002809161694840658]

[0/23] Train loss=0.3280445337295532
[5/23] Train loss=0.27382639050483704
[10/23] Train loss=0.357671856880188
[15/23] Train loss=0.34064745903015137
[20/23] Train loss=0.3160095810890198
Test set avg_accuracy=83.31% avg_sensitivity=84.20%, avg_specificity=83.02% avg_auc=91.55%
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.340975 Test loss=0.390623 Current lr=[0.0002786672134215589]

[0/23] Train loss=0.3325222432613373
[5/23] Train loss=0.2948020100593567
[10/23] Train loss=0.3472493588924408
[15/23] Train loss=0.338936448097229
[20/23] Train loss=0.3625134527683258
Test set avg_accuracy=85.08% avg_sensitivity=80.70%, avg_specificity=86.47% avg_auc=91.35%
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.360679 Test loss=0.347998 Current lr=[0.0002763030833143351]

[0/23] Train loss=0.34877651929855347
[5/23] Train loss=0.30881306529045105
[10/23] Train loss=0.339498370885849
[15/23] Train loss=0.3222695291042328
[20/23] Train loss=0.30695053935050964
Test set avg_accuracy=88.54% avg_sensitivity=76.01%, avg_specificity=92.53% avg_auc=91.48%
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.347319 Test loss=0.309422 Current lr=[0.00027382589537902163]

[0/23] Train loss=0.32387876510620117
[5/23] Train loss=0.299762099981308
[10/23] Train loss=0.32598915696144104
[15/23] Train loss=0.33663851022720337
[20/23] Train loss=0.3225274682044983
Test set avg_accuracy=87.38% avg_sensitivity=82.75%, avg_specificity=88.86% avg_auc=92.44%
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.331155 Test loss=0.320954 Current lr=[0.0002712378670343135]

[0/23] Train loss=0.32643425464630127
[5/23] Train loss=0.29034388065338135
[10/23] Train loss=0.35472196340560913
[15/23] Train loss=0.3215250074863434
[20/23] Train loss=0.2905208468437195
Test set avg_accuracy=88.11% avg_sensitivity=77.09%, avg_specificity=91.62% avg_auc=91.36%
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.329531 Test loss=0.311473 Current lr=[0.0002685413149160838]

[0/23] Train loss=0.3185902535915375
[5/23] Train loss=0.2732527554035187
[10/23] Train loss=0.35238897800445557
[15/23] Train loss=0.3125530481338501
[20/23] Train loss=0.26715895533561707
Test set avg_accuracy=87.03% avg_sensitivity=77.79%, avg_specificity=89.97% avg_auc=91.16%
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.327160 Test loss=0.334278 Current lr=[0.0002657386528036802]

[0/23] Train loss=0.32112327218055725
[5/23] Train loss=0.2597312331199646
[10/23] Train loss=0.31330740451812744
[15/23] Train loss=0.30545324087142944
[20/23] Train loss=0.2853032648563385
Test set avg_accuracy=83.14% avg_sensitivity=86.52%, avg_specificity=82.06% avg_auc=92.10%
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.321249 Test loss=0.412740 Current lr=[0.0002628323894592665]

[0/23] Train loss=0.321632444858551
[5/23] Train loss=0.2604033350944519
[10/23] Train loss=0.3178206980228424
[15/23] Train loss=0.30539682507514954
[20/23] Train loss=0.29009002447128296
Test set avg_accuracy=81.85% avg_sensitivity=87.55%, avg_specificity=80.03% avg_auc=91.73%
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.319869 Test loss=0.438080 Current lr=[0.0002598251263821397]

[0/23] Train loss=0.3205370604991913
[5/23] Train loss=0.2710546553134918
[10/23] Train loss=0.3250919282436371
[15/23] Train loss=0.29984819889068604
[20/23] Train loss=0.2727281153202057
Test set avg_accuracy=86.13% avg_sensitivity=82.16%, avg_specificity=87.40% avg_auc=91.54%
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.315756 Test loss=0.350186 Current lr=[0.00025671955548003657]

[0/23] Train loss=0.29733023047447205
[5/23] Train loss=0.26850858330726624
[10/23] Train loss=0.3010666072368622
[15/23] Train loss=0.31879833340644836
[20/23] Train loss=0.27782416343688965
Test set avg_accuracy=85.66% avg_sensitivity=84.53%, avg_specificity=86.03% avg_auc=91.62%
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.312652 Test loss=0.371216 Current lr=[0.00025351845665951125]

[0/23] Train loss=0.2991045117378235
[5/23] Train loss=0.29491904377937317
[10/23] Train loss=0.29129356145858765
[15/23] Train loss=0.3056985139846802
[20/23] Train loss=0.2729072570800781
Test set avg_accuracy=88.28% avg_sensitivity=69.00%, avg_specificity=94.42% avg_auc=90.32%
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.308468 Test loss=0.317708 Current lr=[0.0002502246953375425]

[0/23] Train loss=0.2938370406627655
[5/23] Train loss=0.25458377599716187
[10/23] Train loss=0.2758452892303467
[15/23] Train loss=0.3026650846004486
[20/23] Train loss=0.2543739080429077
Test set avg_accuracy=88.20% avg_sensitivity=79.19%, avg_specificity=91.07% avg_auc=92.57%
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.303742 Test loss=0.305558 Current lr=[0.0002468412198765973]

[0/23] Train loss=0.2834114730358124
[5/23] Train loss=0.25610047578811646
[10/23] Train loss=0.28456515073776245
[15/23] Train loss=0.28891029953956604
[20/23] Train loss=0.25774624943733215
Test set avg_accuracy=87.38% avg_sensitivity=70.46%, avg_specificity=92.77% avg_auc=90.79%
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.293950 Test loss=0.324070 Current lr=[0.0002433710589454477]

[0/23] Train loss=0.2768033742904663
[5/23] Train loss=0.2536473870277405
[10/23] Train loss=0.2930563688278198
[15/23] Train loss=0.26194706559181213
[20/23] Train loss=0.2631005048751831
Test set avg_accuracy=87.58% avg_sensitivity=60.43%, avg_specificity=96.22% avg_auc=87.53%
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.291526 Test loss=0.362929 Current lr=[0.00023981731880810106]

[0/23] Train loss=0.27052801847457886
[5/23] Train loss=0.2704632580280304
[10/23] Train loss=0.2501106858253479
[15/23] Train loss=0.26901736855506897
[20/23] Train loss=0.24755382537841797
Test set avg_accuracy=88.35% avg_sensitivity=64.91%, avg_specificity=95.81% avg_auc=89.24%
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.286296 Test loss=0.337892 Current lr=[0.00023618318054327415]

[0/23] Train loss=0.2620011270046234
[5/23] Train loss=0.25609347224235535
[10/23] Train loss=0.2662205100059509
[15/23] Train loss=0.29474276304244995
[20/23] Train loss=0.23658932745456696
Test set avg_accuracy=88.14% avg_sensitivity=78.11%, avg_specificity=91.33% avg_auc=91.25%
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.279301 Test loss=0.321131 Current lr=[0.0002324718971968961]

[0/23] Train loss=0.2725362777709961
[5/23] Train loss=0.25363293290138245
[10/23] Train loss=0.26285168528556824
[15/23] Train loss=0.25807633996009827
[20/23] Train loss=0.22789247334003448
Test set avg_accuracy=87.43% avg_sensitivity=75.74%, avg_specificity=91.16% avg_auc=91.64%
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.276278 Test loss=0.330032 Current lr=[0.00022868679087019228]

[0/23] Train loss=0.2753814160823822
[5/23] Train loss=0.23755130171775818
[10/23] Train loss=0.26427674293518066
[15/23] Train loss=0.2522502541542053
[20/23] Train loss=0.22299697995185852
Test set avg_accuracy=88.02% avg_sensitivity=71.91%, avg_specificity=93.15% avg_auc=90.76%
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.269306 Test loss=0.315692 Current lr=[0.0002248312497459532]

[0/23] Train loss=0.2476864606142044
[5/23] Train loss=0.22912970185279846
[10/23] Train loss=0.25948354601860046
[15/23] Train loss=0.25208452343940735
[20/23] Train loss=0.22066476941108704
Test set avg_accuracy=88.14% avg_sensitivity=73.58%, avg_specificity=92.77% avg_auc=91.90%
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.262415 Test loss=0.304983 Current lr=[0.00022090872505565264]

[0/23] Train loss=0.25222450494766235
[5/23] Train loss=0.22598718106746674
[10/23] Train loss=0.27423280477523804
[15/23] Train loss=0.2594202160835266
[20/23] Train loss=0.2287636548280716
Test set avg_accuracy=88.84% avg_sensitivity=79.35%, avg_specificity=91.86% avg_auc=92.20%
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.261613 Test loss=0.303966 Current lr=[0.00021692272799012766]

[0/23] Train loss=0.24215109646320343
[5/23] Train loss=0.23643545806407928
[10/23] Train loss=0.24436238408088684
[15/23] Train loss=0.24101324379444122
[20/23] Train loss=0.233230859041214
Test set avg_accuracy=88.22% avg_sensitivity=74.93%, avg_specificity=92.45% avg_auc=91.23%
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.259047 Test loss=0.319656 Current lr=[0.0002128768265565874]

[0/23] Train loss=0.2598302960395813
[5/23] Train loss=0.23719929158687592
[10/23] Train loss=0.2537182867527008
[15/23] Train loss=0.2305370271205902
[20/23] Train loss=0.21451255679130554
Test set avg_accuracy=89.10% avg_sensitivity=73.96%, avg_specificity=93.92% avg_auc=91.18%
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.253096 Test loss=0.304936 Current lr=[0.00020877464238476336]

[0/23] Train loss=0.23785926401615143
[5/23] Train loss=0.21971990168094635
[10/23] Train loss=0.23863185942173004
[15/23] Train loss=0.2338373363018036
[20/23] Train loss=0.22402086853981018
Test set avg_accuracy=88.01% avg_sensitivity=71.59%, avg_specificity=93.24% avg_auc=90.04%
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.248100 Test loss=0.330251 Current lr=[0.00020461984748506058]

[0/23] Train loss=0.2515617907047272
[5/23] Train loss=0.21361304819583893
[10/23] Train loss=0.24168962240219116
[15/23] Train loss=0.23060831427574158
[20/23] Train loss=0.21411670744419098
Test set avg_accuracy=86.82% avg_sensitivity=81.46%, avg_specificity=88.53% avg_auc=92.11%
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.242788 Test loss=0.351758 Current lr=[0.00020041616096161041]

[0/23] Train loss=0.2272193729877472
[5/23] Train loss=0.21277235448360443
[10/23] Train loss=0.23884662985801697
[15/23] Train loss=0.23780286312103271
[20/23] Train loss=0.2310783416032791
Test set avg_accuracy=86.86% avg_sensitivity=77.74%, avg_specificity=89.77% avg_auc=91.31%
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.248784 Test loss=0.338642 Current lr=[0.0001961673456831693]

[0/23] Train loss=0.2446633279323578
[5/23] Train loss=0.20717112720012665
[10/23] Train loss=0.2277992069721222
[15/23] Train loss=0.24435436725616455
[20/23] Train loss=0.2338140308856964
Test set avg_accuracy=87.23% avg_sensitivity=79.84%, avg_specificity=89.58% avg_auc=91.50%
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.244110 Test loss=0.343979 Current lr=[0.0001918772049148412]

[0/23] Train loss=0.24468016624450684
[5/23] Train loss=0.21819652616977692
[10/23] Train loss=0.2569297254085541
[15/23] Train loss=0.24551333487033844
[20/23] Train loss=0.20945213735103607
Test set avg_accuracy=89.02% avg_sensitivity=80.65%, avg_specificity=91.69% avg_auc=92.78%
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.253706 Test loss=0.312769 Current lr=[0.00018754957891364035]

[0/23] Train loss=0.23984475433826447
[5/23] Train loss=0.21345305442810059
[10/23] Train loss=0.23872575163841248
[15/23] Train loss=0.22578170895576477
[20/23] Train loss=0.21205715835094452
Test set avg_accuracy=88.53% avg_sensitivity=73.75%, avg_specificity=93.24% avg_auc=91.68%
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.242722 Test loss=0.308560 Current lr=[0.0001831883414909412]

[0/23] Train loss=0.23041749000549316
[5/23] Train loss=0.21577177941799164
[10/23] Train loss=0.2286282330751419
[15/23] Train loss=0.2190805822610855
[20/23] Train loss=0.23666058480739594
Test set avg_accuracy=87.79% avg_sensitivity=77.90%, avg_specificity=90.94% avg_auc=92.00%
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.237139 Test loss=0.333976 Current lr=[0.00017879739654489248]

[0/23] Train loss=0.23179267346858978
[5/23] Train loss=0.2108948677778244
[10/23] Train loss=0.23000982403755188
[15/23] Train loss=0.21907123923301697
[20/23] Train loss=0.20506684482097626
Test set avg_accuracy=88.09% avg_sensitivity=76.66%, avg_specificity=91.73% avg_auc=91.05%
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.236860 Test loss=0.325180 Current lr=[0.00017438067456589971]

[0/23] Train loss=0.225690096616745
[5/23] Train loss=0.2075892835855484
[10/23] Train loss=0.23550567030906677
[15/23] Train loss=0.2271619588136673
[20/23] Train loss=0.20585757493972778
Test set avg_accuracy=87.81% avg_sensitivity=80.92%, avg_specificity=90.01% avg_auc=91.88%
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.236754 Test loss=0.333932 Current lr=[0.00016994212911830404]

[0/23] Train loss=0.23175187408924103
[5/23] Train loss=0.203245148062706
[10/23] Train loss=0.2267792671918869
[15/23] Train loss=0.21147435903549194
[20/23] Train loss=0.20072901248931885
Test set avg_accuracy=88.75% avg_sensitivity=76.28%, avg_specificity=92.72% avg_auc=91.88%
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.231066 Test loss=0.314709 Current lr=[0.00016548573330140643]

[0/23] Train loss=0.22545699775218964
[5/23] Train loss=0.21684059500694275
[10/23] Train loss=0.24489600956439972
[15/23] Train loss=0.230385884642601
[20/23] Train loss=0.2167738527059555
Test set avg_accuracy=87.37% avg_sensitivity=82.86%, avg_specificity=88.81% avg_auc=92.14%
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.239503 Test loss=0.354497 Current lr=[0.00016101547619300614]

[0/23] Train loss=0.23124775290489197
[5/23] Train loss=0.22732260823249817
[10/23] Train loss=0.23296648263931274
[15/23] Train loss=0.23844939470291138
[20/23] Train loss=0.22669470310211182
Test set avg_accuracy=87.98% avg_sensitivity=85.28%, avg_specificity=88.84% avg_auc=92.88%
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.239451 Test loss=0.342151 Current lr=[0.00015653535927863545]

[0/23] Train loss=0.22374217212200165
[5/23] Train loss=0.21102499961853027
[10/23] Train loss=0.23722028732299805
[15/23] Train loss=0.22492432594299316
[20/23] Train loss=0.20395015180110931
Test set avg_accuracy=87.75% avg_sensitivity=85.23%, avg_specificity=88.55% avg_auc=92.80%
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.238699 Test loss=0.343324 Current lr=[0.00015204939286968838]

[0/23] Train loss=0.22120842337608337
[5/23] Train loss=0.21226747334003448
[10/23] Train loss=0.23592063784599304
[15/23] Train loss=0.2214125543832779
[20/23] Train loss=0.2069886475801468
Test set avg_accuracy=88.85% avg_sensitivity=73.26%, avg_specificity=93.82% avg_auc=92.01%
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.232118 Test loss=0.306651 Current lr=[0.00014756159251364881]

[0/23] Train loss=0.22777876257896423
[5/23] Train loss=0.21913942694664001
[10/23] Train loss=0.22287899255752563
[15/23] Train loss=0.21569138765335083
[20/23] Train loss=0.19578370451927185
Test set avg_accuracy=87.25% avg_sensitivity=82.53%, avg_specificity=88.76% avg_auc=91.57%
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.231996 Test loss=0.369234 Current lr=[0.00014307597539963164]

[0/23] Train loss=0.22453001141548157
[5/23] Train loss=0.21555009484291077
[10/23] Train loss=0.21700243651866913
[15/23] Train loss=0.22464723885059357
[20/23] Train loss=0.22145870327949524
Test set avg_accuracy=88.80% avg_sensitivity=78.38%, avg_specificity=92.12% avg_auc=92.47%
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.233537 Test loss=0.309810 Current lr=[0.00013859655676245434]

[0/23] Train loss=0.22813887894153595
[5/23] Train loss=0.20314574241638184
[10/23] Train loss=0.21858257055282593
[15/23] Train loss=0.2164732664823532
[20/23] Train loss=0.20586280524730682
Test set avg_accuracy=86.50% avg_sensitivity=87.12%, avg_specificity=86.30% avg_auc=92.97%
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.229869 Test loss=0.357796 Current lr=[0.0001341273462884584]

[0/23] Train loss=0.22244377434253693
[5/23] Train loss=0.19410482048988342
[10/23] Train loss=0.2157287448644638
[15/23] Train loss=0.21678175032138824
[20/23] Train loss=0.2097189873456955
Test set avg_accuracy=86.54% avg_sensitivity=86.68%, avg_specificity=86.49% avg_auc=92.73%
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.226675 Test loss=0.376209 Current lr=[0.0001296723445262966]

[0/23] Train loss=0.21182967722415924
[5/23] Train loss=0.2177477329969406
[10/23] Train loss=0.2120743840932846
[15/23] Train loss=0.2169836014509201
[20/23] Train loss=0.20243577659130096
Test set avg_accuracy=86.16% avg_sensitivity=82.91%, avg_specificity=87.19% avg_auc=92.07%
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.224209 Test loss=0.375695 Current lr=[0.00012523553930590017]

[0/23] Train loss=0.20734331011772156
[5/23] Train loss=0.21033921837806702
[10/23] Train loss=0.20333342254161835
[15/23] Train loss=0.20269235968589783
[20/23] Train loss=0.19485484063625336
Test set avg_accuracy=87.53% avg_sensitivity=82.70%, avg_specificity=89.06% avg_auc=92.71%
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.219872 Test loss=0.343698 Current lr=[0.00012082090216883131]

[0/23] Train loss=0.2116365134716034
[5/23] Train loss=0.1964876502752304
[10/23] Train loss=0.21213538944721222
[15/23] Train loss=0.20689533650875092
[20/23] Train loss=0.1949024647474289
Test set avg_accuracy=88.07% avg_sensitivity=81.29%, avg_specificity=90.23% avg_auc=92.25%
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.216483 Test loss=0.336412 Current lr=[0.00011643238481321519]

[0/23] Train loss=0.19540801644325256
[5/23] Train loss=0.21847528219223022
[10/23] Train loss=0.20741547644138336
[15/23] Train loss=0.2002028524875641
[20/23] Train loss=0.17910313606262207
Test set avg_accuracy=88.76% avg_sensitivity=78.71%, avg_specificity=91.97% avg_auc=92.28%
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.213518 Test loss=0.311937 Current lr=[0.000112073915556435]

[0/23] Train loss=0.2039543241262436
[5/23] Train loss=0.19458834826946259
[10/23] Train loss=0.20157840847969055
[15/23] Train loss=0.19082412123680115
[20/23] Train loss=0.18695546686649323
Test set avg_accuracy=87.06% avg_sensitivity=81.99%, avg_specificity=88.67% avg_auc=92.11%
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.212901 Test loss=0.349399 Current lr=[0.00010774939581875629]

[0/23] Train loss=0.20700758695602417
[5/23] Train loss=0.18752215802669525
[10/23] Train loss=0.21071721613407135
[15/23] Train loss=0.19249515235424042
[20/23] Train loss=0.19343936443328857
Test set avg_accuracy=88.59% avg_sensitivity=76.06%, avg_specificity=92.58% avg_auc=90.41%
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.208066 Test loss=0.325860 Current lr=[0.00010346269663102685]

[0/23] Train loss=0.2008296549320221
[5/23] Train loss=0.19219519197940826
[10/23] Train loss=0.19870473444461823
[15/23] Train loss=0.20053352415561676
[20/23] Train loss=0.17206110060214996
Test set avg_accuracy=88.54% avg_sensitivity=72.02%, avg_specificity=93.80% avg_auc=90.63%
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.203843 Test loss=0.316076 Current lr=[9.921765516958019e-05]

[0/23] Train loss=0.1995367407798767
[5/23] Train loss=0.18213868141174316
[10/23] Train loss=0.18906718492507935
[15/23] Train loss=0.18594244122505188
[20/23] Train loss=0.17607881128787994
Test set avg_accuracy=88.55% avg_sensitivity=73.42%, avg_specificity=93.37% avg_auc=90.92%
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.198448 Test loss=0.326890 Current lr=[9.501807132144291e-05]

[0/23] Train loss=0.18730829656124115
[5/23] Train loss=0.18525785207748413
[10/23] Train loss=0.1893915981054306
[15/23] Train loss=0.18748879432678223
[20/23] Train loss=0.16947773098945618
Test set avg_accuracy=88.92% avg_sensitivity=77.79%, avg_specificity=92.46% avg_auc=92.17%
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.194126 Test loss=0.304626 Current lr=[9.086770428292143e-05]

[0/23] Train loss=0.1856224089860916
[5/23] Train loss=0.1823803186416626
[10/23] Train loss=0.19226491451263428
[15/23] Train loss=0.1777392476797104
[20/23] Train loss=0.1680804342031479
Test set avg_accuracy=88.01% avg_sensitivity=77.95%, avg_specificity=91.21% avg_auc=91.83%
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.192226 Test loss=0.333039 Current lr=[8.677026919461179e-05]

[0/23] Train loss=0.17937102913856506
[5/23] Train loss=0.17293386161327362
[10/23] Train loss=0.18397510051727295
[15/23] Train loss=0.18887166678905487
[20/23] Train loss=0.17369601130485535
Test set avg_accuracy=88.92% avg_sensitivity=70.84%, avg_specificity=94.68% avg_auc=90.34%
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.190998 Test loss=0.312992 Current lr=[8.272943381584592e-05]

[0/23] Train loss=0.17418910562992096
[5/23] Train loss=0.17376622557640076
[10/23] Train loss=0.1815236210823059
[15/23] Train loss=0.1741541624069214
[20/23] Train loss=0.16707684099674225
Test set avg_accuracy=89.09% avg_sensitivity=71.70%, avg_specificity=94.63% avg_auc=90.68%
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.187054 Test loss=0.313784 Current lr=[7.874881524155032e-05]

[0/23] Train loss=0.18111220002174377
[5/23] Train loss=0.1706508994102478
[10/23] Train loss=0.1746564656496048
[15/23] Train loss=0.17738765478134155
[20/23] Train loss=0.16162054240703583
Test set avg_accuracy=88.93% avg_sensitivity=72.51%, avg_specificity=94.16% avg_auc=90.98%
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.185176 Test loss=0.311430 Current lr=[7.483197666445599e-05]

[0/23] Train loss=0.17510920763015747
[5/23] Train loss=0.17451506853103638
[10/23] Train loss=0.1726701259613037
[15/23] Train loss=0.1863241344690323
[20/23] Train loss=0.16653954982757568
Test set avg_accuracy=88.28% avg_sensitivity=74.12%, avg_specificity=92.79% avg_auc=90.98%
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.186672 Test loss=0.325745 Current lr=[7.098242418555859e-05]

[0/23] Train loss=0.18350525200366974
[5/23] Train loss=0.1713738888502121
[10/23] Train loss=0.17159368097782135
[15/23] Train loss=0.17384189367294312
[20/23] Train loss=0.16814051568508148
Test set avg_accuracy=88.71% avg_sensitivity=80.22%, avg_specificity=91.42% avg_auc=91.84%
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.185842 Test loss=0.319307 Current lr=[6.720360367568325e-05]

[0/23] Train loss=0.17276479303836823
[5/23] Train loss=0.17212827503681183
[10/23] Train loss=0.17077532410621643
[15/23] Train loss=0.17628410458564758
[20/23] Train loss=0.16871193051338196
Test set avg_accuracy=89.04% avg_sensitivity=79.08%, avg_specificity=92.21% avg_auc=92.15%
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.185299 Test loss=0.310133 Current lr=[6.349889769096321e-05]

[0/23] Train loss=0.17787736654281616
[5/23] Train loss=0.16612596809864044
[10/23] Train loss=0.17657490074634552
[15/23] Train loss=0.1701524555683136
[20/23] Train loss=0.1755591481924057
Test set avg_accuracy=88.96% avg_sensitivity=74.23%, avg_specificity=93.65% avg_auc=90.64%
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.182674 Test loss=0.315291 Current lr=[5.987162244499424e-05]

[0/23] Train loss=0.1775882989168167
[5/23] Train loss=0.16172972321510315
[10/23] Train loss=0.17487984895706177
[15/23] Train loss=0.16709204018115997
[20/23] Train loss=0.15692056715488434
Test set avg_accuracy=89.11% avg_sensitivity=77.20%, avg_specificity=92.91% avg_auc=91.74%
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.180376 Test loss=0.308344 Current lr=[5.632502484037415e-05]

[0/23] Train loss=0.17812049388885498
[5/23] Train loss=0.16453395783901215
[10/23] Train loss=0.17217332124710083
[15/23] Train loss=0.1784190535545349
[20/23] Train loss=0.15998288989067078
Test set avg_accuracy=89.18% avg_sensitivity=74.99%, avg_specificity=93.70% avg_auc=91.47%
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.180221 Test loss=0.308054 Current lr=[5.286227956228551e-05]

[0/23] Train loss=0.1732337474822998
[5/23] Train loss=0.15902017056941986
[10/23] Train loss=0.16969233751296997
[15/23] Train loss=0.17417772114276886
[20/23] Train loss=0.1613636463880539
Test set avg_accuracy=89.35% avg_sensitivity=75.58%, avg_specificity=93.73% avg_auc=91.38%
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.177511 Test loss=0.303609 Current lr=[4.948648623672213e-05]

[0/23] Train loss=0.1656748503446579
[5/23] Train loss=0.16247384250164032
[10/23] Train loss=0.15798994898796082
[15/23] Train loss=0.1700596958398819
[20/23] Train loss=0.15741106867790222
Test set avg_accuracy=88.53% avg_sensitivity=81.51%, avg_specificity=90.76% avg_auc=92.22%
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.176837 Test loss=0.326054 Current lr=[4.620066665590412e-05]

[0/23] Train loss=0.16831855475902557
[5/23] Train loss=0.16798071563243866
[10/23] Train loss=0.16129495203495026
[15/23] Train loss=0.1724536418914795
[20/23] Train loss=0.1563408076763153
Test set avg_accuracy=88.50% avg_sensitivity=80.05%, avg_specificity=91.19% avg_auc=92.11%
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.176365 Test loss=0.324722 Current lr=[4.30077620733648e-05]

[0/23] Train loss=0.1643010824918747
[5/23] Train loss=0.1601787656545639
[10/23] Train loss=0.16566424071788788
[15/23] Train loss=0.16837088763713837
[20/23] Train loss=0.15635091066360474
Test set avg_accuracy=87.66% avg_sensitivity=83.13%, avg_specificity=89.10% avg_auc=92.00%
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.175185 Test loss=0.349647 Current lr=[3.9910630571130124e-05]

[0/23] Train loss=0.16601258516311646
[5/23] Train loss=0.15974031388759613
[10/23] Train loss=0.16144312918186188
[15/23] Train loss=0.17276930809020996
[20/23] Train loss=0.15925316512584686
Test set avg_accuracy=88.85% avg_sensitivity=79.84%, avg_specificity=91.73% avg_auc=91.82%
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.174668 Test loss=0.320202 Current lr=[3.691204450134834e-05]

[0/23] Train loss=0.1673426330089569
[5/23] Train loss=0.16674387454986572
[10/23] Train loss=0.16995872557163239
[15/23] Train loss=0.16077379882335663
[20/23] Train loss=0.16192841529846191
Test set avg_accuracy=89.13% avg_sensitivity=78.11%, avg_specificity=92.64% avg_auc=91.93%
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.175173 Test loss=0.309197 Current lr=[3.401468800465945e-05]

[0/23] Train loss=0.16535639762878418
[5/23] Train loss=0.1566968560218811
[10/23] Train loss=0.16974809765815735
[15/23] Train loss=0.16328662633895874
[20/23] Train loss=0.15795162320137024
Test set avg_accuracy=89.61% avg_sensitivity=77.30%, avg_specificity=93.53% avg_auc=91.37%
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.173514 Test loss=0.302732 Current lr=[3.122115460752563e-05]

[0/23] Train loss=0.16706500947475433
[5/23] Train loss=0.1525581181049347
[10/23] Train loss=0.16449257731437683
[15/23] Train loss=0.15936413407325745
[20/23] Train loss=0.15275275707244873
Test set avg_accuracy=88.95% avg_sensitivity=78.49%, avg_specificity=92.27% avg_auc=91.72%
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.171241 Test loss=0.313113 Current lr=[2.853394490067387e-05]

[0/23] Train loss=0.16343635320663452
[5/23] Train loss=0.15252411365509033
[10/23] Train loss=0.15719591081142426
[15/23] Train loss=0.16010822355747223
[20/23] Train loss=0.150364950299263
Test set avg_accuracy=88.92% avg_sensitivity=79.41%, avg_specificity=91.95% avg_auc=91.56%
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.167264 Test loss=0.313817 Current lr=[2.595546430072873e-05]

[0/23] Train loss=0.1544768214225769
[5/23] Train loss=0.1524476408958435
[10/23] Train loss=0.15802985429763794
[15/23] Train loss=0.15552373230457306
[20/23] Train loss=0.14918877184391022
Test set avg_accuracy=89.04% avg_sensitivity=77.95%, avg_specificity=92.57% avg_auc=91.34%
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.165184 Test loss=0.312680 Current lr=[2.348802089703847e-05]

[0/23] Train loss=0.1553376466035843
[5/23] Train loss=0.14730864763259888
[10/23] Train loss=0.1504463255405426
[15/23] Train loss=0.1598612517118454
[20/23] Train loss=0.1490856111049652
Test set avg_accuracy=88.93% avg_sensitivity=78.81%, avg_specificity=92.15% avg_auc=91.41%
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.164109 Test loss=0.317182 Current lr=[2.1133823385622626e-05]

[0/23] Train loss=0.15874482691287994
[5/23] Train loss=0.15510152280330658
[10/23] Train loss=0.15500038862228394
[15/23] Train loss=0.15632496774196625
[20/23] Train loss=0.14463616907596588
Test set avg_accuracy=89.30% avg_sensitivity=77.57%, avg_specificity=93.03% avg_auc=91.35%
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.164021 Test loss=0.307554 Current lr=[1.88949790920899e-05]

[0/23] Train loss=0.1580308973789215
[5/23] Train loss=0.14753803610801697
[10/23] Train loss=0.15208759903907776
[15/23] Train loss=0.15760667622089386
[20/23] Train loss=0.1460609883069992
Test set avg_accuracy=89.13% avg_sensitivity=78.76%, avg_specificity=92.43% avg_auc=91.62%
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.163186 Test loss=0.312829 Current lr=[1.677349208529647e-05]

[0/23] Train loss=0.15381158888339996
[5/23] Train loss=0.15003849565982819
[10/23] Train loss=0.1512989103794098
[15/23] Train loss=0.15434157848358154
[20/23] Train loss=0.14384661614894867
Test set avg_accuracy=89.26% avg_sensitivity=78.01%, avg_specificity=92.84% avg_auc=91.39%
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.162129 Test loss=0.308148 Current lr=[1.477126138343271e-05]

[0/23] Train loss=0.15515020489692688
[5/23] Train loss=0.14832699298858643
[10/23] Train loss=0.1508449912071228
[15/23] Train loss=0.15286791324615479
[20/23] Train loss=0.14559130370616913
Test set avg_accuracy=88.88% avg_sensitivity=80.81%, avg_specificity=91.45% avg_auc=91.95%
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.161112 Test loss=0.315473 Current lr=[1.2890079254144858e-05]

[0/23] Train loss=0.15424497425556183
[5/23] Train loss=0.1468048244714737
[10/23] Train loss=0.15670089423656464
[15/23] Train loss=0.15487252175807953
[20/23] Train loss=0.14524568617343903
Test set avg_accuracy=89.14% avg_sensitivity=79.35%, avg_specificity=92.26% avg_auc=91.75%
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.161829 Test loss=0.310455 Current lr=[1.11316296102128e-05]

[0/23] Train loss=0.1534794569015503
[5/23] Train loss=0.1468798667192459
[10/23] Train loss=0.1549576371908188
[15/23] Train loss=0.15250429511070251
[20/23] Train loss=0.147426038980484
Test set avg_accuracy=89.30% avg_sensitivity=78.76%, avg_specificity=92.65% avg_auc=91.60%
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.161464 Test loss=0.309027 Current lr=[9.497486502219914e-06]

[0/23] Train loss=0.15485605597496033
[5/23] Train loss=0.14984038472175598
[10/23] Train loss=0.15391241014003754
[15/23] Train loss=0.1508112996816635
[20/23] Train loss=0.14408369362354279
Test set avg_accuracy=89.14% avg_sensitivity=79.03%, avg_specificity=92.36% avg_auc=91.68%
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.161587 Test loss=0.311797 Current lr=[7.989112709564786e-06]

[0/23] Train loss=0.1557314097881317
[5/23] Train loss=0.14732179045677185
[10/23] Train loss=0.1538454294204712
[15/23] Train loss=0.15470944344997406
[20/23] Train loss=0.14160671830177307
Test set avg_accuracy=89.34% avg_sensitivity=78.92%, avg_specificity=92.65% avg_auc=91.55%
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.160316 Test loss=0.310359 Current lr=[6.60785843107539e-06]

[0/23] Train loss=0.15192022919654846
[5/23] Train loss=0.14764967560768127
[10/23] Train loss=0.14788632094860077
[15/23] Train loss=0.15360935032367706
[20/23] Train loss=0.147989884018898
Test set avg_accuracy=89.27% avg_sensitivity=79.08%, avg_specificity=92.52% avg_auc=91.54%
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.160229 Test loss=0.311585 Current lr=[5.354960076398407e-06]

[0/23] Train loss=0.15295976400375366
[5/23] Train loss=0.1492583006620407
[10/23] Train loss=0.14938880503177643
[15/23] Train loss=0.15387192368507385
[20/23] Train loss=0.1445639431476593
Test set avg_accuracy=89.21% avg_sensitivity=78.98%, avg_specificity=92.46% avg_auc=91.60%
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.159976 Test loss=0.311483 Current lr=[4.231539159245011e-06]

[0/23] Train loss=0.15569676458835602
[5/23] Train loss=0.14786478877067566
[10/23] Train loss=0.15256835520267487
[15/23] Train loss=0.15036310255527496
[20/23] Train loss=0.14303579926490784
Test set avg_accuracy=89.36% avg_sensitivity=79.30%, avg_specificity=92.57% avg_auc=91.61%
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.159103 Test loss=0.310478 Current lr=[3.238601293484323e-06]

[0/23] Train loss=0.15324531495571136
[5/23] Train loss=0.14598599076271057
[10/23] Train loss=0.1496683806180954
[15/23] Train loss=0.14668850600719452
[20/23] Train loss=0.14381864666938782
Test set avg_accuracy=89.30% avg_sensitivity=79.30%, avg_specificity=92.48% avg_auc=91.65%
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.158830 Test loss=0.310326 Current lr=[2.377035292982768e-06]

[0/23] Train loss=0.15523861348628998
[5/23] Train loss=0.1483171582221985
[10/23] Train loss=0.14925628900527954
[15/23] Train loss=0.1484650820493698
[20/23] Train loss=0.14920943975448608
Test set avg_accuracy=89.26% avg_sensitivity=79.08%, avg_specificity=92.50% avg_auc=91.65%
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.159476 Test loss=0.309928 Current lr=[1.647612375995218e-06]

[0/23] Train loss=0.15404927730560303
[5/23] Train loss=0.14880096912384033
[10/23] Train loss=0.15176703035831451
[15/23] Train loss=0.14807745814323425
[20/23] Train loss=0.1432458907365799
Test set avg_accuracy=89.31% avg_sensitivity=79.25%, avg_specificity=92.52% avg_auc=91.64%
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.159110 Test loss=0.310151 Current lr=[1.050985474820339e-06]

[0/23] Train loss=0.15178118646144867
[5/23] Train loss=0.14459162950515747
[10/23] Train loss=0.15024958550930023
[15/23] Train loss=0.14968928694725037
[20/23] Train loss=0.14329198002815247
Test set avg_accuracy=89.28% avg_sensitivity=79.30%, avg_specificity=92.46% avg_auc=91.65%
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.159463 Test loss=0.310603 Current lr=[5.87688651337636e-07]

[0/23] Train loss=0.15595631301403046
[5/23] Train loss=0.14724887907505035
[10/23] Train loss=0.14965219795703888
[15/23] Train loss=0.14943073689937592
[20/23] Train loss=0.14415901899337769
Test set avg_accuracy=89.31% avg_sensitivity=79.25%, avg_specificity=92.52% avg_auc=91.64%
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.160170 Test loss=0.310431 Current lr=[2.581366189498079e-07]

[0/23] Train loss=0.15396255254745483
[5/23] Train loss=0.1466715931892395
[10/23] Train loss=0.15035954117774963
[15/23] Train loss=0.1519286185503006
[20/23] Train loss=0.1435927450656891
Test set avg_accuracy=89.31% avg_sensitivity=79.14%, avg_specificity=92.55% avg_auc=91.65%
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.159663 Test loss=0.310371 Current lr=[6.262437135804758e-08]

[0/23] Train loss=0.15094541013240814
[5/23] Train loss=0.149079367518425
[10/23] Train loss=0.14945971965789795
[15/23] Train loss=0.15098366141319275
[20/23] Train loss=0.14329375326633453
/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
Test set avg_accuracy=89.28% avg_sensitivity=79.19%, avg_specificity=92.50% avg_auc=91.67%
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.159882 Test loss=0.310765 Current lr=[1.326918502775323e-09]

Fold[9] Result: acc=88.36% sen=85.18%, spe=89.37%, auc=94.51%!
Fold[9] Avg_overlap=0.67%(0.22959605515257597)
[0/24] Train loss=1.498773455619812
[5/24] Train loss=1.4795308113098145
[10/24] Train loss=1.4630922079086304
[15/24] Train loss=1.4505748748779297
[20/24] Train loss=1.4293373823165894
Test set avg_accuracy=61.38% avg_sensitivity=44.03%, avg_specificity=66.41% avg_auc=58.15%
Best model saved!! Metric=-96.02802730559952!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=1.460183 Test loss=0.659443 Current lr=[1.2351426987789328e-05]

[0/24] Train loss=1.406243920326233
[5/24] Train loss=1.3998279571533203
[10/24] Train loss=1.3921995162963867
[15/24] Train loss=1.3593733310699463
[20/24] Train loss=1.3280582427978516
Test set avg_accuracy=69.21% avg_sensitivity=56.37%, avg_specificity=72.93% avg_auc=71.27%
Best model saved!! Metric=-56.22870948641368!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=1.379372 Test loss=0.589678 Current lr=[1.3403992660494107e-05]

[0/24] Train loss=1.3206870555877686
[5/24] Train loss=1.309151530265808
[10/24] Train loss=1.321224331855774
[15/24] Train loss=1.2850143909454346
[20/24] Train loss=1.2730644941329956
Test set avg_accuracy=74.45% avg_sensitivity=66.69%, avg_specificity=76.70% avg_auc=78.49%
Best model saved!! Metric=-29.66988625936156!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=1.307766 Test loss=0.544596 Current lr=[1.5152559518339206e-05]

[0/24] Train loss=1.2498962879180908
[5/24] Train loss=1.2403734922409058
[10/24] Train loss=1.2443912029266357
[15/24] Train loss=1.217939019203186
[20/24] Train loss=1.2001763582229614
Test set avg_accuracy=76.04% avg_sensitivity=74.16%, avg_specificity=76.59% avg_auc=81.86%
Best model saved!! Metric=-17.346898660945456!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=1.234531 Test loss=0.516626 Current lr=[1.7588592928216313e-05]

[0/24] Train loss=1.1552114486694336
[5/24] Train loss=1.1603105068206787
[10/24] Train loss=1.1973549127578735
[15/24] Train loss=1.146809458732605
[20/24] Train loss=1.1373326778411865
Test set avg_accuracy=77.01% avg_sensitivity=79.03%, avg_specificity=76.42% avg_auc=84.55%
Best model saved!! Metric=-8.996043052824973!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=1.169372 Test loss=0.492854 Current lr=[2.0700202780633934e-05]

[0/24] Train loss=1.1049914360046387
[5/24] Train loss=1.1029345989227295
[10/24] Train loss=1.137569785118103
[15/24] Train loss=1.084741473197937
[20/24] Train loss=1.0788371562957764
Test set avg_accuracy=78.50% avg_sensitivity=81.69%, avg_specificity=77.58% avg_auc=86.73%
Best model saved!! Metric=-1.498250590410663!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=1.107429 Test loss=0.465885 Current lr=[2.4472201524514136e-05]

[0/24] Train loss=1.0297576189041138
[5/24] Train loss=1.0432147979736328
[10/24] Train loss=1.0867851972579956
[15/24] Train loss=1.0148378610610962
[20/24] Train loss=1.0216212272644043
Test set avg_accuracy=80.14% avg_sensitivity=82.21%, avg_specificity=79.54% avg_auc=88.48%
Best model saved!! Metric=4.377251028363375!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=1.048693 Test loss=0.441840 Current lr=[2.8886178296572108e-05]

[0/24] Train loss=0.9790407419204712
[5/24] Train loss=0.9992092251777649
[10/24] Train loss=1.0223630666732788
[15/24] Train loss=0.956972062587738
[20/24] Train loss=0.9564239978790283
Test set avg_accuracy=82.53% avg_sensitivity=80.88%, avg_specificity=83.00% avg_auc=89.69%
Best model saved!! Metric=10.101824094402545!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.992612 Test loss=0.411147 Current lr=[3.392058878345813e-05]

[0/24] Train loss=0.9339115619659424
[5/24] Train loss=0.9394342303276062
[10/24] Train loss=0.9536539316177368
[15/24] Train loss=0.8989920616149902
[20/24] Train loss=0.9089292287826538
Test set avg_accuracy=84.24% avg_sensitivity=79.95%, avg_specificity=85.49% avg_auc=90.61%
Best model saved!! Metric=14.298883076630517!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.939266 Test loss=0.389857 Current lr=[3.955086037805142e-05]

[0/24] Train loss=0.9011346697807312
[5/24] Train loss=0.894291341304779
[10/24] Train loss=0.9224123954772949
[15/24] Train loss=0.8505139946937561
[20/24] Train loss=0.8561511039733887
Test set avg_accuracy=85.40% avg_sensitivity=80.88%, avg_specificity=86.71% avg_auc=91.49%
Best model saved!! Metric=18.485323009957042!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.892682 Test loss=0.372561 Current lr=[4.57495121166447e-05]

[0/24] Train loss=0.8575310111045837
[5/24] Train loss=0.8348402380943298
[10/24] Train loss=0.8560705184936523
[15/24] Train loss=0.8210161924362183
[20/24] Train loss=0.8080533146858215
Test set avg_accuracy=86.39% avg_sensitivity=80.59%, avg_specificity=88.08% avg_auc=92.13%
Best model saved!! Metric=21.185948240010333!!
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.849866 Test loss=0.350590 Current lr=[5.2486288811615e-05]

[0/24] Train loss=0.8149952292442322
[5/24] Train loss=0.8079433441162109
[10/24] Train loss=0.8075276017189026
[15/24] Train loss=0.7728058695793152
[20/24] Train loss=0.7855850458145142
Test set avg_accuracy=86.26% avg_sensitivity=84.59%, avg_specificity=86.75% avg_auc=92.83%
Best model saved!! Metric=24.425204177169505!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.810671 Test loss=0.349384 Current lr=[5.97283087248885e-05]

[0/24] Train loss=0.7886798977851868
[5/24] Train loss=0.756757915019989
[10/24] Train loss=0.7766870260238647
[15/24] Train loss=0.7455995082855225
[20/24] Train loss=0.7216751575469971
Test set avg_accuracy=87.17% avg_sensitivity=84.18%, avg_specificity=88.04% avg_auc=93.35%
Best model saved!! Metric=26.750042845095848!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.778009 Test loss=0.332435 Current lr=[6.744022406141468e-05]

[0/24] Train loss=0.7461621761322021
[5/24] Train loss=0.7325369119644165
[10/24] Train loss=0.7464501857757568
[15/24] Train loss=0.718433678150177
[20/24] Train loss=0.6989220380783081
Test set avg_accuracy=88.10% avg_sensitivity=83.37%, avg_specificity=89.47% avg_auc=93.54%
Best model saved!! Metric=28.483018670775536!!
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.750066 Test loss=0.313675 Current lr=[7.558439349929357e-05]

[0/24] Train loss=0.7257494926452637
[5/24] Train loss=0.7137407064437866
[10/24] Train loss=0.7327930927276611
[15/24] Train loss=0.6820350289344788
[20/24] Train loss=0.6832678914070129
Test set avg_accuracy=88.61% avg_sensitivity=81.40%, avg_specificity=90.70% avg_auc=93.61%
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.723222 Test loss=0.296066 Current lr=[8.412106591444728e-05]

[0/24] Train loss=0.7059102058410645
[5/24] Train loss=0.6880582571029663
[10/24] Train loss=0.715752899646759
[15/24] Train loss=0.677799642086029
[20/24] Train loss=0.6501997709274292
Test set avg_accuracy=88.62% avg_sensitivity=82.44%, avg_specificity=90.41% avg_auc=94.03%
Best model saved!! Metric=29.50583690106511!!
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.704673 Test loss=0.290543 Current lr=[9.300857440308985e-05]

[0/24] Train loss=0.6807931661605835
[5/24] Train loss=0.6640141010284424
[10/24] Train loss=0.6958652138710022
[15/24] Train loss=0.6545873284339905
[20/24] Train loss=0.6297343373298645
Test set avg_accuracy=88.97% avg_sensitivity=82.62%, avg_specificity=90.81% avg_auc=94.23%
Best model saved!! Metric=30.629381079059144!!
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.685936 Test loss=0.282781 Current lr=[0.00010220353965498347]

[0/24] Train loss=0.6635933518409729
[5/24] Train loss=0.6588224768638611
[10/24] Train loss=0.6730573177337646
[15/24] Train loss=0.63904869556427
[20/24] Train loss=0.6261255145072937
Test set avg_accuracy=88.53% avg_sensitivity=83.72%, avg_specificity=89.92% avg_auc=94.32%
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.669627 Test loss=0.286442 Current lr=[0.0001116610816848323]

[0/24] Train loss=0.6533942818641663
[5/24] Train loss=0.6380180716514587
[10/24] Train loss=0.656259298324585
[15/24] Train loss=0.6210557818412781
[20/24] Train loss=0.602012038230896
Test set avg_accuracy=89.28% avg_sensitivity=82.39%, avg_specificity=91.28% avg_auc=94.35%
Best model saved!! Metric=31.302374681809596!!
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.651569 Test loss=0.272898 Current lr=[0.00012133503888836635]

[0/24] Train loss=0.6442676186561584
[5/24] Train loss=0.6212911009788513
[10/24] Train loss=0.6529188752174377
[15/24] Train loss=0.6144282817840576
[20/24] Train loss=0.5926491022109985
Test set avg_accuracy=88.29% avg_sensitivity=85.57%, avg_specificity=89.08% avg_auc=94.61%
Best model saved!! Metric=31.558937448880627!!
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.639475 Test loss=0.288244 Current lr=[0.00013117819335391835]

[0/24] Train loss=0.618452250957489
[5/24] Train loss=0.5965763330459595
[10/24] Train loss=0.6385337710380554
[15/24] Train loss=0.6118786334991455
[20/24] Train loss=0.5865910053253174
Test set avg_accuracy=88.06% avg_sensitivity=87.08%, avg_specificity=88.34% avg_auc=94.64%
Best model saved!! Metric=32.12060849677739!!
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.625169 Test loss=0.293514 Current lr=[0.00014114250132976375]

[0/24] Train loss=0.6277602314949036
[5/24] Train loss=0.5948513150215149
[10/24] Train loss=0.6204016804695129
[15/24] Train loss=0.5793775320053101
[20/24] Train loss=0.5635587573051453
Test set avg_accuracy=88.92% avg_sensitivity=81.69%, avg_specificity=91.01% avg_auc=94.59%
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.608966 Test loss=0.269292 Current lr=[0.00015117932772232805]

[0/24] Train loss=0.5996266007423401
[5/24] Train loss=0.5513454675674438
[10/24] Train loss=0.6175273060798645
[15/24] Train loss=0.5713039636611938
[20/24] Train loss=0.567427933216095
Test set avg_accuracy=86.76% avg_sensitivity=87.43%, avg_specificity=86.56% avg_auc=94.62%
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.599988 Test loss=0.312337 Current lr=[0.00016123968348069324]

[0/24] Train loss=0.6027958393096924
[5/24] Train loss=0.5478034019470215
[10/24] Train loss=0.6074410676956177
[15/24] Train loss=0.5806486010551453
[20/24] Train loss=0.5525931119918823
Test set avg_accuracy=87.92% avg_sensitivity=85.63%, avg_specificity=88.58% avg_auc=94.61%
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.588957 Test loss=0.289609 Current lr=[0.00017127446470874475]

[0/24] Train loss=0.5956763029098511
[5/24] Train loss=0.5417842864990234
[10/24] Train loss=0.5824986100196838
[15/24] Train loss=0.5528155565261841
[20/24] Train loss=0.532386302947998
Test set avg_accuracy=89.11% avg_sensitivity=82.50%, avg_specificity=91.03% avg_auc=94.55%
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.575307 Test loss=0.266338 Current lr=[0.00018123469233786993]

[0/24] Train loss=0.5683553218841553
[5/24] Train loss=0.5070667266845703
[10/24] Train loss=0.5581185817718506
[15/24] Train loss=0.5403313636779785
[20/24] Train loss=0.5196361541748047
Test set avg_accuracy=89.15% avg_sensitivity=82.10%, avg_specificity=91.20% avg_auc=94.35%
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.559474 Test loss=0.267721 Current lr=[0.0001910717511903828]

[0/24] Train loss=0.5686204433441162
[5/24] Train loss=0.5064802169799805
[10/24] Train loss=0.5753868222236633
[15/24] Train loss=0.5401410460472107
[20/24] Train loss=0.49902454018592834
Test set avg_accuracy=89.27% avg_sensitivity=80.71%, avg_specificity=91.75% avg_auc=94.06%
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.557991 Test loss=0.269407 Current lr=[0.0002007376272668217]

[0/24] Train loss=0.5790092349052429
[5/24] Train loss=0.49174556136131287
[10/24] Train loss=0.5663878321647644
[15/24] Train loss=0.521948516368866
[20/24] Train loss=0.4976593852043152
Test set avg_accuracy=89.65% avg_sensitivity=77.93%, avg_specificity=93.05% avg_auc=93.72%
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.543600 Test loss=0.258585 Current lr=[0.000210185142098938]

[0/24] Train loss=0.5461192727088928
[5/24] Train loss=0.489577054977417
[10/24] Train loss=0.5364416837692261
[15/24] Train loss=0.5305615663528442
[20/24] Train loss=0.4877915382385254
Test set avg_accuracy=88.95% avg_sensitivity=63.04%, avg_specificity=96.46% avg_auc=92.16%
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.534248 Test loss=0.278339 Current lr=[0.00021936818302451596]

[0/24] Train loss=0.556949257850647
[5/24] Train loss=0.4918896555900574
[10/24] Train loss=0.5456365346908569
[15/24] Train loss=0.5094112753868103
[20/24] Train loss=0.48157408833503723
Test set avg_accuracy=88.82% avg_sensitivity=61.47%, avg_specificity=96.74% avg_auc=91.80%
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.527512 Test loss=0.283676 Current lr=[0.0002282419282600662]

[0/24] Train loss=0.5256715416908264
[5/24] Train loss=0.4668608605861664
[10/24] Train loss=0.5522105097770691
[15/24] Train loss=0.5033011436462402
[20/24] Train loss=0.4696919322013855
Test set avg_accuracy=87.08% avg_sensitivity=86.33%, avg_specificity=87.30% avg_auc=94.18%
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.519722 Test loss=0.308456 Current lr=[0.0002367630656728315]

[0/24] Train loss=0.5251444578170776
[5/24] Train loss=0.46538233757019043
[10/24] Train loss=0.5082606077194214
[15/24] Train loss=0.5219023823738098
[20/24] Train loss=0.47821205854415894
Test set avg_accuracy=89.93% avg_sensitivity=72.54%, avg_specificity=94.98% avg_auc=93.66%
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.512957 Test loss=0.251679 Current lr=[0.0002448900041842907]

[0/24] Train loss=0.5169041752815247
[5/24] Train loss=0.47582578659057617
[10/24] Train loss=0.518808901309967
[15/24] Train loss=0.49866241216659546
[20/24] Train loss=0.4635128378868103
Test set avg_accuracy=88.46% avg_sensitivity=78.10%, avg_specificity=91.47% avg_auc=93.45%
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.508048 Test loss=0.281864 Current lr=[0.0002525830767733185]

[0/24] Train loss=0.5223270058631897
[5/24] Train loss=0.4812636971473694
[10/24] Train loss=0.5255701541900635
[15/24] Train loss=0.4890824854373932
[20/24] Train loss=0.4545783996582031
Test set avg_accuracy=88.97% avg_sensitivity=84.30%, avg_specificity=90.33% avg_auc=94.05%
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.495701 Test loss=0.276261 Current lr=[0.00025980473408815364]

[0/24] Train loss=0.49915969371795654
[5/24] Train loss=0.44445425271987915
[10/24] Train loss=0.512861430644989
[15/24] Train loss=0.48545628786087036
[20/24] Train loss=0.4397049844264984
Test set avg_accuracy=89.82% avg_sensitivity=79.37%, avg_specificity=92.85% avg_auc=94.19%
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.485202 Test loss=0.257639 Current lr=[0.00026651972772217115]

[0/24] Train loss=0.47941333055496216
[5/24] Train loss=0.45829322934150696
[10/24] Train loss=0.482265442609787
[15/24] Train loss=0.4911258816719055
[20/24] Train loss=0.43158864974975586
Test set avg_accuracy=89.38% avg_sensitivity=69.29%, avg_specificity=95.20% avg_auc=92.37%
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.474379 Test loss=0.267975 Current lr=[0.0002726952822589012]

[0/24] Train loss=0.5048187375068665
[5/24] Train loss=0.44538044929504395
[10/24] Train loss=0.50096195936203
[15/24] Train loss=0.47896483540534973
[20/24] Train loss=0.42574021220207214
Test set avg_accuracy=88.65% avg_sensitivity=81.05%, avg_specificity=90.85% avg_auc=93.81%
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.473993 Test loss=0.273835 Current lr=[0.00027830125524655523]

[0/24] Train loss=0.4715713858604431
[5/24] Train loss=0.41028690338134766
[10/24] Train loss=0.473471462726593
[15/24] Train loss=0.4910609722137451
[20/24] Train loss=0.4129606783390045
Test set avg_accuracy=88.82% avg_sensitivity=70.92%, avg_specificity=94.00% avg_auc=91.70%
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.465426 Test loss=0.284505 Current lr=[0.00028331028432123506]

[0/24] Train loss=0.5095092058181763
[5/24] Train loss=0.4090363383293152
[10/24] Train loss=0.4949711859226227
[15/24] Train loss=0.45838841795921326
[20/24] Train loss=0.4439581334590912
Test set avg_accuracy=88.16% avg_sensitivity=79.72%, avg_specificity=90.61% avg_auc=93.47%
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.469239 Test loss=0.277861 Current lr=[0.0002876979207607258]

[0/24] Train loss=0.4917113184928894
[5/24] Train loss=0.41194307804107666
[10/24] Train loss=0.43744349479675293
[15/24] Train loss=0.46064430475234985
[20/24] Train loss=0.42585551738739014
Test set avg_accuracy=89.01% avg_sensitivity=73.87%, avg_specificity=93.40% avg_auc=92.30%
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.450964 Test loss=0.278876 Current lr=[0.0002914427488170074]

[0/24] Train loss=0.45546895265579224
[5/24] Train loss=0.403246134519577
[10/24] Train loss=0.4303010106086731
[15/24] Train loss=0.47037622332572937
[20/24] Train loss=0.43173110485076904
Test set avg_accuracy=89.11% avg_sensitivity=76.65%, avg_specificity=92.73% avg_auc=93.04%
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.448927 Test loss=0.272152 Current lr=[0.0002945264902450298]

[0/24] Train loss=0.4762141704559326
[5/24] Train loss=0.3994782269001007
[10/24] Train loss=0.4498463571071625
[15/24] Train loss=0.4589124917984009
[20/24] Train loss=0.4226481020450592
Test set avg_accuracy=89.45% avg_sensitivity=74.45%, avg_specificity=93.80% avg_auc=92.31%
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.450707 Test loss=0.271091 Current lr=[0.00029693409351755454]

[0/24] Train loss=0.4587462842464447
[5/24] Train loss=0.39455607533454895
[10/24] Train loss=0.45949289202690125
[15/24] Train loss=0.47154727578163147
[20/24] Train loss=0.4121999144554138
Test set avg_accuracy=90.09% avg_sensitivity=77.40%, avg_specificity=93.77% avg_auc=93.73%
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.444232 Test loss=0.260003 Current lr=[0.0002986538072906113]

[0/24] Train loss=0.44083642959594727
[5/24] Train loss=0.4211525321006775
[10/24] Train loss=0.4548858106136322
[15/24] Train loss=0.4447616934776306
[20/24] Train loss=0.38970330357551575
Test set avg_accuracy=89.35% avg_sensitivity=80.76%, avg_specificity=91.84% avg_auc=93.47%
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.437317 Test loss=0.275391 Current lr=[0.00029967723776099]

[0/24] Train loss=0.47241201996803284
[5/24] Train loss=0.38707825541496277
[10/24] Train loss=0.4185444116592407
[15/24] Train loss=0.4508434236049652
[20/24] Train loss=0.40393462777137756
Test set avg_accuracy=86.78% avg_sensitivity=86.33%, avg_specificity=86.92% avg_auc=94.01%
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.422706 Test loss=0.300564 Current lr=[0.00029999988343769313]

[0/24] Train loss=0.4334758222103119
[5/24] Train loss=0.34865450859069824
[10/24] Train loss=0.4106942117214203
[15/24] Train loss=0.44231969118118286
[20/24] Train loss=0.40303951501846313
Test set avg_accuracy=88.75% avg_sensitivity=82.16%, avg_specificity=90.66% avg_auc=93.85%
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.421204 Test loss=0.275554 Current lr=[0.0002999271544456625]

[0/24] Train loss=0.4355201721191406
[5/24] Train loss=0.3828528821468353
[10/24] Train loss=0.43221500515937805
[15/24] Train loss=0.44324833154678345
[20/24] Train loss=0.38614726066589355
Test set avg_accuracy=85.52% avg_sensitivity=87.49%, avg_specificity=84.95% avg_auc=93.79%
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.413001 Test loss=0.336003 Current lr=[0.000299720220882401]

[0/24] Train loss=0.4371739327907562
[5/24] Train loss=0.33239465951919556
[10/24] Train loss=0.41384923458099365
[15/24] Train loss=0.4064873456954956
[20/24] Train loss=0.3556257486343384
Test set avg_accuracy=87.49% avg_sensitivity=83.37%, avg_specificity=88.68% avg_auc=93.95%
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.401459 Test loss=0.295811 Current lr=[0.0002993792679814733]

[0/24] Train loss=0.4158312678337097
[5/24] Train loss=0.33851680159568787
[10/24] Train loss=0.3777884244918823
[15/24] Train loss=0.4125400185585022
[20/24] Train loss=0.35078996419906616
Test set avg_accuracy=85.21% avg_sensitivity=81.34%, avg_specificity=86.33% avg_auc=91.19%
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.394136 Test loss=0.350592 Current lr=[0.000298904600941902]

[0/24] Train loss=0.4117337167263031
[5/24] Train loss=0.3755854368209839
[10/24] Train loss=0.3919559717178345
[15/24] Train loss=0.40544700622558594
[20/24] Train loss=0.36102747917175293
Test set avg_accuracy=88.98% avg_sensitivity=74.86%, avg_specificity=93.08% avg_auc=91.92%
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.396988 Test loss=0.287370 Current lr=[0.0002982966446549732]

[0/24] Train loss=0.4054482579231262
[5/24] Train loss=0.33874645829200745
[10/24] Train loss=0.3899657428264618
[15/24] Train loss=0.4291107654571533
[20/24] Train loss=0.35226234793663025
Test set avg_accuracy=88.63% avg_sensitivity=69.29%, avg_specificity=94.24% avg_auc=90.47%
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.388247 Test loss=0.299004 Current lr=[0.000297555943323901]

[0/24] Train loss=0.4181804358959198
[5/24] Train loss=0.35186609625816345
[10/24] Train loss=0.40104931592941284
[15/24] Train loss=0.4144222140312195
[20/24] Train loss=0.36685818433761597
Test set avg_accuracy=86.51% avg_sensitivity=49.02%, avg_specificity=97.38% avg_auc=87.19%
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.397237 Test loss=0.380176 Current lr=[0.00029668315997669206]

[0/24] Train loss=0.44752365350723267
[5/24] Train loss=0.3241497278213501
[10/24] Train loss=0.3786294758319855
[15/24] Train loss=0.39987611770629883
[20/24] Train loss=0.3418339490890503
Test set avg_accuracy=87.94% avg_sensitivity=58.81%, avg_specificity=96.39% avg_auc=88.60%
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.381669 Test loss=0.339374 Current lr=[0.0002956790758726458]

[0/24] Train loss=0.3816428780555725
[5/24] Train loss=0.34044507145881653
[10/24] Train loss=0.3571767807006836
[15/24] Train loss=0.4090275764465332
[20/24] Train loss=0.339192271232605
Test set avg_accuracy=87.72% avg_sensitivity=71.84%, avg_specificity=92.32% avg_auc=90.91%
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.375767 Test loss=0.328037 Current lr=[0.00029454458980302146]

[0/24] Train loss=0.38218265771865845
[5/24] Train loss=0.3575158715248108
[10/24] Train loss=0.3824511766433716
[15/24] Train loss=0.4209713339805603
[20/24] Train loss=0.3507428765296936
Test set avg_accuracy=88.26% avg_sensitivity=81.52%, avg_specificity=90.21% avg_auc=93.51%
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.384411 Test loss=0.297093 Current lr=[0.0002932807172864983]

[0/24] Train loss=0.3923502564430237
[5/24] Train loss=0.34230929613113403
[10/24] Train loss=0.3805202543735504
[15/24] Train loss=0.3988935053348541
[20/24] Train loss=0.3639781177043915
Test set avg_accuracy=86.24% avg_sensitivity=86.85%, avg_specificity=86.06% avg_auc=93.45%
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.391689 Test loss=0.343337 Current lr=[0.0002918885896601485]

[0/24] Train loss=0.3882609009742737
[5/24] Train loss=0.32518771290779114
[10/24] Train loss=0.3700052499771118
[15/24] Train loss=0.41691651940345764
[20/24] Train loss=0.36993396282196045
Test set avg_accuracy=81.33% avg_sensitivity=90.15%, avg_specificity=78.77% avg_auc=93.11%
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.383469 Test loss=0.440855 Current lr=[0.00029036945306673773]

[0/24] Train loss=0.36088889837265015
[5/24] Train loss=0.3689054548740387
[10/24] Train loss=0.3823663890361786
[15/24] Train loss=0.3931809663772583
[20/24] Train loss=0.3525269031524658
Test set avg_accuracy=89.23% avg_sensitivity=73.87%, avg_specificity=93.68% avg_auc=92.00%
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.371602 Test loss=0.289033 Current lr=[0.0002887246673392583]

[0/24] Train loss=0.3558024764060974
[5/24] Train loss=0.31771788001060486
[10/24] Train loss=0.3481568396091461
[15/24] Train loss=0.38240543007850647
[20/24] Train loss=0.3335188031196594
Test set avg_accuracy=89.04% avg_sensitivity=68.48%, avg_specificity=94.99% avg_auc=90.67%
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.365124 Test loss=0.292956 Current lr=[0.0002869557047836946]

[0/24] Train loss=0.35887110233306885
[5/24] Train loss=0.343334823846817
[10/24] Train loss=0.36442831158638
[15/24] Train loss=0.3542531430721283
[20/24] Train loss=0.33765968680381775
Test set avg_accuracy=89.06% avg_sensitivity=67.44%, avg_specificity=95.33% avg_auc=90.92%
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.356112 Test loss=0.298486 Current lr=[0.00028506414886110966]

[0/24] Train loss=0.3515460789203644
[5/24] Train loss=0.31644758582115173
[10/24] Train loss=0.35627302527427673
[15/24] Train loss=0.38077512383461
[20/24] Train loss=0.33737489581108093
Test set avg_accuracy=86.95% avg_sensitivity=85.11%, avg_specificity=87.49% avg_auc=93.43%
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.357480 Test loss=0.320760 Current lr=[0.0002830516927702333]

[0/24] Train loss=0.36031919717788696
[5/24] Train loss=0.32803550362586975
[10/24] Train loss=0.3848956525325775
[15/24] Train loss=0.36331412196159363
[20/24] Train loss=0.33012494444847107
Test set avg_accuracy=85.12% avg_sensitivity=85.05%, avg_specificity=85.14% avg_auc=92.76%
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.357163 Test loss=0.354273 Current lr=[0.00028092013793181987]

[0/24] Train loss=0.3578876852989197
[5/24] Train loss=0.28798091411590576
[10/24] Train loss=0.34703329205513
[15/24] Train loss=0.3369048237800598
[20/24] Train loss=0.31467077136039734
Test set avg_accuracy=89.22% avg_sensitivity=74.22%, avg_specificity=93.57% avg_auc=91.76%
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.341650 Test loss=0.283631 Current lr=[0.00027867139237613254]

[0/24] Train loss=0.3615400493144989
[5/24] Train loss=0.2746106684207916
[10/24] Train loss=0.36189398169517517
[15/24] Train loss=0.342241495847702
[20/24] Train loss=0.3081130385398865
Test set avg_accuracy=86.74% avg_sensitivity=83.20%, avg_specificity=87.77% avg_auc=93.02%
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.343485 Test loss=0.319088 Current lr=[0.000276307469034998]

[0/24] Train loss=0.3575219511985779
[5/24] Train loss=0.30963268876075745
[10/24] Train loss=0.32559001445770264
[15/24] Train loss=0.33893337845802307
[20/24] Train loss=0.3042740523815155
Test set avg_accuracy=88.97% avg_sensitivity=77.35%, avg_specificity=92.34% avg_auc=93.13%
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.339347 Test loss=0.277613 Current lr=[0.00027383048393995985]

[0/24] Train loss=0.33567094802856445
[5/24] Train loss=0.30435341596603394
[10/24] Train loss=0.2905347943305969
[15/24] Train loss=0.32807615399360657
[20/24] Train loss=0.28440919518470764
Test set avg_accuracy=87.81% avg_sensitivity=70.34%, avg_specificity=92.88% avg_auc=88.68%
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.326341 Test loss=0.325992 Current lr=[0.0002712426543281436]

[0/24] Train loss=0.3090885579586029
[5/24] Train loss=0.2849830389022827
[10/24] Train loss=0.3063945174217224
[15/24] Train loss=0.33785414695739746
[20/24] Train loss=0.29324251413345337
Test set avg_accuracy=89.05% avg_sensitivity=75.14%, avg_specificity=93.08% avg_auc=92.02%
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.324536 Test loss=0.288867 Current lr=[0.0002685462966575293]

[0/24] Train loss=0.3459343910217285
[5/24] Train loss=0.27324843406677246
[10/24] Train loss=0.3222752511501312
[15/24] Train loss=0.32597118616104126
[20/24] Train loss=0.2842349112033844
Test set avg_accuracy=89.06% avg_sensitivity=75.72%, avg_specificity=92.93% avg_auc=92.60%
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.324715 Test loss=0.277228 Current lr=[0.00026574382453340795]

[0/24] Train loss=0.3452235162258148
[5/24] Train loss=0.3066572844982147
[10/24] Train loss=0.29460471868515015
[15/24] Train loss=0.34769460558891296
[20/24] Train loss=0.27595487236976624
Test set avg_accuracy=87.29% avg_sensitivity=80.59%, avg_specificity=89.23% avg_auc=92.18%
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.319071 Test loss=0.321274 Current lr=[0.0002628377465478779]

[0/24] Train loss=0.32894963026046753
[5/24] Train loss=0.2626717686653137
[10/24] Train loss=0.2936738431453705
[15/24] Train loss=0.31370672583580017
[20/24] Train loss=0.3084685802459717
Test set avg_accuracy=89.21% avg_sensitivity=76.30%, avg_specificity=92.95% avg_auc=92.44%
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.316270 Test loss=0.283087 Current lr=[0.0002598306640343149]

[0/24] Train loss=0.31018099188804626
[5/24] Train loss=0.2729423940181732
[10/24] Train loss=0.28626617789268494
[15/24] Train loss=0.31780722737312317
[20/24] Train loss=0.28703275322914124
Test set avg_accuracy=84.74% avg_sensitivity=84.47%, avg_specificity=84.82% avg_auc=92.51%
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.306816 Test loss=0.357418 Current lr=[0.00025672526873882695]

[0/24] Train loss=0.32435494661331177
[5/24] Train loss=0.25965744256973267
[10/24] Train loss=0.3045019209384918
[15/24] Train loss=0.3335350751876831
[20/24] Train loss=0.27463412284851074
Test set avg_accuracy=87.16% avg_sensitivity=82.16%, avg_specificity=88.61% avg_auc=92.43%
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.305453 Test loss=0.327958 Current lr=[0.00025352434041077637]

[0/24] Train loss=0.32757723331451416
[5/24] Train loss=0.2741442620754242
[10/24] Train loss=0.29529744386672974
[15/24] Train loss=0.31270337104797363
[20/24] Train loss=0.2869551479816437
Test set avg_accuracy=87.37% avg_sensitivity=83.37%, avg_specificity=88.53% avg_auc=93.17%
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.299772 Test loss=0.319451 Current lr=[0.0002502307443145281]

[0/24] Train loss=0.3064759075641632
[5/24] Train loss=0.2621268630027771
[10/24] Train loss=0.2723851799964905
[15/24] Train loss=0.3045296370983124
[20/24] Train loss=0.277604877948761
Test set avg_accuracy=89.78% avg_sensitivity=78.68%, avg_specificity=93.00% avg_auc=92.62%
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.294766 Test loss=0.275883 Current lr=[0.00024684742866464985]

[0/24] Train loss=0.2886110544204712
[5/24] Train loss=0.27112624049186707
[10/24] Train loss=0.29183313250541687
[15/24] Train loss=0.29184040427207947
[20/24] Train loss=0.2851777970790863
Test set avg_accuracy=88.27% avg_sensitivity=81.81%, avg_specificity=90.14% avg_auc=92.31%
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.294943 Test loss=0.309200 Current lr=[0.00024337742198686098]

[0/24] Train loss=0.30983272194862366
[5/24] Train loss=0.25402384996414185
[10/24] Train loss=0.2824462950229645
[15/24] Train loss=0.3035197854042053
[20/24] Train loss=0.285358726978302
Test set avg_accuracy=89.53% avg_sensitivity=71.44%, avg_specificity=94.78% avg_auc=91.96%
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.293070 Test loss=0.293093 Current lr=[0.00023982383040709125]

[0/24] Train loss=0.29806068539619446
[5/24] Train loss=0.25827300548553467
[10/24] Train loss=0.2674597203731537
[15/24] Train loss=0.3020752966403961
[20/24] Train loss=0.2678777575492859
Test set avg_accuracy=88.54% avg_sensitivity=80.59%, avg_specificity=90.85% avg_auc=92.94%
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.287075 Test loss=0.300679 Current lr=[0.00023618983487107818]

[0/24] Train loss=0.2741493880748749
[5/24] Train loss=0.24902525544166565
[10/24] Train loss=0.26663658022880554
[15/24] Train loss=0.2821747064590454
[20/24] Train loss=0.27036815881729126
Test set avg_accuracy=90.35% avg_sensitivity=79.84%, avg_specificity=93.40% avg_auc=93.21%
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.280990 Test loss=0.260468 Current lr=[0.00023247868829698952]

[0/24] Train loss=0.27535128593444824
[5/24] Train loss=0.26669636368751526
[10/24] Train loss=0.24893073737621307
[15/24] Train loss=0.3036907911300659
[20/24] Train loss=0.25994354486465454
Test set avg_accuracy=86.61% avg_sensitivity=86.67%, avg_specificity=86.60% avg_auc=93.83%
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.282279 Test loss=0.329645 Current lr=[0.0002286937126636206]

[0/24] Train loss=0.28583064675331116
[5/24] Train loss=0.25455915927886963
[10/24] Train loss=0.27181220054626465
[15/24] Train loss=0.3054976165294647
[20/24] Train loss=0.25953981280326843
Test set avg_accuracy=89.43% avg_sensitivity=78.62%, avg_specificity=92.56% avg_auc=92.89%
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.280966 Test loss=0.279033 Current lr=[0.000224838296036774]

[0/24] Train loss=0.27988359332084656
[5/24] Train loss=0.2406471073627472
[10/24] Train loss=0.26600855588912964
[15/24] Train loss=0.29201972484588623
[20/24] Train loss=0.2586282193660736
Test set avg_accuracy=87.89% avg_sensitivity=85.11%, avg_specificity=88.70% avg_auc=94.50%
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.279212 Test loss=0.295202 Current lr=[0.00022091588953648128]

[0/24] Train loss=0.2947596311569214
[5/24] Train loss=0.262045294046402
[10/24] Train loss=0.2532479465007782
[15/24] Train loss=0.278750479221344
[20/24] Train loss=0.2667134404182434
Test set avg_accuracy=86.84% avg_sensitivity=83.31%, avg_specificity=87.86% avg_auc=92.68%
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.274041 Test loss=0.334588 Current lr=[0.00021693000424778344]

[0/24] Train loss=0.25706014037132263
[5/24] Train loss=0.24503980576992035
[10/24] Train loss=0.24026399850845337
[15/24] Train loss=0.27267828583717346
[20/24] Train loss=0.23711299896240234
Test set avg_accuracy=89.17% avg_sensitivity=73.52%, avg_specificity=93.70% avg_auc=92.05%
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.266233 Test loss=0.290035 Current lr=[0.00021288420807783433]

[0/24] Train loss=0.2708917260169983
[5/24] Train loss=0.23164035379886627
[10/24] Train loss=0.28032660484313965
[15/24] Train loss=0.2898848056793213
[20/24] Train loss=0.250348299741745
Test set avg_accuracy=89.44% avg_sensitivity=70.28%, avg_specificity=94.99% avg_auc=89.60%
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.273433 Test loss=0.303735 Current lr=[0.00020878212256214028]

[0/24] Train loss=0.27542126178741455
[5/24] Train loss=0.24096566438674927
[10/24] Train loss=0.25885581970214844
[15/24] Train loss=0.2730720043182373
[20/24] Train loss=0.25884905457496643
Test set avg_accuracy=89.53% avg_sensitivity=73.29%, avg_specificity=94.24% avg_auc=92.01%
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.277664 Test loss=0.292566 Current lr=[0.00020462741962279558]

[0/24] Train loss=0.2738194167613983
[5/24] Train loss=0.2601800858974457
[10/24] Train loss=0.271399587392807
[15/24] Train loss=0.2753220796585083
[20/24] Train loss=0.24875184893608093
Test set avg_accuracy=89.53% avg_sensitivity=81.17%, avg_specificity=91.95% avg_auc=93.89%
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.279848 Test loss=0.272523 Current lr=[0.00020042381828161472]

[0/24] Train loss=0.29592669010162354
[5/24] Train loss=0.24976935982704163
[10/24] Train loss=0.2456815093755722
[15/24] Train loss=0.279220312833786
[20/24] Train loss=0.25227776169776917
Test set avg_accuracy=88.54% avg_sensitivity=83.14%, avg_specificity=90.11% avg_auc=93.49%
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.272139 Test loss=0.300126 Current lr=[0.0001961750813311045]

[0/24] Train loss=0.2683969736099243
[5/24] Train loss=0.2520178258419037
[10/24] Train loss=0.24261663854122162
[15/24] Train loss=0.26366326212882996
[20/24] Train loss=0.24021460115909576
Test set avg_accuracy=89.36% avg_sensitivity=82.16%, avg_specificity=91.45% avg_auc=93.91%
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.262121 Test loss=0.278593 Current lr=[0.00019188501196625468]

[0/24] Train loss=0.2434983104467392
[5/24] Train loss=0.23946477472782135
[10/24] Train loss=0.24699276685714722
[15/24] Train loss=0.258649080991745
[20/24] Train loss=0.25923609733581543
Test set avg_accuracy=89.22% avg_sensitivity=83.31%, avg_specificity=90.93% avg_auc=93.91%
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.260340 Test loss=0.282039 Current lr=[0.00018755745038016378]

[0/24] Train loss=0.26044222712516785
[5/24] Train loss=0.2527960538864136
[10/24] Train loss=0.24412472546100616
[15/24] Train loss=0.26967450976371765
[20/24] Train loss=0.23025116324424744
Test set avg_accuracy=89.23% avg_sensitivity=80.59%, avg_specificity=91.74% avg_auc=93.02%
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.259800 Test loss=0.285564 Current lr=[0.00018319627032654603]

[0/24] Train loss=0.274998277425766
[5/24] Train loss=0.23020990192890167
[10/24] Train loss=0.2596725523471832
[15/24] Train loss=0.25938302278518677
[20/24] Train loss=0.23689933121204376
Test set avg_accuracy=87.49% avg_sensitivity=87.37%, avg_specificity=87.52% avg_auc=93.57%
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.253282 Test loss=0.330505 Current lr=[0.00017880537565219696]

[0/24] Train loss=0.2574065625667572
[5/24] Train loss=0.2281564325094223
[10/24] Train loss=0.2245633751153946
[15/24] Train loss=0.24760527908802032
[20/24] Train loss=0.2258746325969696
Test set avg_accuracy=89.22% avg_sensitivity=83.02%, avg_specificity=91.01% avg_auc=93.61%
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.246328 Test loss=0.290341 Current lr=[0.00017438869680252216]

[0/24] Train loss=0.2421167492866516
[5/24] Train loss=0.2350214719772339
[10/24] Train loss=0.21602384746074677
[15/24] Train loss=0.2520613372325897
[20/24] Train loss=0.2225273847579956
Test set avg_accuracy=87.45% avg_sensitivity=84.30%, avg_specificity=88.36% avg_auc=92.99%
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.242223 Test loss=0.324968 Current lr=[0.00016995018730325622]

[0/24] Train loss=0.2565273940563202
[5/24] Train loss=0.2397451400756836
[10/24] Train loss=0.2275921106338501
[15/24] Train loss=0.23643001914024353
[20/24] Train loss=0.23456965386867523
Test set avg_accuracy=88.26% avg_sensitivity=86.10%, avg_specificity=88.88% avg_auc=93.76%
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.242197 Test loss=0.313745 Current lr=[0.0001654938202215215]

[0/24] Train loss=0.24569809436798096
[5/24] Train loss=0.21706664562225342
[10/24] Train loss=0.22059819102287292
[15/24] Train loss=0.24155423045158386
[20/24] Train loss=0.2224297672510147
Test set avg_accuracy=88.82% avg_sensitivity=80.71%, avg_specificity=91.17% avg_auc=93.28%
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.242261 Test loss=0.302014 Current lr=[0.00016102358460939534]

[0/24] Train loss=0.24091091752052307
[5/24] Train loss=0.2324737310409546
[10/24] Train loss=0.24103067815303802
[15/24] Train loss=0.24892406165599823
[20/24] Train loss=0.22751078009605408
Test set avg_accuracy=88.46% avg_sensitivity=83.43%, avg_specificity=89.92% avg_auc=93.53%
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.245009 Test loss=0.307435 Current lr=[0.000156543481933168]

[0/24] Train loss=0.24662329256534576
[5/24] Train loss=0.21800236403942108
[10/24] Train loss=0.21863868832588196
[15/24] Train loss=0.24947495758533478
[20/24] Train loss=0.21983467042446136
Test set avg_accuracy=89.02% avg_sensitivity=82.44%, avg_specificity=90.93% avg_auc=94.34%
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.242646 Test loss=0.287439 Current lr=[0.00015205752249148835]

[0/24] Train loss=0.24085798859596252
[5/24] Train loss=0.22374357283115387
[10/24] Train loss=0.2503955066204071
[15/24] Train loss=0.24152947962284088
[20/24] Train loss=0.22369223833084106
Test set avg_accuracy=89.62% avg_sensitivity=83.37%, avg_specificity=91.43% avg_auc=93.80%
Best model saved!! Metric=32.23327643163215!!
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.243479 Test loss=0.283910 Current lr=[0.00014756972182560367]

[0/24] Train loss=0.25872018933296204
[5/24] Train loss=0.23329509794712067
[10/24] Train loss=0.22435268759727478
[15/24] Train loss=0.23776312172412872
[20/24] Train loss=0.22863849997520447
Test set avg_accuracy=89.73% avg_sensitivity=79.43%, avg_specificity=92.71% avg_auc=93.72%
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.242024 Test loss=0.277697 Current lr=[0.0001430840971249062]

[0/24] Train loss=0.267569363117218
[5/24] Train loss=0.23766294121742249
[10/24] Train loss=0.20891152322292328
[15/24] Train loss=0.23516754806041718
[20/24] Train loss=0.2319006472826004
Test set avg_accuracy=87.83% avg_sensitivity=86.15%, avg_specificity=88.31% avg_auc=93.86%
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.237676 Test loss=0.329336 Current lr=[0.00013860466363100455]

[0/24] Train loss=0.2291894257068634
[5/24] Train loss=0.21190109848976135
[10/24] Train loss=0.2357500195503235
[15/24] Train loss=0.23772919178009033
[20/24] Train loss=0.24592745304107666
Test set avg_accuracy=89.13% avg_sensitivity=80.59%, avg_specificity=91.60% avg_auc=93.42%
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.238854 Test loss=0.290304 Current lr=[0.000134135431043539]

[0/24] Train loss=0.2465095818042755
[5/24] Train loss=0.21260309219360352
[10/24] Train loss=0.23075172305107117
[15/24] Train loss=0.23836927115917206
[20/24] Train loss=0.22692017257213593
Test set avg_accuracy=90.16% avg_sensitivity=80.88%, avg_specificity=92.85% avg_auc=93.78%
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.235846 Test loss=0.273406 Current lr=[0.0001296803999309568]

[0/24] Train loss=0.22920915484428406
[5/24] Train loss=0.20881929993629456
[10/24] Train loss=0.21410831809043884
[15/24] Train loss=0.2285601645708084
[20/24] Train loss=0.21870450675487518
Test set avg_accuracy=89.97% avg_sensitivity=77.23%, avg_specificity=93.67% avg_auc=92.76%
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.229103 Test loss=0.281332 Current lr=[0.00012524355814946188]

[0/24] Train loss=0.24766750633716583
[5/24] Train loss=0.2160947173833847
[10/24] Train loss=0.2151818424463272
[15/24] Train loss=0.23413696885108948
[20/24] Train loss=0.24378269910812378
Test set avg_accuracy=90.27% avg_sensitivity=74.33%, avg_specificity=94.89% avg_auc=91.80%
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.236720 Test loss=0.282215 Current lr=[0.0001208288772733435]

[0/24] Train loss=0.23980383574962616
[5/24] Train loss=0.21502289175987244
[10/24] Train loss=0.20747433602809906
[15/24] Train loss=0.22708956897258759
[20/24] Train loss=0.21375511586666107
Test set avg_accuracy=89.71% avg_sensitivity=75.72%, avg_specificity=93.77% avg_auc=93.48%
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.231223 Test loss=0.281758 Current lr=[0.00011644030903987921]

[0/24] Train loss=0.23475371301174164
[5/24] Train loss=0.21590177714824677
[10/24] Train loss=0.20460684597492218
[15/24] Train loss=0.2290857881307602
[20/24] Train loss=0.21506154537200928
Test set avg_accuracy=90.34% avg_sensitivity=73.12%, avg_specificity=95.33% avg_auc=91.93%
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.224514 Test loss=0.280881 Current lr=[0.00011208178181199481]

[0/24] Train loss=0.2356913685798645
[5/24] Train loss=0.20568493008613586
[10/24] Train loss=0.20403732359409332
[15/24] Train loss=0.2285739630460739
[20/24] Train loss=0.20410077273845673
Test set avg_accuracy=89.66% avg_sensitivity=74.22%, avg_specificity=94.14% avg_auc=92.63%
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.219052 Test loss=0.291736 Current lr=[0.00010775719706184782]

[0/24] Train loss=0.22538262605667114
[5/24] Train loss=0.20257128775119781
[10/24] Train loss=0.19054651260375977
[15/24] Train loss=0.20936185121536255
[20/24] Train loss=0.20464164018630981
Test set avg_accuracy=89.40% avg_sensitivity=76.36%, avg_specificity=93.18% avg_auc=92.63%
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.213067 Test loss=0.290206 Current lr=[0.00010347042587848097]

[0/24] Train loss=0.21813617646694183
[5/24] Train loss=0.19590365886688232
[10/24] Train loss=0.19496047496795654
[15/24] Train loss=0.2154628485441208
[20/24] Train loss=0.19531069695949554
Test set avg_accuracy=89.32% avg_sensitivity=75.84%, avg_specificity=93.23% avg_auc=92.62%
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.209182 Test loss=0.286065 Current lr=[9.922530550267357e-05]

[0/24] Train loss=0.21718436479568481
[5/24] Train loss=0.19262506067752838
[10/24] Train loss=0.18400810658931732
[15/24] Train loss=0.20625293254852295
[20/24] Train loss=0.20521248877048492
Test set avg_accuracy=89.57% avg_sensitivity=76.94%, avg_specificity=93.23% avg_auc=92.61%
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.206484 Test loss=0.289012 Current lr=[9.502563589209146e-05]

[0/24] Train loss=0.20969665050506592
[5/24] Train loss=0.18516312539577484
[10/24] Train loss=0.18449166417121887
[15/24] Train loss=0.1952391415834427
[20/24] Train loss=0.19532090425491333
Test set avg_accuracy=89.90% avg_sensitivity=78.22%, avg_specificity=93.28% avg_auc=92.57%
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.201912 Test loss=0.288941 Current lr=[9.087517631980985e-05]

[0/24] Train loss=0.20059756934642792
[5/24] Train loss=0.18888045847415924
[10/24] Train loss=0.1787233054637909
[15/24] Train loss=0.19407351315021515
[20/24] Train loss=0.18638649582862854
Test set avg_accuracy=88.93% avg_sensitivity=82.10%, avg_specificity=90.91% avg_auc=93.08%
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.198561 Test loss=0.295787 Current lr=[8.677764200925512e-05]

[0/24] Train loss=0.20366810262203217
[5/24] Train loss=0.1931576281785965
[10/24] Train loss=0.17285172641277313
[15/24] Train loss=0.1916818469762802
[20/24] Train loss=0.1953347623348236
Test set avg_accuracy=90.07% avg_sensitivity=80.36%, avg_specificity=92.88% avg_auc=93.34%
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.196352 Test loss=0.277381 Current lr=[8.273670080857652e-05]

[0/24] Train loss=0.1993822455406189
[5/24] Train loss=0.18429365754127502
[10/24] Train loss=0.17377392947673798
[15/24] Train loss=0.18754130601882935
[20/24] Train loss=0.18938539922237396
Test set avg_accuracy=90.01% avg_sensitivity=81.23%, avg_specificity=92.56% avg_auc=93.57%
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.193911 Test loss=0.276831 Current lr=[7.875596990742549e-05]

[0/24] Train loss=0.19208648800849915
[5/24] Train loss=0.17787232995033264
[10/24] Train loss=0.16921362280845642
[15/24] Train loss=0.18695737421512604
[20/24] Train loss=0.18653006851673126
Test set avg_accuracy=90.18% avg_sensitivity=80.48%, avg_specificity=93.00% avg_auc=93.52%
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.190202 Test loss=0.275511 Current lr=[7.483901259908084e-05]

[0/24] Train loss=0.19006294012069702
[5/24] Train loss=0.1744060516357422
[10/24] Train loss=0.16828031837940216
[15/24] Train loss=0.18628624081611633
[20/24] Train loss=0.19454273581504822
Test set avg_accuracy=90.21% avg_sensitivity=75.96%, avg_specificity=94.34% avg_auc=92.81%
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.187925 Test loss=0.274985 Current lr=[7.098933509081871e-05]

[0/24] Train loss=0.19050030410289764
[5/24] Train loss=0.17840386927127838
[10/24] Train loss=0.1697636991739273
[15/24] Train loss=0.18646955490112305
[20/24] Train loss=0.1849062740802765
Test set avg_accuracy=90.14% avg_sensitivity=76.42%, avg_specificity=94.12% avg_auc=92.95%
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.187272 Test loss=0.276893 Current lr=[6.721038336538246e-05]

[0/24] Train loss=0.18701760470867157
[5/24] Train loss=0.17760975658893585
[10/24] Train loss=0.1669129729270935
[15/24] Train loss=0.1886032223701477
[20/24] Train loss=0.17582634091377258
Test set avg_accuracy=89.77% avg_sensitivity=78.97%, avg_specificity=92.90% avg_auc=93.25%
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.185271 Test loss=0.280484 Current lr=[6.350554009636106e-05]

[0/24] Train loss=0.18585385382175446
[5/24] Train loss=0.17230188846588135
[10/24] Train loss=0.1601480096578598
[15/24] Train loss=0.1798335462808609
[20/24] Train loss=0.1738661378622055
Test set avg_accuracy=90.21% avg_sensitivity=76.94%, avg_specificity=94.05% avg_auc=93.16%
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.181820 Test loss=0.272208 Current lr=[5.9878121620238205e-05]

[0/24] Train loss=0.18307970464229584
[5/24] Train loss=0.17743486166000366
[10/24] Train loss=0.1663130819797516
[15/24] Train loss=0.1831682175397873
[20/24] Train loss=0.17938417196273804
Test set avg_accuracy=89.93% avg_sensitivity=76.71%, avg_specificity=93.77% avg_auc=92.89%
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.182704 Test loss=0.281285 Current lr=[5.633137496782231e-05]

[0/24] Train loss=0.18604975938796997
[5/24] Train loss=0.1712486743927002
[10/24] Train loss=0.1650615632534027
[15/24] Train loss=0.17940881848335266
[20/24] Train loss=0.1818363517522812
Test set avg_accuracy=89.99% avg_sensitivity=76.30%, avg_specificity=93.95% avg_auc=93.03%
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.181558 Test loss=0.284593 Current lr=[5.2868474957713746e-05]

[0/24] Train loss=0.18920205533504486
[5/24] Train loss=0.17477065324783325
[10/24] Train loss=0.1697799414396286
[15/24] Train loss=0.17845037579536438
[20/24] Train loss=0.17739585041999817
Test set avg_accuracy=90.05% avg_sensitivity=73.70%, avg_specificity=94.79% avg_auc=92.32%
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.180542 Test loss=0.286875 Current lr=[4.949252135441245e-05]

[0/24] Train loss=0.19145214557647705
[5/24] Train loss=0.17228074371814728
[10/24] Train loss=0.15900248289108276
[15/24] Train loss=0.17887356877326965
[20/24] Train loss=0.16976529359817505
Test set avg_accuracy=89.79% avg_sensitivity=74.86%, avg_specificity=94.12% avg_auc=92.23%
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.179081 Test loss=0.293307 Current lr=[4.620653609360885e-05]

[0/24] Train loss=0.18126143515110016
[5/24] Train loss=0.1743939369916916
[10/24] Train loss=0.16186559200286865
[15/24] Train loss=0.18219546973705292
[20/24] Train loss=0.17831437289714813
Test set avg_accuracy=90.22% avg_sensitivity=75.38%, avg_specificity=94.52% avg_auc=92.68%
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.181481 Test loss=0.280183 Current lr=[4.301346057714228e-05]

[0/24] Train loss=0.17820186913013458
[5/24] Train loss=0.16744472086429596
[10/24] Train loss=0.1683606207370758
[15/24] Train loss=0.17544810473918915
[20/24] Train loss=0.1788589209318161
Test set avg_accuracy=90.20% avg_sensitivity=74.16%, avg_specificity=94.84% avg_auc=92.52%
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.180545 Test loss=0.277265 Current lr=[3.99161530400477e-05]

[0/24] Train loss=0.18507631123065948
[5/24] Train loss=0.1780349463224411
[10/24] Train loss=0.1636952906847
[15/24] Train loss=0.17800262570381165
[20/24] Train loss=0.1739136427640915
Test set avg_accuracy=90.26% avg_sensitivity=72.77%, avg_specificity=95.33% avg_auc=92.09%
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.181888 Test loss=0.281960 Current lr=[3.69173859920484e-05]

[0/24] Train loss=0.18115468323230743
[5/24] Train loss=0.18243157863616943
[10/24] Train loss=0.16416716575622559
[15/24] Train loss=0.17323461174964905
[20/24] Train loss=0.1835871785879135
Test set avg_accuracy=89.47% avg_sensitivity=80.13%, avg_specificity=92.17% avg_auc=93.48%
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.181766 Test loss=0.286203 Current lr=[3.401984373578441e-05]

[0/24] Train loss=0.17903152108192444
[5/24] Train loss=0.16717320680618286
[10/24] Train loss=0.1724337935447693
[15/24] Train loss=0.17289921641349792
[20/24] Train loss=0.18313580751419067
Test set avg_accuracy=90.01% avg_sensitivity=79.49%, avg_specificity=93.06% avg_auc=93.16%
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.182889 Test loss=0.288681 Current lr=[3.122611996399788e-05]

[0/24] Train loss=0.18850302696228027
[5/24] Train loss=0.1641295850276947
[10/24] Train loss=0.17021851241588593
[15/24] Train loss=0.1781768947839737
[20/24] Train loss=0.1759950816631317
Test set avg_accuracy=90.49% avg_sensitivity=75.43%, avg_specificity=94.86% avg_auc=93.23%
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.181800 Test loss=0.271562 Current lr=[2.8538715437826888e-05]

[0/24] Train loss=0.18795615434646606
[5/24] Train loss=0.1673709601163864
[10/24] Train loss=0.16077512502670288
[15/24] Train loss=0.1766727864742279
[20/24] Train loss=0.1708855777978897
Test set avg_accuracy=90.43% avg_sensitivity=75.72%, avg_specificity=94.69% avg_auc=92.94%
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.176627 Test loss=0.276038 Current lr=[2.596003574828569e-05]

[0/24] Train loss=0.1751624047756195
[5/24] Train loss=0.16422925889492035
[10/24] Train loss=0.15636488795280457
[15/24] Train loss=0.17144717276096344
[20/24] Train loss=0.16510550677776337
Test set avg_accuracy=90.38% avg_sensitivity=78.62%, avg_specificity=93.79% avg_auc=93.51%
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.172296 Test loss=0.272071 Current lr=[2.3492389162934664e-05]

[0/24] Train loss=0.17386065423488617
[5/24] Train loss=0.16527335345745087
[10/24] Train loss=0.15658335387706757
[15/24] Train loss=0.1653861403465271
[20/24] Train loss=0.16803190112113953
Test set avg_accuracy=90.48% avg_sensitivity=77.11%, avg_specificity=94.36% avg_auc=93.29%
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.170755 Test loss=0.271726 Current lr=[2.113798455966845e-05]

[0/24] Train loss=0.17332422733306885
[5/24] Train loss=0.16059307754039764
[10/24] Train loss=0.1523819863796234
[15/24] Train loss=0.16406035423278809
[20/24] Train loss=0.16844400763511658
Test set avg_accuracy=90.46% avg_sensitivity=78.27%, avg_specificity=93.99% avg_auc=93.56%
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.169693 Test loss=0.268848 Current lr=[1.8898929449471093e-05]

[0/24] Train loss=0.1763565093278885
[5/24] Train loss=0.16302254796028137
[10/24] Train loss=0.15565761923789978
[15/24] Train loss=0.1643344908952713
[20/24] Train loss=0.16380168497562408
Test set avg_accuracy=90.56% avg_sensitivity=77.35%, avg_specificity=94.39% avg_auc=93.37%
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.169047 Test loss=0.269156 Current lr=[1.6777228089908115e-05]

[0/24] Train loss=0.17397280037403107
[5/24] Train loss=0.16075362265110016
[10/24] Train loss=0.154042050242424
[15/24] Train loss=0.16586348414421082
[20/24] Train loss=0.1655322164297104
Test set avg_accuracy=90.49% avg_sensitivity=77.75%, avg_specificity=94.19% avg_auc=93.40%
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.168747 Test loss=0.270599 Current lr=[1.4774779691044682e-05]

[0/24] Train loss=0.16781359910964966
[5/24] Train loss=0.1577705591917038
[10/24] Train loss=0.1515919268131256
[15/24] Train loss=0.1674339324235916
[20/24] Train loss=0.163343608379364
Test set avg_accuracy=90.51% avg_sensitivity=77.35%, avg_specificity=94.32% avg_auc=93.27%
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.167763 Test loss=0.271185 Current lr=[1.2893376715395412e-05]

[0/24] Train loss=0.17291559278964996
[5/24] Train loss=0.1621268391609192
[10/24] Train loss=0.15156036615371704
[15/24] Train loss=0.16340641677379608
[20/24] Train loss=0.166216641664505
Test set avg_accuracy=90.57% avg_sensitivity=77.40%, avg_specificity=94.39% avg_auc=93.30%
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.168054 Test loss=0.272249 Current lr=[1.1134703273427479e-05]

[0/24] Train loss=0.17439591884613037
[5/24] Train loss=0.16361428797245026
[10/24] Train loss=0.15118488669395447
[15/24] Train loss=0.16183651983737946
[20/24] Train loss=0.16410954296588898
Test set avg_accuracy=90.42% avg_sensitivity=76.30%, avg_specificity=94.51% avg_auc=93.20%
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.167205 Test loss=0.272289 Current lr=[9.500333616053913e-06]

[0/24] Train loss=0.16972126066684723
[5/24] Train loss=0.15827828645706177
[10/24] Train loss=0.14907021820545197
[15/24] Train loss=0.16305670142173767
[20/24] Train loss=0.1646813601255417
Test set avg_accuracy=90.47% avg_sensitivity=77.11%, avg_specificity=94.34% avg_auc=93.24%
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.166895 Test loss=0.273290 Current lr=[7.991730725465605e-06]

[0/24] Train loss=0.16922013461589813
[5/24] Train loss=0.15755736827850342
[10/24] Train loss=0.14753155410289764
[15/24] Train loss=0.16145655512809753
[20/24] Train loss=0.1645302176475525
Test set avg_accuracy=90.44% avg_sensitivity=77.11%, avg_specificity=94.31% avg_auc=93.27%
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.166334 Test loss=0.272622 Current lr=[6.610245005564217e-06]

[0/24] Train loss=0.17035207152366638
[5/24] Train loss=0.15945826470851898
[10/24] Train loss=0.1499062180519104
[15/24] Train loss=0.16206900775432587
[20/24] Train loss=0.1657043844461441
Test set avg_accuracy=90.46% avg_sensitivity=77.06%, avg_specificity=94.34% avg_auc=93.28%
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.166174 Test loss=0.271977 Current lr=[5.3571130731678635e-06]

[0/24] Train loss=0.1726650893688202
[5/24] Train loss=0.1584906280040741
[10/24] Train loss=0.15120379626750946
[15/24] Train loss=0.1636647880077362
[20/24] Train loss=0.15970613062381744
Test set avg_accuracy=90.43% avg_sensitivity=77.11%, avg_specificity=94.29% avg_auc=93.32%
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.165700 Test loss=0.271277 Current lr=[4.233456651071398e-06]

[0/24] Train loss=0.16906218230724335
[5/24] Train loss=0.1558683067560196
[10/24] Train loss=0.15025107562541962
[15/24] Train loss=0.16268615424633026
[20/24] Train loss=0.16328611969947815
Test set avg_accuracy=90.42% avg_sensitivity=76.77%, avg_specificity=94.37% avg_auc=93.26%
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.164747 Test loss=0.270958 Current lr=[3.240281563952784e-06]

[0/24] Train loss=0.16520510613918304
[5/24] Train loss=0.1592191904783249
[10/24] Train loss=0.14923159778118134
[15/24] Train loss=0.1630522757768631
[20/24] Train loss=0.15923739969730377
Test set avg_accuracy=90.40% avg_sensitivity=76.77%, avg_specificity=94.36% avg_auc=93.27%
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.165196 Test loss=0.271415 Current lr=[2.3784768380236557e-06]

[0/24] Train loss=0.16881929337978363
[5/24] Train loss=0.1582764983177185
[10/24] Train loss=0.14846985042095184
[15/24] Train loss=0.15895061194896698
[20/24] Train loss=0.16122983396053314
Test set avg_accuracy=90.39% avg_sensitivity=76.88%, avg_specificity=94.31% avg_auc=93.22%
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.165375 Test loss=0.272470 Current lr=[1.6488139052304935e-06]

[0/24] Train loss=0.16489793360233307
[5/24] Train loss=0.1560579389333725
[10/24] Train loss=0.14846625924110413
[15/24] Train loss=0.16044586896896362
[20/24] Train loss=0.16000567376613617
Test set avg_accuracy=90.35% avg_sensitivity=76.77%, avg_specificity=94.29% avg_auc=93.24%
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.165193 Test loss=0.272118 Current lr=[1.051945912718594e-06]

[0/24] Train loss=0.16921107470989227
[5/24] Train loss=0.1574978530406952
[10/24] Train loss=0.15154963731765747
[15/24] Train loss=0.16261713206768036
[20/24] Train loss=0.16378183662891388
Test set avg_accuracy=90.39% avg_sensitivity=76.88%, avg_specificity=94.31% avg_auc=93.23%
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.165375 Test loss=0.272034 Current lr=[5.884071381769022e-07]

[0/24] Train loss=0.16842494904994965
[5/24] Train loss=0.15552780032157898
[10/24] Train loss=0.15101447701454163
[15/24] Train loss=0.15995080769062042
[20/24] Train loss=0.15858833491802216
Test set avg_accuracy=90.39% avg_sensitivity=76.71%, avg_specificity=94.36% avg_auc=93.22%
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.164629 Test loss=0.271910 Current lr=[2.586125115870377e-07]

[0/24] Train loss=0.16792260110378265
[5/24] Train loss=0.15828914940357208
[10/24] Train loss=0.15163227915763855
[15/24] Train loss=0.15863865613937378
[20/24] Train loss=0.1619870960712433
Test set avg_accuracy=90.39% avg_sensitivity=76.77%, avg_specificity=94.34% avg_auc=93.22%
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.164558 Test loss=0.271926 Current lr=[6.285724380488484e-08]

[0/24] Train loss=0.17007894814014435
[5/24] Train loss=0.15895052254199982
[10/24] Train loss=0.1476275473833084
[15/24] Train loss=0.15892745554447174
[20/24] Train loss=0.16190896928310394
Test set avg_accuracy=90.40% avg_sensitivity=76.77%, avg_specificity=94.36% avg_auc=93.23%
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.165133 Test loss=0.271802 Current lr=[1.3165623068326024e-09]

Fold[10] Result: acc=89.62% sen=83.37%, spe=91.43%, auc=93.80%!
Fold[10] Avg_overlap=0.67%(0.24349247703194496)
Final Avg Result: avg_acc=88.05%(1.1647513678631332) avg_sen=85.50% (1.54817174431925) avg_spe=88.91% (1.5996673794663032) avg_auc=94.04% (0.8153127854210273) avg_overlap=0.68% (0.009248402152496964)
