/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/23] Train loss=0.681383490562439
[5/23] Train loss=0.6390948295593262
[10/23] Train loss=0.560303807258606
[15/23] Train loss=0.5580517053604126
[20/23] Train loss=0.5330264568328857
Test set avg_accuracy=74.74% avg_sensitivity=0.61%, avg_specificity=99.83% avg_auc=0.5725
Best model saved!! Metric=-93.56130916521829!!
Fold[1] Epoch: 1 [1/100 (1%)] Train loss=0.574183 Test loss=0.617579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4091198146343231
[5/23] Train loss=0.6068529486656189
[10/23] Train loss=0.5441874861717224
[15/23] Train loss=0.5369740724563599
[20/23] Train loss=0.5046179890632629
Test set avg_accuracy=74.32% avg_sensitivity=3.13%, avg_specificity=98.42% avg_auc=0.6311
Best model saved!! Metric=-87.01571774326007!!
Fold[1] Epoch: 2 [2/100 (2%)] Train loss=0.539867 Test loss=0.629883 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.391560435295105
[5/23] Train loss=0.5820818543434143
[10/23] Train loss=0.51137775182724
[15/23] Train loss=0.5175901055335999
[20/23] Train loss=0.46417245268821716
Test set avg_accuracy=75.33% avg_sensitivity=12.53%, avg_specificity=96.58% avg_auc=0.6577
Best model saved!! Metric=-75.78663345958151!!
Fold[1] Epoch: 3 [3/100 (3%)] Train loss=0.515130 Test loss=0.619425 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38464412093162537
[5/23] Train loss=0.53510981798172
[10/23] Train loss=0.47502925992012024
[15/23] Train loss=0.49289679527282715
[20/23] Train loss=0.4217764437198639
Test set avg_accuracy=75.95% avg_sensitivity=19.81%, avg_specificity=94.95% avg_auc=0.7084
Best model saved!! Metric=-64.45868604438978!!
Fold[1] Epoch: 4 [4/100 (4%)] Train loss=0.484948 Test loss=0.621488 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3833741247653961
[5/23] Train loss=0.4909251630306244
[10/23] Train loss=0.44227370619773865
[15/23] Train loss=0.49831774830818176
[20/23] Train loss=0.40742751955986023
Test set avg_accuracy=76.47% avg_sensitivity=25.43%, avg_specificity=93.75% avg_auc=0.7422
Best model saved!! Metric=-56.13624223868946!!
Fold[1] Epoch: 5 [5/100 (5%)] Train loss=0.464346 Test loss=0.599066 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3997425138950348
[5/23] Train loss=0.46871688961982727
[10/23] Train loss=0.4288422167301178
[15/23] Train loss=0.49450933933258057
[20/23] Train loss=0.39835289120674133
Test set avg_accuracy=77.26% avg_sensitivity=30.59%, avg_specificity=93.06% avg_auc=0.7586
Best model saved!! Metric=-49.22632870537321!!
Fold[1] Epoch: 6 [6/100 (6%)] Train loss=0.448425 Test loss=0.574282 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3945251405239105
[5/23] Train loss=0.4565109610557556
[10/23] Train loss=0.43277648091316223
[15/23] Train loss=0.47713595628738403
[20/23] Train loss=0.3899058401584625
Test set avg_accuracy=77.81% avg_sensitivity=33.40%, avg_specificity=92.84% avg_auc=0.7747
Best model saved!! Metric=-44.479973439507134!!
Fold[1] Epoch: 7 [7/100 (7%)] Train loss=0.439460 Test loss=0.542337 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3865669369697571
[5/23] Train loss=0.4541928470134735
[10/23] Train loss=0.41438332200050354
[15/23] Train loss=0.484652578830719
[20/23] Train loss=0.3836040198802948
Test set avg_accuracy=78.00% avg_sensitivity=34.58%, avg_specificity=92.70% avg_auc=0.7851
Best model saved!! Metric=-42.20729524120553!!
Fold[1] Epoch: 8 [8/100 (8%)] Train loss=0.433269 Test loss=0.540234 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37273505330085754
[5/23] Train loss=0.4551144242286682
[10/23] Train loss=0.42018237709999084
[15/23] Train loss=0.4733988344669342
[20/23] Train loss=0.38032108545303345
Test set avg_accuracy=77.97% avg_sensitivity=34.38%, avg_specificity=92.73% avg_auc=0.7827
Fold[1] Epoch: 9 [9/100 (9%)] Train loss=0.431068 Test loss=0.547770 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3607621192932129
[5/23] Train loss=0.44795840978622437
[10/23] Train loss=0.46415865421295166
[15/23] Train loss=0.43784284591674805
[20/23] Train loss=0.3742487132549286
Test set avg_accuracy=77.58% avg_sensitivity=31.49%, avg_specificity=93.18% avg_auc=0.7715
Fold[1] Epoch: 10 [10/100 (10%)] Train loss=0.433748 Test loss=0.580406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34480321407318115
[5/23] Train loss=0.44563281536102295
[10/23] Train loss=0.4002329111099243
[15/23] Train loss=0.4189617931842804
[20/23] Train loss=0.37383654713630676
Test set avg_accuracy=78.35% avg_sensitivity=36.37%, avg_specificity=92.56% avg_auc=0.7992
Best model saved!! Metric=-38.78990927869229!!
Fold[1] Epoch: 11 [11/100 (11%)] Train loss=0.426978 Test loss=0.515766 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3597314655780792
[5/23] Train loss=0.43589290976524353
[10/23] Train loss=0.38999906182289124
[15/23] Train loss=0.41805028915405273
[20/23] Train loss=0.3683004379272461
Test set avg_accuracy=78.88% avg_sensitivity=40.15%, avg_specificity=91.99% avg_auc=0.8101
Best model saved!! Metric=-33.97358670685672!!
Fold[1] Epoch: 12 [12/100 (12%)] Train loss=0.415114 Test loss=0.508204 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3589438498020172
[5/23] Train loss=0.4291382431983948
[10/23] Train loss=0.38964974880218506
[15/23] Train loss=0.4173620343208313
[20/23] Train loss=0.36241453886032104
Test set avg_accuracy=79.10% avg_sensitivity=40.93%, avg_specificity=92.03% avg_auc=0.8089
Best model saved!! Metric=-33.04885694493183!!
Fold[1] Epoch: 13 [13/100 (13%)] Train loss=0.411779 Test loss=0.512152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34164801239967346
[5/23] Train loss=0.4314601421356201
[10/23] Train loss=0.41859862208366394
[15/23] Train loss=0.4115500748157501
[20/23] Train loss=0.3582979738712311
Test set avg_accuracy=79.06% avg_sensitivity=40.03%, avg_specificity=92.27% avg_auc=0.8015
Fold[1] Epoch: 14 [14/100 (14%)] Train loss=0.412627 Test loss=0.522259 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33811837434768677
[5/23] Train loss=0.4276941120624542
[10/23] Train loss=0.3983306288719177
[15/23] Train loss=0.40843138098716736
[20/23] Train loss=0.3634815514087677
Test set avg_accuracy=78.85% avg_sensitivity=38.77%, avg_specificity=92.41% avg_auc=0.8037
Fold[1] Epoch: 15 [15/100 (15%)] Train loss=0.412156 Test loss=0.518878 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3328631520271301
[5/23] Train loss=0.43309444189071655
[10/23] Train loss=0.38733354210853577
[15/23] Train loss=0.4045921564102173
[20/23] Train loss=0.3650750517845154
Test set avg_accuracy=79.10% avg_sensitivity=42.03%, avg_specificity=91.66% avg_auc=0.8253
Best model saved!! Metric=-30.686537087829308!!
Fold[1] Epoch: 16 [16/100 (16%)] Train loss=0.405590 Test loss=0.482113 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34279000759124756
[5/23] Train loss=0.426885724067688
[10/23] Train loss=0.395011842250824
[15/23] Train loss=0.4091854393482208
[20/23] Train loss=0.3603847920894623
Test set avg_accuracy=79.45% avg_sensitivity=43.04%, avg_specificity=91.78% avg_auc=0.8258
Best model saved!! Metric=-29.139821012300974!!
Fold[1] Epoch: 17 [17/100 (17%)] Train loss=0.402165 Test loss=0.491848 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3300761580467224
[5/23] Train loss=0.42501601576805115
[10/23] Train loss=0.4073740541934967
[15/23] Train loss=0.38982588052749634
[20/23] Train loss=0.3562506437301636
Test set avg_accuracy=79.30% avg_sensitivity=40.93%, avg_specificity=92.29% avg_auc=0.8248
Fold[1] Epoch: 18 [18/100 (18%)] Train loss=0.402489 Test loss=0.517128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31652727723121643
[5/23] Train loss=0.42961812019348145
[10/23] Train loss=0.3743310868740082
[15/23] Train loss=0.389218270778656
[20/23] Train loss=0.34175920486450195
Test set avg_accuracy=79.56% avg_sensitivity=44.67%, avg_specificity=91.37% avg_auc=0.8298
Best model saved!! Metric=-27.42129293299137!!
Fold[1] Epoch: 19 [19/100 (19%)] Train loss=0.396217 Test loss=0.484764 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3303675651550293
[5/23] Train loss=0.417122483253479
[10/23] Train loss=0.3615761697292328
[15/23] Train loss=0.3834535777568817
[20/23] Train loss=0.343645840883255
Test set avg_accuracy=79.98% avg_sensitivity=47.44%, avg_specificity=90.99% avg_auc=0.8321
Best model saved!! Metric=-24.378184727229762!!
Fold[1] Epoch: 20 [20/100 (20%)] Train loss=0.392038 Test loss=0.467051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32382863759994507
[5/23] Train loss=0.41512542963027954
[10/23] Train loss=0.365255206823349
[15/23] Train loss=0.381399005651474
[20/23] Train loss=0.3342832624912262
Test set avg_accuracy=80.06% avg_sensitivity=46.99%, avg_specificity=91.26% avg_auc=0.8349
Best model saved!! Metric=-24.204546846680632!!
Fold[1] Epoch: 21 [21/100 (21%)] Train loss=0.387010 Test loss=0.465365 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30841830372810364
[5/23] Train loss=0.4164831042289734
[10/23] Train loss=0.3787572383880615
[15/23] Train loss=0.3743049204349518
[20/23] Train loss=0.33730047941207886
Test set avg_accuracy=79.87% avg_sensitivity=45.20%, avg_specificity=91.60% avg_auc=0.8369
Fold[1] Epoch: 22 [22/100 (22%)] Train loss=0.387486 Test loss=0.472504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3042307496070862
[5/23] Train loss=0.41110461950302124
[10/23] Train loss=0.36506974697113037
[15/23] Train loss=0.3769703507423401
[20/23] Train loss=0.3309183418750763
Test set avg_accuracy=79.61% avg_sensitivity=44.02%, avg_specificity=91.66% avg_auc=0.8334
Fold[1] Epoch: 23 [23/100 (23%)] Train loss=0.385061 Test loss=0.484636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30730220675468445
[5/23] Train loss=0.41155827045440674
[10/23] Train loss=0.3459155559539795
[15/23] Train loss=0.3623928427696228
[20/23] Train loss=0.32998043298721313
Test set avg_accuracy=80.17% avg_sensitivity=48.70%, avg_specificity=90.83% avg_auc=0.8396
Best model saved!! Metric=-22.33765784145507!!
Fold[1] Epoch: 24 [24/100 (24%)] Train loss=0.378961 Test loss=0.458985 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31411996483802795
[5/23] Train loss=0.4056386351585388
[10/23] Train loss=0.34673765301704407
[15/23] Train loss=0.35684725642204285
[20/23] Train loss=0.32108452916145325
Test set avg_accuracy=80.75% avg_sensitivity=51.79%, avg_specificity=90.55% avg_auc=0.8438
Best model saved!! Metric=-18.525489014484066!!
Fold[1] Epoch: 25 [25/100 (25%)] Train loss=0.374253 Test loss=0.445298 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2934284508228302
[5/23] Train loss=0.4060121476650238
[10/23] Train loss=0.37616896629333496
[15/23] Train loss=0.3624269664287567
[20/23] Train loss=0.320002943277359
Test set avg_accuracy=80.33% avg_sensitivity=46.54%, avg_specificity=91.77% avg_auc=0.8413
Fold[1] Epoch: 26 [26/100 (26%)] Train loss=0.376791 Test loss=0.471289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2866373360157013
[5/23] Train loss=0.40751227736473083
[10/23] Train loss=0.3386741876602173
[15/23] Train loss=0.3616398274898529
[20/23] Train loss=0.3247937560081482
Test set avg_accuracy=80.00% avg_sensitivity=46.87%, avg_specificity=91.21% avg_auc=0.8354
Fold[1] Epoch: 27 [27/100 (27%)] Train loss=0.373823 Test loss=0.489008 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3097575306892395
[5/23] Train loss=0.39873263239860535
[10/23] Train loss=0.33457571268081665
[15/23] Train loss=0.36021363735198975
[20/23] Train loss=0.3197568655014038
Test set avg_accuracy=80.46% avg_sensitivity=51.55%, avg_specificity=90.25% avg_auc=0.8440
Fold[1] Epoch: 28 [28/100 (28%)] Train loss=0.367092 Test loss=0.441893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30757588148117065
[5/23] Train loss=0.400593101978302
[10/23] Train loss=0.33504804968833923
[15/23] Train loss=0.3583972752094269
[20/23] Train loss=0.3085505962371826
Test set avg_accuracy=80.96% avg_sensitivity=53.66%, avg_specificity=90.20% avg_auc=0.8480
Best model saved!! Metric=-16.389060598302486!!
Fold[1] Epoch: 29 [29/100 (29%)] Train loss=0.365724 Test loss=0.436418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2841112017631531
[5/23] Train loss=0.4048561453819275
[10/23] Train loss=0.33825448155403137
[15/23] Train loss=0.3482757806777954
[20/23] Train loss=0.31008851528167725
Test set avg_accuracy=80.41% avg_sensitivity=48.09%, avg_specificity=91.35% avg_auc=0.8446
Fold[1] Epoch: 30 [30/100 (30%)] Train loss=0.365036 Test loss=0.468853 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27479103207588196
[5/23] Train loss=0.4028698205947876
[10/23] Train loss=0.32291796803474426
[15/23] Train loss=0.34361591935157776
[20/23] Train loss=0.3035869300365448
Test set avg_accuracy=80.58% avg_sensitivity=51.06%, avg_specificity=90.57% avg_auc=0.8437
Fold[1] Epoch: 31 [31/100 (31%)] Train loss=0.359546 Test loss=0.460454 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28152647614479065
[5/23] Train loss=0.39546337723731995
[10/23] Train loss=0.32592442631721497
[15/23] Train loss=0.3453933596611023
[20/23] Train loss=0.3026820421218872
Test set avg_accuracy=80.71% avg_sensitivity=53.17%, avg_specificity=90.03% avg_auc=0.8465
Fold[1] Epoch: 32 [32/100 (32%)] Train loss=0.354976 Test loss=0.444797 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27788153290748596
[5/23] Train loss=0.3911643326282501
[10/23] Train loss=0.3194863796234131
[15/23] Train loss=0.3336118459701538
[20/23] Train loss=0.2968795895576477
Test set avg_accuracy=80.80% avg_sensitivity=52.77%, avg_specificity=90.29% avg_auc=0.8486
Fold[1] Epoch: 33 [33/100 (33%)] Train loss=0.354719 Test loss=0.450091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2623308598995209
[5/23] Train loss=0.39119425415992737
[10/23] Train loss=0.32283902168273926
[15/23] Train loss=0.33200666308403015
[20/23] Train loss=0.3064028024673462
Test set avg_accuracy=80.44% avg_sensitivity=49.23%, avg_specificity=91.01% avg_auc=0.8434
Fold[1] Epoch: 34 [34/100 (34%)] Train loss=0.351828 Test loss=0.466648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2654944956302643
[5/23] Train loss=0.3919926583766937
[10/23] Train loss=0.31634408235549927
[15/23] Train loss=0.3258480429649353
[20/23] Train loss=0.2974342405796051
Test set avg_accuracy=80.65% avg_sensitivity=53.30%, avg_specificity=89.91% avg_auc=0.8472
Fold[1] Epoch: 35 [35/100 (35%)] Train loss=0.350465 Test loss=0.444840 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26698246598243713
[5/23] Train loss=0.391230046749115
[10/23] Train loss=0.3161745071411133
[15/23] Train loss=0.32304060459136963
[20/23] Train loss=0.29899537563323975
Test set avg_accuracy=80.84% avg_sensitivity=53.21%, avg_specificity=90.20% avg_auc=0.8485
Fold[1] Epoch: 36 [36/100 (36%)] Train loss=0.345195 Test loss=0.446233 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26875028014183044
[5/23] Train loss=0.3862765431404114
[10/23] Train loss=0.3212661147117615
[15/23] Train loss=0.32128429412841797
[20/23] Train loss=0.2877933084964752
Test set avg_accuracy=80.85% avg_sensitivity=50.20%, avg_specificity=91.23% avg_auc=0.8469
Fold[1] Epoch: 37 [37/100 (37%)] Train loss=0.346398 Test loss=0.457525 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24773016571998596
[5/23] Train loss=0.3820243775844574
[10/23] Train loss=0.31137916445732117
[15/23] Train loss=0.32518982887268066
[20/23] Train loss=0.28529053926467896
Test set avg_accuracy=80.31% avg_sensitivity=45.89%, avg_specificity=91.96% avg_auc=0.8421
Fold[1] Epoch: 38 [38/100 (38%)] Train loss=0.345577 Test loss=0.465554 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26062285900115967
[5/23] Train loss=0.38509827852249146
[10/23] Train loss=0.31413647532463074
[15/23] Train loss=0.3232106864452362
[20/23] Train loss=0.29334786534309387
Test set avg_accuracy=80.85% avg_sensitivity=56.47%, avg_specificity=89.11% avg_auc=0.8502
Best model saved!! Metric=-14.547041661242993!!
Fold[1] Epoch: 39 [39/100 (39%)] Train loss=0.340736 Test loss=0.440918 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2673851251602173
[5/23] Train loss=0.3799099028110504
[10/23] Train loss=0.30740728974342346
[15/23] Train loss=0.31759026646614075
[20/23] Train loss=0.28939780592918396
Test set avg_accuracy=81.06% avg_sensitivity=53.82%, avg_specificity=90.28% avg_auc=0.8512
Fold[1] Epoch: 40 [40/100 (40%)] Train loss=0.338367 Test loss=0.441080 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24880576133728027
[5/23] Train loss=0.3782271444797516
[10/23] Train loss=0.29642441868782043
[15/23] Train loss=0.3202573359012604
[20/23] Train loss=0.2886452376842499
Test set avg_accuracy=81.06% avg_sensitivity=53.46%, avg_specificity=90.40% avg_auc=0.8503
Fold[1] Epoch: 41 [41/100 (41%)] Train loss=0.334455 Test loss=0.450598 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23844106495380402
[5/23] Train loss=0.37154242396354675
[10/23] Train loss=0.30025437474250793
[15/23] Train loss=0.3038436472415924
[20/23] Train loss=0.2854630947113037
Test set avg_accuracy=80.74% avg_sensitivity=48.86%, avg_specificity=91.53% avg_auc=0.8446
Fold[1] Epoch: 42 [42/100 (42%)] Train loss=0.332104 Test loss=0.465875 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23852355778217316
[5/23] Train loss=0.3719113767147064
[10/23] Train loss=0.30123433470726013
[15/23] Train loss=0.30364131927490234
[20/23] Train loss=0.28742796182632446
Test set avg_accuracy=80.40% avg_sensitivity=47.93%, avg_specificity=91.39% avg_auc=0.8447
Fold[1] Epoch: 43 [43/100 (43%)] Train loss=0.332406 Test loss=0.469885 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2537077069282532
[5/23] Train loss=0.3822271525859833
[10/23] Train loss=0.29156941175460815
[15/23] Train loss=0.3109910488128662
[20/23] Train loss=0.2812572121620178
Test set avg_accuracy=80.63% avg_sensitivity=56.10%, avg_specificity=88.93% avg_auc=0.8468
Fold[1] Epoch: 44 [44/100 (44%)] Train loss=0.327354 Test loss=0.438854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24107499420642853
[5/23] Train loss=0.3640368580818176
[10/23] Train loss=0.2956298589706421
[15/23] Train loss=0.305966854095459
[20/23] Train loss=0.2744596004486084
Test set avg_accuracy=80.99% avg_sensitivity=55.86%, avg_specificity=89.49% avg_auc=0.8510
Fold[1] Epoch: 45 [45/100 (45%)] Train loss=0.323577 Test loss=0.452230 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2396967113018036
[5/23] Train loss=0.3596191108226776
[10/23] Train loss=0.2840178608894348
[15/23] Train loss=0.3008284270763397
[20/23] Train loss=0.2750740349292755
Test set avg_accuracy=81.15% avg_sensitivity=52.85%, avg_specificity=90.73% avg_auc=0.8506
Fold[1] Epoch: 46 [46/100 (46%)] Train loss=0.320806 Test loss=0.452934 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22707872092723846
[5/23] Train loss=0.3612244725227356
[10/23] Train loss=0.284664124250412
[15/23] Train loss=0.2921432852745056
[20/23] Train loss=0.2670823037624359
Test set avg_accuracy=80.79% avg_sensitivity=49.23%, avg_specificity=91.48% avg_auc=0.8467
Fold[1] Epoch: 47 [47/100 (47%)] Train loss=0.320368 Test loss=0.459551 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22295565903186798
[5/23] Train loss=0.3643595278263092
[10/23] Train loss=0.2799482047557831
[15/23] Train loss=0.30398958921432495
[20/23] Train loss=0.27158284187316895
Test set avg_accuracy=80.43% avg_sensitivity=45.93%, avg_specificity=92.11% avg_auc=0.8411
Fold[1] Epoch: 48 [48/100 (48%)] Train loss=0.319654 Test loss=0.456307 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22518402338027954
[5/23] Train loss=0.3631643056869507
[10/23] Train loss=0.27961668372154236
[15/23] Train loss=0.282877117395401
[20/23] Train loss=0.27355554699897766
Test set avg_accuracy=80.92% avg_sensitivity=52.97%, avg_specificity=90.37% avg_auc=0.8462
Fold[1] Epoch: 49 [49/100 (49%)] Train loss=0.316121 Test loss=0.454855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22884191572666168
[5/23] Train loss=0.35406365990638733
[10/23] Train loss=0.28387150168418884
[15/23] Train loss=0.29220086336135864
[20/23] Train loss=0.2647964358329773
Test set avg_accuracy=81.01% avg_sensitivity=53.78%, avg_specificity=90.22% avg_auc=0.8478
Fold[1] Epoch: 50 [50/100 (50%)] Train loss=0.311012 Test loss=0.454831 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22290286421775818
[5/23] Train loss=0.3599824011325836
[10/23] Train loss=0.27237191796302795
[15/23] Train loss=0.2858293652534485
[20/23] Train loss=0.264137327671051
Test set avg_accuracy=81.04% avg_sensitivity=54.43%, avg_specificity=90.04% avg_auc=0.8491
Fold[1] Epoch: 51 [51/100 (51%)] Train loss=0.310250 Test loss=0.454711 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22585448622703552
[5/23] Train loss=0.351043701171875
[10/23] Train loss=0.2826242446899414
[15/23] Train loss=0.2889353632926941
[20/23] Train loss=0.26332101225852966
Test set avg_accuracy=80.97% avg_sensitivity=51.63%, avg_specificity=90.90% avg_auc=0.8471
Fold[1] Epoch: 52 [52/100 (52%)] Train loss=0.307212 Test loss=0.460689 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21840418875217438
[5/23] Train loss=0.34645530581474304
[10/23] Train loss=0.27278876304626465
[15/23] Train loss=0.28987154364585876
[20/23] Train loss=0.25769364833831787
Test set avg_accuracy=80.99% avg_sensitivity=50.12%, avg_specificity=91.43% avg_auc=0.8465
Fold[1] Epoch: 53 [53/100 (53%)] Train loss=0.306689 Test loss=0.461730 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21543942391872406
[5/23] Train loss=0.3509887456893921
[10/23] Train loss=0.26874661445617676
[15/23] Train loss=0.28483426570892334
[20/23] Train loss=0.25841042399406433
Test set avg_accuracy=80.83% avg_sensitivity=49.67%, avg_specificity=91.38% avg_auc=0.8442
Fold[1] Epoch: 54 [54/100 (54%)] Train loss=0.302117 Test loss=0.465701 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20923902094364166
[5/23] Train loss=0.3416663110256195
[10/23] Train loss=0.2683331370353699
[15/23] Train loss=0.26851537823677063
[20/23] Train loss=0.25762632489204407
Test set avg_accuracy=80.63% avg_sensitivity=48.41%, avg_specificity=91.53% avg_auc=0.8421
Fold[1] Epoch: 55 [55/100 (55%)] Train loss=0.300277 Test loss=0.478632 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2118924856185913
[5/23] Train loss=0.3485356271266937
[10/23] Train loss=0.26351091265678406
[15/23] Train loss=0.27396368980407715
[20/23] Train loss=0.2521679997444153
Test set avg_accuracy=80.94% avg_sensitivity=50.41%, avg_specificity=91.27% avg_auc=0.8415
Fold[1] Epoch: 56 [56/100 (56%)] Train loss=0.299948 Test loss=0.473914 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2091618776321411
[5/23] Train loss=0.3502332270145416
[10/23] Train loss=0.2678785026073456
[15/23] Train loss=0.2588754892349243
[20/23] Train loss=0.2588323652744293
Test set avg_accuracy=80.69% avg_sensitivity=52.44%, avg_specificity=90.25% avg_auc=0.8382
Fold[1] Epoch: 57 [57/100 (57%)] Train loss=0.296844 Test loss=0.466645 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21177348494529724
[5/23] Train loss=0.34421640634536743
[10/23] Train loss=0.26172083616256714
[15/23] Train loss=0.27079787850379944
[20/23] Train loss=0.25461921095848083
Test set avg_accuracy=80.79% avg_sensitivity=51.59%, avg_specificity=90.68% avg_auc=0.8379
Fold[1] Epoch: 58 [58/100 (58%)] Train loss=0.294290 Test loss=0.471281 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21157123148441315
[5/23] Train loss=0.34702008962631226
[10/23] Train loss=0.26067984104156494
[15/23] Train loss=0.26898109912872314
[20/23] Train loss=0.24663721024990082
Test set avg_accuracy=80.72% avg_sensitivity=57.85%, avg_specificity=88.46% avg_auc=0.8461
Best model saved!! Metric=-14.353761233843054!!
Fold[1] Epoch: 59 [59/100 (59%)] Train loss=0.292629 Test loss=0.476707 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2070833146572113
[5/23] Train loss=0.3308124244213104
[10/23] Train loss=0.25824594497680664
[15/23] Train loss=0.2657547891139984
[20/23] Train loss=0.24082128703594208
Test set avg_accuracy=81.22% avg_sensitivity=54.84%, avg_specificity=90.15% avg_auc=0.8460
Fold[1] Epoch: 60 [60/100 (60%)] Train loss=0.289259 Test loss=0.470945 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2039046585559845
[5/23] Train loss=0.33539631962776184
[10/23] Train loss=0.26096847653388977
[15/23] Train loss=0.26147741079330444
[20/23] Train loss=0.24436433613300323
Test set avg_accuracy=80.80% avg_sensitivity=51.95%, avg_specificity=90.57% avg_auc=0.8408
Fold[1] Epoch: 61 [61/100 (61%)] Train loss=0.286733 Test loss=0.479047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.194121316075325
[5/23] Train loss=0.3243290185928345
[10/23] Train loss=0.2560228705406189
[15/23] Train loss=0.24852785468101501
[20/23] Train loss=0.24564068019390106
Test set avg_accuracy=80.64% avg_sensitivity=46.95%, avg_specificity=92.04% avg_auc=0.8400
Fold[1] Epoch: 62 [62/100 (62%)] Train loss=0.285181 Test loss=0.485703 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19684304296970367
[5/23] Train loss=0.33056262135505676
[10/23] Train loss=0.2605859339237213
[15/23] Train loss=0.2593114674091339
[20/23] Train loss=0.24125833809375763
Test set avg_accuracy=80.81% avg_sensitivity=49.63%, avg_specificity=91.37% avg_auc=0.8406
Fold[1] Epoch: 63 [63/100 (63%)] Train loss=0.283286 Test loss=0.475303 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18998150527477264
[5/23] Train loss=0.3243503272533417
[10/23] Train loss=0.2530086934566498
[15/23] Train loss=0.2393282800912857
[20/23] Train loss=0.2399880290031433
Test set avg_accuracy=81.11% avg_sensitivity=52.69%, avg_specificity=90.73% avg_auc=0.8427
Fold[1] Epoch: 64 [64/100 (64%)] Train loss=0.276653 Test loss=0.482020 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19046476483345032
[5/23] Train loss=0.3292433023452759
[10/23] Train loss=0.24819256365299225
[15/23] Train loss=0.24168922007083893
[20/23] Train loss=0.24070945382118225
Test set avg_accuracy=80.91% avg_sensitivity=54.56%, avg_specificity=89.82% avg_auc=0.8388
Fold[1] Epoch: 65 [65/100 (65%)] Train loss=0.274463 Test loss=0.483579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19002296030521393
[5/23] Train loss=0.3247894048690796
[10/23] Train loss=0.2478540986776352
[15/23] Train loss=0.25266480445861816
[20/23] Train loss=0.23296575248241425
Test set avg_accuracy=81.18% avg_sensitivity=55.86%, avg_specificity=89.75% avg_auc=0.8423
Fold[1] Epoch: 66 [66/100 (66%)] Train loss=0.273459 Test loss=0.485709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1912655383348465
[5/23] Train loss=0.3228313624858856
[10/23] Train loss=0.25238826870918274
[15/23] Train loss=0.23859953880310059
[20/23] Train loss=0.22615589201450348
Test set avg_accuracy=80.85% avg_sensitivity=54.23%, avg_specificity=89.87% avg_auc=0.8322
Fold[1] Epoch: 67 [67/100 (67%)] Train loss=0.270678 Test loss=0.479713 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18682220578193665
[5/23] Train loss=0.32951658964157104
[10/23] Train loss=0.23665203154087067
[15/23] Train loss=0.24496354162693024
[20/23] Train loss=0.2386467009782791
Test set avg_accuracy=80.95% avg_sensitivity=52.64%, avg_specificity=90.53% avg_auc=0.8414
Fold[1] Epoch: 68 [68/100 (68%)] Train loss=0.271736 Test loss=0.494862 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.182533860206604
[5/23] Train loss=0.3138267695903778
[10/23] Train loss=0.25727272033691406
[15/23] Train loss=0.2527003884315491
[20/23] Train loss=0.22965824604034424
Test set avg_accuracy=80.23% avg_sensitivity=43.61%, avg_specificity=92.62% avg_auc=0.8322
Fold[1] Epoch: 69 [69/100 (69%)] Train loss=0.276849 Test loss=0.514381 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17411580681800842
[5/23] Train loss=0.32859089970588684
[10/23] Train loss=0.25740429759025574
[15/23] Train loss=0.2380758672952652
[20/23] Train loss=0.22414886951446533
Test set avg_accuracy=80.59% avg_sensitivity=51.26%, avg_specificity=90.51% avg_auc=0.8382
Fold[1] Epoch: 70 [70/100 (70%)] Train loss=0.272484 Test loss=0.495108 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17923468351364136
[5/23] Train loss=0.3224504292011261
[10/23] Train loss=0.2393273413181305
[15/23] Train loss=0.23844727873802185
[20/23] Train loss=0.23062311112880707
Test set avg_accuracy=80.76% avg_sensitivity=55.04%, avg_specificity=89.47% avg_auc=0.8371
Fold[1] Epoch: 71 [71/100 (71%)] Train loss=0.266384 Test loss=0.499731 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18402282893657684
[5/23] Train loss=0.31874024868011475
[10/23] Train loss=0.2458856701850891
[15/23] Train loss=0.23055723309516907
[20/23] Train loss=0.23016571998596191
Test set avg_accuracy=80.98% avg_sensitivity=56.67%, avg_specificity=89.20% avg_auc=0.8381
Fold[1] Epoch: 72 [72/100 (72%)] Train loss=0.262381 Test loss=0.488082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17962971329689026
[5/23] Train loss=0.3123652935028076
[10/23] Train loss=0.24103692173957825
[15/23] Train loss=0.22719119489192963
[20/23] Train loss=0.2268388271331787
Test set avg_accuracy=80.69% avg_sensitivity=49.88%, avg_specificity=91.12% avg_auc=0.8376
Fold[1] Epoch: 73 [73/100 (73%)] Train loss=0.260919 Test loss=0.512384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17726150155067444
[5/23] Train loss=0.30811774730682373
[10/23] Train loss=0.2366470992565155
[15/23] Train loss=0.23823586106300354
[20/23] Train loss=0.22088681161403656
Test set avg_accuracy=80.68% avg_sensitivity=53.66%, avg_specificity=89.82% avg_auc=0.8355
Fold[1] Epoch: 74 [74/100 (74%)] Train loss=0.257633 Test loss=0.503811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17085222899913788
[5/23] Train loss=0.31502801179885864
[10/23] Train loss=0.23821304738521576
[15/23] Train loss=0.23865079879760742
[20/23] Train loss=0.21296891570091248
Test set avg_accuracy=80.92% avg_sensitivity=52.97%, avg_specificity=90.37% avg_auc=0.8353
Fold[1] Epoch: 75 [75/100 (75%)] Train loss=0.256090 Test loss=0.498505 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17094546556472778
[5/23] Train loss=0.32451483607292175
[10/23] Train loss=0.23558345437049866
[15/23] Train loss=0.23684625327587128
[20/23] Train loss=0.21846544742584229
Test set avg_accuracy=80.70% avg_sensitivity=52.40%, avg_specificity=90.28% avg_auc=0.8315
Fold[1] Epoch: 76 [76/100 (76%)] Train loss=0.261293 Test loss=0.504672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1715613603591919
[5/23] Train loss=0.30382007360458374
[10/23] Train loss=0.2527657747268677
[15/23] Train loss=0.23548340797424316
[20/23] Train loss=0.21418383717536926
Test set avg_accuracy=80.78% avg_sensitivity=48.70%, avg_specificity=91.64% avg_auc=0.8309
Fold[1] Epoch: 77 [77/100 (77%)] Train loss=0.257417 Test loss=0.506665 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16766250133514404
[5/23] Train loss=0.306482195854187
[10/23] Train loss=0.2316371649503708
[15/23] Train loss=0.2257123589515686
[20/23] Train loss=0.2223588079214096
Test set avg_accuracy=80.93% avg_sensitivity=51.83%, avg_specificity=90.77% avg_auc=0.8379
Fold[1] Epoch: 78 [78/100 (78%)] Train loss=0.253169 Test loss=0.517800 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1670738011598587
[5/23] Train loss=0.2956724762916565
[10/23] Train loss=0.23178909718990326
[15/23] Train loss=0.2095668911933899
[20/23] Train loss=0.21871384978294373
Test set avg_accuracy=80.91% avg_sensitivity=52.07%, avg_specificity=90.66% avg_auc=0.8370
Fold[1] Epoch: 79 [79/100 (79%)] Train loss=0.248778 Test loss=0.528414 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15893958508968353
[5/23] Train loss=0.2935009300708771
[10/23] Train loss=0.2330542504787445
[15/23] Train loss=0.21702644228935242
[20/23] Train loss=0.21163274347782135
Test set avg_accuracy=81.07% avg_sensitivity=51.87%, avg_specificity=90.95% avg_auc=0.8402
Fold[1] Epoch: 80 [80/100 (80%)] Train loss=0.247512 Test loss=0.517406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15906277298927307
[5/23] Train loss=0.3025090992450714
[10/23] Train loss=0.23393896222114563
[15/23] Train loss=0.21091532707214355
[20/23] Train loss=0.20993368327617645
Test set avg_accuracy=80.56% avg_sensitivity=51.79%, avg_specificity=90.29% avg_auc=0.8372
Fold[1] Epoch: 81 [81/100 (81%)] Train loss=0.245808 Test loss=0.521346 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1554415076971054
[5/23] Train loss=0.29262495040893555
[10/23] Train loss=0.2253805249929428
[15/23] Train loss=0.21991591155529022
[20/23] Train loss=0.21699002385139465
Test set avg_accuracy=80.88% avg_sensitivity=53.09%, avg_specificity=90.29% avg_auc=0.8243
Fold[1] Epoch: 82 [82/100 (82%)] Train loss=0.242488 Test loss=0.514922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15259873867034912
[5/23] Train loss=0.2870495617389679
[10/23] Train loss=0.21556022763252258
[15/23] Train loss=0.2086842805147171
[20/23] Train loss=0.2051883041858673
Test set avg_accuracy=80.80% avg_sensitivity=50.69%, avg_specificity=90.99% avg_auc=0.8236
Fold[1] Epoch: 83 [83/100 (83%)] Train loss=0.237563 Test loss=0.521855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1514134556055069
[5/23] Train loss=0.2821808457374573
[10/23] Train loss=0.22218245267868042
[15/23] Train loss=0.21469035744667053
[20/23] Train loss=0.20840011537075043
Test set avg_accuracy=81.00% avg_sensitivity=53.42%, avg_specificity=90.33% avg_auc=0.8245
Fold[1] Epoch: 84 [84/100 (84%)] Train loss=0.236862 Test loss=0.524015 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14434078335762024
[5/23] Train loss=0.2882833778858185
[10/23] Train loss=0.20792801678180695
[15/23] Train loss=0.2045859694480896
[20/23] Train loss=0.2062913328409195
Test set avg_accuracy=81.05% avg_sensitivity=52.64%, avg_specificity=90.66% avg_auc=0.8324
Fold[1] Epoch: 85 [85/100 (85%)] Train loss=0.232584 Test loss=0.528767 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14556795358657837
[5/23] Train loss=0.2750234007835388
[10/23] Train loss=0.22475162148475647
[15/23] Train loss=0.21059346199035645
[20/23] Train loss=0.18793851137161255
Test set avg_accuracy=80.90% avg_sensitivity=53.25%, avg_specificity=90.25% avg_auc=0.8287
Fold[1] Epoch: 86 [86/100 (86%)] Train loss=0.231157 Test loss=0.525591 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13872045278549194
[5/23] Train loss=0.291030615568161
[10/23] Train loss=0.21487721800804138
[15/23] Train loss=0.21338826417922974
[20/23] Train loss=0.20250430703163147
Test set avg_accuracy=80.91% avg_sensitivity=51.67%, avg_specificity=90.80% avg_auc=0.8193
Fold[1] Epoch: 87 [87/100 (87%)] Train loss=0.229660 Test loss=0.520096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15055599808692932
[5/23] Train loss=0.26914870738983154
[10/23] Train loss=0.21011720597743988
[15/23] Train loss=0.19736279547214508
[20/23] Train loss=0.19324146211147308
Test set avg_accuracy=80.84% avg_sensitivity=51.71%, avg_specificity=90.71% avg_auc=0.8309
Fold[1] Epoch: 88 [88/100 (88%)] Train loss=0.228496 Test loss=0.538289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1378268301486969
[5/23] Train loss=0.28038620948791504
[10/23] Train loss=0.22656908631324768
[15/23] Train loss=0.19444797933101654
[20/23] Train loss=0.1961187720298767
Test set avg_accuracy=81.03% avg_sensitivity=50.16%, avg_specificity=91.48% avg_auc=0.8315
Fold[1] Epoch: 89 [89/100 (89%)] Train loss=0.225420 Test loss=0.546669 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12897609174251556
[5/23] Train loss=0.28099995851516724
[10/23] Train loss=0.21308577060699463
[15/23] Train loss=0.1885092854499817
[20/23] Train loss=0.1956019103527069
Test set avg_accuracy=80.93% avg_sensitivity=51.55%, avg_specificity=90.87% avg_auc=0.8348
Fold[1] Epoch: 90 [90/100 (90%)] Train loss=0.224112 Test loss=0.532610 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.138534814119339
[5/23] Train loss=0.26969000697135925
[10/23] Train loss=0.22115720808506012
[15/23] Train loss=0.1947064846754074
[20/23] Train loss=0.19786152243614197
Test set avg_accuracy=80.64% avg_sensitivity=49.23%, avg_specificity=91.27% avg_auc=0.8217
Fold[1] Epoch: 91 [91/100 (91%)] Train loss=0.227454 Test loss=0.530842 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13532066345214844
[5/23] Train loss=0.2682375907897949
[10/23] Train loss=0.20249168574810028
[15/23] Train loss=0.19433040916919708
[20/23] Train loss=0.19452227652072906
Test set avg_accuracy=80.98% avg_sensitivity=52.56%, avg_specificity=90.59% avg_auc=0.8228
Fold[1] Epoch: 92 [92/100 (92%)] Train loss=0.221122 Test loss=0.539721 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13153062760829926
[5/23] Train loss=0.26339656114578247
[10/23] Train loss=0.19189226627349854
[15/23] Train loss=0.2028627246618271
[20/23] Train loss=0.18507090210914612
Test set avg_accuracy=80.94% avg_sensitivity=54.03%, avg_specificity=90.04% avg_auc=0.8256
Fold[1] Epoch: 93 [93/100 (93%)] Train loss=0.220478 Test loss=0.539788 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12936043739318848
[5/23] Train loss=0.27621084451675415
[10/23] Train loss=0.20438720285892487
[15/23] Train loss=0.17717722058296204
[20/23] Train loss=0.1924438178539276
Test set avg_accuracy=80.85% avg_sensitivity=55.57%, avg_specificity=89.41% avg_auc=0.8229
Fold[1] Epoch: 94 [94/100 (94%)] Train loss=0.216240 Test loss=0.549129 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13809077441692352
[5/23] Train loss=0.274255633354187
[10/23] Train loss=0.20491187274456024
[15/23] Train loss=0.20185694098472595
[20/23] Train loss=0.18318434059619904
Test set avg_accuracy=80.77% avg_sensitivity=55.53%, avg_specificity=89.31% avg_auc=0.8255
Fold[1] Epoch: 95 [95/100 (95%)] Train loss=0.216827 Test loss=0.545796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1343807727098465
[5/23] Train loss=0.2730902433395386
[10/23] Train loss=0.19262336194515228
[15/23] Train loss=0.19180163741111755
[20/23] Train loss=0.1808132827281952
Test set avg_accuracy=80.77% avg_sensitivity=55.49%, avg_specificity=89.33% avg_auc=0.8297
Fold[1] Epoch: 96 [96/100 (96%)] Train loss=0.213472 Test loss=0.550067 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13498328626155853
[5/23] Train loss=0.27100229263305664
[10/23] Train loss=0.1998598575592041
[15/23] Train loss=0.18475952744483948
[20/23] Train loss=0.17421932518482208
Test set avg_accuracy=80.35% avg_sensitivity=51.79%, avg_specificity=90.02% avg_auc=0.8230
Fold[1] Epoch: 97 [97/100 (97%)] Train loss=0.212834 Test loss=0.558289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12434771656990051
[5/23] Train loss=0.259306401014328
[10/23] Train loss=0.19527865946292877
[15/23] Train loss=0.18886946141719818
[20/23] Train loss=0.183733731508255
Test set avg_accuracy=80.52% avg_sensitivity=51.59%, avg_specificity=90.32% avg_auc=0.8264
Fold[1] Epoch: 98 [98/100 (98%)] Train loss=0.207841 Test loss=0.564384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11383572220802307
[5/23] Train loss=0.2595647871494293
[10/23] Train loss=0.19184979796409607
[15/23] Train loss=0.1823257952928543
[20/23] Train loss=0.18317925930023193
Test set avg_accuracy=80.53% avg_sensitivity=51.30%, avg_specificity=90.43% avg_auc=0.8235
Fold[1] Epoch: 99 [99/100 (99%)] Train loss=0.207549 Test loss=0.560128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12053117901086807
[5/23] Train loss=0.25606048107147217
[10/23] Train loss=0.20457535982131958
[15/23] Train loss=0.1778140366077423
[20/23] Train loss=0.17198041081428528
Test set avg_accuracy=80.75% avg_sensitivity=49.39%, avg_specificity=91.37% avg_auc=0.8192
Fold[1] Epoch: 100 [100/100 (100%)] Train loss=0.207793 Test loss=0.561006 Current lr=[3.9999999999999996e-05]

Fold[1] Best Result: acc=80.7201646090535 sen=57.851912123677785, spe=88.46047920683007, auc=0.8461368282659559!
[0/23] Train loss=0.677772581577301
[5/23] Train loss=0.6287007927894592
[10/23] Train loss=0.5597774386405945
[15/23] Train loss=0.5594080686569214
[20/23] Train loss=0.5313604474067688
Test set avg_accuracy=76.94% avg_sensitivity=0.50%, avg_specificity=99.88% avg_auc=0.5806
Best model saved!! Metric=-90.62394171114573!!
Fold[2] Epoch: 1 [1/100 (1%)] Train loss=0.572707 Test loss=0.551315 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5560410022735596
[5/23] Train loss=0.5924018621444702
[10/23] Train loss=0.5394514799118042
[15/23] Train loss=0.5409952998161316
[20/23] Train loss=0.4991466999053955
Test set avg_accuracy=77.28% avg_sensitivity=6.15%, avg_specificity=98.62% avg_auc=0.6281
Best model saved!! Metric=-81.14409955024011!!
Fold[2] Epoch: 2 [2/100 (2%)] Train loss=0.542148 Test loss=0.562976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5481016039848328
[5/23] Train loss=0.5602081418037415
[10/23] Train loss=0.5167919993400574
[15/23] Train loss=0.5261403918266296
[20/23] Train loss=0.4682292342185974
Test set avg_accuracy=77.22% avg_sensitivity=11.98%, avg_specificity=96.80% avg_auc=0.6762
Best model saved!! Metric=-72.37629506853442!!
Fold[2] Epoch: 3 [3/100 (3%)] Train loss=0.520031 Test loss=0.573145 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5317791104316711
[5/23] Train loss=0.5240622162818909
[10/23] Train loss=0.4784134030342102
[15/23] Train loss=0.48792362213134766
[20/23] Train loss=0.4261965751647949
Test set avg_accuracy=77.66% avg_sensitivity=17.81%, avg_specificity=95.62% avg_auc=0.7006
Best model saved!! Metric=-64.84339516791123!!
Fold[2] Epoch: 4 [4/100 (4%)] Train loss=0.490854 Test loss=0.596359 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5029138922691345
[5/23] Train loss=0.4964578449726105
[10/23] Train loss=0.4562912881374359
[15/23] Train loss=0.49807289242744446
[20/23] Train loss=0.4102492034435272
Test set avg_accuracy=78.40% avg_sensitivity=24.64%, avg_specificity=94.53% avg_auc=0.7249
Best model saved!! Metric=-55.93767622730189!!
Fold[2] Epoch: 5 [5/100 (5%)] Train loss=0.470603 Test loss=0.553385 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4638691842556
[5/23] Train loss=0.46864527463912964
[10/23] Train loss=0.4420326054096222
[15/23] Train loss=0.47463223338127136
[20/23] Train loss=0.39851537346839905
Test set avg_accuracy=78.34% avg_sensitivity=25.77%, avg_specificity=94.11% avg_auc=0.7352
Best model saved!! Metric=-54.2552855404025!!
Fold[2] Epoch: 6 [6/100 (6%)] Train loss=0.455293 Test loss=0.575241 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44502514600753784
[5/23] Train loss=0.4531024992465973
[10/23] Train loss=0.4492126405239105
[15/23] Train loss=0.4608922004699707
[20/23] Train loss=0.39096152782440186
Test set avg_accuracy=78.70% avg_sensitivity=28.16%, avg_specificity=93.86% avg_auc=0.7478
Best model saved!! Metric=-50.502830747003856!!
Fold[2] Epoch: 7 [7/100 (7%)] Train loss=0.447802 Test loss=0.567377 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4361608624458313
[5/23] Train loss=0.4481184780597687
[10/23] Train loss=0.41424641013145447
[15/23] Train loss=0.4354528784751892
[20/23] Train loss=0.38069167733192444
Test set avg_accuracy=78.70% avg_sensitivity=30.97%, avg_specificity=93.02% avg_auc=0.7635
Best model saved!! Metric=-46.96823442775192!!
Fold[2] Epoch: 8 [8/100 (8%)] Train loss=0.436674 Test loss=0.530434 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4245678782463074
[5/23] Train loss=0.4389832615852356
[10/23] Train loss=0.3952797055244446
[15/23] Train loss=0.42650777101516724
[20/23] Train loss=0.3758142292499542
Test set avg_accuracy=78.62% avg_sensitivity=34.09%, avg_specificity=91.98% avg_auc=0.7755
Best model saved!! Metric=-43.75637034033272!!
Fold[2] Epoch: 9 [9/100 (9%)] Train loss=0.424392 Test loss=0.517308 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41543132066726685
[5/23] Train loss=0.43523332476615906
[10/23] Train loss=0.3951191008090973
[15/23] Train loss=0.43127912282943726
[20/23] Train loss=0.3731725513935089
Test set avg_accuracy=78.68% avg_sensitivity=36.12%, avg_specificity=91.44% avg_auc=0.7825
Best model saved!! Metric=-41.51553460232273!!
Fold[2] Epoch: 10 [10/100 (10%)] Train loss=0.420527 Test loss=0.514533 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4080546498298645
[5/23] Train loss=0.429914265871048
[10/23] Train loss=0.4272030293941498
[15/23] Train loss=0.4224635064601898
[20/23] Train loss=0.36812788248062134
Test set avg_accuracy=78.85% avg_sensitivity=34.90%, avg_specificity=92.04% avg_auc=0.7766
Fold[2] Epoch: 11 [11/100 (11%)] Train loss=0.420328 Test loss=0.529353 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4119313657283783
[5/23] Train loss=0.43277689814567566
[10/23] Train loss=0.41270411014556885
[15/23] Train loss=0.40959954261779785
[20/23] Train loss=0.3577613830566406
Test set avg_accuracy=78.81% avg_sensitivity=34.27%, avg_specificity=92.17% avg_auc=0.7806
Fold[2] Epoch: 12 [12/100 (12%)] Train loss=0.416967 Test loss=0.526354 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40838706493377686
[5/23] Train loss=0.4257047176361084
[10/23] Train loss=0.3812987208366394
[15/23] Train loss=0.4021475613117218
[20/23] Train loss=0.3593904674053192
Test set avg_accuracy=78.98% avg_sensitivity=38.79%, avg_specificity=91.03% avg_auc=0.7973
Best model saved!! Metric=-37.46421311376132!!
Fold[2] Epoch: 13 [13/100 (13%)] Train loss=0.407782 Test loss=0.484968 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40570464730262756
[5/23] Train loss=0.4279738962650299
[10/23] Train loss=0.36549830436706543
[15/23] Train loss=0.4099624752998352
[20/23] Train loss=0.35354065895080566
Test set avg_accuracy=79.11% avg_sensitivity=40.42%, avg_specificity=90.72% avg_auc=0.8039
Best model saved!! Metric=-35.35911979503044!!
Fold[2] Epoch: 14 [14/100 (14%)] Train loss=0.402790 Test loss=0.469038 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4028250575065613
[5/23] Train loss=0.4176652133464813
[10/23] Train loss=0.3685247600078583
[15/23] Train loss=0.39155974984169006
[20/23] Train loss=0.3486098647117615
Test set avg_accuracy=79.19% avg_sensitivity=41.18%, avg_specificity=90.59% avg_auc=0.8062
Best model saved!! Metric=-34.41947033257104!!
Fold[2] Epoch: 15 [15/100 (15%)] Train loss=0.398636 Test loss=0.470974 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3966676592826843
[5/23] Train loss=0.41493427753448486
[10/23] Train loss=0.3883855938911438
[15/23] Train loss=0.3989097774028778
[20/23] Train loss=0.34571680426597595
Test set avg_accuracy=79.18% avg_sensitivity=39.42%, avg_specificity=91.10% avg_auc=0.7961
Fold[2] Epoch: 16 [16/100 (16%)] Train loss=0.400191 Test loss=0.489212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39225608110427856
[5/23] Train loss=0.4107457995414734
[10/23] Train loss=0.38936853408813477
[15/23] Train loss=0.38427165150642395
[20/23] Train loss=0.3453752100467682
Test set avg_accuracy=79.26% avg_sensitivity=39.15%, avg_specificity=91.29% avg_auc=0.7957
Fold[2] Epoch: 17 [17/100 (17%)] Train loss=0.397726 Test loss=0.490307 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39018774032592773
[5/23] Train loss=0.41900336742401123
[10/23] Train loss=0.35466837882995605
[15/23] Train loss=0.3799535930156708
[20/23] Train loss=0.3402615487575531
Test set avg_accuracy=79.24% avg_sensitivity=41.46%, avg_specificity=90.57% avg_auc=0.8069
Best model saved!! Metric=-34.040757255587344!!
Fold[2] Epoch: 18 [18/100 (18%)] Train loss=0.392488 Test loss=0.462613 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39309772849082947
[5/23] Train loss=0.4134281575679779
[10/23] Train loss=0.35634732246398926
[15/23] Train loss=0.3905368149280548
[20/23] Train loss=0.3404039442539215
Test set avg_accuracy=79.39% avg_sensitivity=44.21%, avg_specificity=89.95% avg_auc=0.8220
Best model saved!! Metric=-30.24580706563405!!
Fold[2] Epoch: 19 [19/100 (19%)] Train loss=0.388084 Test loss=0.441925 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.394951730966568
[5/23] Train loss=0.4107312858104706
[10/23] Train loss=0.348381906747818
[15/23] Train loss=0.3915778696537018
[20/23] Train loss=0.33236849308013916
Test set avg_accuracy=79.51% avg_sensitivity=45.71%, avg_specificity=89.65% avg_auc=0.8281
Best model saved!! Metric=-28.327591540708777!!
Fold[2] Epoch: 20 [20/100 (20%)] Train loss=0.383844 Test loss=0.428675 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38593292236328125
[5/23] Train loss=0.40870121121406555
[10/23] Train loss=0.3623543977737427
[15/23] Train loss=0.38558343052864075
[20/23] Train loss=0.3309340178966522
Test set avg_accuracy=79.44% avg_sensitivity=41.86%, avg_specificity=90.71% avg_auc=0.8151
Fold[2] Epoch: 21 [21/100 (21%)] Train loss=0.385227 Test loss=0.460254 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3762606382369995
[5/23] Train loss=0.40687480568885803
[10/23] Train loss=0.3659350872039795
[15/23] Train loss=0.37853673100471497
[20/23] Train loss=0.33424508571624756
Test set avg_accuracy=79.34% avg_sensitivity=38.74%, avg_specificity=91.52% avg_auc=0.8148
Fold[2] Epoch: 22 [22/100 (22%)] Train loss=0.386977 Test loss=0.483998 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36937060952186584
[5/23] Train loss=0.40692654252052307
[10/23] Train loss=0.353922575712204
[15/23] Train loss=0.3734757602214813
[20/23] Train loss=0.33263102173805237
Test set avg_accuracy=79.14% avg_sensitivity=39.29%, avg_specificity=91.10% avg_auc=0.8129
Fold[2] Epoch: 23 [23/100 (23%)] Train loss=0.383495 Test loss=0.485646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3641374707221985
[5/23] Train loss=0.40699827671051025
[10/23] Train loss=0.34322014451026917
[15/23] Train loss=0.36321699619293213
[20/23] Train loss=0.3302846848964691
Test set avg_accuracy=79.49% avg_sensitivity=45.39%, avg_specificity=89.72% avg_auc=0.8264
Fold[2] Epoch: 24 [24/100 (24%)] Train loss=0.374976 Test loss=0.451304 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38435792922973633
[5/23] Train loss=0.40743568539619446
[10/23] Train loss=0.33802902698516846
[15/23] Train loss=0.35962921380996704
[20/23] Train loss=0.3199715316295624
Test set avg_accuracy=79.80% avg_sensitivity=46.11%, avg_specificity=89.91% avg_auc=0.8337
Best model saved!! Metric=-26.80580649375473!!
Fold[2] Epoch: 25 [25/100 (25%)] Train loss=0.371671 Test loss=0.439715 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37654438614845276
[5/23] Train loss=0.39812326431274414
[10/23] Train loss=0.33722880482673645
[15/23] Train loss=0.3530976474285126
[20/23] Train loss=0.31960946321487427
Test set avg_accuracy=79.85% avg_sensitivity=45.39%, avg_specificity=90.19% avg_auc=0.8322
Fold[2] Epoch: 26 [26/100 (26%)] Train loss=0.367923 Test loss=0.438458 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36635082960128784
[5/23] Train loss=0.3973945379257202
[10/23] Train loss=0.3373369872570038
[15/23] Train loss=0.35048940777778625
[20/23] Train loss=0.31372004747390747
Test set avg_accuracy=79.85% avg_sensitivity=44.30%, avg_specificity=90.52% avg_auc=0.8295
Fold[2] Epoch: 27 [27/100 (27%)] Train loss=0.366092 Test loss=0.443950 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36040663719177246
[5/23] Train loss=0.3935767710208893
[10/23] Train loss=0.32650843262672424
[15/23] Train loss=0.3477764129638672
[20/23] Train loss=0.3159922659397125
Test set avg_accuracy=79.62% avg_sensitivity=43.90%, avg_specificity=90.34% avg_auc=0.8282
Fold[2] Epoch: 28 [28/100 (28%)] Train loss=0.363817 Test loss=0.451909 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36022648215293884
[5/23] Train loss=0.39501163363456726
[10/23] Train loss=0.335923433303833
[15/23] Train loss=0.33763253688812256
[20/23] Train loss=0.31335970759391785
Test set avg_accuracy=79.99% avg_sensitivity=48.73%, avg_specificity=89.37% avg_auc=0.8380
Best model saved!! Metric=-24.104777491437535!!
Fold[2] Epoch: 29 [29/100 (29%)] Train loss=0.361581 Test loss=0.430975 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35762572288513184
[5/23] Train loss=0.3901190161705017
[10/23] Train loss=0.33111467957496643
[15/23] Train loss=0.34613674879074097
[20/23] Train loss=0.30649667978286743
Test set avg_accuracy=79.71% avg_sensitivity=43.76%, avg_specificity=90.49% avg_auc=0.8291
Fold[2] Epoch: 30 [30/100 (30%)] Train loss=0.357697 Test loss=0.458985 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3494805097579956
[5/23] Train loss=0.3922584652900696
[10/23] Train loss=0.31682097911834717
[15/23] Train loss=0.3470451831817627
[20/23] Train loss=0.3033318817615509
Test set avg_accuracy=79.99% avg_sensitivity=47.02%, avg_specificity=89.88% avg_auc=0.8363
Fold[2] Epoch: 31 [31/100 (31%)] Train loss=0.356266 Test loss=0.437429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35728955268859863
[5/23] Train loss=0.39232495427131653
[10/23] Train loss=0.31075459718704224
[15/23] Train loss=0.34041059017181396
[20/23] Train loss=0.3046504855155945
Test set avg_accuracy=80.27% avg_sensitivity=50.99%, avg_specificity=89.05% avg_auc=0.8404
Best model saved!! Metric=-21.63543429164541!!
Fold[2] Epoch: 32 [32/100 (32%)] Train loss=0.352845 Test loss=0.425986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.350760281085968
[5/23] Train loss=0.3853198289871216
[10/23] Train loss=0.3155822157859802
[15/23] Train loss=0.34945303201675415
[20/23] Train loss=0.30562686920166016
Test set avg_accuracy=79.97% avg_sensitivity=48.60%, avg_specificity=89.38% avg_auc=0.8372
Fold[2] Epoch: 33 [33/100 (33%)] Train loss=0.351895 Test loss=0.432661 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3597697615623474
[5/23] Train loss=0.3860810399055481
[10/23] Train loss=0.312465101480484
[15/23] Train loss=0.3363313376903534
[20/23] Train loss=0.29543155431747437
Test set avg_accuracy=80.11% avg_sensitivity=48.01%, avg_specificity=89.75% avg_auc=0.8368
Fold[2] Epoch: 34 [34/100 (34%)] Train loss=0.349486 Test loss=0.437966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34141725301742554
[5/23] Train loss=0.3866053521633148
[10/23] Train loss=0.31345492601394653
[15/23] Train loss=0.3352818489074707
[20/23] Train loss=0.29972609877586365
Test set avg_accuracy=79.89% avg_sensitivity=43.81%, avg_specificity=90.71% avg_auc=0.8321
Fold[2] Epoch: 35 [35/100 (35%)] Train loss=0.347569 Test loss=0.453762 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34084469079971313
[5/23] Train loss=0.38682255148887634
[10/23] Train loss=0.3095017671585083
[15/23] Train loss=0.3248883783817291
[20/23] Train loss=0.2945813834667206
Test set avg_accuracy=79.97% avg_sensitivity=47.65%, avg_specificity=89.66% avg_auc=0.8343
Fold[2] Epoch: 36 [36/100 (36%)] Train loss=0.347505 Test loss=0.447648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.340366393327713
[5/23] Train loss=0.3841079771518707
[10/23] Train loss=0.30224111676216125
[15/23] Train loss=0.33315908908843994
[20/23] Train loss=0.2963104546070099
Test set avg_accuracy=80.05% avg_sensitivity=49.59%, avg_specificity=89.19% avg_auc=0.8355
Fold[2] Epoch: 37 [37/100 (37%)] Train loss=0.344045 Test loss=0.447218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3467967212200165
[5/23] Train loss=0.38430559635162354
[10/23] Train loss=0.3016020953655243
[15/23] Train loss=0.32953330874443054
[20/23] Train loss=0.29389089345932007
Test set avg_accuracy=80.08% avg_sensitivity=49.32%, avg_specificity=89.31% avg_auc=0.8355
Fold[2] Epoch: 38 [38/100 (38%)] Train loss=0.339491 Test loss=0.445305 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34431490302085876
[5/23] Train loss=0.38626760244369507
[10/23] Train loss=0.3009217083454132
[15/23] Train loss=0.3254503309726715
[20/23] Train loss=0.2937871217727661
Test set avg_accuracy=80.38% avg_sensitivity=46.43%, avg_specificity=90.56% avg_auc=0.8301
Fold[2] Epoch: 39 [39/100 (39%)] Train loss=0.338358 Test loss=0.458446 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33529284596443176
[5/23] Train loss=0.3762350082397461
[10/23] Train loss=0.30592355132102966
[15/23] Train loss=0.3195209503173828
[20/23] Train loss=0.2876874506473541
Test set avg_accuracy=80.20% avg_sensitivity=51.40%, avg_specificity=88.84% avg_auc=0.8380
Fold[2] Epoch: 40 [40/100 (40%)] Train loss=0.338755 Test loss=0.439882 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34675803780555725
[5/23] Train loss=0.3824370801448822
[10/23] Train loss=0.2969951033592224
[15/23] Train loss=0.3264525234699249
[20/23] Train loss=0.2809853255748749
Test set avg_accuracy=79.95% avg_sensitivity=54.48%, avg_specificity=87.59% avg_auc=0.8390
Best model saved!! Metric=-20.08196885922421!!
Fold[2] Epoch: 41 [41/100 (41%)] Train loss=0.333482 Test loss=0.441473 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33499419689178467
[5/23] Train loss=0.3659859895706177
[10/23] Train loss=0.29650893807411194
[15/23] Train loss=0.310456782579422
[20/23] Train loss=0.2858181893825531
Test set avg_accuracy=80.03% avg_sensitivity=48.24%, avg_specificity=89.57% avg_auc=0.8314
Fold[2] Epoch: 42 [42/100 (42%)] Train loss=0.331144 Test loss=0.459929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3339012861251831
[5/23] Train loss=0.3697875738143921
[10/23] Train loss=0.30209729075431824
[15/23] Train loss=0.30663639307022095
[20/23] Train loss=0.2776893973350525
Test set avg_accuracy=80.20% avg_sensitivity=52.31%, avg_specificity=88.57% avg_auc=0.8375
Fold[2] Epoch: 43 [43/100 (43%)] Train loss=0.329059 Test loss=0.454232 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33150267601013184
[5/23] Train loss=0.3625248968601227
[10/23] Train loss=0.2864815890789032
[15/23] Train loss=0.30460429191589355
[20/23] Train loss=0.2763376235961914
Test set avg_accuracy=80.00% avg_sensitivity=49.46%, avg_specificity=89.16% avg_auc=0.8335
Fold[2] Epoch: 44 [44/100 (44%)] Train loss=0.325518 Test loss=0.462439 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3325510621070862
[5/23] Train loss=0.3692092299461365
[10/23] Train loss=0.2917270064353943
[15/23] Train loss=0.30420634150505066
[20/23] Train loss=0.26935938000679016
Test set avg_accuracy=80.14% avg_sensitivity=50.50%, avg_specificity=89.03% avg_auc=0.8356
Fold[2] Epoch: 45 [45/100 (45%)] Train loss=0.323689 Test loss=0.456175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3200237452983856
[5/23] Train loss=0.36218902468681335
[10/23] Train loss=0.279397189617157
[15/23] Train loss=0.3084961771965027
[20/23] Train loss=0.2708945870399475
Test set avg_accuracy=80.04% avg_sensitivity=50.41%, avg_specificity=88.93% avg_auc=0.8363
Fold[2] Epoch: 46 [46/100 (46%)] Train loss=0.320224 Test loss=0.451545 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32452526688575745
[5/23] Train loss=0.35513636469841003
[10/23] Train loss=0.2866215705871582
[15/23] Train loss=0.3019949793815613
[20/23] Train loss=0.2713078558444977
Test set avg_accuracy=80.22% avg_sensitivity=50.36%, avg_specificity=89.18% avg_auc=0.8346
Fold[2] Epoch: 47 [47/100 (47%)] Train loss=0.316439 Test loss=0.450074 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31705495715141296
[5/23] Train loss=0.36023297905921936
[10/23] Train loss=0.302074134349823
[15/23] Train loss=0.3032100200653076
[20/23] Train loss=0.2773100435733795
Test set avg_accuracy=79.95% avg_sensitivity=42.13%, avg_specificity=91.29% avg_auc=0.8270
Fold[2] Epoch: 48 [48/100 (48%)] Train loss=0.323001 Test loss=0.480809 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3217160701751709
[5/23] Train loss=0.35957348346710205
[10/23] Train loss=0.29775553941726685
[15/23] Train loss=0.31892529129981995
[20/23] Train loss=0.2615407705307007
Test set avg_accuracy=80.47% avg_sensitivity=54.61%, avg_specificity=88.23% avg_auc=0.8384
Best model saved!! Metric=-18.849231728855244!!
Fold[2] Epoch: 49 [49/100 (49%)] Train loss=0.320711 Test loss=0.433814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3189510405063629
[5/23] Train loss=0.36610379815101624
[10/23] Train loss=0.27762454748153687
[15/23] Train loss=0.2922937572002411
[20/23] Train loss=0.26633012294769287
Test set avg_accuracy=80.52% avg_sensitivity=51.36%, avg_specificity=89.27% avg_auc=0.8389
Fold[2] Epoch: 50 [50/100 (50%)] Train loss=0.312200 Test loss=0.451454 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3150981068611145
[5/23] Train loss=0.3571125268936157
[10/23] Train loss=0.28615519404411316
[15/23] Train loss=0.2941470146179199
[20/23] Train loss=0.26380467414855957
Test set avg_accuracy=80.50% avg_sensitivity=51.45%, avg_specificity=89.22% avg_auc=0.8334
Fold[2] Epoch: 51 [51/100 (51%)] Train loss=0.308803 Test loss=0.452027 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3177592158317566
[5/23] Train loss=0.34294843673706055
[10/23] Train loss=0.27968162298202515
[15/23] Train loss=0.28256240487098694
[20/23] Train loss=0.2641785144805908
Test set avg_accuracy=80.30% avg_sensitivity=51.40%, avg_specificity=88.97% avg_auc=0.8358
Fold[2] Epoch: 52 [52/100 (52%)] Train loss=0.307292 Test loss=0.464141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3146999478340149
[5/23] Train loss=0.3465457558631897
[10/23] Train loss=0.2745213210582733
[15/23] Train loss=0.28205591440200806
[20/23] Train loss=0.2580055892467499
Test set avg_accuracy=80.18% avg_sensitivity=49.64%, avg_specificity=89.34% avg_auc=0.8320
Fold[2] Epoch: 53 [53/100 (53%)] Train loss=0.304184 Test loss=0.466907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3109678030014038
[5/23] Train loss=0.3410550057888031
[10/23] Train loss=0.28063520789146423
[15/23] Train loss=0.284593790769577
[20/23] Train loss=0.25510385632514954
Test set avg_accuracy=80.00% avg_sensitivity=47.74%, avg_specificity=89.68% avg_auc=0.8300
Fold[2] Epoch: 54 [54/100 (54%)] Train loss=0.303238 Test loss=0.475804 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2952125072479248
[5/23] Train loss=0.33441877365112305
[10/23] Train loss=0.26662540435791016
[15/23] Train loss=0.27863478660583496
[20/23] Train loss=0.25707128643989563
Test set avg_accuracy=80.04% avg_sensitivity=48.10%, avg_specificity=89.62% avg_auc=0.8345
Fold[2] Epoch: 55 [55/100 (55%)] Train loss=0.297620 Test loss=0.462896 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29761773347854614
[5/23] Train loss=0.3417407274246216
[10/23] Train loss=0.26981619000434875
[15/23] Train loss=0.2710322439670563
[20/23] Train loss=0.25261637568473816
Test set avg_accuracy=79.82% avg_sensitivity=50.90%, avg_specificity=88.50% avg_auc=0.8341
Fold[2] Epoch: 56 [56/100 (56%)] Train loss=0.296193 Test loss=0.461312 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29984867572784424
[5/23] Train loss=0.3447379767894745
[10/23] Train loss=0.2764662206172943
[15/23] Train loss=0.27983784675598145
[20/23] Train loss=0.2535741627216339
Test set avg_accuracy=80.11% avg_sensitivity=52.03%, avg_specificity=88.54% avg_auc=0.8360
Fold[2] Epoch: 57 [57/100 (57%)] Train loss=0.295933 Test loss=0.461847 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29110604524612427
[5/23] Train loss=0.3375149369239807
[10/23] Train loss=0.2564530372619629
[15/23] Train loss=0.2636815905570984
[20/23] Train loss=0.24261246621608734
Test set avg_accuracy=80.37% avg_sensitivity=55.97%, avg_specificity=87.68% avg_auc=0.8367
Best model saved!! Metric=-18.30888969534224!!
Fold[2] Epoch: 58 [58/100 (58%)] Train loss=0.289356 Test loss=0.458203 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29777777194976807
[5/23] Train loss=0.3466317057609558
[10/23] Train loss=0.255248099565506
[15/23] Train loss=0.27723389863967896
[20/23] Train loss=0.25030213594436646
Test set avg_accuracy=79.67% avg_sensitivity=52.85%, avg_specificity=87.71% avg_auc=0.8316
Fold[2] Epoch: 59 [59/100 (59%)] Train loss=0.289635 Test loss=0.478297 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2994045317173004
[5/23] Train loss=0.33755162358283997
[10/23] Train loss=0.2644888460636139
[15/23] Train loss=0.2715289890766144
[20/23] Train loss=0.24600479006767273
Test set avg_accuracy=79.58% avg_sensitivity=53.03%, avg_specificity=87.55% avg_auc=0.8293
Fold[2] Epoch: 60 [60/100 (60%)] Train loss=0.288155 Test loss=0.481571 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2941129207611084
[5/23] Train loss=0.3264613151550293
[10/23] Train loss=0.2568657100200653
[15/23] Train loss=0.2687239646911621
[20/23] Train loss=0.23714782297611237
Test set avg_accuracy=79.84% avg_sensitivity=51.54%, avg_specificity=88.34% avg_auc=0.8297
Fold[2] Epoch: 61 [61/100 (61%)] Train loss=0.282739 Test loss=0.490281 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28818175196647644
[5/23] Train loss=0.32152414321899414
[10/23] Train loss=0.25469788908958435
[15/23] Train loss=0.25559744238853455
[20/23] Train loss=0.24558371305465698
Test set avg_accuracy=79.72% avg_sensitivity=49.46%, avg_specificity=88.80% avg_auc=0.8275
Fold[2] Epoch: 62 [62/100 (62%)] Train loss=0.279580 Test loss=0.502165 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28578200936317444
[5/23] Train loss=0.3212967813014984
[10/23] Train loss=0.2603378891944885
[15/23] Train loss=0.25428977608680725
[20/23] Train loss=0.23668336868286133
Test set avg_accuracy=79.77% avg_sensitivity=48.24%, avg_specificity=89.23% avg_auc=0.8270
Fold[2] Epoch: 63 [63/100 (63%)] Train loss=0.277502 Test loss=0.499829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2828015685081482
[5/23] Train loss=0.3165873885154724
[10/23] Train loss=0.24869592487812042
[15/23] Train loss=0.2533237040042877
[20/23] Train loss=0.23915961384773254
Test set avg_accuracy=79.78% avg_sensitivity=49.41%, avg_specificity=88.89% avg_auc=0.8288
Fold[2] Epoch: 64 [64/100 (64%)] Train loss=0.276557 Test loss=0.491944 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2807690501213074
[5/23] Train loss=0.3136121928691864
[10/23] Train loss=0.2624039351940155
[15/23] Train loss=0.24746231734752655
[20/23] Train loss=0.2234524041414261
Test set avg_accuracy=79.92% avg_sensitivity=51.40%, avg_specificity=88.47% avg_auc=0.8305
Fold[2] Epoch: 65 [65/100 (65%)] Train loss=0.272599 Test loss=0.487984 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27923184633255005
[5/23] Train loss=0.31849077343940735
[10/23] Train loss=0.24771377444267273
[15/23] Train loss=0.24579349160194397
[20/23] Train loss=0.21901199221611023
Test set avg_accuracy=79.89% avg_sensitivity=50.99%, avg_specificity=88.55% avg_auc=0.8315
Fold[2] Epoch: 66 [66/100 (66%)] Train loss=0.270563 Test loss=0.484612 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27915868163108826
[5/23] Train loss=0.31186625361442566
[10/23] Train loss=0.24448148906230927
[15/23] Train loss=0.25471118092536926
[20/23] Train loss=0.23122088611125946
Test set avg_accuracy=79.69% avg_sensitivity=50.90%, avg_specificity=88.32% avg_auc=0.8305
Fold[2] Epoch: 67 [67/100 (67%)] Train loss=0.269018 Test loss=0.490996 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2673639953136444
[5/23] Train loss=0.3157168924808502
[10/23] Train loss=0.2495860755443573
[15/23] Train loss=0.24296201765537262
[20/23] Train loss=0.2253931164741516
Test set avg_accuracy=79.96% avg_sensitivity=50.14%, avg_specificity=88.91% avg_auc=0.8302
Fold[2] Epoch: 68 [68/100 (68%)] Train loss=0.268325 Test loss=0.492867 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2685557007789612
[5/23] Train loss=0.30926603078842163
[10/23] Train loss=0.23881976306438446
[15/23] Train loss=0.25506243109703064
[20/23] Train loss=0.23236796259880066
Test set avg_accuracy=79.83% avg_sensitivity=48.73%, avg_specificity=89.16% avg_auc=0.8282
Fold[2] Epoch: 69 [69/100 (69%)] Train loss=0.266302 Test loss=0.502355 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26489657163619995
[5/23] Train loss=0.3149501085281372
[10/23] Train loss=0.2453586757183075
[15/23] Train loss=0.24279026687145233
[20/23] Train loss=0.22935977578163147
Test set avg_accuracy=79.70% avg_sensitivity=46.56%, avg_specificity=89.64% avg_auc=0.8258
Fold[2] Epoch: 70 [70/100 (70%)] Train loss=0.265703 Test loss=0.509229 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26445600390434265
[5/23] Train loss=0.31498095393180847
[10/23] Train loss=0.25182247161865234
[15/23] Train loss=0.23310671746730804
[20/23] Train loss=0.22211012244224548
Test set avg_accuracy=79.95% avg_sensitivity=48.33%, avg_specificity=89.43% avg_auc=0.8295
Fold[2] Epoch: 71 [71/100 (71%)] Train loss=0.267942 Test loss=0.489348 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2645929455757141
[5/23] Train loss=0.31455197930336
[10/23] Train loss=0.24227958917617798
[15/23] Train loss=0.23123380541801453
[20/23] Train loss=0.2239322066307068
Test set avg_accuracy=79.76% avg_sensitivity=52.53%, avg_specificity=87.93% avg_auc=0.8267
Fold[2] Epoch: 72 [72/100 (72%)] Train loss=0.261327 Test loss=0.502084 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2650969624519348
[5/23] Train loss=0.3012140989303589
[10/23] Train loss=0.24469852447509766
[15/23] Train loss=0.2433740347623825
[20/23] Train loss=0.22033432126045227
Test set avg_accuracy=79.55% avg_sensitivity=51.40%, avg_specificity=88.00% avg_auc=0.8279
Fold[2] Epoch: 73 [73/100 (73%)] Train loss=0.257988 Test loss=0.511657 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2739831507205963
[5/23] Train loss=0.2960597574710846
[10/23] Train loss=0.24865610897541046
[15/23] Train loss=0.2375524342060089
[20/23] Train loss=0.21255642175674438
Test set avg_accuracy=79.83% avg_sensitivity=48.46%, avg_specificity=89.24% avg_auc=0.8291
Fold[2] Epoch: 74 [74/100 (74%)] Train loss=0.255216 Test loss=0.510405 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2646380066871643
[5/23] Train loss=0.2912050485610962
[10/23] Train loss=0.24197767674922943
[15/23] Train loss=0.2268420308828354
[20/23] Train loss=0.21486841142177582
Test set avg_accuracy=79.84% avg_sensitivity=48.82%, avg_specificity=89.15% avg_auc=0.8251
Fold[2] Epoch: 75 [75/100 (75%)] Train loss=0.253241 Test loss=0.515836 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2556535303592682
[5/23] Train loss=0.30117279291152954
[10/23] Train loss=0.233552023768425
[15/23] Train loss=0.22710171341896057
[20/23] Train loss=0.2128806859254837
Test set avg_accuracy=79.81% avg_sensitivity=50.86%, avg_specificity=88.50% avg_auc=0.8255
Fold[2] Epoch: 76 [76/100 (76%)] Train loss=0.251973 Test loss=0.507835 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26003849506378174
[5/23] Train loss=0.2910492420196533
[10/23] Train loss=0.2346583604812622
[15/23] Train loss=0.22363924980163574
[20/23] Train loss=0.2061188668012619
Test set avg_accuracy=79.86% avg_sensitivity=50.59%, avg_specificity=88.65% avg_auc=0.8289
Fold[2] Epoch: 77 [77/100 (77%)] Train loss=0.247724 Test loss=0.517041 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2545253336429596
[5/23] Train loss=0.290431946516037
[10/23] Train loss=0.23357072472572327
[15/23] Train loss=0.2342599481344223
[20/23] Train loss=0.2120373249053955
Test set avg_accuracy=79.69% avg_sensitivity=51.58%, avg_specificity=88.12% avg_auc=0.8275
Fold[2] Epoch: 78 [78/100 (78%)] Train loss=0.246905 Test loss=0.522078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25105020403862
[5/23] Train loss=0.2939121127128601
[10/23] Train loss=0.22599256038665771
[15/23] Train loss=0.22477371990680695
[20/23] Train loss=0.20787550508975983
Test set avg_accuracy=79.98% avg_sensitivity=47.47%, avg_specificity=89.73% avg_auc=0.8242
Fold[2] Epoch: 79 [79/100 (79%)] Train loss=0.245416 Test loss=0.519501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23594829440116882
[5/23] Train loss=0.29231128096580505
[10/23] Train loss=0.2343825399875641
[15/23] Train loss=0.22065001726150513
[20/23] Train loss=0.20553234219551086
Test set avg_accuracy=80.20% avg_sensitivity=44.67%, avg_specificity=90.86% avg_auc=0.8205
Fold[2] Epoch: 80 [80/100 (80%)] Train loss=0.245550 Test loss=0.529205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23211154341697693
[5/23] Train loss=0.2936217188835144
[10/23] Train loss=0.23275074362754822
[15/23] Train loss=0.22126740217208862
[20/23] Train loss=0.2051897644996643
Test set avg_accuracy=79.95% avg_sensitivity=45.84%, avg_specificity=90.18% avg_auc=0.8223
Fold[2] Epoch: 81 [81/100 (81%)] Train loss=0.243477 Test loss=0.528596 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2362605482339859
[5/23] Train loss=0.2935955822467804
[10/23] Train loss=0.22624655067920685
[15/23] Train loss=0.21622668206691742
[20/23] Train loss=0.21216286718845367
Test set avg_accuracy=79.81% avg_sensitivity=48.82%, avg_specificity=89.11% avg_auc=0.8250
Fold[2] Epoch: 82 [82/100 (82%)] Train loss=0.242350 Test loss=0.528816 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.243543803691864
[5/23] Train loss=0.29590243101119995
[10/23] Train loss=0.22154514491558075
[15/23] Train loss=0.21590323746204376
[20/23] Train loss=0.1993020921945572
Test set avg_accuracy=79.71% avg_sensitivity=52.31%, avg_specificity=87.93% avg_auc=0.8252
Fold[2] Epoch: 83 [83/100 (83%)] Train loss=0.235991 Test loss=0.533861 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24274283647537231
[5/23] Train loss=0.2820407748222351
[10/23] Train loss=0.21907338500022888
[15/23] Train loss=0.2118384689092636
[20/23] Train loss=0.202896848320961
Test set avg_accuracy=79.58% avg_sensitivity=52.03%, avg_specificity=87.85% avg_auc=0.8245
Fold[2] Epoch: 84 [84/100 (84%)] Train loss=0.234266 Test loss=0.529379 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24036560952663422
[5/23] Train loss=0.2656611502170563
[10/23] Train loss=0.21917667984962463
[15/23] Train loss=0.2087956666946411
[20/23] Train loss=0.18969716131687164
Test set avg_accuracy=79.83% avg_sensitivity=48.60%, avg_specificity=89.20% avg_auc=0.8225
Fold[2] Epoch: 85 [85/100 (85%)] Train loss=0.230519 Test loss=0.531627 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22745464742183685
[5/23] Train loss=0.26588931679725647
[10/23] Train loss=0.22806115448474884
[15/23] Train loss=0.2069861739873886
[20/23] Train loss=0.18448062241077423
Test set avg_accuracy=80.13% avg_sensitivity=49.05%, avg_specificity=89.45% avg_auc=0.8235
Fold[2] Epoch: 86 [86/100 (86%)] Train loss=0.229617 Test loss=0.534546 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2347862720489502
[5/23] Train loss=0.27791866660118103
[10/23] Train loss=0.21852914988994598
[15/23] Train loss=0.2055513709783554
[20/23] Train loss=0.1981850415468216
Test set avg_accuracy=79.98% avg_sensitivity=53.44%, avg_specificity=87.94% avg_auc=0.8173
Fold[2] Epoch: 87 [87/100 (87%)] Train loss=0.226347 Test loss=0.510716 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2176589071750641
[5/23] Train loss=0.26939013600349426
[10/23] Train loss=0.19864511489868164
[15/23] Train loss=0.21359343826770782
[20/23] Train loss=0.18813563883304596
Test set avg_accuracy=79.80% avg_sensitivity=55.24%, avg_specificity=87.17% avg_auc=0.8242
Fold[2] Epoch: 88 [88/100 (88%)] Train loss=0.222304 Test loss=0.530042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22901999950408936
[5/23] Train loss=0.26559391617774963
[10/23] Train loss=0.21176350116729736
[15/23] Train loss=0.20010611414909363
[20/23] Train loss=0.18512269854545593
Test set avg_accuracy=80.09% avg_sensitivity=49.19%, avg_specificity=89.37% avg_auc=0.8250
Fold[2] Epoch: 89 [89/100 (89%)] Train loss=0.220149 Test loss=0.538668 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22173307836055756
[5/23] Train loss=0.26922664046287537
[10/23] Train loss=0.20325209200382233
[15/23] Train loss=0.20443476736545563
[20/23] Train loss=0.17836827039718628
Test set avg_accuracy=80.27% avg_sensitivity=49.68%, avg_specificity=89.45% avg_auc=0.8226
Fold[2] Epoch: 90 [90/100 (90%)] Train loss=0.217990 Test loss=0.540620 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23162142932415009
[5/23] Train loss=0.25843045115470886
[10/23] Train loss=0.1954236924648285
[15/23] Train loss=0.19301621615886688
[20/23] Train loss=0.17378787696361542
Test set avg_accuracy=80.24% avg_sensitivity=47.60%, avg_specificity=90.03% avg_auc=0.8211
Fold[2] Epoch: 91 [91/100 (91%)] Train loss=0.212844 Test loss=0.543557 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2215617597103119
[5/23] Train loss=0.261730432510376
[10/23] Train loss=0.19338545203208923
[15/23] Train loss=0.21777845919132233
[20/23] Train loss=0.17055857181549072
Test set avg_accuracy=80.30% avg_sensitivity=50.77%, avg_specificity=89.16% avg_auc=0.8211
Fold[2] Epoch: 92 [92/100 (92%)] Train loss=0.211884 Test loss=0.541485 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20728014409542084
[5/23] Train loss=0.2504259943962097
[10/23] Train loss=0.19676831364631653
[15/23] Train loss=0.19385921955108643
[20/23] Train loss=0.19524574279785156
Test set avg_accuracy=79.92% avg_sensitivity=47.15%, avg_specificity=89.75% avg_auc=0.8208
Fold[2] Epoch: 93 [93/100 (93%)] Train loss=0.213963 Test loss=0.548285 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21739347279071808
[5/23] Train loss=0.24963049590587616
[10/23] Train loss=0.19884905219078064
[15/23] Train loss=0.19599026441574097
[20/23] Train loss=0.18129421770572662
Test set avg_accuracy=80.49% avg_sensitivity=53.12%, avg_specificity=88.70% avg_auc=0.8254
Fold[2] Epoch: 94 [94/100 (94%)] Train loss=0.211645 Test loss=0.541400 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2074759304523468
[5/23] Train loss=0.25773322582244873
[10/23] Train loss=0.18792489171028137
[15/23] Train loss=0.1949360966682434
[20/23] Train loss=0.16421760618686676
Test set avg_accuracy=80.09% avg_sensitivity=47.06%, avg_specificity=90.00% avg_auc=0.8207
Fold[2] Epoch: 95 [95/100 (95%)] Train loss=0.208455 Test loss=0.552603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2142886221408844
[5/23] Train loss=0.25666436553001404
[10/23] Train loss=0.19974841177463531
[15/23] Train loss=0.19264648854732513
[20/23] Train loss=0.17019954323768616
Test set avg_accuracy=80.06% avg_sensitivity=51.99%, avg_specificity=88.49% avg_auc=0.8212
Fold[2] Epoch: 96 [96/100 (96%)] Train loss=0.209821 Test loss=0.561021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20732393860816956
[5/23] Train loss=0.2742859423160553
[10/23] Train loss=0.19998440146446228
[15/23] Train loss=0.1878988891839981
[20/23] Train loss=0.18199831247329712
Test set avg_accuracy=80.02% avg_sensitivity=51.54%, avg_specificity=88.57% avg_auc=0.8161
Fold[2] Epoch: 97 [97/100 (97%)] Train loss=0.212171 Test loss=0.549616 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21984736621379852
[5/23] Train loss=0.25149303674697876
[10/23] Train loss=0.1870020031929016
[15/23] Train loss=0.19038957357406616
[20/23] Train loss=0.17409387230873108
Test set avg_accuracy=80.01% avg_sensitivity=52.40%, avg_specificity=88.30% avg_auc=0.8227
Fold[2] Epoch: 98 [98/100 (98%)] Train loss=0.204945 Test loss=0.568867 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21120606362819672
[5/23] Train loss=0.23155079782009125
[10/23] Train loss=0.19164979457855225
[15/23] Train loss=0.18256106972694397
[20/23] Train loss=0.1541719287633896
Test set avg_accuracy=80.15% avg_sensitivity=51.40%, avg_specificity=88.77% avg_auc=0.8203
Fold[2] Epoch: 99 [99/100 (99%)] Train loss=0.200256 Test loss=0.572439 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21330472826957703
[5/23] Train loss=0.2457534670829773
[10/23] Train loss=0.189498171210289
[15/23] Train loss=0.18226701021194458
[20/23] Train loss=0.161110982298851
Test set avg_accuracy=79.70% avg_sensitivity=48.96%, avg_specificity=88.92% avg_auc=0.8117
Fold[2] Epoch: 100 [100/100 (100%)] Train loss=0.199697 Test loss=0.599312 Current lr=[3.9999999999999996e-05]

Fold[2] Best Result: acc=80.36515388628065 sen=55.96745027124774, spe=87.68479587684796, auc=0.8367371027028141!
[0/23] Train loss=0.6894772052764893
[5/23] Train loss=0.7176534533500671
[10/23] Train loss=0.564598798751831
[15/23] Train loss=0.5558534264564514
[20/23] Train loss=0.5262864232063293
Test set avg_accuracy=68.35% avg_sensitivity=0.46%, avg_specificity=99.78% avg_auc=0.5931
Best model saved!! Metric=-98.09734070514499!!
Fold[3] Epoch: 1 [1/100 (1%)] Train loss=0.563304 Test loss=0.789989 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5668132305145264
[5/23] Train loss=0.60272216796875
[10/23] Train loss=0.5313808917999268
[15/23] Train loss=0.5239434838294983
[20/23] Train loss=0.48815518617630005
Test set avg_accuracy=68.78% avg_sensitivity=5.97%, avg_specificity=97.86% avg_auc=0.6462
Best model saved!! Metric=-88.76853428949691!!
Fold[3] Epoch: 2 [2/100 (2%)] Train loss=0.521973 Test loss=0.749997 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.53401780128479
[5/23] Train loss=0.5505965352058411
[10/23] Train loss=0.49069246649742126
[15/23] Train loss=0.5015855431556702
[20/23] Train loss=0.43663498759269714
Test set avg_accuracy=70.40% avg_sensitivity=15.69%, avg_specificity=95.75% avg_auc=0.6900
Best model saved!! Metric=-75.16004790044799!!
Fold[3] Epoch: 3 [3/100 (3%)] Train loss=0.487623 Test loss=0.758367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4964779019355774
[5/23] Train loss=0.5021418333053589
[10/23] Train loss=0.44636812806129456
[15/23] Train loss=0.4991115629673004
[20/23] Train loss=0.42214804887771606
Test set avg_accuracy=71.84% avg_sensitivity=20.60%, avg_specificity=95.58% avg_auc=0.7239
Best model saved!! Metric=-65.59361250602781!!
Fold[3] Epoch: 4 [4/100 (4%)] Train loss=0.461656 Test loss=0.792176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4619297683238983
[5/23] Train loss=0.4900793731212616
[10/23] Train loss=0.41845470666885376
[15/23] Train loss=0.4591977298259735
[20/23] Train loss=0.4017387628555298
Test set avg_accuracy=73.74% avg_sensitivity=26.87%, avg_specificity=95.45% avg_auc=0.7512
Best model saved!! Metric=-54.81579465141083!!
Fold[3] Epoch: 5 [5/100 (5%)] Train loss=0.443920 Test loss=0.702829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.45008575916290283
[5/23] Train loss=0.4600967466831207
[10/23] Train loss=0.4022199213504791
[15/23] Train loss=0.46637439727783203
[20/23] Train loss=0.40154510736465454
Test set avg_accuracy=74.94% avg_sensitivity=30.85%, avg_specificity=95.36% avg_auc=0.7671
Best model saved!! Metric=-48.147298390782545!!
Fold[3] Epoch: 6 [6/100 (6%)] Train loss=0.433681 Test loss=0.693790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4431922733783722
[5/23] Train loss=0.4549412429332733
[10/23] Train loss=0.3965211510658264
[15/23] Train loss=0.4431453347206116
[20/23] Train loss=0.38904285430908203
Test set avg_accuracy=75.92% avg_sensitivity=34.53%, avg_specificity=95.08% avg_auc=0.7802
Best model saved!! Metric=-42.45525656588705!!
Fold[3] Epoch: 7 [7/100 (7%)] Train loss=0.424838 Test loss=0.637197 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4317288398742676
[5/23] Train loss=0.4403960108757019
[10/23] Train loss=0.3935161232948303
[15/23] Train loss=0.44736433029174805
[20/23] Train loss=0.38728609681129456
Test set avg_accuracy=76.43% avg_sensitivity=36.62%, avg_specificity=94.87% avg_auc=0.7940
Best model saved!! Metric=-38.67977331753449!!
Fold[3] Epoch: 8 [8/100 (8%)] Train loss=0.420215 Test loss=0.613730 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4418471157550812
[5/23] Train loss=0.43995165824890137
[10/23] Train loss=0.38309186697006226
[15/23] Train loss=0.4339241087436676
[20/23] Train loss=0.3801664113998413
Test set avg_accuracy=76.63% avg_sensitivity=37.41%, avg_specificity=94.79% avg_auc=0.8010
Best model saved!! Metric=-37.06591599015941!!
Fold[3] Epoch: 9 [9/100 (9%)] Train loss=0.415830 Test loss=0.598228 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43125471472740173
[5/23] Train loss=0.4338111877441406
[10/23] Train loss=0.37822872400283813
[15/23] Train loss=0.4268217980861664
[20/23] Train loss=0.3720358610153198
Test set avg_accuracy=77.12% avg_sensitivity=39.40%, avg_specificity=94.59% avg_auc=0.8085
Best model saved!! Metric=-34.030283367524014!!
Fold[3] Epoch: 10 [10/100 (10%)] Train loss=0.411779 Test loss=0.564025 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4255792200565338
[5/23] Train loss=0.43011218309402466
[10/23] Train loss=0.3741553723812103
[15/23] Train loss=0.4366809129714966
[20/23] Train loss=0.3735766112804413
Test set avg_accuracy=77.41% avg_sensitivity=40.83%, avg_specificity=94.35% avg_auc=0.8126
Best model saved!! Metric=-32.156312550483456!!
Fold[3] Epoch: 11 [11/100 (11%)] Train loss=0.408889 Test loss=0.559059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43000391125679016
[5/23] Train loss=0.42458468675613403
[10/23] Train loss=0.3721070885658264
[15/23] Train loss=0.42670801281929016
[20/23] Train loss=0.36655569076538086
Test set avg_accuracy=77.64% avg_sensitivity=42.12%, avg_specificity=94.09% avg_auc=0.8167
Best model saved!! Metric=-30.478703643026805!!
Fold[3] Epoch: 12 [12/100 (12%)] Train loss=0.404521 Test loss=0.541762 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4165927767753601
[5/23] Train loss=0.43316614627838135
[10/23] Train loss=0.36762771010398865
[15/23] Train loss=0.44631242752075195
[20/23] Train loss=0.36302027106285095
Test set avg_accuracy=77.63% avg_sensitivity=42.09%, avg_specificity=94.09% avg_auc=0.8202
Best model saved!! Metric=-30.177585810119112!!
Fold[3] Epoch: 13 [13/100 (13%)] Train loss=0.403622 Test loss=0.540086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4375765919685364
[5/23] Train loss=0.42460933327674866
[10/23] Train loss=0.3718661963939667
[15/23] Train loss=0.4258369505405426
[20/23] Train loss=0.3533734083175659
Test set avg_accuracy=77.76% avg_sensitivity=42.72%, avg_specificity=93.99% avg_auc=0.8168
Best model saved!! Metric=-29.843809766115932!!
Fold[3] Epoch: 14 [14/100 (14%)] Train loss=0.400841 Test loss=0.539946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41006284952163696
[5/23] Train loss=0.4281022250652313
[10/23] Train loss=0.3594658672809601
[15/23] Train loss=0.4375528395175934
[20/23] Train loss=0.3586205244064331
Test set avg_accuracy=77.52% avg_sensitivity=41.63%, avg_specificity=94.15% avg_auc=0.8196
Fold[3] Epoch: 15 [15/100 (15%)] Train loss=0.401652 Test loss=0.562926 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4088708460330963
[5/23] Train loss=0.4283563196659088
[10/23] Train loss=0.3682112991809845
[15/23] Train loss=0.42993661761283875
[20/23] Train loss=0.350157231092453
Test set avg_accuracy=77.05% avg_sensitivity=39.37%, avg_specificity=94.50% avg_auc=0.8112
Fold[3] Epoch: 16 [16/100 (16%)] Train loss=0.400496 Test loss=0.588754 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39293333888053894
[5/23] Train loss=0.42497357726097107
[10/23] Train loss=0.3889954686164856
[15/23] Train loss=0.40565893054008484
[20/23] Train loss=0.3510530889034271
Test set avg_accuracy=76.50% avg_sensitivity=37.65%, avg_specificity=94.50% avg_auc=0.8041
Fold[3] Epoch: 17 [17/100 (17%)] Train loss=0.399940 Test loss=0.629406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39438459277153015
[5/23] Train loss=0.4146568477153778
[10/23] Train loss=0.37849098443984985
[15/23] Train loss=0.393941193819046
[20/23] Train loss=0.34262189269065857
Test set avg_accuracy=77.25% avg_sensitivity=39.93%, avg_specificity=94.53% avg_auc=0.8080
Fold[3] Epoch: 18 [18/100 (18%)] Train loss=0.394820 Test loss=0.607451 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39533698558807373
[5/23] Train loss=0.4181326627731323
[10/23] Train loss=0.3559146225452423
[15/23] Train loss=0.3951842486858368
[20/23] Train loss=0.3439910411834717
Test set avg_accuracy=78.03% avg_sensitivity=43.95%, avg_specificity=93.81% avg_auc=0.8254
Best model saved!! Metric=-27.677653136400803!!
Fold[3] Epoch: 19 [19/100 (19%)] Train loss=0.386780 Test loss=0.555918 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4025369882583618
[5/23] Train loss=0.4186409115791321
[10/23] Train loss=0.3443259000778198
[15/23] Train loss=0.39768269658088684
[20/23] Train loss=0.34270790219306946
Test set avg_accuracy=78.14% avg_sensitivity=44.98%, avg_specificity=93.50% avg_auc=0.8285
Best model saved!! Metric=-26.534237585572207!!
Fold[3] Epoch: 20 [20/100 (20%)] Train loss=0.382212 Test loss=0.537336 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40235137939453125
[5/23] Train loss=0.40875962376594543
[10/23] Train loss=0.34919673204421997
[15/23] Train loss=0.3892004191875458
[20/23] Train loss=0.33685219287872314
Test set avg_accuracy=78.33% avg_sensitivity=46.63%, avg_specificity=93.01% avg_auc=0.8277
Best model saved!! Metric=-25.250800077530037!!
Fold[3] Epoch: 21 [21/100 (21%)] Train loss=0.379885 Test loss=0.534933 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39805662631988525
[5/23] Train loss=0.4110112488269806
[10/23] Train loss=0.35541170835494995
[15/23] Train loss=0.3872031569480896
[20/23] Train loss=0.3359124958515167
Test set avg_accuracy=77.93% avg_sensitivity=43.71%, avg_specificity=93.78% avg_auc=0.8232
Fold[3] Epoch: 22 [22/100 (22%)] Train loss=0.381738 Test loss=0.556583 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3771906793117523
[5/23] Train loss=0.41268202662467957
[10/23] Train loss=0.3659146726131439
[15/23] Train loss=0.38457873463630676
[20/23] Train loss=0.3439246416091919
Test set avg_accuracy=77.81% avg_sensitivity=42.16%, avg_specificity=94.32% avg_auc=0.8299
Fold[3] Epoch: 23 [23/100 (23%)] Train loss=0.382288 Test loss=0.576123 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37182340025901794
[5/23] Train loss=0.4037723243236542
[10/23] Train loss=0.35026267170906067
[15/23] Train loss=0.3797823488712311
[20/23] Train loss=0.33903568983078003
Test set avg_accuracy=77.45% avg_sensitivity=39.10%, avg_specificity=95.21% avg_auc=0.8318
Fold[3] Epoch: 24 [24/100 (24%)] Train loss=0.379573 Test loss=0.598966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3722406029701233
[5/23] Train loss=0.40671810507774353
[10/23] Train loss=0.35250821709632874
[15/23] Train loss=0.3692763149738312
[20/23] Train loss=0.34165143966674805
Test set avg_accuracy=78.18% avg_sensitivity=44.68%, avg_specificity=93.70% avg_auc=0.8404
Fold[3] Epoch: 25 [25/100 (25%)] Train loss=0.374976 Test loss=0.552154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37497493624687195
[5/23] Train loss=0.40498068928718567
[10/23] Train loss=0.3440523147583008
[15/23] Train loss=0.3653183579444885
[20/23] Train loss=0.32974493503570557
Test set avg_accuracy=78.05% avg_sensitivity=42.62%, avg_specificity=94.45% avg_auc=0.8401
Fold[3] Epoch: 26 [26/100 (26%)] Train loss=0.372992 Test loss=0.573977 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37031957507133484
[5/23] Train loss=0.4104364812374115
[10/23] Train loss=0.34159815311431885
[15/23] Train loss=0.3554736375808716
[20/23] Train loss=0.3218005895614624
Test set avg_accuracy=78.60% avg_sensitivity=45.70%, avg_specificity=93.84% avg_auc=0.8402
Best model saved!! Metric=-23.827411198058606!!
Fold[3] Epoch: 27 [27/100 (27%)] Train loss=0.369125 Test loss=0.555992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3719457685947418
[5/23] Train loss=0.3931281268596649
[10/23] Train loss=0.3307192623615265
[15/23] Train loss=0.36749619245529175
[20/23] Train loss=0.3175811469554901
Test set avg_accuracy=78.55% avg_sensitivity=45.47%, avg_specificity=93.87% avg_auc=0.8354
Fold[3] Epoch: 28 [28/100 (28%)] Train loss=0.365277 Test loss=0.549267 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36675676703453064
[5/23] Train loss=0.40114107728004456
[10/23] Train loss=0.33235231041908264
[15/23] Train loss=0.36049559712409973
[20/23] Train loss=0.316105455160141
Test set avg_accuracy=78.52% avg_sensitivity=45.61%, avg_specificity=93.76% avg_auc=0.8405
Fold[3] Epoch: 29 [29/100 (29%)] Train loss=0.361449 Test loss=0.553828 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3637547492980957
[5/23] Train loss=0.3949977457523346
[10/23] Train loss=0.32486552000045776
[15/23] Train loss=0.35607510805130005
[20/23] Train loss=0.3194274306297302
Test set avg_accuracy=78.58% avg_sensitivity=46.00%, avg_specificity=93.67% avg_auc=0.8449
Best model saved!! Metric=-23.253910505609852!!
Fold[3] Epoch: 30 [30/100 (30%)] Train loss=0.360972 Test loss=0.536549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3569123148918152
[5/23] Train loss=0.38901445269584656
[10/23] Train loss=0.3325045704841614
[15/23] Train loss=0.3535556197166443
[20/23] Train loss=0.317844420671463
Test set avg_accuracy=78.46% avg_sensitivity=45.41%, avg_specificity=93.76% avg_auc=0.8432
Fold[3] Epoch: 31 [31/100 (31%)] Train loss=0.357343 Test loss=0.562257 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.355089396238327
[5/23] Train loss=0.3952755928039551
[10/23] Train loss=0.32786640524864197
[15/23] Train loss=0.3337727189064026
[20/23] Train loss=0.3046601712703705
Test set avg_accuracy=78.97% avg_sensitivity=46.47%, avg_specificity=94.02% avg_auc=0.8413
Best model saved!! Metric=-22.408927077824156!!
Fold[3] Epoch: 32 [32/100 (32%)] Train loss=0.353054 Test loss=0.556536 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34709468483924866
[5/23] Train loss=0.39207398891448975
[10/23] Train loss=0.3139069676399231
[15/23] Train loss=0.34355488419532776
[20/23] Train loss=0.3054593801498413
Test set avg_accuracy=78.80% avg_sensitivity=45.64%, avg_specificity=94.16% avg_auc=0.8361
Fold[3] Epoch: 33 [33/100 (33%)] Train loss=0.350326 Test loss=0.549620 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34495842456817627
[5/23] Train loss=0.3929639458656311
[10/23] Train loss=0.30907636880874634
[15/23] Train loss=0.35076087713241577
[20/23] Train loss=0.3021199405193329
Test set avg_accuracy=79.19% avg_sensitivity=49.25%, avg_specificity=93.06% avg_auc=0.8435
Best model saved!! Metric=-20.149909523225833!!
Fold[3] Epoch: 34 [34/100 (34%)] Train loss=0.347824 Test loss=0.524832 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3537085950374603
[5/23] Train loss=0.3838772773742676
[10/23] Train loss=0.324552983045578
[15/23] Train loss=0.33511674404144287
[20/23] Train loss=0.30247339606285095
Test set avg_accuracy=78.86% avg_sensitivity=46.93%, avg_specificity=93.64% avg_auc=0.8459
Fold[3] Epoch: 35 [35/100 (35%)] Train loss=0.345331 Test loss=0.538143 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35376936197280884
[5/23] Train loss=0.3853820264339447
[10/23] Train loss=0.30820178985595703
[15/23] Train loss=0.33095744252204895
[20/23] Train loss=0.29858577251434326
Test set avg_accuracy=78.68% avg_sensitivity=46.17%, avg_specificity=93.73% avg_auc=0.8458
Fold[3] Epoch: 36 [36/100 (36%)] Train loss=0.343653 Test loss=0.535878 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3382563591003418
[5/23] Train loss=0.38334763050079346
[10/23] Train loss=0.3105980455875397
[15/23] Train loss=0.3381812870502472
[20/23] Train loss=0.2932482957839966
Test set avg_accuracy=78.68% avg_sensitivity=46.60%, avg_specificity=93.53% avg_auc=0.8413
Fold[3] Epoch: 37 [37/100 (37%)] Train loss=0.341732 Test loss=0.549746 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33810698986053467
[5/23] Train loss=0.38014140725135803
[10/23] Train loss=0.3097955882549286
[15/23] Train loss=0.32366490364074707
[20/23] Train loss=0.2843034267425537
Test set avg_accuracy=78.53% avg_sensitivity=45.34%, avg_specificity=93.90% avg_auc=0.8389
Fold[3] Epoch: 38 [38/100 (38%)] Train loss=0.339518 Test loss=0.552751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33887842297554016
[5/23] Train loss=0.3825753927230835
[10/23] Train loss=0.30293476581573486
[15/23] Train loss=0.3259483575820923
[20/23] Train loss=0.2933045029640198
Test set avg_accuracy=78.73% avg_sensitivity=47.10%, avg_specificity=93.38% avg_auc=0.8435
Fold[3] Epoch: 39 [39/100 (39%)] Train loss=0.336557 Test loss=0.541374 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34502315521240234
[5/23] Train loss=0.38135117292404175
[10/23] Train loss=0.3022342324256897
[15/23] Train loss=0.3339804410934448
[20/23] Train loss=0.2937712073326111
Test set avg_accuracy=78.88% avg_sensitivity=48.33%, avg_specificity=93.03% avg_auc=0.8465
Fold[3] Epoch: 40 [40/100 (40%)] Train loss=0.335328 Test loss=0.521991 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3401516079902649
[5/23] Train loss=0.3820236623287201
[10/23] Train loss=0.2981559634208679
[15/23] Train loss=0.3282042145729065
[20/23] Train loss=0.28692758083343506
Test set avg_accuracy=79.37% avg_sensitivity=51.01%, avg_specificity=92.50% avg_auc=0.8477
Best model saved!! Metric=-18.33993748695072!!
Fold[3] Epoch: 41 [41/100 (41%)] Train loss=0.329553 Test loss=0.510626 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3244052529335022
[5/23] Train loss=0.3693406581878662
[10/23] Train loss=0.29443004727363586
[15/23] Train loss=0.3127448558807373
[20/23] Train loss=0.28455498814582825
Test set avg_accuracy=79.42% avg_sensitivity=50.71%, avg_specificity=92.72% avg_auc=0.8461
Fold[3] Epoch: 42 [42/100 (42%)] Train loss=0.326584 Test loss=0.515709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32671332359313965
[5/23] Train loss=0.3703632056713104
[10/23] Train loss=0.29248881340026855
[15/23] Train loss=0.3304535150527954
[20/23] Train loss=0.28218328952789307
Test set avg_accuracy=79.35% avg_sensitivity=50.32%, avg_specificity=92.80% avg_auc=0.8470
Fold[3] Epoch: 43 [43/100 (43%)] Train loss=0.325285 Test loss=0.515609 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31939178705215454
[5/23] Train loss=0.36811181902885437
[10/23] Train loss=0.28882601857185364
[15/23] Train loss=0.3042210340499878
[20/23] Train loss=0.2845146656036377
Test set avg_accuracy=78.74% avg_sensitivity=47.00%, avg_specificity=93.44% avg_auc=0.8471
Fold[3] Epoch: 44 [44/100 (44%)] Train loss=0.324496 Test loss=0.529602 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3231422007083893
[5/23] Train loss=0.3646456003189087
[10/23] Train loss=0.2919665277004242
[15/23] Train loss=0.31391197443008423
[20/23] Train loss=0.2865222096443176
Test set avg_accuracy=77.94% avg_sensitivity=43.05%, avg_specificity=94.10% avg_auc=0.8418
Fold[3] Epoch: 45 [45/100 (45%)] Train loss=0.324439 Test loss=0.564930 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31391674280166626
[5/23] Train loss=0.36066383123397827
[10/23] Train loss=0.28493770956993103
[15/23] Train loss=0.29811134934425354
[20/23] Train loss=0.2739531397819519
Test set avg_accuracy=78.39% avg_sensitivity=44.71%, avg_specificity=93.99% avg_auc=0.8429
Fold[3] Epoch: 46 [46/100 (46%)] Train loss=0.320088 Test loss=0.562500 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30825406312942505
[5/23] Train loss=0.36610743403434753
[10/23] Train loss=0.28545230627059937
[15/23] Train loss=0.31147608160972595
[20/23] Train loss=0.27748817205429077
Test set avg_accuracy=79.06% avg_sensitivity=47.46%, avg_specificity=93.69% avg_auc=0.8431
Fold[3] Epoch: 47 [47/100 (47%)] Train loss=0.316685 Test loss=0.529462 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32216715812683105
[5/23] Train loss=0.35535940527915955
[10/23] Train loss=0.2782174050807953
[15/23] Train loss=0.3015822172164917
[20/23] Train loss=0.27467551827430725
Test set avg_accuracy=79.02% avg_sensitivity=47.20%, avg_specificity=93.76% avg_auc=0.8471
Fold[3] Epoch: 48 [48/100 (48%)] Train loss=0.315810 Test loss=0.534083 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3097192943096161
[5/23] Train loss=0.35392022132873535
[10/23] Train loss=0.27684712409973145
[15/23] Train loss=0.3066602051258087
[20/23] Train loss=0.2614918351173401
Test set avg_accuracy=79.85% avg_sensitivity=53.50%, avg_specificity=92.06% avg_auc=0.8501
Best model saved!! Metric=-15.577692894310218!!
Fold[3] Epoch: 49 [49/100 (49%)] Train loss=0.310557 Test loss=0.504140 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3267693519592285
[5/23] Train loss=0.3503176271915436
[10/23] Train loss=0.27117735147476196
[15/23] Train loss=0.30184775590896606
[20/23] Train loss=0.2705831229686737
Test set avg_accuracy=79.39% avg_sensitivity=50.55%, avg_specificity=92.75% avg_auc=0.8473
Fold[3] Epoch: 50 [50/100 (50%)] Train loss=0.307193 Test loss=0.517966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30586421489715576
[5/23] Train loss=0.3536961078643799
[10/23] Train loss=0.2751002907752991
[15/23] Train loss=0.2925465404987335
[20/23] Train loss=0.2688506841659546
Test set avg_accuracy=78.95% avg_sensitivity=48.56%, avg_specificity=93.03% avg_auc=0.8446
Fold[3] Epoch: 51 [51/100 (51%)] Train loss=0.305846 Test loss=0.533314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2999662160873413
[5/23] Train loss=0.3485577702522278
[10/23] Train loss=0.27424541115760803
[15/23] Train loss=0.2873085141181946
[20/23] Train loss=0.2691529393196106
Test set avg_accuracy=78.68% avg_sensitivity=47.89%, avg_specificity=92.93% avg_auc=0.8449
Fold[3] Epoch: 52 [52/100 (52%)] Train loss=0.304990 Test loss=0.538872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29551416635513306
[5/23] Train loss=0.3426100015640259
[10/23] Train loss=0.2738690674304962
[15/23] Train loss=0.28246551752090454
[20/23] Train loss=0.26878365874290466
Test set avg_accuracy=78.18% avg_sensitivity=44.18%, avg_specificity=93.93% avg_auc=0.8416
Fold[3] Epoch: 53 [53/100 (53%)] Train loss=0.304134 Test loss=0.561894 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2894939184188843
[5/23] Train loss=0.3520576059818268
[10/23] Train loss=0.27611014246940613
[15/23] Train loss=0.28696125745773315
[20/23] Train loss=0.2589417099952698
Test set avg_accuracy=78.78% avg_sensitivity=46.93%, avg_specificity=93.53% avg_auc=0.8461
Fold[3] Epoch: 54 [54/100 (54%)] Train loss=0.300347 Test loss=0.532944 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2916673719882965
[5/23] Train loss=0.3495211899280548
[10/23] Train loss=0.2618173360824585
[15/23] Train loss=0.289237916469574
[20/23] Train loss=0.2614154815673828
Test set avg_accuracy=78.71% avg_sensitivity=47.06%, avg_specificity=93.36% avg_auc=0.8466
Fold[3] Epoch: 55 [55/100 (55%)] Train loss=0.299816 Test loss=0.534187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28721126914024353
[5/23] Train loss=0.34359118342399597
[10/23] Train loss=0.2595065236091614
[15/23] Train loss=0.28247785568237305
[20/23] Train loss=0.2586512863636017
Test set avg_accuracy=79.22% avg_sensitivity=50.85%, avg_specificity=92.37% avg_auc=0.8416
Fold[3] Epoch: 56 [56/100 (56%)] Train loss=0.293351 Test loss=0.511709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30036860704421997
[5/23] Train loss=0.34034672379493713
[10/23] Train loss=0.2587468922138214
[15/23] Train loss=0.28313279151916504
[20/23] Train loss=0.25330761075019836
Test set avg_accuracy=79.51% avg_sensitivity=52.17%, avg_specificity=92.17% avg_auc=0.8482
Fold[3] Epoch: 57 [57/100 (57%)] Train loss=0.292881 Test loss=0.514827 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28986257314682007
[5/23] Train loss=0.3362423777580261
[10/23] Train loss=0.25693637132644653
[15/23] Train loss=0.2819032073020935
[20/23] Train loss=0.25045374035835266
Test set avg_accuracy=79.21% avg_sensitivity=50.85%, avg_specificity=92.35% avg_auc=0.8424
Fold[3] Epoch: 58 [58/100 (58%)] Train loss=0.288216 Test loss=0.513517 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30123522877693176
[5/23] Train loss=0.3325166404247284
[10/23] Train loss=0.24871592223644257
[15/23] Train loss=0.2785891592502594
[20/23] Train loss=0.24458187818527222
Test set avg_accuracy=79.14% avg_sensitivity=49.88%, avg_specificity=92.69% avg_auc=0.8450
Fold[3] Epoch: 59 [59/100 (59%)] Train loss=0.287741 Test loss=0.525432 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2873010039329529
[5/23] Train loss=0.33166515827178955
[10/23] Train loss=0.26540857553482056
[15/23] Train loss=0.27598288655281067
[20/23] Train loss=0.2572540044784546
Test set avg_accuracy=78.15% avg_sensitivity=45.80%, avg_specificity=93.13% avg_auc=0.8409
Fold[3] Epoch: 60 [60/100 (60%)] Train loss=0.288952 Test loss=0.560712 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2769472301006317
[5/23] Train loss=0.32972386479377747
[10/23] Train loss=0.2452586144208908
[15/23] Train loss=0.2637857496738434
[20/23] Train loss=0.2418014109134674
Test set avg_accuracy=78.17% avg_sensitivity=45.61%, avg_specificity=93.26% avg_auc=0.8399
Fold[3] Epoch: 61 [61/100 (61%)] Train loss=0.282297 Test loss=0.566713 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26802146434783936
[5/23] Train loss=0.32339781522750854
[10/23] Train loss=0.24731871485710144
[15/23] Train loss=0.28641632199287415
[20/23] Train loss=0.2609586715698242
Test set avg_accuracy=77.63% avg_sensitivity=41.86%, avg_specificity=94.19% avg_auc=0.8373
Fold[3] Epoch: 62 [62/100 (62%)] Train loss=0.290194 Test loss=0.581327 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.290779709815979
[5/23] Train loss=0.35776418447494507
[10/23] Train loss=0.24488241970539093
[15/23] Train loss=0.29441285133361816
[20/23] Train loss=0.2478908896446228
Test set avg_accuracy=80.10% avg_sensitivity=59.67%, avg_specificity=89.57% avg_auc=0.8436
Best model saved!! Metric=-12.299732995580674!!
Fold[3] Epoch: 63 [63/100 (63%)] Train loss=0.292557 Test loss=0.499841 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3025375306606293
[5/23] Train loss=0.3341945707798004
[10/23] Train loss=0.26076361536979675
[15/23] Train loss=0.27476558089256287
[20/23] Train loss=0.25510409474372864
Test set avg_accuracy=78.56% avg_sensitivity=47.16%, avg_specificity=93.10% avg_auc=0.8413
Fold[3] Epoch: 64 [64/100 (64%)] Train loss=0.290513 Test loss=0.548113 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27980437874794006
[5/23] Train loss=0.3328222334384918
[10/23] Train loss=0.25636374950408936
[15/23] Train loss=0.26694104075431824
[20/23] Train loss=0.25354060530662537
Test set avg_accuracy=78.89% avg_sensitivity=51.77%, avg_specificity=91.44% avg_auc=0.8449
Fold[3] Epoch: 65 [65/100 (65%)] Train loss=0.283711 Test loss=0.537070 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27252286672592163
[5/23] Train loss=0.31594622135162354
[10/23] Train loss=0.2535184919834137
[15/23] Train loss=0.26417094469070435
[20/23] Train loss=0.23814739286899567
Test set avg_accuracy=78.78% avg_sensitivity=51.97%, avg_specificity=91.20% avg_auc=0.8428
Fold[3] Epoch: 66 [66/100 (66%)] Train loss=0.277231 Test loss=0.547564 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2739683985710144
[5/23] Train loss=0.3208449184894562
[10/23] Train loss=0.24140098690986633
[15/23] Train loss=0.2645021677017212
[20/23] Train loss=0.24360646307468414
Test set avg_accuracy=78.96% avg_sensitivity=51.51%, avg_specificity=91.67% avg_auc=0.8425
Fold[3] Epoch: 67 [67/100 (67%)] Train loss=0.274423 Test loss=0.537303 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26514336466789246
[5/23] Train loss=0.32692137360572815
[10/23] Train loss=0.233143150806427
[15/23] Train loss=0.2686273753643036
[20/23] Train loss=0.24325008690357208
Test set avg_accuracy=79.11% avg_sensitivity=50.51%, avg_specificity=92.35% avg_auc=0.8409
Fold[3] Epoch: 68 [68/100 (68%)] Train loss=0.271015 Test loss=0.540749 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2647440731525421
[5/23] Train loss=0.31930965185165405
[10/23] Train loss=0.2422553151845932
[15/23] Train loss=0.2512906789779663
[20/23] Train loss=0.2321101278066635
Test set avg_accuracy=79.04% avg_sensitivity=52.24%, avg_specificity=91.46% avg_auc=0.8418
Fold[3] Epoch: 69 [69/100 (69%)] Train loss=0.265622 Test loss=0.540501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26240861415863037
[5/23] Train loss=0.3058021664619446
[10/23] Train loss=0.23804280161857605
[15/23] Train loss=0.23845815658569336
[20/23] Train loss=0.2376183122396469
Test set avg_accuracy=78.97% avg_sensitivity=50.71%, avg_specificity=92.06% avg_auc=0.8421
Fold[3] Epoch: 70 [70/100 (70%)] Train loss=0.263041 Test loss=0.550244 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2599758207798004
[5/23] Train loss=0.31828516721725464
[10/23] Train loss=0.22805699706077576
[15/23] Train loss=0.24044281244277954
[20/23] Train loss=0.23685215413570404
Test set avg_accuracy=79.03% avg_sensitivity=52.01%, avg_specificity=91.55% avg_auc=0.8431
Fold[3] Epoch: 71 [71/100 (71%)] Train loss=0.261631 Test loss=0.544059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2631749212741852
[5/23] Train loss=0.3091982901096344
[10/23] Train loss=0.22855766117572784
[15/23] Train loss=0.24538874626159668
[20/23] Train loss=0.2311614602804184
Test set avg_accuracy=78.89% avg_sensitivity=50.22%, avg_specificity=92.17% avg_auc=0.8389
Fold[3] Epoch: 72 [72/100 (72%)] Train loss=0.256616 Test loss=0.551075 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25272902846336365
[5/23] Train loss=0.30904245376586914
[10/23] Train loss=0.23030567169189453
[15/23] Train loss=0.24756388366222382
[20/23] Train loss=0.22479774057865143
Test set avg_accuracy=78.70% avg_sensitivity=49.68%, avg_specificity=92.14% avg_auc=0.8354
Fold[3] Epoch: 73 [73/100 (73%)] Train loss=0.255473 Test loss=0.556180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2482331097126007
[5/23] Train loss=0.31047362089157104
[10/23] Train loss=0.23503002524375916
[15/23] Train loss=0.24071820080280304
[20/23] Train loss=0.23901522159576416
Test set avg_accuracy=78.60% avg_sensitivity=48.92%, avg_specificity=92.35% avg_auc=0.8424
Fold[3] Epoch: 74 [74/100 (74%)] Train loss=0.257150 Test loss=0.569576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24814489483833313
[5/23] Train loss=0.29377689957618713
[10/23] Train loss=0.22076568007469177
[15/23] Train loss=0.2347647249698639
[20/23] Train loss=0.22626206278800964
Test set avg_accuracy=78.47% avg_sensitivity=49.42%, avg_specificity=91.92% avg_auc=0.8389
Fold[3] Epoch: 75 [75/100 (75%)] Train loss=0.249140 Test loss=0.563210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2368696630001068
[5/23] Train loss=0.3126203119754791
[10/23] Train loss=0.22633051872253418
[15/23] Train loss=0.22951388359069824
[20/23] Train loss=0.22392062842845917
Test set avg_accuracy=78.35% avg_sensitivity=47.83%, avg_specificity=92.49% avg_auc=0.8375
Fold[3] Epoch: 76 [76/100 (76%)] Train loss=0.249313 Test loss=0.571942 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23645640909671783
[5/23] Train loss=0.2935605049133301
[10/23] Train loss=0.22017908096313477
[15/23] Train loss=0.234837606549263
[20/23] Train loss=0.21736305952072144
Test set avg_accuracy=78.73% avg_sensitivity=49.22%, avg_specificity=92.40% avg_auc=0.8385
Fold[3] Epoch: 77 [77/100 (77%)] Train loss=0.245248 Test loss=0.557956 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23461419343948364
[5/23] Train loss=0.30005398392677307
[10/23] Train loss=0.22224701941013336
[15/23] Train loss=0.2310403436422348
[20/23] Train loss=0.22160758078098297
Test set avg_accuracy=78.57% avg_sensitivity=49.22%, avg_specificity=92.17% avg_auc=0.8366
Fold[3] Epoch: 78 [78/100 (78%)] Train loss=0.244602 Test loss=0.563430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23818328976631165
[5/23] Train loss=0.2939421534538269
[10/23] Train loss=0.21138900518417358
[15/23] Train loss=0.22711381316184998
[20/23] Train loss=0.21436528861522675
Test set avg_accuracy=78.94% avg_sensitivity=50.98%, avg_specificity=91.89% avg_auc=0.8344
Fold[3] Epoch: 79 [79/100 (79%)] Train loss=0.243331 Test loss=0.562311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.237090066075325
[5/23] Train loss=0.289844274520874
[10/23] Train loss=0.2146105170249939
[15/23] Train loss=0.22545646131038666
[20/23] Train loss=0.21165278553962708
Test set avg_accuracy=78.68% avg_sensitivity=49.22%, avg_specificity=92.32% avg_auc=0.8309
Fold[3] Epoch: 80 [80/100 (80%)] Train loss=0.238109 Test loss=0.560750 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23266994953155518
[5/23] Train loss=0.2894934117794037
[10/23] Train loss=0.2132532149553299
[15/23] Train loss=0.22855430841445923
[20/23] Train loss=0.21570809185504913
Test set avg_accuracy=78.52% avg_sensitivity=50.32%, avg_specificity=91.58% avg_auc=0.8305
Fold[3] Epoch: 81 [81/100 (81%)] Train loss=0.238146 Test loss=0.585368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23449024558067322
[5/23] Train loss=0.28859296441078186
[10/23] Train loss=0.21369048953056335
[15/23] Train loss=0.22144797444343567
[20/23] Train loss=0.21698592603206635
Test set avg_accuracy=78.40% avg_sensitivity=49.65%, avg_specificity=91.72% avg_auc=0.8351
Fold[3] Epoch: 82 [82/100 (82%)] Train loss=0.239432 Test loss=0.563625 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24085141718387604
[5/23] Train loss=0.29181259870529175
[10/23] Train loss=0.2022494077682495
[15/23] Train loss=0.22010637819766998
[20/23] Train loss=0.21041645109653473
Test set avg_accuracy=79.03% avg_sensitivity=56.58%, avg_specificity=89.43% avg_auc=0.8339
Fold[3] Epoch: 83 [83/100 (83%)] Train loss=0.232261 Test loss=0.562173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21774347126483917
[5/23] Train loss=0.2743246555328369
[10/23] Train loss=0.21686919033527374
[15/23] Train loss=0.23038823902606964
[20/23] Train loss=0.20638196170330048
Test set avg_accuracy=78.85% avg_sensitivity=51.44%, avg_specificity=91.54% avg_auc=0.8321
Fold[3] Epoch: 84 [84/100 (84%)] Train loss=0.231800 Test loss=0.571761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21938931941986084
[5/23] Train loss=0.2768658399581909
[10/23] Train loss=0.21127814054489136
[15/23] Train loss=0.2146085947751999
[20/23] Train loss=0.2093481421470642
Test set avg_accuracy=78.76% avg_sensitivity=50.81%, avg_specificity=91.71% avg_auc=0.8323
Fold[3] Epoch: 85 [85/100 (85%)] Train loss=0.229561 Test loss=0.577963 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21445497870445251
[5/23] Train loss=0.2748299539089203
[10/23] Train loss=0.21368849277496338
[15/23] Train loss=0.2103746384382248
[20/23] Train loss=0.20614230632781982
Test set avg_accuracy=78.48% avg_sensitivity=48.96%, avg_specificity=92.15% avg_auc=0.8360
Fold[3] Epoch: 86 [86/100 (86%)] Train loss=0.230061 Test loss=0.593613 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22035513818264008
[5/23] Train loss=0.28565123677253723
[10/23] Train loss=0.21478818356990814
[15/23] Train loss=0.21114031970500946
[20/23] Train loss=0.20095418393611908
Test set avg_accuracy=78.17% avg_sensitivity=48.56%, avg_specificity=91.89% avg_auc=0.8307
Fold[3] Epoch: 87 [87/100 (87%)] Train loss=0.227912 Test loss=0.613717 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20759700238704681
[5/23] Train loss=0.2743335962295532
[10/23] Train loss=0.20220685005187988
[15/23] Train loss=0.20683299005031586
[20/23] Train loss=0.2073609083890915
Test set avg_accuracy=78.73% avg_sensitivity=48.76%, avg_specificity=92.61% avg_auc=0.8325
Fold[3] Epoch: 88 [88/100 (88%)] Train loss=0.223750 Test loss=0.614936 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2172510325908661
[5/23] Train loss=0.27696529030799866
[10/23] Train loss=0.19482961297035217
[15/23] Train loss=0.20392431318759918
[20/23] Train loss=0.19889259338378906
Test set avg_accuracy=78.31% avg_sensitivity=47.10%, avg_specificity=92.76% avg_auc=0.8240
Fold[3] Epoch: 89 [89/100 (89%)] Train loss=0.224047 Test loss=0.614435 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21053819358348846
[5/23] Train loss=0.2725454568862915
[10/23] Train loss=0.20267733931541443
[15/23] Train loss=0.20503361523151398
[20/23] Train loss=0.19377219676971436
Test set avg_accuracy=78.27% avg_sensitivity=48.06%, avg_specificity=92.26% avg_auc=0.8303
Fold[3] Epoch: 90 [90/100 (90%)] Train loss=0.218436 Test loss=0.601286 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21369700133800507
[5/23] Train loss=0.2858130931854248
[10/23] Train loss=0.19218306243419647
[15/23] Train loss=0.2074355185031891
[20/23] Train loss=0.1965934783220291
Test set avg_accuracy=79.29% avg_sensitivity=52.57%, avg_specificity=91.66% avg_auc=0.8311
Fold[3] Epoch: 91 [91/100 (91%)] Train loss=0.219772 Test loss=0.581082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21071195602416992
[5/23] Train loss=0.27272987365722656
[10/23] Train loss=0.19268065690994263
[15/23] Train loss=0.19185180962085724
[20/23] Train loss=0.20435841381549835
Test set avg_accuracy=78.71% avg_sensitivity=51.84%, avg_specificity=91.15% avg_auc=0.8176
Fold[3] Epoch: 92 [92/100 (92%)] Train loss=0.215758 Test loss=0.588810 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20425273478031158
[5/23] Train loss=0.2616395950317383
[10/23] Train loss=0.18864378333091736
[15/23] Train loss=0.20151130855083466
[20/23] Train loss=0.1875288188457489
Test set avg_accuracy=78.72% avg_sensitivity=53.43%, avg_specificity=90.43% avg_auc=0.8325
Fold[3] Epoch: 93 [93/100 (93%)] Train loss=0.214864 Test loss=0.604966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20006966590881348
[5/23] Train loss=0.27877259254455566
[10/23] Train loss=0.19315041601657867
[15/23] Train loss=0.18299412727355957
[20/23] Train loss=0.19259871542453766
Test set avg_accuracy=78.59% avg_sensitivity=51.11%, avg_specificity=91.32% avg_auc=0.8182
Fold[3] Epoch: 94 [94/100 (94%)] Train loss=0.212712 Test loss=0.599296 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20418918132781982
[5/23] Train loss=0.2593924403190613
[10/23] Train loss=0.19867245852947235
[15/23] Train loss=0.21494616568088531
[20/23] Train loss=0.19605565071105957
Test set avg_accuracy=78.90% avg_sensitivity=52.87%, avg_specificity=90.95% avg_auc=0.8371
Fold[3] Epoch: 95 [95/100 (95%)] Train loss=0.212578 Test loss=0.621869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20061340928077698
[5/23] Train loss=0.2532273232936859
[10/23] Train loss=0.18432176113128662
[15/23] Train loss=0.18704503774642944
[20/23] Train loss=0.19833366572856903
Test set avg_accuracy=78.69% avg_sensitivity=51.67%, avg_specificity=91.20% avg_auc=0.8334
Fold[3] Epoch: 96 [96/100 (96%)] Train loss=0.206094 Test loss=0.617048 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19170962274074554
[5/23] Train loss=0.25617483258247375
[10/23] Train loss=0.20058634877204895
[15/23] Train loss=0.1908346712589264
[20/23] Train loss=0.19237898290157318
Test set avg_accuracy=78.13% avg_sensitivity=48.42%, avg_specificity=91.89% avg_auc=0.8277
Fold[3] Epoch: 97 [97/100 (97%)] Train loss=0.206989 Test loss=0.650110 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18938568234443665
[5/23] Train loss=0.26552361249923706
[10/23] Train loss=0.193901926279068
[15/23] Train loss=0.19549442827701569
[20/23] Train loss=0.19730181992053986
Test set avg_accuracy=78.20% avg_sensitivity=49.65%, avg_specificity=91.43% avg_auc=0.8156
Fold[3] Epoch: 98 [98/100 (98%)] Train loss=0.208691 Test loss=0.609389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22985431551933289
[5/23] Train loss=0.2600615620613098
[10/23] Train loss=0.19068259000778198
[15/23] Train loss=0.17944984138011932
[20/23] Train loss=0.19430668652057648
Test set avg_accuracy=77.83% avg_sensitivity=45.11%, avg_specificity=92.98% avg_auc=0.8181
Fold[3] Epoch: 99 [99/100 (99%)] Train loss=0.208984 Test loss=0.639180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19711089134216309
[5/23] Train loss=0.248960480093956
[10/23] Train loss=0.18002577126026154
[15/23] Train loss=0.20300836861133575
[20/23] Train loss=0.17809146642684937
Test set avg_accuracy=78.71% avg_sensitivity=51.11%, avg_specificity=91.49% avg_auc=0.8189
Fold[3] Epoch: 100 [100/100 (100%)] Train loss=0.202484 Test loss=0.616584 Current lr=[3.9999999999999996e-05]

Fold[3] Best Result: acc=80.10498687664041 sen=59.66832504145937, spe=89.56989247311829, auc=0.8435706261320126!
[0/23] Train loss=0.6932954788208008
[5/23] Train loss=0.6643271446228027
[10/23] Train loss=0.5960084199905396
[15/23] Train loss=0.5495848059654236
[20/23] Train loss=0.5324696898460388
Test set avg_accuracy=75.73% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5793
Best model saved!! Metric=-92.34080842176152!!
Fold[4] Epoch: 1 [1/100 (1%)] Train loss=0.582586 Test loss=0.620777 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5796974897384644
[5/23] Train loss=0.5873100757598877
[10/23] Train loss=0.5523675084114075
[15/23] Train loss=0.5286465883255005
[20/23] Train loss=0.5027782320976257
Test set avg_accuracy=76.01% avg_sensitivity=3.49%, avg_specificity=99.25% avg_auc=0.6094
Best model saved!! Metric=-86.30216619693005!!
Fold[4] Epoch: 2 [2/100 (2%)] Train loss=0.546673 Test loss=0.587636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5574501752853394
[5/23] Train loss=0.5579125285148621
[10/23] Train loss=0.5155957341194153
[15/23] Train loss=0.5047600865364075
[20/23] Train loss=0.46459048986434937
Test set avg_accuracy=76.13% avg_sensitivity=13.80%, avg_specificity=96.10% avg_auc=0.6665
Best model saved!! Metric=-73.31680813209964!!
Fold[4] Epoch: 3 [3/100 (3%)] Train loss=0.518994 Test loss=0.562907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5238608717918396
[5/23] Train loss=0.4991486966609955
[10/23] Train loss=0.47210976481437683
[15/23] Train loss=0.4739711582660675
[20/23] Train loss=0.41770967841148376
Test set avg_accuracy=76.26% avg_sensitivity=20.78%, avg_specificity=94.04% avg_auc=0.7193
Best model saved!! Metric=-62.97371549810521!!
Fold[4] Epoch: 4 [4/100 (4%)] Train loss=0.483323 Test loss=0.557677 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48711657524108887
[5/23] Train loss=0.4592196047306061
[10/23] Train loss=0.432673841714859
[15/23] Train loss=0.4579989016056061
[20/23] Train loss=0.399813711643219
Test set avg_accuracy=77.22% avg_sensitivity=26.87%, avg_specificity=93.35% avg_auc=0.7620
Best model saved!! Metric=-52.36841091225056!!
Fold[4] Epoch: 5 [5/100 (5%)] Train loss=0.457098 Test loss=0.528476 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4651736915111542
[5/23] Train loss=0.45032140612602234
[10/23] Train loss=0.40678104758262634
[15/23] Train loss=0.4427087604999542
[20/23] Train loss=0.3991752564907074
Test set avg_accuracy=78.41% avg_sensitivity=33.55%, avg_specificity=92.79% avg_auc=0.7914
Best model saved!! Metric=-42.11840959941062!!
Fold[4] Epoch: 6 [6/100 (6%)] Train loss=0.444336 Test loss=0.490900 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4488678276538849
[5/23] Train loss=0.44298118352890015
[10/23] Train loss=0.40023690462112427
[15/23] Train loss=0.43675535917282104
[20/23] Train loss=0.39115720987319946
Test set avg_accuracy=79.05% avg_sensitivity=37.56%, avg_specificity=92.34% avg_auc=0.8084
Best model saved!! Metric=-36.2105603729438!!
Fold[4] Epoch: 7 [7/100 (7%)] Train loss=0.436709 Test loss=0.463973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4473978281021118
[5/23] Train loss=0.43443939089775085
[10/23] Train loss=0.3921475112438202
[15/23] Train loss=0.43311482667922974
[20/23] Train loss=0.38126277923583984
Test set avg_accuracy=79.39% avg_sensitivity=39.59%, avg_specificity=92.15% avg_auc=0.8093
Best model saved!! Metric=-33.94507794674444!!
Fold[4] Epoch: 8 [8/100 (8%)] Train loss=0.431162 Test loss=0.457532 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43913182616233826
[5/23] Train loss=0.4333471357822418
[10/23] Train loss=0.3827787935733795
[15/23] Train loss=0.4345833659172058
[20/23] Train loss=0.37406647205352783
Test set avg_accuracy=79.50% avg_sensitivity=39.76%, avg_specificity=92.23% avg_auc=0.8169
Best model saved!! Metric=-32.823000493469536!!
Fold[4] Epoch: 9 [9/100 (9%)] Train loss=0.427308 Test loss=0.458916 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42899876832962036
[5/23] Train loss=0.43393272161483765
[10/23] Train loss=0.3762364089488983
[15/23] Train loss=0.418110191822052
[20/23] Train loss=0.3679813742637634
Test set avg_accuracy=79.61% avg_sensitivity=38.38%, avg_specificity=92.83% avg_auc=0.8168
Fold[4] Epoch: 10 [10/100 (10%)] Train loss=0.424458 Test loss=0.480451 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41596898436546326
[5/23] Train loss=0.43150585889816284
[10/23] Train loss=0.39316755533218384
[15/23] Train loss=0.40658557415008545
[20/23] Train loss=0.3713741600513458
Test set avg_accuracy=79.70% avg_sensitivity=37.65%, avg_specificity=93.17% avg_auc=0.8158
Fold[4] Epoch: 11 [11/100 (11%)] Train loss=0.422611 Test loss=0.496010 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4110148847103119
[5/23] Train loss=0.4204722046852112
[10/23] Train loss=0.39252591133117676
[15/23] Train loss=0.3997536897659302
[20/23] Train loss=0.3611052632331848
Test set avg_accuracy=79.92% avg_sensitivity=40.92%, avg_specificity=92.41% avg_auc=0.8270
Best model saved!! Metric=-30.0502009780502!!
Fold[4] Epoch: 12 [12/100 (12%)] Train loss=0.416615 Test loss=0.469705 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40468594431877136
[5/23] Train loss=0.4085426926612854
[10/23] Train loss=0.37167593836784363
[15/23] Train loss=0.38753533363342285
[20/23] Train loss=0.35973039269447327
Test set avg_accuracy=80.16% avg_sensitivity=43.73%, avg_specificity=91.83% avg_auc=0.8351
Best model saved!! Metric=-26.775666996820533!!
Fold[4] Epoch: 13 [13/100 (13%)] Train loss=0.407577 Test loss=0.452096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4072008430957794
[5/23] Train loss=0.40840908885002136
[10/23] Train loss=0.36955422163009644
[15/23] Train loss=0.39119353890419006
[20/23] Train loss=0.3491255044937134
Test set avg_accuracy=80.43% avg_sensitivity=45.19%, avg_specificity=91.72% avg_auc=0.8433
Best model saved!! Metric=-24.32768020032355!!
Fold[4] Epoch: 14 [14/100 (14%)] Train loss=0.404385 Test loss=0.431053 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4007200002670288
[5/23] Train loss=0.40939515829086304
[10/23] Train loss=0.36288899183273315
[15/23] Train loss=0.39471322298049927
[20/23] Train loss=0.3518781363964081
Test set avg_accuracy=80.49% avg_sensitivity=45.19%, avg_specificity=91.80% avg_auc=0.8435
Best model saved!! Metric=-24.166338652017824!!
Fold[4] Epoch: 15 [15/100 (15%)] Train loss=0.403875 Test loss=0.432538 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40129411220550537
[5/23] Train loss=0.40581873059272766
[10/23] Train loss=0.3590024709701538
[15/23] Train loss=0.3757128417491913
[20/23] Train loss=0.34236863255500793
Test set avg_accuracy=80.63% avg_sensitivity=46.05%, avg_specificity=91.71% avg_auc=0.8423
Best model saved!! Metric=-23.38062895623827!!
Fold[4] Epoch: 16 [16/100 (16%)] Train loss=0.398565 Test loss=0.435688 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4015933573246002
[5/23] Train loss=0.39877089858055115
[10/23] Train loss=0.3543793559074402
[15/23] Train loss=0.3804199993610382
[20/23] Train loss=0.33882060647010803
Test set avg_accuracy=80.93% avg_sensitivity=47.87%, avg_specificity=91.53% avg_auc=0.8521
Best model saved!! Metric=-20.46795970855124!!
Fold[4] Epoch: 17 [17/100 (17%)] Train loss=0.397348 Test loss=0.411946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40138185024261475
[5/23] Train loss=0.3995136618614197
[10/23] Train loss=0.3524639308452606
[15/23] Train loss=0.37443241477012634
[20/23] Train loss=0.33718612790107727
Test set avg_accuracy=80.94% avg_sensitivity=48.12%, avg_specificity=91.46% avg_auc=0.8493
Fold[4] Epoch: 18 [18/100 (18%)] Train loss=0.396864 Test loss=0.417410 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38950350880622864
[5/23] Train loss=0.3943549394607544
[10/23] Train loss=0.3527069687843323
[15/23] Train loss=0.3623097240924835
[20/23] Train loss=0.3365504741668701
Test set avg_accuracy=80.75% avg_sensitivity=46.74%, avg_specificity=91.65% avg_auc=0.8491
Fold[4] Epoch: 19 [19/100 (19%)] Train loss=0.393080 Test loss=0.424968 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3901427686214447
[5/23] Train loss=0.38297519087791443
[10/23] Train loss=0.34816139936447144
[15/23] Train loss=0.3572164475917816
[20/23] Train loss=0.33495497703552246
Test set avg_accuracy=80.88% avg_sensitivity=47.05%, avg_specificity=91.72% avg_auc=0.8533
Fold[4] Epoch: 20 [20/100 (20%)] Train loss=0.389974 Test loss=0.422349 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3757238984107971
[5/23] Train loss=0.38420698046684265
[10/23] Train loss=0.34799280762672424
[15/23] Train loss=0.36616799235343933
[20/23] Train loss=0.331302672624588
Test set avg_accuracy=80.81% avg_sensitivity=46.87%, avg_specificity=91.68% avg_auc=0.8534
Fold[4] Epoch: 21 [21/100 (21%)] Train loss=0.386748 Test loss=0.417837 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37880879640579224
[5/23] Train loss=0.38345974683761597
[10/23] Train loss=0.34302616119384766
[15/23] Train loss=0.35780757665634155
[20/23] Train loss=0.32062584161758423
Test set avg_accuracy=81.13% avg_sensitivity=48.64%, avg_specificity=91.54% avg_auc=0.8559
Best model saved!! Metric=-19.100292818151495!!
Fold[4] Epoch: 22 [22/100 (22%)] Train loss=0.385134 Test loss=0.415876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38469648361206055
[5/23] Train loss=0.3767796456813812
[10/23] Train loss=0.3323065936565399
[15/23] Train loss=0.34627223014831543
[20/23] Train loss=0.3249411880970001
Test set avg_accuracy=81.30% avg_sensitivity=50.24%, avg_specificity=91.25% avg_auc=0.8576
Best model saved!! Metric=-17.454073043949855!!
Fold[4] Epoch: 23 [23/100 (23%)] Train loss=0.378280 Test loss=0.411929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3716866075992584
[5/23] Train loss=0.37627527117729187
[10/23] Train loss=0.33675625920295715
[15/23] Train loss=0.34669554233551025
[20/23] Train loss=0.32183507084846497
Test set avg_accuracy=81.34% avg_sensitivity=52.61%, avg_specificity=90.55% avg_auc=0.8574
Best model saved!! Metric=-15.76694895627767!!
Fold[4] Epoch: 24 [24/100 (24%)] Train loss=0.376482 Test loss=0.407965 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37574338912963867
[5/23] Train loss=0.37309911847114563
[10/23] Train loss=0.3299056887626648
[15/23] Train loss=0.342253178358078
[20/23] Train loss=0.31947407126426697
Test set avg_accuracy=81.52% avg_sensitivity=54.64%, avg_specificity=90.13% avg_auc=0.8596
Best model saved!! Metric=-13.753150907858815!!
Fold[4] Epoch: 25 [25/100 (25%)] Train loss=0.374559 Test loss=0.400483 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37894517183303833
[5/23] Train loss=0.37043389678001404
[10/23] Train loss=0.34212857484817505
[15/23] Train loss=0.34069961309432983
[20/23] Train loss=0.3098289370536804
Test set avg_accuracy=81.40% avg_sensitivity=54.20%, avg_specificity=90.12% avg_auc=0.8526
Fold[4] Epoch: 26 [26/100 (26%)] Train loss=0.374757 Test loss=0.409578 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3788352906703949
[5/23] Train loss=0.36324256658554077
[10/23] Train loss=0.32460588216781616
[15/23] Train loss=0.33553797006607056
[20/23] Train loss=0.3130367696285248
Test set avg_accuracy=81.72% avg_sensitivity=56.27%, avg_specificity=89.87% avg_auc=0.8574
Best model saved!! Metric=-12.399503446450847!!
Fold[4] Epoch: 27 [27/100 (27%)] Train loss=0.369672 Test loss=0.407028 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36831438541412354
[5/23] Train loss=0.3562520742416382
[10/23] Train loss=0.32381176948547363
[15/23] Train loss=0.3289141058921814
[20/23] Train loss=0.3134113550186157
Test set avg_accuracy=81.74% avg_sensitivity=57.22%, avg_specificity=89.59% avg_auc=0.8568
Best model saved!! Metric=-11.769395775615855!!
Fold[4] Epoch: 28 [28/100 (28%)] Train loss=0.366478 Test loss=0.406452 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37063872814178467
[5/23] Train loss=0.3509238660335541
[10/23] Train loss=0.31911933422088623
[15/23] Train loss=0.3336246907711029
[20/23] Train loss=0.31136271357536316
Test set avg_accuracy=81.83% avg_sensitivity=58.78%, avg_specificity=89.22% avg_auc=0.8570
Best model saved!! Metric=-10.471651917266678!!
Fold[4] Epoch: 29 [29/100 (29%)] Train loss=0.364274 Test loss=0.404521 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36774322390556335
[5/23] Train loss=0.3524884581565857
[10/23] Train loss=0.3141970634460449
[15/23] Train loss=0.32245293259620667
[20/23] Train loss=0.3102082908153534
Test set avg_accuracy=81.83% avg_sensitivity=58.52%, avg_specificity=89.30% avg_auc=0.8569
Fold[4] Epoch: 30 [30/100 (30%)] Train loss=0.362959 Test loss=0.409666 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3659355938434601
[5/23] Train loss=0.35386064648628235
[10/23] Train loss=0.3100467622280121
[15/23] Train loss=0.3378349244594574
[20/23] Train loss=0.3091835081577301
Test set avg_accuracy=81.74% avg_sensitivity=59.03%, avg_specificity=89.01% avg_auc=0.8637
Best model saved!! Metric=-9.845402713281526!!
Fold[4] Epoch: 31 [31/100 (31%)] Train loss=0.360933 Test loss=0.400633 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36674174666404724
[5/23] Train loss=0.34764963388442993
[10/23] Train loss=0.30454131960868835
[15/23] Train loss=0.318774551153183
[20/23] Train loss=0.3035872280597687
Test set avg_accuracy=81.73% avg_sensitivity=59.81%, avg_specificity=88.75% avg_auc=0.8638
Best model saved!! Metric=-9.335361752925571!!
Fold[4] Epoch: 32 [32/100 (32%)] Train loss=0.356627 Test loss=0.401994 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35938671231269836
[5/23] Train loss=0.3483250141143799
[10/23] Train loss=0.3139558434486389
[15/23] Train loss=0.31231170892715454
[20/23] Train loss=0.30136916041374207
Test set avg_accuracy=81.83% avg_sensitivity=58.30%, avg_specificity=89.37% avg_auc=0.8634
Fold[4] Epoch: 33 [33/100 (33%)] Train loss=0.354919 Test loss=0.406591 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36652252078056335
[5/23] Train loss=0.34240177273750305
[10/23] Train loss=0.30575433373451233
[15/23] Train loss=0.3194219470024109
[20/23] Train loss=0.30255115032196045
Test set avg_accuracy=82.08% avg_sensitivity=58.47%, avg_specificity=89.65% avg_auc=0.8651
Best model saved!! Metric=-9.287281139854343!!
Fold[4] Epoch: 34 [34/100 (34%)] Train loss=0.352724 Test loss=0.407136 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34889400005340576
[5/23] Train loss=0.3406159579753876
[10/23] Train loss=0.3038691282272339
[15/23] Train loss=0.31482523679733276
[20/23] Train loss=0.29034340381622314
Test set avg_accuracy=82.17% avg_sensitivity=58.09%, avg_specificity=89.88% avg_auc=0.8636
Fold[4] Epoch: 35 [35/100 (35%)] Train loss=0.349524 Test loss=0.409068 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3479015529155731
[5/23] Train loss=0.3366478681564331
[10/23] Train loss=0.3065754473209381
[15/23] Train loss=0.3159603774547577
[20/23] Train loss=0.2940666675567627
Test set avg_accuracy=82.00% avg_sensitivity=54.59%, avg_specificity=90.78% avg_auc=0.8633
Fold[4] Epoch: 36 [36/100 (36%)] Train loss=0.350758 Test loss=0.408663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34879371523857117
[5/23] Train loss=0.3346790373325348
[10/23] Train loss=0.3036436438560486
[15/23] Train loss=0.3120751678943634
[20/23] Train loss=0.2923543155193329
Test set avg_accuracy=82.00% avg_sensitivity=55.58%, avg_specificity=90.46% avg_auc=0.8636
Fold[4] Epoch: 37 [37/100 (37%)] Train loss=0.346530 Test loss=0.412598 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34571510553359985
[5/23] Train loss=0.3351976275444031
[10/23] Train loss=0.2987268269062042
[15/23] Train loss=0.3127373456954956
[20/23] Train loss=0.2873840034008026
Test set avg_accuracy=82.05% avg_sensitivity=55.33%, avg_specificity=90.62% avg_auc=0.8635
Fold[4] Epoch: 38 [38/100 (38%)] Train loss=0.343763 Test loss=0.410788 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34874874353408813
[5/23] Train loss=0.3341508209705353
[10/23] Train loss=0.29894545674324036
[15/23] Train loss=0.3031165897846222
[20/23] Train loss=0.2894601821899414
Test set avg_accuracy=81.99% avg_sensitivity=56.14%, avg_specificity=90.27% avg_auc=0.8630
Fold[4] Epoch: 39 [39/100 (39%)] Train loss=0.342113 Test loss=0.413352 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3365536034107208
[5/23] Train loss=0.32837483286857605
[10/23] Train loss=0.29331329464912415
[15/23] Train loss=0.305931955575943
[20/23] Train loss=0.29148533940315247
Test set avg_accuracy=81.73% avg_sensitivity=53.26%, avg_specificity=90.85% avg_auc=0.8615
Fold[4] Epoch: 40 [40/100 (40%)] Train loss=0.340471 Test loss=0.419643 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3394336700439453
[5/23] Train loss=0.32500502467155457
[10/23] Train loss=0.28905102610588074
[15/23] Train loss=0.2978155314922333
[20/23] Train loss=0.28963321447372437
Test set avg_accuracy=82.04% avg_sensitivity=60.11%, avg_specificity=89.07% avg_auc=0.8659
Best model saved!! Metric=-8.18590355496842!!
Fold[4] Epoch: 41 [41/100 (41%)] Train loss=0.336645 Test loss=0.410814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34338629245758057
[5/23] Train loss=0.3254174292087555
[10/23] Train loss=0.28978466987609863
[15/23] Train loss=0.2952904999256134
[20/23] Train loss=0.2928502857685089
Test set avg_accuracy=82.12% avg_sensitivity=59.03%, avg_specificity=89.52% avg_auc=0.8642
Fold[4] Epoch: 42 [42/100 (42%)] Train loss=0.333487 Test loss=0.409698 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3439948558807373
[5/23] Train loss=0.3199712932109833
[10/23] Train loss=0.2935802638530731
[15/23] Train loss=0.2972995340824127
[20/23] Train loss=0.27463942766189575
Test set avg_accuracy=82.06% avg_sensitivity=59.34%, avg_specificity=89.34% avg_auc=0.8654
Fold[4] Epoch: 43 [43/100 (43%)] Train loss=0.331445 Test loss=0.415333 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33584874868392944
[5/23] Train loss=0.31349530816078186
[10/23] Train loss=0.28807714581489563
[15/23] Train loss=0.2902872562408447
[20/23] Train loss=0.28411731123924255
Test set avg_accuracy=81.80% avg_sensitivity=58.30%, avg_specificity=89.33% avg_auc=0.8644
Fold[4] Epoch: 44 [44/100 (44%)] Train loss=0.329702 Test loss=0.419595 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3319986164569855
[5/23] Train loss=0.3104339838027954
[10/23] Train loss=0.28564244508743286
[15/23] Train loss=0.29219427704811096
[20/23] Train loss=0.2756527364253998
Test set avg_accuracy=81.97% avg_sensitivity=55.58%, avg_specificity=90.42% avg_auc=0.8626
Fold[4] Epoch: 45 [45/100 (45%)] Train loss=0.328619 Test loss=0.422681 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32043588161468506
[5/23] Train loss=0.3122524619102478
[10/23] Train loss=0.28998446464538574
[15/23] Train loss=0.29154595732688904
[20/23] Train loss=0.27460360527038574
Test set avg_accuracy=81.85% avg_sensitivity=59.08%, avg_specificity=89.15% avg_auc=0.8660
Fold[4] Epoch: 46 [46/100 (46%)] Train loss=0.326430 Test loss=0.412952 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3329705595970154
[5/23] Train loss=0.31376734375953674
[10/23] Train loss=0.27555716037750244
[15/23] Train loss=0.28600335121154785
[20/23] Train loss=0.27268186211586
Test set avg_accuracy=82.05% avg_sensitivity=56.19%, avg_specificity=90.34% avg_auc=0.8648
Fold[4] Epoch: 47 [47/100 (47%)] Train loss=0.323865 Test loss=0.417422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33272069692611694
[5/23] Train loss=0.30631646513938904
[10/23] Train loss=0.27927878499031067
[15/23] Train loss=0.28539589047431946
[20/23] Train loss=0.2671675682067871
Test set avg_accuracy=81.81% avg_sensitivity=59.47%, avg_specificity=88.97% avg_auc=0.8644
Fold[4] Epoch: 48 [48/100 (48%)] Train loss=0.321243 Test loss=0.421570 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32760173082351685
[5/23] Train loss=0.30490219593048096
[10/23] Train loss=0.2824964225292206
[15/23] Train loss=0.28442949056625366
[20/23] Train loss=0.270082026720047
Test set avg_accuracy=81.80% avg_sensitivity=55.89%, avg_specificity=90.11% avg_auc=0.8649
Fold[4] Epoch: 49 [49/100 (49%)] Train loss=0.317686 Test loss=0.418012 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3206711709499359
[5/23] Train loss=0.3011026382446289
[10/23] Train loss=0.279030978679657
[15/23] Train loss=0.26896536350250244
[20/23] Train loss=0.26967743039131165
Test set avg_accuracy=81.70% avg_sensitivity=55.76%, avg_specificity=90.01% avg_auc=0.8640
Fold[4] Epoch: 50 [50/100 (50%)] Train loss=0.315114 Test loss=0.424974 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31160300970077515
[5/23] Train loss=0.2983863353729248
[10/23] Train loss=0.2786410450935364
[15/23] Train loss=0.2836386263370514
[20/23] Train loss=0.2677782475948334
Test set avg_accuracy=81.77% avg_sensitivity=55.37%, avg_specificity=90.23% avg_auc=0.8636
Fold[4] Epoch: 51 [51/100 (51%)] Train loss=0.311336 Test loss=0.425758 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.312195360660553
[5/23] Train loss=0.29602357745170593
[10/23] Train loss=0.27959349751472473
[15/23] Train loss=0.2628200352191925
[20/23] Train loss=0.2640765607357025
Test set avg_accuracy=81.93% avg_sensitivity=54.03%, avg_specificity=90.87% avg_auc=0.8623
Fold[4] Epoch: 52 [52/100 (52%)] Train loss=0.312771 Test loss=0.426751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31962576508522034
[5/23] Train loss=0.2939215302467346
[10/23] Train loss=0.2639148235321045
[15/23] Train loss=0.27521106600761414
[20/23] Train loss=0.2599088251590729
Test set avg_accuracy=81.81% avg_sensitivity=55.89%, avg_specificity=90.12% avg_auc=0.8639
Fold[4] Epoch: 53 [53/100 (53%)] Train loss=0.305317 Test loss=0.423608 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3045298457145691
[5/23] Train loss=0.29742440581321716
[10/23] Train loss=0.27399083971977234
[15/23] Train loss=0.2690698802471161
[20/23] Train loss=0.26228582859039307
Test set avg_accuracy=81.60% avg_sensitivity=59.98%, avg_specificity=88.53% avg_auc=0.8654
Fold[4] Epoch: 54 [54/100 (54%)] Train loss=0.305137 Test loss=0.427398 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3172719478607178
[5/23] Train loss=0.2921133041381836
[10/23] Train loss=0.26860111951828003
[15/23] Train loss=0.27310052514076233
[20/23] Train loss=0.25385618209838867
Test set avg_accuracy=81.63% avg_sensitivity=57.18%, avg_specificity=89.47% avg_auc=0.8644
Fold[4] Epoch: 55 [55/100 (55%)] Train loss=0.304047 Test loss=0.429437 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3065776526927948
[5/23] Train loss=0.28680136799812317
[10/23] Train loss=0.2707752287387848
[15/23] Train loss=0.2628876566886902
[20/23] Train loss=0.25457313656806946
Test set avg_accuracy=81.62% avg_sensitivity=57.18%, avg_specificity=89.46% avg_auc=0.8630
Fold[4] Epoch: 56 [56/100 (56%)] Train loss=0.299012 Test loss=0.426872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31438148021698
[5/23] Train loss=0.2922977805137634
[10/23] Train loss=0.26168355345726013
[15/23] Train loss=0.2644116282463074
[20/23] Train loss=0.25134801864624023
Test set avg_accuracy=81.57% avg_sensitivity=60.54%, avg_specificity=88.31% avg_auc=0.8647
Fold[4] Epoch: 57 [57/100 (57%)] Train loss=0.296352 Test loss=0.429570 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3062132000923157
[5/23] Train loss=0.28755655884742737
[10/23] Train loss=0.2607822120189667
[15/23] Train loss=0.25550419092178345
[20/23] Train loss=0.25607946515083313
Test set avg_accuracy=81.73% avg_sensitivity=59.59%, avg_specificity=88.82% avg_auc=0.8625
Fold[4] Epoch: 58 [58/100 (58%)] Train loss=0.295939 Test loss=0.431142 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30491650104522705
[5/23] Train loss=0.2838262915611267
[10/23] Train loss=0.26469430327415466
[15/23] Train loss=0.2525676190853119
[20/23] Train loss=0.24541383981704712
Test set avg_accuracy=81.60% avg_sensitivity=57.40%, avg_specificity=89.36% avg_auc=0.8642
Fold[4] Epoch: 59 [59/100 (59%)] Train loss=0.292327 Test loss=0.427292 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2924865782260895
[5/23] Train loss=0.2669640779495239
[10/23] Train loss=0.25866127014160156
[15/23] Train loss=0.25020700693130493
[20/23] Train loss=0.24437250196933746
Test set avg_accuracy=81.40% avg_sensitivity=57.31%, avg_specificity=89.12% avg_auc=0.8633
Fold[4] Epoch: 60 [60/100 (60%)] Train loss=0.288753 Test loss=0.430543 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29348504543304443
[5/23] Train loss=0.26710066199302673
[10/23] Train loss=0.2649289667606354
[15/23] Train loss=0.2490500956773758
[20/23] Train loss=0.24545049667358398
Test set avg_accuracy=81.59% avg_sensitivity=57.61%, avg_specificity=89.28% avg_auc=0.8631
Fold[4] Epoch: 61 [61/100 (61%)] Train loss=0.287784 Test loss=0.435781 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2948538661003113
[5/23] Train loss=0.2777218222618103
[10/23] Train loss=0.26519274711608887
[15/23] Train loss=0.2551144063472748
[20/23] Train loss=0.2400449514389038
Test set avg_accuracy=81.74% avg_sensitivity=58.52%, avg_specificity=89.18% avg_auc=0.8646
Fold[4] Epoch: 62 [62/100 (62%)] Train loss=0.288708 Test loss=0.435047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2910584509372711
[5/23] Train loss=0.2687304615974426
[10/23] Train loss=0.25780490040779114
[15/23] Train loss=0.2506336569786072
[20/23] Train loss=0.24306924641132355
Test set avg_accuracy=81.70% avg_sensitivity=58.17%, avg_specificity=89.23% avg_auc=0.8639
Fold[4] Epoch: 63 [63/100 (63%)] Train loss=0.285322 Test loss=0.437657 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29187139868736267
[5/23] Train loss=0.2790183126926422
[10/23] Train loss=0.26280659437179565
[15/23] Train loss=0.245575949549675
[20/23] Train loss=0.237410306930542
Test set avg_accuracy=81.87% avg_sensitivity=55.50%, avg_specificity=90.33% avg_auc=0.8632
Fold[4] Epoch: 64 [64/100 (64%)] Train loss=0.286349 Test loss=0.432702 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28282272815704346
[5/23] Train loss=0.26762473583221436
[10/23] Train loss=0.26482754945755005
[15/23] Train loss=0.23955446481704712
[20/23] Train loss=0.23285992443561554
Test set avg_accuracy=81.76% avg_sensitivity=55.89%, avg_specificity=90.05% avg_auc=0.8623
Fold[4] Epoch: 65 [65/100 (65%)] Train loss=0.280660 Test loss=0.435468 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27711427211761475
[5/23] Train loss=0.2737487554550171
[10/23] Train loss=0.25942355394363403
[15/23] Train loss=0.23252223432064056
[20/23] Train loss=0.22952376306056976
Test set avg_accuracy=81.79% avg_sensitivity=59.42%, avg_specificity=88.96% avg_auc=0.8633
Fold[4] Epoch: 66 [66/100 (66%)] Train loss=0.277983 Test loss=0.443498 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28429776430130005
[5/23] Train loss=0.2605745196342468
[10/23] Train loss=0.26159051060676575
[15/23] Train loss=0.23470495641231537
[20/23] Train loss=0.23070970177650452
Test set avg_accuracy=81.58% avg_sensitivity=55.76%, avg_specificity=89.86% avg_auc=0.8632
Fold[4] Epoch: 67 [67/100 (67%)] Train loss=0.279078 Test loss=0.440550 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27188804745674133
[5/23] Train loss=0.2562659978866577
[10/23] Train loss=0.2644076645374298
[15/23] Train loss=0.2354043573141098
[20/23] Train loss=0.23231583833694458
Test set avg_accuracy=81.85% avg_sensitivity=54.12%, avg_specificity=90.74% avg_auc=0.8623
Fold[4] Epoch: 68 [68/100 (68%)] Train loss=0.275108 Test loss=0.447282 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27942100167274475
[5/23] Train loss=0.26648372411727905
[10/23] Train loss=0.24923565983772278
[15/23] Train loss=0.2166905552148819
[20/23] Train loss=0.22199459373950958
Test set avg_accuracy=81.68% avg_sensitivity=53.30%, avg_specificity=90.78% avg_auc=0.8630
Fold[4] Epoch: 69 [69/100 (69%)] Train loss=0.270612 Test loss=0.451112 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27472302317619324
[5/23] Train loss=0.24945512413978577
[10/23] Train loss=0.2433079034090042
[15/23] Train loss=0.2316322773694992
[20/23] Train loss=0.22219690680503845
Test set avg_accuracy=81.82% avg_sensitivity=51.57%, avg_specificity=91.51% avg_auc=0.8609
Fold[4] Epoch: 70 [70/100 (70%)] Train loss=0.270357 Test loss=0.458663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28030529618263245
[5/23] Train loss=0.2505781650543213
[10/23] Train loss=0.25248169898986816
[15/23] Train loss=0.23678478598594666
[20/23] Train loss=0.2257194072008133
Test set avg_accuracy=81.88% avg_sensitivity=52.57%, avg_specificity=91.28% avg_auc=0.8618
Fold[4] Epoch: 71 [71/100 (71%)] Train loss=0.270945 Test loss=0.454576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2638249397277832
[5/23] Train loss=0.2516321539878845
[10/23] Train loss=0.23271958529949188
[15/23] Train loss=0.22556625306606293
[20/23] Train loss=0.22385866940021515
Test set avg_accuracy=81.58% avg_sensitivity=59.72%, avg_specificity=88.58% avg_auc=0.8610
Fold[4] Epoch: 72 [72/100 (72%)] Train loss=0.262493 Test loss=0.450864 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2796783447265625
[5/23] Train loss=0.25188976526260376
[10/23] Train loss=0.23689793050289154
[15/23] Train loss=0.2378949373960495
[20/23] Train loss=0.2237018495798111
Test set avg_accuracy=81.85% avg_sensitivity=54.98%, avg_specificity=90.46% avg_auc=0.8624
Fold[4] Epoch: 73 [73/100 (73%)] Train loss=0.266312 Test loss=0.467009 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26874494552612305
[5/23] Train loss=0.2560065984725952
[10/23] Train loss=0.24310217797756195
[15/23] Train loss=0.2452235370874405
[20/23] Train loss=0.2220340520143509
Test set avg_accuracy=81.18% avg_sensitivity=56.88%, avg_specificity=88.97% avg_auc=0.8565
Fold[4] Epoch: 74 [74/100 (74%)] Train loss=0.264585 Test loss=0.462134 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2704164683818817
[5/23] Train loss=0.2605915367603302
[10/23] Train loss=0.24857264757156372
[15/23] Train loss=0.24186089634895325
[20/23] Train loss=0.23037075996398926
Test set avg_accuracy=81.42% avg_sensitivity=63.65%, avg_specificity=87.12% avg_auc=0.8603
Best model saved!! Metric=-7.782248419102027!!
Fold[4] Epoch: 75 [75/100 (75%)] Train loss=0.269065 Test loss=0.468405 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2566947638988495
[5/23] Train loss=0.24733597040176392
[10/23] Train loss=0.25463253259658813
[15/23] Train loss=0.2237188071012497
[20/23] Train loss=0.22690124809741974
Test set avg_accuracy=81.48% avg_sensitivity=59.03%, avg_specificity=88.67% avg_auc=0.8596
Fold[4] Epoch: 76 [76/100 (76%)] Train loss=0.263544 Test loss=0.455091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26599547266960144
[5/23] Train loss=0.24000351130962372
[10/23] Train loss=0.23182421922683716
[15/23] Train loss=0.21194708347320557
[20/23] Train loss=0.20972123742103577
Test set avg_accuracy=81.58% avg_sensitivity=57.01%, avg_specificity=89.46% avg_auc=0.8617
Fold[4] Epoch: 77 [77/100 (77%)] Train loss=0.255220 Test loss=0.456336 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2546011209487915
[5/23] Train loss=0.2419442981481552
[10/23] Train loss=0.23342421650886536
[15/23] Train loss=0.20948219299316406
[20/23] Train loss=0.20807293057441711
Test set avg_accuracy=81.53% avg_sensitivity=56.92%, avg_specificity=89.41% avg_auc=0.8617
Fold[4] Epoch: 78 [78/100 (78%)] Train loss=0.249799 Test loss=0.460301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2564815878868103
[5/23] Train loss=0.23384472727775574
[10/23] Train loss=0.2292802333831787
[15/23] Train loss=0.21782559156417847
[20/23] Train loss=0.2065674215555191
Test set avg_accuracy=81.64% avg_sensitivity=58.43%, avg_specificity=89.08% avg_auc=0.8594
Fold[4] Epoch: 79 [79/100 (79%)] Train loss=0.246978 Test loss=0.461653 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2567381262779236
[5/23] Train loss=0.22832386195659637
[10/23] Train loss=0.22843383252620697
[15/23] Train loss=0.2149522751569748
[20/23] Train loss=0.21016432344913483
Test set avg_accuracy=81.70% avg_sensitivity=55.80%, avg_specificity=89.99% avg_auc=0.8592
Fold[4] Epoch: 80 [80/100 (80%)] Train loss=0.252014 Test loss=0.465885 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24734260141849518
[5/23] Train loss=0.23330582678318024
[10/23] Train loss=0.23055368661880493
[15/23] Train loss=0.20449642837047577
[20/23] Train loss=0.1998836249113083
Test set avg_accuracy=81.57% avg_sensitivity=55.45%, avg_specificity=89.94% avg_auc=0.8609
Fold[4] Epoch: 81 [81/100 (81%)] Train loss=0.246791 Test loss=0.461498 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2555907070636749
[5/23] Train loss=0.22925999760627747
[10/23] Train loss=0.23411411046981812
[15/23] Train loss=0.20478343963623047
[20/23] Train loss=0.2028259038925171
Test set avg_accuracy=81.40% avg_sensitivity=57.22%, avg_specificity=89.15% avg_auc=0.8595
Fold[4] Epoch: 82 [82/100 (82%)] Train loss=0.244747 Test loss=0.466392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24955712258815765
[5/23] Train loss=0.22837147116661072
[10/23] Train loss=0.23109865188598633
[15/23] Train loss=0.2033827155828476
[20/23] Train loss=0.19427524507045746
Test set avg_accuracy=81.37% avg_sensitivity=55.50%, avg_specificity=89.66% avg_auc=0.8603
Fold[4] Epoch: 83 [83/100 (83%)] Train loss=0.239217 Test loss=0.471285 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23471508920192719
[5/23] Train loss=0.2255372405052185
[10/23] Train loss=0.21102935075759888
[15/23] Train loss=0.20458360016345978
[20/23] Train loss=0.20313923060894012
Test set avg_accuracy=81.54% avg_sensitivity=55.20%, avg_specificity=89.98% avg_auc=0.8595
Fold[4] Epoch: 84 [84/100 (84%)] Train loss=0.236534 Test loss=0.481778 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23439832031726837
[5/23] Train loss=0.21640315651893616
[10/23] Train loss=0.2225916087627411
[15/23] Train loss=0.19503851234912872
[20/23] Train loss=0.19317194819450378
Test set avg_accuracy=81.82% avg_sensitivity=54.20%, avg_specificity=90.67% avg_auc=0.8584
Fold[4] Epoch: 85 [85/100 (85%)] Train loss=0.232391 Test loss=0.486147 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2425367832183838
[5/23] Train loss=0.2197485864162445
[10/23] Train loss=0.21351516246795654
[15/23] Train loss=0.20372194051742554
[20/23] Train loss=0.19671766459941864
Test set avg_accuracy=81.64% avg_sensitivity=56.36%, avg_specificity=89.75% avg_auc=0.8577
Fold[4] Epoch: 86 [86/100 (86%)] Train loss=0.234197 Test loss=0.485768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22150765359401703
[5/23] Train loss=0.2279362678527832
[10/23] Train loss=0.21165157854557037
[15/23] Train loss=0.19615785777568817
[20/23] Train loss=0.19801874458789825
Test set avg_accuracy=81.34% avg_sensitivity=58.52%, avg_specificity=88.65% avg_auc=0.8579
Fold[4] Epoch: 87 [87/100 (87%)] Train loss=0.229228 Test loss=0.485563 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23445571959018707
[5/23] Train loss=0.20831766724586487
[10/23] Train loss=0.20391079783439636
[15/23] Train loss=0.1874988079071045
[20/23] Train loss=0.2046961635351181
Test set avg_accuracy=81.30% avg_sensitivity=60.59%, avg_specificity=87.94% avg_auc=0.8574
Fold[4] Epoch: 88 [88/100 (88%)] Train loss=0.225776 Test loss=0.483743 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23264841735363007
[5/23] Train loss=0.2153533697128296
[10/23] Train loss=0.21601615846157074
[15/23] Train loss=0.1829303354024887
[20/23] Train loss=0.19732554256916046
Test set avg_accuracy=81.12% avg_sensitivity=63.48%, avg_specificity=86.77% avg_auc=0.8520
Fold[4] Epoch: 89 [89/100 (89%)] Train loss=0.228471 Test loss=0.496171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.237577423453331
[5/23] Train loss=0.20891375839710236
[10/23] Train loss=0.20003314316272736
[15/23] Train loss=0.189626544713974
[20/23] Train loss=0.19222137331962585
Test set avg_accuracy=81.35% avg_sensitivity=61.49%, avg_specificity=87.71% avg_auc=0.8551
Fold[4] Epoch: 90 [90/100 (90%)] Train loss=0.221295 Test loss=0.495457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2222803384065628
[5/23] Train loss=0.20877231657505035
[10/23] Train loss=0.20080165565013885
[15/23] Train loss=0.17666590213775635
[20/23] Train loss=0.18782925605773926
Test set avg_accuracy=81.26% avg_sensitivity=61.06%, avg_specificity=87.73% avg_auc=0.8534
Fold[4] Epoch: 91 [91/100 (91%)] Train loss=0.220204 Test loss=0.500006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24056383967399597
[5/23] Train loss=0.20116104185581207
[10/23] Train loss=0.19899143278598785
[15/23] Train loss=0.18290212750434875
[20/23] Train loss=0.18285760283470154
Test set avg_accuracy=81.33% avg_sensitivity=62.48%, avg_specificity=87.37% avg_auc=0.8546
Fold[4] Epoch: 92 [92/100 (92%)] Train loss=0.219501 Test loss=0.506087 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22069121897220612
[5/23] Train loss=0.20627088844776154
[10/23] Train loss=0.19857804477214813
[15/23] Train loss=0.17433853447437286
[20/23] Train loss=0.18044596910476685
Test set avg_accuracy=81.45% avg_sensitivity=60.28%, avg_specificity=88.24% avg_auc=0.8500
Fold[4] Epoch: 93 [93/100 (93%)] Train loss=0.213549 Test loss=0.508055 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22504457831382751
[5/23] Train loss=0.20119628310203552
[10/23] Train loss=0.2048635482788086
[15/23] Train loss=0.17740179598331451
[20/23] Train loss=0.17500561475753784
Test set avg_accuracy=81.06% avg_sensitivity=56.19%, avg_specificity=89.03% avg_auc=0.8475
Fold[4] Epoch: 94 [94/100 (94%)] Train loss=0.215967 Test loss=0.500851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21315906941890717
[5/23] Train loss=0.20007231831550598
[10/23] Train loss=0.21640782058238983
[15/23] Train loss=0.1816094070672989
[20/23] Train loss=0.18304088711738586
Test set avg_accuracy=81.44% avg_sensitivity=54.72%, avg_specificity=90.01% avg_auc=0.8552
Fold[4] Epoch: 95 [95/100 (95%)] Train loss=0.212533 Test loss=0.488697 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21622289717197418
[5/23] Train loss=0.19956181943416595
[10/23] Train loss=0.18983888626098633
[15/23] Train loss=0.17147767543792725
[20/23] Train loss=0.17110100388526917
Test set avg_accuracy=81.55% avg_sensitivity=58.39%, avg_specificity=88.97% avg_auc=0.8550
Fold[4] Epoch: 96 [96/100 (96%)] Train loss=0.209787 Test loss=0.498460 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23269842565059662
[5/23] Train loss=0.20715433359146118
[10/23] Train loss=0.1939738541841507
[15/23] Train loss=0.17800694704055786
[20/23] Train loss=0.1696893721818924
Test set avg_accuracy=81.73% avg_sensitivity=55.76%, avg_specificity=90.05% avg_auc=0.8567
Fold[4] Epoch: 97 [97/100 (97%)] Train loss=0.207040 Test loss=0.499455 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2232181876897812
[5/23] Train loss=0.19148878753185272
[10/23] Train loss=0.19333291053771973
[15/23] Train loss=0.17536458373069763
[20/23] Train loss=0.1771029233932495
Test set avg_accuracy=81.76% avg_sensitivity=53.26%, avg_specificity=90.89% avg_auc=0.8544
Fold[4] Epoch: 98 [98/100 (98%)] Train loss=0.209711 Test loss=0.502955 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21677058935165405
[5/23] Train loss=0.18962641060352325
[10/23] Train loss=0.20648087561130524
[15/23] Train loss=0.16411244869232178
[20/23] Train loss=0.17106972634792328
Test set avg_accuracy=81.62% avg_sensitivity=50.84%, avg_specificity=91.49% avg_auc=0.8516
Fold[4] Epoch: 99 [99/100 (99%)] Train loss=0.209148 Test loss=0.502437 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.197529137134552
[5/23] Train loss=0.18903957307338715
[10/23] Train loss=0.19150683283805847
[15/23] Train loss=0.17972241342067719
[20/23] Train loss=0.1637123078107834
Test set avg_accuracy=81.73% avg_sensitivity=45.28%, avg_specificity=93.41% avg_auc=0.8520
Fold[4] Epoch: 100 [100/100 (100%)] Train loss=0.207465 Test loss=0.541344 Current lr=[3.9999999999999996e-05]

Fold[4] Best Result: acc=81.42333856619571 sen=63.64812419146184, spe=87.1199557766722, auc=0.8602633304656823!
[0/23] Train loss=0.6996555328369141
[5/23] Train loss=0.6766694784164429
[10/23] Train loss=0.5697506666183472
[15/23] Train loss=0.554958701133728
[20/23] Train loss=0.524317741394043
Test set avg_accuracy=74.79% avg_sensitivity=0.91%, avg_specificity=99.79% avg_auc=0.5516
Best model saved!! Metric=-95.34753609009122!!
Fold[5] Epoch: 1 [1/100 (1%)] Train loss=0.582176 Test loss=0.638555 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5698679685592651
[5/23] Train loss=0.5930114984512329
[10/23] Train loss=0.529326856136322
[15/23] Train loss=0.5284188389778137
[20/23] Train loss=0.496896892786026
Test set avg_accuracy=74.90% avg_sensitivity=2.69%, avg_specificity=99.34% avg_auc=0.6274
Best model saved!! Metric=-86.32711874561936!!
Fold[5] Epoch: 2 [2/100 (2%)] Train loss=0.543330 Test loss=0.604309 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5479649901390076
[5/23] Train loss=0.552255392074585
[10/23] Train loss=0.495276540517807
[15/23] Train loss=0.5041685700416565
[20/23] Train loss=0.45939651131629944
Test set avg_accuracy=75.27% avg_sensitivity=10.89%, avg_specificity=97.06% avg_auc=0.6970
Best model saved!! Metric=-73.08721472937454!!
Fold[5] Epoch: 3 [3/100 (3%)] Train loss=0.516173 Test loss=0.583186 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.52205491065979
[5/23] Train loss=0.4978030323982239
[10/23] Train loss=0.44862115383148193
[15/23] Train loss=0.476976215839386
[20/23] Train loss=0.4187941551208496
Test set avg_accuracy=76.92% avg_sensitivity=24.17%, avg_specificity=94.78% avg_auc=0.7389
Best model saved!! Metric=-56.23473034582841!!
Fold[5] Epoch: 4 [4/100 (4%)] Train loss=0.484057 Test loss=0.569455 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48749837279319763
[5/23] Train loss=0.46371200680732727
[10/23] Train loss=0.429465115070343
[15/23] Train loss=0.4714319705963135
[20/23] Train loss=0.39952903985977173
Test set avg_accuracy=78.02% avg_sensitivity=34.27%, avg_specificity=92.83% avg_auc=0.7680
Best model saved!! Metric=-44.07383093340092!!
Fold[5] Epoch: 5 [5/100 (5%)] Train loss=0.460963 Test loss=0.538935 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4596403241157532
[5/23] Train loss=0.45186978578567505
[10/23] Train loss=0.41656869649887085
[15/23] Train loss=0.4685080647468567
[20/23] Train loss=0.3925088346004486
Test set avg_accuracy=78.72% avg_sensitivity=40.69%, avg_specificity=91.60% avg_auc=0.7879
Best model saved!! Metric=-36.20453764964914!!
Fold[5] Epoch: 6 [6/100 (6%)] Train loss=0.446903 Test loss=0.505158 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4406803250312805
[5/23] Train loss=0.4438234269618988
[10/23] Train loss=0.4010767340660095
[15/23] Train loss=0.45962491631507874
[20/23] Train loss=0.38293877243995667
Test set avg_accuracy=79.31% avg_sensitivity=45.32%, avg_specificity=90.81% avg_auc=0.7983
Best model saved!! Metric=-30.731489872808755!!
Fold[5] Epoch: 7 [7/100 (7%)] Train loss=0.436286 Test loss=0.490869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4388396441936493
[5/23] Train loss=0.4353172779083252
[10/23] Train loss=0.39216139912605286
[15/23] Train loss=0.4430483877658844
[20/23] Train loss=0.3784804046154022
Test set avg_accuracy=79.45% avg_sensitivity=47.19%, avg_specificity=90.36% avg_auc=0.8039
Best model saved!! Metric=-28.61446672130347!!
Fold[5] Epoch: 8 [8/100 (8%)] Train loss=0.429199 Test loss=0.489334 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42935895919799805
[5/23] Train loss=0.42728227376937866
[10/23] Train loss=0.3908211290836334
[15/23] Train loss=0.4381396472454071
[20/23] Train loss=0.3721592128276825
Test set avg_accuracy=79.60% avg_sensitivity=49.17%, avg_specificity=89.90% avg_auc=0.8099
Best model saved!! Metric=-26.330145830843364!!
Fold[5] Epoch: 9 [9/100 (9%)] Train loss=0.422556 Test loss=0.481272 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43201377987861633
[5/23] Train loss=0.4209941625595093
[10/23] Train loss=0.3847266733646393
[15/23] Train loss=0.41934311389923096
[20/23] Train loss=0.3665519058704376
Test set avg_accuracy=79.78% avg_sensitivity=50.04%, avg_specificity=89.84% avg_auc=0.8132
Best model saved!! Metric=-25.015334372002542!!
Fold[5] Epoch: 10 [10/100 (10%)] Train loss=0.417314 Test loss=0.478641 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4232906699180603
[5/23] Train loss=0.41766807436943054
[10/23] Train loss=0.37811917066574097
[15/23] Train loss=0.4217149615287781
[20/23] Train loss=0.3621542155742645
Test set avg_accuracy=79.76% avg_sensitivity=50.08%, avg_specificity=89.80% avg_auc=0.8174
Best model saved!! Metric=-24.61956398131968!!
Fold[5] Epoch: 11 [11/100 (11%)] Train loss=0.415422 Test loss=0.473761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41884300112724304
[5/23] Train loss=0.4131486117839813
[10/23] Train loss=0.37910473346710205
[15/23] Train loss=0.4050543010234833
[20/23] Train loss=0.3648833930492401
Test set avg_accuracy=79.91% avg_sensitivity=50.66%, avg_specificity=89.80% avg_auc=0.8184
Best model saved!! Metric=-23.78977213629425!!
Fold[5] Epoch: 12 [12/100 (12%)] Train loss=0.411935 Test loss=0.475609 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.408920556306839
[5/23] Train loss=0.4077360928058624
[10/23] Train loss=0.3820957541465759
[15/23] Train loss=0.395425021648407
[20/23] Train loss=0.35668885707855225
Test set avg_accuracy=79.96% avg_sensitivity=50.66%, avg_specificity=89.87% avg_auc=0.8206
Best model saved!! Metric=-23.44887377759543!!
Fold[5] Epoch: 13 [13/100 (13%)] Train loss=0.407265 Test loss=0.475170 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3997683525085449
[5/23] Train loss=0.40890902280807495
[10/23] Train loss=0.3893934488296509
[15/23] Train loss=0.3923569619655609
[20/23] Train loss=0.35505127906799316
Test set avg_accuracy=80.13% avg_sensitivity=51.37%, avg_specificity=89.86% avg_auc=0.8235
Best model saved!! Metric=-22.295152841161705!!
Fold[5] Epoch: 14 [14/100 (14%)] Train loss=0.405434 Test loss=0.471464 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.398001492023468
[5/23] Train loss=0.4033503830432892
[10/23] Train loss=0.38857683539390564
[15/23] Train loss=0.380842000246048
[20/23] Train loss=0.3510980010032654
Test set avg_accuracy=80.01% avg_sensitivity=51.24%, avg_specificity=89.75% avg_auc=0.8226
Fold[5] Epoch: 15 [15/100 (15%)] Train loss=0.402513 Test loss=0.473884 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3966395854949951
[5/23] Train loss=0.3966563940048218
[10/23] Train loss=0.3701835572719574
[15/23] Train loss=0.3786867558956146
[20/23] Train loss=0.3446662127971649
Test set avg_accuracy=80.15% avg_sensitivity=52.36%, avg_specificity=89.55% avg_auc=0.8258
Best model saved!! Metric=-21.363819592568092!!
Fold[5] Epoch: 16 [16/100 (16%)] Train loss=0.398429 Test loss=0.466938 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3904975354671478
[5/23] Train loss=0.39529702067375183
[10/23] Train loss=0.37017306685447693
[15/23] Train loss=0.37747642397880554
[20/23] Train loss=0.33999133110046387
Test set avg_accuracy=80.04% avg_sensitivity=52.94%, avg_specificity=89.21% avg_auc=0.8272
Best model saved!! Metric=-21.08854775453523!!
Fold[5] Epoch: 17 [17/100 (17%)] Train loss=0.393979 Test loss=0.464458 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39726147055625916
[5/23] Train loss=0.3899635076522827
[10/23] Train loss=0.3525843024253845
[15/23] Train loss=0.3663508892059326
[20/23] Train loss=0.3393628001213074
Test set avg_accuracy=80.33% avg_sensitivity=54.51%, avg_specificity=89.07% avg_auc=0.8299
Best model saved!! Metric=-19.092724548125716!!
Fold[5] Epoch: 18 [18/100 (18%)] Train loss=0.390763 Test loss=0.453264 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3971322476863861
[5/23] Train loss=0.3902008831501007
[10/23] Train loss=0.35159385204315186
[15/23] Train loss=0.36115148663520813
[20/23] Train loss=0.3458223044872284
Test set avg_accuracy=80.17% avg_sensitivity=54.43%, avg_specificity=88.88% avg_auc=0.8321
Fold[5] Epoch: 19 [19/100 (19%)] Train loss=0.389562 Test loss=0.447071 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.394653856754303
[5/23] Train loss=0.38859108090400696
[10/23] Train loss=0.35051268339157104
[15/23] Train loss=0.36017605662345886
[20/23] Train loss=0.33206161856651306
Test set avg_accuracy=80.17% avg_sensitivity=56.25%, avg_specificity=88.26% avg_auc=0.8334
Best model saved!! Metric=-17.980403113069578!!
Fold[5] Epoch: 20 [20/100 (20%)] Train loss=0.385937 Test loss=0.439617 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38789165019989014
[5/23] Train loss=0.38467875123023987
[10/23] Train loss=0.34115907549858093
[15/23] Train loss=0.3650335967540741
[20/23] Train loss=0.33109867572784424
Test set avg_accuracy=80.26% avg_sensitivity=56.58%, avg_specificity=88.28% avg_auc=0.8319
Best model saved!! Metric=-17.69000133213143!!
Fold[5] Epoch: 21 [21/100 (21%)] Train loss=0.382387 Test loss=0.441347 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3890593945980072
[5/23] Train loss=0.37968939542770386
[10/23] Train loss=0.3386162519454956
[15/23] Train loss=0.35840025544166565
[20/23] Train loss=0.3294294774532318
Test set avg_accuracy=80.25% avg_sensitivity=56.79%, avg_specificity=88.19% avg_auc=0.8354
Best model saved!! Metric=-17.232051446890566!!
Fold[5] Epoch: 22 [22/100 (22%)] Train loss=0.382780 Test loss=0.434742 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39115583896636963
[5/23] Train loss=0.37806448340415955
[10/23] Train loss=0.3412207365036011
[15/23] Train loss=0.3679487109184265
[20/23] Train loss=0.32250308990478516
Test set avg_accuracy=80.27% avg_sensitivity=57.08%, avg_specificity=88.12% avg_auc=0.8392
Best model saved!! Metric=-16.607945359242052!!
Fold[5] Epoch: 23 [23/100 (23%)] Train loss=0.380988 Test loss=0.425496 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39288511872291565
[5/23] Train loss=0.37247806787490845
[10/23] Train loss=0.337923139333725
[15/23] Train loss=0.3509882986545563
[20/23] Train loss=0.3256501257419586
Test set avg_accuracy=80.10% avg_sensitivity=56.42%, avg_specificity=88.12% avg_auc=0.8377
Fold[5] Epoch: 24 [24/100 (24%)] Train loss=0.378709 Test loss=0.433771 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3907212018966675
[5/23] Train loss=0.36997583508491516
[10/23] Train loss=0.33228805661201477
[15/23] Train loss=0.3425675332546234
[20/23] Train loss=0.31929683685302734
Test set avg_accuracy=80.16% avg_sensitivity=57.28%, avg_specificity=87.90% avg_auc=0.8395
Fold[5] Epoch: 25 [25/100 (25%)] Train loss=0.373397 Test loss=0.428423 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3747798800468445
[5/23] Train loss=0.37429165840148926
[10/23] Train loss=0.33724209666252136
[15/23] Train loss=0.33978965878486633
[20/23] Train loss=0.31629085540771484
Test set avg_accuracy=80.15% avg_sensitivity=57.86%, avg_specificity=87.69% avg_auc=0.8406
Best model saved!! Metric=-16.240787840852644!!
Fold[5] Epoch: 26 [26/100 (26%)] Train loss=0.370281 Test loss=0.429758 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37375515699386597
[5/23] Train loss=0.36108162999153137
[10/23] Train loss=0.3311717212200165
[15/23] Train loss=0.34739014506340027
[20/23] Train loss=0.3129286468029022
Test set avg_accuracy=80.27% avg_sensitivity=57.86%, avg_specificity=87.86% avg_auc=0.8405
Best model saved!! Metric=-15.95670378813137!!
Fold[5] Epoch: 27 [27/100 (27%)] Train loss=0.367354 Test loss=0.429036 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37387895584106445
[5/23] Train loss=0.3598339557647705
[10/23] Train loss=0.32953935861587524
[15/23] Train loss=0.344840943813324
[20/23] Train loss=0.3079667091369629
Test set avg_accuracy=80.19% avg_sensitivity=59.40%, avg_specificity=87.23% avg_auc=0.8410
Best model saved!! Metric=-15.086657098668534!!
Fold[5] Epoch: 28 [28/100 (28%)] Train loss=0.364720 Test loss=0.433592 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3681022524833679
[5/23] Train loss=0.3567841649055481
[10/23] Train loss=0.33284705877304077
[15/23] Train loss=0.3384075164794922
[20/23] Train loss=0.3096765875816345
Test set avg_accuracy=80.45% avg_sensitivity=57.95%, avg_specificity=88.07% avg_auc=0.8412
Fold[5] Epoch: 29 [29/100 (29%)] Train loss=0.363344 Test loss=0.431362 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3603900074958801
[5/23] Train loss=0.3565445840358734
[10/23] Train loss=0.3250958025455475
[15/23] Train loss=0.3371467888355255
[20/23] Train loss=0.3054215908050537
Test set avg_accuracy=80.04% avg_sensitivity=59.98%, avg_specificity=86.83% avg_auc=0.8416
Best model saved!! Metric=-14.99470658361419!!
Fold[5] Epoch: 30 [30/100 (30%)] Train loss=0.360977 Test loss=0.429066 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35669755935668945
[5/23] Train loss=0.35695523023605347
[10/23] Train loss=0.3297590911388397
[15/23] Train loss=0.33856236934661865
[20/23] Train loss=0.3057768642902374
Test set avg_accuracy=79.99% avg_sensitivity=59.19%, avg_specificity=87.03% avg_auc=0.8420
Fold[5] Epoch: 31 [31/100 (31%)] Train loss=0.360118 Test loss=0.428460 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34990811347961426
[5/23] Train loss=0.3516434133052826
[10/23] Train loss=0.32981324195861816
[15/23] Train loss=0.3424617350101471
[20/23] Train loss=0.30773138999938965
Test set avg_accuracy=80.21% avg_sensitivity=59.56%, avg_specificity=87.20% avg_auc=0.8411
Best model saved!! Metric=-14.926380535254484!!
Fold[5] Epoch: 32 [32/100 (32%)] Train loss=0.358465 Test loss=0.433813 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3650157153606415
[5/23] Train loss=0.3500160276889801
[10/23] Train loss=0.3235109746456146
[15/23] Train loss=0.3285936117172241
[20/23] Train loss=0.3005661070346832
Test set avg_accuracy=79.80% avg_sensitivity=61.01%, avg_specificity=86.16% avg_auc=0.8420
Best model saved!! Metric=-14.828555335001113!!
Fold[5] Epoch: 33 [33/100 (33%)] Train loss=0.354270 Test loss=0.433292 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3629484176635742
[5/23] Train loss=0.34804707765579224
[10/23] Train loss=0.31318238377571106
[15/23] Train loss=0.32146310806274414
[20/23] Train loss=0.3076424300670624
Test set avg_accuracy=79.80% avg_sensitivity=61.63%, avg_specificity=85.95% avg_auc=0.8430
Best model saved!! Metric=-14.316516830897633!!
Fold[5] Epoch: 34 [34/100 (34%)] Train loss=0.351221 Test loss=0.430219 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3627544641494751
[5/23] Train loss=0.3471469581127167
[10/23] Train loss=0.3109816312789917
[15/23] Train loss=0.32607582211494446
[20/23] Train loss=0.2969404458999634
Test set avg_accuracy=79.68% avg_sensitivity=62.71%, avg_specificity=85.42% avg_auc=0.8440
Best model saved!! Metric=-13.798873662840215!!
Fold[5] Epoch: 35 [35/100 (35%)] Train loss=0.349831 Test loss=0.430127 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3709385097026825
[5/23] Train loss=0.3343160152435303
[10/23] Train loss=0.30832740664482117
[15/23] Train loss=0.31517502665519714
[20/23] Train loss=0.3007383942604065
Test set avg_accuracy=79.26% avg_sensitivity=63.78%, avg_specificity=84.49% avg_auc=0.8443
Fold[5] Epoch: 36 [36/100 (36%)] Train loss=0.346736 Test loss=0.430674 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35662612318992615
[5/23] Train loss=0.34905382990837097
[10/23] Train loss=0.30442535877227783
[15/23] Train loss=0.3168255686759949
[20/23] Train loss=0.29386621713638306
Test set avg_accuracy=79.87% avg_sensitivity=61.05%, avg_specificity=86.24% avg_auc=0.8426
Fold[5] Epoch: 37 [37/100 (37%)] Train loss=0.343578 Test loss=0.431744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35041743516921997
[5/23] Train loss=0.34052520990371704
[10/23] Train loss=0.3018442392349243
[15/23] Train loss=0.319134384393692
[20/23] Train loss=0.29302549362182617
Test set avg_accuracy=79.09% avg_sensitivity=63.49%, avg_specificity=84.37% avg_auc=0.8430
Fold[5] Epoch: 38 [38/100 (38%)] Train loss=0.343922 Test loss=0.435212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3594232201576233
[5/23] Train loss=0.3337364196777344
[10/23] Train loss=0.3072047829627991
[15/23] Train loss=0.3113856613636017
[20/23] Train loss=0.2929382622241974
Test set avg_accuracy=79.71% avg_sensitivity=62.62%, avg_specificity=85.49% avg_auc=0.8433
Fold[5] Epoch: 39 [39/100 (39%)] Train loss=0.343416 Test loss=0.432148 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35248804092407227
[5/23] Train loss=0.33424970507621765
[10/23] Train loss=0.305983304977417
[15/23] Train loss=0.31517189741134644
[20/23] Train loss=0.289669007062912
Test set avg_accuracy=79.30% avg_sensitivity=61.92%, avg_specificity=85.18% avg_auc=0.8426
Fold[5] Epoch: 40 [40/100 (40%)] Train loss=0.339668 Test loss=0.432341 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3408205807209015
[5/23] Train loss=0.32824864983558655
[10/23] Train loss=0.30887672305107117
[15/23] Train loss=0.3102044463157654
[20/23] Train loss=0.2842991352081299
Test set avg_accuracy=79.68% avg_sensitivity=59.73%, avg_specificity=86.43% avg_auc=0.8409
Fold[5] Epoch: 41 [41/100 (41%)] Train loss=0.337644 Test loss=0.439900 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3399588465690613
[5/23] Train loss=0.32107919454574585
[10/23] Train loss=0.300715833902359
[15/23] Train loss=0.3174944221973419
[20/23] Train loss=0.28054457902908325
Test set avg_accuracy=79.78% avg_sensitivity=60.64%, avg_specificity=86.26% avg_auc=0.8417
Fold[5] Epoch: 42 [42/100 (42%)] Train loss=0.333898 Test loss=0.441176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33254358172416687
[5/23] Train loss=0.3210112750530243
[10/23] Train loss=0.3043488562107086
[15/23] Train loss=0.3107658922672272
[20/23] Train loss=0.2831697165966034
Test set avg_accuracy=79.79% avg_sensitivity=61.47%, avg_specificity=85.99% avg_auc=0.8425
Fold[5] Epoch: 43 [43/100 (43%)] Train loss=0.332777 Test loss=0.435857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33111003041267395
[5/23] Train loss=0.3258102238178253
[10/23] Train loss=0.2986176311969757
[15/23] Train loss=0.30120059847831726
[20/23] Train loss=0.28531065583229065
Test set avg_accuracy=79.86% avg_sensitivity=60.89%, avg_specificity=86.29% avg_auc=0.8434
Fold[5] Epoch: 44 [44/100 (44%)] Train loss=0.330852 Test loss=0.438251 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33945104479789734
[5/23] Train loss=0.3163195550441742
[10/23] Train loss=0.2934093177318573
[15/23] Train loss=0.2946530878543854
[20/23] Train loss=0.2771788537502289
Test set avg_accuracy=78.89% avg_sensitivity=63.95%, avg_specificity=83.95% avg_auc=0.8430
Fold[5] Epoch: 45 [45/100 (45%)] Train loss=0.328037 Test loss=0.451300 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3357560336589813
[5/23] Train loss=0.32129210233688354
[10/23] Train loss=0.2887052893638611
[15/23] Train loss=0.28990691900253296
[20/23] Train loss=0.2778245508670807
Test set avg_accuracy=79.87% avg_sensitivity=61.80%, avg_specificity=85.99% avg_auc=0.8455
Best model saved!! Metric=-13.783210319315844!!
Fold[5] Epoch: 46 [46/100 (46%)] Train loss=0.325385 Test loss=0.435416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3327063322067261
[5/23] Train loss=0.31756591796875
[10/23] Train loss=0.29155847430229187
[15/23] Train loss=0.29595550894737244
[20/23] Train loss=0.2699415981769562
Test set avg_accuracy=79.30% avg_sensitivity=63.66%, avg_specificity=84.59% avg_auc=0.8452
Fold[5] Epoch: 47 [47/100 (47%)] Train loss=0.322352 Test loss=0.440888 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3388405740261078
[5/23] Train loss=0.31336477398872375
[10/23] Train loss=0.28319481015205383
[15/23] Train loss=0.28592556715011597
[20/23] Train loss=0.2680107355117798
Test set avg_accuracy=79.35% avg_sensitivity=63.62%, avg_specificity=84.68% avg_auc=0.8447
Fold[5] Epoch: 48 [48/100 (48%)] Train loss=0.321936 Test loss=0.438321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33243003487586975
[5/23] Train loss=0.3150087296962738
[10/23] Train loss=0.2922855615615845
[15/23] Train loss=0.2947410047054291
[20/23] Train loss=0.2720891833305359
Test set avg_accuracy=79.26% avg_sensitivity=62.87%, avg_specificity=84.80% avg_auc=0.8444
Fold[5] Epoch: 49 [49/100 (49%)] Train loss=0.320540 Test loss=0.440263 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3307221233844757
[5/23] Train loss=0.3059367537498474
[10/23] Train loss=0.28639519214630127
[15/23] Train loss=0.2876165211200714
[20/23] Train loss=0.26418519020080566
Test set avg_accuracy=79.27% avg_sensitivity=62.38%, avg_specificity=84.98% avg_auc=0.8425
Fold[5] Epoch: 50 [50/100 (50%)] Train loss=0.315791 Test loss=0.443683 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32169997692108154
[5/23] Train loss=0.3075971305370331
[10/23] Train loss=0.2965112328529358
[15/23] Train loss=0.27915358543395996
[20/23] Train loss=0.2628103494644165
Test set avg_accuracy=79.68% avg_sensitivity=61.63%, avg_specificity=85.78% avg_auc=0.8425
Fold[5] Epoch: 51 [51/100 (51%)] Train loss=0.312735 Test loss=0.445747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3150744140148163
[5/23] Train loss=0.29828768968582153
[10/23] Train loss=0.29086583852767944
[15/23] Train loss=0.2867094874382019
[20/23] Train loss=0.2686924934387207
Test set avg_accuracy=79.91% avg_sensitivity=61.34%, avg_specificity=86.19% avg_auc=0.8452
Fold[5] Epoch: 52 [52/100 (52%)] Train loss=0.311991 Test loss=0.441549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3065855801105499
[5/23] Train loss=0.3054005801677704
[10/23] Train loss=0.2920394837856293
[15/23] Train loss=0.2865530550479889
[20/23] Train loss=0.26237961649894714
Test set avg_accuracy=79.84% avg_sensitivity=61.59%, avg_specificity=86.02% avg_auc=0.8450
Fold[5] Epoch: 53 [53/100 (53%)] Train loss=0.310604 Test loss=0.436920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32008084654808044
[5/23] Train loss=0.30016884207725525
[10/23] Train loss=0.2822073698043823
[15/23] Train loss=0.29312604665756226
[20/23] Train loss=0.2643589377403259
Test set avg_accuracy=80.17% avg_sensitivity=62.33%, avg_specificity=86.20% avg_auc=0.8467
Best model saved!! Metric=-12.628481618508863!!
Fold[5] Epoch: 54 [54/100 (54%)] Train loss=0.309531 Test loss=0.441621 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30313822627067566
[5/23] Train loss=0.3002566397190094
[10/23] Train loss=0.28020939230918884
[15/23] Train loss=0.27566513419151306
[20/23] Train loss=0.2580699622631073
Test set avg_accuracy=79.41% avg_sensitivity=62.96%, avg_specificity=84.98% avg_auc=0.8446
Fold[5] Epoch: 55 [55/100 (55%)] Train loss=0.305310 Test loss=0.447102 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29999107122421265
[5/23] Train loss=0.2964303195476532
[10/23] Train loss=0.27835896611213684
[15/23] Train loss=0.280810683965683
[20/23] Train loss=0.25336918234825134
Test set avg_accuracy=79.16% avg_sensitivity=64.24%, avg_specificity=84.21% avg_auc=0.8442
Fold[5] Epoch: 56 [56/100 (56%)] Train loss=0.302434 Test loss=0.447801 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3309566080570221
[5/23] Train loss=0.29071658849716187
[10/23] Train loss=0.2707071900367737
[15/23] Train loss=0.2729160189628601
[20/23] Train loss=0.25380799174308777
Test set avg_accuracy=79.64% avg_sensitivity=61.75%, avg_specificity=85.70% avg_auc=0.8439
Fold[5] Epoch: 57 [57/100 (57%)] Train loss=0.302484 Test loss=0.447443 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3044278621673584
[5/23] Train loss=0.2859199643135071
[10/23] Train loss=0.2752000689506531
[15/23] Train loss=0.2634594142436981
[20/23] Train loss=0.2477761209011078
Test set avg_accuracy=78.95% avg_sensitivity=64.82%, avg_specificity=83.74% avg_auc=0.8447
Fold[5] Epoch: 58 [58/100 (58%)] Train loss=0.298502 Test loss=0.452251 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3165002465248108
[5/23] Train loss=0.2918107211589813
[10/23] Train loss=0.2757854759693146
[15/23] Train loss=0.27544835209846497
[20/23] Train loss=0.2450697273015976
Test set avg_accuracy=79.65% avg_sensitivity=63.99%, avg_specificity=84.96% avg_auc=0.8452
Fold[5] Epoch: 59 [59/100 (59%)] Train loss=0.297075 Test loss=0.448589 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29724782705307007
[5/23] Train loss=0.2862774729728699
[10/23] Train loss=0.27519693970680237
[15/23] Train loss=0.27296826243400574
[20/23] Train loss=0.24863167107105255
Test set avg_accuracy=79.26% avg_sensitivity=64.53%, avg_specificity=84.24% avg_auc=0.8461
Fold[5] Epoch: 60 [60/100 (60%)] Train loss=0.293118 Test loss=0.451558 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3037327527999878
[5/23] Train loss=0.2802596092224121
[10/23] Train loss=0.27108117938041687
[15/23] Train loss=0.27783098816871643
[20/23] Train loss=0.24842752516269684
Test set avg_accuracy=78.93% avg_sensitivity=64.24%, avg_specificity=83.91% avg_auc=0.8442
Fold[5] Epoch: 61 [61/100 (61%)] Train loss=0.293328 Test loss=0.449921 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30515196919441223
[5/23] Train loss=0.28294920921325684
[10/23] Train loss=0.2733677923679352
[15/23] Train loss=0.26097482442855835
[20/23] Train loss=0.24673573672771454
Test set avg_accuracy=78.96% avg_sensitivity=64.11%, avg_specificity=83.99% avg_auc=0.8430
Fold[5] Epoch: 62 [62/100 (62%)] Train loss=0.292874 Test loss=0.455403 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3049073815345764
[5/23] Train loss=0.2761078178882599
[10/23] Train loss=0.2643168270587921
[15/23] Train loss=0.2565615475177765
[20/23] Train loss=0.24221037328243256
Test set avg_accuracy=79.52% avg_sensitivity=62.96%, avg_specificity=85.12% avg_auc=0.8455
Fold[5] Epoch: 63 [63/100 (63%)] Train loss=0.292239 Test loss=0.451524 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2985338568687439
[5/23] Train loss=0.27246370911598206
[10/23] Train loss=0.2608872056007385
[15/23] Train loss=0.2742040753364563
[20/23] Train loss=0.23467296361923218
Test set avg_accuracy=78.82% avg_sensitivity=64.45%, avg_specificity=83.68% avg_auc=0.8429
Fold[5] Epoch: 64 [64/100 (64%)] Train loss=0.287279 Test loss=0.460893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30190083384513855
[5/23] Train loss=0.2702087461948395
[10/23] Train loss=0.26575303077697754
[15/23] Train loss=0.2666666507720947
[20/23] Train loss=0.23726730048656464
Test set avg_accuracy=79.23% avg_sensitivity=63.25%, avg_specificity=84.63% avg_auc=0.8447
Fold[5] Epoch: 65 [65/100 (65%)] Train loss=0.283581 Test loss=0.452833 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2898615896701813
[5/23] Train loss=0.2598338723182678
[10/23] Train loss=0.26250508427619934
[15/23] Train loss=0.26307544112205505
[20/23] Train loss=0.22622108459472656
Test set avg_accuracy=79.86% avg_sensitivity=63.20%, avg_specificity=85.50% avg_auc=0.8469
Fold[5] Epoch: 66 [66/100 (66%)] Train loss=0.284629 Test loss=0.446242 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2862723171710968
[5/23] Train loss=0.2603422999382019
[10/23] Train loss=0.2739331126213074
[15/23] Train loss=0.25621485710144043
[20/23] Train loss=0.2478678971529007
Test set avg_accuracy=79.27% avg_sensitivity=62.83%, avg_specificity=84.83% avg_auc=0.8398
Fold[5] Epoch: 67 [67/100 (67%)] Train loss=0.283234 Test loss=0.454801 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3008836507797241
[5/23] Train loss=0.2630384862422943
[10/23] Train loss=0.2631375789642334
[15/23] Train loss=0.2541046440601349
[20/23] Train loss=0.23329685628414154
Test set avg_accuracy=79.93% avg_sensitivity=62.04%, avg_specificity=85.98% avg_auc=0.8439
Fold[5] Epoch: 68 [68/100 (68%)] Train loss=0.280075 Test loss=0.452753 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28997576236724854
[5/23] Train loss=0.2699735760688782
[10/23] Train loss=0.25643041729927063
[15/23] Train loss=0.2487446367740631
[20/23] Train loss=0.22783499956130981
Test set avg_accuracy=79.88% avg_sensitivity=60.22%, avg_specificity=86.54% avg_auc=0.8432
Fold[5] Epoch: 69 [69/100 (69%)] Train loss=0.276582 Test loss=0.457999 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2834778428077698
[5/23] Train loss=0.2638372778892517
[10/23] Train loss=0.2570032477378845
[15/23] Train loss=0.24027706682682037
[20/23] Train loss=0.23152939975261688
Test set avg_accuracy=79.18% avg_sensitivity=61.84%, avg_specificity=85.05% avg_auc=0.8396
Fold[5] Epoch: 70 [70/100 (70%)] Train loss=0.273612 Test loss=0.467466 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28415438532829285
[5/23] Train loss=0.25817662477493286
[10/23] Train loss=0.24505272507667542
[15/23] Train loss=0.24334126710891724
[20/23] Train loss=0.22029906511306763
Test set avg_accuracy=79.35% avg_sensitivity=62.38%, avg_specificity=85.10% avg_auc=0.8410
Fold[5] Epoch: 71 [71/100 (71%)] Train loss=0.269611 Test loss=0.459256 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26834267377853394
[5/23] Train loss=0.25923219323158264
[10/23] Train loss=0.2652421295642853
[15/23] Train loss=0.24746467173099518
[20/23] Train loss=0.22344212234020233
Test set avg_accuracy=79.99% avg_sensitivity=58.94%, avg_specificity=87.11% avg_auc=0.8433
Fold[5] Epoch: 72 [72/100 (72%)] Train loss=0.270658 Test loss=0.448025 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2772844433784485
[5/23] Train loss=0.25288692116737366
[10/23] Train loss=0.2606976628303528
[15/23] Train loss=0.2533157467842102
[20/23] Train loss=0.2235257476568222
Test set avg_accuracy=80.12% avg_sensitivity=59.11%, avg_specificity=87.23% avg_auc=0.8450
Fold[5] Epoch: 73 [73/100 (73%)] Train loss=0.270340 Test loss=0.450205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28511470556259155
[5/23] Train loss=0.2533761262893677
[10/23] Train loss=0.24918268620967865
[15/23] Train loss=0.2464841604232788
[20/23] Train loss=0.21504773199558258
Test set avg_accuracy=80.44% avg_sensitivity=58.61%, avg_specificity=87.83% avg_auc=0.8426
Fold[5] Epoch: 74 [74/100 (74%)] Train loss=0.268515 Test loss=0.452951 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26179900765419006
[5/23] Train loss=0.2510009706020355
[10/23] Train loss=0.24991551041603088
[15/23] Train loss=0.23761828243732452
[20/23] Train loss=0.21767079830169678
Test set avg_accuracy=79.45% avg_sensitivity=63.49%, avg_specificity=84.84% avg_auc=0.8410
Fold[5] Epoch: 75 [75/100 (75%)] Train loss=0.263292 Test loss=0.463893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27354446053504944
[5/23] Train loss=0.2558075189590454
[10/23] Train loss=0.25188058614730835
[15/23] Train loss=0.23529547452926636
[20/23] Train loss=0.2196277529001236
Test set avg_accuracy=79.39% avg_sensitivity=63.70%, avg_specificity=84.70% avg_auc=0.8393
Fold[5] Epoch: 76 [76/100 (76%)] Train loss=0.261854 Test loss=0.472145 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.266781747341156
[5/23] Train loss=0.2556111514568329
[10/23] Train loss=0.23406216502189636
[15/23] Train loss=0.23160585761070251
[20/23] Train loss=0.2152269035577774
Test set avg_accuracy=79.86% avg_sensitivity=62.42%, avg_specificity=85.77% avg_auc=0.8395
Fold[5] Epoch: 77 [77/100 (77%)] Train loss=0.257344 Test loss=0.470871 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2600692808628082
[5/23] Train loss=0.24512042105197906
[10/23] Train loss=0.2428514063358307
[15/23] Train loss=0.2367938905954361
[20/23] Train loss=0.20722262561321259
Test set avg_accuracy=79.27% avg_sensitivity=64.82%, avg_specificity=84.16% avg_auc=0.8409
Fold[5] Epoch: 78 [78/100 (78%)] Train loss=0.255158 Test loss=0.482644 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2725449800491333
[5/23] Train loss=0.24328608810901642
[10/23] Train loss=0.23137108981609344
[15/23] Train loss=0.22267554700374603
[20/23] Train loss=0.2127290964126587
Test set avg_accuracy=78.90% avg_sensitivity=64.98%, avg_specificity=83.61% avg_auc=0.8380
Fold[5] Epoch: 79 [79/100 (79%)] Train loss=0.255067 Test loss=0.483571 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26138103008270264
[5/23] Train loss=0.2432163506746292
[10/23] Train loss=0.23152102530002594
[15/23] Train loss=0.23334118723869324
[20/23] Train loss=0.20592716336250305
Test set avg_accuracy=79.18% avg_sensitivity=64.98%, avg_specificity=83.99% avg_auc=0.8406
Fold[5] Epoch: 80 [80/100 (80%)] Train loss=0.251075 Test loss=0.479431 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2635718286037445
[5/23] Train loss=0.23308400809764862
[10/23] Train loss=0.2244890183210373
[15/23] Train loss=0.2326536923646927
[20/23] Train loss=0.19242653250694275
Test set avg_accuracy=79.01% avg_sensitivity=63.45%, avg_specificity=84.27% avg_auc=0.8384
Fold[5] Epoch: 81 [81/100 (81%)] Train loss=0.248873 Test loss=0.479790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2644486427307129
[5/23] Train loss=0.24119889736175537
[10/23] Train loss=0.22920525074005127
[15/23] Train loss=0.23310115933418274
[20/23] Train loss=0.20837412774562836
Test set avg_accuracy=79.35% avg_sensitivity=65.48%, avg_specificity=84.05% avg_auc=0.8402
Fold[5] Epoch: 82 [82/100 (82%)] Train loss=0.249037 Test loss=0.483895 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26281601190567017
[5/23] Train loss=0.23328682780265808
[10/23] Train loss=0.22607114911079407
[15/23] Train loss=0.2247592955827713
[20/23] Train loss=0.20499679446220398
Test set avg_accuracy=78.79% avg_sensitivity=64.16%, avg_specificity=83.74% avg_auc=0.8328
Fold[5] Epoch: 83 [83/100 (83%)] Train loss=0.248883 Test loss=0.488192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25474756956100464
[5/23] Train loss=0.23116974532604218
[10/23] Train loss=0.23153789341449738
[15/23] Train loss=0.2213190197944641
[20/23] Train loss=0.199935182929039
Test set avg_accuracy=79.37% avg_sensitivity=63.87%, avg_specificity=84.62% avg_auc=0.8386
Fold[5] Epoch: 84 [84/100 (84%)] Train loss=0.243742 Test loss=0.483268 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2509344220161438
[5/23] Train loss=0.22612264752388
[10/23] Train loss=0.23760639131069183
[15/23] Train loss=0.229217067360878
[20/23] Train loss=0.20662817358970642
Test set avg_accuracy=79.74% avg_sensitivity=60.60%, avg_specificity=86.22% avg_auc=0.8370
Fold[5] Epoch: 85 [85/100 (85%)] Train loss=0.243681 Test loss=0.475070 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24584752321243286
[5/23] Train loss=0.2218334972858429
[10/23] Train loss=0.23275206983089447
[15/23] Train loss=0.2303529977798462
[20/23] Train loss=0.19897028803825378
Test set avg_accuracy=79.82% avg_sensitivity=61.05%, avg_specificity=86.17% avg_auc=0.8375
Fold[5] Epoch: 86 [86/100 (86%)] Train loss=0.241550 Test loss=0.469350 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2552061975002289
[5/23] Train loss=0.21671642363071442
[10/23] Train loss=0.22687219083309174
[15/23] Train loss=0.21056289970874786
[20/23] Train loss=0.19967946410179138
Test set avg_accuracy=79.31% avg_sensitivity=62.91%, avg_specificity=84.86% avg_auc=0.8327
Fold[5] Epoch: 87 [87/100 (87%)] Train loss=0.237810 Test loss=0.486499 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2441873401403427
[5/23] Train loss=0.23157943785190582
[10/23] Train loss=0.22603817284107208
[15/23] Train loss=0.2239563912153244
[20/23] Train loss=0.19548897445201874
Test set avg_accuracy=79.48% avg_sensitivity=60.51%, avg_specificity=85.89% avg_auc=0.8338
Fold[5] Epoch: 88 [88/100 (88%)] Train loss=0.237993 Test loss=0.484561 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23794308304786682
[5/23] Train loss=0.21867413818836212
[10/23] Train loss=0.2177974283695221
[15/23] Train loss=0.22798027098178864
[20/23] Train loss=0.19378124177455902
Test set avg_accuracy=79.81% avg_sensitivity=61.26%, avg_specificity=86.09% avg_auc=0.8347
Fold[5] Epoch: 89 [89/100 (89%)] Train loss=0.233712 Test loss=0.480528 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23943543434143066
[5/23] Train loss=0.22673988342285156
[10/23] Train loss=0.22843746840953827
[15/23] Train loss=0.217006117105484
[20/23] Train loss=0.19303686916828156
Test set avg_accuracy=80.58% avg_sensitivity=59.40%, avg_specificity=87.74% avg_auc=0.8348
Fold[5] Epoch: 90 [90/100 (90%)] Train loss=0.236758 Test loss=0.474664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24402667582035065
[5/23] Train loss=0.21392686665058136
[10/23] Train loss=0.2206362783908844
[15/23] Train loss=0.21953275799751282
[20/23] Train loss=0.185878187417984
Test set avg_accuracy=80.12% avg_sensitivity=60.89%, avg_specificity=86.62% avg_auc=0.8346
Fold[5] Epoch: 91 [91/100 (91%)] Train loss=0.231896 Test loss=0.477003 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23872198164463043
[5/23] Train loss=0.2111045867204666
[10/23] Train loss=0.21080030500888824
[15/23] Train loss=0.21104364097118378
[20/23] Train loss=0.18137557804584503
Test set avg_accuracy=80.00% avg_sensitivity=61.34%, avg_specificity=86.31% avg_auc=0.8334
Fold[5] Epoch: 92 [92/100 (92%)] Train loss=0.228910 Test loss=0.485480 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22753679752349854
[5/23] Train loss=0.2132064700126648
[10/23] Train loss=0.218882754445076
[15/23] Train loss=0.20993676781654358
[20/23] Train loss=0.19191080331802368
Test set avg_accuracy=80.01% avg_sensitivity=60.35%, avg_specificity=86.66% avg_auc=0.8363
Fold[5] Epoch: 93 [93/100 (93%)] Train loss=0.230001 Test loss=0.487029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22863101959228516
[5/23] Train loss=0.2052219957113266
[10/23] Train loss=0.222991481423378
[15/23] Train loss=0.20972202718257904
[20/23] Train loss=0.17734698951244354
Test set avg_accuracy=80.20% avg_sensitivity=61.96%, avg_specificity=86.37% avg_auc=0.8389
Fold[5] Epoch: 94 [94/100 (94%)] Train loss=0.227577 Test loss=0.487541 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2286493480205536
[5/23] Train loss=0.21364757418632507
[10/23] Train loss=0.2091875672340393
[15/23] Train loss=0.20664460957050323
[20/23] Train loss=0.18095217645168304
Test set avg_accuracy=80.30% avg_sensitivity=59.56%, avg_specificity=87.32% avg_auc=0.8368
Fold[5] Epoch: 95 [95/100 (95%)] Train loss=0.224180 Test loss=0.486388 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22218607366085052
[5/23] Train loss=0.20208105444908142
[10/23] Train loss=0.20629048347473145
[15/23] Train loss=0.20050621032714844
[20/23] Train loss=0.18308663368225098
Test set avg_accuracy=80.06% avg_sensitivity=60.60%, avg_specificity=86.65% avg_auc=0.8302
Fold[5] Epoch: 96 [96/100 (96%)] Train loss=0.221365 Test loss=0.495310 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21789786219596863
[5/23] Train loss=0.2010151743888855
[10/23] Train loss=0.20428767800331116
[15/23] Train loss=0.20454418659210205
[20/23] Train loss=0.17951983213424683
Test set avg_accuracy=79.19% avg_sensitivity=60.97%, avg_specificity=85.36% avg_auc=0.8274
Fold[5] Epoch: 97 [97/100 (97%)] Train loss=0.218939 Test loss=0.507322 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22736144065856934
[5/23] Train loss=0.21213054656982422
[10/23] Train loss=0.20399907231330872
[15/23] Train loss=0.2046550065279007
[20/23] Train loss=0.1722850799560547
Test set avg_accuracy=79.30% avg_sensitivity=61.88%, avg_specificity=85.19% avg_auc=0.8320
Fold[5] Epoch: 98 [98/100 (98%)] Train loss=0.220542 Test loss=0.501402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22372208535671234
[5/23] Train loss=0.19979596138000488
[10/23] Train loss=0.20785480737686157
[15/23] Train loss=0.2050892561674118
[20/23] Train loss=0.18135188519954681
Test set avg_accuracy=79.45% avg_sensitivity=62.50%, avg_specificity=85.18% avg_auc=0.8347
Fold[5] Epoch: 99 [99/100 (99%)] Train loss=0.216676 Test loss=0.501946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22689779102802277
[5/23] Train loss=0.1946578323841095
[10/23] Train loss=0.19951258599758148
[15/23] Train loss=0.19301357865333557
[20/23] Train loss=0.1751469373703003
Test set avg_accuracy=78.64% avg_sensitivity=65.89%, avg_specificity=82.95% avg_auc=0.8304
Fold[5] Epoch: 100 [100/100 (100%)] Train loss=0.214747 Test loss=0.524134 Current lr=[3.9999999999999996e-05]

Fold[5] Best Result: acc=80.16745159602301 sen=62.33443708609272, spe=86.2025493766634, auc=0.8466708032271201!
[0/23] Train loss=0.701093852519989
[5/23] Train loss=0.6781174540519714
[10/23] Train loss=0.5595526099205017
[15/23] Train loss=0.5646714568138123
[20/23] Train loss=0.5319475531578064
Test set avg_accuracy=76.80% avg_sensitivity=0.00%, avg_specificity=99.90% avg_auc=0.5479
Best model saved!! Metric=-94.49869019760182!!
Fold[6] Epoch: 1 [1/100 (1%)] Train loss=0.586633 Test loss=0.584602 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5614678859710693
[5/23] Train loss=0.6018072366714478
[10/23] Train loss=0.5167730450630188
[15/23] Train loss=0.5332398414611816
[20/23] Train loss=0.5112501978874207
Test set avg_accuracy=76.59% avg_sensitivity=1.64%, avg_specificity=99.14% avg_auc=0.5885
Best model saved!! Metric=-89.77826533735599!!
Fold[6] Epoch: 2 [2/100 (2%)] Train loss=0.551806 Test loss=0.567248 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5508114099502563
[5/23] Train loss=0.558749794960022
[10/23] Train loss=0.4842524826526642
[15/23] Train loss=0.5059760212898254
[20/23] Train loss=0.47455525398254395
Test set avg_accuracy=76.37% avg_sensitivity=6.89%, avg_specificity=97.27% avg_auc=0.6660
Best model saved!! Metric=-78.87246311575116!!
Fold[6] Epoch: 3 [3/100 (3%)] Train loss=0.526833 Test loss=0.551386 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5298272967338562
[5/23] Train loss=0.5019569396972656
[10/23] Train loss=0.46672508120536804
[15/23] Train loss=0.47728073596954346
[20/23] Train loss=0.4308388829231262
Test set avg_accuracy=77.81% avg_sensitivity=18.70%, avg_specificity=95.58% avg_auc=0.7199
Best model saved!! Metric=-61.91878687962148!!
Fold[6] Epoch: 4 [4/100 (4%)] Train loss=0.495711 Test loss=0.533892 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4965600073337555
[5/23] Train loss=0.4647488594055176
[10/23] Train loss=0.4717569947242737
[15/23] Train loss=0.4642702043056488
[20/23] Train loss=0.40424445271492004
Test set avg_accuracy=78.76% avg_sensitivity=26.96%, avg_specificity=94.33% avg_auc=0.7608
Best model saved!! Metric=-49.87203229972731!!
Fold[6] Epoch: 5 [5/100 (5%)] Train loss=0.468879 Test loss=0.517751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4655764400959015
[5/23] Train loss=0.44584745168685913
[10/23] Train loss=0.4797963798046112
[15/23] Train loss=0.44142019748687744
[20/23] Train loss=0.3901514708995819
Test set avg_accuracy=79.47% avg_sensitivity=32.39%, avg_specificity=93.63% avg_auc=0.7789
Best model saved!! Metric=-42.61549551442026!!
Fold[6] Epoch: 6 [6/100 (6%)] Train loss=0.450190 Test loss=0.515635 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4385054409503937
[5/23] Train loss=0.4369647204875946
[10/23] Train loss=0.4722155034542084
[15/23] Train loss=0.42011696100234985
[20/23] Train loss=0.3927594721317291
Test set avg_accuracy=80.41% avg_sensitivity=37.91%, avg_specificity=93.19% avg_auc=0.7943
Best model saved!! Metric=-35.05227074083398!!
Fold[6] Epoch: 7 [7/100 (7%)] Train loss=0.438918 Test loss=0.492047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4349117577075958
[5/23] Train loss=0.4273795783519745
[10/23] Train loss=0.47263625264167786
[15/23] Train loss=0.40890422463417053
[20/23] Train loss=0.3810928761959076
Test set avg_accuracy=80.52% avg_sensitivity=39.01%, avg_specificity=93.00% avg_auc=0.7965
Best model saved!! Metric=-33.82731016383391!!
Fold[6] Epoch: 8 [8/100 (8%)] Train loss=0.434369 Test loss=0.476526 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42622441053390503
[5/23] Train loss=0.426645964384079
[10/23] Train loss=0.4737307131290436
[15/23] Train loss=0.4136590361595154
[20/23] Train loss=0.37355899810791016
Test set avg_accuracy=80.80% avg_sensitivity=41.56%, avg_specificity=92.60% avg_auc=0.8098
Best model saved!! Metric=-30.054649170513386!!
Fold[6] Epoch: 9 [9/100 (9%)] Train loss=0.427639 Test loss=0.459252 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4374605119228363
[5/23] Train loss=0.4165191054344177
[10/23] Train loss=0.46876585483551025
[15/23] Train loss=0.39372965693473816
[20/23] Train loss=0.361046701669693
Test set avg_accuracy=81.26% avg_sensitivity=43.25%, avg_specificity=92.69% avg_auc=0.8163
Best model saved!! Metric=-27.18030314491228!!
Fold[6] Epoch: 10 [10/100 (10%)] Train loss=0.421790 Test loss=0.453653 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4137377142906189
[5/23] Train loss=0.41681036353111267
[10/23] Train loss=0.4651964604854584
[15/23] Train loss=0.39305901527404785
[20/23] Train loss=0.3706547021865845
Test set avg_accuracy=81.30% avg_sensitivity=44.75%, avg_specificity=92.29% avg_auc=0.8226
Best model saved!! Metric=-25.397274328271706!!
Fold[6] Epoch: 11 [11/100 (11%)] Train loss=0.418695 Test loss=0.445185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41641542315483093
[5/23] Train loss=0.4104893207550049
[10/23] Train loss=0.4607677161693573
[15/23] Train loss=0.38410496711730957
[20/23] Train loss=0.3607552945613861
Test set avg_accuracy=81.42% avg_sensitivity=45.99%, avg_specificity=92.08% avg_auc=0.8298
Best model saved!! Metric=-23.532329893621572!!
Fold[6] Epoch: 12 [12/100 (12%)] Train loss=0.414763 Test loss=0.431647 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41862407326698303
[5/23] Train loss=0.40609535574913025
[10/23] Train loss=0.4630357325077057
[15/23] Train loss=0.37991368770599365
[20/23] Train loss=0.3573701083660126
Test set avg_accuracy=81.47% avg_sensitivity=46.17%, avg_specificity=92.08% avg_auc=0.8290
Best model saved!! Metric=-23.38459472036637!!
Fold[6] Epoch: 13 [13/100 (13%)] Train loss=0.411589 Test loss=0.433467 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4088178873062134
[5/23] Train loss=0.4011646807193756
[10/23] Train loss=0.45622801780700684
[15/23] Train loss=0.37542396783828735
[20/23] Train loss=0.3553643524646759
Test set avg_accuracy=81.54% avg_sensitivity=47.49%, avg_specificity=91.78% avg_auc=0.8372
Best model saved!! Metric=-21.472335287794067!!
Fold[6] Epoch: 14 [14/100 (14%)] Train loss=0.406554 Test loss=0.419028 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42545920610427856
[5/23] Train loss=0.39845460653305054
[10/23] Train loss=0.45306068658828735
[15/23] Train loss=0.3720235824584961
[20/23] Train loss=0.35179224610328674
Test set avg_accuracy=81.51% avg_sensitivity=47.08%, avg_specificity=91.86% avg_auc=0.8318
Fold[6] Epoch: 15 [15/100 (15%)] Train loss=0.404353 Test loss=0.430110 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39573442935943604
[5/23] Train loss=0.4025956392288208
[10/23] Train loss=0.44695061445236206
[15/23] Train loss=0.3699023723602295
[20/23] Train loss=0.34767910838127136
Test set avg_accuracy=81.46% avg_sensitivity=48.36%, avg_specificity=91.41% avg_auc=0.8392
Best model saved!! Metric=-20.853606611012474!!
Fold[6] Epoch: 16 [16/100 (16%)] Train loss=0.403862 Test loss=0.416154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41474172472953796
[5/23] Train loss=0.3953380286693573
[10/23] Train loss=0.45160168409347534
[15/23] Train loss=0.36181774735450745
[20/23] Train loss=0.3476790487766266
Test set avg_accuracy=81.51% avg_sensitivity=47.95%, avg_specificity=91.60% avg_auc=0.8366
Fold[6] Epoch: 17 [17/100 (17%)] Train loss=0.400037 Test loss=0.426366 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4020468294620514
[5/23] Train loss=0.38986101746559143
[10/23] Train loss=0.4425918459892273
[15/23] Train loss=0.35907313227653503
[20/23] Train loss=0.33457058668136597
Test set avg_accuracy=81.50% avg_sensitivity=48.13%, avg_specificity=91.53% avg_auc=0.8395
Fold[6] Epoch: 18 [18/100 (18%)] Train loss=0.395788 Test loss=0.418248 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39624476432800293
[5/23] Train loss=0.3957935869693756
[10/23] Train loss=0.44403937458992004
[15/23] Train loss=0.36210671067237854
[20/23] Train loss=0.33681246638298035
Test set avg_accuracy=81.41% avg_sensitivity=47.26%, avg_specificity=91.68% avg_auc=0.8357
Fold[6] Epoch: 19 [19/100 (19%)] Train loss=0.396498 Test loss=0.426597 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39140066504478455
[5/23] Train loss=0.38802456855773926
[10/23] Train loss=0.45173928141593933
[15/23] Train loss=0.3572930097579956
[20/23] Train loss=0.33277350664138794
Test set avg_accuracy=81.15% avg_sensitivity=45.57%, avg_specificity=91.85% avg_auc=0.8311
Fold[6] Epoch: 20 [20/100 (20%)] Train loss=0.397090 Test loss=0.442200 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38286444544792175
[5/23] Train loss=0.3842885196208954
[10/23] Train loss=0.4487468898296356
[15/23] Train loss=0.3526163697242737
[20/23] Train loss=0.33307790756225586
Test set avg_accuracy=81.23% avg_sensitivity=45.12%, avg_specificity=92.10% avg_auc=0.8260
Fold[6] Epoch: 21 [21/100 (21%)] Train loss=0.394208 Test loss=0.453132 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3859531879425049
[5/23] Train loss=0.384936660528183
[10/23] Train loss=0.4409838020801544
[15/23] Train loss=0.35842400789260864
[20/23] Train loss=0.3411760628223419
Test set avg_accuracy=81.80% avg_sensitivity=51.92%, avg_specificity=90.79% avg_auc=0.8415
Best model saved!! Metric=-17.33526987662622!!
Fold[6] Epoch: 22 [22/100 (22%)] Train loss=0.390555 Test loss=0.422170 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3862035274505615
[5/23] Train loss=0.3798832595348358
[10/23] Train loss=0.4327429533004761
[15/23] Train loss=0.3545934855937958
[20/23] Train loss=0.33956989645957947
Test set avg_accuracy=81.81% avg_sensitivity=53.74%, avg_specificity=90.26% avg_auc=0.8507
Best model saved!! Metric=-15.112552639925827!!
Fold[6] Epoch: 23 [23/100 (23%)] Train loss=0.384997 Test loss=0.396110 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3932569622993469
[5/23] Train loss=0.37859615683555603
[10/23] Train loss=0.4258117973804474
[15/23] Train loss=0.34956082701683044
[20/23] Train loss=0.3301340341567993
Test set avg_accuracy=81.76% avg_sensitivity=55.02%, avg_specificity=89.81% avg_auc=0.8536
Best model saved!! Metric=-14.05708104822282!!
Fold[6] Epoch: 24 [24/100 (24%)] Train loss=0.381951 Test loss=0.391319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38083258271217346
[5/23] Train loss=0.37310412526130676
[10/23] Train loss=0.4301747977733612
[15/23] Train loss=0.3463265597820282
[20/23] Train loss=0.3232566714286804
Test set avg_accuracy=81.73% avg_sensitivity=52.74%, avg_specificity=90.45% avg_auc=0.8454
Fold[6] Epoch: 25 [25/100 (25%)] Train loss=0.380271 Test loss=0.408481 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3726712465286255
[5/23] Train loss=0.3764951527118683
[10/23] Train loss=0.42892947793006897
[15/23] Train loss=0.3432128429412842
[20/23] Train loss=0.31656062602996826
Test set avg_accuracy=81.56% avg_sensitivity=51.37%, avg_specificity=90.64% avg_auc=0.8415
Fold[6] Epoch: 26 [26/100 (26%)] Train loss=0.378887 Test loss=0.421847 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3781784176826477
[5/23] Train loss=0.373845636844635
[10/23] Train loss=0.41668352484703064
[15/23] Train loss=0.3340016305446625
[20/23] Train loss=0.3228359818458557
Test set avg_accuracy=81.93% avg_sensitivity=55.47%, avg_specificity=89.89% avg_auc=0.8514
Best model saved!! Metric=-13.56652347173403!!
Fold[6] Epoch: 27 [27/100 (27%)] Train loss=0.375337 Test loss=0.402706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3735172748565674
[5/23] Train loss=0.3685431480407715
[10/23] Train loss=0.4128100275993347
[15/23] Train loss=0.3304801285266876
[20/23] Train loss=0.3185614347457886
Test set avg_accuracy=81.74% avg_sensitivity=57.21%, avg_specificity=89.12% avg_auc=0.8562
Best model saved!! Metric=-12.312849301980496!!
Fold[6] Epoch: 28 [28/100 (28%)] Train loss=0.368973 Test loss=0.390774 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37802234292030334
[5/23] Train loss=0.363603800535202
[10/23] Train loss=0.40299704670906067
[15/23] Train loss=0.32940027117729187
[20/23] Train loss=0.3190605640411377
Test set avg_accuracy=81.88% avg_sensitivity=59.12%, avg_specificity=88.72% avg_auc=0.8556
Best model saved!! Metric=-10.713213517599442!!
Fold[6] Epoch: 29 [29/100 (29%)] Train loss=0.367351 Test loss=0.393430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3805370628833771
[5/23] Train loss=0.3597758114337921
[10/23] Train loss=0.4014171063899994
[15/23] Train loss=0.3386630415916443
[20/23] Train loss=0.3106673061847687
Test set avg_accuracy=81.90% avg_sensitivity=56.11%, avg_specificity=89.65% avg_auc=0.8540
Fold[6] Epoch: 30 [30/100 (30%)] Train loss=0.365409 Test loss=0.395146 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3657292127609253
[5/23] Train loss=0.36619332432746887
[10/23] Train loss=0.40013939142227173
[15/23] Train loss=0.32641661167144775
[20/23] Train loss=0.3058689832687378
Test set avg_accuracy=81.84% avg_sensitivity=57.48%, avg_specificity=89.16% avg_auc=0.8536
Fold[6] Epoch: 31 [31/100 (31%)] Train loss=0.362926 Test loss=0.400654 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3618966042995453
[5/23] Train loss=0.3579466938972473
[10/23] Train loss=0.4138665199279785
[15/23] Train loss=0.3260971009731293
[20/23] Train loss=0.3088584244251251
Test set avg_accuracy=82.36% avg_sensitivity=57.03%, avg_specificity=89.98% avg_auc=0.8584
Fold[6] Epoch: 32 [32/100 (32%)] Train loss=0.367338 Test loss=0.397188 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36892804503440857
[5/23] Train loss=0.3556012213230133
[10/23] Train loss=0.404623806476593
[15/23] Train loss=0.3150840997695923
[20/23] Train loss=0.3091355562210083
Test set avg_accuracy=82.16% avg_sensitivity=56.07%, avg_specificity=90.01% avg_auc=0.8599
Fold[6] Epoch: 33 [33/100 (33%)] Train loss=0.361849 Test loss=0.393729 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3564017415046692
[5/23] Train loss=0.3527853190898895
[10/23] Train loss=0.39975595474243164
[15/23] Train loss=0.31883397698402405
[20/23] Train loss=0.2988925874233246
Test set avg_accuracy=82.13% avg_sensitivity=55.38%, avg_specificity=90.18% avg_auc=0.8607
Fold[6] Epoch: 34 [34/100 (34%)] Train loss=0.356620 Test loss=0.393177 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35512715578079224
[5/23] Train loss=0.3507368564605713
[10/23] Train loss=0.3969527781009674
[15/23] Train loss=0.3234895169734955
[20/23] Train loss=0.29401886463165283
Test set avg_accuracy=82.39% avg_sensitivity=53.56%, avg_specificity=91.07% avg_auc=0.8561
Fold[6] Epoch: 35 [35/100 (35%)] Train loss=0.353816 Test loss=0.403572 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34970954060554504
[5/23] Train loss=0.34796881675720215
[10/23] Train loss=0.39224594831466675
[15/23] Train loss=0.31928640604019165
[20/23] Train loss=0.2974705696105957
Test set avg_accuracy=82.42% avg_sensitivity=56.07%, avg_specificity=90.34% avg_auc=0.8590
Fold[6] Epoch: 36 [36/100 (36%)] Train loss=0.352850 Test loss=0.399489 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3459979295730591
[5/23] Train loss=0.34787288308143616
[10/23] Train loss=0.3852893114089966
[15/23] Train loss=0.3058795928955078
[20/23] Train loss=0.2935103178024292
Test set avg_accuracy=82.17% avg_sensitivity=59.58%, avg_specificity=88.97% avg_auc=0.8616
Best model saved!! Metric=-9.121256044226799!!
Fold[6] Epoch: 37 [37/100 (37%)] Train loss=0.348933 Test loss=0.396074 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.347368448972702
[5/23] Train loss=0.33642029762268066
[10/23] Train loss=0.39067670702934265
[15/23] Train loss=0.30674439668655396
[20/23] Train loss=0.2904154658317566
Test set avg_accuracy=82.25% avg_sensitivity=56.11%, avg_specificity=90.11% avg_auc=0.8600
Fold[6] Epoch: 38 [38/100 (38%)] Train loss=0.346823 Test loss=0.396797 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3557966649532318
[5/23] Train loss=0.34210801124572754
[10/23] Train loss=0.3798046112060547
[15/23] Train loss=0.30511510372161865
[20/23] Train loss=0.28710290789604187
Test set avg_accuracy=82.09% avg_sensitivity=59.67%, avg_specificity=88.83% avg_auc=0.8636
Best model saved!! Metric=-9.053471775611415!!
Fold[6] Epoch: 39 [39/100 (39%)] Train loss=0.344080 Test loss=0.391086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3419414162635803
[5/23] Train loss=0.3323586881160736
[10/23] Train loss=0.37550055980682373
[15/23] Train loss=0.30735164880752563
[20/23] Train loss=0.2874412536621094
Test set avg_accuracy=82.10% avg_sensitivity=58.85%, avg_specificity=89.09% avg_auc=0.8615
Fold[6] Epoch: 40 [40/100 (40%)] Train loss=0.339072 Test loss=0.397822 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34051263332366943
[5/23] Train loss=0.341581255197525
[10/23] Train loss=0.3705311417579651
[15/23] Train loss=0.3013012409210205
[20/23] Train loss=0.27829641103744507
Test set avg_accuracy=81.88% avg_sensitivity=59.17%, avg_specificity=88.71% avg_auc=0.8614
Fold[6] Epoch: 41 [41/100 (41%)] Train loss=0.337559 Test loss=0.398846 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33996710181236267
[5/23] Train loss=0.32990214228630066
[10/23] Train loss=0.36871927976608276
[15/23] Train loss=0.2882443070411682
[20/23] Train loss=0.27437880635261536
Test set avg_accuracy=82.27% avg_sensitivity=61.31%, avg_specificity=88.57% avg_auc=0.8624
Best model saved!! Metric=-7.606661759068218!!
Fold[6] Epoch: 42 [42/100 (42%)] Train loss=0.333592 Test loss=0.399632 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3372364938259125
[5/23] Train loss=0.3341315984725952
[10/23] Train loss=0.3616114854812622
[15/23] Train loss=0.29286715388298035
[20/23] Train loss=0.2840116024017334
Test set avg_accuracy=82.11% avg_sensitivity=62.09%, avg_specificity=88.13% avg_auc=0.8642
Best model saved!! Metric=-7.249209021344991!!
Fold[6] Epoch: 43 [43/100 (43%)] Train loss=0.335311 Test loss=0.397196 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3365875482559204
[5/23] Train loss=0.3206231892108917
[10/23] Train loss=0.3605557680130005
[15/23] Train loss=0.29881763458251953
[20/23] Train loss=0.2898297905921936
Test set avg_accuracy=82.07% avg_sensitivity=64.32%, avg_specificity=87.40% avg_auc=0.8657
Best model saved!! Metric=-5.6311960043945035!!
Fold[6] Epoch: 44 [44/100 (44%)] Train loss=0.331651 Test loss=0.399361 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3416544795036316
[5/23] Train loss=0.3249056339263916
[10/23] Train loss=0.35163581371307373
[15/23] Train loss=0.2964000105857849
[20/23] Train loss=0.27919870615005493
Test set avg_accuracy=82.19% avg_sensitivity=63.69%, avg_specificity=87.76% avg_auc=0.8661
Fold[6] Epoch: 45 [45/100 (45%)] Train loss=0.331993 Test loss=0.392670 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3376395106315613
[5/23] Train loss=0.32037994265556335
[10/23] Train loss=0.35433492064476013
[15/23] Train loss=0.2990744709968567
[20/23] Train loss=0.2795960605144501
Test set avg_accuracy=82.30% avg_sensitivity=62.27%, avg_specificity=88.32% avg_auc=0.8649
Fold[6] Epoch: 46 [46/100 (46%)] Train loss=0.332554 Test loss=0.388914 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3393681049346924
[5/23] Train loss=0.30875641107559204
[10/23] Train loss=0.35234856605529785
[15/23] Train loss=0.2966004014015198
[20/23] Train loss=0.2721862196922302
Test set avg_accuracy=82.13% avg_sensitivity=61.45%, avg_specificity=88.35% avg_auc=0.8641
Fold[6] Epoch: 47 [47/100 (47%)] Train loss=0.327030 Test loss=0.392872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32225480675697327
[5/23] Train loss=0.31190553307533264
[10/23] Train loss=0.3508755564689636
[15/23] Train loss=0.28603750467300415
[20/23] Train loss=0.2752840518951416
Test set avg_accuracy=82.33% avg_sensitivity=59.63%, avg_specificity=89.16% avg_auc=0.8658
Fold[6] Epoch: 48 [48/100 (48%)] Train loss=0.323946 Test loss=0.387606 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32801562547683716
[5/23] Train loss=0.30490198731422424
[10/23] Train loss=0.34991195797920227
[15/23] Train loss=0.28801265358924866
[20/23] Train loss=0.2691537141799927
Test set avg_accuracy=82.12% avg_sensitivity=53.79%, avg_specificity=90.64% avg_auc=0.8626
Fold[6] Epoch: 49 [49/100 (49%)] Train loss=0.320990 Test loss=0.391841 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3113420903682709
[5/23] Train loss=0.29818934202194214
[10/23] Train loss=0.36430367827415466
[15/23] Train loss=0.2808879315853119
[20/23] Train loss=0.2638068199157715
Test set avg_accuracy=82.27% avg_sensitivity=54.15%, avg_specificity=90.72% avg_auc=0.8634
Fold[6] Epoch: 50 [50/100 (50%)] Train loss=0.318892 Test loss=0.394772 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3199160695075989
[5/23] Train loss=0.31012946367263794
[10/23] Train loss=0.3522792458534241
[15/23] Train loss=0.28661850094795227
[20/23] Train loss=0.26979920268058777
Test set avg_accuracy=82.24% avg_sensitivity=47.26%, avg_specificity=92.76% avg_auc=0.8586
Fold[6] Epoch: 51 [51/100 (51%)] Train loss=0.319533 Test loss=0.409271 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3177570700645447
[5/23] Train loss=0.3076326251029968
[10/23] Train loss=0.34238308668136597
[15/23] Train loss=0.27575623989105225
[20/23] Train loss=0.26614275574684143
Test set avg_accuracy=82.56% avg_sensitivity=60.72%, avg_specificity=89.13% avg_auc=0.8651
Fold[6] Epoch: 52 [52/100 (52%)] Train loss=0.317220 Test loss=0.393874 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3126766085624695
[5/23] Train loss=0.2995991110801697
[10/23] Train loss=0.3314360976219177
[15/23] Train loss=0.28315600752830505
[20/23] Train loss=0.26030001044273376
Test set avg_accuracy=82.53% avg_sensitivity=61.54%, avg_specificity=88.84% avg_auc=0.8659
Fold[6] Epoch: 53 [53/100 (53%)] Train loss=0.310765 Test loss=0.391178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3121758997440338
[5/23] Train loss=0.3071700930595398
[10/23] Train loss=0.32685956358909607
[15/23] Train loss=0.2805674970149994
[20/23] Train loss=0.25193658471107483
Test set avg_accuracy=82.48% avg_sensitivity=61.68%, avg_specificity=88.73% avg_auc=0.8649
Fold[6] Epoch: 54 [54/100 (54%)] Train loss=0.309152 Test loss=0.393067 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3075704872608185
[5/23] Train loss=0.29793286323547363
[10/23] Train loss=0.3211324214935303
[15/23] Train loss=0.26047295331954956
[20/23] Train loss=0.2550022006034851
Test set avg_accuracy=82.49% avg_sensitivity=64.19%, avg_specificity=87.99% avg_auc=0.8668
Best model saved!! Metric=-4.649935236291765!!
Fold[6] Epoch: 55 [55/100 (55%)] Train loss=0.304346 Test loss=0.401827 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3060666024684906
[5/23] Train loss=0.29220497608184814
[10/23] Train loss=0.31726258993148804
[15/23] Train loss=0.26124492287635803
[20/23] Train loss=0.25474879145622253
Test set avg_accuracy=82.37% avg_sensitivity=63.91%, avg_specificity=87.93% avg_auc=0.8657
Fold[6] Epoch: 56 [56/100 (56%)] Train loss=0.300962 Test loss=0.402387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30589407682418823
[5/23] Train loss=0.28884178400039673
[10/23] Train loss=0.32197892665863037
[15/23] Train loss=0.2645457684993744
[20/23] Train loss=0.24889297783374786
Test set avg_accuracy=82.28% avg_sensitivity=59.35%, avg_specificity=89.17% avg_auc=0.8648
Fold[6] Epoch: 57 [57/100 (57%)] Train loss=0.299347 Test loss=0.396859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3033898174762726
[5/23] Train loss=0.28023749589920044
[10/23] Train loss=0.3117564618587494
[15/23] Train loss=0.27704960107803345
[20/23] Train loss=0.25098422169685364
Test set avg_accuracy=82.64% avg_sensitivity=52.46%, avg_specificity=91.71% avg_auc=0.8649
Fold[6] Epoch: 58 [58/100 (58%)] Train loss=0.301141 Test loss=0.404131 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30625995993614197
[5/23] Train loss=0.2916051149368286
[10/23] Train loss=0.324136883020401
[15/23] Train loss=0.26863765716552734
[20/23] Train loss=0.24502097070217133
Test set avg_accuracy=82.39% avg_sensitivity=53.60%, avg_specificity=91.05% avg_auc=0.8605
Fold[6] Epoch: 59 [59/100 (59%)] Train loss=0.303661 Test loss=0.402321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2918517589569092
[5/23] Train loss=0.2859765887260437
[10/23] Train loss=0.3157164454460144
[15/23] Train loss=0.2725643813610077
[20/23] Train loss=0.2457631379365921
Test set avg_accuracy=82.50% avg_sensitivity=58.71%, avg_specificity=89.65% avg_auc=0.8623
Fold[6] Epoch: 60 [60/100 (60%)] Train loss=0.297466 Test loss=0.398709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29022717475891113
[5/23] Train loss=0.2900039851665497
[10/23] Train loss=0.3043649196624756
[15/23] Train loss=0.2544481158256531
[20/23] Train loss=0.23869650065898895
Test set avg_accuracy=82.87% avg_sensitivity=57.44%, avg_specificity=90.52% avg_auc=0.8633
Fold[6] Epoch: 61 [61/100 (61%)] Train loss=0.293190 Test loss=0.405696 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28297826647758484
[5/23] Train loss=0.2799990773200989
[10/23] Train loss=0.3076566755771637
[15/23] Train loss=0.2556501626968384
[20/23] Train loss=0.24464276432991028
Test set avg_accuracy=82.72% avg_sensitivity=59.81%, avg_specificity=89.61% avg_auc=0.8622
Fold[6] Epoch: 62 [62/100 (62%)] Train loss=0.291834 Test loss=0.410436 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28885188698768616
[5/23] Train loss=0.27053940296173096
[10/23] Train loss=0.2971860468387604
[15/23] Train loss=0.2637903392314911
[20/23] Train loss=0.24372941255569458
Test set avg_accuracy=82.61% avg_sensitivity=62.45%, avg_specificity=88.67% avg_auc=0.8639
Fold[6] Epoch: 63 [63/100 (63%)] Train loss=0.287932 Test loss=0.407751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29551395773887634
[5/23] Train loss=0.2760760486125946
[10/23] Train loss=0.2931998670101166
[15/23] Train loss=0.25700366497039795
[20/23] Train loss=0.24479800462722778
Test set avg_accuracy=82.43% avg_sensitivity=63.64%, avg_specificity=88.08% avg_auc=0.8645
Fold[6] Epoch: 64 [64/100 (64%)] Train loss=0.286299 Test loss=0.421706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2852139472961426
[5/23] Train loss=0.26044949889183044
[10/23] Train loss=0.2969394028186798
[15/23] Train loss=0.25271695852279663
[20/23] Train loss=0.2399323582649231
Test set avg_accuracy=82.67% avg_sensitivity=62.00%, avg_specificity=88.89% avg_auc=0.8618
Fold[6] Epoch: 65 [65/100 (65%)] Train loss=0.283561 Test loss=0.408917 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28039178252220154
[5/23] Train loss=0.2625419795513153
[10/23] Train loss=0.28631696105003357
[15/23] Train loss=0.25165605545043945
[20/23] Train loss=0.23852689564228058
Test set avg_accuracy=82.24% avg_sensitivity=64.51%, avg_specificity=87.57% avg_auc=0.8619
Fold[6] Epoch: 66 [66/100 (66%)] Train loss=0.281877 Test loss=0.416817 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2899230122566223
[5/23] Train loss=0.2644299268722534
[10/23] Train loss=0.28135308623313904
[15/23] Train loss=0.25696173310279846
[20/23] Train loss=0.23531007766723633
Test set avg_accuracy=82.27% avg_sensitivity=66.33%, avg_specificity=87.06% avg_auc=0.8590
Best model saved!! Metric=-4.436332395530952!!
Fold[6] Epoch: 67 [67/100 (67%)] Train loss=0.281303 Test loss=0.427746 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3020060360431671
[5/23] Train loss=0.2638266086578369
[10/23] Train loss=0.28768518567085266
[15/23] Train loss=0.2565532326698303
[20/23] Train loss=0.22788092494010925
Test set avg_accuracy=82.56% avg_sensitivity=63.05%, avg_specificity=88.43% avg_auc=0.8613
Fold[6] Epoch: 68 [68/100 (68%)] Train loss=0.277542 Test loss=0.416274 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2812202274799347
[5/23] Train loss=0.2587665319442749
[10/23] Train loss=0.2818591594696045
[15/23] Train loss=0.24302594363689423
[20/23] Train loss=0.2313852310180664
Test set avg_accuracy=82.49% avg_sensitivity=59.17%, avg_specificity=89.50% avg_auc=0.8590
Fold[6] Epoch: 69 [69/100 (69%)] Train loss=0.275316 Test loss=0.413914 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28771916031837463
[5/23] Train loss=0.2632887661457062
[10/23] Train loss=0.2876076400279999
[15/23] Train loss=0.23279975354671478
[20/23] Train loss=0.23213234543800354
Test set avg_accuracy=82.58% avg_sensitivity=56.66%, avg_specificity=90.38% avg_auc=0.8584
Fold[6] Epoch: 70 [70/100 (70%)] Train loss=0.274844 Test loss=0.418699 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2690068483352661
[5/23] Train loss=0.2547941207885742
[10/23] Train loss=0.2950465977191925
[15/23] Train loss=0.25023043155670166
[20/23] Train loss=0.21992331743240356
Test set avg_accuracy=82.29% avg_sensitivity=50.96%, avg_specificity=91.71% avg_auc=0.8525
Fold[6] Epoch: 71 [71/100 (71%)] Train loss=0.271235 Test loss=0.418514 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28760606050491333
[5/23] Train loss=0.2650398910045624
[10/23] Train loss=0.2985847294330597
[15/23] Train loss=0.2434069812297821
[20/23] Train loss=0.21343110501766205
Test set avg_accuracy=82.87% avg_sensitivity=51.19%, avg_specificity=92.40% avg_auc=0.8541
Fold[6] Epoch: 72 [72/100 (72%)] Train loss=0.273919 Test loss=0.435105 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2747025191783905
[5/23] Train loss=0.25141391158103943
[10/23] Train loss=0.2871114909648895
[15/23] Train loss=0.2404259294271469
[20/23] Train loss=0.22389376163482666
Test set avg_accuracy=82.53% avg_sensitivity=55.06%, avg_specificity=90.79% avg_auc=0.8547
Fold[6] Epoch: 73 [73/100 (73%)] Train loss=0.267869 Test loss=0.428144 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26844319701194763
[5/23] Train loss=0.25397711992263794
[10/23] Train loss=0.27338019013404846
[15/23] Train loss=0.23649892210960388
[20/23] Train loss=0.22129300236701965
Test set avg_accuracy=82.09% avg_sensitivity=59.90%, avg_specificity=88.76% avg_auc=0.8554
Fold[6] Epoch: 74 [74/100 (74%)] Train loss=0.266573 Test loss=0.429449 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2621684670448303
[5/23] Train loss=0.2504364252090454
[10/23] Train loss=0.2633706331253052
[15/23] Train loss=0.22145980596542358
[20/23] Train loss=0.21496550738811493
Test set avg_accuracy=82.39% avg_sensitivity=63.09%, avg_specificity=88.20% avg_auc=0.8565
Fold[6] Epoch: 75 [75/100 (75%)] Train loss=0.258345 Test loss=0.437227 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26961952447891235
[5/23] Train loss=0.2446146309375763
[10/23] Train loss=0.25942569971084595
[15/23] Train loss=0.2090998888015747
[20/23] Train loss=0.20807291567325592
Test set avg_accuracy=82.81% avg_sensitivity=63.18%, avg_specificity=88.71% avg_auc=0.8594
Fold[6] Epoch: 76 [76/100 (76%)] Train loss=0.256649 Test loss=0.439814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26429763436317444
[5/23] Train loss=0.2413247525691986
[10/23] Train loss=0.2588420808315277
[15/23] Train loss=0.23021958768367767
[20/23] Train loss=0.20172196626663208
Test set avg_accuracy=82.66% avg_sensitivity=59.63%, avg_specificity=89.59% avg_auc=0.8551
Fold[6] Epoch: 77 [77/100 (77%)] Train loss=0.254024 Test loss=0.434702 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25227826833724976
[5/23] Train loss=0.24601058661937714
[10/23] Train loss=0.2599230408668518
[15/23] Train loss=0.22259126603603363
[20/23] Train loss=0.2127440869808197
Test set avg_accuracy=82.11% avg_sensitivity=58.85%, avg_specificity=89.11% avg_auc=0.8503
Fold[6] Epoch: 78 [78/100 (78%)] Train loss=0.250248 Test loss=0.433325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2503550350666046
[5/23] Train loss=0.2331634759902954
[10/23] Train loss=0.2529408633708954
[15/23] Train loss=0.20992322266101837
[20/23] Train loss=0.20665203034877777
Test set avg_accuracy=82.25% avg_sensitivity=60.90%, avg_specificity=88.67% avg_auc=0.8527
Fold[6] Epoch: 79 [79/100 (79%)] Train loss=0.249015 Test loss=0.447401 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2624518573284149
[5/23] Train loss=0.23357534408569336
[10/23] Train loss=0.24866756796836853
[15/23] Train loss=0.21979877352714539
[20/23] Train loss=0.2042255401611328
Test set avg_accuracy=81.85% avg_sensitivity=61.77%, avg_specificity=87.88% avg_auc=0.8488
Fold[6] Epoch: 80 [80/100 (80%)] Train loss=0.248006 Test loss=0.454411 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25036537647247314
[5/23] Train loss=0.23737896978855133
[10/23] Train loss=0.2515852451324463
[15/23] Train loss=0.220070481300354
[20/23] Train loss=0.2139958143234253
Test set avg_accuracy=82.24% avg_sensitivity=61.13%, avg_specificity=88.58% avg_auc=0.8501
Fold[6] Epoch: 81 [81/100 (81%)] Train loss=0.247782 Test loss=0.447315 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2596456706523895
[5/23] Train loss=0.238691046833992
[10/23] Train loss=0.2451782077550888
[15/23] Train loss=0.24040599167346954
[20/23] Train loss=0.19367815554141998
Test set avg_accuracy=81.81% avg_sensitivity=61.50%, avg_specificity=87.93% avg_auc=0.8502
Fold[6] Epoch: 82 [82/100 (82%)] Train loss=0.246911 Test loss=0.446284 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2515958547592163
[5/23] Train loss=0.2306467443704605
[10/23] Train loss=0.244008868932724
[15/23] Train loss=0.22927898168563843
[20/23] Train loss=0.20632235705852509
Test set avg_accuracy=81.97% avg_sensitivity=64.60%, avg_specificity=87.20% avg_auc=0.8480
Fold[6] Epoch: 83 [83/100 (83%)] Train loss=0.243981 Test loss=0.464015 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25554218888282776
[5/23] Train loss=0.21794235706329346
[10/23] Train loss=0.2420455366373062
[15/23] Train loss=0.2103622555732727
[20/23] Train loss=0.200807586312294
Test set avg_accuracy=81.99% avg_sensitivity=62.64%, avg_specificity=87.82% avg_auc=0.8484
Fold[6] Epoch: 84 [84/100 (84%)] Train loss=0.242476 Test loss=0.458931 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2505970895290375
[5/23] Train loss=0.21617266535758972
[10/23] Train loss=0.23062528669834137
[15/23] Train loss=0.20818129181861877
[20/23] Train loss=0.20364594459533691
Test set avg_accuracy=81.80% avg_sensitivity=59.44%, avg_specificity=88.53% avg_auc=0.8463
Fold[6] Epoch: 85 [85/100 (85%)] Train loss=0.237218 Test loss=0.449470 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2444351315498352
[5/23] Train loss=0.21900025010108948
[10/23] Train loss=0.22991874814033508
[15/23] Train loss=0.2147379070520401
[20/23] Train loss=0.19607456028461456
Test set avg_accuracy=81.78% avg_sensitivity=56.98%, avg_specificity=89.24% avg_auc=0.8439
Fold[6] Epoch: 86 [86/100 (86%)] Train loss=0.239615 Test loss=0.453299 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2383815348148346
[5/23] Train loss=0.20468448102474213
[10/23] Train loss=0.23144900798797607
[15/23] Train loss=0.1996719241142273
[20/23] Train loss=0.1980462223291397
Test set avg_accuracy=81.56% avg_sensitivity=59.26%, avg_specificity=88.27% avg_auc=0.8436
Fold[6] Epoch: 87 [87/100 (87%)] Train loss=0.231986 Test loss=0.459443 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23984333872795105
[5/23] Train loss=0.21449849009513855
[10/23] Train loss=0.23982973396778107
[15/23] Train loss=0.2015804648399353
[20/23] Train loss=0.18924902379512787
Test set avg_accuracy=82.05% avg_sensitivity=57.07%, avg_specificity=89.56% avg_auc=0.8443
Fold[6] Epoch: 88 [88/100 (88%)] Train loss=0.233670 Test loss=0.464029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2376982718706131
[5/23] Train loss=0.21511691808700562
[10/23] Train loss=0.237579345703125
[15/23] Train loss=0.19940908253192902
[20/23] Train loss=0.19052310287952423
Test set avg_accuracy=81.92% avg_sensitivity=52.55%, avg_specificity=90.75% avg_auc=0.8388
Fold[6] Epoch: 89 [89/100 (89%)] Train loss=0.231511 Test loss=0.461254 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24136042594909668
[5/23] Train loss=0.20727142691612244
[10/23] Train loss=0.25452542304992676
[15/23] Train loss=0.20887567102909088
[20/23] Train loss=0.19338759779930115
Test set avg_accuracy=82.03% avg_sensitivity=47.95%, avg_specificity=92.27% avg_auc=0.8431
Fold[6] Epoch: 90 [90/100 (90%)] Train loss=0.235023 Test loss=0.469751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24487300217151642
[5/23] Train loss=0.21382705867290497
[10/23] Train loss=0.23520025610923767
[15/23] Train loss=0.2016618847846985
[20/23] Train loss=0.1892852485179901
Test set avg_accuracy=81.28% avg_sensitivity=48.59%, avg_specificity=91.11% avg_auc=0.8378
Fold[6] Epoch: 91 [91/100 (91%)] Train loss=0.232948 Test loss=0.471675 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23442979156970978
[5/23] Train loss=0.2223312258720398
[10/23] Train loss=0.2295704185962677
[15/23] Train loss=0.19870315492153168
[20/23] Train loss=0.18695375323295593
Test set avg_accuracy=81.71% avg_sensitivity=54.74%, avg_specificity=89.82% avg_auc=0.8445
Fold[6] Epoch: 92 [92/100 (92%)] Train loss=0.231737 Test loss=0.464359 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22121913731098175
[5/23] Train loss=0.2131475806236267
[10/23] Train loss=0.21418315172195435
[15/23] Train loss=0.20133449137210846
[20/23] Train loss=0.18619738519191742
Test set avg_accuracy=81.76% avg_sensitivity=59.26%, avg_specificity=88.53% avg_auc=0.8450
Fold[6] Epoch: 93 [93/100 (93%)] Train loss=0.223164 Test loss=0.473906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2286711484193802
[5/23] Train loss=0.19630929827690125
[10/23] Train loss=0.21369847655296326
[15/23] Train loss=0.19162197411060333
[20/23] Train loss=0.18784214556217194
Test set avg_accuracy=81.41% avg_sensitivity=62.45%, avg_specificity=87.12% avg_auc=0.8399
Fold[6] Epoch: 94 [94/100 (94%)] Train loss=0.222577 Test loss=0.489905 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22313354909420013
[5/23] Train loss=0.20220567286014557
[10/23] Train loss=0.2137122005224228
[15/23] Train loss=0.2009207159280777
[20/23] Train loss=0.1841256320476532
Test set avg_accuracy=81.58% avg_sensitivity=60.40%, avg_specificity=87.95% avg_auc=0.8445
Fold[6] Epoch: 95 [95/100 (95%)] Train loss=0.216802 Test loss=0.484545 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22121980786323547
[5/23] Train loss=0.1994311809539795
[10/23] Train loss=0.2165374606847763
[15/23] Train loss=0.20587632060050964
[20/23] Train loss=0.17432671785354614
Test set avg_accuracy=81.76% avg_sensitivity=60.40%, avg_specificity=88.19% avg_auc=0.8450
Fold[6] Epoch: 96 [96/100 (96%)] Train loss=0.217133 Test loss=0.477723 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22251133620738983
[5/23] Train loss=0.2001674622297287
[10/23] Train loss=0.2046378254890442
[15/23] Train loss=0.19784976541996002
[20/23] Train loss=0.1694319099187851
Test set avg_accuracy=81.32% avg_sensitivity=60.90%, avg_specificity=87.46% avg_auc=0.8423
Fold[6] Epoch: 97 [97/100 (97%)] Train loss=0.215833 Test loss=0.486910 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21549835801124573
[5/23] Train loss=0.19635769724845886
[10/23] Train loss=0.2046384960412979
[15/23] Train loss=0.2001533955335617
[20/23] Train loss=0.17400310933589935
Test set avg_accuracy=81.47% avg_sensitivity=56.52%, avg_specificity=88.97% avg_auc=0.8387
Fold[6] Epoch: 98 [98/100 (98%)] Train loss=0.213030 Test loss=0.488005 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21765194833278656
[5/23] Train loss=0.19353307783603668
[10/23] Train loss=0.22193025052547455
[15/23] Train loss=0.19298554956912994
[20/23] Train loss=0.1650668829679489
Test set avg_accuracy=81.76% avg_sensitivity=55.38%, avg_specificity=89.70% avg_auc=0.8372
Fold[6] Epoch: 99 [99/100 (99%)] Train loss=0.213544 Test loss=0.482291 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21049119532108307
[5/23] Train loss=0.19230584800243378
[10/23] Train loss=0.2250603586435318
[15/23] Train loss=0.1845642328262329
[20/23] Train loss=0.16869142651557922
Test set avg_accuracy=81.71% avg_sensitivity=49.45%, avg_specificity=91.41% avg_auc=0.8346
Fold[6] Epoch: 100 [100/100 (100%)] Train loss=0.211131 Test loss=0.477471 Current lr=[3.9999999999999996e-05]

Fold[6] Best Result: acc=82.26793248945148 sen=66.33211678832117, spe=87.0609220636663, auc=0.859026962630301!
[0/23] Train loss=0.7193781137466431
[5/23] Train loss=0.6879532933235168
[10/23] Train loss=0.5633022785186768
[15/23] Train loss=0.550345778465271
[20/23] Train loss=0.5331235527992249
Test set avg_accuracy=75.69% avg_sensitivity=0.55%, avg_specificity=99.96% avg_auc=0.5664
Best model saved!! Metric=-93.15964297876586!!
Fold[7] Epoch: 1 [1/100 (1%)] Train loss=0.586546 Test loss=0.615396 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5693120956420898
[5/23] Train loss=0.601469874382019
[10/23] Train loss=0.511828601360321
[15/23] Train loss=0.5202744603157043
[20/23] Train loss=0.5073955059051514
Test set avg_accuracy=76.03% avg_sensitivity=4.10%, avg_specificity=99.27% avg_auc=0.6011
Best model saved!! Metric=-86.49754010803348!!
Fold[7] Epoch: 2 [2/100 (2%)] Train loss=0.549891 Test loss=0.578869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5454310178756714
[5/23] Train loss=0.5468561053276062
[10/23] Train loss=0.4823804199695587
[15/23] Train loss=0.49199336767196655
[20/23] Train loss=0.46576258540153503
Test set avg_accuracy=76.77% avg_sensitivity=12.50%, avg_specificity=97.53% avg_auc=0.6589
Best model saved!! Metric=-73.30731865386521!!
Fold[7] Epoch: 3 [3/100 (3%)] Train loss=0.518095 Test loss=0.584648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5135828256607056
[5/23] Train loss=0.489024817943573
[10/23] Train loss=0.4791263937950134
[15/23] Train loss=0.46576252579689026
[20/23] Train loss=0.42447319626808167
Test set avg_accuracy=78.02% avg_sensitivity=19.88%, avg_specificity=96.80% avg_auc=0.7164
Best model saved!! Metric=-59.65830310453521!!
Fold[7] Epoch: 4 [4/100 (4%)] Train loss=0.484743 Test loss=0.615899 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48139309883117676
[5/23] Train loss=0.4607835114002228
[10/23] Train loss=0.4622975289821625
[15/23] Train loss=0.462700754404068
[20/23] Train loss=0.40751928091049194
Test set avg_accuracy=79.11% avg_sensitivity=27.22%, avg_specificity=95.88% avg_auc=0.7511
Best model saved!! Metric=-48.67704327390427!!
Fold[7] Epoch: 5 [5/100 (5%)] Train loss=0.459854 Test loss=0.574289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4637923538684845
[5/23] Train loss=0.447062611579895
[10/23] Train loss=0.47323110699653625
[15/23] Train loss=0.42974287271499634
[20/23] Train loss=0.3992268145084381
Test set avg_accuracy=79.71% avg_sensitivity=30.38%, avg_specificity=95.64% avg_auc=0.7588
Best model saved!! Metric=-44.39148567016992!!
Fold[7] Epoch: 6 [6/100 (6%)] Train loss=0.450832 Test loss=0.553926 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43252161145210266
[5/23] Train loss=0.4445975720882416
[10/23] Train loss=0.47501319646835327
[15/23] Train loss=0.43714115023612976
[20/23] Train loss=0.38851359486579895
Test set avg_accuracy=79.97% avg_sensitivity=33.49%, avg_specificity=94.98% avg_auc=0.7769
Best model saved!! Metric=-39.864328238651964!!
Fold[7] Epoch: 7 [7/100 (7%)] Train loss=0.441356 Test loss=0.524810 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43724608421325684
[5/23] Train loss=0.43162739276885986
[10/23] Train loss=0.4673405587673187
[15/23] Train loss=0.4259399175643921
[20/23] Train loss=0.37948447465896606
Test set avg_accuracy=80.22% avg_sensitivity=35.49%, avg_specificity=94.67% avg_auc=0.7894
Best model saved!! Metric=-36.6753106056045!!
Fold[7] Epoch: 8 [8/100 (8%)] Train loss=0.434395 Test loss=0.499825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4342329502105713
[5/23] Train loss=0.42651814222335815
[10/23] Train loss=0.47087156772613525
[15/23] Train loss=0.4056931138038635
[20/23] Train loss=0.3847046494483948
Test set avg_accuracy=80.24% avg_sensitivity=35.45%, avg_specificity=94.71% avg_auc=0.7932
Best model saved!! Metric=-36.27627726079426!!
Fold[7] Epoch: 9 [9/100 (9%)] Train loss=0.429679 Test loss=0.504243 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42807185649871826
[5/23] Train loss=0.41673851013183594
[10/23] Train loss=0.47081899642944336
[15/23] Train loss=0.3944939970970154
[20/23] Train loss=0.37741848826408386
Test set avg_accuracy=80.41% avg_sensitivity=35.92%, avg_specificity=94.78% avg_auc=0.7939
Best model saved!! Metric=-35.505999859831206!!
Fold[7] Epoch: 10 [10/100 (10%)] Train loss=0.425890 Test loss=0.511232 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4202464818954468
[5/23] Train loss=0.41566047072410583
[10/23] Train loss=0.47080954909324646
[15/23] Train loss=0.39221838116645813
[20/23] Train loss=0.37085115909576416
Test set avg_accuracy=80.43% avg_sensitivity=35.79%, avg_specificity=94.85% avg_auc=0.7942
Fold[7] Epoch: 11 [11/100 (11%)] Train loss=0.424709 Test loss=0.520174 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41863253712654114
[5/23] Train loss=0.4172288775444031
[10/23] Train loss=0.47050943970680237
[15/23] Train loss=0.39194273948669434
[20/23] Train loss=0.3632596433162689
Test set avg_accuracy=80.41% avg_sensitivity=37.16%, avg_specificity=94.38% avg_auc=0.7997
Best model saved!! Metric=-34.083063069376976!!
Fold[7] Epoch: 12 [12/100 (12%)] Train loss=0.423002 Test loss=0.511159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4121527671813965
[5/23] Train loss=0.4120521545410156
[10/23] Train loss=0.45837607979774475
[15/23] Train loss=0.3842012882232666
[20/23] Train loss=0.3676816523075104
Test set avg_accuracy=80.72% avg_sensitivity=40.96%, avg_specificity=93.56% avg_auc=0.8150
Best model saved!! Metric=-29.26447113557429!!
Fold[7] Epoch: 13 [13/100 (13%)] Train loss=0.416789 Test loss=0.464387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41354814171791077
[5/23] Train loss=0.40456297993659973
[10/23] Train loss=0.45601674914360046
[15/23] Train loss=0.37219002842903137
[20/23] Train loss=0.36549216508865356
Test set avg_accuracy=81.02% avg_sensitivity=44.33%, avg_specificity=92.87% avg_auc=0.8255
Best model saved!! Metric=-25.224102245460365!!
Fold[7] Epoch: 14 [14/100 (14%)] Train loss=0.408946 Test loss=0.449613 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4163746237754822
[5/23] Train loss=0.4022481441497803
[10/23] Train loss=0.4548759460449219
[15/23] Train loss=0.36589986085891724
[20/23] Train loss=0.3549876809120178
Test set avg_accuracy=81.20% avg_sensitivity=44.88%, avg_specificity=92.93% avg_auc=0.8273
Best model saved!! Metric=-24.261697314089748!!
Fold[7] Epoch: 15 [15/100 (15%)] Train loss=0.403112 Test loss=0.442383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40716803073883057
[5/23] Train loss=0.40180695056915283
[10/23] Train loss=0.4546996057033539
[15/23] Train loss=0.36026790738105774
[20/23] Train loss=0.35407230257987976
Test set avg_accuracy=81.35% avg_sensitivity=44.28%, avg_specificity=93.33% avg_auc=0.8283
Best model saved!! Metric=-24.20188392204232!!
Fold[7] Epoch: 16 [16/100 (16%)] Train loss=0.404150 Test loss=0.456339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3980709910392761
[5/23] Train loss=0.39812561869621277
[10/23] Train loss=0.4577455222606659
[15/23] Train loss=0.3670402467250824
[20/23] Train loss=0.3480347990989685
Test set avg_accuracy=81.30% avg_sensitivity=43.26%, avg_specificity=93.59% avg_auc=0.8230
Fold[7] Epoch: 17 [17/100 (17%)] Train loss=0.403235 Test loss=0.470933 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3921860456466675
[5/23] Train loss=0.40005871653556824
[10/23] Train loss=0.448284387588501
[15/23] Train loss=0.3600178062915802
[20/23] Train loss=0.3501599133014679
Test set avg_accuracy=81.40% avg_sensitivity=45.44%, avg_specificity=93.01% avg_auc=0.8281
Best model saved!! Metric=-23.344956917691107!!
Fold[7] Epoch: 18 [18/100 (18%)] Train loss=0.399848 Test loss=0.462781 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3936050534248352
[5/23] Train loss=0.39100122451782227
[10/23] Train loss=0.4474523663520813
[15/23] Train loss=0.35976821184158325
[20/23] Train loss=0.3460456132888794
Test set avg_accuracy=81.67% avg_sensitivity=49.87%, avg_specificity=91.94% avg_auc=0.8393
Best model saved!! Metric=-18.595647962441014!!
Fold[7] Epoch: 19 [19/100 (19%)] Train loss=0.392817 Test loss=0.428269 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.404032438993454
[5/23] Train loss=0.3877565264701843
[10/23] Train loss=0.4433068335056305
[15/23] Train loss=0.3569351136684418
[20/23] Train loss=0.3409600853919983
Test set avg_accuracy=81.65% avg_sensitivity=48.08%, avg_specificity=92.49% avg_auc=0.8368
Fold[7] Epoch: 20 [20/100 (20%)] Train loss=0.391640 Test loss=0.439965 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3923390805721283
[5/23] Train loss=0.38853710889816284
[10/23] Train loss=0.4417180120944977
[15/23] Train loss=0.34831318259239197
[20/23] Train loss=0.34109988808631897
Test set avg_accuracy=81.60% avg_sensitivity=46.63%, avg_specificity=92.90% avg_auc=0.8350
Fold[7] Epoch: 21 [21/100 (21%)] Train loss=0.389325 Test loss=0.454052 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37908434867858887
[5/23] Train loss=0.38778480887413025
[10/23] Train loss=0.4369671046733856
[15/23] Train loss=0.35371649265289307
[20/23] Train loss=0.3366180658340454
Test set avg_accuracy=81.49% avg_sensitivity=47.14%, avg_specificity=92.59% avg_auc=0.8337
Fold[7] Epoch: 22 [22/100 (22%)] Train loss=0.389314 Test loss=0.451191 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3901737332344055
[5/23] Train loss=0.38450515270233154
[10/23] Train loss=0.4346126317977905
[15/23] Train loss=0.3410657048225403
[20/23] Train loss=0.3327779173851013
Test set avg_accuracy=81.80% avg_sensitivity=50.17%, avg_specificity=92.02% avg_auc=0.8424
Best model saved!! Metric=-17.7696500514893!!
Fold[7] Epoch: 23 [23/100 (23%)] Train loss=0.383712 Test loss=0.429468 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39205795526504517
[5/23] Train loss=0.3852929174900055
[10/23] Train loss=0.42821985483169556
[15/23] Train loss=0.3463023602962494
[20/23] Train loss=0.3302656412124634
Test set avg_accuracy=81.72% avg_sensitivity=51.62%, avg_specificity=91.44% avg_auc=0.8422
Best model saved!! Metric=-16.993576341199095!!
Fold[7] Epoch: 24 [24/100 (24%)] Train loss=0.380512 Test loss=0.425314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3851819336414337
[5/23] Train loss=0.3772560954093933
[10/23] Train loss=0.4293557107448578
[15/23] Train loss=0.3475981652736664
[20/23] Train loss=0.32279130816459656
Test set avg_accuracy=81.73% avg_sensitivity=49.87%, avg_specificity=92.02% avg_auc=0.8419
Fold[7] Epoch: 25 [25/100 (25%)] Train loss=0.378636 Test loss=0.434926 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3771243095397949
[5/23] Train loss=0.38017430901527405
[10/23] Train loss=0.42835402488708496
[15/23] Train loss=0.3328113853931427
[20/23] Train loss=0.32320651412010193
Test set avg_accuracy=81.68% avg_sensitivity=50.81%, avg_specificity=91.65% avg_auc=0.8414
Fold[7] Epoch: 26 [26/100 (26%)] Train loss=0.376182 Test loss=0.435963 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3780806362628937
[5/23] Train loss=0.3742782175540924
[10/23] Train loss=0.4214461147785187
[15/23] Train loss=0.3296070992946625
[20/23] Train loss=0.322399377822876
Test set avg_accuracy=81.93% avg_sensitivity=53.37%, avg_specificity=91.15% avg_auc=0.8450
Best model saved!! Metric=-15.046755899632867!!
Fold[7] Epoch: 27 [27/100 (27%)] Train loss=0.370266 Test loss=0.427650 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37968531250953674
[5/23] Train loss=0.3788212537765503
[10/23] Train loss=0.41912537813186646
[15/23] Train loss=0.3283480107784271
[20/23] Train loss=0.31972867250442505
Test set avg_accuracy=82.05% avg_sensitivity=54.78%, avg_specificity=90.86% avg_auc=0.8500
Best model saved!! Metric=-13.302914978055885!!
Fold[7] Epoch: 28 [28/100 (28%)] Train loss=0.369328 Test loss=0.419404 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3715752363204956
[5/23] Train loss=0.3738747835159302
[10/23] Train loss=0.4145922064781189
[15/23] Train loss=0.32388338446617126
[20/23] Train loss=0.31376805901527405
Test set avg_accuracy=82.21% avg_sensitivity=54.78%, avg_specificity=91.07% avg_auc=0.8500
Best model saved!! Metric=-12.93955439803925!!
Fold[7] Epoch: 29 [29/100 (29%)] Train loss=0.367893 Test loss=0.417944 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3845105767250061
[5/23] Train loss=0.3651680648326874
[10/23] Train loss=0.41053950786590576
[15/23] Train loss=0.3333527743816376
[20/23] Train loss=0.3164668679237366
Test set avg_accuracy=82.48% avg_sensitivity=53.37%, avg_specificity=91.88% avg_auc=0.8487
Fold[7] Epoch: 30 [30/100 (30%)] Train loss=0.366632 Test loss=0.426210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3674745261669159
[5/23] Train loss=0.36465078592300415
[10/23] Train loss=0.41766518354415894
[15/23] Train loss=0.329409658908844
[20/23] Train loss=0.313703328371048
Test set avg_accuracy=82.20% avg_sensitivity=49.19%, avg_specificity=92.86% avg_auc=0.8452
Fold[7] Epoch: 31 [31/100 (31%)] Train loss=0.368159 Test loss=0.447907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3632650077342987
[5/23] Train loss=0.367236465215683
[10/23] Train loss=0.4144132137298584
[15/23] Train loss=0.32799363136291504
[20/23] Train loss=0.30824100971221924
Test set avg_accuracy=82.28% avg_sensitivity=50.77%, avg_specificity=92.46% avg_auc=0.8444
Fold[7] Epoch: 32 [32/100 (32%)] Train loss=0.369058 Test loss=0.452189 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3594835102558136
[5/23] Train loss=0.36506950855255127
[10/23] Train loss=0.4062420725822449
[15/23] Train loss=0.32741740345954895
[20/23] Train loss=0.3166089951992035
Test set avg_accuracy=82.39% avg_sensitivity=52.43%, avg_specificity=92.06% avg_auc=0.8501
Fold[7] Epoch: 33 [33/100 (33%)] Train loss=0.362231 Test loss=0.428388 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35831770300865173
[5/23] Train loss=0.3593044579029083
[10/23] Train loss=0.405490517616272
[15/23] Train loss=0.31988945603370667
[20/23] Train loss=0.3065240979194641
Test set avg_accuracy=82.44% avg_sensitivity=53.75%, avg_specificity=91.70% avg_auc=0.8498
Fold[7] Epoch: 34 [34/100 (34%)] Train loss=0.356051 Test loss=0.437105 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35158178210258484
[5/23] Train loss=0.3532797396183014
[10/23] Train loss=0.4062827527523041
[15/23] Train loss=0.31463488936424255
[20/23] Train loss=0.30140364170074463
Test set avg_accuracy=82.65% avg_sensitivity=55.20%, avg_specificity=91.51% avg_auc=0.8539
Best model saved!! Metric=-11.252017944742754!!
Fold[7] Epoch: 35 [35/100 (35%)] Train loss=0.352429 Test loss=0.415682 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3588498830795288
[5/23] Train loss=0.3555219769477844
[10/23] Train loss=0.39334750175476074
[15/23] Train loss=0.3147921562194824
[20/23] Train loss=0.2959730923175812
Test set avg_accuracy=82.23% avg_sensitivity=52.90%, avg_specificity=91.70% avg_auc=0.8514
Fold[7] Epoch: 36 [36/100 (36%)] Train loss=0.351019 Test loss=0.428944 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3484974801540375
[5/23] Train loss=0.34561672806739807
[10/23] Train loss=0.39060407876968384
[15/23] Train loss=0.3050215542316437
[20/23] Train loss=0.3025859296321869
Test set avg_accuracy=82.24% avg_sensitivity=54.31%, avg_specificity=91.26% avg_auc=0.8510
Fold[7] Epoch: 37 [37/100 (37%)] Train loss=0.347691 Test loss=0.430937 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3471277356147766
[5/23] Train loss=0.34768685698509216
[10/23] Train loss=0.3911101222038269
[15/23] Train loss=0.30293500423431396
[20/23] Train loss=0.2924515902996063
Test set avg_accuracy=82.60% avg_sensitivity=55.76%, avg_specificity=91.28% avg_auc=0.8526
Best model saved!! Metric=-11.105150513701405!!
Fold[7] Epoch: 38 [38/100 (38%)] Train loss=0.344839 Test loss=0.432286 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3513096570968628
[5/23] Train loss=0.3446815609931946
[10/23] Train loss=0.3892981708049774
[15/23] Train loss=0.3036261200904846
[20/23] Train loss=0.2897550165653229
Test set avg_accuracy=82.68% avg_sensitivity=55.93%, avg_specificity=91.32% avg_auc=0.8541
Best model saved!! Metric=-10.660421981792485!!
Fold[7] Epoch: 39 [39/100 (39%)] Train loss=0.342966 Test loss=0.426648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34695136547088623
[5/23] Train loss=0.35281902551651
[10/23] Train loss=0.3919975757598877
[15/23] Train loss=0.30157360434532166
[20/23] Train loss=0.29032954573631287
Test set avg_accuracy=82.43% avg_sensitivity=49.91%, avg_specificity=92.93% avg_auc=0.8513
Fold[7] Epoch: 40 [40/100 (40%)] Train loss=0.342378 Test loss=0.433301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34237056970596313
[5/23] Train loss=0.3490315079689026
[10/23] Train loss=0.3868124186992645
[15/23] Train loss=0.2976597547531128
[20/23] Train loss=0.2923568785190582
Test set avg_accuracy=82.35% avg_sensitivity=53.11%, avg_specificity=91.80% avg_auc=0.8510
Fold[7] Epoch: 41 [41/100 (41%)] Train loss=0.341480 Test loss=0.429654 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34368714690208435
[5/23] Train loss=0.3440153896808624
[10/23] Train loss=0.3799615204334259
[15/23] Train loss=0.2967587113380432
[20/23] Train loss=0.2807539403438568
Test set avg_accuracy=82.61% avg_sensitivity=57.25%, avg_specificity=90.81% avg_auc=0.8549
Best model saved!! Metric=-9.831294927708013!!
Fold[7] Epoch: 42 [42/100 (42%)] Train loss=0.336452 Test loss=0.421176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33827370405197144
[5/23] Train loss=0.3333969712257385
[10/23] Train loss=0.3790782690048218
[15/23] Train loss=0.29662054777145386
[20/23] Train loss=0.2817992568016052
Test set avg_accuracy=82.48% avg_sensitivity=51.54%, avg_specificity=92.48% avg_auc=0.8514
Fold[7] Epoch: 43 [43/100 (43%)] Train loss=0.335600 Test loss=0.435199 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3342677652835846
[5/23] Train loss=0.3416352868080139
[10/23] Train loss=0.3671961724758148
[15/23] Train loss=0.3081035614013672
[20/23] Train loss=0.284722238779068
Test set avg_accuracy=82.60% avg_sensitivity=56.78%, avg_specificity=90.95% avg_auc=0.8536
Fold[7] Epoch: 44 [44/100 (44%)] Train loss=0.334117 Test loss=0.434019 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33021965622901917
[5/23] Train loss=0.33143073320388794
[10/23] Train loss=0.36876380443573
[15/23] Train loss=0.2970430850982666
[20/23] Train loss=0.2733684778213501
Test set avg_accuracy=82.50% avg_sensitivity=56.19%, avg_specificity=91.00% avg_auc=0.8557
Fold[7] Epoch: 45 [45/100 (45%)] Train loss=0.327311 Test loss=0.420538 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33933648467063904
[5/23] Train loss=0.3315851390361786
[10/23] Train loss=0.3710819482803345
[15/23] Train loss=0.2909276485443115
[20/23] Train loss=0.2803201377391815
Test set avg_accuracy=82.52% avg_sensitivity=54.27%, avg_specificity=91.65% avg_auc=0.8526
Fold[7] Epoch: 46 [46/100 (46%)] Train loss=0.327899 Test loss=0.428254 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33269035816192627
[5/23] Train loss=0.324222207069397
[10/23] Train loss=0.366974800825119
[15/23] Train loss=0.29252681136131287
[20/23] Train loss=0.2748611569404602
Test set avg_accuracy=82.51% avg_sensitivity=54.99%, avg_specificity=91.40% avg_auc=0.8522
Fold[7] Epoch: 47 [47/100 (47%)] Train loss=0.325027 Test loss=0.426745 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.333607017993927
[5/23] Train loss=0.32648590207099915
[10/23] Train loss=0.3603571653366089
[15/23] Train loss=0.2793947160243988
[20/23] Train loss=0.2817242741584778
Test set avg_accuracy=82.31% avg_sensitivity=53.24%, avg_specificity=91.70% avg_auc=0.8512
Fold[7] Epoch: 48 [48/100 (48%)] Train loss=0.322249 Test loss=0.429795 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31726953387260437
[5/23] Train loss=0.3157397210597992
[10/23] Train loss=0.3543851971626282
[15/23] Train loss=0.28093230724334717
[20/23] Train loss=0.2723628282546997
Test set avg_accuracy=82.44% avg_sensitivity=57.51%, avg_specificity=90.49% avg_auc=0.8566
Fold[7] Epoch: 49 [49/100 (49%)] Train loss=0.320743 Test loss=0.418885 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33050674200057983
[5/23] Train loss=0.3250340521335602
[10/23] Train loss=0.35434189438819885
[15/23] Train loss=0.27257075905799866
[20/23] Train loss=0.26783716678619385
Test set avg_accuracy=82.61% avg_sensitivity=56.57%, avg_specificity=91.03% avg_auc=0.8559
Fold[7] Epoch: 50 [50/100 (50%)] Train loss=0.318287 Test loss=0.423356 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33144712448120117
[5/23] Train loss=0.3179650902748108
[10/23] Train loss=0.3503403961658478
[15/23] Train loss=0.27001479268074036
[20/23] Train loss=0.26754236221313477
Test set avg_accuracy=82.52% avg_sensitivity=53.71%, avg_specificity=91.83% avg_auc=0.8530
Fold[7] Epoch: 51 [51/100 (51%)] Train loss=0.314890 Test loss=0.430301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32441163063049316
[5/23] Train loss=0.3092762529850006
[10/23] Train loss=0.35452863574028015
[15/23] Train loss=0.26640045642852783
[20/23] Train loss=0.2669472098350525
Test set avg_accuracy=82.46% avg_sensitivity=52.69%, avg_specificity=92.08% avg_auc=0.8528
Fold[7] Epoch: 52 [52/100 (52%)] Train loss=0.313017 Test loss=0.437445 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3074680268764496
[5/23] Train loss=0.31258127093315125
[10/23] Train loss=0.34212711453437805
[15/23] Train loss=0.26845455169677734
[20/23] Train loss=0.26463818550109863
Test set avg_accuracy=82.52% avg_sensitivity=54.78%, avg_specificity=91.48% avg_auc=0.8537
Fold[7] Epoch: 53 [53/100 (53%)] Train loss=0.309722 Test loss=0.434515 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31547072529792786
[5/23] Train loss=0.3167571425437927
[10/23] Train loss=0.3454015851020813
[15/23] Train loss=0.26927095651626587
[20/23] Train loss=0.2537320852279663
Test set avg_accuracy=82.25% avg_sensitivity=54.35%, avg_specificity=91.26% avg_auc=0.8565
Fold[7] Epoch: 54 [54/100 (54%)] Train loss=0.309851 Test loss=0.435580 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3174878656864166
[5/23] Train loss=0.30670586228370667
[10/23] Train loss=0.3397294580936432
[15/23] Train loss=0.2599530518054962
[20/23] Train loss=0.2561778724193573
Test set avg_accuracy=82.43% avg_sensitivity=51.92%, avg_specificity=92.28% avg_auc=0.8518
Fold[7] Epoch: 55 [55/100 (55%)] Train loss=0.307356 Test loss=0.448540 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3139883875846863
[5/23] Train loss=0.30572769045829773
[10/23] Train loss=0.34337154030799866
[15/23] Train loss=0.2686287462711334
[20/23] Train loss=0.25774872303009033
Test set avg_accuracy=82.38% avg_sensitivity=53.84%, avg_specificity=91.59% avg_auc=0.8523
Fold[7] Epoch: 56 [56/100 (56%)] Train loss=0.303979 Test loss=0.437697 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31271472573280334
[5/23] Train loss=0.3039320111274719
[10/23] Train loss=0.33178552985191345
[15/23] Train loss=0.25948697328567505
[20/23] Train loss=0.2520325183868408
Test set avg_accuracy=82.59% avg_sensitivity=53.24%, avg_specificity=92.08% avg_auc=0.8560
Fold[7] Epoch: 57 [57/100 (57%)] Train loss=0.299644 Test loss=0.430783 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30516600608825684
[5/23] Train loss=0.3027844727039337
[10/23] Train loss=0.32928818464279175
[15/23] Train loss=0.2604770362377167
[20/23] Train loss=0.24649889767169952
Test set avg_accuracy=82.65% avg_sensitivity=55.03%, avg_specificity=91.57% avg_auc=0.8589
Fold[7] Epoch: 58 [58/100 (58%)] Train loss=0.301269 Test loss=0.424146 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.316518098115921
[5/23] Train loss=0.3019438087940216
[10/23] Train loss=0.33409610390663147
[15/23] Train loss=0.2625264525413513
[20/23] Train loss=0.24659788608551025
Test set avg_accuracy=82.62% avg_sensitivity=54.14%, avg_specificity=91.83% avg_auc=0.8550
Fold[7] Epoch: 59 [59/100 (59%)] Train loss=0.298749 Test loss=0.435036 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3036389946937561
[5/23] Train loss=0.29300495982170105
[10/23] Train loss=0.3256894052028656
[15/23] Train loss=0.24681273102760315
[20/23] Train loss=0.2482416182756424
Test set avg_accuracy=82.42% avg_sensitivity=52.47%, avg_specificity=92.09% avg_auc=0.8557
Fold[7] Epoch: 60 [60/100 (60%)] Train loss=0.296485 Test loss=0.437731 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2997351586818695
[5/23] Train loss=0.29418283700942993
[10/23] Train loss=0.31477421522140503
[15/23] Train loss=0.25002285838127136
[20/23] Train loss=0.24826228618621826
Test set avg_accuracy=82.45% avg_sensitivity=55.25%, avg_specificity=91.23% avg_auc=0.8574
Fold[7] Epoch: 61 [61/100 (61%)] Train loss=0.292984 Test loss=0.431344 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2976050078868866
[5/23] Train loss=0.2878780663013458
[10/23] Train loss=0.3122575581073761
[15/23] Train loss=0.2564443051815033
[20/23] Train loss=0.23799096047878265
Test set avg_accuracy=82.18% avg_sensitivity=52.18%, avg_specificity=91.87% avg_auc=0.8554
Fold[7] Epoch: 62 [62/100 (62%)] Train loss=0.288905 Test loss=0.436176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.309355229139328
[5/23] Train loss=0.28897565603256226
[10/23] Train loss=0.3182177245616913
[15/23] Train loss=0.24888955056667328
[20/23] Train loss=0.2529575824737549
Test set avg_accuracy=82.49% avg_sensitivity=54.61%, avg_specificity=91.50% avg_auc=0.8584
Fold[7] Epoch: 63 [63/100 (63%)] Train loss=0.291151 Test loss=0.430780 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29730886220932007
[5/23] Train loss=0.2851784825325012
[10/23] Train loss=0.313986212015152
[15/23] Train loss=0.2383464127779007
[20/23] Train loss=0.2367427796125412
Test set avg_accuracy=82.47% avg_sensitivity=54.44%, avg_specificity=91.52% avg_auc=0.8566
Fold[7] Epoch: 64 [64/100 (64%)] Train loss=0.284866 Test loss=0.427756 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29793664813041687
[5/23] Train loss=0.29269835352897644
[10/23] Train loss=0.3131006360054016
[15/23] Train loss=0.2561342418193817
[20/23] Train loss=0.23970158398151398
Test set avg_accuracy=82.50% avg_sensitivity=53.71%, avg_specificity=91.80% avg_auc=0.8556
Fold[7] Epoch: 65 [65/100 (65%)] Train loss=0.282226 Test loss=0.443846 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29837852716445923
[5/23] Train loss=0.28172582387924194
[10/23] Train loss=0.3008229732513428
[15/23] Train loss=0.24710942804813385
[20/23] Train loss=0.23740456998348236
Test set avg_accuracy=82.29% avg_sensitivity=58.79%, avg_specificity=89.88% avg_auc=0.8588
Best model saved!! Metric=-9.157922422367813!!
Fold[7] Epoch: 66 [66/100 (66%)] Train loss=0.279588 Test loss=0.435091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2903333306312561
[5/23] Train loss=0.2816047966480255
[10/23] Train loss=0.294854998588562
[15/23] Train loss=0.24202318489551544
[20/23] Train loss=0.23358933627605438
Test set avg_accuracy=82.19% avg_sensitivity=56.83%, avg_specificity=90.38% avg_auc=0.8561
Fold[7] Epoch: 67 [67/100 (67%)] Train loss=0.277498 Test loss=0.437987 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28382012248039246
[5/23] Train loss=0.28016236424446106
[10/23] Train loss=0.3041015863418579
[15/23] Train loss=0.2448641061782837
[20/23] Train loss=0.22714650630950928
Test set avg_accuracy=82.38% avg_sensitivity=53.46%, avg_specificity=91.72% avg_auc=0.8542
Fold[7] Epoch: 68 [68/100 (68%)] Train loss=0.280768 Test loss=0.437654 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2817625105381012
[5/23] Train loss=0.27259960770606995
[10/23] Train loss=0.30868327617645264
[15/23] Train loss=0.23239536583423615
[20/23] Train loss=0.2346227914094925
Test set avg_accuracy=81.77% avg_sensitivity=45.56%, avg_specificity=93.47% avg_auc=0.8503
Fold[7] Epoch: 69 [69/100 (69%)] Train loss=0.277314 Test loss=0.462771 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2786906063556671
[5/23] Train loss=0.2757137715816498
[10/23] Train loss=0.3043654263019562
[15/23] Train loss=0.23903167247772217
[20/23] Train loss=0.2256145179271698
Test set avg_accuracy=81.90% avg_sensitivity=48.63%, avg_specificity=92.64% avg_auc=0.8457
Fold[7] Epoch: 70 [70/100 (70%)] Train loss=0.276056 Test loss=0.474680 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27733373641967773
[5/23] Train loss=0.2734649181365967
[10/23] Train loss=0.29097646474838257
[15/23] Train loss=0.23695173859596252
[20/23] Train loss=0.22438198328018188
Test set avg_accuracy=82.42% avg_sensitivity=52.09%, avg_specificity=92.21% avg_auc=0.8511
Fold[7] Epoch: 71 [71/100 (71%)] Train loss=0.269638 Test loss=0.467697 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2789250314235687
[5/23] Train loss=0.27154871821403503
[10/23] Train loss=0.3035033941268921
[15/23] Train loss=0.2288665920495987
[20/23] Train loss=0.23143701255321503
Test set avg_accuracy=82.38% avg_sensitivity=51.45%, avg_specificity=92.36% avg_auc=0.8523
Fold[7] Epoch: 72 [72/100 (72%)] Train loss=0.277880 Test loss=0.470655 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27403315901756287
[5/23] Train loss=0.2706713080406189
[10/23] Train loss=0.28578290343284607
[15/23] Train loss=0.2428627610206604
[20/23] Train loss=0.22722922265529633
Test set avg_accuracy=82.38% avg_sensitivity=57.76%, avg_specificity=90.33% avg_auc=0.8567
Fold[7] Epoch: 73 [73/100 (73%)] Train loss=0.271637 Test loss=0.416095 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2838518023490906
[5/23] Train loss=0.26929226517677307
[10/23] Train loss=0.28890955448150635
[15/23] Train loss=0.22556793689727783
[20/23] Train loss=0.22167767584323883
Test set avg_accuracy=82.52% avg_sensitivity=57.47%, avg_specificity=90.61% avg_auc=0.8575
Fold[7] Epoch: 74 [74/100 (74%)] Train loss=0.267263 Test loss=0.445420 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27587562799453735
[5/23] Train loss=0.2597101628780365
[10/23] Train loss=0.2805677056312561
[15/23] Train loss=0.23166576027870178
[20/23] Train loss=0.21757793426513672
Test set avg_accuracy=82.36% avg_sensitivity=59.56%, avg_specificity=89.73% avg_auc=0.8606
Best model saved!! Metric=-8.283103787317202!!
Fold[7] Epoch: 75 [75/100 (75%)] Train loss=0.263192 Test loss=0.436902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27367842197418213
[5/23] Train loss=0.2615862786769867
[10/23] Train loss=0.2754323482513428
[15/23] Train loss=0.22485469281673431
[20/23] Train loss=0.22121736407279968
Test set avg_accuracy=82.27% avg_sensitivity=55.72%, avg_specificity=90.85% avg_auc=0.8514
Fold[7] Epoch: 76 [76/100 (76%)] Train loss=0.261971 Test loss=0.431115 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2665972411632538
[5/23] Train loss=0.2486116886138916
[10/23] Train loss=0.28048133850097656
[15/23] Train loss=0.22862979769706726
[20/23] Train loss=0.21766936779022217
Test set avg_accuracy=82.58% avg_sensitivity=59.00%, avg_specificity=90.20% avg_auc=0.8585
Fold[7] Epoch: 77 [77/100 (77%)] Train loss=0.258583 Test loss=0.436552 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2775496244430542
[5/23] Train loss=0.25566044449806213
[10/23] Train loss=0.268237441778183
[15/23] Train loss=0.22102798521518707
[20/23] Train loss=0.21543695032596588
Test set avg_accuracy=82.17% avg_sensitivity=55.59%, avg_specificity=90.75% avg_auc=0.8544
Fold[7] Epoch: 78 [78/100 (78%)] Train loss=0.256717 Test loss=0.445689 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2739858031272888
[5/23] Train loss=0.25638866424560547
[10/23] Train loss=0.26774948835372925
[15/23] Train loss=0.22103793919086456
[20/23] Train loss=0.20542608201503754
Test set avg_accuracy=82.04% avg_sensitivity=57.30%, avg_specificity=90.04% avg_auc=0.8552
Fold[7] Epoch: 79 [79/100 (79%)] Train loss=0.255453 Test loss=0.437879 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2634126842021942
[5/23] Train loss=0.24558968842029572
[10/23] Train loss=0.26715222001075745
[15/23] Train loss=0.21720340847969055
[20/23] Train loss=0.21402829885482788
Test set avg_accuracy=82.55% avg_sensitivity=52.99%, avg_specificity=92.10% avg_auc=0.8571
Fold[7] Epoch: 80 [80/100 (80%)] Train loss=0.256047 Test loss=0.437854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2571694552898407
[5/23] Train loss=0.2429204285144806
[10/23] Train loss=0.27147307991981506
[15/23] Train loss=0.22551418840885162
[20/23] Train loss=0.2098211944103241
Test set avg_accuracy=82.28% avg_sensitivity=51.71%, avg_specificity=92.16% avg_auc=0.8556
Fold[7] Epoch: 81 [81/100 (81%)] Train loss=0.255750 Test loss=0.449178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2624286413192749
[5/23] Train loss=0.2501336336135864
[10/23] Train loss=0.28926751017570496
[15/23] Train loss=0.2067977786064148
[20/23] Train loss=0.21444916725158691
Test set avg_accuracy=81.61% avg_sensitivity=44.84%, avg_specificity=93.50% avg_auc=0.8455
Fold[7] Epoch: 82 [82/100 (82%)] Train loss=0.255291 Test loss=0.481389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2666197717189789
[5/23] Train loss=0.24153879284858704
[10/23] Train loss=0.27091479301452637
[15/23] Train loss=0.2104155421257019
[20/23] Train loss=0.21028225123882294
Test set avg_accuracy=82.23% avg_sensitivity=50.94%, avg_specificity=92.34% avg_auc=0.8526
Fold[7] Epoch: 83 [83/100 (83%)] Train loss=0.251161 Test loss=0.472351 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2573274075984955
[5/23] Train loss=0.2595959007740021
[10/23] Train loss=0.2559926211833954
[15/23] Train loss=0.21254104375839233
[20/23] Train loss=0.211547389626503
Test set avg_accuracy=82.06% avg_sensitivity=51.37%, avg_specificity=91.98% avg_auc=0.8492
Fold[7] Epoch: 84 [84/100 (84%)] Train loss=0.248035 Test loss=0.491151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25084638595581055
[5/23] Train loss=0.2430799901485443
[10/23] Train loss=0.2586688697338104
[15/23] Train loss=0.20650887489318848
[20/23] Train loss=0.21005122363567352
Test set avg_accuracy=82.19% avg_sensitivity=55.50%, avg_specificity=90.81% avg_auc=0.8521
Fold[7] Epoch: 85 [85/100 (85%)] Train loss=0.244274 Test loss=0.475617 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26348868012428284
[5/23] Train loss=0.23482365906238556
[10/23] Train loss=0.25466814637184143
[15/23] Train loss=0.21125443279743195
[20/23] Train loss=0.20852941274642944
Test set avg_accuracy=82.01% avg_sensitivity=58.06%, avg_specificity=89.75% avg_auc=0.8548
Fold[7] Epoch: 86 [86/100 (86%)] Train loss=0.246251 Test loss=0.457359 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2542857229709625
[5/23] Train loss=0.24154318869113922
[10/23] Train loss=0.2518948018550873
[15/23] Train loss=0.20455402135849
[20/23] Train loss=0.21391336619853973
Test set avg_accuracy=82.31% avg_sensitivity=58.87%, avg_specificity=89.88% avg_auc=0.8581
Fold[7] Epoch: 87 [87/100 (87%)] Train loss=0.246620 Test loss=0.454309 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.241013765335083
[5/23] Train loss=0.2273528277873993
[10/23] Train loss=0.24857015907764435
[15/23] Train loss=0.20667250454425812
[20/23] Train loss=0.19987118244171143
Test set avg_accuracy=82.61% avg_sensitivity=57.94%, avg_specificity=90.59% avg_auc=0.8565
Fold[7] Epoch: 88 [88/100 (88%)] Train loss=0.240904 Test loss=0.448585 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2465168833732605
[5/23] Train loss=0.23508848249912262
[10/23] Train loss=0.2464095950126648
[15/23] Train loss=0.21264365315437317
[20/23] Train loss=0.19924695789813995
Test set avg_accuracy=82.23% avg_sensitivity=56.48%, avg_specificity=90.55% avg_auc=0.8544
Fold[7] Epoch: 89 [89/100 (89%)] Train loss=0.238386 Test loss=0.467638 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24131092429161072
[5/23] Train loss=0.23238644003868103
[10/23] Train loss=0.24897970259189606
[15/23] Train loss=0.21183015406131744
[20/23] Train loss=0.19613538682460785
Test set avg_accuracy=82.44% avg_sensitivity=54.22%, avg_specificity=91.55% avg_auc=0.8536
Fold[7] Epoch: 90 [90/100 (90%)] Train loss=0.240504 Test loss=0.460605 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2304099053144455
[5/23] Train loss=0.2376728057861328
[10/23] Train loss=0.24523238837718964
[15/23] Train loss=0.20870059728622437
[20/23] Train loss=0.1967659741640091
Test set avg_accuracy=82.00% avg_sensitivity=52.47%, avg_specificity=91.54% avg_auc=0.8529
Fold[7] Epoch: 91 [91/100 (91%)] Train loss=0.235327 Test loss=0.458425 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23769043385982513
[5/23] Train loss=0.23399730026721954
[10/23] Train loss=0.2507495880126953
[15/23] Train loss=0.20640473067760468
[20/23] Train loss=0.19062896072864532
Test set avg_accuracy=81.99% avg_sensitivity=52.52%, avg_specificity=91.51% avg_auc=0.8521
Fold[7] Epoch: 92 [92/100 (92%)] Train loss=0.236688 Test loss=0.461446 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24437078833580017
[5/23] Train loss=0.24027444422245026
[10/23] Train loss=0.2516888976097107
[15/23] Train loss=0.2124233841896057
[20/23] Train loss=0.20693109929561615
Test set avg_accuracy=82.04% avg_sensitivity=54.39%, avg_specificity=90.97% avg_auc=0.8551
Fold[7] Epoch: 93 [93/100 (93%)] Train loss=0.239357 Test loss=0.469042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23392653465270996
[5/23] Train loss=0.23097361624240875
[10/23] Train loss=0.23129813373088837
[15/23] Train loss=0.19308112561702728
[20/23] Train loss=0.19298332929611206
Test set avg_accuracy=82.08% avg_sensitivity=60.24%, avg_specificity=89.14% avg_auc=0.8505
Fold[7] Epoch: 94 [94/100 (94%)] Train loss=0.231648 Test loss=0.473346 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.252032607793808
[5/23] Train loss=0.2289378046989441
[10/23] Train loss=0.2386981099843979
[15/23] Train loss=0.2020861804485321
[20/23] Train loss=0.1848721206188202
Test set avg_accuracy=82.44% avg_sensitivity=55.25%, avg_specificity=91.22% avg_auc=0.8518
Fold[7] Epoch: 95 [95/100 (95%)] Train loss=0.226191 Test loss=0.480305 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22716981172561646
[5/23] Train loss=0.21834169328212738
[10/23] Train loss=0.2255827933549881
[15/23] Train loss=0.18735617399215698
[20/23] Train loss=0.1824093461036682
Test set avg_accuracy=82.26% avg_sensitivity=55.03%, avg_specificity=91.06% avg_auc=0.8561
Fold[7] Epoch: 96 [96/100 (96%)] Train loss=0.221028 Test loss=0.482178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2278592586517334
[5/23] Train loss=0.22141018509864807
[10/23] Train loss=0.23047159612178802
[15/23] Train loss=0.1866726279258728
[20/23] Train loss=0.18671467900276184
Test set avg_accuracy=82.27% avg_sensitivity=54.10%, avg_specificity=91.37% avg_auc=0.8504
Fold[7] Epoch: 97 [97/100 (97%)] Train loss=0.219810 Test loss=0.475707 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22117826342582703
[5/23] Train loss=0.21171151101589203
[10/23] Train loss=0.22389806807041168
[15/23] Train loss=0.1868402510881424
[20/23] Train loss=0.1833481341600418
Test set avg_accuracy=82.06% avg_sensitivity=51.88%, avg_specificity=91.81% avg_auc=0.8462
Fold[7] Epoch: 98 [98/100 (98%)] Train loss=0.219554 Test loss=0.497636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22135144472122192
[5/23] Train loss=0.21408875286579132
[10/23] Train loss=0.21572142839431763
[15/23] Train loss=0.19050730764865875
[20/23] Train loss=0.17587946355342865
Test set avg_accuracy=82.16% avg_sensitivity=55.97%, avg_specificity=90.61% avg_auc=0.8529
Fold[7] Epoch: 99 [99/100 (99%)] Train loss=0.217556 Test loss=0.478218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21303190290927887
[5/23] Train loss=0.2175542116165161
[10/23] Train loss=0.22362253069877625
[15/23] Train loss=0.18456701934337616
[20/23] Train loss=0.17411023378372192
Test set avg_accuracy=82.28% avg_sensitivity=55.16%, avg_specificity=91.04% avg_auc=0.8523
Fold[7] Epoch: 100 [100/100 (100%)] Train loss=0.214877 Test loss=0.486271 Current lr=[3.9999999999999996e-05]

Fold[7] Best Result: acc=82.36458333333333 sen=59.55631399317406, spe=89.73263506063948, auc=0.8606336382553593!
[0/23] Train loss=0.712537944316864
[5/23] Train loss=0.6861116290092468
[10/23] Train loss=0.555115818977356
[15/23] Train loss=0.5699453353881836
[20/23] Train loss=0.531414806842804
Test set avg_accuracy=76.84% avg_sensitivity=0.40%, avg_specificity=99.85% avg_auc=0.5521
Best model saved!! Metric=-93.6966123009657!!
Fold[8] Epoch: 1 [1/100 (1%)] Train loss=0.587466 Test loss=0.582267 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5660471320152283
[5/23] Train loss=0.5921062231063843
[10/23] Train loss=0.5046417117118835
[15/23] Train loss=0.5314218401908875
[20/23] Train loss=0.4988940358161926
Test set avg_accuracy=77.07% avg_sensitivity=5.21%, avg_specificity=98.70% avg_auc=0.6104
Best model saved!! Metric=-83.97151367324301!!
Fold[8] Epoch: 2 [2/100 (2%)] Train loss=0.545279 Test loss=0.546518 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5439485311508179
[5/23] Train loss=0.5417446494102478
[10/23] Train loss=0.47803041338920593
[15/23] Train loss=0.4798453450202942
[20/23] Train loss=0.4464725852012634
Test set avg_accuracy=77.50% avg_sensitivity=11.41%, avg_specificity=97.39% avg_auc=0.6833
Best model saved!! Metric=-71.37701675167177!!
Fold[8] Epoch: 3 [3/100 (3%)] Train loss=0.510587 Test loss=0.552497 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5146914720535278
[5/23] Train loss=0.49275708198547363
[10/23] Train loss=0.47326138615608215
[15/23] Train loss=0.43843215703964233
[20/23] Train loss=0.4154767692089081
Test set avg_accuracy=78.19% avg_sensitivity=17.81%, avg_specificity=96.36% avg_auc=0.7160
Best model saved!! Metric=-62.04604139016419!!
Fold[8] Epoch: 4 [4/100 (4%)] Train loss=0.481105 Test loss=0.574239 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48176395893096924
[5/23] Train loss=0.46064451336860657
[10/23] Train loss=0.4775833487510681
[15/23] Train loss=0.4266136884689331
[20/23] Train loss=0.40290677547454834
Test set avg_accuracy=78.94% avg_sensitivity=24.11%, avg_specificity=95.45% avg_auc=0.7388
Best model saved!! Metric=-53.61694645356138!!
Fold[8] Epoch: 5 [5/100 (5%)] Train loss=0.465773 Test loss=0.561358 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4539289176464081
[5/23] Train loss=0.45280760526657104
[10/23] Train loss=0.48835432529449463
[15/23] Train loss=0.426808625459671
[20/23] Train loss=0.3882271647453308
Test set avg_accuracy=79.51% avg_sensitivity=26.74%, avg_specificity=95.39% avg_auc=0.7535
Best model saved!! Metric=-49.01684799177233!!
Fold[8] Epoch: 6 [6/100 (6%)] Train loss=0.455186 Test loss=0.566034 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43741488456726074
[5/23] Train loss=0.4404914677143097
[10/23] Train loss=0.477347195148468
[15/23] Train loss=0.42886507511138916
[20/23] Train loss=0.38147810101509094
Test set avg_accuracy=80.09% avg_sensitivity=29.41%, avg_specificity=95.34% avg_auc=0.7753
Best model saved!! Metric=-43.619734869645825!!
Fold[8] Epoch: 7 [7/100 (7%)] Train loss=0.447088 Test loss=0.532353 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42680633068084717
[5/23] Train loss=0.43457746505737305
[10/23] Train loss=0.47039732336997986
[15/23] Train loss=0.4206794500350952
[20/23] Train loss=0.38168060779571533
Test set avg_accuracy=80.33% avg_sensitivity=31.70%, avg_specificity=94.97% avg_auc=0.7771
Best model saved!! Metric=-41.2896658232101!!
Fold[8] Epoch: 8 [8/100 (8%)] Train loss=0.439952 Test loss=0.512016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4254487454891205
[5/23] Train loss=0.42293068766593933
[10/23] Train loss=0.4706513285636902
[15/23] Train loss=0.4100784659385681
[20/23] Train loss=0.37265118956565857
Test set avg_accuracy=80.32% avg_sensitivity=33.13%, avg_specificity=94.52% avg_auc=0.7826
Best model saved!! Metric=-39.765130120421965!!
Fold[8] Epoch: 9 [9/100 (9%)] Train loss=0.434425 Test loss=0.514555 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4281489849090576
[5/23] Train loss=0.42226770520210266
[10/23] Train loss=0.47212380170822144
[15/23] Train loss=0.4239695370197296
[20/23] Train loss=0.37758585810661316
Test set avg_accuracy=80.60% avg_sensitivity=33.93%, avg_specificity=94.64% avg_auc=0.8025
Best model saved!! Metric=-36.58198906416901!!
Fold[8] Epoch: 10 [10/100 (10%)] Train loss=0.432040 Test loss=0.504519 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4206501245498657
[5/23] Train loss=0.42193517088890076
[10/23] Train loss=0.46109068393707275
[15/23] Train loss=0.4080180525779724
[20/23] Train loss=0.3795303404331207
Test set avg_accuracy=80.76% avg_sensitivity=37.35%, avg_specificity=93.82% avg_auc=0.8162
Best model saved!! Metric=-32.44967531932261!!
Fold[8] Epoch: 11 [11/100 (11%)] Train loss=0.426102 Test loss=0.473013 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41936546564102173
[5/23] Train loss=0.4127935767173767
[10/23] Train loss=0.46149447560310364
[15/23] Train loss=0.39419442415237427
[20/23] Train loss=0.3653273284435272
Test set avg_accuracy=81.02% avg_sensitivity=37.80%, avg_specificity=94.03% avg_auc=0.8211
Best model saved!! Metric=-31.043886190986925!!
Fold[8] Epoch: 12 [12/100 (12%)] Train loss=0.419518 Test loss=0.468832 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.413162499666214
[5/23] Train loss=0.41348788142204285
[10/23] Train loss=0.46306151151657104
[15/23] Train loss=0.40189141035079956
[20/23] Train loss=0.36524179577827454
Test set avg_accuracy=81.11% avg_sensitivity=38.44%, avg_specificity=93.95% avg_auc=0.8250
Best model saved!! Metric=-29.99403610718081!!
Fold[8] Epoch: 13 [13/100 (13%)] Train loss=0.415956 Test loss=0.465516 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40768635272979736
[5/23] Train loss=0.4099672734737396
[10/23] Train loss=0.45298895239830017
[15/23] Train loss=0.39638423919677734
[20/23] Train loss=0.3559415340423584
Test set avg_accuracy=81.32% avg_sensitivity=41.02%, avg_specificity=93.45% avg_auc=0.8313
Best model saved!! Metric=-27.078361892968864!!
Fold[8] Epoch: 14 [14/100 (14%)] Train loss=0.412138 Test loss=0.440777 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40647754073143005
[5/23] Train loss=0.40432167053222656
[10/23] Train loss=0.4517417550086975
[15/23] Train loss=0.386947900056839
[20/23] Train loss=0.35570305585861206
Test set avg_accuracy=81.41% avg_sensitivity=42.06%, avg_specificity=93.25% avg_auc=0.8326
Best model saved!! Metric=-26.01126287719705!!
Fold[8] Epoch: 15 [15/100 (15%)] Train loss=0.407160 Test loss=0.435754 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41129788756370544
[5/23] Train loss=0.39994052052497864
[10/23] Train loss=0.4513588845729828
[15/23] Train loss=0.3814696967601776
[20/23] Train loss=0.3485414385795593
Test set avg_accuracy=81.62% avg_sensitivity=42.46%, avg_specificity=93.40% avg_auc=0.8350
Best model saved!! Metric=-25.015418115142126!!
Fold[8] Epoch: 16 [16/100 (16%)] Train loss=0.405342 Test loss=0.431417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4019888639450073
[5/23] Train loss=0.40113815665245056
[10/23] Train loss=0.44750601053237915
[15/23] Train loss=0.378950834274292
[20/23] Train loss=0.3369424045085907
Test set avg_accuracy=81.59% avg_sensitivity=43.60%, avg_specificity=93.03% avg_auc=0.8438
Best model saved!! Metric=-23.390099988306865!!
Fold[8] Epoch: 17 [17/100 (17%)] Train loss=0.403739 Test loss=0.420017 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39937931299209595
[5/23] Train loss=0.39201176166534424
[10/23] Train loss=0.4465469717979431
[15/23] Train loss=0.36565732955932617
[20/23] Train loss=0.3447267711162567
Test set avg_accuracy=81.89% avg_sensitivity=46.88%, avg_specificity=92.43% avg_auc=0.8512
Best model saved!! Metric=-19.678848419931!!
Fold[8] Epoch: 18 [18/100 (18%)] Train loss=0.397947 Test loss=0.403863 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40906068682670593
[5/23] Train loss=0.3952638506889343
[10/23] Train loss=0.4429258704185486
[15/23] Train loss=0.3683454096317291
[20/23] Train loss=0.3383111357688904
Test set avg_accuracy=81.99% avg_sensitivity=46.83%, avg_specificity=92.57% avg_auc=0.8528
Best model saved!! Metric=-19.34153953511928!!
Fold[8] Epoch: 19 [19/100 (19%)] Train loss=0.395182 Test loss=0.404238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3902686536312103
[5/23] Train loss=0.3943942189216614
[10/23] Train loss=0.4435999393463135
[15/23] Train loss=0.360625684261322
[20/23] Train loss=0.3364289700984955
Test set avg_accuracy=82.20% avg_sensitivity=47.97%, avg_specificity=92.51% avg_auc=0.8549
Best model saved!! Metric=-17.83236116581567!!
Fold[8] Epoch: 20 [20/100 (20%)] Train loss=0.392256 Test loss=0.402531 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38946229219436646
[5/23] Train loss=0.39123910665512085
[10/23] Train loss=0.4404297173023224
[15/23] Train loss=0.3611770570278168
[20/23] Train loss=0.3315828740596771
Test set avg_accuracy=82.09% avg_sensitivity=45.78%, avg_specificity=93.01% avg_auc=0.8510
Fold[8] Epoch: 21 [21/100 (21%)] Train loss=0.392267 Test loss=0.417775 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38210418820381165
[5/23] Train loss=0.3867821991443634
[10/23] Train loss=0.4422643780708313
[15/23] Train loss=0.3633122146129608
[20/23] Train loss=0.33292824029922485
Test set avg_accuracy=81.94% avg_sensitivity=45.78%, avg_specificity=92.82% avg_auc=0.8526
Fold[8] Epoch: 22 [22/100 (22%)] Train loss=0.390372 Test loss=0.412536 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38308021426200867
[5/23] Train loss=0.38599511981010437
[10/23] Train loss=0.4354436993598938
[15/23] Train loss=0.3732798993587494
[20/23] Train loss=0.3296048641204834
Test set avg_accuracy=82.13% avg_sensitivity=45.73%, avg_specificity=93.09% avg_auc=0.8507
Fold[8] Epoch: 23 [23/100 (23%)] Train loss=0.389210 Test loss=0.424851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38257429003715515
[5/23] Train loss=0.38158661127090454
[10/23] Train loss=0.42580050230026245
[15/23] Train loss=0.3568545877933502
[20/23] Train loss=0.33151599764823914
Test set avg_accuracy=82.23% avg_sensitivity=49.40%, avg_specificity=92.10% avg_auc=0.8594
Best model saved!! Metric=-16.329095483648437!!
Fold[8] Epoch: 24 [24/100 (24%)] Train loss=0.384628 Test loss=0.397576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38233432173728943
[5/23] Train loss=0.3786953389644623
[10/23] Train loss=0.4261747896671295
[15/23] Train loss=0.3465978801250458
[20/23] Train loss=0.3228828012943268
Test set avg_accuracy=82.24% avg_sensitivity=51.24%, avg_specificity=91.57% avg_auc=0.8614
Best model saved!! Metric=-14.813283864993178!!
Fold[8] Epoch: 25 [25/100 (25%)] Train loss=0.380745 Test loss=0.390257 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38145723938941956
[5/23] Train loss=0.37030673027038574
[10/23] Train loss=0.4303842782974243
[15/23] Train loss=0.34313032031059265
[20/23] Train loss=0.32056355476379395
Test set avg_accuracy=82.05% avg_sensitivity=52.73%, avg_specificity=90.88% avg_auc=0.8620
Best model saved!! Metric=-14.141011433046566!!
Fold[8] Epoch: 26 [26/100 (26%)] Train loss=0.375992 Test loss=0.389644 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38756871223449707
[5/23] Train loss=0.37566038966178894
[10/23] Train loss=0.4250842034816742
[15/23] Train loss=0.34179797768592834
[20/23] Train loss=0.312545508146286
Test set avg_accuracy=82.08% avg_sensitivity=48.51%, avg_specificity=92.18% avg_auc=0.8593
Fold[8] Epoch: 27 [27/100 (27%)] Train loss=0.375416 Test loss=0.404360 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36596548557281494
[5/23] Train loss=0.37411582469940186
[10/23] Train loss=0.42636391520500183
[15/23] Train loss=0.3480606973171234
[20/23] Train loss=0.3125125467777252
Test set avg_accuracy=82.13% avg_sensitivity=47.62%, avg_specificity=92.52% avg_auc=0.8574
Fold[8] Epoch: 28 [28/100 (28%)] Train loss=0.376075 Test loss=0.411192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3617442548274994
[5/23] Train loss=0.3796890676021576
[10/23] Train loss=0.4295889139175415
[15/23] Train loss=0.35539790987968445
[20/23] Train loss=0.3104704022407532
Test set avg_accuracy=82.03% avg_sensitivity=47.02%, avg_specificity=92.57% avg_auc=0.8569
Fold[8] Epoch: 29 [29/100 (29%)] Train loss=0.374896 Test loss=0.411612 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3681250512599945
[5/23] Train loss=0.3642892837524414
[10/23] Train loss=0.41353920102119446
[15/23] Train loss=0.34697556495666504
[20/23] Train loss=0.31565025448799133
Test set avg_accuracy=82.21% avg_sensitivity=49.01%, avg_specificity=92.21% avg_auc=0.8589
Fold[8] Epoch: 30 [30/100 (30%)] Train loss=0.372011 Test loss=0.404414 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36690422892570496
[5/23] Train loss=0.3670594394207001
[10/23] Train loss=0.407970666885376
[15/23] Train loss=0.33392056822776794
[20/23] Train loss=0.302886426448822
Test set avg_accuracy=82.58% avg_sensitivity=53.47%, avg_specificity=91.34% avg_auc=0.8642
Best model saved!! Metric=-12.17974739645536!!
Fold[8] Epoch: 31 [31/100 (31%)] Train loss=0.366444 Test loss=0.390307 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38198745250701904
[5/23] Train loss=0.354375958442688
[10/23] Train loss=0.4139087200164795
[15/23] Train loss=0.32901227474212646
[20/23] Train loss=0.30207470059394836
Test set avg_accuracy=82.70% avg_sensitivity=52.03%, avg_specificity=91.92% avg_auc=0.8652
Fold[8] Epoch: 32 [32/100 (32%)] Train loss=0.363056 Test loss=0.391237 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3710814416408539
[5/23] Train loss=0.36409926414489746
[10/23] Train loss=0.409640371799469
[15/23] Train loss=0.3326534330844879
[20/23] Train loss=0.29902809858322144
Test set avg_accuracy=82.40% avg_sensitivity=50.45%, avg_specificity=92.01% avg_auc=0.8623
Fold[8] Epoch: 33 [33/100 (33%)] Train loss=0.362825 Test loss=0.403778 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3506357669830322
[5/23] Train loss=0.358977735042572
[10/23] Train loss=0.4133641719818115
[15/23] Train loss=0.33080607652664185
[20/23] Train loss=0.2956087589263916
Test set avg_accuracy=82.19% avg_sensitivity=49.31%, avg_specificity=92.09% avg_auc=0.8612
Fold[8] Epoch: 34 [34/100 (34%)] Train loss=0.360458 Test loss=0.410808 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34999507665634155
[5/23] Train loss=0.35739409923553467
[10/23] Train loss=0.401671439409256
[15/23] Train loss=0.32093527913093567
[20/23] Train loss=0.29939109086990356
Test set avg_accuracy=82.47% avg_sensitivity=54.81%, avg_specificity=90.79% avg_auc=0.8673
Best model saved!! Metric=-11.204369955671961!!
Fold[8] Epoch: 35 [35/100 (35%)] Train loss=0.358484 Test loss=0.390216 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3588568866252899
[5/23] Train loss=0.3482075333595276
[10/23] Train loss=0.4186893701553345
[15/23] Train loss=0.33459824323654175
[20/23] Train loss=0.30638575553894043
Test set avg_accuracy=82.71% avg_sensitivity=51.88%, avg_specificity=91.98% avg_auc=0.8653
Fold[8] Epoch: 36 [36/100 (36%)] Train loss=0.360468 Test loss=0.401404 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35950809717178345
[5/23] Train loss=0.34840652346611023
[10/23] Train loss=0.40063920617103577
[15/23] Train loss=0.3171667158603668
[20/23] Train loss=0.2922022342681885
Test set avg_accuracy=82.88% avg_sensitivity=56.15%, avg_specificity=90.92% avg_auc=0.8688
Best model saved!! Metric=-9.16570957948041!!
Fold[8] Epoch: 37 [37/100 (37%)] Train loss=0.355241 Test loss=0.387618 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3503366708755493
[5/23] Train loss=0.34216177463531494
[10/23] Train loss=0.3939959406852722
[15/23] Train loss=0.3163837492465973
[20/23] Train loss=0.29284775257110596
Test set avg_accuracy=82.74% avg_sensitivity=55.65%, avg_specificity=90.89% avg_auc=0.8680
Fold[8] Epoch: 38 [38/100 (38%)] Train loss=0.350860 Test loss=0.391068 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3421856164932251
[5/23] Train loss=0.34363359212875366
[10/23] Train loss=0.3872394263744354
[15/23] Train loss=0.3125978410243988
[20/23] Train loss=0.2904208302497864
Test set avg_accuracy=82.82% avg_sensitivity=56.99%, avg_specificity=90.60% avg_auc=0.8683
Best model saved!! Metric=-8.759478468255693!!
Fold[8] Epoch: 39 [39/100 (39%)] Train loss=0.349539 Test loss=0.387313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34899547696113586
[5/23] Train loss=0.3367510437965393
[10/23] Train loss=0.3899284601211548
[15/23] Train loss=0.3153822720050812
[20/23] Train loss=0.2824224829673767
Test set avg_accuracy=82.90% avg_sensitivity=54.71%, avg_specificity=91.39% avg_auc=0.8652
Fold[8] Epoch: 40 [40/100 (40%)] Train loss=0.346871 Test loss=0.396487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3459945321083069
[5/23] Train loss=0.33572205901145935
[10/23] Train loss=0.3881033658981323
[15/23] Train loss=0.30584385991096497
[20/23] Train loss=0.2858065664768219
Test set avg_accuracy=82.85% avg_sensitivity=55.41%, avg_specificity=91.10% avg_auc=0.8677
Fold[8] Epoch: 41 [41/100 (41%)] Train loss=0.344455 Test loss=0.390159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3588721752166748
[5/23] Train loss=0.33938974142074585
[10/23] Train loss=0.3822939693927765
[15/23] Train loss=0.30470526218414307
[20/23] Train loss=0.279365599155426
Test set avg_accuracy=82.75% avg_sensitivity=54.61%, avg_specificity=91.22% avg_auc=0.8651
Fold[8] Epoch: 42 [42/100 (42%)] Train loss=0.341696 Test loss=0.400873 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33796730637550354
[5/23] Train loss=0.33538302779197693
[10/23] Train loss=0.3846048414707184
[15/23] Train loss=0.303729772567749
[20/23] Train loss=0.2799815833568573
Test set avg_accuracy=82.60% avg_sensitivity=51.93%, avg_specificity=91.83% avg_auc=0.8594
Fold[8] Epoch: 43 [43/100 (43%)] Train loss=0.341619 Test loss=0.397325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3386891782283783
[5/23] Train loss=0.33882397413253784
[10/23] Train loss=0.38408100605010986
[15/23] Train loss=0.3124515414237976
[20/23] Train loss=0.2773415148258209
Test set avg_accuracy=82.32% avg_sensitivity=49.45%, avg_specificity=92.21% avg_auc=0.8577
Fold[8] Epoch: 44 [44/100 (44%)] Train loss=0.341689 Test loss=0.416686 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33496639132499695
[5/23] Train loss=0.32730573415756226
[10/23] Train loss=0.37316274642944336
[15/23] Train loss=0.29566219449043274
[20/23] Train loss=0.27976441383361816
Test set avg_accuracy=82.82% avg_sensitivity=57.24%, avg_specificity=90.52% avg_auc=0.8645
Fold[8] Epoch: 45 [45/100 (45%)] Train loss=0.336622 Test loss=0.386532 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3357447385787964
[5/23] Train loss=0.3269481062889099
[10/23] Train loss=0.37919872999191284
[15/23] Train loss=0.302868127822876
[20/23] Train loss=0.2791951298713684
Test set avg_accuracy=82.85% avg_sensitivity=54.96%, avg_specificity=91.24% avg_auc=0.8643
Fold[8] Epoch: 46 [46/100 (46%)] Train loss=0.335678 Test loss=0.403337 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32587045431137085
[5/23] Train loss=0.32118818163871765
[10/23] Train loss=0.3625448942184448
[15/23] Train loss=0.2939298748970032
[20/23] Train loss=0.272381454706192
Test set avg_accuracy=82.74% avg_sensitivity=59.57%, avg_specificity=89.71% avg_auc=0.8630
Best model saved!! Metric=-7.672481337001502!!
Fold[8] Epoch: 47 [47/100 (47%)] Train loss=0.328907 Test loss=0.389896 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3352194130420685
[5/23] Train loss=0.3173508644104004
[10/23] Train loss=0.36264339089393616
[15/23] Train loss=0.29220178723335266
[20/23] Train loss=0.2663188576698303
Test set avg_accuracy=82.75% avg_sensitivity=53.37%, avg_specificity=91.60% avg_auc=0.8630
Fold[8] Epoch: 48 [48/100 (48%)] Train loss=0.327829 Test loss=0.409557 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32675114274024963
[5/23] Train loss=0.3165702223777771
[10/23] Train loss=0.3649919629096985
[15/23] Train loss=0.28946995735168457
[20/23] Train loss=0.26508840918540955
Test set avg_accuracy=82.94% avg_sensitivity=55.01%, avg_specificity=91.34% avg_auc=0.8654
Fold[8] Epoch: 49 [49/100 (49%)] Train loss=0.327151 Test loss=0.389609 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3275461494922638
[5/23] Train loss=0.31949955224990845
[10/23] Train loss=0.36571213603019714
[15/23] Train loss=0.28905075788497925
[20/23] Train loss=0.2717048227787018
Test set avg_accuracy=82.57% avg_sensitivity=54.71%, avg_specificity=90.95% avg_auc=0.8660
Fold[8] Epoch: 50 [50/100 (50%)] Train loss=0.325897 Test loss=0.395271 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3310743570327759
[5/23] Train loss=0.31950992345809937
[10/23] Train loss=0.35786205530166626
[15/23] Train loss=0.2880915403366089
[20/23] Train loss=0.270512193441391
Test set avg_accuracy=82.96% avg_sensitivity=55.06%, avg_specificity=91.36% avg_auc=0.8648
Fold[8] Epoch: 51 [51/100 (51%)] Train loss=0.324227 Test loss=0.395429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3207378685474396
[5/23] Train loss=0.30545496940612793
[10/23] Train loss=0.35723310708999634
[15/23] Train loss=0.2787616550922394
[20/23] Train loss=0.26452264189720154
Test set avg_accuracy=82.78% avg_sensitivity=53.77%, avg_specificity=91.51% avg_auc=0.8633
Fold[8] Epoch: 52 [52/100 (52%)] Train loss=0.320008 Test loss=0.394811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32058820128440857
[5/23] Train loss=0.3124254047870636
[10/23] Train loss=0.3556614816188812
[15/23] Train loss=0.2771977484226227
[20/23] Train loss=0.26599857211112976
Test set avg_accuracy=82.73% avg_sensitivity=54.02%, avg_specificity=91.37% avg_auc=0.8629
Fold[8] Epoch: 53 [53/100 (53%)] Train loss=0.319260 Test loss=0.400095 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3188404142856598
[5/23] Train loss=0.31149032711982727
[10/23] Train loss=0.35985803604125977
[15/23] Train loss=0.2750317454338074
[20/23] Train loss=0.2600369155406952
Test set avg_accuracy=82.72% avg_sensitivity=53.52%, avg_specificity=91.51% avg_auc=0.8582
Fold[8] Epoch: 54 [54/100 (54%)] Train loss=0.316256 Test loss=0.407825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3111896812915802
[5/23] Train loss=0.30887824296951294
[10/23] Train loss=0.3484265208244324
[15/23] Train loss=0.27477481961250305
[20/23] Train loss=0.260338693857193
Test set avg_accuracy=82.54% avg_sensitivity=54.22%, avg_specificity=91.06% avg_auc=0.8635
Fold[8] Epoch: 55 [55/100 (55%)] Train loss=0.316450 Test loss=0.399793 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31773504614830017
[5/23] Train loss=0.301748126745224
[10/23] Train loss=0.34493306279182434
[15/23] Train loss=0.2716636657714844
[20/23] Train loss=0.25553351640701294
Test set avg_accuracy=82.81% avg_sensitivity=58.98%, avg_specificity=89.98% avg_auc=0.8609
Fold[8] Epoch: 56 [56/100 (56%)] Train loss=0.310974 Test loss=0.404873 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31815028190612793
[5/23] Train loss=0.3105955123901367
[10/23] Train loss=0.3445832431316376
[15/23] Train loss=0.2752113342285156
[20/23] Train loss=0.2574242949485779
Test set avg_accuracy=82.72% avg_sensitivity=54.46%, avg_specificity=91.22% avg_auc=0.8614
Fold[8] Epoch: 57 [57/100 (57%)] Train loss=0.312964 Test loss=0.422179 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3072383999824524
[5/23] Train loss=0.2938416302204132
[10/23] Train loss=0.342393159866333
[15/23] Train loss=0.2677578628063202
[20/23] Train loss=0.2532235085964203
Test set avg_accuracy=82.52% avg_sensitivity=54.66%, avg_specificity=90.91% avg_auc=0.8509
Fold[8] Epoch: 58 [58/100 (58%)] Train loss=0.310234 Test loss=0.413376 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3033131957054138
[5/23] Train loss=0.303447961807251
[10/23] Train loss=0.3421591818332672
[15/23] Train loss=0.27044111490249634
[20/23] Train loss=0.2536461651325226
Test set avg_accuracy=82.54% avg_sensitivity=52.28%, avg_specificity=91.64% avg_auc=0.8653
Fold[8] Epoch: 59 [59/100 (59%)] Train loss=0.308818 Test loss=0.411970 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2990032434463501
[5/23] Train loss=0.29671579599380493
[10/23] Train loss=0.34855303168296814
[15/23] Train loss=0.26470646262168884
[20/23] Train loss=0.24572178721427917
Test set avg_accuracy=82.48% avg_sensitivity=51.84%, avg_specificity=91.70% avg_auc=0.8638
Fold[8] Epoch: 60 [60/100 (60%)] Train loss=0.306532 Test loss=0.416154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30343833565711975
[5/23] Train loss=0.29493165016174316
[10/23] Train loss=0.3433710038661957
[15/23] Train loss=0.27310439944267273
[20/23] Train loss=0.25807446241378784
Test set avg_accuracy=82.64% avg_sensitivity=50.94%, avg_specificity=92.18% avg_auc=0.8574
Fold[8] Epoch: 61 [61/100 (61%)] Train loss=0.308511 Test loss=0.415384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3080514073371887
[5/23] Train loss=0.302509069442749
[10/23] Train loss=0.3300632834434509
[15/23] Train loss=0.26396486163139343
[20/23] Train loss=0.24260848760604858
Test set avg_accuracy=83.12% avg_sensitivity=56.55%, avg_specificity=91.12% avg_auc=0.8660
Fold[8] Epoch: 62 [62/100 (62%)] Train loss=0.307240 Test loss=0.411982 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.304627388715744
[5/23] Train loss=0.2887401878833771
[10/23] Train loss=0.3171936869621277
[15/23] Train loss=0.25356781482696533
[20/23] Train loss=0.2465890645980835
Test set avg_accuracy=83.01% avg_sensitivity=59.52%, avg_specificity=90.07% avg_auc=0.8600
Best model saved!! Metric=-7.400864094069185!!
Fold[8] Epoch: 63 [63/100 (63%)] Train loss=0.298016 Test loss=0.423855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3063327372074127
[5/23] Train loss=0.27768874168395996
[10/23] Train loss=0.316255658864975
[15/23] Train loss=0.2600457966327667
[20/23] Train loss=0.2485520988702774
Test set avg_accuracy=82.90% avg_sensitivity=56.99%, avg_specificity=90.70% avg_auc=0.8656
Fold[8] Epoch: 64 [64/100 (64%)] Train loss=0.298293 Test loss=0.423142 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30805525183677673
[5/23] Train loss=0.2908996641635895
[10/23] Train loss=0.3173903226852417
[15/23] Train loss=0.2564481794834137
[20/23] Train loss=0.24738995730876923
Test set avg_accuracy=82.28% avg_sensitivity=50.89%, avg_specificity=91.73% avg_auc=0.8617
Fold[8] Epoch: 65 [65/100 (65%)] Train loss=0.305373 Test loss=0.420487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2937045693397522
[5/23] Train loss=0.2782500982284546
[10/23] Train loss=0.3261748254299164
[15/23] Train loss=0.2531003952026367
[20/23] Train loss=0.2425840198993683
Test set avg_accuracy=83.06% avg_sensitivity=56.50%, avg_specificity=91.06% avg_auc=0.8611
Fold[8] Epoch: 66 [66/100 (66%)] Train loss=0.296310 Test loss=0.406015 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29179829359054565
[5/23] Train loss=0.28647443652153015
[10/23] Train loss=0.3065735101699829
[15/23] Train loss=0.25230562686920166
[20/23] Train loss=0.2402036488056183
Test set avg_accuracy=82.64% avg_sensitivity=53.67%, avg_specificity=91.36% avg_auc=0.8563
Fold[8] Epoch: 67 [67/100 (67%)] Train loss=0.295214 Test loss=0.417048 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2838900685310364
[5/23] Train loss=0.2849210202693939
[10/23] Train loss=0.3265901803970337
[15/23] Train loss=0.26409876346588135
[20/23] Train loss=0.23949266970157623
Test set avg_accuracy=82.89% avg_sensitivity=51.64%, avg_specificity=92.30% avg_auc=0.8587
Fold[8] Epoch: 68 [68/100 (68%)] Train loss=0.293217 Test loss=0.421157 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28023454546928406
[5/23] Train loss=0.2833607792854309
[10/23] Train loss=0.3023928999900818
[15/23] Train loss=0.24151892960071564
[20/23] Train loss=0.23596204817295074
Test set avg_accuracy=82.99% avg_sensitivity=59.33%, avg_specificity=90.12% avg_auc=0.8632
Best model saved!! Metric=-7.240748898250816!!
Fold[8] Epoch: 69 [69/100 (69%)] Train loss=0.286552 Test loss=0.416923 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2994256615638733
[5/23] Train loss=0.2776205539703369
[10/23] Train loss=0.3014598488807678
[15/23] Train loss=0.24387164413928986
[20/23] Train loss=0.23360955715179443
Test set avg_accuracy=82.83% avg_sensitivity=57.59%, avg_specificity=90.43% avg_auc=0.8545
Fold[8] Epoch: 70 [70/100 (70%)] Train loss=0.286986 Test loss=0.429761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2758227288722992
[5/23] Train loss=0.26375773549079895
[10/23] Train loss=0.30468249320983887
[15/23] Train loss=0.23479673266410828
[20/23] Train loss=0.22558078169822693
Test set avg_accuracy=83.25% avg_sensitivity=59.23%, avg_specificity=90.48% avg_auc=0.8639
Best model saved!! Metric=-6.660895560147736!!
Fold[8] Epoch: 71 [71/100 (71%)] Train loss=0.279167 Test loss=0.415373 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28739428520202637
[5/23] Train loss=0.2612566649913788
[10/23] Train loss=0.29275503754615784
[15/23] Train loss=0.22838746011257172
[20/23] Train loss=0.23854205012321472
Test set avg_accuracy=82.74% avg_sensitivity=57.64%, avg_specificity=90.30% avg_auc=0.8543
Fold[8] Epoch: 72 [72/100 (72%)] Train loss=0.279986 Test loss=0.430534 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2812432050704956
[5/23] Train loss=0.25689950585365295
[10/23] Train loss=0.2945590913295746
[15/23] Train loss=0.24016115069389343
[20/23] Train loss=0.2233271449804306
Test set avg_accuracy=83.17% avg_sensitivity=58.13%, avg_specificity=90.70% avg_auc=0.8609
Fold[8] Epoch: 73 [73/100 (73%)] Train loss=0.276441 Test loss=0.422744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28649255633354187
[5/23] Train loss=0.2637563645839691
[10/23] Train loss=0.28854915499687195
[15/23] Train loss=0.2323371022939682
[20/23] Train loss=0.2178238034248352
Test set avg_accuracy=83.04% avg_sensitivity=54.91%, avg_specificity=91.51% avg_auc=0.8573
Fold[8] Epoch: 74 [74/100 (74%)] Train loss=0.273864 Test loss=0.417676 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2735827565193176
[5/23] Train loss=0.26197630167007446
[10/23] Train loss=0.2957027852535248
[15/23] Train loss=0.22109434008598328
[20/23] Train loss=0.22155408561229706
Test set avg_accuracy=82.40% avg_sensitivity=57.69%, avg_specificity=89.83% avg_auc=0.8486
Fold[8] Epoch: 75 [75/100 (75%)] Train loss=0.271170 Test loss=0.436973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2661186754703522
[5/23] Train loss=0.2598656415939331
[10/23] Train loss=0.2922741770744324
[15/23] Train loss=0.22729602456092834
[20/23] Train loss=0.22548547387123108
Test set avg_accuracy=82.85% avg_sensitivity=53.42%, avg_specificity=91.70% avg_auc=0.8564
Fold[8] Epoch: 76 [76/100 (76%)] Train loss=0.274035 Test loss=0.425312 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2635100483894348
[5/23] Train loss=0.25843173265457153
[10/23] Train loss=0.2950158715248108
[15/23] Train loss=0.23951439559459686
[20/23] Train loss=0.218237042427063
Test set avg_accuracy=82.41% avg_sensitivity=50.45%, avg_specificity=92.03% avg_auc=0.8515
Fold[8] Epoch: 77 [77/100 (77%)] Train loss=0.273244 Test loss=0.446939 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26447513699531555
[5/23] Train loss=0.26418137550354004
[10/23] Train loss=0.2843078374862671
[15/23] Train loss=0.2428649663925171
[20/23] Train loss=0.22216007113456726
Test set avg_accuracy=82.74% avg_sensitivity=52.73%, avg_specificity=91.77% avg_auc=0.8593
Fold[8] Epoch: 78 [78/100 (78%)] Train loss=0.275227 Test loss=0.435043 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26957544684410095
[5/23] Train loss=0.25292372703552246
[10/23] Train loss=0.2762238085269928
[15/23] Train loss=0.2271443009376526
[20/23] Train loss=0.22134637832641602
Test set avg_accuracy=82.73% avg_sensitivity=62.30%, avg_specificity=88.88% avg_auc=0.8474
Fold[8] Epoch: 79 [79/100 (79%)] Train loss=0.270449 Test loss=0.438225 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28310737013816833
[5/23] Train loss=0.2745884954929352
[10/23] Train loss=0.2657007873058319
[15/23] Train loss=0.23201733827590942
[20/23] Train loss=0.21678213775157928
Test set avg_accuracy=82.71% avg_sensitivity=59.62%, avg_specificity=89.66% avg_auc=0.8588
Fold[8] Epoch: 80 [80/100 (80%)] Train loss=0.273551 Test loss=0.454301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25870227813720703
[5/23] Train loss=0.2593767046928406
[10/23] Train loss=0.2746883034706116
[15/23] Train loss=0.21334072947502136
[20/23] Train loss=0.2100875973701477
Test set avg_accuracy=82.66% avg_sensitivity=54.71%, avg_specificity=91.07% avg_auc=0.8537
Fold[8] Epoch: 81 [81/100 (81%)] Train loss=0.268256 Test loss=0.429825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2615920305252075
[5/23] Train loss=0.2398562729358673
[10/23] Train loss=0.2851921319961548
[15/23] Train loss=0.21601206064224243
[20/23] Train loss=0.22086334228515625
Test set avg_accuracy=82.81% avg_sensitivity=55.46%, avg_specificity=91.04% avg_auc=0.8597
Fold[8] Epoch: 82 [82/100 (82%)] Train loss=0.266679 Test loss=0.427637 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2592845559120178
[5/23] Train loss=0.251218318939209
[10/23] Train loss=0.2818165719509125
[15/23] Train loss=0.2271001935005188
[20/23] Train loss=0.2198551595211029
Test set avg_accuracy=82.49% avg_sensitivity=51.88%, avg_specificity=91.70% avg_auc=0.8492
Fold[8] Epoch: 83 [83/100 (83%)] Train loss=0.270509 Test loss=0.440316 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2665916085243225
[5/23] Train loss=0.2706754803657532
[10/23] Train loss=0.27040693163871765
[15/23] Train loss=0.22600221633911133
[20/23] Train loss=0.22086332738399506
Test set avg_accuracy=82.69% avg_sensitivity=54.37%, avg_specificity=91.21% avg_auc=0.8471
Fold[8] Epoch: 84 [84/100 (84%)] Train loss=0.268835 Test loss=0.457925 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25795498490333557
[5/23] Train loss=0.24021735787391663
[10/23] Train loss=0.2646140456199646
[15/23] Train loss=0.21406260132789612
[20/23] Train loss=0.20841005444526672
Test set avg_accuracy=83.06% avg_sensitivity=61.26%, avg_specificity=89.63% avg_auc=0.8556
Best model saved!! Metric=-6.492622185155875!!
Fold[8] Epoch: 85 [85/100 (85%)] Train loss=0.258797 Test loss=0.436455 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27564704418182373
[5/23] Train loss=0.24433395266532898
[10/23] Train loss=0.2749708890914917
[15/23] Train loss=0.21688465774059296
[20/23] Train loss=0.20688770711421967
Test set avg_accuracy=82.51% avg_sensitivity=53.08%, avg_specificity=91.37% avg_auc=0.8538
Fold[8] Epoch: 86 [86/100 (86%)] Train loss=0.261753 Test loss=0.441712 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2608213722705841
[5/23] Train loss=0.2523948848247528
[10/23] Train loss=0.2737765312194824
[15/23] Train loss=0.2214304655790329
[20/23] Train loss=0.21018050611019135
Test set avg_accuracy=82.73% avg_sensitivity=57.39%, avg_specificity=90.36% avg_auc=0.8516
Fold[8] Epoch: 87 [87/100 (87%)] Train loss=0.263676 Test loss=0.442922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2643404006958008
[5/23] Train loss=0.2613564729690552
[10/23] Train loss=0.2561895251274109
[15/23] Train loss=0.20658603310585022
[20/23] Train loss=0.21413002908229828
Test set avg_accuracy=83.24% avg_sensitivity=57.24%, avg_specificity=91.06% avg_auc=0.8541
Fold[8] Epoch: 88 [88/100 (88%)] Train loss=0.259093 Test loss=0.446073 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24365855753421783
[5/23] Train loss=0.23875375092029572
[10/23] Train loss=0.25884130597114563
[15/23] Train loss=0.2036997377872467
[20/23] Train loss=0.20591595768928528
Test set avg_accuracy=83.03% avg_sensitivity=57.29%, avg_specificity=90.77% avg_auc=0.8544
Fold[8] Epoch: 89 [89/100 (89%)] Train loss=0.250907 Test loss=0.448434 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2570086419582367
[5/23] Train loss=0.24181059002876282
[10/23] Train loss=0.23932437598705292
[15/23] Train loss=0.20555295050144196
[20/23] Train loss=0.20554998517036438
Test set avg_accuracy=82.64% avg_sensitivity=58.13%, avg_specificity=90.01% avg_auc=0.8440
Fold[8] Epoch: 90 [90/100 (90%)] Train loss=0.251479 Test loss=0.455098 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.253018319606781
[5/23] Train loss=0.23602235317230225
[10/23] Train loss=0.2554646134376526
[15/23] Train loss=0.2026326060295105
[20/23] Train loss=0.2004685252904892
Test set avg_accuracy=82.96% avg_sensitivity=55.31%, avg_specificity=91.28% avg_auc=0.8599
Fold[8] Epoch: 91 [91/100 (91%)] Train loss=0.247179 Test loss=0.438398 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24201634526252747
[5/23] Train loss=0.23308049142360687
[10/23] Train loss=0.25397154688835144
[15/23] Train loss=0.19891715049743652
[20/23] Train loss=0.19628748297691345
Test set avg_accuracy=82.70% avg_sensitivity=54.76%, avg_specificity=91.10% avg_auc=0.8507
Fold[8] Epoch: 92 [92/100 (92%)] Train loss=0.243637 Test loss=0.454657 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2367171347141266
[5/23] Train loss=0.23679523169994354
[10/23] Train loss=0.24131041765213013
[15/23] Train loss=0.18965013325214386
[20/23] Train loss=0.18616321682929993
Test set avg_accuracy=82.71% avg_sensitivity=56.75%, avg_specificity=90.52% avg_auc=0.8552
Fold[8] Epoch: 93 [93/100 (93%)] Train loss=0.236061 Test loss=0.452964 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23866122961044312
[5/23] Train loss=0.23139704763889313
[10/23] Train loss=0.24003857374191284
[15/23] Train loss=0.19809488952159882
[20/23] Train loss=0.19395720958709717
Test set avg_accuracy=82.65% avg_sensitivity=53.87%, avg_specificity=91.31% avg_auc=0.8522
Fold[8] Epoch: 94 [94/100 (94%)] Train loss=0.237733 Test loss=0.460003 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.236347496509552
[5/23] Train loss=0.23344328999519348
[10/23] Train loss=0.2387794405221939
[15/23] Train loss=0.1887090504169464
[20/23] Train loss=0.17936064302921295
Test set avg_accuracy=82.93% avg_sensitivity=56.25%, avg_specificity=90.95% avg_auc=0.8498
Fold[8] Epoch: 95 [95/100 (95%)] Train loss=0.233138 Test loss=0.458270 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24387617409229279
[5/23] Train loss=0.2233489751815796
[10/23] Train loss=0.2339129000902176
[15/23] Train loss=0.1877685785293579
[20/23] Train loss=0.18991748988628387
Test set avg_accuracy=82.86% avg_sensitivity=54.91%, avg_specificity=91.27% avg_auc=0.8561
Fold[8] Epoch: 96 [96/100 (96%)] Train loss=0.234727 Test loss=0.474593 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23059429228305817
[5/23] Train loss=0.22246220707893372
[10/23] Train loss=0.23316766321659088
[15/23] Train loss=0.1806536763906479
[20/23] Train loss=0.18940313160419464
Test set avg_accuracy=83.49% avg_sensitivity=61.46%, avg_specificity=90.12% avg_auc=0.8584
Best model saved!! Metric=-5.0959660334697325!!
Fold[8] Epoch: 97 [97/100 (97%)] Train loss=0.232766 Test loss=0.441158 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23964320123195648
[5/23] Train loss=0.23782853782176971
[10/23] Train loss=0.23313240706920624
[15/23] Train loss=0.18533052504062653
[20/23] Train loss=0.18393783271312714
Test set avg_accuracy=82.17% avg_sensitivity=53.72%, avg_specificity=90.73% avg_auc=0.8387
Fold[8] Epoch: 98 [98/100 (98%)] Train loss=0.233925 Test loss=0.484326 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2185293585062027
[5/23] Train loss=0.21528591215610504
[10/23] Train loss=0.22830693423748016
[15/23] Train loss=0.18411041796207428
[20/23] Train loss=0.1825319081544876
Test set avg_accuracy=83.16% avg_sensitivity=56.80%, avg_specificity=91.09% avg_auc=0.8493
Fold[8] Epoch: 99 [99/100 (99%)] Train loss=0.228062 Test loss=0.461068 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23942020535469055
[5/23] Train loss=0.2128678262233734
[10/23] Train loss=0.2225814014673233
[15/23] Train loss=0.1782325804233551
[20/23] Train loss=0.1757088154554367
Test set avg_accuracy=82.86% avg_sensitivity=58.98%, avg_specificity=90.04% avg_auc=0.8534
Fold[8] Epoch: 100 [100/100 (100%)] Train loss=0.224392 Test loss=0.462843 Current lr=[3.9999999999999996e-05]

Fold[8] Best Result: acc=83.48823866896156 sen=61.458333333333336, spe=90.11792804896254, auc=0.8583953391527284!
[0/23] Train loss=0.703381359577179
[5/23] Train loss=0.6879031658172607
[10/23] Train loss=0.5608298778533936
[15/23] Train loss=0.5659822225570679
[20/23] Train loss=0.559230625629425
Test set avg_accuracy=74.78% avg_sensitivity=1.67%, avg_specificity=99.65% avg_auc=0.6140
Best model saved!! Metric=-88.49454111639812!!
Fold[9] Epoch: 1 [1/100 (1%)] Train loss=0.583297 Test loss=0.606368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5738532543182373
[5/23] Train loss=0.5909433364868164
[10/23] Train loss=0.5067875981330872
[15/23] Train loss=0.5308765172958374
[20/23] Train loss=0.5131220817565918
Test set avg_accuracy=75.62% avg_sensitivity=10.00%, avg_specificity=97.94% avg_auc=0.6825
Best model saved!! Metric=-74.18691064450813!!
Fold[9] Epoch: 2 [2/100 (2%)] Train loss=0.540285 Test loss=0.558237 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5433103442192078
[5/23] Train loss=0.5383554100990295
[10/23] Train loss=0.4758116900920868
[15/23] Train loss=0.47559186816215515
[20/23] Train loss=0.4750869870185852
Test set avg_accuracy=76.73% avg_sensitivity=22.69%, avg_specificity=95.11% avg_auc=0.7442
Best model saved!! Metric=-57.046448129217026!!
Fold[9] Epoch: 3 [3/100 (3%)] Train loss=0.506098 Test loss=0.524257 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5044745206832886
[5/23] Train loss=0.4845491051673889
[10/23] Train loss=0.4723239541053772
[15/23] Train loss=0.4377795159816742
[20/23] Train loss=0.4470411241054535
Test set avg_accuracy=78.17% avg_sensitivity=32.87%, avg_specificity=93.58% avg_auc=0.7754
Best model saved!! Metric=-43.83601702625086!!
Fold[9] Epoch: 4 [4/100 (4%)] Train loss=0.472829 Test loss=0.527745 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.46906933188438416
[5/23] Train loss=0.4613901674747467
[10/23] Train loss=0.47565457224845886
[15/23] Train loss=0.4261675775051117
[20/23] Train loss=0.4433407187461853
Test set avg_accuracy=78.29% avg_sensitivity=34.64%, avg_specificity=93.14% avg_auc=0.7859
Best model saved!! Metric=-41.3503591795437!!
Fold[9] Epoch: 5 [5/100 (5%)] Train loss=0.457765 Test loss=0.527242 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44438832998275757
[5/23] Train loss=0.44971662759780884
[10/23] Train loss=0.4789169132709503
[15/23] Train loss=0.4133722484111786
[20/23] Train loss=0.4416995942592621
Test set avg_accuracy=78.63% avg_sensitivity=36.68%, avg_specificity=92.90% avg_auc=0.7963
Best model saved!! Metric=-38.15858674455791!!
Fold[9] Epoch: 6 [6/100 (6%)] Train loss=0.446891 Test loss=0.506343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4364461600780487
[5/23] Train loss=0.442952424287796
[10/23] Train loss=0.48852330446243286
[15/23] Train loss=0.4175823926925659
[20/23] Train loss=0.4307291507720947
Test set avg_accuracy=78.63% avg_sensitivity=36.54%, avg_specificity=92.95% avg_auc=0.8024
Best model saved!! Metric=-37.64355776990511!!
Fold[9] Epoch: 7 [7/100 (7%)] Train loss=0.441965 Test loss=0.517393 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4398832619190216
[5/23] Train loss=0.4281908869743347
[10/23] Train loss=0.48068374395370483
[15/23] Train loss=0.42880451679229736
[20/23] Train loss=0.4186783730983734
Test set avg_accuracy=78.95% avg_sensitivity=38.68%, avg_specificity=92.65% avg_auc=0.8121
Best model saved!! Metric=-34.51615847673437!!
Fold[9] Epoch: 8 [8/100 (8%)] Train loss=0.434215 Test loss=0.495851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42359423637390137
[5/23] Train loss=0.43197202682495117
[10/23] Train loss=0.465166300535202
[15/23] Train loss=0.4153214991092682
[20/23] Train loss=0.41474243998527527
Test set avg_accuracy=79.24% avg_sensitivity=42.54%, avg_specificity=91.73% avg_auc=0.8173
Best model saved!! Metric=-30.754492091852526!!
Fold[9] Epoch: 9 [9/100 (9%)] Train loss=0.426429 Test loss=0.469176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41598257422447205
[5/23] Train loss=0.42206066846847534
[10/23] Train loss=0.4602494239807129
[15/23] Train loss=0.4020652770996094
[20/23] Train loss=0.40921083092689514
Test set avg_accuracy=79.24% avg_sensitivity=42.72%, avg_specificity=91.67% avg_auc=0.8180
Best model saved!! Metric=-30.565484934273755!!
Fold[9] Epoch: 10 [10/100 (10%)] Train loss=0.418211 Test loss=0.479379 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4115734398365021
[5/23] Train loss=0.41140270233154297
[10/23] Train loss=0.4652377665042877
[15/23] Train loss=0.3957444131374359
[20/23] Train loss=0.40706831216812134
Test set avg_accuracy=78.97% avg_sensitivity=40.96%, avg_specificity=91.90% avg_auc=0.8185
Fold[9] Epoch: 11 [11/100 (11%)] Train loss=0.419048 Test loss=0.492425 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40500226616859436
[5/23] Train loss=0.41433584690093994
[10/23] Train loss=0.4723559319972992
[15/23] Train loss=0.40764716267585754
[20/23] Train loss=0.40460309386253357
Test set avg_accuracy=79.17% avg_sensitivity=41.84%, avg_specificity=91.87% avg_auc=0.8247
Fold[9] Epoch: 12 [12/100 (12%)] Train loss=0.418025 Test loss=0.481368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4047258794307709
[5/23] Train loss=0.4096854329109192
[10/23] Train loss=0.45959073305130005
[15/23] Train loss=0.4019501507282257
[20/23] Train loss=0.3936401307582855
Test set avg_accuracy=79.40% avg_sensitivity=44.49%, avg_specificity=91.27% avg_auc=0.8300
Best model saved!! Metric=-27.837840920943286!!
Fold[9] Epoch: 13 [13/100 (13%)] Train loss=0.409790 Test loss=0.458335 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40125587582588196
[5/23] Train loss=0.40617579221725464
[10/23] Train loss=0.4582563042640686
[15/23] Train loss=0.3836829960346222
[20/23] Train loss=0.39335259795188904
Test set avg_accuracy=79.75% avg_sensitivity=45.79%, avg_specificity=91.30% avg_auc=0.8311
Best model saved!! Metric=-26.04370501778869!!
Fold[9] Epoch: 14 [14/100 (14%)] Train loss=0.404130 Test loss=0.459884 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40597033500671387
[5/23] Train loss=0.39656519889831543
[10/23] Train loss=0.4556865990161896
[15/23] Train loss=0.38089391589164734
[20/23] Train loss=0.3920036852359772
Test set avg_accuracy=79.66% avg_sensitivity=44.40%, avg_specificity=91.65% avg_auc=0.8302
Fold[9] Epoch: 15 [15/100 (15%)] Train loss=0.401739 Test loss=0.473809 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3946581780910492
[5/23] Train loss=0.39461562037467957
[10/23] Train loss=0.4566286504268646
[15/23] Train loss=0.3800618648529053
[20/23] Train loss=0.38872525095939636
Test set avg_accuracy=79.65% avg_sensitivity=45.10%, avg_specificity=91.40% avg_auc=0.8365
Fold[9] Epoch: 16 [16/100 (16%)] Train loss=0.399084 Test loss=0.463811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3911038935184479
[5/23] Train loss=0.3953298032283783
[10/23] Train loss=0.45688962936401367
[15/23] Train loss=0.3748183846473694
[20/23] Train loss=0.38163870573043823
Test set avg_accuracy=79.80% avg_sensitivity=46.30%, avg_specificity=91.19% avg_auc=0.8376
Best model saved!! Metric=-24.942454587255924!!
Fold[9] Epoch: 17 [17/100 (17%)] Train loss=0.395878 Test loss=0.451861 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3890516459941864
[5/23] Train loss=0.3934093713760376
[10/23] Train loss=0.44906166195869446
[15/23] Train loss=0.3758922219276428
[20/23] Train loss=0.378955602645874
Test set avg_accuracy=79.96% avg_sensitivity=48.54%, avg_specificity=90.65% avg_auc=0.8408
Best model saved!! Metric=-22.760372948759294!!
Fold[9] Epoch: 18 [18/100 (18%)] Train loss=0.391795 Test loss=0.443126 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3896242678165436
[5/23] Train loss=0.3876723051071167
[10/23] Train loss=0.4424944519996643
[15/23] Train loss=0.36727890372276306
[20/23] Train loss=0.373669296503067
Test set avg_accuracy=80.07% avg_sensitivity=48.40%, avg_specificity=90.84% avg_auc=0.8405
Best model saved!! Metric=-22.64009672719949!!
Fold[9] Epoch: 19 [19/100 (19%)] Train loss=0.386562 Test loss=0.447269 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38359951972961426
[5/23] Train loss=0.3870205283164978
[10/23] Train loss=0.4395580291748047
[15/23] Train loss=0.3647197186946869
[20/23] Train loss=0.37099191546440125
Test set avg_accuracy=80.24% avg_sensitivity=49.28%, avg_specificity=90.77% avg_auc=0.8432
Best model saved!! Metric=-21.399871413122497!!
Fold[9] Epoch: 20 [20/100 (20%)] Train loss=0.384834 Test loss=0.439658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38082802295684814
[5/23] Train loss=0.3860327899456024
[10/23] Train loss=0.4388963282108307
[15/23] Train loss=0.3621566891670227
[20/23] Train loss=0.37100496888160706
Test set avg_accuracy=80.29% avg_sensitivity=49.74%, avg_specificity=90.69% avg_auc=0.8431
Best model saved!! Metric=-20.960981775175508!!
Fold[9] Epoch: 21 [21/100 (21%)] Train loss=0.381372 Test loss=0.441903 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37559863924980164
[5/23] Train loss=0.38177523016929626
[10/23] Train loss=0.4374801218509674
[15/23] Train loss=0.3585498332977295
[20/23] Train loss=0.3585326671600342
Test set avg_accuracy=80.22% avg_sensitivity=50.77%, avg_specificity=90.24% avg_auc=0.8449
Best model saved!! Metric=-20.27225035737566!!
Fold[9] Epoch: 22 [22/100 (22%)] Train loss=0.379225 Test loss=0.437179 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37339136004447937
[5/23] Train loss=0.37462398409843445
[10/23] Train loss=0.43292948603630066
[15/23] Train loss=0.35381853580474854
[20/23] Train loss=0.36258214712142944
Test set avg_accuracy=80.54% avg_sensitivity=51.70%, avg_specificity=90.35% avg_auc=0.8436
Best model saved!! Metric=-19.04317821798451!!
Fold[9] Epoch: 23 [23/100 (23%)] Train loss=0.374329 Test loss=0.436088 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37152260541915894
[5/23] Train loss=0.37675100564956665
[10/23] Train loss=0.4350113868713379
[15/23] Train loss=0.3444892466068268
[20/23] Train loss=0.3578891158103943
Test set avg_accuracy=80.35% avg_sensitivity=51.88%, avg_specificity=90.04% avg_auc=0.8448
Fold[9] Epoch: 24 [24/100 (24%)] Train loss=0.373279 Test loss=0.435351 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36814454197883606
[5/23] Train loss=0.3713622987270355
[10/23] Train loss=0.4312252998352051
[15/23] Train loss=0.3511199951171875
[20/23] Train loss=0.35394519567489624
Test set avg_accuracy=80.29% avg_sensitivity=51.60%, avg_specificity=90.05% avg_auc=0.8451
Fold[9] Epoch: 25 [25/100 (25%)] Train loss=0.369953 Test loss=0.436066 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3635319769382477
[5/23] Train loss=0.3705858290195465
[10/23] Train loss=0.42687246203422546
[15/23] Train loss=0.3486770689487457
[20/23] Train loss=0.3526928722858429
Test set avg_accuracy=80.39% avg_sensitivity=51.84%, avg_specificity=90.10% avg_auc=0.8425
Fold[9] Epoch: 26 [26/100 (26%)] Train loss=0.367648 Test loss=0.439301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3592219352722168
[5/23] Train loss=0.3672279417514801
[10/23] Train loss=0.4214818477630615
[15/23] Train loss=0.3428919017314911
[20/23] Train loss=0.3466189205646515
Test set avg_accuracy=80.66% avg_sensitivity=54.02%, avg_specificity=89.72% avg_auc=0.8429
Best model saved!! Metric=-17.308994833679748!!
Fold[9] Epoch: 27 [27/100 (27%)] Train loss=0.364721 Test loss=0.435458 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36036449670791626
[5/23] Train loss=0.3650336265563965
[10/23] Train loss=0.4267481565475464
[15/23] Train loss=0.35115545988082886
[20/23] Train loss=0.349619060754776
Test set avg_accuracy=80.51% avg_sensitivity=51.93%, avg_specificity=90.23% avg_auc=0.8394
Fold[9] Epoch: 28 [28/100 (28%)] Train loss=0.364662 Test loss=0.447956 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.358646959066391
[5/23] Train loss=0.36677828431129456
[10/23] Train loss=0.41679269075393677
[15/23] Train loss=0.342557430267334
[20/23] Train loss=0.35150960087776184
Test set avg_accuracy=80.68% avg_sensitivity=56.16%, avg_specificity=89.03% avg_auc=0.8461
Best model saved!! Metric=-15.519121350908524!!
Fold[9] Epoch: 29 [29/100 (29%)] Train loss=0.360983 Test loss=0.429100 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36348292231559753
[5/23] Train loss=0.3564203679561615
[10/23] Train loss=0.416881799697876
[15/23] Train loss=0.3329060971736908
[20/23] Train loss=0.3413652181625366
Test set avg_accuracy=80.50% avg_sensitivity=53.14%, avg_specificity=89.80% avg_auc=0.8435
Fold[9] Epoch: 30 [30/100 (30%)] Train loss=0.359396 Test loss=0.438168 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3574667274951935
[5/23] Train loss=0.3620925545692444
[10/23] Train loss=0.408298522233963
[15/23] Train loss=0.3335813581943512
[20/23] Train loss=0.34423211216926575
Test set avg_accuracy=80.48% avg_sensitivity=55.14%, avg_specificity=89.10% avg_auc=0.8450
Fold[9] Epoch: 31 [31/100 (31%)] Train loss=0.359009 Test loss=0.444310 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35868287086486816
[5/23] Train loss=0.3519672453403473
[10/23] Train loss=0.40481802821159363
[15/23] Train loss=0.33177950978279114
[20/23] Train loss=0.34709569811820984
Test set avg_accuracy=80.14% avg_sensitivity=54.86%, avg_specificity=88.74% avg_auc=0.8422
Fold[9] Epoch: 32 [32/100 (32%)] Train loss=0.355375 Test loss=0.452613 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3524967432022095
[5/23] Train loss=0.3531731069087982
[10/23] Train loss=0.41222620010375977
[15/23] Train loss=0.32778534293174744
[20/23] Train loss=0.3325079083442688
Test set avg_accuracy=80.29% avg_sensitivity=54.35%, avg_specificity=89.12% avg_auc=0.8420
Fold[9] Epoch: 33 [33/100 (33%)] Train loss=0.350845 Test loss=0.453663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3491998314857483
[5/23] Train loss=0.35311925411224365
[10/23] Train loss=0.4089336097240448
[15/23] Train loss=0.33673688769340515
[20/23] Train loss=0.3317609429359436
Test set avg_accuracy=80.29% avg_sensitivity=52.58%, avg_specificity=89.72% avg_auc=0.8409
Fold[9] Epoch: 34 [34/100 (34%)] Train loss=0.351478 Test loss=0.461289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34225189685821533
[5/23] Train loss=0.34930524230003357
[10/23] Train loss=0.3956674337387085
[15/23] Train loss=0.3235718607902527
[20/23] Train loss=0.3329390585422516
Test set avg_accuracy=80.13% avg_sensitivity=56.81%, avg_specificity=88.06% avg_auc=0.8436
Fold[9] Epoch: 35 [35/100 (35%)] Train loss=0.346732 Test loss=0.441249 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3420126736164093
[5/23] Train loss=0.3420312702655792
[10/23] Train loss=0.39727312326431274
[15/23] Train loss=0.3280986249446869
[20/23] Train loss=0.33415472507476807
Test set avg_accuracy=80.32% avg_sensitivity=54.81%, avg_specificity=88.99% avg_auc=0.8407
Fold[9] Epoch: 36 [36/100 (36%)] Train loss=0.343884 Test loss=0.450892 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3403330147266388
[5/23] Train loss=0.3441338837146759
[10/23] Train loss=0.4022216200828552
[15/23] Train loss=0.3199293613433838
[20/23] Train loss=0.32461267709732056
Test set avg_accuracy=80.73% avg_sensitivity=55.09%, avg_specificity=89.45% avg_auc=0.8443
Fold[9] Epoch: 37 [37/100 (37%)] Train loss=0.341681 Test loss=0.449964 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3361256420612335
[5/23] Train loss=0.34591659903526306
[10/23] Train loss=0.3947535455226898
[15/23] Train loss=0.314818799495697
[20/23] Train loss=0.32439470291137695
Test set avg_accuracy=80.55% avg_sensitivity=57.09%, avg_specificity=88.54% avg_auc=0.8439
Best model saved!! Metric=-15.430167774209657!!
Fold[9] Epoch: 38 [38/100 (38%)] Train loss=0.338540 Test loss=0.448323 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3436034619808197
[5/23] Train loss=0.3349533677101135
[10/23] Train loss=0.3841342031955719
[15/23] Train loss=0.31165629625320435
[20/23] Train loss=0.3291361331939697
Test set avg_accuracy=80.61% avg_sensitivity=56.76%, avg_specificity=88.73% avg_auc=0.8456
Best model saved!! Metric=-15.338409385397021!!
Fold[9] Epoch: 39 [39/100 (39%)] Train loss=0.336182 Test loss=0.444991 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33328020572662354
[5/23] Train loss=0.33691415190696716
[10/23] Train loss=0.3880065381526947
[15/23] Train loss=0.3208780586719513
[20/23] Train loss=0.3214654326438904
Test set avg_accuracy=80.53% avg_sensitivity=52.12%, avg_specificity=90.20% avg_auc=0.8420
Fold[9] Epoch: 40 [40/100 (40%)] Train loss=0.336388 Test loss=0.459872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3362627923488617
[5/23] Train loss=0.33613210916519165
[10/23] Train loss=0.38081443309783936
[15/23] Train loss=0.30723562836647034
[20/23] Train loss=0.3123694360256195
Test set avg_accuracy=80.21% avg_sensitivity=58.58%, avg_specificity=87.57% avg_auc=0.8445
Best model saved!! Metric=-15.18878495522213!!
Fold[9] Epoch: 41 [41/100 (41%)] Train loss=0.332746 Test loss=0.450160 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33504942059516907
[5/23] Train loss=0.33140042424201965
[10/23] Train loss=0.3772040605545044
[15/23] Train loss=0.31151333451271057
[20/23] Train loss=0.31502506136894226
Test set avg_accuracy=80.37% avg_sensitivity=55.74%, avg_specificity=88.74% avg_auc=0.8423
Fold[9] Epoch: 42 [42/100 (42%)] Train loss=0.330867 Test loss=0.458321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.325418621301651
[5/23] Train loss=0.32662561535835266
[10/23] Train loss=0.37279751896858215
[15/23] Train loss=0.2976429760456085
[20/23] Train loss=0.3095124363899231
Test set avg_accuracy=80.38% avg_sensitivity=56.90%, avg_specificity=88.36% avg_auc=0.8437
Fold[9] Epoch: 43 [43/100 (43%)] Train loss=0.328708 Test loss=0.455282 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3228977918624878
[5/23] Train loss=0.3195980489253998
[10/23] Train loss=0.37154993414878845
[15/23] Train loss=0.2945001423358917
[20/23] Train loss=0.30496639013290405
Test set avg_accuracy=80.29% avg_sensitivity=56.67%, avg_specificity=88.33% avg_auc=0.8415
Fold[9] Epoch: 44 [44/100 (44%)] Train loss=0.323184 Test loss=0.459761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3255033791065216
[5/23] Train loss=0.324340283870697
[10/23] Train loss=0.36995622515678406
[15/23] Train loss=0.2960602641105652
[20/23] Train loss=0.30706730484962463
Test set avg_accuracy=80.18% avg_sensitivity=54.49%, avg_specificity=88.92% avg_auc=0.8418
Fold[9] Epoch: 45 [45/100 (45%)] Train loss=0.323157 Test loss=0.463342 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.324939489364624
[5/23] Train loss=0.32326653599739075
[10/23] Train loss=0.3579865097999573
[15/23] Train loss=0.29892250895500183
[20/23] Train loss=0.30368590354919434
Test set avg_accuracy=80.55% avg_sensitivity=56.07%, avg_specificity=88.88% avg_auc=0.8428
Fold[9] Epoch: 46 [46/100 (46%)] Train loss=0.319936 Test loss=0.459853 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3106228709220886
[5/23] Train loss=0.31998756527900696
[10/23] Train loss=0.36080580949783325
[15/23] Train loss=0.28812047839164734
[20/23] Train loss=0.2984054982662201
Test set avg_accuracy=80.39% avg_sensitivity=54.11%, avg_specificity=89.33% avg_auc=0.8399
Fold[9] Epoch: 47 [47/100 (47%)] Train loss=0.318007 Test loss=0.459014 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31457674503326416
[5/23] Train loss=0.3136870563030243
[10/23] Train loss=0.35738757252693176
[15/23] Train loss=0.2882114350795746
[20/23] Train loss=0.2876734137535095
Test set avg_accuracy=80.40% avg_sensitivity=57.09%, avg_specificity=88.33% avg_auc=0.8422
Fold[9] Epoch: 48 [48/100 (48%)] Train loss=0.313337 Test loss=0.457346 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31378206610679626
[5/23] Train loss=0.30756068229675293
[10/23] Train loss=0.35042253136634827
[15/23] Train loss=0.28016701340675354
[20/23] Train loss=0.2910027503967285
Test set avg_accuracy=80.40% avg_sensitivity=57.51%, avg_specificity=88.19% avg_auc=0.8427
Fold[9] Epoch: 49 [49/100 (49%)] Train loss=0.309256 Test loss=0.458528 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3169928789138794
[5/23] Train loss=0.3086271286010742
[10/23] Train loss=0.341645747423172
[15/23] Train loss=0.2823614180088043
[20/23] Train loss=0.2926633358001709
Test set avg_accuracy=80.47% avg_sensitivity=56.81%, avg_specificity=88.52% avg_auc=0.8413
Fold[9] Epoch: 50 [50/100 (50%)] Train loss=0.308217 Test loss=0.460872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30779391527175903
[5/23] Train loss=0.30932581424713135
[10/23] Train loss=0.3367915153503418
[15/23] Train loss=0.27387484908103943
[20/23] Train loss=0.2874176502227783
Test set avg_accuracy=80.37% avg_sensitivity=57.60%, avg_specificity=88.11% avg_auc=0.8413
Fold[9] Epoch: 51 [51/100 (51%)] Train loss=0.304694 Test loss=0.462175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3108442425727844
[5/23] Train loss=0.2981075048446655
[10/23] Train loss=0.34080493450164795
[15/23] Train loss=0.28141582012176514
[20/23] Train loss=0.2947233319282532
Test set avg_accuracy=80.60% avg_sensitivity=55.23%, avg_specificity=89.23% avg_auc=0.8412
Fold[9] Epoch: 52 [52/100 (52%)] Train loss=0.306629 Test loss=0.458681 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30801647901535034
[5/23] Train loss=0.30242231488227844
[10/23] Train loss=0.3402160108089447
[15/23] Train loss=0.2706819474697113
[20/23] Train loss=0.2896957993507385
Test set avg_accuracy=80.28% avg_sensitivity=53.93%, avg_specificity=89.25% avg_auc=0.8403
Fold[9] Epoch: 53 [53/100 (53%)] Train loss=0.302376 Test loss=0.465112 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2998907268047333
[5/23] Train loss=0.3080889582633972
[10/23] Train loss=0.3394111692905426
[15/23] Train loss=0.2693614959716797
[20/23] Train loss=0.28176695108413696
Test set avg_accuracy=80.60% avg_sensitivity=52.67%, avg_specificity=90.10% avg_auc=0.8415
Fold[9] Epoch: 54 [54/100 (54%)] Train loss=0.304579 Test loss=0.466658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30420050024986267
[5/23] Train loss=0.30875441431999207
[10/23] Train loss=0.33236196637153625
[15/23] Train loss=0.2784861922264099
[20/23] Train loss=0.2861095070838928
Test set avg_accuracy=80.04% avg_sensitivity=52.21%, avg_specificity=89.50% avg_auc=0.8369
Fold[9] Epoch: 55 [55/100 (55%)] Train loss=0.308281 Test loss=0.484830 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29176077246665955
[5/23] Train loss=0.305220365524292
[10/23] Train loss=0.32760342955589294
[15/23] Train loss=0.2708846628665924
[20/23] Train loss=0.2764449119567871
Test set avg_accuracy=80.31% avg_sensitivity=59.32%, avg_specificity=87.44% avg_auc=0.8408
Best model saved!! Metric=-14.846200388623895!!
Fold[9] Epoch: 56 [56/100 (56%)] Train loss=0.298468 Test loss=0.476501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2919653058052063
[5/23] Train loss=0.3044792115688324
[10/23] Train loss=0.32447898387908936
[15/23] Train loss=0.25861188769340515
[20/23] Train loss=0.2803729176521301
Test set avg_accuracy=80.41% avg_sensitivity=57.74%, avg_specificity=88.12% avg_auc=0.8404
Fold[9] Epoch: 57 [57/100 (57%)] Train loss=0.294170 Test loss=0.476227 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.292367547750473
[5/23] Train loss=0.29558226466178894
[10/23] Train loss=0.32276052236557007
[15/23] Train loss=0.2583983242511749
[20/23] Train loss=0.2698231339454651
Test set avg_accuracy=80.17% avg_sensitivity=59.23%, avg_specificity=87.29% avg_auc=0.8407
Fold[9] Epoch: 58 [58/100 (58%)] Train loss=0.290152 Test loss=0.472470 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2929631471633911
[5/23] Train loss=0.2919144630432129
[10/23] Train loss=0.31352362036705017
[15/23] Train loss=0.24872907996177673
[20/23] Train loss=0.27126938104629517
Test set avg_accuracy=80.20% avg_sensitivity=58.34%, avg_specificity=87.63% avg_auc=0.8399
Fold[9] Epoch: 59 [59/100 (59%)] Train loss=0.286006 Test loss=0.469998 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29001811146736145
[5/23] Train loss=0.28043773770332336
[10/23] Train loss=0.3298005163669586
[15/23] Train loss=0.24955740571022034
[20/23] Train loss=0.26756253838539124
Test set avg_accuracy=80.35% avg_sensitivity=54.53%, avg_specificity=89.14% avg_auc=0.8399
Fold[9] Epoch: 60 [60/100 (60%)] Train loss=0.286096 Test loss=0.477491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.289697527885437
[5/23] Train loss=0.2811262905597687
[10/23] Train loss=0.3120931088924408
[15/23] Train loss=0.24743176996707916
[20/23] Train loss=0.2717922627925873
Test set avg_accuracy=80.39% avg_sensitivity=54.67%, avg_specificity=89.14% avg_auc=0.8394
Fold[9] Epoch: 61 [61/100 (61%)] Train loss=0.284547 Test loss=0.486865 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28199508786201477
[5/23] Train loss=0.28479456901550293
[10/23] Train loss=0.3008851706981659
[15/23] Train loss=0.24570660293102264
[20/23] Train loss=0.2578606903553009
Test set avg_accuracy=80.05% avg_sensitivity=57.97%, avg_specificity=87.56% avg_auc=0.8379
Fold[9] Epoch: 62 [62/100 (62%)] Train loss=0.281217 Test loss=0.480321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2843305468559265
[5/23] Train loss=0.2816070318222046
[10/23] Train loss=0.2975057065486908
[15/23] Train loss=0.24261541664600372
[20/23] Train loss=0.26327210664749146
Test set avg_accuracy=80.17% avg_sensitivity=55.28%, avg_specificity=88.63% avg_auc=0.8380
Fold[9] Epoch: 63 [63/100 (63%)] Train loss=0.278966 Test loss=0.482984 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28106266260147095
[5/23] Train loss=0.2822433114051819
[10/23] Train loss=0.2925885319709778
[15/23] Train loss=0.23788650333881378
[20/23] Train loss=0.25907981395721436
Test set avg_accuracy=80.27% avg_sensitivity=58.07%, avg_specificity=87.82% avg_auc=0.8395
Fold[9] Epoch: 64 [64/100 (64%)] Train loss=0.274173 Test loss=0.480115 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.273669570684433
[5/23] Train loss=0.2739124596118927
[10/23] Train loss=0.2929743528366089
[15/23] Train loss=0.2333248257637024
[20/23] Train loss=0.2537950277328491
Test set avg_accuracy=80.44% avg_sensitivity=57.18%, avg_specificity=88.35% avg_auc=0.8392
Fold[9] Epoch: 65 [65/100 (65%)] Train loss=0.270759 Test loss=0.483274 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2797163128852844
[5/23] Train loss=0.2706387937068939
[10/23] Train loss=0.28720322251319885
[15/23] Train loss=0.22901581227779388
[20/23] Train loss=0.24931032955646515
Test set avg_accuracy=80.09% avg_sensitivity=56.30%, avg_specificity=88.19% avg_auc=0.8387
Fold[9] Epoch: 66 [66/100 (66%)] Train loss=0.268646 Test loss=0.488525 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.272659569978714
[5/23] Train loss=0.2621043920516968
[10/23] Train loss=0.2996857464313507
[15/23] Train loss=0.2400786280632019
[20/23] Train loss=0.25431498885154724
Test set avg_accuracy=80.33% avg_sensitivity=51.00%, avg_specificity=90.31% avg_auc=0.8379
Fold[9] Epoch: 67 [67/100 (67%)] Train loss=0.272116 Test loss=0.502647 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2811111509799957
[5/23] Train loss=0.27876922488212585
[10/23] Train loss=0.2989986538887024
[15/23] Train loss=0.24371978640556335
[20/23] Train loss=0.2519780993461609
Test set avg_accuracy=80.15% avg_sensitivity=51.14%, avg_specificity=90.02% avg_auc=0.8353
Fold[9] Epoch: 68 [68/100 (68%)] Train loss=0.277279 Test loss=0.493567 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2759798765182495
[5/23] Train loss=0.28178852796554565
[10/23] Train loss=0.2855146527290344
[15/23] Train loss=0.24187378585338593
[20/23] Train loss=0.2552250325679779
Test set avg_accuracy=80.05% avg_sensitivity=55.74%, avg_specificity=88.31% avg_auc=0.8375
Fold[9] Epoch: 69 [69/100 (69%)] Train loss=0.272373 Test loss=0.493287 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.268527626991272
[5/23] Train loss=0.2686914801597595
[10/23] Train loss=0.28614890575408936
[15/23] Train loss=0.22464434802532196
[20/23] Train loss=0.24722787737846375
Test set avg_accuracy=79.82% avg_sensitivity=60.53%, avg_specificity=86.39% avg_auc=0.8379
Fold[9] Epoch: 70 [70/100 (70%)] Train loss=0.261765 Test loss=0.495922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27671658992767334
[5/23] Train loss=0.26282164454460144
[10/23] Train loss=0.27443307638168335
[15/23] Train loss=0.21845345199108124
[20/23] Train loss=0.24883069097995758
Test set avg_accuracy=80.14% avg_sensitivity=59.88%, avg_specificity=87.03% avg_auc=0.8375
Fold[9] Epoch: 71 [71/100 (71%)] Train loss=0.259008 Test loss=0.505192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26469913125038147
[5/23] Train loss=0.2665897309780121
[10/23] Train loss=0.27424225211143494
[15/23] Train loss=0.22799883782863617
[20/23] Train loss=0.2349880486726761
Test set avg_accuracy=80.05% avg_sensitivity=55.97%, avg_specificity=88.24% avg_auc=0.8348
Fold[9] Epoch: 72 [72/100 (72%)] Train loss=0.257202 Test loss=0.488079 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2581399381160736
[5/23] Train loss=0.2587110698223114
[10/23] Train loss=0.2802054286003113
[15/23] Train loss=0.2166714072227478
[20/23] Train loss=0.24338498711585999
Test set avg_accuracy=79.94% avg_sensitivity=55.60%, avg_specificity=88.22% avg_auc=0.8342
Fold[9] Epoch: 73 [73/100 (73%)] Train loss=0.254675 Test loss=0.498340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24680685997009277
[5/23] Train loss=0.2537233531475067
[10/23] Train loss=0.2657817602157593
[15/23] Train loss=0.219496488571167
[20/23] Train loss=0.22580033540725708
Test set avg_accuracy=80.14% avg_sensitivity=56.67%, avg_specificity=88.12% avg_auc=0.8399
Fold[9] Epoch: 74 [74/100 (74%)] Train loss=0.253129 Test loss=0.489006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2428782880306244
[5/23] Train loss=0.25360679626464844
[10/23] Train loss=0.26631706953048706
[15/23] Train loss=0.2062603384256363
[20/23] Train loss=0.23761038482189178
Test set avg_accuracy=80.35% avg_sensitivity=55.32%, avg_specificity=88.87% avg_auc=0.8393
Fold[9] Epoch: 75 [75/100 (75%)] Train loss=0.250426 Test loss=0.492619 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25418469309806824
[5/23] Train loss=0.24927636981010437
[10/23] Train loss=0.270164430141449
[15/23] Train loss=0.21397462487220764
[20/23] Train loss=0.2291412055492401
Test set avg_accuracy=80.07% avg_sensitivity=54.44%, avg_specificity=88.79% avg_auc=0.8363
Fold[9] Epoch: 76 [76/100 (76%)] Train loss=0.249231 Test loss=0.510422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2502567172050476
[5/23] Train loss=0.25459256768226624
[10/23] Train loss=0.27505436539649963
[15/23] Train loss=0.22169092297554016
[20/23] Train loss=0.23630325496196747
Test set avg_accuracy=80.38% avg_sensitivity=51.88%, avg_specificity=90.07% avg_auc=0.8364
Fold[9] Epoch: 77 [77/100 (77%)] Train loss=0.253531 Test loss=0.506238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25896331667900085
[5/23] Train loss=0.25947266817092896
[10/23] Train loss=0.25603342056274414
[15/23] Train loss=0.210529625415802
[20/23] Train loss=0.22854556143283844
Test set avg_accuracy=80.19% avg_sensitivity=57.18%, avg_specificity=88.01% avg_auc=0.8348
Fold[9] Epoch: 78 [78/100 (78%)] Train loss=0.250370 Test loss=0.511791 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24187539517879486
[5/23] Train loss=0.2706579864025116
[10/23] Train loss=0.2541174590587616
[15/23] Train loss=0.2045668214559555
[20/23] Train loss=0.2241506576538086
Test set avg_accuracy=80.29% avg_sensitivity=60.53%, avg_specificity=87.02% avg_auc=0.8345
Best model saved!! Metric=-14.70929647575018!!
Fold[9] Epoch: 79 [79/100 (79%)] Train loss=0.243742 Test loss=0.516128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2502687871456146
[5/23] Train loss=0.23758651316165924
[10/23] Train loss=0.248843252658844
[15/23] Train loss=0.19868260622024536
[20/23] Train loss=0.22397923469543457
Test set avg_accuracy=80.47% avg_sensitivity=60.58%, avg_specificity=87.24% avg_auc=0.8364
Best model saved!! Metric=-14.075837289464795!!
Fold[9] Epoch: 80 [80/100 (80%)] Train loss=0.236752 Test loss=0.517726 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2399124950170517
[5/23] Train loss=0.23011049628257751
[10/23] Train loss=0.2378334254026413
[15/23] Train loss=0.20178884267807007
[20/23] Train loss=0.2193455845117569
Test set avg_accuracy=80.13% avg_sensitivity=58.95%, avg_specificity=87.33% avg_auc=0.8342
Fold[9] Epoch: 81 [81/100 (81%)] Train loss=0.233216 Test loss=0.514365 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23778508603572845
[5/23] Train loss=0.24607603251934052
[10/23] Train loss=0.24528707563877106
[15/23] Train loss=0.2016986459493637
[20/23] Train loss=0.21553446352481842
Test set avg_accuracy=80.08% avg_sensitivity=58.34%, avg_specificity=87.48% avg_auc=0.8327
Fold[9] Epoch: 82 [82/100 (82%)] Train loss=0.235745 Test loss=0.517191 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2348584234714508
[5/23] Train loss=0.24640622735023499
[10/23] Train loss=0.23649823665618896
[15/23] Train loss=0.19523517787456512
[20/23] Train loss=0.21492117643356323
Test set avg_accuracy=79.94% avg_sensitivity=58.86%, avg_specificity=87.11% avg_auc=0.8332
Fold[9] Epoch: 83 [83/100 (83%)] Train loss=0.231425 Test loss=0.510705 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2366996854543686
[5/23] Train loss=0.23791395127773285
[10/23] Train loss=0.24074631929397583
[15/23] Train loss=0.18461808562278748
[20/23] Train loss=0.20723474025726318
Test set avg_accuracy=79.81% avg_sensitivity=57.28%, avg_specificity=87.48% avg_auc=0.8324
Fold[9] Epoch: 84 [84/100 (84%)] Train loss=0.228518 Test loss=0.533713 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22785057127475739
[5/23] Train loss=0.22603586316108704
[10/23] Train loss=0.22896885871887207
[15/23] Train loss=0.18574608862400055
[20/23] Train loss=0.20866599678993225
Test set avg_accuracy=80.44% avg_sensitivity=55.65%, avg_specificity=88.87% avg_auc=0.8355
Fold[9] Epoch: 85 [85/100 (85%)] Train loss=0.225942 Test loss=0.519978 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.222967728972435
[5/23] Train loss=0.2579101324081421
[10/23] Train loss=0.23322997987270355
[15/23] Train loss=0.20221254229545593
[20/23] Train loss=0.21320000290870667
Test set avg_accuracy=79.65% avg_sensitivity=54.72%, avg_specificity=88.12% avg_auc=0.8335
Fold[9] Epoch: 86 [86/100 (86%)] Train loss=0.239223 Test loss=0.526044 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24965274333953857
[5/23] Train loss=0.2341187298297882
[10/23] Train loss=0.2561792731285095
[15/23] Train loss=0.19907532632350922
[20/23] Train loss=0.22122161090373993
Test set avg_accuracy=80.18% avg_sensitivity=54.95%, avg_specificity=88.76% avg_auc=0.8347
Fold[9] Epoch: 87 [87/100 (87%)] Train loss=0.237038 Test loss=0.522634 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2353040874004364
[5/23] Train loss=0.25108861923217773
[10/23] Train loss=0.24467918276786804
[15/23] Train loss=0.2176770120859146
[20/23] Train loss=0.22065387666225433
Test set avg_accuracy=79.92% avg_sensitivity=49.19%, avg_specificity=90.37% avg_auc=0.8330
Fold[9] Epoch: 88 [88/100 (88%)] Train loss=0.244792 Test loss=0.537186 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2512476146221161
[5/23] Train loss=0.25399595499038696
[10/23] Train loss=0.2604503035545349
[15/23] Train loss=0.2106541246175766
[20/23] Train loss=0.2199046015739441
Test set avg_accuracy=80.24% avg_sensitivity=54.49%, avg_specificity=88.99% avg_auc=0.8377
Fold[9] Epoch: 89 [89/100 (89%)] Train loss=0.241408 Test loss=0.533786 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23751215636730194
[5/23] Train loss=0.22853471338748932
[10/23] Train loss=0.22953511774539948
[15/23] Train loss=0.18383678793907166
[20/23] Train loss=0.19328974187374115
Test set avg_accuracy=79.83% avg_sensitivity=61.92%, avg_specificity=85.93% avg_auc=0.8273
Fold[9] Epoch: 90 [90/100 (90%)] Train loss=0.224061 Test loss=0.545857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23727893829345703
[5/23] Train loss=0.2299576848745346
[10/23] Train loss=0.2148219496011734
[15/23] Train loss=0.1777685433626175
[20/23] Train loss=0.20052294433116913
Test set avg_accuracy=80.26% avg_sensitivity=60.34%, avg_specificity=87.03% avg_auc=0.8303
Fold[9] Epoch: 91 [91/100 (91%)] Train loss=0.221269 Test loss=0.540992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20899038016796112
[5/23] Train loss=0.21722277998924255
[10/23] Train loss=0.2156161516904831
[15/23] Train loss=0.1738855391740799
[20/23] Train loss=0.189979687333107
Test set avg_accuracy=79.91% avg_sensitivity=58.11%, avg_specificity=87.32% avg_auc=0.8301
Fold[9] Epoch: 92 [92/100 (92%)] Train loss=0.213637 Test loss=0.546870 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21418657898902893
[5/23] Train loss=0.2243485152721405
[10/23] Train loss=0.21504656970500946
[15/23] Train loss=0.16614161431789398
[20/23] Train loss=0.20544622838497162
Test set avg_accuracy=79.71% avg_sensitivity=54.35%, avg_specificity=88.33% avg_auc=0.8317
Fold[9] Epoch: 93 [93/100 (93%)] Train loss=0.213309 Test loss=0.541139 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2128174901008606
[5/23] Train loss=0.22500690817832947
[10/23] Train loss=0.2184910774230957
[15/23] Train loss=0.17508924007415771
[20/23] Train loss=0.19513586163520813
Test set avg_accuracy=79.78% avg_sensitivity=57.60%, avg_specificity=87.32% avg_auc=0.8290
Fold[9] Epoch: 94 [94/100 (94%)] Train loss=0.211990 Test loss=0.549138 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20644570887088776
[5/23] Train loss=0.2214120775461197
[10/23] Train loss=0.21818381547927856
[15/23] Train loss=0.1658085584640503
[20/23] Train loss=0.1963917762041092
Test set avg_accuracy=79.86% avg_sensitivity=56.58%, avg_specificity=87.78% avg_auc=0.8289
Fold[9] Epoch: 95 [95/100 (95%)] Train loss=0.209820 Test loss=0.546293 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1957862824201584
[5/23] Train loss=0.20940104126930237
[10/23] Train loss=0.20165453851222992
[15/23] Train loss=0.16171976923942566
[20/23] Train loss=0.18945522606372833
Test set avg_accuracy=79.56% avg_sensitivity=59.04%, avg_specificity=86.54% avg_auc=0.8295
Fold[9] Epoch: 96 [96/100 (96%)] Train loss=0.201384 Test loss=0.554023 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20226819813251495
[5/23] Train loss=0.21083638072013855
[10/23] Train loss=0.19870056211948395
[15/23] Train loss=0.1545235961675644
[20/23] Train loss=0.18507352471351624
Test set avg_accuracy=79.88% avg_sensitivity=59.09%, avg_specificity=86.95% avg_auc=0.8281
Fold[9] Epoch: 97 [97/100 (97%)] Train loss=0.200486 Test loss=0.557141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1971203088760376
[5/23] Train loss=0.20243746042251587
[10/23] Train loss=0.19347220659255981
[15/23] Train loss=0.15522925555706024
[20/23] Train loss=0.1765553504228592
Test set avg_accuracy=79.88% avg_sensitivity=59.93%, avg_specificity=86.67% avg_auc=0.8273
Fold[9] Epoch: 98 [98/100 (98%)] Train loss=0.198549 Test loss=0.554791 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20319758355617523
[5/23] Train loss=0.20247332751750946
[10/23] Train loss=0.19249922037124634
[15/23] Train loss=0.15407055616378784
[20/23] Train loss=0.18571405112743378
Test set avg_accuracy=79.99% avg_sensitivity=56.16%, avg_specificity=88.09% avg_auc=0.8250
Fold[9] Epoch: 99 [99/100 (99%)] Train loss=0.196562 Test loss=0.553586 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19769400358200073
[5/23] Train loss=0.2019670456647873
[10/23] Train loss=0.19218043982982635
[15/23] Train loss=0.15268997848033905
[20/23] Train loss=0.20087668299674988
Test set avg_accuracy=79.92% avg_sensitivity=53.84%, avg_specificity=88.79% avg_auc=0.8332
Fold[9] Epoch: 100 [100/100 (100%)] Train loss=0.195079 Test loss=0.560596 Current lr=[3.9999999999999996e-05]

Fold[9] Best Result: acc=80.47197640117994 sen=60.57647605764761, spe=87.23908918406073, auc=0.8363662106764692!
[0/23] Train loss=0.7181662321090698
[5/23] Train loss=0.6887120008468628
[10/23] Train loss=0.5548532009124756
[15/23] Train loss=0.5772772431373596
[20/23] Train loss=0.6025898456573486
Test set avg_accuracy=77.55% avg_sensitivity=0.57%, avg_specificity=99.84% avg_auc=0.5481
Best model saved!! Metric=-93.23695583321614!!
Fold[10] Epoch: 1 [1/100 (1%)] Train loss=0.592208 Test loss=0.562262 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5611692667007446
[5/23] Train loss=0.6057711243629456
[10/23] Train loss=0.5257066488265991
[15/23] Train loss=0.5484768748283386
[20/23] Train loss=0.5887563228607178
Test set avg_accuracy=77.42% avg_sensitivity=1.70%, avg_specificity=99.33% avg_auc=0.5698
Best model saved!! Metric=-90.57491179966134!!
Fold[10] Epoch: 2 [2/100 (2%)] Train loss=0.557590 Test loss=0.544414 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.550382137298584
[5/23] Train loss=0.5758025646209717
[10/23] Train loss=0.5028904676437378
[15/23] Train loss=0.524943470954895
[20/23] Train loss=0.576225757598877
Test set avg_accuracy=77.47% avg_sensitivity=5.24%, avg_specificity=98.38% avg_auc=0.6414
Best model saved!! Metric=-80.76253502763322!!
Fold[10] Epoch: 3 [3/100 (3%)] Train loss=0.538781 Test loss=0.549889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5338216423988342
[5/23] Train loss=0.5315827131271362
[10/23] Train loss=0.49002140760421753
[15/23] Train loss=0.4799448251724243
[20/23] Train loss=0.5847298502922058
Test set avg_accuracy=78.44% avg_sensitivity=11.00%, avg_specificity=97.96% avg_auc=0.6794
Best model saved!! Metric=-70.65816470591449!!
Fold[10] Epoch: 4 [4/100 (4%)] Train loss=0.517287 Test loss=0.566201 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5211957097053528
[5/23] Train loss=0.49275389313697815
[10/23] Train loss=0.47956207394599915
[15/23] Train loss=0.4482042193412781
[20/23] Train loss=0.5782638788223267
Test set avg_accuracy=78.90% avg_sensitivity=15.42%, avg_specificity=97.28% avg_auc=0.7201
Best model saved!! Metric=-62.39246290248194!!
Fold[10] Epoch: 5 [5/100 (5%)] Train loss=0.494381 Test loss=0.550768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4906226694583893
[5/23] Train loss=0.4677276313304901
[10/23] Train loss=0.4707140326499939
[15/23] Train loss=0.43449434638023376
[20/23] Train loss=0.575806736946106
Test set avg_accuracy=79.71% avg_sensitivity=21.07%, avg_specificity=96.68% avg_auc=0.7466
Best model saved!! Metric=-53.88035130934769!!
Fold[10] Epoch: 6 [6/100 (6%)] Train loss=0.475668 Test loss=0.531986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.45433861017227173
[5/23] Train loss=0.45594093203544617
[10/23] Train loss=0.4857921898365021
[15/23] Train loss=0.43193233013153076
[20/23] Train loss=0.5537052750587463
Test set avg_accuracy=80.22% avg_sensitivity=23.59%, avg_specificity=96.61% avg_auc=0.7692
Best model saved!! Metric=-48.66541805117505!!
Fold[10] Epoch: 7 [7/100 (7%)] Train loss=0.464477 Test loss=0.526137 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4446951150894165
[5/23] Train loss=0.448018878698349
[10/23] Train loss=0.4772283136844635
[15/23] Train loss=0.43295159935951233
[20/23] Train loss=0.5297440886497498
Test set avg_accuracy=80.53% avg_sensitivity=27.13%, avg_specificity=95.98% avg_auc=0.7785
Best model saved!! Metric=-44.49734898482072!!
Fold[10] Epoch: 8 [8/100 (8%)] Train loss=0.455012 Test loss=0.508861 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43375274538993835
[5/23] Train loss=0.437713086605072
[10/23] Train loss=0.4735400676727295
[15/23] Train loss=0.41731780767440796
[20/23] Train loss=0.5363720059394836
Test set avg_accuracy=80.76% avg_sensitivity=28.73%, avg_specificity=95.82% avg_auc=0.7843
Best model saved!! Metric=-42.26136144564802!!
Fold[10] Epoch: 9 [9/100 (9%)] Train loss=0.448204 Test loss=0.508955 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43213751912117004
[5/23] Train loss=0.42814910411834717
[10/23] Train loss=0.48087507486343384
[15/23] Train loss=0.428453266620636
[20/23] Train loss=0.5338152050971985
Test set avg_accuracy=80.93% avg_sensitivity=29.39%, avg_specificity=95.85% avg_auc=0.7963
Best model saved!! Metric=-40.190801797564!!
Fold[10] Epoch: 10 [10/100 (10%)] Train loss=0.443710 Test loss=0.511369 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42502087354660034
[5/23] Train loss=0.4265332520008087
[10/23] Train loss=0.47170698642730713
[15/23] Train loss=0.42570874094963074
[20/23] Train loss=0.5080589652061462
Test set avg_accuracy=81.37% avg_sensitivity=33.30%, avg_specificity=95.29% avg_auc=0.8041
Best model saved!! Metric=-35.63754551375671!!
Fold[10] Epoch: 11 [11/100 (11%)] Train loss=0.436081 Test loss=0.479877 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41902706027030945
[5/23] Train loss=0.4206840991973877
[10/23] Train loss=0.4687618315219879
[15/23] Train loss=0.409423828125
[20/23] Train loss=0.5119631290435791
Test set avg_accuracy=81.34% avg_sensitivity=34.22%, avg_specificity=94.97% avg_auc=0.8116
Best model saved!! Metric=-34.30745282406566!!
Fold[10] Epoch: 12 [12/100 (12%)] Train loss=0.429234 Test loss=0.481966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40648406744003296
[5/23] Train loss=0.41725602746009827
[10/23] Train loss=0.46837949752807617
[15/23] Train loss=0.406581848859787
[20/23] Train loss=0.5171113014221191
Test set avg_accuracy=81.43% avg_sensitivity=34.33%, avg_specificity=95.06% avg_auc=0.8192
Best model saved!! Metric=-33.25817321772629!!
Fold[10] Epoch: 13 [13/100 (13%)] Train loss=0.427594 Test loss=0.480897 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40739136934280396
[5/23] Train loss=0.4140661358833313
[10/23] Train loss=0.4693942666053772
[15/23] Train loss=0.4122112989425659
[20/23] Train loss=0.5040861964225769
Test set avg_accuracy=81.45% avg_sensitivity=34.99%, avg_specificity=94.90% avg_auc=0.8226
Best model saved!! Metric=-32.39118991929878!!
Fold[10] Epoch: 14 [14/100 (14%)] Train loss=0.423786 Test loss=0.471322 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4039037227630615
[5/23] Train loss=0.4083113670349121
[10/23] Train loss=0.46077364683151245
[15/23] Train loss=0.4104748070240021
[20/23] Train loss=0.48139989376068115
Test set avg_accuracy=81.57% avg_sensitivity=37.72%, avg_specificity=94.26% avg_auc=0.8277
Best model saved!! Metric=-29.68225020161836!!
Fold[10] Epoch: 15 [15/100 (15%)] Train loss=0.419748 Test loss=0.448172 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4098781943321228
[5/23] Train loss=0.40968629717826843
[10/23] Train loss=0.4548328220844269
[15/23] Train loss=0.3929586708545685
[20/23] Train loss=0.48867911100387573
Test set avg_accuracy=81.70% avg_sensitivity=40.13%, avg_specificity=93.72% avg_auc=0.8302
Best model saved!! Metric=-27.422845947494764!!
Fold[10] Epoch: 16 [16/100 (16%)] Train loss=0.412914 Test loss=0.441979 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40184128284454346
[5/23] Train loss=0.4070373773574829
[10/23] Train loss=0.4565613567829132
[15/23] Train loss=0.3929996192455292
[20/23] Train loss=0.48556894063949585
Test set avg_accuracy=81.68% avg_sensitivity=40.70%, avg_specificity=93.55% avg_auc=0.8335
Best model saved!! Metric=-26.720465678962675!!
Fold[10] Epoch: 17 [17/100 (17%)] Train loss=0.409473 Test loss=0.434205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39920660853385925
[5/23] Train loss=0.4023914337158203
[10/23] Train loss=0.45682013034820557
[15/23] Train loss=0.3834701478481293
[20/23] Train loss=0.5069932341575623
Test set avg_accuracy=81.58% avg_sensitivity=39.16%, avg_specificity=93.86% avg_auc=0.8308
Fold[10] Epoch: 18 [18/100 (18%)] Train loss=0.409011 Test loss=0.441775 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3960370719432831
[5/23] Train loss=0.40402424335479736
[10/23] Train loss=0.4576297402381897
[15/23] Train loss=0.39140844345092773
[20/23] Train loss=0.4916714131832123
Test set avg_accuracy=81.58% avg_sensitivity=41.47%, avg_specificity=93.19% avg_auc=0.8360
Best model saved!! Metric=-26.166391650820923!!
Fold[10] Epoch: 19 [19/100 (19%)] Train loss=0.408018 Test loss=0.434313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.391943097114563
[5/23] Train loss=0.39797282218933105
[10/23] Train loss=0.44737526774406433
[15/23] Train loss=0.3779560923576355
[20/23] Train loss=0.48615917563438416
Test set avg_accuracy=81.96% avg_sensitivity=43.88%, avg_specificity=92.98% avg_auc=0.8430
Best model saved!! Metric=-22.874723382777297!!
Fold[10] Epoch: 20 [20/100 (20%)] Train loss=0.403132 Test loss=0.416417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39360108971595764
[5/23] Train loss=0.39817896485328674
[10/23] Train loss=0.4403434991836548
[15/23] Train loss=0.3748328983783722
[20/23] Train loss=0.4874391555786133
Test set avg_accuracy=82.16% avg_sensitivity=45.07%, avg_specificity=92.89% avg_auc=0.8449
Best model saved!! Metric=-21.398417752183413!!
Fold[10] Epoch: 21 [21/100 (21%)] Train loss=0.398396 Test loss=0.417270 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3873443901538849
[5/23] Train loss=0.3894656300544739
[10/23] Train loss=0.4428355097770691
[15/23] Train loss=0.36408597230911255
[20/23] Train loss=0.5021474957466125
Test set avg_accuracy=82.33% avg_sensitivity=44.66%, avg_specificity=93.23% avg_auc=0.8485
Best model saved!! Metric=-20.93220690176728!!
Fold[10] Epoch: 22 [22/100 (22%)] Train loss=0.396114 Test loss=0.420577 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3809507489204407
[5/23] Train loss=0.3952069580554962
[10/23] Train loss=0.44226202368736267
[15/23] Train loss=0.3757982850074768
[20/23] Train loss=0.4938357472419739
Test set avg_accuracy=82.05% avg_sensitivity=41.26%, avg_specificity=93.86% avg_auc=0.8410
Fold[10] Epoch: 23 [23/100 (23%)] Train loss=0.397238 Test loss=0.446618 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38291195034980774
[5/23] Train loss=0.3932393193244934
[10/23] Train loss=0.4525403678417206
[15/23] Train loss=0.3834569454193115
[20/23] Train loss=0.4576275050640106
Test set avg_accuracy=82.17% avg_sensitivity=43.58%, avg_specificity=93.34% avg_auc=0.8448
Fold[10] Epoch: 24 [24/100 (24%)] Train loss=0.394320 Test loss=0.426421 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3797374367713928
[5/23] Train loss=0.3970649838447571
[10/23] Train loss=0.42876526713371277
[15/23] Train loss=0.3611796200275421
[20/23] Train loss=0.47631314396858215
Test set avg_accuracy=82.15% avg_sensitivity=48.15%, avg_specificity=91.98% avg_auc=0.8531
Best model saved!! Metric=-18.410086436551563!!
Fold[10] Epoch: 25 [25/100 (25%)] Train loss=0.388386 Test loss=0.397535 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38232195377349854
[5/23] Train loss=0.38724109530448914
[10/23] Train loss=0.4295673072338104
[15/23] Train loss=0.3597404658794403
[20/23] Train loss=0.474065899848938
Test set avg_accuracy=82.15% avg_sensitivity=45.12%, avg_specificity=92.86% avg_auc=0.8549
Fold[10] Epoch: 26 [26/100 (26%)] Train loss=0.384822 Test loss=0.409965 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3686579465866089
[5/23] Train loss=0.39284026622772217
[10/23] Train loss=0.43336713314056396
[15/23] Train loss=0.3614112138748169
[20/23] Train loss=0.4661169648170471
Test set avg_accuracy=82.20% avg_sensitivity=45.79%, avg_specificity=92.74% avg_auc=0.8514
Fold[10] Epoch: 27 [27/100 (27%)] Train loss=0.384571 Test loss=0.416086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3673672378063202
[5/23] Train loss=0.38779792189598083
[10/23] Train loss=0.43161219358444214
[15/23] Train loss=0.35757124423980713
[20/23] Train loss=0.4577259123325348
Test set avg_accuracy=82.32% avg_sensitivity=46.40%, avg_specificity=92.71% avg_auc=0.8555
Fold[10] Epoch: 28 [28/100 (28%)] Train loss=0.380750 Test loss=0.408074 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3711735010147095
[5/23] Train loss=0.38270941376686096
[10/23] Train loss=0.42976638674736023
[15/23] Train loss=0.35315439105033875
[20/23] Train loss=0.45405685901641846
Test set avg_accuracy=82.45% avg_sensitivity=47.12%, avg_specificity=92.67% avg_auc=0.8563
Best model saved!! Metric=-18.132857655671526!!
Fold[10] Epoch: 29 [29/100 (29%)] Train loss=0.378108 Test loss=0.410133 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3593675196170807
[5/23] Train loss=0.3828483819961548
[10/23] Train loss=0.42042288184165955
[15/23] Train loss=0.35264211893081665
[20/23] Train loss=0.4662450850009918
Test set avg_accuracy=82.50% avg_sensitivity=49.59%, avg_specificity=92.03% avg_auc=0.8546
Best model saved!! Metric=-16.424246872297196!!
Fold[10] Epoch: 30 [30/100 (30%)] Train loss=0.372842 Test loss=0.411035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3695445656776428
[5/23] Train loss=0.37614870071411133
[10/23] Train loss=0.42486199736595154
[15/23] Train loss=0.3459354043006897
[20/23] Train loss=0.4724237024784088
Test set avg_accuracy=82.35% avg_sensitivity=48.46%, avg_specificity=92.16% avg_auc=0.8573
Fold[10] Epoch: 31 [31/100 (31%)] Train loss=0.371260 Test loss=0.405467 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3615557551383972
[5/23] Train loss=0.37935328483581543
[10/23] Train loss=0.42716336250305176
[15/23] Train loss=0.3392942547798157
[20/23] Train loss=0.4636208415031433
Test set avg_accuracy=82.36% avg_sensitivity=45.68%, avg_specificity=92.98% avg_auc=0.8522
Fold[10] Epoch: 32 [32/100 (32%)] Train loss=0.371698 Test loss=0.412269 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3583161234855652
[5/23] Train loss=0.37205126881599426
[10/23] Train loss=0.41787904500961304
[15/23] Train loss=0.3428843021392822
[20/23] Train loss=0.43940290808677673
Test set avg_accuracy=82.54% avg_sensitivity=49.49%, avg_specificity=92.10% avg_auc=0.8574
Best model saved!! Metric=-16.13829407934659!!
Fold[10] Epoch: 33 [33/100 (33%)] Train loss=0.368009 Test loss=0.400722 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3578822612762451
[5/23] Train loss=0.37112298607826233
[10/23] Train loss=0.4076695144176483
[15/23] Train loss=0.3363826870918274
[20/23] Train loss=0.4541061818599701
Test set avg_accuracy=82.32% avg_sensitivity=52.31%, avg_specificity=91.00% avg_auc=0.8607
Best model saved!! Metric=-14.29383352239542!!
Fold[10] Epoch: 34 [34/100 (34%)] Train loss=0.365840 Test loss=0.399063 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.353755384683609
[5/23] Train loss=0.3659208118915558
[10/23] Train loss=0.40907415747642517
[15/23] Train loss=0.3283929228782654
[20/23] Train loss=0.4545089304447174
Test set avg_accuracy=82.50% avg_sensitivity=50.41%, avg_specificity=91.79% avg_auc=0.8598
Fold[10] Epoch: 35 [35/100 (35%)] Train loss=0.360440 Test loss=0.395256 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3518742322921753
[5/23] Train loss=0.3742290139198303
[10/23] Train loss=0.4084046185016632
[15/23] Train loss=0.33490315079689026
[20/23] Train loss=0.4239714741706848
Test set avg_accuracy=82.26% avg_sensitivity=50.05%, avg_specificity=91.58% avg_auc=0.8629
Fold[10] Epoch: 36 [36/100 (36%)] Train loss=0.359566 Test loss=0.394656 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.349632203578949
[5/23] Train loss=0.3599727749824524
[10/23] Train loss=0.400469034910202
[15/23] Train loss=0.3270256221294403
[20/23] Train loss=0.42529985308647156
Test set avg_accuracy=82.66% avg_sensitivity=51.44%, avg_specificity=91.70% avg_auc=0.8589
Fold[10] Epoch: 37 [37/100 (37%)] Train loss=0.356436 Test loss=0.395058 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.346179336309433
[5/23] Train loss=0.3613596558570862
[10/23] Train loss=0.39691677689552307
[15/23] Train loss=0.32687637209892273
[20/23] Train loss=0.43737277388572693
Test set avg_accuracy=82.71% avg_sensitivity=52.88%, avg_specificity=91.34% avg_auc=0.8618
Best model saved!! Metric=-12.885780784525826!!
Fold[10] Epoch: 38 [38/100 (38%)] Train loss=0.353944 Test loss=0.406422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34162330627441406
[5/23] Train loss=0.36057808995246887
[10/23] Train loss=0.4042028784751892
[15/23] Train loss=0.3189961016178131
[20/23] Train loss=0.44704559445381165
Test set avg_accuracy=82.63% avg_sensitivity=50.15%, avg_specificity=92.03% avg_auc=0.8614
Fold[10] Epoch: 39 [39/100 (39%)] Train loss=0.353786 Test loss=0.404672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.344687819480896
[5/23] Train loss=0.3499625027179718
[10/23] Train loss=0.407914936542511
[15/23] Train loss=0.3315548002719879
[20/23] Train loss=0.4198096990585327
Test set avg_accuracy=82.47% avg_sensitivity=49.74%, avg_specificity=91.94% avg_auc=0.8605
Fold[10] Epoch: 40 [40/100 (40%)] Train loss=0.351152 Test loss=0.391192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3399182856082916
[5/23] Train loss=0.35480189323425293
[10/23] Train loss=0.4030873477458954
[15/23] Train loss=0.3184960186481476
[20/23] Train loss=0.4162057936191559
Test set avg_accuracy=82.61% avg_sensitivity=54.47%, avg_specificity=90.75% avg_auc=0.8673
Best model saved!! Metric=-11.442200803570065!!
Fold[10] Epoch: 41 [41/100 (41%)] Train loss=0.349282 Test loss=0.387152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33606937527656555
[5/23] Train loss=0.35311999917030334
[10/23] Train loss=0.39003488421440125
[15/23] Train loss=0.3174040615558624
[20/23] Train loss=0.41531476378440857
Test set avg_accuracy=82.57% avg_sensitivity=45.48%, avg_specificity=93.31% avg_auc=0.8520
Fold[10] Epoch: 42 [42/100 (42%)] Train loss=0.348677 Test loss=0.414583 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3318382501602173
[5/23] Train loss=0.3452531099319458
[10/23] Train loss=0.3860277235507965
[15/23] Train loss=0.30662867426872253
[20/23] Train loss=0.435663640499115
Test set avg_accuracy=82.69% avg_sensitivity=56.73%, avg_specificity=90.20% avg_auc=0.8603
Best model saved!! Metric=-10.35142082510445!!
Fold[10] Epoch: 43 [43/100 (43%)] Train loss=0.343442 Test loss=0.381190 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3411098122596741
[5/23] Train loss=0.3384269177913666
[10/23] Train loss=0.38915643095970154
[15/23] Train loss=0.3148840665817261
[20/23] Train loss=0.42146703600883484
Test set avg_accuracy=82.62% avg_sensitivity=50.51%, avg_specificity=91.91% avg_auc=0.8608
Fold[10] Epoch: 44 [44/100 (44%)] Train loss=0.340365 Test loss=0.423579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32842859625816345
[5/23] Train loss=0.33541303873062134
[10/23] Train loss=0.37860947847366333
[15/23] Train loss=0.3023632764816284
[20/23] Train loss=0.4095536768436432
Test set avg_accuracy=82.61% avg_sensitivity=53.96%, avg_specificity=90.90% avg_auc=0.8654
Fold[10] Epoch: 45 [45/100 (45%)] Train loss=0.338699 Test loss=0.389451 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33010348677635193
[5/23] Train loss=0.33781158924102783
[10/23] Train loss=0.3795357644557953
[15/23] Train loss=0.30160003900527954
[20/23] Train loss=0.41854438185691833
Test set avg_accuracy=82.49% avg_sensitivity=51.49%, avg_specificity=91.46% avg_auc=0.8611
Fold[10] Epoch: 46 [46/100 (46%)] Train loss=0.335012 Test loss=0.396885 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32839226722717285
[5/23] Train loss=0.33932653069496155
[10/23] Train loss=0.37912726402282715
[15/23] Train loss=0.30828481912612915
[20/23] Train loss=0.39470988512039185
Test set avg_accuracy=82.76% avg_sensitivity=51.90%, avg_specificity=91.69% avg_auc=0.8662
Fold[10] Epoch: 47 [47/100 (47%)] Train loss=0.336088 Test loss=0.396906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3289487361907959
[5/23] Train loss=0.32474783062934875
[10/23] Train loss=0.36456745862960815
[15/23] Train loss=0.2961893379688263
[20/23] Train loss=0.38977304100990295
Test set avg_accuracy=83.09% avg_sensitivity=54.57%, avg_specificity=91.34% avg_auc=0.8597
Fold[10] Epoch: 48 [48/100 (48%)] Train loss=0.327765 Test loss=0.414528 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32277700304985046
[5/23] Train loss=0.3250303566455841
[10/23] Train loss=0.3618754744529724
[15/23] Train loss=0.2858448624610901
[20/23] Train loss=0.41106241941452026
Test set avg_accuracy=82.92% avg_sensitivity=51.59%, avg_specificity=91.98% avg_auc=0.8634
Fold[10] Epoch: 49 [49/100 (49%)] Train loss=0.326415 Test loss=0.414935 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31840676069259644
[5/23] Train loss=0.3214952051639557
[10/23] Train loss=0.3600119352340698
[15/23] Train loss=0.286373108625412
[20/23] Train loss=0.4113847315311432
Test set avg_accuracy=82.68% avg_sensitivity=52.00%, avg_specificity=91.55% avg_auc=0.8631
Fold[10] Epoch: 50 [50/100 (50%)] Train loss=0.324143 Test loss=0.390935 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.319687157869339
[5/23] Train loss=0.32550784945487976
[10/23] Train loss=0.3665597140789032
[15/23] Train loss=0.29280897974967957
[20/23] Train loss=0.423267126083374
Test set avg_accuracy=82.79% avg_sensitivity=47.84%, avg_specificity=92.91% avg_auc=0.8568
Fold[10] Epoch: 51 [51/100 (51%)] Train loss=0.327246 Test loss=0.412114 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32353338599205017
[5/23] Train loss=0.3221074640750885
[10/23] Train loss=0.36392122507095337
[15/23] Train loss=0.2997516691684723
[20/23] Train loss=0.399913489818573
Test set avg_accuracy=82.62% avg_sensitivity=50.87%, avg_specificity=91.81% avg_auc=0.8608
Fold[10] Epoch: 52 [52/100 (52%)] Train loss=0.329213 Test loss=0.389855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32130327820777893
[5/23] Train loss=0.3278326988220215
[10/23] Train loss=0.3492193818092346
[15/23] Train loss=0.2886058986186981
[20/23] Train loss=0.3834993839263916
Test set avg_accuracy=82.77% avg_sensitivity=52.72%, avg_specificity=91.46% avg_auc=0.8638
Fold[10] Epoch: 53 [53/100 (53%)] Train loss=0.321344 Test loss=0.422079 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3134579360485077
[5/23] Train loss=0.3102174699306488
[10/23] Train loss=0.36100655794143677
[15/23] Train loss=0.2863057553768158
[20/23] Train loss=0.3972924053668976
Test set avg_accuracy=83.07% avg_sensitivity=52.00%, avg_specificity=92.06% avg_auc=0.8606
Fold[10] Epoch: 54 [54/100 (54%)] Train loss=0.316928 Test loss=0.405626 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3155363202095032
[5/23] Train loss=0.3179052770137787
[10/23] Train loss=0.3437559902667999
[15/23] Train loss=0.27459651231765747
[20/23] Train loss=0.379568487405777
Test set avg_accuracy=82.68% avg_sensitivity=50.46%, avg_specificity=92.00% avg_auc=0.8621
Fold[10] Epoch: 55 [55/100 (55%)] Train loss=0.312207 Test loss=0.411320 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30512097477912903
[5/23] Train loss=0.3194468021392822
[10/23] Train loss=0.34677839279174805
[15/23] Train loss=0.27261409163475037
[20/23] Train loss=0.38113731145858765
Test set avg_accuracy=82.99% avg_sensitivity=54.27%, avg_specificity=91.30% avg_auc=0.8587
Fold[10] Epoch: 56 [56/100 (56%)] Train loss=0.310961 Test loss=0.396339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30621400475502014
[5/23] Train loss=0.30633530020713806
[10/23] Train loss=0.33314287662506104
[15/23] Train loss=0.2748449444770813
[20/23] Train loss=0.37153077125549316
Test set avg_accuracy=82.73% avg_sensitivity=53.49%, avg_specificity=91.20% avg_auc=0.8611
Fold[10] Epoch: 57 [57/100 (57%)] Train loss=0.308302 Test loss=0.428655 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30856791138648987
[5/23] Train loss=0.29997092485427856
[10/23] Train loss=0.32995370030403137
[15/23] Train loss=0.26387089490890503
[20/23] Train loss=0.38640233874320984
Test set avg_accuracy=82.87% avg_sensitivity=57.04%, avg_specificity=90.35% avg_auc=0.8627
Best model saved!! Metric=-9.466527375659432!!
Fold[10] Epoch: 58 [58/100 (58%)] Train loss=0.304290 Test loss=0.411069 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3064879775047302
[5/23] Train loss=0.3032815158367157
[10/23] Train loss=0.3333915174007416
[15/23] Train loss=0.2630068361759186
[20/23] Train loss=0.37373989820480347
Test set avg_accuracy=82.86% avg_sensitivity=53.85%, avg_specificity=91.26% avg_auc=0.8637
Fold[10] Epoch: 59 [59/100 (59%)] Train loss=0.302992 Test loss=0.411147 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2926919460296631
[5/23] Train loss=0.301025927066803
[10/23] Train loss=0.3309747278690338
[15/23] Train loss=0.2580559253692627
[20/23] Train loss=0.3687736392021179
Test set avg_accuracy=82.81% avg_sensitivity=56.99%, avg_specificity=90.29% avg_auc=0.8577
Fold[10] Epoch: 60 [60/100 (60%)] Train loss=0.298606 Test loss=0.399484 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.300721675157547
[5/23] Train loss=0.3004583716392517
[10/23] Train loss=0.3240583539009094
[15/23] Train loss=0.26627230644226074
[20/23] Train loss=0.37410715222358704
Test set avg_accuracy=82.91% avg_sensitivity=52.00%, avg_specificity=91.85% avg_auc=0.8577
Fold[10] Epoch: 61 [61/100 (61%)] Train loss=0.300978 Test loss=0.405630 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2888793349266052
[5/23] Train loss=0.301274836063385
[10/23] Train loss=0.3345286548137665
[15/23] Train loss=0.26605504751205444
[20/23] Train loss=0.36418774724006653
Test set avg_accuracy=83.07% avg_sensitivity=53.39%, avg_specificity=91.66% avg_auc=0.8634
Fold[10] Epoch: 62 [62/100 (62%)] Train loss=0.304889 Test loss=0.412184 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2927529811859131
[5/23] Train loss=0.30886590480804443
[10/23] Train loss=0.32338544726371765
[15/23] Train loss=0.2493741810321808
[20/23] Train loss=0.3737870454788208
Test set avg_accuracy=82.90% avg_sensitivity=57.45%, avg_specificity=90.26% avg_auc=0.8442
Fold[10] Epoch: 63 [63/100 (63%)] Train loss=0.298390 Test loss=0.427273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3099549114704132
[5/23] Train loss=0.2911578118801117
[10/23] Train loss=0.3181922137737274
[15/23] Train loss=0.2459748089313507
[20/23] Train loss=0.37322989106178284
Test set avg_accuracy=83.10% avg_sensitivity=55.24%, avg_specificity=91.17% avg_auc=0.8638
Fold[10] Epoch: 64 [64/100 (64%)] Train loss=0.293939 Test loss=0.420707 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28979894518852234
[5/23] Train loss=0.28998616337776184
[10/23] Train loss=0.32460150122642517
[15/23] Train loss=0.25385990738868713
[20/23] Train loss=0.3684248924255371
Test set avg_accuracy=82.96% avg_sensitivity=53.44%, avg_specificity=91.51% avg_auc=0.8579
Fold[10] Epoch: 65 [65/100 (65%)] Train loss=0.297116 Test loss=0.408191 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2866770923137665
[5/23] Train loss=0.29928478598594666
[10/23] Train loss=0.3089849650859833
[15/23] Train loss=0.24860195815563202
[20/23] Train loss=0.354493647813797
Test set avg_accuracy=82.88% avg_sensitivity=55.86%, avg_specificity=90.70% avg_auc=0.8549
Fold[10] Epoch: 66 [66/100 (66%)] Train loss=0.289338 Test loss=0.423727 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28501394391059875
[5/23] Train loss=0.28543874621391296
[10/23] Train loss=0.30680757761001587
[15/23] Train loss=0.2307734340429306
[20/23] Train loss=0.3806658983230591
Test set avg_accuracy=82.76% avg_sensitivity=54.01%, avg_specificity=91.08% avg_auc=0.8627
Fold[10] Epoch: 67 [67/100 (67%)] Train loss=0.287488 Test loss=0.427028 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28281766176223755
[5/23] Train loss=0.2736157774925232
[10/23] Train loss=0.2963891625404358
[15/23] Train loss=0.2521979808807373
[20/23] Train loss=0.3794776499271393
Test set avg_accuracy=82.93% avg_sensitivity=50.36%, avg_specificity=92.36% avg_auc=0.8546
Fold[10] Epoch: 68 [68/100 (68%)] Train loss=0.286621 Test loss=0.414045 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2900664210319519
[5/23] Train loss=0.2902803122997284
[10/23] Train loss=0.3079846203327179
[15/23] Train loss=0.25085246562957764
[20/23] Train loss=0.36486953496932983
Test set avg_accuracy=82.55% avg_sensitivity=49.69%, avg_specificity=92.06% avg_auc=0.8576
Fold[10] Epoch: 69 [69/100 (69%)] Train loss=0.289440 Test loss=0.443513 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2810070216655731
[5/23] Train loss=0.28752297163009644
[10/23] Train loss=0.3038676977157593
[15/23] Train loss=0.2399597018957138
[20/23] Train loss=0.34502410888671875
Test set avg_accuracy=82.81% avg_sensitivity=50.72%, avg_specificity=92.10% avg_auc=0.8553
Fold[10] Epoch: 70 [70/100 (70%)] Train loss=0.284614 Test loss=0.428822 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2724481225013733
[5/23] Train loss=0.284848690032959
[10/23] Train loss=0.28991419076919556
[15/23] Train loss=0.24077150225639343
[20/23] Train loss=0.3458922505378723
Test set avg_accuracy=82.91% avg_sensitivity=58.22%, avg_specificity=90.05% avg_auc=0.8550
Best model saved!! Metric=-9.322180512717907!!
Fold[10] Epoch: 71 [71/100 (71%)] Train loss=0.279760 Test loss=0.437716 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2731843888759613
[5/23] Train loss=0.2741740345954895
[10/23] Train loss=0.28585347533226013
[15/23] Train loss=0.2338757961988449
[20/23] Train loss=0.3403136730194092
Test set avg_accuracy=82.53% avg_sensitivity=53.80%, avg_specificity=90.84% avg_auc=0.8537
Fold[10] Epoch: 72 [72/100 (72%)] Train loss=0.275141 Test loss=0.431553 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.268655925989151
[5/23] Train loss=0.2685807943344116
[10/23] Train loss=0.29082903265953064
[15/23] Train loss=0.22994743287563324
[20/23] Train loss=0.3344912528991699
Test set avg_accuracy=82.92% avg_sensitivity=54.78%, avg_specificity=91.06% avg_auc=0.8532
Fold[10] Epoch: 73 [73/100 (73%)] Train loss=0.272551 Test loss=0.437582 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.264255166053772
[5/23] Train loss=0.27647003531455994
[10/23] Train loss=0.272022545337677
[15/23] Train loss=0.22790761291980743
[20/23] Train loss=0.3511650562286377
Test set avg_accuracy=82.90% avg_sensitivity=53.80%, avg_specificity=91.31% avg_auc=0.8529
Fold[10] Epoch: 74 [74/100 (74%)] Train loss=0.269585 Test loss=0.436929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2803751230239868
[5/23] Train loss=0.26528027653694153
[10/23] Train loss=0.27573761343955994
[15/23] Train loss=0.220068097114563
[20/23] Train loss=0.3518609404563904
Test set avg_accuracy=82.48% avg_sensitivity=53.75%, avg_specificity=90.79% avg_auc=0.8408
Fold[10] Epoch: 75 [75/100 (75%)] Train loss=0.267482 Test loss=0.438208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2667681872844696
[5/23] Train loss=0.2586476802825928
[10/23] Train loss=0.2757551670074463
[15/23] Train loss=0.21845342218875885
[20/23] Train loss=0.34457483887672424
Test set avg_accuracy=82.93% avg_sensitivity=48.97%, avg_specificity=92.76% avg_auc=0.8332
Fold[10] Epoch: 76 [76/100 (76%)] Train loss=0.268526 Test loss=0.453340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2668318748474121
[5/23] Train loss=0.26593849062919617
[10/23] Train loss=0.288650780916214
[15/23] Train loss=0.22954383492469788
[20/23] Train loss=0.3322102427482605
Test set avg_accuracy=82.12% avg_sensitivity=48.82%, avg_specificity=91.76% avg_auc=0.8468
Fold[10] Epoch: 77 [77/100 (77%)] Train loss=0.269163 Test loss=0.462763 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26343098282814026
[5/23] Train loss=0.2705858647823334
[10/23] Train loss=0.2639806568622589
[15/23] Train loss=0.21618317067623138
[20/23] Train loss=0.32517945766448975
Test set avg_accuracy=82.20% avg_sensitivity=59.10%, avg_specificity=88.89% avg_auc=0.8450
Fold[10] Epoch: 78 [78/100 (78%)] Train loss=0.264025 Test loss=0.452184 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2757033705711365
[5/23] Train loss=0.2577199339866638
[10/23] Train loss=0.2711200714111328
[15/23] Train loss=0.22040987014770508
[20/23] Train loss=0.3293602764606476
Test set avg_accuracy=82.20% avg_sensitivity=50.82%, avg_specificity=91.28% avg_auc=0.8371
Fold[10] Epoch: 79 [79/100 (79%)] Train loss=0.264092 Test loss=0.454968 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2793801426887512
[5/23] Train loss=0.25882038474082947
[10/23] Train loss=0.26122432947158813
[15/23] Train loss=0.20988589525222778
[20/23] Train loss=0.3316583037376404
Test set avg_accuracy=82.04% avg_sensitivity=60.33%, avg_specificity=88.33% avg_auc=0.8388
Fold[10] Epoch: 80 [80/100 (80%)] Train loss=0.258714 Test loss=0.462745 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25293177366256714
[5/23] Train loss=0.24680697917938232
[10/23] Train loss=0.2631453573703766
[15/23] Train loss=0.2009054273366928
[20/23] Train loss=0.3268200159072876
Test set avg_accuracy=82.56% avg_sensitivity=52.67%, avg_specificity=91.21% avg_auc=0.8441
Fold[10] Epoch: 81 [81/100 (81%)] Train loss=0.257086 Test loss=0.467216 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24973221123218536
[5/23] Train loss=0.24408452212810516
[10/23] Train loss=0.261921763420105
[15/23] Train loss=0.20432916283607483
[20/23] Train loss=0.32016727328300476
Test set avg_accuracy=82.21% avg_sensitivity=52.67%, avg_specificity=90.76% avg_auc=0.8381
Fold[10] Epoch: 82 [82/100 (82%)] Train loss=0.250990 Test loss=0.458142 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25562363862991333
[5/23] Train loss=0.2524770498275757
[10/23] Train loss=0.25603899359703064
[15/23] Train loss=0.2007012516260147
[20/23] Train loss=0.31741440296173096
Test set avg_accuracy=82.58% avg_sensitivity=52.83%, avg_specificity=91.20% avg_auc=0.8494
Fold[10] Epoch: 83 [83/100 (83%)] Train loss=0.250610 Test loss=0.476668 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24783147871494293
[5/23] Train loss=0.24458938837051392
[10/23] Train loss=0.250996857881546
[15/23] Train loss=0.19863229990005493
[20/23] Train loss=0.3224974572658539
Test set avg_accuracy=83.01% avg_sensitivity=55.65%, avg_specificity=90.93% avg_auc=0.8335
Fold[10] Epoch: 84 [84/100 (84%)] Train loss=0.249308 Test loss=0.443121 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24339793622493744
[5/23] Train loss=0.2417995184659958
[10/23] Train loss=0.2508360743522644
[15/23] Train loss=0.1979953497648239
[20/23] Train loss=0.3101594150066376
Test set avg_accuracy=82.66% avg_sensitivity=56.63%, avg_specificity=90.20% avg_auc=0.8404
Fold[10] Epoch: 85 [85/100 (85%)] Train loss=0.246780 Test loss=0.464313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24206587672233582
[5/23] Train loss=0.2414862960577011
[10/23] Train loss=0.2501727044582367
[15/23] Train loss=0.19752837717533112
[20/23] Train loss=0.3073180913925171
Test set avg_accuracy=82.53% avg_sensitivity=55.04%, avg_specificity=90.48% avg_auc=0.8407
Fold[10] Epoch: 86 [86/100 (86%)] Train loss=0.243862 Test loss=0.464260 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24653202295303345
[5/23] Train loss=0.2378658950328827
[10/23] Train loss=0.24345603585243225
[15/23] Train loss=0.1889108121395111
[20/23] Train loss=0.3262102007865906
Test set avg_accuracy=81.73% avg_sensitivity=58.74%, avg_specificity=88.38% avg_auc=0.8366
Fold[10] Epoch: 87 [87/100 (87%)] Train loss=0.240550 Test loss=0.470168 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2473583072423935
[5/23] Train loss=0.22705107927322388
[10/23] Train loss=0.24054479598999023
[15/23] Train loss=0.1915387064218521
[20/23] Train loss=0.2999652922153473
Test set avg_accuracy=82.62% avg_sensitivity=54.57%, avg_specificity=90.73% avg_auc=0.8442
Fold[10] Epoch: 88 [88/100 (88%)] Train loss=0.237594 Test loss=0.467319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2375655621290207
[5/23] Train loss=0.22888699173927307
[10/23] Train loss=0.24022936820983887
[15/23] Train loss=0.19144058227539062
[20/23] Train loss=0.2946728467941284
Test set avg_accuracy=82.56% avg_sensitivity=54.88%, avg_specificity=90.57% avg_auc=0.8430
Fold[10] Epoch: 89 [89/100 (89%)] Train loss=0.237763 Test loss=0.475019 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22836701571941376
[5/23] Train loss=0.23657266795635223
[10/23] Train loss=0.23791424930095673
[15/23] Train loss=0.18138816952705383
[20/23] Train loss=0.30644068121910095
Test set avg_accuracy=83.11% avg_sensitivity=53.44%, avg_specificity=91.70% avg_auc=0.8386
Fold[10] Epoch: 90 [90/100 (90%)] Train loss=0.236190 Test loss=0.468002 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2329339236021042
[5/23] Train loss=0.23216569423675537
[10/23] Train loss=0.24033695459365845
[15/23] Train loss=0.18836845457553864
[20/23] Train loss=0.29321402311325073
Test set avg_accuracy=82.09% avg_sensitivity=56.68%, avg_specificity=89.44% avg_auc=0.8305
Fold[10] Epoch: 91 [91/100 (91%)] Train loss=0.233058 Test loss=0.490714 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2290852665901184
[5/23] Train loss=0.2318955957889557
[10/23] Train loss=0.22955478727817535
[15/23] Train loss=0.18528799712657928
[20/23] Train loss=0.300006240606308
Test set avg_accuracy=82.94% avg_sensitivity=48.41%, avg_specificity=92.94% avg_auc=0.8412
Fold[10] Epoch: 92 [92/100 (92%)] Train loss=0.234512 Test loss=0.486142 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.234535351395607
[5/23] Train loss=0.22302065789699554
[10/23] Train loss=0.24678167700767517
[15/23] Train loss=0.19799946248531342
[20/23] Train loss=0.3001159429550171
Test set avg_accuracy=82.27% avg_sensitivity=50.77%, avg_specificity=91.39% avg_auc=0.8248
Fold[10] Epoch: 93 [93/100 (93%)] Train loss=0.237252 Test loss=0.499418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22873064875602722
[5/23] Train loss=0.23793746531009674
[10/23] Train loss=0.2233443707227707
[15/23] Train loss=0.1785452514886856
[20/23] Train loss=0.3160554766654968
Test set avg_accuracy=82.21% avg_sensitivity=54.68%, avg_specificity=90.18% avg_auc=0.8225
Fold[10] Epoch: 94 [94/100 (94%)] Train loss=0.230506 Test loss=0.487653 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2288270741701126
[5/23] Train loss=0.22625555098056793
[10/23] Train loss=0.21719889342784882
[15/23] Train loss=0.16791023313999176
[20/23] Train loss=0.3008154332637787
Test set avg_accuracy=82.53% avg_sensitivity=54.47%, avg_specificity=90.65% avg_auc=0.8368
Fold[10] Epoch: 95 [95/100 (95%)] Train loss=0.226340 Test loss=0.478073 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2263212651014328
[5/23] Train loss=0.21954473853111267
[10/23] Train loss=0.21393385529518127
[15/23] Train loss=0.17283135652542114
[20/23] Train loss=0.28472277522087097
Test set avg_accuracy=82.30% avg_sensitivity=55.24%, avg_specificity=90.12% avg_auc=0.8387
Fold[10] Epoch: 96 [96/100 (96%)] Train loss=0.221775 Test loss=0.485395 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2187451720237732
[5/23] Train loss=0.20805469155311584
[10/23] Train loss=0.21650069952011108
[15/23] Train loss=0.17596882581710815
[20/23] Train loss=0.2913336157798767
Test set avg_accuracy=82.64% avg_sensitivity=56.42%, avg_specificity=90.23% avg_auc=0.8386
Fold[10] Epoch: 97 [97/100 (97%)] Train loss=0.218613 Test loss=0.499406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2217138260602951
[5/23] Train loss=0.2120629996061325
[10/23] Train loss=0.20442292094230652
[15/23] Train loss=0.1740753948688507
[20/23] Train loss=0.2900000810623169
Test set avg_accuracy=82.53% avg_sensitivity=54.93%, avg_specificity=90.51% avg_auc=0.8360
Fold[10] Epoch: 98 [98/100 (98%)] Train loss=0.215591 Test loss=0.487522 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2075774073600769
[5/23] Train loss=0.20682822167873383
[10/23] Train loss=0.21445108950138092
[15/23] Train loss=0.16313964128494263
[20/23] Train loss=0.2721010446548462
Test set avg_accuracy=82.25% avg_sensitivity=51.70%, avg_specificity=91.09% avg_auc=0.8350
Fold[10] Epoch: 99 [99/100 (99%)] Train loss=0.214933 Test loss=0.493717 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2112586498260498
[5/23] Train loss=0.20883575081825256
[10/23] Train loss=0.2081380933523178
[15/23] Train loss=0.16908781230449677
[20/23] Train loss=0.27832290530204773
Test set avg_accuracy=82.58% avg_sensitivity=52.26%, avg_specificity=91.36% avg_auc=0.8315
Fold[10] Epoch: 100 [100/100 (100%)] Train loss=0.211867 Test loss=0.493275 Current lr=[3.9999999999999996e-05]

Fold[10] Best Result: acc=82.90657439446368 sen=58.22199383350463, spe=90.05056513979774, auc=0.8549868611951605!
Final Avg Result: avg_acc=81.428040% avg_sen=60.561548% avg_spe=88.323881% avg_auc=0.850279
