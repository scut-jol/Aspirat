[0/12] Train loss=0.7224671840667725
[5/12] Train loss=0.5711579918861389
[10/12] Train loss=0.4201928675174713
Test set avg_accuracy=73.64% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7752
Best model saved!!!!
Fold[1] Epoch: 1 [1/300 (0%)] Train loss=0.721368 Test loss=1.029591

[0/12] Train loss=0.40476012229919434
[5/12] Train loss=0.3925854563713074
[10/12] Train loss=0.36132121086120605
Test set avg_accuracy=74.65% avg_sensitivity=4.37%, avg_specificity=99.81% avg_auc=0.8608
Best model saved!!!!
Fold[1] Epoch: 2 [2/300 (1%)] Train loss=0.400773 Test loss=0.467383

[0/12] Train loss=0.36417505145072937
[5/12] Train loss=0.36076822876930237
[10/12] Train loss=0.2962610125541687
Test set avg_accuracy=80.23% avg_sensitivity=28.19%, avg_specificity=98.86% avg_auc=0.8887
Best model saved!!!!
Fold[1] Epoch: 3 [3/300 (1%)] Train loss=0.346613 Test loss=0.398698

[0/12] Train loss=0.318682461977005
[5/12] Train loss=0.32270756363868713
[10/12] Train loss=0.2588987350463867
Test set avg_accuracy=83.64% avg_sensitivity=46.32%, avg_specificity=97.00% avg_auc=0.8993
Best model saved!!!!
Fold[1] Epoch: 4 [4/300 (1%)] Train loss=0.314063 Test loss=0.376854

[0/12] Train loss=0.2940050959587097
[5/12] Train loss=0.2881968915462494
[10/12] Train loss=0.2348739504814148
Test set avg_accuracy=84.57% avg_sensitivity=53.84%, avg_specificity=95.57% avg_auc=0.9066
Best model saved!!!!
Fold[1] Epoch: 5 [5/300 (2%)] Train loss=0.286574 Test loss=0.366260

[0/12] Train loss=0.2662092447280884
[5/12] Train loss=0.269609659910202
[10/12] Train loss=0.20789679884910583
Test set avg_accuracy=86.57% avg_sensitivity=63.86%, avg_specificity=94.70% avg_auc=0.9210
Best model saved!!!!
Fold[1] Epoch: 6 [6/300 (2%)] Train loss=0.263822 Test loss=0.333316

[0/12] Train loss=0.25087177753448486
[5/12] Train loss=0.24936117231845856
[10/12] Train loss=0.20401738584041595
Test set avg_accuracy=87.04% avg_sensitivity=70.70%, avg_specificity=92.90% avg_auc=0.9295
Best model saved!!!!
Fold[1] Epoch: 7 [7/300 (2%)] Train loss=0.244443 Test loss=0.306346

[0/12] Train loss=0.22335578501224518
[5/12] Train loss=0.22530923783779144
[10/12] Train loss=0.18688808381557465
Test set avg_accuracy=88.01% avg_sensitivity=68.23%, avg_specificity=95.09% avg_auc=0.9299
Best model saved!!!!
Fold[1] Epoch: 8 [8/300 (3%)] Train loss=0.223127 Test loss=0.305711

[0/12] Train loss=0.20506030321121216
[5/12] Train loss=0.20697546005249023
[10/12] Train loss=0.1847234070301056
Test set avg_accuracy=84.44% avg_sensitivity=44.89%, avg_specificity=98.60% avg_auc=0.9030
Fold[1] Epoch: 9 [9/300 (3%)] Train loss=0.211175 Test loss=0.424685

[0/12] Train loss=0.21375536918640137
[5/12] Train loss=0.20341943204402924
[10/12] Train loss=0.1798054575920105
Test set avg_accuracy=86.59% avg_sensitivity=61.71%, avg_specificity=95.50% avg_auc=0.9128
Fold[1] Epoch: 10 [10/300 (3%)] Train loss=0.206169 Test loss=0.350731

[0/12] Train loss=0.19175231456756592
[5/12] Train loss=0.20696894824504852
[10/12] Train loss=0.18123793601989746
Test set avg_accuracy=87.06% avg_sensitivity=61.83%, avg_specificity=96.10% avg_auc=0.9159
Fold[1] Epoch: 11 [11/300 (4%)] Train loss=0.199102 Test loss=0.364750

[0/12] Train loss=0.18279509246349335
[5/12] Train loss=0.17282603681087494
[10/12] Train loss=0.15065360069274902
Test set avg_accuracy=84.23% avg_sensitivity=49.38%, avg_specificity=96.71% avg_auc=0.9111
Fold[1] Epoch: 12 [12/300 (4%)] Train loss=0.185799 Test loss=0.441469

[0/12] Train loss=0.22695016860961914
[5/12] Train loss=0.19866235554218292
[10/12] Train loss=0.15973526239395142
Test set avg_accuracy=87.12% avg_sensitivity=66.00%, avg_specificity=94.68% avg_auc=0.9238
Fold[1] Epoch: 13 [13/300 (4%)] Train loss=0.189757 Test loss=0.348037

[0/12] Train loss=0.16290093958377838
[5/12] Train loss=0.18922483921051025
[10/12] Train loss=0.14890684187412262
Test set avg_accuracy=85.48% avg_sensitivity=57.46%, avg_specificity=95.52% avg_auc=0.9102
Fold[1] Epoch: 14 [14/300 (5%)] Train loss=0.176009 Test loss=0.396595

[0/12] Train loss=0.17805832624435425
[5/12] Train loss=0.15488509833812714
[10/12] Train loss=0.14938507974147797
Test set avg_accuracy=87.76% avg_sensitivity=70.82%, avg_specificity=93.82% avg_auc=0.9191
Fold[1] Epoch: 15 [15/300 (5%)] Train loss=0.181412 Test loss=0.401190

[0/12] Train loss=0.17156396806240082
[5/12] Train loss=0.14913004636764526
[10/12] Train loss=0.14045023918151855
Test set avg_accuracy=88.19% avg_sensitivity=70.46%, avg_specificity=94.53% avg_auc=0.9268
Best model saved!!!!
Fold[1] Epoch: 16 [16/300 (5%)] Train loss=0.166768 Test loss=0.343536

[0/12] Train loss=0.1420581191778183
[5/12] Train loss=0.15908017754554749
[10/12] Train loss=0.14302761852741241
Test set avg_accuracy=88.13% avg_sensitivity=81.99%, avg_specificity=90.33% avg_auc=0.9291
Best model saved!!!!
Fold[1] Epoch: 17 [17/300 (6%)] Train loss=0.143813 Test loss=0.363638

[0/12] Train loss=0.14031115174293518
[5/12] Train loss=0.12520702183246613
[10/12] Train loss=0.09776193648576736
Test set avg_accuracy=87.95% avg_sensitivity=82.70%, avg_specificity=89.82% avg_auc=0.9316
Best model saved!!!!
Fold[1] Epoch: 18 [18/300 (6%)] Train loss=0.127668 Test loss=0.390926

[0/12] Train loss=0.14621874690055847
[5/12] Train loss=0.10058243572711945
[10/12] Train loss=0.10395503044128418
Test set avg_accuracy=87.80% avg_sensitivity=72.64%, avg_specificity=93.22% avg_auc=0.9168
Fold[1] Epoch: 19 [19/300 (6%)] Train loss=0.115930 Test loss=0.370944

[0/12] Train loss=0.10248848795890808
[5/12] Train loss=0.09915931522846222
[10/12] Train loss=0.08113566040992737
Test set avg_accuracy=86.73% avg_sensitivity=59.24%, avg_specificity=96.57% avg_auc=0.9104
Fold[1] Epoch: 20 [20/300 (7%)] Train loss=0.098103 Test loss=0.450948

[0/12] Train loss=0.08741391450166702
[5/12] Train loss=0.08712592720985413
[10/12] Train loss=0.07165144383907318
Test set avg_accuracy=87.26% avg_sensitivity=71.09%, avg_specificity=93.05% avg_auc=0.9265
Fold[1] Epoch: 21 [21/300 (7%)] Train loss=0.086234 Test loss=0.404637

[0/12] Train loss=0.0757923275232315
[5/12] Train loss=0.06728781759738922
[10/12] Train loss=0.0538448691368103
Test set avg_accuracy=87.47% avg_sensitivity=70.89%, avg_specificity=93.41% avg_auc=0.9205
Fold[1] Epoch: 22 [22/300 (7%)] Train loss=0.070599 Test loss=0.437517

[0/12] Train loss=0.05997209623456001
[5/12] Train loss=0.053238797932863235
[10/12] Train loss=0.043772198259830475
Test set avg_accuracy=87.36% avg_sensitivity=74.31%, avg_specificity=92.03% avg_auc=0.9207
Fold[1] Epoch: 23 [23/300 (8%)] Train loss=0.057624 Test loss=0.444506

[0/12] Train loss=0.051497932523489
[5/12] Train loss=0.051031652837991714
[10/12] Train loss=0.03562307357788086
Test set avg_accuracy=87.23% avg_sensitivity=73.00%, avg_specificity=92.33% avg_auc=0.9201
Fold[1] Epoch: 24 [24/300 (8%)] Train loss=0.046524 Test loss=0.473892

[0/12] Train loss=0.04167412593960762
[5/12] Train loss=0.034279122948646545
[10/12] Train loss=0.026037218049168587
Test set avg_accuracy=87.31% avg_sensitivity=68.23%, avg_specificity=94.14% avg_auc=0.9164
Fold[1] Epoch: 25 [25/300 (8%)] Train loss=0.036846 Test loss=0.505154

[0/12] Train loss=0.03389719873666763
[5/12] Train loss=0.03144155070185661
[10/12] Train loss=0.028867511078715324
Test set avg_accuracy=87.82% avg_sensitivity=71.53%, avg_specificity=93.65% avg_auc=0.9206
Fold[1] Epoch: 26 [26/300 (9%)] Train loss=0.032898 Test loss=0.516521

[0/12] Train loss=0.02903980202972889
[5/12] Train loss=0.031284675002098083
[10/12] Train loss=0.02193577028810978
Test set avg_accuracy=87.52% avg_sensitivity=74.91%, avg_specificity=92.03% avg_auc=0.9225
Fold[1] Epoch: 27 [27/300 (9%)] Train loss=0.029616 Test loss=0.509377

[0/12] Train loss=0.025738462805747986
[5/12] Train loss=0.024937620386481285
[10/12] Train loss=0.020464353263378143
Test set avg_accuracy=87.31% avg_sensitivity=72.84%, avg_specificity=92.48% avg_auc=0.9194
Fold[1] Epoch: 28 [28/300 (9%)] Train loss=0.025939 Test loss=0.527644

Early Stopping!!! Best loss=0.3057112991809845
Fold[1] Best Result: acc=87.9454926624738 sen=82.7037773359841, spe=89.8220640569395, auc=0.9315747366335795!
[0/12] Train loss=0.700401246547699
[5/12] Train loss=0.6279436945915222
[10/12] Train loss=0.5447534322738647
Test set avg_accuracy=78.06% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6761
Best model saved!!!!
Fold[2] Epoch: 1 [1/300 (0%)] Train loss=0.845941 Test loss=0.501452

[0/12] Train loss=0.5005635023117065
[5/12] Train loss=0.40137165784835815
[10/12] Train loss=0.3966684639453888
Test set avg_accuracy=79.48% avg_sensitivity=8.64%, avg_specificity=99.39% avg_auc=0.8211
Best model saved!!!!
Fold[2] Epoch: 2 [2/300 (1%)] Train loss=0.437028 Test loss=0.429123

[0/12] Train loss=0.37916553020477295
[5/12] Train loss=0.36642488837242126
[10/12] Train loss=0.336152046918869
Test set avg_accuracy=82.81% avg_sensitivity=31.64%, avg_specificity=97.19% avg_auc=0.8647
Best model saved!!!!
Fold[2] Epoch: 3 [3/300 (1%)] Train loss=0.371584 Test loss=0.374756

[0/12] Train loss=0.3383064270019531
[5/12] Train loss=0.33342310786247253
[10/12] Train loss=0.30314087867736816
Test set avg_accuracy=85.16% avg_sensitivity=48.78%, avg_specificity=95.39% avg_auc=0.8876
Best model saved!!!!
Fold[2] Epoch: 4 [4/300 (1%)] Train loss=0.334906 Test loss=0.342544

[0/12] Train loss=0.3043299913406372
[5/12] Train loss=0.2961125373840332
[10/12] Train loss=0.2661736011505127
Test set avg_accuracy=86.98% avg_sensitivity=58.86%, avg_specificity=94.89% avg_auc=0.9020
Best model saved!!!!
Fold[2] Epoch: 5 [5/300 (2%)] Train loss=0.304912 Test loss=0.322382

[0/12] Train loss=0.28231626749038696
[5/12] Train loss=0.2736155390739441
[10/12] Train loss=0.247457355260849
Test set avg_accuracy=87.34% avg_sensitivity=57.37%, avg_specificity=95.76% avg_auc=0.9060
Best model saved!!!!
Fold[2] Epoch: 6 [6/300 (2%)] Train loss=0.282506 Test loss=0.317206

[0/12] Train loss=0.2553195655345917
[5/12] Train loss=0.24686560034751892
[10/12] Train loss=0.2348816990852356
Test set avg_accuracy=88.14% avg_sensitivity=58.57%, avg_specificity=96.45% avg_auc=0.9124
Best model saved!!!!
Fold[2] Epoch: 7 [7/300 (2%)] Train loss=0.263486 Test loss=0.300685

[0/12] Train loss=0.2415621429681778
[5/12] Train loss=0.24569366872310638
[10/12] Train loss=0.20786136388778687
Test set avg_accuracy=88.54% avg_sensitivity=65.63%, avg_specificity=94.98% avg_auc=0.9160
Best model saved!!!!
Fold[2] Epoch: 8 [8/300 (3%)] Train loss=0.246821 Test loss=0.297548

[0/12] Train loss=0.23307634890079498
[5/12] Train loss=0.22044537961483002
[10/12] Train loss=0.21562175452709198
Test set avg_accuracy=88.18% avg_sensitivity=65.15%, avg_specificity=94.66% avg_auc=0.9129
Fold[2] Epoch: 9 [9/300 (3%)] Train loss=0.231250 Test loss=0.322234

[0/12] Train loss=0.22091124951839447
[5/12] Train loss=0.22292663156986237
[10/12] Train loss=0.19083786010742188
Test set avg_accuracy=86.00% avg_sensitivity=54.58%, avg_specificity=94.83% avg_auc=0.8964
Fold[2] Epoch: 10 [10/300 (3%)] Train loss=0.217990 Test loss=0.392627

[0/12] Train loss=0.22299827635288239
[5/12] Train loss=0.20100803673267365
[10/12] Train loss=0.17807580530643463
Test set avg_accuracy=87.40% avg_sensitivity=58.09%, avg_specificity=95.64% avg_auc=0.9112
Fold[2] Epoch: 11 [11/300 (4%)] Train loss=0.217058 Test loss=0.352627

[0/12] Train loss=0.1966535598039627
[5/12] Train loss=0.2341366410255432
[10/12] Train loss=0.17579838633537292
Test set avg_accuracy=87.64% avg_sensitivity=63.42%, avg_specificity=94.44% avg_auc=0.9184
Fold[2] Epoch: 12 [12/300 (4%)] Train loss=0.211258 Test loss=0.314497

[0/12] Train loss=0.1958099901676178
[5/12] Train loss=0.18901900947093964
[10/12] Train loss=0.19094331562519073
Test set avg_accuracy=86.78% avg_sensitivity=51.37%, avg_specificity=96.74% avg_auc=0.8909
Fold[2] Epoch: 13 [13/300 (4%)] Train loss=0.198274 Test loss=0.417057

[0/12] Train loss=0.20348547399044037
[5/12] Train loss=0.2134234458208084
[10/12] Train loss=0.16923770308494568
Test set avg_accuracy=87.97% avg_sensitivity=56.02%, avg_specificity=96.95% avg_auc=0.9049
Fold[2] Epoch: 14 [14/300 (5%)] Train loss=0.212815 Test loss=0.341359

[0/12] Train loss=0.2361292839050293
[5/12] Train loss=0.2343151867389679
[10/12] Train loss=0.16888467967510223
Test set avg_accuracy=84.57% avg_sensitivity=34.09%, avg_specificity=98.76% avg_auc=0.8856
Fold[2] Epoch: 15 [15/300 (5%)] Train loss=0.215764 Test loss=0.535512

[0/12] Train loss=0.26652073860168457
[5/12] Train loss=0.18577110767364502
[10/12] Train loss=0.19337622821331024
Test set avg_accuracy=86.94% avg_sensitivity=55.16%, avg_specificity=95.87% avg_auc=0.9018
Fold[2] Epoch: 16 [16/300 (5%)] Train loss=0.215060 Test loss=0.365180

[0/12] Train loss=0.22644001245498657
[5/12] Train loss=0.20379547774791718
[10/12] Train loss=0.1610173135995865
Test set avg_accuracy=87.72% avg_sensitivity=59.24%, avg_specificity=95.72% avg_auc=0.9064
Fold[2] Epoch: 17 [17/300 (6%)] Train loss=0.205528 Test loss=0.388496

[0/12] Train loss=0.17116495966911316
[5/12] Train loss=0.1572468876838684
[10/12] Train loss=0.1471155285835266
Test set avg_accuracy=87.70% avg_sensitivity=55.21%, avg_specificity=96.83% avg_auc=0.9068
Fold[2] Epoch: 18 [18/300 (6%)] Train loss=0.176903 Test loss=0.375699

[0/12] Train loss=0.15662799775600433
[5/12] Train loss=0.136665478348732
[10/12] Train loss=0.14512278139591217
Test set avg_accuracy=88.31% avg_sensitivity=63.66%, avg_specificity=95.24% avg_auc=0.9036
Fold[2] Epoch: 19 [19/300 (6%)] Train loss=0.159682 Test loss=0.373279

[0/12] Train loss=0.15408073365688324
[5/12] Train loss=0.14394313097000122
[10/12] Train loss=0.13651421666145325
Test set avg_accuracy=86.52% avg_sensitivity=70.96%, avg_specificity=90.89% avg_auc=0.9148
Fold[2] Epoch: 20 [20/300 (7%)] Train loss=0.142742 Test loss=0.405567

[0/12] Train loss=0.17031368613243103
[5/12] Train loss=0.13222551345825195
[10/12] Train loss=0.09370369464159012
Test set avg_accuracy=87.47% avg_sensitivity=68.07%, avg_specificity=92.92% avg_auc=0.9113
Fold[2] Epoch: 21 [21/300 (7%)] Train loss=0.127506 Test loss=0.410988

[0/12] Train loss=0.12266938388347626
[5/12] Train loss=0.11213064938783646
[10/12] Train loss=0.10437309741973877
Test set avg_accuracy=88.21% avg_sensitivity=56.89%, avg_specificity=97.02% avg_auc=0.9054
Fold[2] Epoch: 22 [22/300 (7%)] Train loss=0.115022 Test loss=0.414209

[0/12] Train loss=0.11196605861186981
[5/12] Train loss=0.10360598564147949
[10/12] Train loss=0.08058560639619827
Test set avg_accuracy=87.26% avg_sensitivity=57.03%, avg_specificity=95.75% avg_auc=0.9066
Fold[2] Epoch: 23 [23/300 (8%)] Train loss=0.100377 Test loss=0.453483

[0/12] Train loss=0.10665950924158096
[5/12] Train loss=0.09534353762865067
[10/12] Train loss=0.08399543911218643
Test set avg_accuracy=86.74% avg_sensitivity=66.97%, avg_specificity=92.30% avg_auc=0.9132
Fold[2] Epoch: 24 [24/300 (8%)] Train loss=0.099604 Test loss=0.442558

[0/12] Train loss=0.09135695546865463
[5/12] Train loss=0.08861570060253143
[10/12] Train loss=0.07211805135011673
Test set avg_accuracy=87.41% avg_sensitivity=67.83%, avg_specificity=92.92% avg_auc=0.9069
Fold[2] Epoch: 25 [25/300 (8%)] Train loss=0.090464 Test loss=0.407644

[0/12] Train loss=0.09882445633411407
[5/12] Train loss=0.08235658705234528
[10/12] Train loss=0.059085406363010406
Test set avg_accuracy=87.06% avg_sensitivity=69.95%, avg_specificity=91.86% avg_auc=0.9157
Fold[2] Epoch: 26 [26/300 (9%)] Train loss=0.079967 Test loss=0.465348

[0/12] Train loss=0.06894434988498688
[5/12] Train loss=0.06262080371379852
[10/12] Train loss=0.05104793980717659
Test set avg_accuracy=87.31% avg_sensitivity=64.14%, avg_specificity=93.82% avg_auc=0.9024
Fold[2] Epoch: 27 [27/300 (9%)] Train loss=0.062833 Test loss=0.566261

[0/12] Train loss=0.06199463829398155
[5/12] Train loss=0.051748380064964294
[10/12] Train loss=0.04776403307914734
Test set avg_accuracy=87.96% avg_sensitivity=59.67%, avg_specificity=95.91% avg_auc=0.9013
Fold[2] Epoch: 28 [28/300 (9%)] Train loss=0.055831 Test loss=0.480463

Early Stopping!!! Best loss=0.29754823446273804
Fold[2] Best Result: acc=88.54133754607687 sen=65.62650024003841, spe=94.98111171073934, auc=0.9160304072828663!
[0/12] Train loss=0.7024278044700623
[5/12] Train loss=0.5960774421691895
[10/12] Train loss=0.44785991311073303
Test set avg_accuracy=69.26% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7604
Best model saved!!!!
Fold[3] Epoch: 1 [1/300 (0%)] Train loss=0.690864 Test loss=0.828148

[0/12] Train loss=0.40771496295928955
[5/12] Train loss=0.4038007855415344
[10/12] Train loss=0.38811495900154114
Test set avg_accuracy=69.26% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.8221
Best model saved!!!!
Fold[3] Epoch: 2 [2/300 (1%)] Train loss=0.399955 Test loss=0.781910

[0/12] Train loss=0.3541323244571686
[5/12] Train loss=0.3699842691421509
[10/12] Train loss=0.3135750889778137
Test set avg_accuracy=73.45% avg_sensitivity=16.64%, avg_specificity=98.66% avg_auc=0.8486
Best model saved!!!!
Fold[3] Epoch: 3 [3/300 (1%)] Train loss=0.355265 Test loss=0.522712

[0/12] Train loss=0.30842798948287964
[5/12] Train loss=0.3146553635597229
[10/12] Train loss=0.2594680190086365
Test set avg_accuracy=77.07% avg_sensitivity=30.66%, avg_specificity=97.67% avg_auc=0.8690
Best model saved!!!!
Fold[3] Epoch: 4 [4/300 (1%)] Train loss=0.306155 Test loss=0.517846

[0/12] Train loss=0.2696569263935089
[5/12] Train loss=0.27696913480758667
[10/12] Train loss=0.25004255771636963
Test set avg_accuracy=79.42% avg_sensitivity=44.01%, avg_specificity=95.13% avg_auc=0.8837
Best model saved!!!!
Fold[3] Epoch: 5 [5/300 (2%)] Train loss=0.279248 Test loss=0.472421

[0/12] Train loss=0.253280371427536
[5/12] Train loss=0.27665939927101135
[10/12] Train loss=0.2288428544998169
Test set avg_accuracy=82.04% avg_sensitivity=56.97%, avg_specificity=93.16% avg_auc=0.8973
Best model saved!!!!
Fold[3] Epoch: 6 [6/300 (2%)] Train loss=0.266331 Test loss=0.398886

[0/12] Train loss=0.2509264647960663
[5/12] Train loss=0.24142685532569885
[10/12] Train loss=0.21638721227645874
Test set avg_accuracy=82.46% avg_sensitivity=55.82%, avg_specificity=94.28% avg_auc=0.9043
Best model saved!!!!
Fold[3] Epoch: 7 [7/300 (2%)] Train loss=0.245482 Test loss=0.409328

[0/12] Train loss=0.21761174499988556
[5/12] Train loss=0.22618602216243744
[10/12] Train loss=0.19696243107318878
Test set avg_accuracy=80.85% avg_sensitivity=43.34%, avg_specificity=97.50% avg_auc=0.9025
Fold[3] Epoch: 8 [8/300 (3%)] Train loss=0.223313 Test loss=0.466479

[0/12] Train loss=0.22187906503677368
[5/12] Train loss=0.2008036971092224
[10/12] Train loss=0.195611372590065
Test set avg_accuracy=82.85% avg_sensitivity=52.24%, avg_specificity=96.44% avg_auc=0.9037
Fold[3] Epoch: 9 [9/300 (3%)] Train loss=0.212245 Test loss=0.436976

[0/12] Train loss=0.1988561600446701
[5/12] Train loss=0.24154618382453918
[10/12] Train loss=0.1724993884563446
Test set avg_accuracy=83.91% avg_sensitivity=69.17%, avg_specificity=90.45% avg_auc=0.9133
Best model saved!!!!
Fold[3] Epoch: 10 [10/300 (3%)] Train loss=0.209414 Test loss=0.363500

[0/12] Train loss=0.21196599304676056
[5/12] Train loss=0.1905667781829834
[10/12] Train loss=0.17255431413650513
Test set avg_accuracy=81.95% avg_sensitivity=51.58%, avg_specificity=95.43% avg_auc=0.9004
Fold[3] Epoch: 11 [11/300 (4%)] Train loss=0.193939 Test loss=0.469458

[0/12] Train loss=0.17123417556285858
[5/12] Train loss=0.1757643222808838
[10/12] Train loss=0.14853282272815704
Test set avg_accuracy=82.61% avg_sensitivity=60.55%, avg_specificity=92.40% avg_auc=0.9047
Fold[3] Epoch: 12 [12/300 (4%)] Train loss=0.169885 Test loss=0.419117

[0/12] Train loss=0.15486973524093628
[5/12] Train loss=0.14787963032722473
[10/12] Train loss=0.14132116734981537
Test set avg_accuracy=82.95% avg_sensitivity=55.15%, avg_specificity=95.29% avg_auc=0.8987
Fold[3] Epoch: 13 [13/300 (4%)] Train loss=0.149733 Test loss=0.481203

[0/12] Train loss=0.14808009564876556
[5/12] Train loss=0.1392507404088974
[10/12] Train loss=0.11362747848033905
Test set avg_accuracy=82.66% avg_sensitivity=54.27%, avg_specificity=95.26% avg_auc=0.8902
Fold[3] Epoch: 14 [14/300 (5%)] Train loss=0.135398 Test loss=0.497862

[0/12] Train loss=0.137289896607399
[5/12] Train loss=0.12948104739189148
[10/12] Train loss=0.11112886667251587
Test set avg_accuracy=83.63% avg_sensitivity=66.29%, avg_specificity=91.32% avg_auc=0.8975
Fold[3] Epoch: 15 [15/300 (5%)] Train loss=0.126118 Test loss=0.489729

[0/12] Train loss=0.12816761434078217
[5/12] Train loss=0.11538391560316086
[10/12] Train loss=0.135230153799057
Test set avg_accuracy=82.38% avg_sensitivity=57.71%, avg_specificity=93.33% avg_auc=0.8958
Fold[3] Epoch: 16 [16/300 (5%)] Train loss=0.119475 Test loss=0.505669

[0/12] Train loss=0.11448951810598373
[5/12] Train loss=0.11099083721637726
[10/12] Train loss=0.10064594447612762
Test set avg_accuracy=83.41% avg_sensitivity=60.37%, avg_specificity=93.64% avg_auc=0.8969
Fold[3] Epoch: 17 [17/300 (6%)] Train loss=0.112040 Test loss=0.491896

[0/12] Train loss=0.10917056351900101
[5/12] Train loss=0.09710317850112915
[10/12] Train loss=0.08471964299678802
Test set avg_accuracy=81.07% avg_sensitivity=45.90%, avg_specificity=96.67% avg_auc=0.8796
Fold[3] Epoch: 18 [18/300 (6%)] Train loss=0.102015 Test loss=0.645141

[0/12] Train loss=0.11760261654853821
[5/12] Train loss=0.09548765420913696
[10/12] Train loss=0.08728108555078506
Test set avg_accuracy=80.37% avg_sensitivity=40.64%, avg_specificity=97.99% avg_auc=0.8695
Fold[3] Epoch: 19 [19/300 (6%)] Train loss=0.097384 Test loss=0.729776

[0/12] Train loss=0.10702929645776749
[5/12] Train loss=0.09361612051725388
[10/12] Train loss=0.08923357725143433
Test set avg_accuracy=82.23% avg_sensitivity=53.29%, avg_specificity=95.07% avg_auc=0.8848
Fold[3] Epoch: 20 [20/300 (7%)] Train loss=0.099461 Test loss=0.580231

[0/12] Train loss=0.10299497097730637
[5/12] Train loss=0.09307946264743805
[10/12] Train loss=0.08784856647253036
Test set avg_accuracy=81.62% avg_sensitivity=53.96%, avg_specificity=93.89% avg_auc=0.8909
Fold[3] Epoch: 21 [21/300 (7%)] Train loss=0.092898 Test loss=0.633735

[0/12] Train loss=0.10600273311138153
[5/12] Train loss=0.07534246146678925
[10/12] Train loss=0.08328540623188019
Test set avg_accuracy=81.80% avg_sensitivity=51.61%, avg_specificity=95.20% avg_auc=0.8978
Fold[3] Epoch: 22 [22/300 (7%)] Train loss=0.089622 Test loss=0.693840

[0/12] Train loss=0.09502001106739044
[5/12] Train loss=0.10056895762681961
[10/12] Train loss=0.0757012739777565
Test set avg_accuracy=81.40% avg_sensitivity=48.67%, avg_specificity=95.93% avg_auc=0.8907
Fold[3] Epoch: 23 [23/300 (8%)] Train loss=0.084790 Test loss=0.719769

[0/12] Train loss=0.09377973526716232
[5/12] Train loss=0.07065800577402115
[10/12] Train loss=0.06855596601963043
Test set avg_accuracy=80.00% avg_sensitivity=42.40%, avg_specificity=96.69% avg_auc=0.8789
Fold[3] Epoch: 24 [24/300 (8%)] Train loss=0.077057 Test loss=0.781961

[0/12] Train loss=0.09896919131278992
[5/12] Train loss=0.06248616799712181
[10/12] Train loss=0.05833815038204193
Test set avg_accuracy=82.78% avg_sensitivity=55.26%, avg_specificity=94.99% avg_auc=0.8901
Fold[3] Epoch: 25 [25/300 (8%)] Train loss=0.070375 Test loss=0.703931

[0/12] Train loss=0.0853460356593132
[5/12] Train loss=0.06242269277572632
[10/12] Train loss=0.05325641110539436
Test set avg_accuracy=82.30% avg_sensitivity=55.50%, avg_specificity=94.20% avg_auc=0.8932
Fold[3] Epoch: 26 [26/300 (9%)] Train loss=0.067848 Test loss=0.761461

[0/12] Train loss=0.07112357765436172
[5/12] Train loss=0.05819658562541008
[10/12] Train loss=0.08890999853610992
Test set avg_accuracy=83.02% avg_sensitivity=57.88%, avg_specificity=94.17% avg_auc=0.8896
Fold[3] Epoch: 27 [27/300 (9%)] Train loss=0.070963 Test loss=0.620983

[0/12] Train loss=0.07919800281524658
[5/12] Train loss=0.07545019686222076
[10/12] Train loss=0.07468263804912567
Test set avg_accuracy=83.22% avg_sensitivity=70.15%, avg_specificity=89.02% avg_auc=0.9038
Fold[3] Epoch: 28 [28/300 (9%)] Train loss=0.071092 Test loss=0.559482

[0/12] Train loss=0.09400314837694168
[5/12] Train loss=0.07758092880249023
[10/12] Train loss=0.06757456064224243
Test set avg_accuracy=83.70% avg_sensitivity=68.64%, avg_specificity=90.39% avg_auc=0.9008
Fold[3] Epoch: 29 [29/300 (10%)] Train loss=0.074944 Test loss=0.629858

[0/12] Train loss=0.11142754554748535
[5/12] Train loss=0.07750667631626129
[10/12] Train loss=0.055038969963788986
Test set avg_accuracy=83.88% avg_sensitivity=69.31%, avg_specificity=90.34% avg_auc=0.9009
Fold[3] Epoch: 30 [30/300 (10%)] Train loss=0.078402 Test loss=0.617321

Early Stopping!!! Best loss=0.3634999394416809
Fold[3] Best Result: acc=83.90953150242326 sen=69.16608269096005, spe=90.45249572383766, auc=0.9132804793093893!
[0/12] Train loss=0.7076419591903687
[5/12] Train loss=0.6693409085273743
[10/12] Train loss=0.4744342863559723
Test set avg_accuracy=73.42% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7481
Best model saved!!!!
Fold[4] Epoch: 1 [1/300 (0%)] Train loss=0.706561 Test loss=0.662832

[0/12] Train loss=0.42159146070480347
[5/12] Train loss=0.394083172082901
[10/12] Train loss=0.38487985730171204
Test set avg_accuracy=73.81% avg_sensitivity=1.54%, avg_specificity=99.97% avg_auc=0.8493
Best model saved!!!!
Fold[4] Epoch: 2 [2/300 (1%)] Train loss=0.403551 Test loss=0.691620

[0/12] Train loss=0.36164119839668274
[5/12] Train loss=0.39167484641075134
[10/12] Train loss=0.32253673672676086
Test set avg_accuracy=80.46% avg_sensitivity=37.11%, avg_specificity=96.16% avg_auc=0.8700
Best model saved!!!!
Fold[4] Epoch: 3 [3/300 (1%)] Train loss=0.359102 Test loss=0.454327

[0/12] Train loss=0.31621894240379333
[5/12] Train loss=0.3052746653556824
[10/12] Train loss=0.27174943685531616
Test set avg_accuracy=81.83% avg_sensitivity=41.56%, avg_specificity=96.42% avg_auc=0.8874
Best model saved!!!!
Fold[4] Epoch: 4 [4/300 (1%)] Train loss=0.308235 Test loss=0.412997

[0/12] Train loss=0.2719873785972595
[5/12] Train loss=0.2725459039211273
[10/12] Train loss=0.23444797098636627
Test set avg_accuracy=83.56% avg_sensitivity=51.03%, avg_specificity=95.35% avg_auc=0.8953
Best model saved!!!!
Fold[4] Epoch: 5 [5/300 (2%)] Train loss=0.270611 Test loss=0.408323

[0/12] Train loss=0.2435532808303833
[5/12] Train loss=0.2379150390625
[10/12] Train loss=0.21063901484012604
Test set avg_accuracy=83.38% avg_sensitivity=48.54%, avg_specificity=95.99% avg_auc=0.8980
Fold[4] Epoch: 6 [6/300 (2%)] Train loss=0.243027 Test loss=0.430690

[0/12] Train loss=0.2317778766155243
[5/12] Train loss=0.21860371530056
[10/12] Train loss=0.19514963030815125
Test set avg_accuracy=84.33% avg_sensitivity=66.80%, avg_specificity=90.68% avg_auc=0.8999
Best model saved!!!!
Fold[4] Epoch: 7 [7/300 (2%)] Train loss=0.226711 Test loss=0.404794

[0/12] Train loss=0.2261396050453186
[5/12] Train loss=0.20767797529697418
[10/12] Train loss=0.21821922063827515
Test set avg_accuracy=83.70% avg_sensitivity=46.18%, avg_specificity=97.29% avg_auc=0.9036
Fold[4] Epoch: 8 [8/300 (3%)] Train loss=0.222461 Test loss=0.457432

[0/12] Train loss=0.1918407380580902
[5/12] Train loss=0.21800750494003296
[10/12] Train loss=0.17365778982639313
Test set avg_accuracy=85.69% avg_sensitivity=64.08%, avg_specificity=93.52% avg_auc=0.9066
Best model saved!!!!
Fold[4] Epoch: 9 [9/300 (3%)] Train loss=0.206389 Test loss=0.384649

[0/12] Train loss=0.18858905136585236
[5/12] Train loss=0.1782895177602768
[10/12] Train loss=0.151942640542984
Test set avg_accuracy=85.71% avg_sensitivity=64.43%, avg_specificity=93.42% avg_auc=0.9070
Best model saved!!!!
Fold[4] Epoch: 10 [10/300 (3%)] Train loss=0.185090 Test loss=0.385481

[0/12] Train loss=0.17251306772232056
[5/12] Train loss=0.15041163563728333
[10/12] Train loss=0.14309604465961456
Test set avg_accuracy=85.43% avg_sensitivity=58.24%, avg_specificity=95.27% avg_auc=0.9020
Fold[4] Epoch: 11 [11/300 (4%)] Train loss=0.165888 Test loss=0.428639

[0/12] Train loss=0.14831982553005219
[5/12] Train loss=0.14574982225894928
[10/12] Train loss=0.13742445409297943
Test set avg_accuracy=85.77% avg_sensitivity=64.04%, avg_specificity=93.63% avg_auc=0.9032
Fold[4] Epoch: 12 [12/300 (4%)] Train loss=0.147564 Test loss=0.424872

[0/12] Train loss=0.13788340985774994
[5/12] Train loss=0.1274898201227188
[10/12] Train loss=0.13231326639652252
Test set avg_accuracy=85.24% avg_sensitivity=60.29%, avg_specificity=94.27% avg_auc=0.8936
Fold[4] Epoch: 13 [13/300 (4%)] Train loss=0.135573 Test loss=0.486707

[0/12] Train loss=0.1505143791437149
[5/12] Train loss=0.12548449635505676
[10/12] Train loss=0.11689452826976776
Test set avg_accuracy=84.35% avg_sensitivity=60.57%, avg_specificity=92.96% avg_auc=0.9016
Fold[4] Epoch: 14 [14/300 (5%)] Train loss=0.133490 Test loss=0.506282

[0/12] Train loss=0.13725392520427704
[5/12] Train loss=0.14537982642650604
[10/12] Train loss=0.11500120162963867
Test set avg_accuracy=85.37% avg_sensitivity=61.99%, avg_specificity=93.83% avg_auc=0.9051
Fold[4] Epoch: 15 [15/300 (5%)] Train loss=0.130488 Test loss=0.527153

[0/12] Train loss=0.12403099983930588
[5/12] Train loss=0.11986009776592255
[10/12] Train loss=0.11282339692115784
Test set avg_accuracy=86.23% avg_sensitivity=67.31%, avg_specificity=93.08% avg_auc=0.9067
Best model saved!!!!
Fold[4] Epoch: 16 [16/300 (5%)] Train loss=0.125622 Test loss=0.468767

[0/12] Train loss=0.11967694014310837
[5/12] Train loss=0.10222972929477692
[10/12] Train loss=0.10019470751285553
Test set avg_accuracy=85.47% avg_sensitivity=54.30%, avg_specificity=96.76% avg_auc=0.8988
Fold[4] Epoch: 17 [17/300 (6%)] Train loss=0.115145 Test loss=0.513179

[0/12] Train loss=0.13915614783763885
[5/12] Train loss=0.08563965559005737
[10/12] Train loss=0.09941474348306656
Test set avg_accuracy=85.72% avg_sensitivity=62.82%, avg_specificity=94.02% avg_auc=0.9031
Fold[4] Epoch: 18 [18/300 (6%)] Train loss=0.102754 Test loss=0.522638

[0/12] Train loss=0.09777437150478363
[5/12] Train loss=0.08061832189559937
[10/12] Train loss=0.08456465601921082
Test set avg_accuracy=85.08% avg_sensitivity=70.23%, avg_specificity=90.46% avg_auc=0.9043
Fold[4] Epoch: 19 [19/300 (6%)] Train loss=0.091162 Test loss=0.588590

[0/12] Train loss=0.10225969552993774
[5/12] Train loss=0.08122421056032181
[10/12] Train loss=0.0944305881857872
Test set avg_accuracy=86.02% avg_sensitivity=70.94%, avg_specificity=91.48% avg_auc=0.9074
Best model saved!!!!
Fold[4] Epoch: 20 [20/300 (7%)] Train loss=0.092223 Test loss=0.548272

[0/12] Train loss=0.10973244905471802
[5/12] Train loss=0.0859052762389183
[10/12] Train loss=0.06598294526338577
Test set avg_accuracy=84.81% avg_sensitivity=71.02%, avg_specificity=89.81% avg_auc=0.9034
Fold[4] Epoch: 21 [21/300 (7%)] Train loss=0.085286 Test loss=0.570389

[0/12] Train loss=0.07727663218975067
[5/12] Train loss=0.09723227471113205
[10/12] Train loss=0.06334597617387772
Test set avg_accuracy=83.78% avg_sensitivity=74.33%, avg_specificity=87.21% avg_auc=0.8924
Fold[4] Epoch: 22 [22/300 (7%)] Train loss=0.080184 Test loss=0.681188

[0/12] Train loss=0.10473943501710892
[5/12] Train loss=0.08674533665180206
[10/12] Train loss=0.07866587489843369
Test set avg_accuracy=84.84% avg_sensitivity=74.49%, avg_specificity=88.59% avg_auc=0.8888
Fold[4] Epoch: 23 [23/300 (8%)] Train loss=0.098331 Test loss=0.614601

[0/12] Train loss=0.10109041631221771
[5/12] Train loss=0.08039271831512451
[10/12] Train loss=0.07770506292581558
Test set avg_accuracy=86.05% avg_sensitivity=64.87%, avg_specificity=93.72% avg_auc=0.8982
Fold[4] Epoch: 24 [24/300 (8%)] Train loss=0.099467 Test loss=0.540261

[0/12] Train loss=0.08925379067659378
[5/12] Train loss=0.08016666769981384
[10/12] Train loss=0.07881511002779007
Test set avg_accuracy=84.68% avg_sensitivity=55.32%, avg_specificity=95.30% avg_auc=0.8941
Fold[4] Epoch: 25 [25/300 (8%)] Train loss=0.082352 Test loss=0.614074

[0/12] Train loss=0.07698031514883041
[5/12] Train loss=0.07443562150001526
[10/12] Train loss=0.053246352821588516
Test set avg_accuracy=84.34% avg_sensitivity=59.50%, avg_specificity=93.33% avg_auc=0.8984
Fold[4] Epoch: 26 [26/300 (9%)] Train loss=0.068916 Test loss=0.630640

[0/12] Train loss=0.08865239471197128
[5/12] Train loss=0.059773366898298264
[10/12] Train loss=0.040625035762786865
Test set avg_accuracy=85.02% avg_sensitivity=60.45%, avg_specificity=93.92% avg_auc=0.9013
Fold[4] Epoch: 27 [27/300 (9%)] Train loss=0.062185 Test loss=0.657908

[0/12] Train loss=0.05144263058900833
[5/12] Train loss=0.044728152453899384
[10/12] Train loss=0.038406264036893845
Test set avg_accuracy=85.53% avg_sensitivity=64.51%, avg_specificity=93.15% avg_auc=0.8985
Fold[4] Epoch: 28 [28/300 (9%)] Train loss=0.048826 Test loss=0.664592

[0/12] Train loss=0.04772389307618141
[5/12] Train loss=0.038029611110687256
[10/12] Train loss=0.02812345325946808
Test set avg_accuracy=85.04% avg_sensitivity=66.88%, avg_specificity=91.62% avg_auc=0.9013
Fold[4] Epoch: 29 [29/300 (10%)] Train loss=0.037805 Test loss=0.682927

Early Stopping!!! Best loss=0.3846488893032074
Fold[4] Best Result: acc=86.0167714884696 sen=70.9384858044164, spe=91.4762992575671, auc=0.9073875597450398!
[0/12] Train loss=0.7080318927764893
[5/12] Train loss=0.5985067486763
[10/12] Train loss=0.4267755150794983
Test set avg_accuracy=76.20% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.8080
Best model saved!!!!
Fold[5] Epoch: 1 [1/300 (0%)] Train loss=0.680886 Test loss=0.645722

[0/12] Train loss=0.3993244469165802
[5/12] Train loss=0.4072721302509308
[10/12] Train loss=0.3619990348815918
Test set avg_accuracy=83.29% avg_sensitivity=36.48%, avg_specificity=97.91% avg_auc=0.8615
Best model saved!!!!
Fold[5] Epoch: 2 [2/300 (1%)] Train loss=0.397464 Test loss=0.385582

[0/12] Train loss=0.34100478887557983
[5/12] Train loss=0.3615246117115021
[10/12] Train loss=0.3045657277107239
Test set avg_accuracy=83.39% avg_sensitivity=34.40%, avg_specificity=98.68% avg_auc=0.8859
Best model saved!!!!
Fold[5] Epoch: 3 [3/300 (1%)] Train loss=0.349632 Test loss=0.384287

[0/12] Train loss=0.3046674430370331
[5/12] Train loss=0.3216652572154999
[10/12] Train loss=0.2700963616371155
Test set avg_accuracy=86.56% avg_sensitivity=51.06%, avg_specificity=97.65% avg_auc=0.9003
Best model saved!!!!
Fold[5] Epoch: 4 [4/300 (1%)] Train loss=0.312222 Test loss=0.354946

[0/12] Train loss=0.27241769433021545
[5/12] Train loss=0.27153000235557556
[10/12] Train loss=0.2330828607082367
Test set avg_accuracy=87.43% avg_sensitivity=64.76%, avg_specificity=94.50% avg_auc=0.9142
Best model saved!!!!
Fold[5] Epoch: 5 [5/300 (2%)] Train loss=0.283500 Test loss=0.311642

[0/12] Train loss=0.24979206919670105
[5/12] Train loss=0.28214341402053833
[10/12] Train loss=0.21923308074474335
Test set avg_accuracy=88.87% avg_sensitivity=67.24%, avg_specificity=95.63% avg_auc=0.9228
Best model saved!!!!
Fold[5] Epoch: 6 [6/300 (2%)] Train loss=0.267699 Test loss=0.298568

[0/12] Train loss=0.23699329793453217
[5/12] Train loss=0.2408294826745987
[10/12] Train loss=0.20619550347328186
Test set avg_accuracy=89.15% avg_sensitivity=70.21%, avg_specificity=95.06% avg_auc=0.9272
Best model saved!!!!
Fold[5] Epoch: 7 [7/300 (2%)] Train loss=0.244856 Test loss=0.283887

[0/12] Train loss=0.2250427007675171
[5/12] Train loss=0.23330999910831451
[10/12] Train loss=0.1885712593793869
Test set avg_accuracy=89.21% avg_sensitivity=68.79%, avg_specificity=95.58% avg_auc=0.9288
Fold[5] Epoch: 8 [8/300 (3%)] Train loss=0.230560 Test loss=0.282656

[0/12] Train loss=0.2268868237733841
[5/12] Train loss=0.2572692036628723
[10/12] Train loss=0.1760055273771286
Test set avg_accuracy=87.90% avg_sensitivity=57.71%, avg_specificity=97.33% avg_auc=0.9220
Fold[5] Epoch: 9 [9/300 (3%)] Train loss=0.225007 Test loss=0.332300

[0/12] Train loss=0.19690588116645813
[5/12] Train loss=0.21551400423049927
[10/12] Train loss=0.20011836290359497
Test set avg_accuracy=83.18% avg_sensitivity=32.09%, avg_specificity=99.13% avg_auc=0.9094
Fold[5] Epoch: 10 [10/300 (3%)] Train loss=0.211839 Test loss=0.459450

[0/12] Train loss=0.20888933539390564
[5/12] Train loss=0.1880732923746109
[10/12] Train loss=0.15910090506076813
Test set avg_accuracy=85.23% avg_sensitivity=43.79%, avg_specificity=98.17% avg_auc=0.9112
Fold[5] Epoch: 11 [11/300 (4%)] Train loss=0.188545 Test loss=0.444382

[0/12] Train loss=0.1933085322380066
[5/12] Train loss=0.18667544424533844
[10/12] Train loss=0.1630239635705948
Test set avg_accuracy=86.18% avg_sensitivity=49.87%, avg_specificity=97.52% avg_auc=0.9111
Fold[5] Epoch: 12 [12/300 (4%)] Train loss=0.185979 Test loss=0.374541

[0/12] Train loss=0.22089456021785736
[5/12] Train loss=0.2014431208372116
[10/12] Train loss=0.1645200401544571
Test set avg_accuracy=85.80% avg_sensitivity=46.90%, avg_specificity=97.95% avg_auc=0.8996
Fold[5] Epoch: 13 [13/300 (4%)] Train loss=0.196356 Test loss=0.488753

[0/12] Train loss=0.1803092211484909
[5/12] Train loss=0.17889001965522766
[10/12] Train loss=0.16101820766925812
Test set avg_accuracy=87.27% avg_sensitivity=52.70%, avg_specificity=98.06% avg_auc=0.9186
Fold[5] Epoch: 14 [14/300 (5%)] Train loss=0.191110 Test loss=0.345392

[0/12] Train loss=0.19647949934005737
[5/12] Train loss=0.1823335736989975
[10/12] Train loss=0.1473819762468338
Test set avg_accuracy=87.11% avg_sensitivity=58.29%, avg_specificity=96.11% avg_auc=0.9021
Fold[5] Epoch: 15 [15/300 (5%)] Train loss=0.172594 Test loss=0.414480

[0/12] Train loss=0.16648797690868378
[5/12] Train loss=0.13622398674488068
[10/12] Train loss=0.14096301794052124
Test set avg_accuracy=88.59% avg_sensitivity=62.23%, avg_specificity=96.82% avg_auc=0.9171
Fold[5] Epoch: 16 [16/300 (5%)] Train loss=0.158339 Test loss=0.381071

[0/12] Train loss=0.1496526002883911
[5/12] Train loss=0.13937045633792877
[10/12] Train loss=0.15220604836940765
Test set avg_accuracy=88.31% avg_sensitivity=74.38%, avg_specificity=92.66% avg_auc=0.9081
Fold[5] Epoch: 17 [17/300 (6%)] Train loss=0.150558 Test loss=0.390437

[0/12] Train loss=0.14071276783943176
[5/12] Train loss=0.15463490784168243
[10/12] Train loss=0.1879149079322815
Test set avg_accuracy=86.97% avg_sensitivity=85.20%, avg_specificity=87.53% avg_auc=0.9277
Best model saved!!!!
Fold[5] Epoch: 18 [18/300 (6%)] Train loss=0.158570 Test loss=0.390541

[0/12] Train loss=0.18334056437015533
[5/12] Train loss=0.17864733934402466
[10/12] Train loss=0.1296311467885971
Test set avg_accuracy=84.44% avg_sensitivity=89.27%, avg_specificity=82.93% avg_auc=0.9177
Fold[5] Epoch: 19 [19/300 (6%)] Train loss=0.157249 Test loss=0.566060

[0/12] Train loss=0.1519271433353424
[5/12] Train loss=0.12857189774513245
[10/12] Train loss=0.12041327357292175
Test set avg_accuracy=90.20% avg_sensitivity=78.63%, avg_specificity=93.81% avg_auc=0.9220
Best model saved!!!!
Fold[5] Epoch: 20 [20/300 (7%)] Train loss=0.156516 Test loss=0.318473

[0/12] Train loss=0.1380661576986313
[5/12] Train loss=0.12026748061180115
[10/12] Train loss=0.10632850229740143
Test set avg_accuracy=89.46% avg_sensitivity=73.49%, avg_specificity=94.45% avg_auc=0.9279
Fold[5] Epoch: 21 [21/300 (7%)] Train loss=0.123327 Test loss=0.349355

[0/12] Train loss=0.10741360485553741
[5/12] Train loss=0.09797364473342896
[10/12] Train loss=0.06802434474229813
Test set avg_accuracy=90.00% avg_sensitivity=76.99%, avg_specificity=94.06% avg_auc=0.9304
Fold[5] Epoch: 22 [22/300 (7%)] Train loss=0.090072 Test loss=0.370381

[0/12] Train loss=0.08077950030565262
[5/12] Train loss=0.0701422467827797
[10/12] Train loss=0.05967240780591965
Test set avg_accuracy=89.20% avg_sensitivity=77.75%, avg_specificity=92.77% avg_auc=0.9177
Fold[5] Epoch: 23 [23/300 (8%)] Train loss=0.074313 Test loss=0.416387

[0/12] Train loss=0.07124421745538712
[5/12] Train loss=0.06469091773033142
[10/12] Train loss=0.043672095984220505
Test set avg_accuracy=89.10% avg_sensitivity=82.18%, avg_specificity=91.27% avg_auc=0.9277
Best model saved!!!!
Fold[5] Epoch: 24 [24/300 (8%)] Train loss=0.059303 Test loss=0.445713

[0/12] Train loss=0.05662129819393158
[5/12] Train loss=0.04409411922097206
[10/12] Train loss=0.036957334727048874
Test set avg_accuracy=89.39% avg_sensitivity=78.81%, avg_specificity=92.69% avg_auc=0.9235
Fold[5] Epoch: 25 [25/300 (8%)] Train loss=0.047139 Test loss=0.440151

[0/12] Train loss=0.0477215014398098
[5/12] Train loss=0.03847269341349602
[10/12] Train loss=0.031318314373493195
Test set avg_accuracy=89.75% avg_sensitivity=76.24%, avg_specificity=93.96% avg_auc=0.9236
Fold[5] Epoch: 26 [26/300 (9%)] Train loss=0.039288 Test loss=0.475626

[0/12] Train loss=0.03669368848204613
[5/12] Train loss=0.0357297882437706
[10/12] Train loss=0.026646895334124565
Test set avg_accuracy=89.41% avg_sensitivity=77.62%, avg_specificity=93.09% avg_auc=0.9216
Fold[5] Epoch: 27 [27/300 (9%)] Train loss=0.033957 Test loss=0.505125

[0/12] Train loss=0.029631735756993294
[5/12] Train loss=0.031752146780490875
[10/12] Train loss=0.022484181448817253
Test set avg_accuracy=89.35% avg_sensitivity=80.72%, avg_specificity=92.04% avg_auc=0.9245
Fold[5] Epoch: 28 [28/300 (9%)] Train loss=0.028266 Test loss=0.510443

Early Stopping!!! Best loss=0.28265634179115295
Fold[5] Best Result: acc=89.10337552742617 sen=82.18085106382979, spe=91.26522702104097, auc=0.9276641334931631!
[0/12] Train loss=0.7096104025840759
[5/12] Train loss=0.6007798910140991
[10/12] Train loss=0.46296262741088867
Test set avg_accuracy=74.88% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7293
Best model saved!!!!
Fold[6] Epoch: 1 [1/300 (0%)] Train loss=0.737076 Test loss=0.824599

[0/12] Train loss=0.3912656605243683
[5/12] Train loss=0.40478429198265076
[10/12] Train loss=0.34396520256996155
Test set avg_accuracy=81.86% avg_sensitivity=32.46%, avg_specificity=98.44% avg_auc=0.8701
Best model saved!!!!
Fold[6] Epoch: 2 [2/300 (1%)] Train loss=0.386178 Test loss=0.402048

[0/12] Train loss=0.34117409586906433
[5/12] Train loss=0.39154917001724243
[10/12] Train loss=0.30450960993766785
Test set avg_accuracy=80.35% avg_sensitivity=24.76%, avg_specificity=99.01% avg_auc=0.8785
Fold[6] Epoch: 3 [3/300 (1%)] Train loss=0.353084 Test loss=0.439867

[0/12] Train loss=0.3027779459953308
[5/12] Train loss=0.3269546329975128
[10/12] Train loss=0.2749827802181244
Test set avg_accuracy=82.33% avg_sensitivity=32.92%, avg_specificity=98.91% avg_auc=0.8980
Best model saved!!!!
Fold[6] Epoch: 4 [4/300 (1%)] Train loss=0.317146 Test loss=0.397249

[0/12] Train loss=0.27883225679397583
[5/12] Train loss=0.31958243250846863
[10/12] Train loss=0.24447223544120789
Test set avg_accuracy=85.02% avg_sensitivity=44.86%, avg_specificity=98.49% avg_auc=0.9173
Best model saved!!!!
Fold[6] Epoch: 5 [5/300 (2%)] Train loss=0.292893 Test loss=0.354893

[0/12] Train loss=0.2588728070259094
[5/12] Train loss=0.27424919605255127
[10/12] Train loss=0.23273979127407074
Test set avg_accuracy=86.15% avg_sensitivity=50.15%, avg_specificity=98.22% avg_auc=0.9236
Best model saved!!!!
Fold[6] Epoch: 6 [6/300 (2%)] Train loss=0.271340 Test loss=0.354878

[0/12] Train loss=0.24517618119716644
[5/12] Train loss=0.2590474486351013
[10/12] Train loss=0.22112014889717102
Test set avg_accuracy=89.05% avg_sensitivity=63.18%, avg_specificity=97.73% avg_auc=0.9316
Best model saved!!!!
Fold[6] Epoch: 7 [7/300 (2%)] Train loss=0.258751 Test loss=0.294772

[0/12] Train loss=0.22517898678779602
[5/12] Train loss=0.24148181080818176
[10/12] Train loss=0.20960074663162231
Test set avg_accuracy=87.57% avg_sensitivity=56.67%, avg_specificity=97.94% avg_auc=0.9256
Fold[6] Epoch: 8 [8/300 (3%)] Train loss=0.239953 Test loss=0.317258

[0/12] Train loss=0.2233634889125824
[5/12] Train loss=0.2276238650083542
[10/12] Train loss=0.1843710094690323
Test set avg_accuracy=86.26% avg_sensitivity=50.95%, avg_specificity=98.11% avg_auc=0.9229
Fold[6] Epoch: 9 [9/300 (3%)] Train loss=0.220119 Test loss=0.351114

[0/12] Train loss=0.2559012472629547
[5/12] Train loss=0.22317929565906525
[10/12] Train loss=0.17577430605888367
Test set avg_accuracy=88.70% avg_sensitivity=62.80%, avg_specificity=97.39% avg_auc=0.9305
Fold[6] Epoch: 10 [10/300 (3%)] Train loss=0.211964 Test loss=0.330539

[0/12] Train loss=0.20802782475948334
[5/12] Train loss=0.21921947598457336
[10/12] Train loss=0.17665591835975647
Test set avg_accuracy=87.28% avg_sensitivity=54.76%, avg_specificity=98.20% avg_auc=0.9202
Fold[6] Epoch: 11 [11/300 (4%)] Train loss=0.207183 Test loss=0.391457

[0/12] Train loss=0.19516707956790924
[5/12] Train loss=0.19205230474472046
[10/12] Train loss=0.18365567922592163
Test set avg_accuracy=87.43% avg_sensitivity=52.98%, avg_specificity=98.99% avg_auc=0.9250
Fold[6] Epoch: 12 [12/300 (4%)] Train loss=0.204265 Test loss=0.353035

[0/12] Train loss=0.1987120807170868
[5/12] Train loss=0.18613861501216888
[10/12] Train loss=0.17801491916179657
Test set avg_accuracy=87.56% avg_sensitivity=56.12%, avg_specificity=98.11% avg_auc=0.9157
Fold[6] Epoch: 13 [13/300 (4%)] Train loss=0.194671 Test loss=0.379084

[0/12] Train loss=0.21118758618831635
[5/12] Train loss=0.16396291553974152
[10/12] Train loss=0.17729227244853973
Test set avg_accuracy=89.76% avg_sensitivity=80.83%, avg_specificity=92.76% avg_auc=0.9297
Best model saved!!!!
Fold[6] Epoch: 14 [14/300 (5%)] Train loss=0.188586 Test loss=0.348421

[0/12] Train loss=0.19895760715007782
[5/12] Train loss=0.20319879055023193
[10/12] Train loss=0.15861834585666656
Test set avg_accuracy=89.93% avg_sensitivity=76.68%, avg_specificity=94.38% avg_auc=0.9255
Fold[6] Epoch: 15 [15/300 (5%)] Train loss=0.184009 Test loss=0.344535

[0/12] Train loss=0.18233802914619446
[5/12] Train loss=0.15849082171916962
[10/12] Train loss=0.1343906968832016
Test set avg_accuracy=90.21% avg_sensitivity=79.05%, avg_specificity=93.95% avg_auc=0.9275
Fold[6] Epoch: 16 [16/300 (5%)] Train loss=0.163460 Test loss=0.320237

[0/12] Train loss=0.16175177693367004
[5/12] Train loss=0.13262900710105896
[10/12] Train loss=0.11600743979215622
Test set avg_accuracy=89.78% avg_sensitivity=73.09%, avg_specificity=95.38% avg_auc=0.9261
Fold[6] Epoch: 17 [17/300 (6%)] Train loss=0.142479 Test loss=0.348126

[0/12] Train loss=0.13271544873714447
[5/12] Train loss=0.12305346876382828
[10/12] Train loss=0.11868225038051605
Test set avg_accuracy=89.34% avg_sensitivity=65.21%, avg_specificity=97.43% avg_auc=0.9190
Fold[6] Epoch: 18 [18/300 (6%)] Train loss=0.121896 Test loss=0.367251

[0/12] Train loss=0.11101758480072021
[5/12] Train loss=0.10616414248943329
[10/12] Train loss=0.08594557642936707
Test set avg_accuracy=89.40% avg_sensitivity=66.61%, avg_specificity=97.05% avg_auc=0.9247
Fold[6] Epoch: 19 [19/300 (6%)] Train loss=0.106290 Test loss=0.362153

[0/12] Train loss=0.10445254296064377
[5/12] Train loss=0.10455703735351562
[10/12] Train loss=0.08433391153812408
Test set avg_accuracy=89.59% avg_sensitivity=75.33%, avg_specificity=94.38% avg_auc=0.9278
Fold[6] Epoch: 20 [20/300 (7%)] Train loss=0.096822 Test loss=0.378586

[0/12] Train loss=0.0883294939994812
[5/12] Train loss=0.0828489437699318
[10/12] Train loss=0.06663491576910019
Test set avg_accuracy=89.55% avg_sensitivity=81.85%, avg_specificity=92.13% avg_auc=0.9265
Fold[6] Epoch: 21 [21/300 (7%)] Train loss=0.079817 Test loss=0.400715

[0/12] Train loss=0.08377203345298767
[5/12] Train loss=0.06917940825223923
[10/12] Train loss=0.06065528467297554
Test set avg_accuracy=90.04% avg_sensitivity=73.97%, avg_specificity=95.43% avg_auc=0.9218
Fold[6] Epoch: 22 [22/300 (7%)] Train loss=0.071632 Test loss=0.376295

[0/12] Train loss=0.0631624311208725
[5/12] Train loss=0.05754450708627701
[10/12] Train loss=0.04744840785861015
Test set avg_accuracy=89.53% avg_sensitivity=72.79%, avg_specificity=95.14% avg_auc=0.9221
Fold[6] Epoch: 23 [23/300 (8%)] Train loss=0.055706 Test loss=0.449407

[0/12] Train loss=0.053337663412094116
[5/12] Train loss=0.04511258751153946
[10/12] Train loss=0.037572480738162994
Test set avg_accuracy=89.37% avg_sensitivity=74.06%, avg_specificity=94.50% avg_auc=0.9256
Fold[6] Epoch: 24 [24/300 (8%)] Train loss=0.045853 Test loss=0.435766

[0/12] Train loss=0.04577719047665596
[5/12] Train loss=0.03879234939813614
[10/12] Train loss=0.03129167854785919
Test set avg_accuracy=89.30% avg_sensitivity=73.72%, avg_specificity=94.53% avg_auc=0.9255
Fold[6] Epoch: 25 [25/300 (8%)] Train loss=0.037897 Test loss=0.463713

[0/12] Train loss=0.032806262373924255
[5/12] Train loss=0.030466990545392036
[10/12] Train loss=0.029649505391716957
Test set avg_accuracy=90.29% avg_sensitivity=75.03%, avg_specificity=95.41% avg_auc=0.9254
Fold[6] Epoch: 26 [26/300 (9%)] Train loss=0.031349 Test loss=0.460565

[0/12] Train loss=0.028184080496430397
[5/12] Train loss=0.026305418461561203
[10/12] Train loss=0.022447679191827774
Test set avg_accuracy=89.46% avg_sensitivity=77.61%, avg_specificity=93.44% avg_auc=0.9270
Fold[6] Epoch: 27 [27/300 (9%)] Train loss=0.026844 Test loss=0.480661

Early Stopping!!! Best loss=0.2947724163532257
Fold[6] Best Result: acc=89.76076555023923 sen=80.82945408379179, spe=92.75773927861403, auc=0.9296723738338964!
[0/12] Train loss=0.7120523452758789
[5/12] Train loss=0.6359782218933105
[10/12] Train loss=0.45953962206840515
Test set avg_accuracy=76.58% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.8031
Best model saved!!!!
Fold[7] Epoch: 1 [1/300 (0%)] Train loss=0.706474 Test loss=0.540588

[0/12] Train loss=0.4301106035709381
[5/12] Train loss=0.44880157709121704
[10/12] Train loss=0.3795449733734131
Test set avg_accuracy=78.73% avg_sensitivity=10.36%, avg_specificity=99.64% avg_auc=0.8494
Best model saved!!!!
Fold[7] Epoch: 2 [2/300 (1%)] Train loss=0.415538 Test loss=0.442860

[0/12] Train loss=0.35702213644981384
[5/12] Train loss=0.3746776878833771
[10/12] Train loss=0.31782227754592896
Test set avg_accuracy=78.57% avg_sensitivity=10.14%, avg_specificity=99.50% avg_auc=0.8821
Best model saved!!!!
Fold[7] Epoch: 3 [3/300 (1%)] Train loss=0.355475 Test loss=0.464337

[0/12] Train loss=0.3148149251937866
[5/12] Train loss=0.34049537777900696
[10/12] Train loss=0.278842955827713
Test set avg_accuracy=82.66% avg_sensitivity=29.82%, avg_specificity=98.82% avg_auc=0.9032
Best model saved!!!!
Fold[7] Epoch: 4 [4/300 (1%)] Train loss=0.323726 Test loss=0.403402

[0/12] Train loss=0.28899291157722473
[5/12] Train loss=0.3125218152999878
[10/12] Train loss=0.24331288039684296
Test set avg_accuracy=86.25% avg_sensitivity=49.28%, avg_specificity=97.56% avg_auc=0.9187
Best model saved!!!!
Fold[7] Epoch: 5 [5/300 (2%)] Train loss=0.297145 Test loss=0.373093

[0/12] Train loss=0.25657230615615845
[5/12] Train loss=0.2843855321407318
[10/12] Train loss=0.2363102287054062
Test set avg_accuracy=88.49% avg_sensitivity=61.36%, avg_specificity=96.79% avg_auc=0.9318
Best model saved!!!!
Fold[7] Epoch: 6 [6/300 (2%)] Train loss=0.276268 Test loss=0.307058

[0/12] Train loss=0.24346598982810974
[5/12] Train loss=0.24459391832351685
[10/12] Train loss=0.2173253446817398
Test set avg_accuracy=87.38% avg_sensitivity=54.16%, avg_specificity=97.54% avg_auc=0.9257
Fold[7] Epoch: 7 [7/300 (2%)] Train loss=0.252745 Test loss=0.335866

[0/12] Train loss=0.2415333390235901
[5/12] Train loss=0.23725448548793793
[10/12] Train loss=0.19673414528369904
Test set avg_accuracy=89.52% avg_sensitivity=63.98%, avg_specificity=97.33% avg_auc=0.9347
Best model saved!!!!
Fold[7] Epoch: 8 [8/300 (3%)] Train loss=0.239740 Test loss=0.314823

[0/12] Train loss=0.21769429743289948
[5/12] Train loss=0.22897420823574066
[10/12] Train loss=0.19346128404140472
Test set avg_accuracy=87.82% avg_sensitivity=55.07%, avg_specificity=97.84% avg_auc=0.9301
Fold[7] Epoch: 9 [9/300 (3%)] Train loss=0.227043 Test loss=0.387405

[0/12] Train loss=0.23042409121990204
[5/12] Train loss=0.22673025727272034
[10/12] Train loss=0.18130239844322205
Test set avg_accuracy=85.39% avg_sensitivity=43.26%, avg_specificity=98.28% avg_auc=0.9046
Fold[7] Epoch: 10 [10/300 (3%)] Train loss=0.215483 Test loss=0.505829

[0/12] Train loss=0.2814614772796631
[5/12] Train loss=0.21150553226470947
[10/12] Train loss=0.19971516728401184
Test set avg_accuracy=85.90% avg_sensitivity=45.93%, avg_specificity=98.13% avg_auc=0.9103
Fold[7] Epoch: 11 [11/300 (4%)] Train loss=0.230720 Test loss=0.383197

[0/12] Train loss=0.2079841047525406
[5/12] Train loss=0.2526535093784332
[10/12] Train loss=0.2249089926481247
Test set avg_accuracy=87.57% avg_sensitivity=54.25%, avg_specificity=97.76% avg_auc=0.9164
Fold[7] Epoch: 12 [12/300 (4%)] Train loss=0.247897 Test loss=0.395884

[0/12] Train loss=0.21259760856628418
[5/12] Train loss=0.23626649379730225
[10/12] Train loss=0.19398750364780426
Test set avg_accuracy=89.60% avg_sensitivity=67.06%, avg_specificity=96.50% avg_auc=0.9266
Best model saved!!!!
Fold[7] Epoch: 13 [13/300 (4%)] Train loss=0.226322 Test loss=0.320968

[0/12] Train loss=0.19556967914104462
[5/12] Train loss=0.20292678475379944
[10/12] Train loss=0.18120993673801422
Test set avg_accuracy=90.49% avg_sensitivity=71.90%, avg_specificity=96.18% avg_auc=0.9333
Best model saved!!!!
Fold[7] Epoch: 14 [14/300 (5%)] Train loss=0.204220 Test loss=0.291351

[0/12] Train loss=0.18904507160186768
[5/12] Train loss=0.16283965110778809
[10/12] Train loss=0.18058012425899506
Test set avg_accuracy=90.26% avg_sensitivity=80.18%, avg_specificity=93.34% avg_auc=0.9379
Best model saved!!!!
Fold[7] Epoch: 15 [15/300 (5%)] Train loss=0.184032 Test loss=0.315644

[0/12] Train loss=0.18957965075969696
[5/12] Train loss=0.1709526628255844
[10/12] Train loss=0.13132092356681824
Test set avg_accuracy=90.48% avg_sensitivity=75.52%, avg_specificity=95.06% avg_auc=0.9323
Fold[7] Epoch: 16 [16/300 (5%)] Train loss=0.172177 Test loss=0.315471

[0/12] Train loss=0.1600349098443985
[5/12] Train loss=0.13534186780452728
[10/12] Train loss=0.1347137987613678
Test set avg_accuracy=90.87% avg_sensitivity=78.24%, avg_specificity=94.74% avg_auc=0.9395
Best model saved!!!!
Fold[7] Epoch: 17 [17/300 (6%)] Train loss=0.160066 Test loss=0.287103

[0/12] Train loss=0.14182788133621216
[5/12] Train loss=0.132181316614151
[10/12] Train loss=0.11199934780597687
Test set avg_accuracy=90.96% avg_sensitivity=74.75%, avg_specificity=95.92% avg_auc=0.9397
Fold[7] Epoch: 18 [18/300 (6%)] Train loss=0.127345 Test loss=0.324176

[0/12] Train loss=0.11321069300174713
[5/12] Train loss=0.12107866257429123
[10/12] Train loss=0.08675239235162735
Test set avg_accuracy=89.55% avg_sensitivity=62.53%, avg_specificity=97.81% avg_auc=0.9277
Fold[7] Epoch: 19 [19/300 (6%)] Train loss=0.105239 Test loss=0.400458

[0/12] Train loss=0.10860861837863922
[5/12] Train loss=0.09028910100460052
[10/12] Train loss=0.0786185935139656
Test set avg_accuracy=90.38% avg_sensitivity=73.39%, avg_specificity=95.57% avg_auc=0.9331
Fold[7] Epoch: 20 [20/300 (7%)] Train loss=0.094546 Test loss=0.341607

[0/12] Train loss=0.08822304755449295
[5/12] Train loss=0.09809689968824387
[10/12] Train loss=0.07594536989927292
Test set avg_accuracy=90.24% avg_sensitivity=79.77%, avg_specificity=93.44% avg_auc=0.9349
Fold[7] Epoch: 21 [21/300 (7%)] Train loss=0.081086 Test loss=0.396302

[0/12] Train loss=0.08660095930099487
[5/12] Train loss=0.08312297612428665
[10/12] Train loss=0.06388775259256363
Test set avg_accuracy=90.37% avg_sensitivity=75.38%, avg_specificity=94.95% avg_auc=0.9305
Fold[7] Epoch: 22 [22/300 (7%)] Train loss=0.076074 Test loss=0.397274

[0/12] Train loss=0.06290441006422043
[5/12] Train loss=0.07288370281457901
[10/12] Train loss=0.05426707863807678
Test set avg_accuracy=90.73% avg_sensitivity=73.89%, avg_specificity=95.88% avg_auc=0.9246
Fold[7] Epoch: 23 [23/300 (8%)] Train loss=0.065036 Test loss=0.376272

[0/12] Train loss=0.06470334529876709
[5/12] Train loss=0.05346836522221565
[10/12] Train loss=0.04765547439455986
Test set avg_accuracy=90.68% avg_sensitivity=75.25%, avg_specificity=95.40% avg_auc=0.9349
Fold[7] Epoch: 24 [24/300 (8%)] Train loss=0.054787 Test loss=0.444396

[0/12] Train loss=0.052312061190605164
[5/12] Train loss=0.0417824313044548
[10/12] Train loss=0.03782890737056732
Test set avg_accuracy=90.32% avg_sensitivity=71.99%, avg_specificity=95.93% avg_auc=0.9301
Fold[7] Epoch: 25 [25/300 (8%)] Train loss=0.044306 Test loss=0.474910

[0/12] Train loss=0.047369785606861115
[5/12] Train loss=0.0366801917552948
[10/12] Train loss=0.031597431749105453
Test set avg_accuracy=90.23% avg_sensitivity=72.49%, avg_specificity=95.65% avg_auc=0.9276
Fold[7] Epoch: 26 [26/300 (9%)] Train loss=0.038482 Test loss=0.474537

[0/12] Train loss=0.03936006501317024
[5/12] Train loss=0.035387471318244934
[10/12] Train loss=0.026840876787900925
Test set avg_accuracy=90.60% avg_sensitivity=76.65%, avg_specificity=94.87% avg_auc=0.9293
Fold[7] Epoch: 27 [27/300 (9%)] Train loss=0.032725 Test loss=0.498766

[0/12] Train loss=0.03068378195166588
[5/12] Train loss=0.032526250928640366
[10/12] Train loss=0.023786228150129318
Test set avg_accuracy=90.80% avg_sensitivity=73.76%, avg_specificity=96.01% avg_auc=0.9318
Fold[7] Epoch: 28 [28/300 (9%)] Train loss=0.028100 Test loss=0.502959

[0/12] Train loss=0.025616388767957687
[5/12] Train loss=0.023451698943972588
[10/12] Train loss=0.019745685160160065
Test set avg_accuracy=90.45% avg_sensitivity=72.94%, avg_specificity=95.81% avg_auc=0.9303
Fold[7] Epoch: 29 [29/300 (10%)] Train loss=0.024000 Test loss=0.559149

[0/12] Train loss=0.021670496091246605
[5/12] Train loss=0.0192769356071949
[10/12] Train loss=0.016819767653942108
Test set avg_accuracy=90.06% avg_sensitivity=73.08%, avg_specificity=95.25% avg_auc=0.9280
Fold[7] Epoch: 30 [30/300 (10%)] Train loss=0.019953 Test loss=0.605169

[0/12] Train loss=0.02367505617439747
[5/12] Train loss=0.017882240936160088
[10/12] Train loss=0.015677621588110924
Test set avg_accuracy=90.31% avg_sensitivity=74.57%, avg_specificity=95.13% avg_auc=0.9267
Fold[7] Epoch: 31 [31/300 (10%)] Train loss=0.019411 Test loss=0.605794

[0/12] Train loss=0.018102452158927917
[5/12] Train loss=0.01699152961373329
[10/12] Train loss=0.012916733510792255
Test set avg_accuracy=90.70% avg_sensitivity=75.02%, avg_specificity=95.50% avg_auc=0.9325
Fold[7] Epoch: 32 [32/300 (11%)] Train loss=0.017287 Test loss=0.589805

[0/12] Train loss=0.015063400380313396
[5/12] Train loss=0.01556050032377243
[10/12] Train loss=0.015669366344809532
Test set avg_accuracy=90.34% avg_sensitivity=72.49%, avg_specificity=95.81% avg_auc=0.9278
Fold[7] Epoch: 33 [33/300 (11%)] Train loss=0.016083 Test loss=0.644315

[0/12] Train loss=0.020740583539009094
[5/12] Train loss=0.016654541715979576
[10/12] Train loss=0.009788339957594872
Test set avg_accuracy=90.45% avg_sensitivity=71.31%, avg_specificity=96.30% avg_auc=0.9313
Fold[7] Epoch: 34 [34/300 (11%)] Train loss=0.015386 Test loss=0.613608

[0/12] Train loss=0.02291179448366165
[5/12] Train loss=0.015663141384720802
[10/12] Train loss=0.014350230805575848
Test set avg_accuracy=90.42% avg_sensitivity=73.17%, avg_specificity=95.70% avg_auc=0.9279
Fold[7] Epoch: 35 [35/300 (12%)] Train loss=0.016920 Test loss=0.672274

[0/12] Train loss=0.012954804114997387
[5/12] Train loss=0.019523732364177704
[10/12] Train loss=0.015522741712629795
Test set avg_accuracy=90.22% avg_sensitivity=75.70%, avg_specificity=94.66% avg_auc=0.9288
Fold[7] Epoch: 36 [36/300 (12%)] Train loss=0.014190 Test loss=0.681056

[0/12] Train loss=0.01509932428598404
[5/12] Train loss=0.01026364229619503
[10/12] Train loss=0.012534589506685734
Test set avg_accuracy=90.54% avg_sensitivity=72.76%, avg_specificity=95.97% avg_auc=0.9297
Fold[7] Epoch: 37 [37/300 (12%)] Train loss=0.013821 Test loss=0.672731

Early Stopping!!! Best loss=0.2871030569076538
Fold[7] Best Result: acc=90.87440381558028 sen=78.23529411764706, spe=94.74048442906575, auc=0.9394983794955298!
[0/12] Train loss=0.7001200914382935
[5/12] Train loss=0.6673765182495117
[10/12] Train loss=0.5192738175392151
Test set avg_accuracy=76.36% avg_sensitivity=0.87%, avg_specificity=99.95% avg_auc=0.7276
Best model saved!!!!
Fold[8] Epoch: 1 [1/300 (0%)] Train loss=0.751344 Test loss=0.498709

[0/12] Train loss=0.433559387922287
[5/12] Train loss=0.43647342920303345
[10/12] Train loss=0.377556711435318
Test set avg_accuracy=80.77% avg_sensitivity=25.87%, avg_specificity=97.93% avg_auc=0.8613
Best model saved!!!!
Fold[8] Epoch: 2 [2/300 (1%)] Train loss=0.420983 Test loss=0.398521

[0/12] Train loss=0.36489924788475037
[5/12] Train loss=0.38526979088783264
[10/12] Train loss=0.32552385330200195
Test set avg_accuracy=78.90% avg_sensitivity=12.36%, avg_specificity=99.70% avg_auc=0.8767
Fold[8] Epoch: 3 [3/300 (1%)] Train loss=0.370345 Test loss=0.424666

[0/12] Train loss=0.3268158733844757
[5/12] Train loss=0.33871030807495117
[10/12] Train loss=0.28220224380493164
Test set avg_accuracy=83.64% avg_sensitivity=42.52%, avg_specificity=96.50% avg_auc=0.8960
Best model saved!!!!
Fold[8] Epoch: 4 [4/300 (1%)] Train loss=0.328391 Test loss=0.357822

[0/12] Train loss=0.28333941102027893
[5/12] Train loss=0.2983437478542328
[10/12] Train loss=0.24068275094032288
Test set avg_accuracy=86.78% avg_sensitivity=57.96%, avg_specificity=95.79% avg_auc=0.9100
Best model saved!!!!
Fold[8] Epoch: 5 [5/300 (2%)] Train loss=0.295339 Test loss=0.337298

[0/12] Train loss=0.2652924954891205
[5/12] Train loss=0.28103214502334595
[10/12] Train loss=0.21647053956985474
Test set avg_accuracy=87.76% avg_sensitivity=70.27%, avg_specificity=93.23% avg_auc=0.9219
Best model saved!!!!
Fold[8] Epoch: 6 [6/300 (2%)] Train loss=0.273307 Test loss=0.311146

[0/12] Train loss=0.24918530881404877
[5/12] Train loss=0.24017347395420074
[10/12] Train loss=0.20332954823970795
Test set avg_accuracy=87.59% avg_sensitivity=68.97%, avg_specificity=93.41% avg_auc=0.9259
Fold[8] Epoch: 7 [7/300 (2%)] Train loss=0.249373 Test loss=0.312735

[0/12] Train loss=0.2306782603263855
[5/12] Train loss=0.22915688157081604
[10/12] Train loss=0.18338540196418762
Test set avg_accuracy=88.17% avg_sensitivity=71.04%, avg_specificity=93.53% avg_auc=0.9311
Best model saved!!!!
Fold[8] Epoch: 8 [8/300 (3%)] Train loss=0.232902 Test loss=0.302194

[0/12] Train loss=0.2107432782649994
[5/12] Train loss=0.2137359380722046
[10/12] Train loss=0.16794396936893463
Test set avg_accuracy=88.51% avg_sensitivity=73.02%, avg_specificity=93.35% avg_auc=0.9314
Best model saved!!!!
Fold[8] Epoch: 9 [9/300 (3%)] Train loss=0.213336 Test loss=0.317651

[0/12] Train loss=0.21850720047950745
[5/12] Train loss=0.19369660317897797
[10/12] Train loss=0.164434015750885
Test set avg_accuracy=88.45% avg_sensitivity=72.49%, avg_specificity=93.44% avg_auc=0.9282
Fold[8] Epoch: 10 [10/300 (3%)] Train loss=0.205056 Test loss=0.320604

[0/12] Train loss=0.20560699701309204
[5/12] Train loss=0.21678602695465088
[10/12] Train loss=0.1886766254901886
Test set avg_accuracy=87.67% avg_sensitivity=60.33%, avg_specificity=96.21% avg_auc=0.9130
Fold[8] Epoch: 11 [11/300 (4%)] Train loss=0.212045 Test loss=0.333084

[0/12] Train loss=0.19583465158939362
[5/12] Train loss=0.18670178949832916
[10/12] Train loss=0.17201171815395355
Test set avg_accuracy=88.00% avg_sensitivity=57.87%, avg_specificity=97.42% avg_auc=0.9223
Fold[8] Epoch: 12 [12/300 (4%)] Train loss=0.197543 Test loss=0.370591

[0/12] Train loss=0.22795557975769043
[5/12] Train loss=0.22105157375335693
[10/12] Train loss=0.14876724779605865
Test set avg_accuracy=88.60% avg_sensitivity=66.94%, avg_specificity=95.37% avg_auc=0.9318
Fold[8] Epoch: 13 [13/300 (4%)] Train loss=0.195581 Test loss=0.310892

[0/12] Train loss=0.17810098826885223
[5/12] Train loss=0.17630457878112793
[10/12] Train loss=0.13878053426742554
Test set avg_accuracy=87.29% avg_sensitivity=57.63%, avg_specificity=96.56% avg_auc=0.9265
Fold[8] Epoch: 14 [14/300 (5%)] Train loss=0.178665 Test loss=0.334014

[0/12] Train loss=0.1684764176607132
[5/12] Train loss=0.1527288556098938
[10/12] Train loss=0.12493141740560532
Test set avg_accuracy=84.99% avg_sensitivity=41.36%, avg_specificity=98.63% avg_auc=0.9097
Fold[8] Epoch: 15 [15/300 (5%)] Train loss=0.166665 Test loss=0.529484

[0/12] Train loss=0.17005208134651184
[5/12] Train loss=0.15867140889167786
[10/12] Train loss=0.14470751583576202
Test set avg_accuracy=88.32% avg_sensitivity=75.87%, avg_specificity=92.21% avg_auc=0.9322
Best model saved!!!!
Fold[8] Epoch: 16 [16/300 (5%)] Train loss=0.168835 Test loss=0.304493

[0/12] Train loss=0.16566145420074463
[5/12] Train loss=0.16896924376487732
[10/12] Train loss=0.14859165251255035
Test set avg_accuracy=87.46% avg_sensitivity=72.59%, avg_specificity=92.11% avg_auc=0.9274
Fold[8] Epoch: 17 [17/300 (6%)] Train loss=0.170510 Test loss=0.362409

[0/12] Train loss=0.16586171090602875
[5/12] Train loss=0.15231914818286896
[10/12] Train loss=0.14294293522834778
Test set avg_accuracy=88.13% avg_sensitivity=80.45%, avg_specificity=90.53% avg_auc=0.9310
Best model saved!!!!
Fold[8] Epoch: 18 [18/300 (6%)] Train loss=0.163702 Test loss=0.375555

[0/12] Train loss=0.17710480093955994
[5/12] Train loss=0.15551242232322693
[10/12] Train loss=0.11627842485904694
Test set avg_accuracy=88.77% avg_sensitivity=76.98%, avg_specificity=92.46% avg_auc=0.9341
Fold[8] Epoch: 19 [19/300 (6%)] Train loss=0.149101 Test loss=0.336999

[0/12] Train loss=0.14052556455135345
[5/12] Train loss=0.13363885879516602
[10/12] Train loss=0.09818050265312195
Test set avg_accuracy=86.66% avg_sensitivity=81.03%, avg_specificity=88.41% avg_auc=0.9299
Fold[8] Epoch: 20 [20/300 (7%)] Train loss=0.126940 Test loss=0.411147

[0/12] Train loss=0.11947619915008545
[5/12] Train loss=0.10914839804172516
[10/12] Train loss=0.10078013688325882
Test set avg_accuracy=88.11% avg_sensitivity=75.82%, avg_specificity=91.96% avg_auc=0.9266
Fold[8] Epoch: 21 [21/300 (7%)] Train loss=0.112345 Test loss=0.385969

[0/12] Train loss=0.11752892285585403
[5/12] Train loss=0.11011440306901932
[10/12] Train loss=0.0778236836194992
Test set avg_accuracy=88.60% avg_sensitivity=74.90%, avg_specificity=92.88% avg_auc=0.9286
Fold[8] Epoch: 22 [22/300 (7%)] Train loss=0.101491 Test loss=0.385943

[0/12] Train loss=0.10130645334720612
[5/12] Train loss=0.09754350781440735
[10/12] Train loss=0.07835422456264496
Test set avg_accuracy=88.84% avg_sensitivity=73.84%, avg_specificity=93.53% avg_auc=0.9281
Fold[8] Epoch: 23 [23/300 (8%)] Train loss=0.091259 Test loss=0.403740

[0/12] Train loss=0.08982015401124954
[5/12] Train loss=0.08949367702007294
[10/12] Train loss=0.06962829828262329
Test set avg_accuracy=88.83% avg_sensitivity=68.53%, avg_specificity=95.17% avg_auc=0.9266
Fold[8] Epoch: 24 [24/300 (8%)] Train loss=0.078967 Test loss=0.411120

[0/12] Train loss=0.08700419217348099
[5/12] Train loss=0.07044637203216553
[10/12] Train loss=0.07602940499782562
Test set avg_accuracy=88.97% avg_sensitivity=69.64%, avg_specificity=95.01% avg_auc=0.9241
Fold[8] Epoch: 25 [25/300 (8%)] Train loss=0.081392 Test loss=0.421917

[0/12] Train loss=0.073684923350811
[5/12] Train loss=0.07621563971042633
[10/12] Train loss=0.08120834827423096
Test set avg_accuracy=87.54% avg_sensitivity=79.54%, avg_specificity=90.04% avg_auc=0.9234
Fold[8] Epoch: 26 [26/300 (9%)] Train loss=0.077757 Test loss=0.485556

[0/12] Train loss=0.09891241788864136
[5/12] Train loss=0.07285578548908234
[10/12] Train loss=0.056696318089962006
Test set avg_accuracy=87.71% avg_sensitivity=79.34%, avg_specificity=90.33% avg_auc=0.9287
Fold[8] Epoch: 27 [27/300 (9%)] Train loss=0.074320 Test loss=0.529068

[0/12] Train loss=0.08118139952421188
[5/12] Train loss=0.0704912543296814
[10/12] Train loss=0.0536639541387558
Test set avg_accuracy=88.38% avg_sensitivity=76.16%, avg_specificity=92.20% avg_auc=0.9240
Fold[8] Epoch: 28 [28/300 (9%)] Train loss=0.066112 Test loss=0.465956

Early Stopping!!! Best loss=0.30219388008117676
Fold[8] Best Result: acc=88.1264367816092 sen=80.45366795366795, spe=90.52504526252262, auc=0.9309924201294146!
[0/12] Train loss=0.6982640624046326
[5/12] Train loss=0.655741810798645
[10/12] Train loss=0.5401694774627686
Test set avg_accuracy=74.93% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5946
Best model saved!!!!
Fold[9] Epoch: 1 [1/300 (0%)] Train loss=0.778687 Test loss=0.665111

[0/12] Train loss=0.460186243057251
[5/12] Train loss=0.4294910132884979
[10/12] Train loss=0.36573857069015503
Test set avg_accuracy=77.25% avg_sensitivity=13.91%, avg_specificity=98.44% avg_auc=0.8432
Best model saved!!!!
Fold[9] Epoch: 2 [2/300 (1%)] Train loss=0.425185 Test loss=0.488979

[0/12] Train loss=0.35434335470199585
[5/12] Train loss=0.39379531145095825
[10/12] Train loss=0.33210286498069763
Test set avg_accuracy=76.31% avg_sensitivity=9.38%, avg_specificity=98.71% avg_auc=0.8447
Fold[9] Epoch: 3 [3/300 (1%)] Train loss=0.366487 Test loss=0.556229

[0/12] Train loss=0.3211999833583832
[5/12] Train loss=0.35525158047676086
[10/12] Train loss=0.28953197598457336
Test set avg_accuracy=79.68% avg_sensitivity=26.87%, avg_specificity=97.35% avg_auc=0.8726
Best model saved!!!!
Fold[9] Epoch: 4 [4/300 (1%)] Train loss=0.337425 Test loss=0.491562

[0/12] Train loss=0.2932296693325043
[5/12] Train loss=0.32999271154403687
[10/12] Train loss=0.270974725484848
Test set avg_accuracy=83.53% avg_sensitivity=46.77%, avg_specificity=95.84% avg_auc=0.8926
Best model saved!!!!
Fold[9] Epoch: 5 [5/300 (2%)] Train loss=0.313108 Test loss=0.384866

[0/12] Train loss=0.2802598178386688
[5/12] Train loss=0.29977259039878845
[10/12] Train loss=0.24778316915035248
Test set avg_accuracy=83.27% avg_sensitivity=43.23%, avg_specificity=96.67% avg_auc=0.8964
Fold[9] Epoch: 6 [6/300 (2%)] Train loss=0.282347 Test loss=0.409201

[0/12] Train loss=0.26886144280433655
[5/12] Train loss=0.26037654280662537
[10/12] Train loss=0.2313387244939804
Test set avg_accuracy=83.48% avg_sensitivity=44.60%, avg_specificity=96.48% avg_auc=0.9021
Fold[9] Epoch: 7 [7/300 (2%)] Train loss=0.259434 Test loss=0.434492

[0/12] Train loss=0.25191497802734375
[5/12] Train loss=0.23966221511363983
[10/12] Train loss=0.20895959436893463
Test set avg_accuracy=85.22% avg_sensitivity=54.22%, avg_specificity=95.60% avg_auc=0.9106
Best model saved!!!!
Fold[9] Epoch: 8 [8/300 (3%)] Train loss=0.240832 Test loss=0.403970

[0/12] Train loss=0.22075630724430084
[5/12] Train loss=0.22044789791107178
[10/12] Train loss=0.2043439745903015
Test set avg_accuracy=83.70% avg_sensitivity=48.75%, avg_specificity=95.39% avg_auc=0.8903
Fold[9] Epoch: 9 [9/300 (3%)] Train loss=0.231045 Test loss=0.465157

[0/12] Train loss=0.2507668733596802
[5/12] Train loss=0.22598649561405182
[10/12] Train loss=0.19239377975463867
Test set avg_accuracy=84.10% avg_sensitivity=55.12%, avg_specificity=93.80% avg_auc=0.8930
Fold[9] Epoch: 10 [10/300 (3%)] Train loss=0.234179 Test loss=0.453264

[0/12] Train loss=0.2210467904806137
[5/12] Train loss=0.2573010325431824
[10/12] Train loss=0.21297618746757507
Test set avg_accuracy=86.22% avg_sensitivity=60.16%, avg_specificity=94.94% avg_auc=0.9184
Best model saved!!!!
Fold[9] Epoch: 11 [11/300 (4%)] Train loss=0.236011 Test loss=0.351926

[0/12] Train loss=0.2103918343782425
[5/12] Train loss=0.2021791785955429
[10/12] Train loss=0.17844948172569275
Test set avg_accuracy=87.00% avg_sensitivity=63.84%, avg_specificity=94.75% avg_auc=0.9131
Best model saved!!!!
Fold[9] Epoch: 12 [12/300 (4%)] Train loss=0.215692 Test loss=0.343166

[0/12] Train loss=0.1976841241121292
[5/12] Train loss=0.1761188954114914
[10/12] Train loss=0.17368653416633606
Test set avg_accuracy=86.38% avg_sensitivity=61.29%, avg_specificity=94.78% avg_auc=0.9115
Fold[9] Epoch: 13 [13/300 (4%)] Train loss=0.198898 Test loss=0.355349

[0/12] Train loss=0.18810969591140747
[5/12] Train loss=0.19015894830226898
[10/12] Train loss=0.20941318571567535
Test set avg_accuracy=86.23% avg_sensitivity=78.17%, avg_specificity=88.93% avg_auc=0.9221
Best model saved!!!!
Fold[9] Epoch: 14 [14/300 (5%)] Train loss=0.193089 Test loss=0.393118

[0/12] Train loss=0.2175302803516388
[5/12] Train loss=0.182284876704216
[10/12] Train loss=0.16478101909160614
Test set avg_accuracy=85.93% avg_sensitivity=77.70%, avg_specificity=88.69% avg_auc=0.9070
Fold[9] Epoch: 15 [15/300 (5%)] Train loss=0.190900 Test loss=0.426487

[0/12] Train loss=0.18591763079166412
[5/12] Train loss=0.17913009226322174
[10/12] Train loss=0.16099457442760468
Test set avg_accuracy=87.94% avg_sensitivity=68.84%, avg_specificity=94.34% avg_auc=0.9187
Fold[9] Epoch: 16 [16/300 (5%)] Train loss=0.182010 Test loss=0.341172

[0/12] Train loss=0.1615830659866333
[5/12] Train loss=0.14601674675941467
[10/12] Train loss=0.12266548722982407
Test set avg_accuracy=86.51% avg_sensitivity=67.85%, avg_specificity=92.76% avg_auc=0.9092
Fold[9] Epoch: 17 [17/300 (6%)] Train loss=0.152702 Test loss=0.410691

[0/12] Train loss=0.138473778963089
[5/12] Train loss=0.13567699491977692
[10/12] Train loss=0.10699284821748734
Test set avg_accuracy=86.71% avg_sensitivity=65.91%, avg_specificity=93.67% avg_auc=0.9164
Fold[9] Epoch: 18 [18/300 (6%)] Train loss=0.131444 Test loss=0.421301

[0/12] Train loss=0.12689712643623352
[5/12] Train loss=0.11715187877416611
[10/12] Train loss=0.09734970331192017
Test set avg_accuracy=86.37% avg_sensitivity=66.81%, avg_specificity=92.92% avg_auc=0.9145
Fold[9] Epoch: 19 [19/300 (6%)] Train loss=0.120089 Test loss=0.450650

[0/12] Train loss=0.1183718889951706
[5/12] Train loss=0.10452431440353394
[10/12] Train loss=0.09019510447978973
Test set avg_accuracy=86.95% avg_sensitivity=63.65%, avg_specificity=94.75% avg_auc=0.9086
Fold[9] Epoch: 20 [20/300 (7%)] Train loss=0.108924 Test loss=0.436904

[0/12] Train loss=0.10289407521486282
[5/12] Train loss=0.09287220984697342
[10/12] Train loss=0.08368295431137085
Test set avg_accuracy=86.57% avg_sensitivity=68.65%, avg_specificity=92.57% avg_auc=0.9101
Fold[9] Epoch: 21 [21/300 (7%)] Train loss=0.101170 Test loss=0.445966

[0/12] Train loss=0.09011621028184891
[5/12] Train loss=0.09752685576677322
[10/12] Train loss=0.0723995566368103
Test set avg_accuracy=86.48% avg_sensitivity=74.78%, avg_specificity=90.39% avg_auc=0.9157
Fold[9] Epoch: 22 [22/300 (7%)] Train loss=0.089413 Test loss=0.488767

[0/12] Train loss=0.09441321343183517
[5/12] Train loss=0.08135569095611572
[10/12] Train loss=0.06411093473434448
Test set avg_accuracy=87.17% avg_sensitivity=71.43%, avg_specificity=92.44% avg_auc=0.9147
Fold[9] Epoch: 23 [23/300 (8%)] Train loss=0.083114 Test loss=0.459728

[0/12] Train loss=0.07860375195741653
[5/12] Train loss=0.07692496478557587
[10/12] Train loss=0.06314907968044281
Test set avg_accuracy=86.55% avg_sensitivity=67.37%, avg_specificity=92.96% avg_auc=0.9047
Fold[9] Epoch: 24 [24/300 (8%)] Train loss=0.075236 Test loss=0.515679

[0/12] Train loss=0.07336439192295074
[5/12] Train loss=0.06582501530647278
[10/12] Train loss=0.05830512195825577
Test set avg_accuracy=86.55% avg_sensitivity=70.06%, avg_specificity=92.06% avg_auc=0.9142
Fold[9] Epoch: 25 [25/300 (8%)] Train loss=0.068237 Test loss=0.491841

[0/12] Train loss=0.07137667387723923
[5/12] Train loss=0.06734680384397507
[10/12] Train loss=0.054343510419130325
Test set avg_accuracy=86.52% avg_sensitivity=62.61%, avg_specificity=94.53% avg_auc=0.9105
Fold[9] Epoch: 26 [26/300 (9%)] Train loss=0.062134 Test loss=0.568373

[0/12] Train loss=0.06849293410778046
[5/12] Train loss=0.05452127382159233
[10/12] Train loss=0.04190599173307419
Test set avg_accuracy=86.64% avg_sensitivity=64.12%, avg_specificity=94.18% avg_auc=0.9093
Fold[9] Epoch: 27 [27/300 (9%)] Train loss=0.057362 Test loss=0.535760

[0/12] Train loss=0.05452525243163109
[5/12] Train loss=0.04915633052587509
[10/12] Train loss=0.04799164459109306
Test set avg_accuracy=86.21% avg_sensitivity=74.63%, avg_specificity=90.08% avg_auc=0.9128
Fold[9] Epoch: 28 [28/300 (9%)] Train loss=0.054243 Test loss=0.610768

[0/12] Train loss=0.05485901981592178
[5/12] Train loss=0.05740465223789215
[10/12] Train loss=0.04186156392097473
Test set avg_accuracy=86.00% avg_sensitivity=77.93%, avg_specificity=88.70% avg_auc=0.9113
Fold[9] Epoch: 29 [29/300 (10%)] Train loss=0.049372 Test loss=0.677861

[0/12] Train loss=0.054490771144628525
[5/12] Train loss=0.041894279420375824
[10/12] Train loss=0.044899459928274155
Test set avg_accuracy=86.63% avg_sensitivity=67.85%, avg_specificity=92.92% avg_auc=0.9134
Fold[9] Epoch: 30 [30/300 (10%)] Train loss=0.049205 Test loss=0.580395

[0/12] Train loss=0.046227142214775085
[5/12] Train loss=0.046927113085985184
[10/12] Train loss=0.03582288324832916
Test set avg_accuracy=85.80% avg_sensitivity=57.57%, avg_specificity=95.25% avg_auc=0.9040
Fold[9] Epoch: 31 [31/300 (10%)] Train loss=0.044231 Test loss=0.673928

[0/12] Train loss=0.049926768988370895
[5/12] Train loss=0.03814079239964485
[10/12] Train loss=0.033701151609420776
Test set avg_accuracy=86.45% avg_sensitivity=73.83%, avg_specificity=90.68% avg_auc=0.9150
Fold[9] Epoch: 32 [32/300 (11%)] Train loss=0.041967 Test loss=0.615147

[0/12] Train loss=0.04714786261320114
[5/12] Train loss=0.03892804682254791
[10/12] Train loss=0.031683504581451416
Test set avg_accuracy=85.80% avg_sensitivity=73.69%, avg_specificity=89.86% avg_auc=0.9135
Fold[9] Epoch: 33 [33/300 (11%)] Train loss=0.037996 Test loss=0.728328

[0/12] Train loss=0.034659821540117264
[5/12] Train loss=0.035975806415081024
[10/12] Train loss=0.025653578341007233
Test set avg_accuracy=86.41% avg_sensitivity=70.72%, avg_specificity=91.65% avg_auc=0.9046
Fold[9] Epoch: 34 [34/300 (11%)] Train loss=0.034849 Test loss=0.679473

[0/12] Train loss=0.03492843359708786
[5/12] Train loss=0.03172909840941429
[10/12] Train loss=0.020682716742157936
Test set avg_accuracy=86.19% avg_sensitivity=67.75%, avg_specificity=92.36% avg_auc=0.9060
Fold[9] Epoch: 35 [35/300 (12%)] Train loss=0.029959 Test loss=0.748746

[0/12] Train loss=0.029709354043006897
[5/12] Train loss=0.0235148873180151
[10/12] Train loss=0.017220860347151756
Test set avg_accuracy=86.16% avg_sensitivity=67.42%, avg_specificity=92.43% avg_auc=0.9118
Fold[9] Epoch: 36 [36/300 (12%)] Train loss=0.025418 Test loss=0.775709

Early Stopping!!! Best loss=0.3411715030670166
Fold[9] Best Result: acc=86.22931442080379 sen=78.17067421027816, spe=88.92569805963085, auc=0.9220608390363747!
[0/12] Train loss=0.6994774341583252
[5/12] Train loss=0.6517059803009033
[10/12] Train loss=0.5173196196556091
Test set avg_accuracy=77.21% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7245
Best model saved!!!!
Fold[10] Epoch: 1 [1/300 (0%)] Train loss=0.702861 Test loss=0.701487

[0/12] Train loss=0.40990322828292847
[5/12] Train loss=0.4134807884693146
[10/12] Train loss=0.4430408477783203
Test set avg_accuracy=84.66% avg_sensitivity=42.74%, avg_specificity=97.04% avg_auc=0.8716
Best model saved!!!!
Fold[10] Epoch: 2 [2/300 (1%)] Train loss=0.404716 Test loss=0.369014

[0/12] Train loss=0.3606455624103546
[5/12] Train loss=0.37660491466522217
[10/12] Train loss=0.4128497838973999
Test set avg_accuracy=86.90% avg_sensitivity=50.90%, avg_specificity=97.53% avg_auc=0.8994
Best model saved!!!!
Fold[10] Epoch: 3 [3/300 (1%)] Train loss=0.357001 Test loss=0.329409

[0/12] Train loss=0.31064844131469727
[5/12] Train loss=0.3169688582420349
[10/12] Train loss=0.36614230275154114
Test set avg_accuracy=83.91% avg_sensitivity=34.88%, avg_specificity=98.38% avg_auc=0.9014
Fold[10] Epoch: 4 [4/300 (1%)] Train loss=0.318382 Test loss=0.368127

[0/12] Train loss=0.2750001847743988
[5/12] Train loss=0.2855066955089569
[10/12] Train loss=0.34409743547439575
Test set avg_accuracy=89.63% avg_sensitivity=66.51%, avg_specificity=96.46% avg_auc=0.9304
Best model saved!!!!
Fold[10] Epoch: 5 [5/300 (2%)] Train loss=0.288137 Test loss=0.280495

[0/12] Train loss=0.24516181647777557
[5/12] Train loss=0.25413376092910767
[10/12] Train loss=0.31412631273269653
Test set avg_accuracy=90.08% avg_sensitivity=67.91%, avg_specificity=96.63% avg_auc=0.9402
Best model saved!!!!
Fold[10] Epoch: 6 [6/300 (2%)] Train loss=0.264550 Test loss=0.257184

[0/12] Train loss=0.23062196373939514
[5/12] Train loss=0.2384004145860672
[10/12] Train loss=0.2942964434623718
Test set avg_accuracy=90.44% avg_sensitivity=67.65%, avg_specificity=97.16% avg_auc=0.9409
Best model saved!!!!
Fold[10] Epoch: 7 [7/300 (2%)] Train loss=0.249750 Test loss=0.255173

[0/12] Train loss=0.22310861945152283
[5/12] Train loss=0.22237560153007507
[10/12] Train loss=0.2630622982978821
Test set avg_accuracy=90.24% avg_sensitivity=67.34%, avg_specificity=96.99% avg_auc=0.9386
Fold[10] Epoch: 8 [8/300 (3%)] Train loss=0.230494 Test loss=0.273514

[0/12] Train loss=0.20906296372413635
[5/12] Train loss=0.21706749498844147
[10/12] Train loss=0.28381308913230896
Test set avg_accuracy=91.01% avg_sensitivity=77.88%, avg_specificity=94.89% avg_auc=0.9401
Best model saved!!!!
Fold[10] Epoch: 9 [9/300 (3%)] Train loss=0.223271 Test loss=0.270459

[0/12] Train loss=0.21436093747615814
[5/12] Train loss=0.23212768137454987
[10/12] Train loss=0.23845626413822174
Test set avg_accuracy=89.75% avg_sensitivity=61.60%, avg_specificity=98.06% avg_auc=0.9417
Fold[10] Epoch: 10 [10/300 (3%)] Train loss=0.213595 Test loss=0.273470

[0/12] Train loss=0.2079608142375946
[5/12] Train loss=0.21102756261825562
[10/12] Train loss=0.2285655438899994
Test set avg_accuracy=89.96% avg_sensitivity=64.24%, avg_specificity=97.56% avg_auc=0.9379
Fold[10] Epoch: 11 [11/300 (4%)] Train loss=0.201880 Test loss=0.277450

[0/12] Train loss=0.17869171500205994
[5/12] Train loss=0.20284722745418549
[10/12] Train loss=0.2145645171403885
Test set avg_accuracy=90.40% avg_sensitivity=70.08%, avg_specificity=96.40% avg_auc=0.9361
Fold[10] Epoch: 12 [12/300 (4%)] Train loss=0.181684 Test loss=0.264107

[0/12] Train loss=0.1633228361606598
[5/12] Train loss=0.14877425134181976
[10/12] Train loss=0.2058582752943039
Test set avg_accuracy=90.38% avg_sensitivity=65.79%, avg_specificity=97.64% avg_auc=0.9454
Fold[10] Epoch: 13 [13/300 (4%)] Train loss=0.166498 Test loss=0.265991

[0/12] Train loss=0.16356854140758514
[5/12] Train loss=0.16866619884967804
[10/12] Train loss=0.16987833380699158
Test set avg_accuracy=90.65% avg_sensitivity=72.61%, avg_specificity=95.97% avg_auc=0.9469
Fold[10] Epoch: 14 [14/300 (5%)] Train loss=0.155258 Test loss=0.276500

[0/12] Train loss=0.1461765468120575
[5/12] Train loss=0.15382246673107147
[10/12] Train loss=0.1926291286945343
Test set avg_accuracy=88.02% avg_sensitivity=52.40%, avg_specificity=98.54% avg_auc=0.9313
Fold[10] Epoch: 15 [15/300 (5%)] Train loss=0.153004 Test loss=0.364143

[0/12] Train loss=0.17956894636154175
[5/12] Train loss=0.1486426740884781
[10/12] Train loss=0.14923220872879028
Test set avg_accuracy=86.02% avg_sensitivity=42.43%, avg_specificity=98.89% avg_auc=0.9255
Fold[10] Epoch: 16 [16/300 (5%)] Train loss=0.141452 Test loss=0.426022

[0/12] Train loss=0.1891091763973236
[5/12] Train loss=0.15183821320533752
[10/12] Train loss=0.18672822415828705
Test set avg_accuracy=85.67% avg_sensitivity=42.07%, avg_specificity=98.54% avg_auc=0.9261
Fold[10] Epoch: 17 [17/300 (6%)] Train loss=0.162525 Test loss=0.395893

[0/12] Train loss=0.1663542538881302
[5/12] Train loss=0.15689077973365784
[10/12] Train loss=0.20910155773162842
Test set avg_accuracy=89.78% avg_sensitivity=67.34%, avg_specificity=96.40% avg_auc=0.9360
Fold[10] Epoch: 18 [18/300 (6%)] Train loss=0.171702 Test loss=0.312305

[0/12] Train loss=0.1482994109392166
[5/12] Train loss=0.1529156118631363
[10/12] Train loss=0.18347114324569702
Test set avg_accuracy=90.29% avg_sensitivity=66.87%, avg_specificity=97.21% avg_auc=0.9413
Fold[10] Epoch: 19 [19/300 (6%)] Train loss=0.169571 Test loss=0.300759

[0/12] Train loss=0.15807321667671204
[5/12] Train loss=0.13854621350765228
[10/12] Train loss=0.1702566146850586
Test set avg_accuracy=90.26% avg_sensitivity=75.09%, avg_specificity=94.74% avg_auc=0.9342
Fold[10] Epoch: 20 [20/300 (7%)] Train loss=0.151931 Test loss=0.300864

[0/12] Train loss=0.13637994229793549
[5/12] Train loss=0.14402586221694946
[10/12] Train loss=0.12912385165691376
Test set avg_accuracy=90.22% avg_sensitivity=84.19%, avg_specificity=92.01% avg_auc=0.9429
Best model saved!!!!
Fold[10] Epoch: 21 [21/300 (7%)] Train loss=0.125346 Test loss=0.325309

[0/12] Train loss=0.13608038425445557
[5/12] Train loss=0.11153533309698105
[10/12] Train loss=0.10998865962028503
Test set avg_accuracy=90.21% avg_sensitivity=79.53%, avg_specificity=93.36% avg_auc=0.9374
Fold[10] Epoch: 22 [22/300 (7%)] Train loss=0.111903 Test loss=0.326143

[0/12] Train loss=0.09993588179349899
[5/12] Train loss=0.08563604950904846
[10/12] Train loss=0.11060786992311478
Test set avg_accuracy=89.46% avg_sensitivity=63.77%, avg_specificity=97.04% avg_auc=0.9344
Fold[10] Epoch: 23 [23/300 (8%)] Train loss=0.094265 Test loss=0.346123

[0/12] Train loss=0.08475678414106369
[5/12] Train loss=0.07698870450258255
[10/12] Train loss=0.07728252559900284
Test set avg_accuracy=90.87% avg_sensitivity=70.80%, avg_specificity=96.80% avg_auc=0.9380
Fold[10] Epoch: 24 [24/300 (8%)] Train loss=0.073938 Test loss=0.339518

[0/12] Train loss=0.06619775295257568
[5/12] Train loss=0.06989271193742752
[10/12] Train loss=0.06549965590238571
Test set avg_accuracy=90.59% avg_sensitivity=80.41%, avg_specificity=93.59% avg_auc=0.9419
Fold[10] Epoch: 25 [25/300 (8%)] Train loss=0.061981 Test loss=0.370511

[0/12] Train loss=0.06009422987699509
[5/12] Train loss=0.0537651963531971
[10/12] Train loss=0.04988531395792961
Test set avg_accuracy=90.58% avg_sensitivity=75.14%, avg_specificity=95.13% avg_auc=0.9363
Fold[10] Epoch: 26 [26/300 (9%)] Train loss=0.053414 Test loss=0.358827

[0/12] Train loss=0.05166667699813843
[5/12] Train loss=0.04407365992665291
[10/12] Train loss=0.042451903223991394
Test set avg_accuracy=90.95% avg_sensitivity=76.18%, avg_specificity=95.32% avg_auc=0.9418
Fold[10] Epoch: 27 [27/300 (9%)] Train loss=0.042383 Test loss=0.375252

Early Stopping!!! Best loss=0.2551725506782532
Fold[10] Best Result: acc=90.22379269729093 sen=84.18604651162791, spe=92.00610221205187, auc=0.9428613382687142!
Final Avg Result: avg_acc=88.073122% avg_sen=77.249083% avg_spe=91.695227% avg_auc=0.926102
