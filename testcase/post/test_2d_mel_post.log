/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/23] Train loss=0.681383490562439
[5/23] Train loss=0.639116644859314
[10/23] Train loss=0.5602952837944031
[15/23] Train loss=0.5582426190376282
[20/23] Train loss=0.5338305234909058
Test set avg_accuracy=74.71% avg_sensitivity=0.08%, avg_specificity=99.97% avg_auc=0.5727
Best model saved!! Metric=-93.96064403355487!!
Fold[1] Epoch: 1 [1/100 (1%)] Train loss=0.574391 Test loss=0.617021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40988096594810486
[5/23] Train loss=0.6071849465370178
[10/23] Train loss=0.5438173413276672
[15/23] Train loss=0.5357704758644104
[20/23] Train loss=0.5045977830886841
Test set avg_accuracy=74.36% avg_sensitivity=2.28%, avg_specificity=98.76% avg_auc=0.6277
Best model saved!! Metric=-87.83154046184076!!
Fold[1] Epoch: 2 [2/100 (2%)] Train loss=0.539818 Test loss=0.628820 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3921513557434082
[5/23] Train loss=0.5828392505645752
[10/23] Train loss=0.5131238102912903
[15/23] Train loss=0.5183447599411011
[20/23] Train loss=0.46596595644950867
Test set avg_accuracy=74.91% avg_sensitivity=8.58%, avg_specificity=97.36% avg_auc=0.6557
Best model saved!! Metric=-79.58317880897044!!
Fold[1] Epoch: 3 [3/100 (3%)] Train loss=0.516167 Test loss=0.619208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38595542311668396
[5/23] Train loss=0.5387335419654846
[10/23] Train loss=0.47667261958122253
[15/23] Train loss=0.49324432015419006
[20/23] Train loss=0.4262714385986328
Test set avg_accuracy=75.91% avg_sensitivity=16.72%, avg_specificity=95.94% avg_auc=0.7045
Best model saved!! Metric=-66.98142429803562!!
Fold[1] Epoch: 4 [4/100 (4%)] Train loss=0.486824 Test loss=0.622636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3858162462711334
[5/23] Train loss=0.492643266916275
[10/23] Train loss=0.44515255093574524
[15/23] Train loss=0.501002848148346
[20/23] Train loss=0.41044461727142334
Test set avg_accuracy=76.77% avg_sensitivity=22.66%, avg_specificity=95.08% avg_auc=0.7396
Best model saved!! Metric=-57.526633805694026!!
Fold[1] Epoch: 5 [5/100 (5%)] Train loss=0.465937 Test loss=0.605288 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40353795886039734
[5/23] Train loss=0.46803298592567444
[10/23] Train loss=0.4302188456058502
[15/23] Train loss=0.4932156801223755
[20/23] Train loss=0.3987537622451782
Test set avg_accuracy=77.11% avg_sensitivity=27.18%, avg_specificity=94.01% avg_auc=0.7598
Best model saved!! Metric=-51.725120806634486!!
Fold[1] Epoch: 6 [6/100 (6%)] Train loss=0.449215 Test loss=0.573696 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.397430956363678
[5/23] Train loss=0.4575171172618866
[10/23] Train loss=0.4271337389945984
[15/23] Train loss=0.4780588150024414
[20/23] Train loss=0.3916639983654022
Test set avg_accuracy=77.86% avg_sensitivity=30.07%, avg_specificity=94.04% avg_auc=0.7772
Best model saved!! Metric=-46.31283325242914!!
Fold[1] Epoch: 7 [7/100 (7%)] Train loss=0.439648 Test loss=0.545519 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38992840051651
[5/23] Train loss=0.44969552755355835
[10/23] Train loss=0.412120521068573
[15/23] Train loss=0.47863122820854187
[20/23] Train loss=0.38432934880256653
Test set avg_accuracy=77.95% avg_sensitivity=31.04%, avg_specificity=93.83% avg_auc=0.7882
Best model saved!! Metric=-44.35196293025047!!
Fold[1] Epoch: 8 [8/100 (8%)] Train loss=0.431538 Test loss=0.532434 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37703680992126465
[5/23] Train loss=0.4506151080131531
[10/23] Train loss=0.41293078660964966
[15/23] Train loss=0.47142547369003296
[20/23] Train loss=0.37746021151542664
Test set avg_accuracy=78.10% avg_sensitivity=32.02%, avg_specificity=93.69% avg_auc=0.7921
Best model saved!! Metric=-42.98315942585815!!
Fold[1] Epoch: 9 [9/100 (9%)] Train loss=0.427474 Test loss=0.523676 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3687303066253662
[5/23] Train loss=0.4495428204536438
[10/23] Train loss=0.41864922642707825
[15/23] Train loss=0.47524765133857727
[20/23] Train loss=0.37430617213249207
Test set avg_accuracy=77.90% avg_sensitivity=29.58%, avg_specificity=94.26% avg_auc=0.7832
Fold[1] Epoch: 10 [10/100 (10%)] Train loss=0.428152 Test loss=0.537140 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35624152421951294
[5/23] Train loss=0.44482648372650146
[10/23] Train loss=0.43761447072029114
[15/23] Train loss=0.42254239320755005
[20/23] Train loss=0.3771212100982666
Test set avg_accuracy=77.75% avg_sensitivity=27.34%, avg_specificity=94.81% avg_auc=0.7803
Fold[1] Epoch: 11 [11/100 (11%)] Train loss=0.429919 Test loss=0.577487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3430240750312805
[5/23] Train loss=0.4367566704750061
[10/23] Train loss=0.40433353185653687
[15/23] Train loss=0.4154512882232666
[20/23] Train loss=0.37145575881004333
Test set avg_accuracy=78.07% avg_sensitivity=31.04%, avg_specificity=93.98% avg_auc=0.7994
Best model saved!! Metric=-42.96701801061463!!
Fold[1] Epoch: 12 [12/100 (12%)] Train loss=0.424225 Test loss=0.519953 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3542111814022064
[5/23] Train loss=0.4319482743740082
[10/23] Train loss=0.3787798285484314
[15/23] Train loss=0.42046067118644714
[20/23] Train loss=0.37073245644569397
Test set avg_accuracy=78.87% avg_sensitivity=37.06%, avg_specificity=93.02% avg_auc=0.8132
Best model saved!! Metric=-35.73085275521639!!
Fold[1] Epoch: 13 [13/100 (13%)] Train loss=0.413819 Test loss=0.493011 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35859307646751404
[5/23] Train loss=0.43093833327293396
[10/23] Train loss=0.38205358386039734
[15/23] Train loss=0.41500455141067505
[20/23] Train loss=0.3625725507736206
Test set avg_accuracy=79.24% avg_sensitivity=37.23%, avg_specificity=93.46% avg_auc=0.8129
Best model saved!! Metric=-34.78897245285501!!
Fold[1] Epoch: 14 [14/100 (14%)] Train loss=0.408689 Test loss=0.496666 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.347439169883728
[5/23] Train loss=0.42609095573425293
[10/23] Train loss=0.42237430810928345
[15/23] Train loss=0.4180285334587097
[20/23] Train loss=0.370237797498703
Test set avg_accuracy=78.52% avg_sensitivity=31.33%, avg_specificity=94.49% avg_auc=0.7956
Fold[1] Epoch: 15 [15/100 (15%)] Train loss=0.414952 Test loss=0.528103 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.332918256521225
[5/23] Train loss=0.43018433451652527
[10/23] Train loss=0.4035579562187195
[15/23] Train loss=0.40629711747169495
[20/23] Train loss=0.35970789194107056
Test set avg_accuracy=78.74% avg_sensitivity=34.21%, avg_specificity=93.82% avg_auc=0.8069
Fold[1] Epoch: 16 [16/100 (16%)] Train loss=0.412488 Test loss=0.517007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3310796916484833
[5/23] Train loss=0.4340399205684662
[10/23] Train loss=0.38782909512519836
[15/23] Train loss=0.4026198089122772
[20/23] Train loss=0.3670927584171295
Test set avg_accuracy=79.10% avg_sensitivity=39.18%, avg_specificity=92.62% avg_auc=0.8238
Best model saved!! Metric=-32.71665518981656!!
Fold[1] Epoch: 17 [17/100 (17%)] Train loss=0.404238 Test loss=0.478712 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3401568830013275
[5/23] Train loss=0.42564788460731506
[10/23] Train loss=0.39414966106414795
[15/23] Train loss=0.405224472284317
[20/23] Train loss=0.3632071614265442
Test set avg_accuracy=79.17% avg_sensitivity=37.23%, avg_specificity=93.36% avg_auc=0.8247
Fold[1] Epoch: 18 [18/100 (18%)] Train loss=0.401192 Test loss=0.492622 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32063204050064087
[5/23] Train loss=0.42828404903411865
[10/23] Train loss=0.40499022603034973
[15/23] Train loss=0.38490429520606995
[20/23] Train loss=0.34541863203048706
Test set avg_accuracy=79.14% avg_sensitivity=34.38%, avg_specificity=94.29% avg_auc=0.8243
Fold[1] Epoch: 19 [19/100 (19%)] Train loss=0.400671 Test loss=0.512049 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3157704174518585
[5/23] Train loss=0.41861018538475037
[10/23] Train loss=0.36918357014656067
[15/23] Train loss=0.39031070470809937
[20/23] Train loss=0.3419833183288574
Test set avg_accuracy=79.85% avg_sensitivity=40.11%, avg_specificity=93.29% avg_auc=0.8278
Best model saved!! Metric=-29.96207086053945!!
Fold[1] Epoch: 20 [20/100 (20%)] Train loss=0.397590 Test loss=0.479873 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3281857371330261
[5/23] Train loss=0.4184471368789673
[10/23] Train loss=0.3588356077671051
[15/23] Train loss=0.3855210542678833
[20/23] Train loss=0.3408597707748413
Test set avg_accuracy=79.93% avg_sensitivity=42.31%, avg_specificity=92.66% avg_auc=0.8333
Best model saved!! Metric=-27.773376506028065!!
Fold[1] Epoch: 21 [21/100 (21%)] Train loss=0.389371 Test loss=0.463138 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32290637493133545
[5/23] Train loss=0.41626280546188354
[10/23] Train loss=0.3757683336734772
[15/23] Train loss=0.38334572315216064
[20/23] Train loss=0.34119388461112976
Test set avg_accuracy=79.74% avg_sensitivity=39.67%, avg_specificity=93.31% avg_auc=0.8361
Fold[1] Epoch: 22 [22/100 (22%)] Train loss=0.388285 Test loss=0.470294 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30734187364578247
[5/23] Train loss=0.4129040837287903
[10/23] Train loss=0.3822005093097687
[15/23] Train loss=0.3798172175884247
[20/23] Train loss=0.33410006761550903
Test set avg_accuracy=79.64% avg_sensitivity=37.79%, avg_specificity=93.80% avg_auc=0.8337
Fold[1] Epoch: 23 [23/100 (23%)] Train loss=0.388611 Test loss=0.483235 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3023427128791809
[5/23] Train loss=0.41490620374679565
[10/23] Train loss=0.34929054975509644
[15/23] Train loss=0.3656066060066223
[20/23] Train loss=0.3317335844039917
Test set avg_accuracy=80.13% avg_sensitivity=42.27%, avg_specificity=92.95% avg_auc=0.8361
Best model saved!! Metric=-27.031948402451587!!
Fold[1] Epoch: 24 [24/100 (24%)] Train loss=0.384065 Test loss=0.470513 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32015541195869446
[5/23] Train loss=0.4066500961780548
[10/23] Train loss=0.3463248610496521
[15/23] Train loss=0.3594146966934204
[20/23] Train loss=0.3291158676147461
Test set avg_accuracy=80.51% avg_sensitivity=45.44%, avg_specificity=92.39% avg_auc=0.8400
Best model saved!! Metric=-23.660510584550327!!
Fold[1] Epoch: 25 [25/100 (25%)] Train loss=0.377842 Test loss=0.449114 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3057924509048462
[5/23] Train loss=0.40829527378082275
[10/23] Train loss=0.36874425411224365
[15/23] Train loss=0.3589482307434082
[20/23] Train loss=0.3286879360675812
Test set avg_accuracy=80.82% avg_sensitivity=46.34%, avg_specificity=92.50% avg_auc=0.8435
Best model saved!! Metric=-21.99374505560054!!
Fold[1] Epoch: 26 [26/100 (26%)] Train loss=0.376784 Test loss=0.449435 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2941555082798004
[5/23] Train loss=0.40439552068710327
[10/23] Train loss=0.3622361421585083
[15/23] Train loss=0.3677116930484772
[20/23] Train loss=0.319865882396698
Test set avg_accuracy=80.22% avg_sensitivity=42.35%, avg_specificity=93.03% avg_auc=0.8404
Fold[1] Epoch: 27 [27/100 (27%)] Train loss=0.376107 Test loss=0.476585 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28245195746421814
[5/23] Train loss=0.40095728635787964
[10/23] Train loss=0.34034156799316406
[15/23] Train loss=0.35836294293403625
[20/23] Train loss=0.32662248611450195
Test set avg_accuracy=80.85% avg_sensitivity=45.36%, avg_specificity=92.87% avg_auc=0.8394
Fold[1] Epoch: 28 [28/100 (28%)] Train loss=0.372019 Test loss=0.467369 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3047659397125244
[5/23] Train loss=0.4058033227920532
[10/23] Train loss=0.3340417146682739
[15/23] Train loss=0.363935261964798
[20/23] Train loss=0.3174854815006256
Test set avg_accuracy=81.05% avg_sensitivity=50.53%, avg_specificity=91.38% avg_auc=0.8429
Best model saved!! Metric=-18.75040412984123!!
Fold[1] Epoch: 29 [29/100 (29%)] Train loss=0.368363 Test loss=0.444898 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2968129515647888
[5/23] Train loss=0.4081084430217743
[10/23] Train loss=0.3257911205291748
[15/23] Train loss=0.3493555784225464
[20/23] Train loss=0.3120519816875458
Test set avg_accuracy=81.19% avg_sensitivity=50.77%, avg_specificity=91.49% avg_auc=0.8459
Best model saved!! Metric=-17.955894871789315!!
Fold[1] Epoch: 30 [30/100 (30%)] Train loss=0.362929 Test loss=0.444399 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28124889731407166
[5/23] Train loss=0.40059107542037964
[10/23] Train loss=0.33858758211135864
[15/23] Train loss=0.34688055515289307
[20/23] Train loss=0.3081183135509491
Test set avg_accuracy=81.02% avg_sensitivity=47.31%, avg_specificity=92.43% avg_auc=0.8438
Fold[1] Epoch: 31 [31/100 (31%)] Train loss=0.362316 Test loss=0.457137 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.270244836807251
[5/23] Train loss=0.3972996771335602
[10/23] Train loss=0.3366614580154419
[15/23] Train loss=0.34694796800613403
[20/23] Train loss=0.30425187945365906
Test set avg_accuracy=80.62% avg_sensitivity=43.82%, avg_specificity=93.07% avg_auc=0.8391
Fold[1] Epoch: 32 [32/100 (32%)] Train loss=0.361602 Test loss=0.464777 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26992055773735046
[5/23] Train loss=0.40243014693260193
[10/23] Train loss=0.32091712951660156
[15/23] Train loss=0.33342382311820984
[20/23] Train loss=0.30706197023391724
Test set avg_accuracy=80.69% avg_sensitivity=49.02%, avg_specificity=91.41% avg_auc=0.8435
Fold[1] Epoch: 33 [33/100 (33%)] Train loss=0.359806 Test loss=0.456573 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27689671516418457
[5/23] Train loss=0.3955393135547638
[10/23] Train loss=0.32185351848602295
[15/23] Train loss=0.3438872992992401
[20/23] Train loss=0.31227031350135803
Test set avg_accuracy=80.86% avg_sensitivity=52.03%, avg_specificity=90.62% avg_auc=0.8466
Best model saved!! Metric=-17.816642285570477!!
Fold[1] Epoch: 34 [34/100 (34%)] Train loss=0.354532 Test loss=0.444005 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27713364362716675
[5/23] Train loss=0.3951769173145294
[10/23] Train loss=0.3206186592578888
[15/23] Train loss=0.33009207248687744
[20/23] Train loss=0.30036428570747375
Test set avg_accuracy=81.12% avg_sensitivity=51.55%, avg_specificity=91.13% avg_auc=0.8460
Best model saved!! Metric=-17.603547091940797!!
Fold[1] Epoch: 35 [35/100 (35%)] Train loss=0.354738 Test loss=0.446008 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2681184411048889
[5/23] Train loss=0.39334970712661743
[10/23] Train loss=0.3225749433040619
[15/23] Train loss=0.3276617228984833
[20/23] Train loss=0.30396178364753723
Test set avg_accuracy=80.92% avg_sensitivity=47.40%, avg_specificity=92.26% avg_auc=0.8409
Fold[1] Epoch: 36 [36/100 (36%)] Train loss=0.352454 Test loss=0.455376 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26847389340400696
[5/23] Train loss=0.390279620885849
[10/23] Train loss=0.31870120763778687
[15/23] Train loss=0.32462936639785767
[20/23] Train loss=0.2962954342365265
Test set avg_accuracy=81.34% avg_sensitivity=50.57%, avg_specificity=91.75% avg_auc=0.8441
Fold[1] Epoch: 37 [37/100 (37%)] Train loss=0.348732 Test loss=0.443595 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25744423270225525
[5/23] Train loss=0.38518354296684265
[10/23] Train loss=0.3161352276802063
[15/23] Train loss=0.3303101062774658
[20/23] Train loss=0.29207032918930054
Test set avg_accuracy=81.07% avg_sensitivity=49.27%, avg_specificity=91.83% avg_auc=0.8446
Fold[1] Epoch: 38 [38/100 (38%)] Train loss=0.345593 Test loss=0.451902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2594244182109833
[5/23] Train loss=0.3849163055419922
[10/23] Train loss=0.3119926154613495
[15/23] Train loss=0.32096612453460693
[20/23] Train loss=0.2941489815711975
Test set avg_accuracy=81.43% avg_sensitivity=54.80%, avg_specificity=90.44% avg_auc=0.8471
Best model saved!! Metric=-14.615515160466348!!
Fold[1] Epoch: 39 [39/100 (39%)] Train loss=0.342193 Test loss=0.440341 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2585597038269043
[5/23] Train loss=0.38636332750320435
[10/23] Train loss=0.31453263759613037
[15/23] Train loss=0.31730103492736816
[20/23] Train loss=0.28748852014541626
Test set avg_accuracy=81.15% avg_sensitivity=49.47%, avg_specificity=91.88% avg_auc=0.8418
Fold[1] Epoch: 40 [40/100 (40%)] Train loss=0.342264 Test loss=0.448364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2586066424846649
[5/23] Train loss=0.3824993073940277
[10/23] Train loss=0.3016042709350586
[15/23] Train loss=0.32074424624443054
[20/23] Train loss=0.2932831048965454
Test set avg_accuracy=81.27% avg_sensitivity=48.90%, avg_specificity=92.22% avg_auc=0.8413
Fold[1] Epoch: 41 [41/100 (41%)] Train loss=0.340050 Test loss=0.449882 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2432895302772522
[5/23] Train loss=0.38508787751197815
[10/23] Train loss=0.3073640763759613
[15/23] Train loss=0.3076007068157196
[20/23] Train loss=0.29262781143188477
Test set avg_accuracy=80.96% avg_sensitivity=48.82%, avg_specificity=91.83% avg_auc=0.8421
Fold[1] Epoch: 42 [42/100 (42%)] Train loss=0.336947 Test loss=0.455343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24739950895309448
[5/23] Train loss=0.3768523931503296
[10/23] Train loss=0.30005255341529846
[15/23] Train loss=0.30727341771125793
[20/23] Train loss=0.28997179865837097
Test set avg_accuracy=81.31% avg_sensitivity=50.49%, avg_specificity=91.74% avg_auc=0.8416
Fold[1] Epoch: 43 [43/100 (43%)] Train loss=0.335702 Test loss=0.452152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25701504945755005
[5/23] Train loss=0.38321730494499207
[10/23] Train loss=0.2918224036693573
[15/23] Train loss=0.3079011142253876
[20/23] Train loss=0.28444042801856995
Test set avg_accuracy=81.39% avg_sensitivity=56.35%, avg_specificity=89.87% avg_auc=0.8444
Best model saved!! Metric=-13.963070629757508!!
Fold[1] Epoch: 44 [44/100 (44%)] Train loss=0.331208 Test loss=0.440809 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24297599494457245
[5/23] Train loss=0.37014040350914
[10/23] Train loss=0.29504621028900146
[15/23] Train loss=0.3117006719112396
[20/23] Train loss=0.2779599726200104
Test set avg_accuracy=81.66% avg_sensitivity=53.01%, avg_specificity=91.35% avg_auc=0.8504
Fold[1] Epoch: 45 [45/100 (45%)] Train loss=0.326050 Test loss=0.452411 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.241023451089859
[5/23] Train loss=0.36659151315689087
[10/23] Train loss=0.28858327865600586
[15/23] Train loss=0.30397871136665344
[20/23] Train loss=0.27966633439064026
Test set avg_accuracy=81.80% avg_sensitivity=52.24%, avg_specificity=91.81% avg_auc=0.8476
Fold[1] Epoch: 46 [46/100 (46%)] Train loss=0.324541 Test loss=0.452059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24099943041801453
[5/23] Train loss=0.3693976402282715
[10/23] Train loss=0.2886548340320587
[15/23] Train loss=0.30700305104255676
[20/23] Train loss=0.26943838596343994
Test set avg_accuracy=81.91% avg_sensitivity=52.93%, avg_specificity=91.72% avg_auc=0.8490
Fold[1] Epoch: 47 [47/100 (47%)] Train loss=0.323048 Test loss=0.453482 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23244284093379974
[5/23] Train loss=0.36050188541412354
[10/23] Train loss=0.2902172803878784
[15/23] Train loss=0.30366867780685425
[20/23] Train loss=0.27117183804512024
Test set avg_accuracy=81.49% avg_sensitivity=45.57%, avg_specificity=93.65% avg_auc=0.8411
Fold[1] Epoch: 48 [48/100 (48%)] Train loss=0.322382 Test loss=0.455418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22433257102966309
[5/23] Train loss=0.36293825507164
[10/23] Train loss=0.2866319417953491
[15/23] Train loss=0.2859261929988861
[20/23] Train loss=0.2657069265842438
Test set avg_accuracy=81.42% avg_sensitivity=50.00%, avg_specificity=92.05% avg_auc=0.8462
Fold[1] Epoch: 49 [49/100 (49%)] Train loss=0.321328 Test loss=0.456473 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22718028724193573
[5/23] Train loss=0.3504175543785095
[10/23] Train loss=0.28830406069755554
[15/23] Train loss=0.2951982915401459
[20/23] Train loss=0.2680785655975342
Test set avg_accuracy=80.93% avg_sensitivity=42.60%, avg_specificity=93.90% avg_auc=0.8378
Fold[1] Epoch: 50 [50/100 (50%)] Train loss=0.319322 Test loss=0.473706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23487801849842072
[5/23] Train loss=0.3659021556377411
[10/23] Train loss=0.27953195571899414
[15/23] Train loss=0.29272666573524475
[20/23] Train loss=0.26681169867515564
Test set avg_accuracy=82.05% avg_sensitivity=57.32%, avg_specificity=90.42% avg_auc=0.8439
Best model saved!! Metric=-11.824916997341663!!
Fold[1] Epoch: 51 [51/100 (51%)] Train loss=0.317396 Test loss=0.455494 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23664875328540802
[5/23] Train loss=0.35948869585990906
[10/23] Train loss=0.28428158164024353
[15/23] Train loss=0.291574627161026
[20/23] Train loss=0.26338809728622437
Test set avg_accuracy=81.78% avg_sensitivity=53.34%, avg_specificity=91.41% avg_auc=0.8458
Fold[1] Epoch: 52 [52/100 (52%)] Train loss=0.310274 Test loss=0.461146 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22537703812122345
[5/23] Train loss=0.3558898866176605
[10/23] Train loss=0.27250486612319946
[15/23] Train loss=0.2907218337059021
[20/23] Train loss=0.26482269167900085
Test set avg_accuracy=82.19% avg_sensitivity=53.25%, avg_specificity=91.99% avg_auc=0.8436
Fold[1] Epoch: 53 [53/100 (53%)] Train loss=0.312163 Test loss=0.455452 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23420226573944092
[5/23] Train loss=0.3585328459739685
[10/23] Train loss=0.272860050201416
[15/23] Train loss=0.2914928197860718
[20/23] Train loss=0.2606610953807831
Test set avg_accuracy=81.62% avg_sensitivity=48.62%, avg_specificity=92.78% avg_auc=0.8426
Fold[1] Epoch: 54 [54/100 (54%)] Train loss=0.306887 Test loss=0.464253 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21405819058418274
[5/23] Train loss=0.35587283968925476
[10/23] Train loss=0.27565720677375793
[15/23] Train loss=0.27596139907836914
[20/23] Train loss=0.25497928261756897
Test set avg_accuracy=82.16% avg_sensitivity=53.09%, avg_specificity=92.00% avg_auc=0.8452
Fold[1] Epoch: 55 [55/100 (55%)] Train loss=0.305804 Test loss=0.467713 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2196141630411148
[5/23] Train loss=0.3571055233478546
[10/23] Train loss=0.26812219619750977
[15/23] Train loss=0.2754381597042084
[20/23] Train loss=0.25889015197753906
Test set avg_accuracy=81.47% avg_sensitivity=49.47%, avg_specificity=92.30% avg_auc=0.8417
Fold[1] Epoch: 56 [56/100 (56%)] Train loss=0.303721 Test loss=0.462198 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21997866034507751
[5/23] Train loss=0.3507022559642792
[10/23] Train loss=0.2844124436378479
[15/23] Train loss=0.2662537097930908
[20/23] Train loss=0.2660658061504364
Test set avg_accuracy=81.77% avg_sensitivity=51.22%, avg_specificity=92.11% avg_auc=0.8380
Fold[1] Epoch: 57 [57/100 (57%)] Train loss=0.304249 Test loss=0.465051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21408960223197937
[5/23] Train loss=0.34802186489105225
[10/23] Train loss=0.27233827114105225
[15/23] Train loss=0.27183663845062256
[20/23] Train loss=0.2620742917060852
Test set avg_accuracy=81.32% avg_sensitivity=49.06%, avg_specificity=92.23% avg_auc=0.8372
Fold[1] Epoch: 58 [58/100 (58%)] Train loss=0.302180 Test loss=0.477051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21421271562576294
[5/23] Train loss=0.3563234806060791
[10/23] Train loss=0.264186829328537
[15/23] Train loss=0.2615770697593689
[20/23] Train loss=0.2529153823852539
Test set avg_accuracy=82.52% avg_sensitivity=58.67%, avg_specificity=90.59% avg_auc=0.8435
Best model saved!! Metric=-9.87018104271213!!
Fold[1] Epoch: 59 [59/100 (59%)] Train loss=0.296926 Test loss=0.464621 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20978035032749176
[5/23] Train loss=0.35277292132377625
[10/23] Train loss=0.2693430185317993
[15/23] Train loss=0.26967093348503113
[20/23] Train loss=0.2521134316921234
Test set avg_accuracy=82.11% avg_sensitivity=53.99%, avg_specificity=91.63% avg_auc=0.8451
Fold[1] Epoch: 60 [60/100 (60%)] Train loss=0.296326 Test loss=0.470136 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2221693992614746
[5/23] Train loss=0.3345736563205719
[10/23] Train loss=0.2694895267486572
[15/23] Train loss=0.2669925093650818
[20/23] Train loss=0.2436811476945877
Test set avg_accuracy=81.47% avg_sensitivity=49.15%, avg_specificity=92.41% avg_auc=0.8391
Fold[1] Epoch: 61 [61/100 (61%)] Train loss=0.291238 Test loss=0.480641 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20015154778957367
[5/23] Train loss=0.33692240715026855
[10/23] Train loss=0.25794896483421326
[15/23] Train loss=0.2600773572921753
[20/23] Train loss=0.24378623068332672
Test set avg_accuracy=81.72% avg_sensitivity=47.60%, avg_specificity=93.27% avg_auc=0.8393
Fold[1] Epoch: 62 [62/100 (62%)] Train loss=0.290631 Test loss=0.480869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20507873594760895
[5/23] Train loss=0.3333345055580139
[10/23] Train loss=0.274837851524353
[15/23] Train loss=0.25883591175079346
[20/23] Train loss=0.2492426186800003
Test set avg_accuracy=81.78% avg_sensitivity=50.37%, avg_specificity=92.41% avg_auc=0.8385
Fold[1] Epoch: 63 [63/100 (63%)] Train loss=0.289743 Test loss=0.467641 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1943911761045456
[5/23] Train loss=0.3347930312156677
[10/23] Train loss=0.2620926797389984
[15/23] Train loss=0.25365564227104187
[20/23] Train loss=0.24620820581912994
Test set avg_accuracy=81.51% avg_sensitivity=46.62%, avg_specificity=93.32% avg_auc=0.8388
Fold[1] Epoch: 64 [64/100 (64%)] Train loss=0.286736 Test loss=0.473944 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19984132051467896
[5/23] Train loss=0.33979204297065735
[10/23] Train loss=0.2652854025363922
[15/23] Train loss=0.25312182307243347
[20/23] Train loss=0.24067410826683044
Test set avg_accuracy=82.44% avg_sensitivity=57.69%, avg_specificity=90.82% avg_auc=0.8450
Fold[1] Epoch: 65 [65/100 (65%)] Train loss=0.285402 Test loss=0.469515 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19734710454940796
[5/23] Train loss=0.3353935182094574
[10/23] Train loss=0.24978458881378174
[15/23] Train loss=0.2537158131599426
[20/23] Train loss=0.23619218170642853
Test set avg_accuracy=81.49% avg_sensitivity=55.00%, avg_specificity=90.46% avg_auc=0.8401
Fold[1] Epoch: 66 [66/100 (66%)] Train loss=0.279408 Test loss=0.475261 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19514968991279602
[5/23] Train loss=0.3254069685935974
[10/23] Train loss=0.2638315260410309
[15/23] Train loss=0.24149653315544128
[20/23] Train loss=0.23455937206745148
Test set avg_accuracy=81.94% avg_sensitivity=52.52%, avg_specificity=91.90% avg_auc=0.8291
Fold[1] Epoch: 67 [67/100 (67%)] Train loss=0.276082 Test loss=0.483295 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19228291511535645
[5/23] Train loss=0.3324662744998932
[10/23] Train loss=0.24481210112571716
[15/23] Train loss=0.24547259509563446
[20/23] Train loss=0.23532584309577942
Test set avg_accuracy=82.29% avg_sensitivity=52.36%, avg_specificity=92.43% avg_auc=0.8402
Fold[1] Epoch: 68 [68/100 (68%)] Train loss=0.275670 Test loss=0.488390 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18410034477710724
[5/23] Train loss=0.32442888617515564
[10/23] Train loss=0.2528593838214874
[15/23] Train loss=0.24902351200580597
[20/23] Train loss=0.2352725863456726
Test set avg_accuracy=81.93% avg_sensitivity=52.48%, avg_specificity=91.90% avg_auc=0.8287
Fold[1] Epoch: 69 [69/100 (69%)] Train loss=0.273394 Test loss=0.486344 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1845140904188156
[5/23] Train loss=0.3277216851711273
[10/23] Train loss=0.24607789516448975
[15/23] Train loss=0.24010372161865234
[20/23] Train loss=0.22610554099082947
Test set avg_accuracy=82.31% avg_sensitivity=56.51%, avg_specificity=91.05% avg_auc=0.8335
Fold[1] Epoch: 70 [70/100 (70%)] Train loss=0.269457 Test loss=0.480127 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18839669227600098
[5/23] Train loss=0.3228268027305603
[10/23] Train loss=0.2496083527803421
[15/23] Train loss=0.24643144011497498
[20/23] Train loss=0.23124508559703827
Test set avg_accuracy=81.78% avg_sensitivity=51.83%, avg_specificity=91.92% avg_auc=0.8383
Fold[1] Epoch: 71 [71/100 (71%)] Train loss=0.270060 Test loss=0.488156 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18132296204566956
[5/23] Train loss=0.31743764877319336
[10/23] Train loss=0.24512851238250732
[15/23] Train loss=0.2324381172657013
[20/23] Train loss=0.2277100831270218
Test set avg_accuracy=82.11% avg_sensitivity=54.80%, avg_specificity=91.35% avg_auc=0.8362
Fold[1] Epoch: 72 [72/100 (72%)] Train loss=0.265593 Test loss=0.490522 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1753353476524353
[5/23] Train loss=0.323030561208725
[10/23] Train loss=0.2406494915485382
[15/23] Train loss=0.22199395298957825
[20/23] Train loss=0.23216509819030762
Test set avg_accuracy=81.86% avg_sensitivity=54.76%, avg_specificity=91.04% avg_auc=0.8254
Fold[1] Epoch: 73 [73/100 (73%)] Train loss=0.264767 Test loss=0.505348 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1854269802570343
[5/23] Train loss=0.3086548149585724
[10/23] Train loss=0.23624026775360107
[15/23] Train loss=0.25214239954948425
[20/23] Train loss=0.2238902449607849
Test set avg_accuracy=82.16% avg_sensitivity=56.75%, avg_specificity=90.76% avg_auc=0.8309
Fold[1] Epoch: 74 [74/100 (74%)] Train loss=0.259711 Test loss=0.500893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1816847324371338
[5/23] Train loss=0.31721973419189453
[10/23] Train loss=0.24449506402015686
[15/23] Train loss=0.23307804763317108
[20/23] Train loss=0.21379363536834717
Test set avg_accuracy=81.47% avg_sensitivity=51.59%, avg_specificity=91.59% avg_auc=0.8275
Fold[1] Epoch: 75 [75/100 (75%)] Train loss=0.257390 Test loss=0.511793 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1808282881975174
[5/23] Train loss=0.31707763671875
[10/23] Train loss=0.23718833923339844
[15/23] Train loss=0.23340864479541779
[20/23] Train loss=0.21258363127708435
Test set avg_accuracy=81.85% avg_sensitivity=57.28%, avg_specificity=90.17% avg_auc=0.8303
Fold[1] Epoch: 76 [76/100 (76%)] Train loss=0.255575 Test loss=0.504514 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18069183826446533
[5/23] Train loss=0.3069043457508087
[10/23] Train loss=0.23878541588783264
[15/23] Train loss=0.22750402987003326
[20/23] Train loss=0.21476054191589355
Test set avg_accuracy=81.69% avg_sensitivity=51.87%, avg_specificity=91.78% avg_auc=0.8350
Fold[1] Epoch: 77 [77/100 (77%)] Train loss=0.257531 Test loss=0.499340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18541015684604645
[5/23] Train loss=0.3112337589263916
[10/23] Train loss=0.23546576499938965
[15/23] Train loss=0.24471727013587952
[20/23] Train loss=0.2231687307357788
Test set avg_accuracy=82.28% avg_sensitivity=54.96%, avg_specificity=91.53% avg_auc=0.8297
Fold[1] Epoch: 78 [78/100 (78%)] Train loss=0.256334 Test loss=0.502325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16891808807849884
[5/23] Train loss=0.2992458641529083
[10/23] Train loss=0.23861800134181976
[15/23] Train loss=0.21574324369430542
[20/23] Train loss=0.2235672026872635
Test set avg_accuracy=81.19% avg_sensitivity=44.75%, avg_specificity=93.53% avg_auc=0.8331
Fold[1] Epoch: 79 [79/100 (79%)] Train loss=0.254355 Test loss=0.527457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16740107536315918
[5/23] Train loss=0.29407522082328796
[10/23] Train loss=0.25774648785591125
[15/23] Train loss=0.21619556844234467
[20/23] Train loss=0.22169725596904755
Test set avg_accuracy=81.34% avg_sensitivity=45.48%, avg_specificity=93.47% avg_auc=0.8289
Fold[1] Epoch: 80 [80/100 (80%)] Train loss=0.256964 Test loss=0.510324 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17630721628665924
[5/23] Train loss=0.3113633096218109
[10/23] Train loss=0.24600864946842194
[15/23] Train loss=0.21644851565361023
[20/23] Train loss=0.21722349524497986
Test set avg_accuracy=81.60% avg_sensitivity=51.34%, avg_specificity=91.85% avg_auc=0.8267
Fold[1] Epoch: 81 [81/100 (81%)] Train loss=0.253666 Test loss=0.513796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16134107112884521
[5/23] Train loss=0.2981944680213928
[10/23] Train loss=0.227382630109787
[15/23] Train loss=0.2256982922554016
[20/23] Train loss=0.227229043841362
Test set avg_accuracy=81.62% avg_sensitivity=52.03%, avg_specificity=91.63% avg_auc=0.8292
Fold[1] Epoch: 82 [82/100 (82%)] Train loss=0.249514 Test loss=0.524544 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16408969461917877
[5/23] Train loss=0.2948686182498932
[10/23] Train loss=0.21899548172950745
[15/23] Train loss=0.21860121190547943
[20/23] Train loss=0.20876997709274292
Test set avg_accuracy=81.47% avg_sensitivity=54.31%, avg_specificity=90.66% avg_auc=0.8245
Fold[1] Epoch: 83 [83/100 (83%)] Train loss=0.243417 Test loss=0.531974 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15983951091766357
[5/23] Train loss=0.2897091805934906
[10/23] Train loss=0.22494058310985565
[15/23] Train loss=0.2126423865556717
[20/23] Train loss=0.20726273953914642
Test set avg_accuracy=81.40% avg_sensitivity=53.70%, avg_specificity=90.77% avg_auc=0.8253
Fold[1] Epoch: 84 [84/100 (84%)] Train loss=0.240184 Test loss=0.528418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15455380082130432
[5/23] Train loss=0.29499194025993347
[10/23] Train loss=0.22113828361034393
[15/23] Train loss=0.21763910353183746
[20/23] Train loss=0.2129376232624054
Test set avg_accuracy=81.80% avg_sensitivity=51.26%, avg_specificity=92.14% avg_auc=0.8297
Fold[1] Epoch: 85 [85/100 (85%)] Train loss=0.237015 Test loss=0.526512 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15124760568141937
[5/23] Train loss=0.28163009881973267
[10/23] Train loss=0.21924805641174316
[15/23] Train loss=0.21896234154701233
[20/23] Train loss=0.1975407898426056
Test set avg_accuracy=81.55% avg_sensitivity=50.77%, avg_specificity=91.97% avg_auc=0.8272
Fold[1] Epoch: 86 [86/100 (86%)] Train loss=0.234120 Test loss=0.540048 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15391989052295685
[5/23] Train loss=0.2942419946193695
[10/23] Train loss=0.2175632119178772
[15/23] Train loss=0.2144448459148407
[20/23] Train loss=0.20332883298397064
Test set avg_accuracy=81.62% avg_sensitivity=59.56%, avg_specificity=89.08% avg_auc=0.8239
Fold[1] Epoch: 87 [87/100 (87%)] Train loss=0.237016 Test loss=0.536794 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16053174436092377
[5/23] Train loss=0.281855970621109
[10/23] Train loss=0.22046120464801788
[15/23] Train loss=0.2111799716949463
[20/23] Train loss=0.20293575525283813
Test set avg_accuracy=81.75% avg_sensitivity=52.40%, avg_specificity=91.68% avg_auc=0.8278
Fold[1] Epoch: 88 [88/100 (88%)] Train loss=0.235235 Test loss=0.539925 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15084342658519745
[5/23] Train loss=0.28490936756134033
[10/23] Train loss=0.22241909801959991
[15/23] Train loss=0.20458540320396423
[20/23] Train loss=0.19744960963726044
Test set avg_accuracy=81.47% avg_sensitivity=47.97%, avg_specificity=92.81% avg_auc=0.8286
Fold[1] Epoch: 89 [89/100 (89%)] Train loss=0.230148 Test loss=0.553462 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1409813016653061
[5/23] Train loss=0.2811650335788727
[10/23] Train loss=0.20916582643985748
[15/23] Train loss=0.20221830904483795
[20/23] Train loss=0.20109955966472626
Test set avg_accuracy=81.21% avg_sensitivity=43.65%, avg_specificity=93.93% avg_auc=0.8305
Fold[1] Epoch: 90 [90/100 (90%)] Train loss=0.234136 Test loss=0.560943 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14544673264026642
[5/23] Train loss=0.28656211495399475
[10/23] Train loss=0.23439809679985046
[15/23] Train loss=0.21408961713314056
[20/23] Train loss=0.1958385556936264
Test set avg_accuracy=81.72% avg_sensitivity=51.71%, avg_specificity=91.88% avg_auc=0.8198
Fold[1] Epoch: 91 [91/100 (91%)] Train loss=0.236077 Test loss=0.527808 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1394197642803192
[5/23] Train loss=0.28600814938545227
[10/23] Train loss=0.2087283730506897
[15/23] Train loss=0.19322088360786438
[20/23] Train loss=0.20374470949172974
Test set avg_accuracy=81.21% avg_sensitivity=51.06%, avg_specificity=91.42% avg_auc=0.8149
Fold[1] Epoch: 92 [92/100 (92%)] Train loss=0.230661 Test loss=0.538009 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15423713624477386
[5/23] Train loss=0.2683911919593811
[10/23] Train loss=0.2064719796180725
[15/23] Train loss=0.2010239213705063
[20/23] Train loss=0.1978994458913803
Test set avg_accuracy=81.20% avg_sensitivity=53.50%, avg_specificity=90.58% avg_auc=0.8238
Fold[1] Epoch: 93 [93/100 (93%)] Train loss=0.225946 Test loss=0.543251 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14415572583675385
[5/23] Train loss=0.27835214138031006
[10/23] Train loss=0.20650193095207214
[15/23] Train loss=0.18610255420207977
[20/23] Train loss=0.18851973116397858
Test set avg_accuracy=81.58% avg_sensitivity=53.74%, avg_specificity=91.01% avg_auc=0.8311
Fold[1] Epoch: 94 [94/100 (94%)] Train loss=0.218126 Test loss=0.553574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14894358813762665
[5/23] Train loss=0.2703501880168915
[10/23] Train loss=0.20636579394340515
[15/23] Train loss=0.1978973001241684
[20/23] Train loss=0.18661029636859894
Test set avg_accuracy=82.10% avg_sensitivity=55.66%, avg_specificity=91.05% avg_auc=0.8283
Fold[1] Epoch: 95 [95/100 (95%)] Train loss=0.218170 Test loss=0.544881 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1358899474143982
[5/23] Train loss=0.2726525664329529
[10/23] Train loss=0.1939857006072998
[15/23] Train loss=0.18849393725395203
[20/23] Train loss=0.18304164707660675
Test set avg_accuracy=81.31% avg_sensitivity=51.79%, avg_specificity=91.30% avg_auc=0.8283
Fold[1] Epoch: 96 [96/100 (96%)] Train loss=0.213666 Test loss=0.561592 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13726702332496643
[5/23] Train loss=0.2683783173561096
[10/23] Train loss=0.20153409242630005
[15/23] Train loss=0.18536752462387085
[20/23] Train loss=0.17888987064361572
Test set avg_accuracy=81.71% avg_sensitivity=53.05%, avg_specificity=91.41% avg_auc=0.8265
Fold[1] Epoch: 97 [97/100 (97%)] Train loss=0.212988 Test loss=0.573339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12246177345514297
[5/23] Train loss=0.2568439543247223
[10/23] Train loss=0.19814379513263702
[15/23] Train loss=0.18596594035625458
[20/23] Train loss=0.1829889714717865
Test set avg_accuracy=81.24% avg_sensitivity=49.06%, avg_specificity=92.14% avg_auc=0.8230
Fold[1] Epoch: 98 [98/100 (98%)] Train loss=0.209490 Test loss=0.569613 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12568996846675873
[5/23] Train loss=0.2538990080356598
[10/23] Train loss=0.21286427974700928
[15/23] Train loss=0.1795974224805832
[20/23] Train loss=0.1833023875951767
Test set avg_accuracy=81.63% avg_sensitivity=51.18%, avg_specificity=91.93% avg_auc=0.8280
Fold[1] Epoch: 99 [99/100 (99%)] Train loss=0.216883 Test loss=0.579301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13111531734466553
[5/23] Train loss=0.267145037651062
[10/23] Train loss=0.20240457355976105
[15/23] Train loss=0.1964046061038971
[20/23] Train loss=0.17266273498535156
Test set avg_accuracy=81.74% avg_sensitivity=49.31%, avg_specificity=92.72% avg_auc=0.8328
Fold[1] Epoch: 100 [100/100 (100%)] Train loss=0.215751 Test loss=0.563945 Current lr=[3.9999999999999996e-05]

Fold[1] Best Result: acc=82.52057613168724 sen=58.665581773799836, spe=90.59487744423024, auc=0.8434878360757057!
[0/23] Train loss=0.677772581577301
[5/23] Train loss=0.6287102699279785
[10/23] Train loss=0.5599055290222168
[15/23] Train loss=0.5592868328094482
[20/23] Train loss=0.5313394665718079
Test set avg_accuracy=76.92% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5795
Best model saved!! Metric=-91.12591399589618!!
Fold[2] Epoch: 1 [1/100 (1%)] Train loss=0.572672 Test loss=0.550692 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5558400750160217
[5/23] Train loss=0.5926368236541748
[10/23] Train loss=0.5391321182250977
[15/23] Train loss=0.5412570238113403
[20/23] Train loss=0.49823102355003357
Test set avg_accuracy=76.97% avg_sensitivity=2.53%, avg_specificity=99.31% avg_auc=0.6280
Best model saved!! Metric=-84.38752425789255!!
Fold[2] Epoch: 2 [2/100 (2%)] Train loss=0.541818 Test loss=0.558521 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5446232557296753
[5/23] Train loss=0.5582165122032166
[10/23] Train loss=0.5131747722625732
[15/23] Train loss=0.5287889242172241
[20/23] Train loss=0.4650317430496216
Test set avg_accuracy=77.35% avg_sensitivity=8.73%, avg_specificity=97.94% avg_auc=0.6796
Best model saved!! Metric=-74.02779728415163!!
Fold[2] Epoch: 3 [3/100 (3%)] Train loss=0.518522 Test loss=0.569958 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.52805095911026
[5/23] Train loss=0.521199643611908
[10/23] Train loss=0.47879382967948914
[15/23] Train loss=0.4962693452835083
[20/23] Train loss=0.4273638427257538
Test set avg_accuracy=77.83% avg_sensitivity=14.33%, avg_specificity=96.88% avg_auc=0.7040
Best model saved!! Metric=-66.5554950357942!!
Fold[2] Epoch: 4 [4/100 (4%)] Train loss=0.489937 Test loss=0.588197 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5019891858100891
[5/23] Train loss=0.4935968518257141
[10/23] Train loss=0.4602969288825989
[15/23] Train loss=0.4896661937236786
[20/23] Train loss=0.4127754867076874
Test set avg_accuracy=78.35% avg_sensitivity=18.08%, avg_specificity=96.43% avg_auc=0.7189
Best model saved!! Metric=-61.24366415419125!!
Fold[2] Epoch: 5 [5/100 (5%)] Train loss=0.471597 Test loss=0.563016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4705808758735657
[5/23] Train loss=0.46818938851356506
[10/23] Train loss=0.44140419363975525
[15/23] Train loss=0.46667101979255676
[20/23] Train loss=0.3955177068710327
Test set avg_accuracy=78.73% avg_sensitivity=21.70%, avg_specificity=95.84% avg_auc=0.7364
Best model saved!! Metric=-56.094419368405084!!
Fold[2] Epoch: 6 [6/100 (6%)] Train loss=0.454197 Test loss=0.574567 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44339656829833984
[5/23] Train loss=0.45169147849082947
[10/23] Train loss=0.44452765583992004
[15/23] Train loss=0.46903350949287415
[20/23] Train loss=0.3926117420196533
Test set avg_accuracy=79.01% avg_sensitivity=25.05%, avg_specificity=95.20% avg_auc=0.7515
Best model saved!! Metric=-51.60001969085788!!
Fold[2] Epoch: 7 [7/100 (7%)] Train loss=0.446038 Test loss=0.563345 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43337664008140564
[5/23] Train loss=0.4481094181537628
[10/23] Train loss=0.42669427394866943
[15/23] Train loss=0.4376910924911499
[20/23] Train loss=0.3839380145072937
Test set avg_accuracy=79.42% avg_sensitivity=25.99%, avg_specificity=95.44% avg_auc=0.7572
Best model saved!! Metric=-49.42967412579809!!
Fold[2] Epoch: 8 [8/100 (8%)] Train loss=0.438362 Test loss=0.550851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42804187536239624
[5/23] Train loss=0.43982967734336853
[10/23] Train loss=0.40086641907691956
[15/23] Train loss=0.42128247022628784
[20/23] Train loss=0.374403178691864
Test set avg_accuracy=79.26% avg_sensitivity=27.85%, avg_specificity=94.68% avg_auc=0.7736
Best model saved!! Metric=-46.845078350057186!!
Fold[2] Epoch: 9 [9/100 (9%)] Train loss=0.427577 Test loss=0.519516 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41317763924598694
[5/23] Train loss=0.43655240535736084
[10/23] Train loss=0.38768842816352844
[15/23] Train loss=0.4266971945762634
[20/23] Train loss=0.37389376759529114
Test set avg_accuracy=79.52% avg_sensitivity=32.01%, avg_specificity=93.77% avg_auc=0.7848
Best model saved!! Metric=-42.22128778254712!!
Fold[2] Epoch: 10 [10/100 (10%)] Train loss=0.419553 Test loss=0.505064 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4120491147041321
[5/23] Train loss=0.43096989393234253
[10/23] Train loss=0.4012888967990875
[15/23] Train loss=0.4142744243144989
[20/23] Train loss=0.3659496009349823
Test set avg_accuracy=79.59% avg_sensitivity=32.01%, avg_specificity=93.87% avg_auc=0.7831
Best model saved!! Metric=-42.216642240604145!!
Fold[2] Epoch: 11 [11/100 (11%)] Train loss=0.415762 Test loss=0.515880 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4103972911834717
[5/23] Train loss=0.43425580859184265
[10/23] Train loss=0.4181516468524933
[15/23] Train loss=0.4206315577030182
[20/23] Train loss=0.3618351221084595
Test set avg_accuracy=79.79% avg_sensitivity=31.42%, avg_specificity=94.30% avg_auc=0.7811
Fold[2] Epoch: 12 [12/100 (12%)] Train loss=0.416820 Test loss=0.520778 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40625858306884766
[5/23] Train loss=0.42085933685302734
[10/23] Train loss=0.39980489015579224
[15/23] Train loss=0.4007011353969574
[20/23] Train loss=0.35806843638420105
Test set avg_accuracy=79.93% avg_sensitivity=32.41%, avg_specificity=94.18% avg_auc=0.7867
Best model saved!! Metric=-40.81044569886174!!
Fold[2] Epoch: 13 [13/100 (13%)] Train loss=0.411577 Test loss=0.516071 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4020983874797821
[5/23] Train loss=0.4291928708553314
[10/23] Train loss=0.36887723207473755
[15/23] Train loss=0.40532612800598145
[20/23] Train loss=0.35663536190986633
Test set avg_accuracy=79.66% avg_sensitivity=34.86%, avg_specificity=93.10% avg_auc=0.7984
Best model saved!! Metric=-38.55119163962191!!
Fold[2] Epoch: 14 [14/100 (14%)] Train loss=0.405750 Test loss=0.479307 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4032188653945923
[5/23] Train loss=0.41995328664779663
[10/23] Train loss=0.3670482337474823
[15/23] Train loss=0.3953498899936676
[20/23] Train loss=0.3534562587738037
Test set avg_accuracy=80.00% avg_sensitivity=37.07%, avg_specificity=92.88% avg_auc=0.8096
Best model saved!! Metric=-35.086021795471446!!
Fold[2] Epoch: 15 [15/100 (15%)] Train loss=0.399556 Test loss=0.470278 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4014344811439514
[5/23] Train loss=0.41684097051620483
[10/23] Train loss=0.36916378140449524
[15/23] Train loss=0.39884862303733826
[20/23] Train loss=0.349656879901886
Test set avg_accuracy=80.15% avg_sensitivity=36.66%, avg_specificity=93.19% avg_auc=0.8041
Fold[2] Epoch: 16 [16/100 (16%)] Train loss=0.397702 Test loss=0.473746 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39279043674468994
[5/23] Train loss=0.41514113545417786
[10/23] Train loss=0.39054396748542786
[15/23] Train loss=0.38986748456954956
[20/23] Train loss=0.35013827681541443
Test set avg_accuracy=80.05% avg_sensitivity=35.35%, avg_specificity=93.46% avg_auc=0.7990
Fold[2] Epoch: 17 [17/100 (17%)] Train loss=0.397472 Test loss=0.482087 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3900415003299713
[5/23] Train loss=0.4191671311855316
[10/23] Train loss=0.37386006116867065
[15/23] Train loss=0.384939581155777
[20/23] Train loss=0.3426382541656494
Test set avg_accuracy=79.74% avg_sensitivity=32.82%, avg_specificity=93.82% avg_auc=0.7976
Fold[2] Epoch: 18 [18/100 (18%)] Train loss=0.397083 Test loss=0.489964 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3835424482822418
[5/23] Train loss=0.41631975769996643
[10/23] Train loss=0.3688586950302124
[15/23] Train loss=0.3853728175163269
[20/23] Train loss=0.3498108685016632
Test set avg_accuracy=79.80% avg_sensitivity=35.76%, avg_specificity=93.02% avg_auc=0.8114
Fold[2] Epoch: 19 [19/100 (19%)] Train loss=0.393331 Test loss=0.476189 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3874855041503906
[5/23] Train loss=0.4135805368423462
[10/23] Train loss=0.36407437920570374
[15/23] Train loss=0.39202094078063965
[20/23] Train loss=0.3436664342880249
Test set avg_accuracy=79.79% avg_sensitivity=37.79%, avg_specificity=92.39% avg_auc=0.8215
Best model saved!! Metric=-33.87052935548795!!
Fold[2] Epoch: 20 [20/100 (20%)] Train loss=0.387443 Test loss=0.456844 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38651734590530396
[5/23] Train loss=0.40805596113204956
[10/23] Train loss=0.3726581037044525
[15/23] Train loss=0.3782728910446167
[20/23] Train loss=0.33581823110580444
Test set avg_accuracy=80.13% avg_sensitivity=36.84%, avg_specificity=93.11% avg_auc=0.8223
Best model saved!! Metric=-33.68738186937566!!
Fold[2] Epoch: 21 [21/100 (21%)] Train loss=0.387015 Test loss=0.468028 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37415799498558044
[5/23] Train loss=0.4015235900878906
[10/23] Train loss=0.36449742317199707
[15/23] Train loss=0.368319034576416
[20/23] Train loss=0.3303549289703369
Test set avg_accuracy=79.75% avg_sensitivity=33.50%, avg_specificity=93.63% avg_auc=0.8143
Fold[2] Epoch: 22 [22/100 (22%)] Train loss=0.384116 Test loss=0.489853 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3727777600288391
[5/23] Train loss=0.4018810987472534
[10/23] Train loss=0.338913232088089
[15/23] Train loss=0.3726238012313843
[20/23] Train loss=0.3315260112285614
Test set avg_accuracy=80.42% avg_sensitivity=38.88%, avg_specificity=92.88% avg_auc=0.8139
Best model saved!! Metric=-32.43106863701125!!
Fold[2] Epoch: 23 [23/100 (23%)] Train loss=0.379982 Test loss=0.473927 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3707006573677063
[5/23] Train loss=0.4042002260684967
[10/23] Train loss=0.33574193716049194
[15/23] Train loss=0.36652565002441406
[20/23] Train loss=0.3263607621192932
Test set avg_accuracy=80.61% avg_sensitivity=42.41%, avg_specificity=92.07% avg_auc=0.8260
Best model saved!! Metric=-28.3250734673894!!
Fold[2] Epoch: 24 [24/100 (24%)] Train loss=0.373180 Test loss=0.446812 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3840743899345398
[5/23] Train loss=0.4041961431503296
[10/23] Train loss=0.34237706661224365
[15/23] Train loss=0.3578398525714874
[20/23] Train loss=0.322517067193985
Test set avg_accuracy=80.45% avg_sensitivity=41.95%, avg_specificity=92.00% avg_auc=0.8365
Best model saved!! Metric=-27.9517709617271!!
Fold[2] Epoch: 25 [25/100 (25%)] Train loss=0.372492 Test loss=0.429135 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37432244420051575
[5/23] Train loss=0.39957529306411743
[10/23] Train loss=0.34955060482025146
[15/23] Train loss=0.35586750507354736
[20/23] Train loss=0.32293757796287537
Test set avg_accuracy=80.41% avg_sensitivity=38.43%, avg_specificity=93.00% avg_auc=0.8305
Fold[2] Epoch: 26 [26/100 (26%)] Train loss=0.370864 Test loss=0.449978 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36590853333473206
[5/23] Train loss=0.3998129367828369
[10/23] Train loss=0.3375855088233948
[15/23] Train loss=0.3504127860069275
[20/23] Train loss=0.31495916843414307
Test set avg_accuracy=80.20% avg_sensitivity=36.75%, avg_specificity=93.23% avg_auc=0.8263
Fold[2] Epoch: 27 [27/100 (27%)] Train loss=0.368072 Test loss=0.462332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36008843779563904
[5/23] Train loss=0.3967818021774292
[10/23] Train loss=0.3286072611808777
[15/23] Train loss=0.3496015965938568
[20/23] Train loss=0.3164834976196289
Test set avg_accuracy=80.04% avg_sensitivity=39.56%, avg_specificity=92.19% avg_auc=0.8285
Fold[2] Epoch: 28 [28/100 (28%)] Train loss=0.365080 Test loss=0.457291 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3666258156299591
[5/23] Train loss=0.39560526609420776
[10/23] Train loss=0.3259464204311371
[15/23] Train loss=0.34015077352523804
[20/23] Train loss=0.3140128552913666
Test set avg_accuracy=81.01% avg_sensitivity=44.71%, avg_specificity=91.90% avg_auc=0.8378
Best model saved!! Metric=-24.598603570086624!!
Fold[2] Epoch: 29 [29/100 (29%)] Train loss=0.361373 Test loss=0.429455 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3632014989852905
[5/23] Train loss=0.3919897973537445
[10/23] Train loss=0.32545775175094604
[15/23] Train loss=0.3438437283039093
[20/23] Train loss=0.30815133452415466
Test set avg_accuracy=80.48% avg_sensitivity=40.78%, avg_specificity=92.39% avg_auc=0.8311
Fold[2] Epoch: 30 [30/100 (30%)] Train loss=0.357141 Test loss=0.452069 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3511200249195099
[5/23] Train loss=0.3896464705467224
[10/23] Train loss=0.3164541721343994
[15/23] Train loss=0.3439484238624573
[20/23] Train loss=0.3023732006549835
Test set avg_accuracy=81.06% avg_sensitivity=44.98%, avg_specificity=91.89% avg_auc=0.8380
Best model saved!! Metric=-24.265791315442588!!
Fold[2] Epoch: 31 [31/100 (31%)] Train loss=0.354857 Test loss=0.430859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3564718961715698
[5/23] Train loss=0.39027997851371765
[10/23] Train loss=0.31785503029823303
[15/23] Train loss=0.3379461467266083
[20/23] Train loss=0.3029481768608093
Test set avg_accuracy=81.06% avg_sensitivity=44.08%, avg_specificity=92.16% avg_auc=0.8396
Fold[2] Epoch: 32 [32/100 (32%)] Train loss=0.353224 Test loss=0.429260 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3488062620162964
[5/23] Train loss=0.38513800501823425
[10/23] Train loss=0.31979629397392273
[15/23] Train loss=0.34846702218055725
[20/23] Train loss=0.3049028813838959
Test set avg_accuracy=80.77% avg_sensitivity=41.86%, avg_specificity=92.45% avg_auc=0.8361
Fold[2] Epoch: 33 [33/100 (33%)] Train loss=0.353506 Test loss=0.439326 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35519441962242126
[5/23] Train loss=0.3826594054698944
[10/23] Train loss=0.3165149986743927
[15/23] Train loss=0.3346683084964752
[20/23] Train loss=0.2954281270503998
Test set avg_accuracy=80.77% avg_sensitivity=42.95%, avg_specificity=92.12% avg_auc=0.8372
Fold[2] Epoch: 34 [34/100 (34%)] Train loss=0.348751 Test loss=0.438290 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3436368703842163
[5/23] Train loss=0.3864434063434601
[10/23] Train loss=0.3395894467830658
[15/23] Train loss=0.3934851288795471
[20/23] Train loss=0.32140278816223145
Test set avg_accuracy=79.98% avg_sensitivity=27.85%, avg_specificity=95.62% avg_auc=0.8102
Fold[2] Epoch: 35 [35/100 (35%)] Train loss=0.368637 Test loss=0.513187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3558318316936493
[5/23] Train loss=0.3944728374481201
[10/23] Train loss=0.31816717982292175
[15/23] Train loss=0.3518872559070587
[20/23] Train loss=0.294057697057724
Test set avg_accuracy=80.75% avg_sensitivity=49.95%, avg_specificity=89.99% avg_auc=0.8417
Best model saved!! Metric=-21.137745442600103!!
Fold[2] Epoch: 36 [36/100 (36%)] Train loss=0.362205 Test loss=0.417264 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3465500771999359
[5/23] Train loss=0.385317325592041
[10/23] Train loss=0.32235994935035706
[15/23] Train loss=0.3476705253124237
[20/23] Train loss=0.3105506896972656
Test set avg_accuracy=80.81% avg_sensitivity=46.65%, avg_specificity=91.06% avg_auc=0.8442
Fold[2] Epoch: 37 [37/100 (37%)] Train loss=0.352118 Test loss=0.419751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3499037027359009
[5/23] Train loss=0.40214574337005615
[10/23] Train loss=0.3194056749343872
[15/23] Train loss=0.3349892497062683
[20/23] Train loss=0.2981971800327301
Test set avg_accuracy=81.16% avg_sensitivity=44.03%, avg_specificity=92.30% avg_auc=0.8394
Fold[2] Epoch: 38 [38/100 (38%)] Train loss=0.351132 Test loss=0.436564 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34052544832229614
[5/23] Train loss=0.3845598101615906
[10/23] Train loss=0.30312293767929077
[15/23] Train loss=0.33439314365386963
[20/23] Train loss=0.29882651567459106
Test set avg_accuracy=80.94% avg_sensitivity=47.56%, avg_specificity=90.95% avg_auc=0.8407
Fold[2] Epoch: 39 [39/100 (39%)] Train loss=0.343053 Test loss=0.438869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35156500339508057
[5/23] Train loss=0.3687816262245178
[10/23] Train loss=0.3094426095485687
[15/23] Train loss=0.3263426423072815
[20/23] Train loss=0.2969245910644531
Test set avg_accuracy=80.98% avg_sensitivity=45.16%, avg_specificity=91.73% avg_auc=0.8412
Fold[2] Epoch: 40 [40/100 (40%)] Train loss=0.340419 Test loss=0.431139 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3436017632484436
[5/23] Train loss=0.3776719272136688
[10/23] Train loss=0.30502885580062866
[15/23] Train loss=0.31918081641197205
[20/23] Train loss=0.28449463844299316
Test set avg_accuracy=80.98% avg_sensitivity=44.26%, avg_specificity=92.00% avg_auc=0.8390
Fold[2] Epoch: 41 [41/100 (41%)] Train loss=0.335589 Test loss=0.448687 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33434730768203735
[5/23] Train loss=0.381797194480896
[10/23] Train loss=0.29543423652648926
[15/23] Train loss=0.31214866042137146
[20/23] Train loss=0.2845025360584259
Test set avg_accuracy=80.90% avg_sensitivity=42.72%, avg_specificity=92.35% avg_auc=0.8336
Fold[2] Epoch: 42 [42/100 (42%)] Train loss=0.335255 Test loss=0.459276 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.340742826461792
[5/23] Train loss=0.3754902184009552
[10/23] Train loss=0.2946566045284271
[15/23] Train loss=0.324024498462677
[20/23] Train loss=0.28238800168037415
Test set avg_accuracy=81.38% avg_sensitivity=50.05%, avg_specificity=90.78% avg_auc=0.8414
Best model saved!! Metric=-19.656032177136687!!
Fold[2] Epoch: 43 [43/100 (43%)] Train loss=0.330210 Test loss=0.435882 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3405940532684326
[5/23] Train loss=0.3603444993495941
[10/23] Train loss=0.2897564768791199
[15/23] Train loss=0.3156353235244751
[20/23] Train loss=0.2800292372703552
Test set avg_accuracy=81.34% avg_sensitivity=48.10%, avg_specificity=91.31% avg_auc=0.8432
Fold[2] Epoch: 44 [44/100 (44%)] Train loss=0.327314 Test loss=0.434008 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3342033326625824
[5/23] Train loss=0.36563634872436523
[10/23] Train loss=0.29824525117874146
[15/23] Train loss=0.3130210041999817
[20/23] Train loss=0.2749492824077606
Test set avg_accuracy=81.27% avg_sensitivity=43.22%, avg_specificity=92.69% avg_auc=0.8346
Fold[2] Epoch: 45 [45/100 (45%)] Train loss=0.328439 Test loss=0.455867 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32050061225891113
[5/23] Train loss=0.3608638048171997
[10/23] Train loss=0.2873137891292572
[15/23] Train loss=0.3071260154247284
[20/23] Train loss=0.2745884656906128
Test set avg_accuracy=80.88% avg_sensitivity=42.27%, avg_specificity=92.46% avg_auc=0.8362
Fold[2] Epoch: 46 [46/100 (46%)] Train loss=0.326474 Test loss=0.452610 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32123446464538574
[5/23] Train loss=0.3575253486633301
[10/23] Train loss=0.2861255705356598
[15/23] Train loss=0.30841514468193054
[20/23] Train loss=0.2748979330062866
Test set avg_accuracy=81.06% avg_sensitivity=49.28%, avg_specificity=90.60% avg_auc=0.8418
Fold[2] Epoch: 47 [47/100 (47%)] Train loss=0.320440 Test loss=0.438193 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32354459166526794
[5/23] Train loss=0.35636794567108154
[10/23] Train loss=0.2922515571117401
[15/23] Train loss=0.29714107513427734
[20/23] Train loss=0.27618470788002014
Test set avg_accuracy=80.94% avg_sensitivity=45.61%, avg_specificity=91.54% avg_auc=0.8392
Fold[2] Epoch: 48 [48/100 (48%)] Train loss=0.319592 Test loss=0.450146 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3278420865535736
[5/23] Train loss=0.35623353719711304
[10/23] Train loss=0.28118640184402466
[15/23] Train loss=0.30406326055526733
[20/23] Train loss=0.2654096782207489
Test set avg_accuracy=80.90% avg_sensitivity=45.39%, avg_specificity=91.55% avg_auc=0.8391
Fold[2] Epoch: 49 [49/100 (49%)] Train loss=0.316621 Test loss=0.450214 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31451213359832764
[5/23] Train loss=0.36293280124664307
[10/23] Train loss=0.2721826434135437
[15/23] Train loss=0.29626598954200745
[20/23] Train loss=0.2661532461643219
Test set avg_accuracy=81.25% avg_sensitivity=49.01%, avg_specificity=90.93% avg_auc=0.8406
Fold[2] Epoch: 50 [50/100 (50%)] Train loss=0.312969 Test loss=0.445096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32031652331352234
[5/23] Train loss=0.35444825887680054
[10/23] Train loss=0.2906585931777954
[15/23] Train loss=0.30412134528160095
[20/23] Train loss=0.26919105648994446
Test set avg_accuracy=80.91% avg_sensitivity=45.80%, avg_specificity=91.44% avg_auc=0.8388
Fold[2] Epoch: 51 [51/100 (51%)] Train loss=0.312899 Test loss=0.451554 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3171095550060272
[5/23] Train loss=0.3449022173881531
[10/23] Train loss=0.27941828966140747
[15/23] Train loss=0.29350799322128296
[20/23] Train loss=0.2653847634792328
Test set avg_accuracy=81.10% avg_sensitivity=49.28%, avg_specificity=90.64% avg_auc=0.8387
Fold[2] Epoch: 52 [52/100 (52%)] Train loss=0.309619 Test loss=0.455652 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31734389066696167
[5/23] Train loss=0.3455229103565216
[10/23] Train loss=0.28314703702926636
[15/23] Train loss=0.2918229401111603
[20/23] Train loss=0.2633734941482544
Test set avg_accuracy=81.26% avg_sensitivity=44.62%, avg_specificity=92.26% avg_auc=0.8365
Fold[2] Epoch: 53 [53/100 (53%)] Train loss=0.307250 Test loss=0.458719 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3107589781284332
[5/23] Train loss=0.34449636936187744
[10/23] Train loss=0.2908048927783966
[15/23] Train loss=0.29410067200660706
[20/23] Train loss=0.2620077133178711
Test set avg_accuracy=80.96% avg_sensitivity=41.68%, avg_specificity=92.74% avg_auc=0.8354
Fold[2] Epoch: 54 [54/100 (54%)] Train loss=0.308115 Test loss=0.470010 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3024275600910187
[5/23] Train loss=0.34702497720718384
[10/23] Train loss=0.26341694593429565
[15/23] Train loss=0.28625795245170593
[20/23] Train loss=0.26055192947387695
Test set avg_accuracy=81.09% avg_sensitivity=46.25%, avg_specificity=91.54% avg_auc=0.8394
Fold[2] Epoch: 55 [55/100 (55%)] Train loss=0.301952 Test loss=0.450625 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30768337845802307
[5/23] Train loss=0.35014933347702026
[10/23] Train loss=0.2673724889755249
[15/23] Train loss=0.2801273763179779
[20/23] Train loss=0.25261545181274414
Test set avg_accuracy=81.19% avg_sensitivity=50.14%, avg_specificity=90.51% avg_auc=0.8409
Fold[2] Epoch: 56 [56/100 (56%)] Train loss=0.298573 Test loss=0.456060 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3048873245716095
[5/23] Train loss=0.3460475206375122
[10/23] Train loss=0.273570716381073
[15/23] Train loss=0.277387797832489
[20/23] Train loss=0.2523805797100067
Test set avg_accuracy=80.93% avg_sensitivity=47.24%, avg_specificity=91.03% avg_auc=0.8379
Fold[2] Epoch: 57 [57/100 (57%)] Train loss=0.296489 Test loss=0.457431 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30128931999206543
[5/23] Train loss=0.33857807517051697
[10/23] Train loss=0.26382386684417725
[15/23] Train loss=0.269081175327301
[20/23] Train loss=0.24429678916931152
Test set avg_accuracy=81.27% avg_sensitivity=50.09%, avg_specificity=90.63% avg_auc=0.8385
Fold[2] Epoch: 58 [58/100 (58%)] Train loss=0.293355 Test loss=0.460514 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3015246093273163
[5/23] Train loss=0.33684685826301575
[10/23] Train loss=0.25620272755622864
[15/23] Train loss=0.2730984091758728
[20/23] Train loss=0.25099506974220276
Test set avg_accuracy=80.95% avg_sensitivity=49.59%, avg_specificity=90.36% avg_auc=0.8355
Fold[2] Epoch: 59 [59/100 (59%)] Train loss=0.291116 Test loss=0.455602 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30160027742385864
[5/23] Train loss=0.33298254013061523
[10/23] Train loss=0.26824113726615906
[15/23] Train loss=0.27556928992271423
[20/23] Train loss=0.2483157217502594
Test set avg_accuracy=80.82% avg_sensitivity=49.32%, avg_specificity=90.28% avg_auc=0.8335
Fold[2] Epoch: 60 [60/100 (60%)] Train loss=0.288698 Test loss=0.464709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2958930432796478
[5/23] Train loss=0.3298439085483551
[10/23] Train loss=0.2673530876636505
[15/23] Train loss=0.27431684732437134
[20/23] Train loss=0.23282435536384583
Test set avg_accuracy=80.74% avg_sensitivity=45.52%, avg_specificity=91.31% avg_auc=0.8338
Fold[2] Epoch: 61 [61/100 (61%)] Train loss=0.283990 Test loss=0.468097 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2949032187461853
[5/23] Train loss=0.33135858178138733
[10/23] Train loss=0.25550469756126404
[15/23] Train loss=0.2603069543838501
[20/23] Train loss=0.24384351074695587
Test set avg_accuracy=80.86% avg_sensitivity=48.24%, avg_specificity=90.64% avg_auc=0.8334
Fold[2] Epoch: 62 [62/100 (62%)] Train loss=0.283182 Test loss=0.471334 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29073646664619446
[5/23] Train loss=0.3185265362262726
[10/23] Train loss=0.2585941553115845
[15/23] Train loss=0.26282835006713867
[20/23] Train loss=0.23268330097198486
Test set avg_accuracy=81.56% avg_sensitivity=48.42%, avg_specificity=91.51% avg_auc=0.8344
Fold[2] Epoch: 63 [63/100 (63%)] Train loss=0.281186 Test loss=0.473156 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28288665413856506
[5/23] Train loss=0.3207066059112549
[10/23] Train loss=0.2501929700374603
[15/23] Train loss=0.25862088799476624
[20/23] Train loss=0.23340289294719696
Test set avg_accuracy=81.14% avg_sensitivity=46.84%, avg_specificity=91.43% avg_auc=0.8346
Fold[2] Epoch: 64 [64/100 (64%)] Train loss=0.279165 Test loss=0.473802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2820252478122711
[5/23] Train loss=0.32354116439819336
[10/23] Train loss=0.2994533181190491
[15/23] Train loss=0.3143745958805084
[20/23] Train loss=0.2645368278026581
Test set avg_accuracy=80.69% avg_sensitivity=59.72%, avg_specificity=86.98% avg_auc=0.8197
Best model saved!! Metric=-16.64703502011297!!
Fold[2] Epoch: 65 [65/100 (65%)] Train loss=0.298717 Test loss=0.477790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3045380413532257
[5/23] Train loss=0.3346403241157532
[10/23] Train loss=0.2748448848724365
[15/23] Train loss=0.2894701659679413
[20/23] Train loss=0.24917326867580414
Test set avg_accuracy=80.55% avg_sensitivity=52.22%, avg_specificity=89.05% avg_auc=0.8304
Fold[2] Epoch: 66 [66/100 (66%)] Train loss=0.297475 Test loss=0.453715 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29050034284591675
[5/23] Train loss=0.3343791961669922
[10/23] Train loss=0.25882822275161743
[15/23] Train loss=0.28269222378730774
[20/23] Train loss=0.2404910773038864
Test set avg_accuracy=80.96% avg_sensitivity=48.37%, avg_specificity=90.74% avg_auc=0.8314
Fold[2] Epoch: 67 [67/100 (67%)] Train loss=0.284956 Test loss=0.462880 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2763710021972656
[5/23] Train loss=0.31855058670043945
[10/23] Train loss=0.27319031953811646
[15/23] Train loss=0.2556905150413513
[20/23] Train loss=0.23221173882484436
Test set avg_accuracy=81.34% avg_sensitivity=48.69%, avg_specificity=91.13% avg_auc=0.8352
Fold[2] Epoch: 68 [68/100 (68%)] Train loss=0.279584 Test loss=0.467781 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.279002845287323
[5/23] Train loss=0.3267376124858856
[10/23] Train loss=0.2529551386833191
[15/23] Train loss=0.2684045135974884
[20/23] Train loss=0.233695849776268
Test set avg_accuracy=80.94% avg_sensitivity=49.37%, avg_specificity=90.41% avg_auc=0.8367
Fold[2] Epoch: 69 [69/100 (69%)] Train loss=0.276501 Test loss=0.473299 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2777380645275116
[5/23] Train loss=0.3174453675746918
[10/23] Train loss=0.2422357201576233
[15/23] Train loss=0.2517099678516388
[20/23] Train loss=0.23599094152450562
Test set avg_accuracy=80.78% avg_sensitivity=46.84%, avg_specificity=90.97% avg_auc=0.8353
Fold[2] Epoch: 70 [70/100 (70%)] Train loss=0.271375 Test loss=0.475917 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2683805823326111
[5/23] Train loss=0.3261129856109619
[10/23] Train loss=0.24392913281917572
[15/23] Train loss=0.24200516939163208
[20/23] Train loss=0.2302175760269165
Test set avg_accuracy=81.20% avg_sensitivity=46.56%, avg_specificity=91.59% avg_auc=0.8348
Fold[2] Epoch: 71 [71/100 (71%)] Train loss=0.273135 Test loss=0.466219 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2676803767681122
[5/23] Train loss=0.3082704246044159
[10/23] Train loss=0.25824296474456787
[15/23] Train loss=0.24032382667064667
[20/23] Train loss=0.22116456925868988
Test set avg_accuracy=81.40% avg_sensitivity=49.10%, avg_specificity=91.09% avg_auc=0.8336
Fold[2] Epoch: 72 [72/100 (72%)] Train loss=0.267094 Test loss=0.471061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2639308571815491
[5/23] Train loss=0.30946919322013855
[10/23] Train loss=0.24525678157806396
[15/23] Train loss=0.25053468346595764
[20/23] Train loss=0.21153894066810608
Test set avg_accuracy=80.78% avg_sensitivity=52.40%, avg_specificity=89.30% avg_auc=0.8359
Fold[2] Epoch: 73 [73/100 (73%)] Train loss=0.260299 Test loss=0.496890 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2852759063243866
[5/23] Train loss=0.30944257974624634
[10/23] Train loss=0.24267344176769257
[15/23] Train loss=0.2453971952199936
[20/23] Train loss=0.2163701057434082
Test set avg_accuracy=81.03% avg_sensitivity=47.42%, avg_specificity=91.12% avg_auc=0.8296
Fold[2] Epoch: 74 [74/100 (74%)] Train loss=0.258990 Test loss=0.494725 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2660294771194458
[5/23] Train loss=0.29640358686447144
[10/23] Train loss=0.2444266527891159
[15/23] Train loss=0.23053008317947388
[20/23] Train loss=0.2101493775844574
Test set avg_accuracy=80.83% avg_sensitivity=47.88%, avg_specificity=90.72% avg_auc=0.8304
Fold[2] Epoch: 75 [75/100 (75%)] Train loss=0.255180 Test loss=0.488195 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2602042853832245
[5/23] Train loss=0.3034002184867859
[10/23] Train loss=0.22690004110336304
[15/23] Train loss=0.2377464920282364
[20/23] Train loss=0.20941993594169617
Test set avg_accuracy=81.03% avg_sensitivity=50.59%, avg_specificity=90.17% avg_auc=0.8256
Fold[2] Epoch: 76 [76/100 (76%)] Train loss=0.255467 Test loss=0.491254 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2632145583629608
[5/23] Train loss=0.28517088294029236
[10/23] Train loss=0.240529865026474
[15/23] Train loss=0.2310960441827774
[20/23] Train loss=0.21177293360233307
Test set avg_accuracy=80.75% avg_sensitivity=48.01%, avg_specificity=90.57% avg_auc=0.8316
Fold[2] Epoch: 77 [77/100 (77%)] Train loss=0.251602 Test loss=0.498199 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25222504138946533
[5/23] Train loss=0.2958243787288666
[10/23] Train loss=0.25233298540115356
[15/23] Train loss=0.23408332467079163
[20/23] Train loss=0.21360673010349274
Test set avg_accuracy=80.67% avg_sensitivity=45.39%, avg_specificity=91.25% avg_auc=0.8330
Fold[2] Epoch: 78 [78/100 (78%)] Train loss=0.251436 Test loss=0.489579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25990286469459534
[5/23] Train loss=0.2930110692977905
[10/23] Train loss=0.23711638152599335
[15/23] Train loss=0.23159316182136536
[20/23] Train loss=0.20925679802894592
Test set avg_accuracy=80.63% avg_sensitivity=44.98%, avg_specificity=91.32% avg_auc=0.8309
Fold[2] Epoch: 79 [79/100 (79%)] Train loss=0.250212 Test loss=0.481931 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25082916021347046
[5/23] Train loss=0.29945504665374756
[10/23] Train loss=0.22873122990131378
[15/23] Train loss=0.2246531844139099
[20/23] Train loss=0.19685055315494537
Test set avg_accuracy=80.93% avg_sensitivity=40.91%, avg_specificity=92.93% avg_auc=0.8303
Fold[2] Epoch: 80 [80/100 (80%)] Train loss=0.246092 Test loss=0.494594 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2381955087184906
[5/23] Train loss=0.29678499698638916
[10/23] Train loss=0.2305581271648407
[15/23] Train loss=0.23123082518577576
[20/23] Train loss=0.20766232907772064
Test set avg_accuracy=80.62% avg_sensitivity=43.13%, avg_specificity=91.86% avg_auc=0.8298
Fold[2] Epoch: 81 [81/100 (81%)] Train loss=0.247372 Test loss=0.506252 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24180981516838074
[5/23] Train loss=0.314572811126709
[10/23] Train loss=0.23078519105911255
[15/23] Train loss=0.23384638130664825
[20/23] Train loss=0.20148184895515442
Test set avg_accuracy=80.58% avg_sensitivity=50.14%, avg_specificity=89.72% avg_auc=0.8277
Fold[2] Epoch: 82 [82/100 (82%)] Train loss=0.245878 Test loss=0.515750 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24992802739143372
[5/23] Train loss=0.2980331778526306
[10/23] Train loss=0.21845240890979767
[15/23] Train loss=0.21274340152740479
[20/23] Train loss=0.19847938418388367
Test set avg_accuracy=81.12% avg_sensitivity=48.82%, avg_specificity=90.80% avg_auc=0.8274
Fold[2] Epoch: 83 [83/100 (83%)] Train loss=0.238153 Test loss=0.517236 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23928548395633698
[5/23] Train loss=0.2829282283782959
[10/23] Train loss=0.22124020755290985
[15/23] Train loss=0.21812723577022552
[20/23] Train loss=0.190486341714859
Test set avg_accuracy=80.97% avg_sensitivity=48.24%, avg_specificity=90.79% avg_auc=0.8295
Fold[2] Epoch: 84 [84/100 (84%)] Train loss=0.236844 Test loss=0.521652 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24700355529785156
[5/23] Train loss=0.28071117401123047
[10/23] Train loss=0.2271888107061386
[15/23] Train loss=0.2149905115365982
[20/23] Train loss=0.19480308890342712
Test set avg_accuracy=80.82% avg_sensitivity=44.17%, avg_specificity=91.82% avg_auc=0.8280
Fold[2] Epoch: 85 [85/100 (85%)] Train loss=0.235433 Test loss=0.512881 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23170815408229828
[5/23] Train loss=0.26550188660621643
[10/23] Train loss=0.21900485455989838
[15/23] Train loss=0.2070428878068924
[20/23] Train loss=0.18644565343856812
Test set avg_accuracy=81.07% avg_sensitivity=43.76%, avg_specificity=92.27% avg_auc=0.8256
Fold[2] Epoch: 86 [86/100 (86%)] Train loss=0.230457 Test loss=0.509739 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23487332463264465
[5/23] Train loss=0.26840636134147644
[10/23] Train loss=0.2109680324792862
[15/23] Train loss=0.21545390784740448
[20/23] Train loss=0.18536882102489471
Test set avg_accuracy=81.22% avg_sensitivity=44.58%, avg_specificity=92.21% avg_auc=0.8159
Fold[2] Epoch: 87 [87/100 (87%)] Train loss=0.229517 Test loss=0.519047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.225630521774292
[5/23] Train loss=0.2774360179901123
[10/23] Train loss=0.21194005012512207
[15/23] Train loss=0.21026292443275452
[20/23] Train loss=0.19008485972881317
Test set avg_accuracy=81.07% avg_sensitivity=49.86%, avg_specificity=90.44% avg_auc=0.8169
Fold[2] Epoch: 88 [88/100 (88%)] Train loss=0.227452 Test loss=0.523411 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22896061837673187
[5/23] Train loss=0.28012266755104065
[10/23] Train loss=0.22092609107494354
[15/23] Train loss=0.21198445558547974
[20/23] Train loss=0.18187981843948364
Test set avg_accuracy=81.16% avg_sensitivity=46.16%, avg_specificity=91.66% avg_auc=0.8242
Fold[2] Epoch: 89 [89/100 (89%)] Train loss=0.225378 Test loss=0.517185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23139192163944244
[5/23] Train loss=0.27389663457870483
[10/23] Train loss=0.21178202331066132
[15/23] Train loss=0.20233798027038574
[20/23] Train loss=0.18224740028381348
Test set avg_accuracy=81.38% avg_sensitivity=45.57%, avg_specificity=92.12% avg_auc=0.8264
Fold[2] Epoch: 90 [90/100 (90%)] Train loss=0.224330 Test loss=0.538566 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2330331951379776
[5/23] Train loss=0.261794775724411
[10/23] Train loss=0.20474769175052643
[15/23] Train loss=0.20228436589241028
[20/23] Train loss=0.18977656960487366
Test set avg_accuracy=81.19% avg_sensitivity=44.53%, avg_specificity=92.19% avg_auc=0.8187
Fold[2] Epoch: 91 [91/100 (91%)] Train loss=0.219124 Test loss=0.535232 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22883440554141998
[5/23] Train loss=0.27508544921875
[10/23] Train loss=0.21070986986160278
[15/23] Train loss=0.21503084897994995
[20/23] Train loss=0.17656219005584717
Test set avg_accuracy=81.07% avg_sensitivity=46.61%, avg_specificity=91.41% avg_auc=0.8138
Fold[2] Epoch: 92 [92/100 (92%)] Train loss=0.223111 Test loss=0.519929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.223495215177536
[5/23] Train loss=0.27194878458976746
[10/23] Train loss=0.19872577488422394
[15/23] Train loss=0.20628269016742706
[20/23] Train loss=0.17909111082553864
Test set avg_accuracy=81.61% avg_sensitivity=47.20%, avg_specificity=91.93% avg_auc=0.8238
Fold[2] Epoch: 93 [93/100 (93%)] Train loss=0.220556 Test loss=0.512120 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22725631296634674
[5/23] Train loss=0.2661437392234802
[10/23] Train loss=0.20921728014945984
[15/23] Train loss=0.19979234039783478
[20/23] Train loss=0.17483940720558167
Test set avg_accuracy=80.96% avg_sensitivity=46.29%, avg_specificity=91.36% avg_auc=0.8241
Fold[2] Epoch: 94 [94/100 (94%)] Train loss=0.216629 Test loss=0.537907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21286192536354065
[5/23] Train loss=0.26461607217788696
[10/23] Train loss=0.19969400763511658
[15/23] Train loss=0.19259969890117645
[20/23] Train loss=0.1741286665201187
Test set avg_accuracy=81.31% avg_sensitivity=46.61%, avg_specificity=91.73% avg_auc=0.8262
Fold[2] Epoch: 95 [95/100 (95%)] Train loss=0.212525 Test loss=0.526009 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22671754658222198
[5/23] Train loss=0.2545851767063141
[10/23] Train loss=0.18909986317157745
[15/23] Train loss=0.20089134573936462
[20/23] Train loss=0.16445708274841309
Test set avg_accuracy=80.91% avg_sensitivity=46.43%, avg_specificity=91.25% avg_auc=0.8196
Fold[2] Epoch: 96 [96/100 (96%)] Train loss=0.211441 Test loss=0.542418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21407605707645416
[5/23] Train loss=0.2607966661453247
[10/23] Train loss=0.19450438022613525
[15/23] Train loss=0.19791077077388763
[20/23] Train loss=0.17275841534137726
Test set avg_accuracy=80.64% avg_sensitivity=44.62%, avg_specificity=91.44% avg_auc=0.8108
Fold[2] Epoch: 97 [97/100 (97%)] Train loss=0.211821 Test loss=0.550331 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21855571866035461
[5/23] Train loss=0.2422177493572235
[10/23] Train loss=0.19124539196491241
[15/23] Train loss=0.19704508781433105
[20/23] Train loss=0.1684296727180481
Test set avg_accuracy=80.63% avg_sensitivity=43.08%, avg_specificity=91.89% avg_auc=0.8256
Fold[2] Epoch: 98 [98/100 (98%)] Train loss=0.208157 Test loss=0.543113 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20509110391139984
[5/23] Train loss=0.24243782460689545
[10/23] Train loss=0.190942645072937
[15/23] Train loss=0.19349811971187592
[20/23] Train loss=0.15918207168579102
Test set avg_accuracy=80.35% avg_sensitivity=39.69%, avg_specificity=92.55% avg_auc=0.8197
Fold[2] Epoch: 99 [99/100 (99%)] Train loss=0.210578 Test loss=0.564389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21456846594810486
[5/23] Train loss=0.25150197744369507
[10/23] Train loss=0.19027650356292725
[15/23] Train loss=0.19246216118335724
[20/23] Train loss=0.17503030598163605
Test set avg_accuracy=80.26% avg_sensitivity=40.91%, avg_specificity=92.07% avg_auc=0.8200
Fold[2] Epoch: 100 [100/100 (100%)] Train loss=0.208349 Test loss=0.542125 Current lr=[3.9999999999999996e-05]

Fold[2] Best Result: acc=80.6885758998435 sen=59.719710669077756, spe=86.9795198697952, auc=0.8196515854117058!
[0/23] Train loss=0.6894772052764893
[5/23] Train loss=0.7176556587219238
[10/23] Train loss=0.5643103718757629
[15/23] Train loss=0.556209146976471
[20/23] Train loss=0.5259340405464172
Test set avg_accuracy=68.35% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5912
Best model saved!! Metric=-98.52866080714394!!
Fold[3] Epoch: 1 [1/100 (1%)] Train loss=0.563279 Test loss=0.790397 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5672221779823303
[5/23] Train loss=0.6019484996795654
[10/23] Train loss=0.5312588810920715
[15/23] Train loss=0.5243775248527527
[20/23] Train loss=0.4912514388561249
Test set avg_accuracy=68.28% avg_sensitivity=2.65%, avg_specificity=98.68% avg_auc=0.6406
Best model saved!! Metric=-92.32895719522784!!
Fold[3] Epoch: 2 [2/100 (2%)] Train loss=0.522476 Test loss=0.758601 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5367639064788818
[5/23] Train loss=0.55755215883255
[10/23] Train loss=0.49673113226890564
[15/23] Train loss=0.5047475099563599
[20/23] Train loss=0.4464089572429657
Test set avg_accuracy=68.84% avg_sensitivity=9.35%, avg_specificity=96.39% avg_auc=0.6828
Best model saved!! Metric=-83.14135337881353!!
Fold[3] Epoch: 3 [3/100 (3%)] Train loss=0.491939 Test loss=0.775460 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5045003890991211
[5/23] Train loss=0.5112351775169373
[10/23] Train loss=0.4550638198852539
[15/23] Train loss=0.5047266483306885
[20/23] Train loss=0.42506924271583557
Test set avg_accuracy=70.43% avg_sensitivity=14.56%, avg_specificity=96.30% avg_auc=0.7144
Best model saved!! Metric=-73.27982387292263!!
Fold[3] Epoch: 4 [4/100 (4%)] Train loss=0.466795 Test loss=0.799528 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.470564067363739
[5/23] Train loss=0.49421340227127075
[10/23] Train loss=0.4236060678958893
[15/23] Train loss=0.46590834856033325
[20/23] Train loss=0.4025813639163971
Test set avg_accuracy=71.69% avg_sensitivity=18.74%, avg_specificity=96.21% avg_auc=0.7401
Best model saved!! Metric=-65.3643144751345!!
Fold[3] Epoch: 5 [5/100 (5%)] Train loss=0.447107 Test loss=0.747312 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.453556090593338
[5/23] Train loss=0.4654178023338318
[10/23] Train loss=0.4050130844116211
[15/23] Train loss=0.466938316822052
[20/23] Train loss=0.40133610367774963
Test set avg_accuracy=72.54% avg_sensitivity=21.36%, avg_specificity=96.24% avg_auc=0.7602
Best model saved!! Metric=-59.85038234768882!!
Fold[3] Epoch: 6 [6/100 (6%)] Train loss=0.436369 Test loss=0.726060 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44198134541511536
[5/23] Train loss=0.4569466710090637
[10/23] Train loss=0.3975488245487213
[15/23] Train loss=0.4457673132419586
[20/23] Train loss=0.3904816508293152
Test set avg_accuracy=74.09% avg_sensitivity=26.73%, avg_specificity=96.02% avg_auc=0.7737
Best model saved!! Metric=-51.788224834919234!!
Fold[3] Epoch: 7 [7/100 (7%)] Train loss=0.426997 Test loss=0.666998 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4326518177986145
[5/23] Train loss=0.44356104731559753
[10/23] Train loss=0.39793282747268677
[15/23] Train loss=0.4517039656639099
[20/23] Train loss=0.3880242705345154
Test set avg_accuracy=74.88% avg_sensitivity=28.72%, avg_specificity=96.25% avg_auc=0.7879
Best model saved!! Metric=-47.362379534045964!!
Fold[3] Epoch: 8 [8/100 (8%)] Train loss=0.422568 Test loss=0.635740 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44243377447128296
[5/23] Train loss=0.4429139494895935
[10/23] Train loss=0.38590356707572937
[15/23] Train loss=0.43084535002708435
[20/23] Train loss=0.3797740936279297
Test set avg_accuracy=75.08% avg_sensitivity=29.32%, avg_specificity=96.27% avg_auc=0.7976
Best model saved!! Metric=-45.57183778443998!!
Fold[3] Epoch: 9 [9/100 (9%)] Train loss=0.417037 Test loss=0.608995 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4307684302330017
[5/23] Train loss=0.4312150180339813
[10/23] Train loss=0.37833207845687866
[15/23] Train loss=0.4259212911128998
[20/23] Train loss=0.37208518385887146
Test set avg_accuracy=75.63% avg_sensitivity=31.44%, avg_specificity=96.10% avg_auc=0.8066
Best model saved!! Metric=-42.1703927797021!!
Fold[3] Epoch: 10 [10/100 (10%)] Train loss=0.412903 Test loss=0.585929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4292568862438202
[5/23] Train loss=0.43228593468666077
[10/23] Train loss=0.3735799193382263
[15/23] Train loss=0.4302733242511749
[20/23] Train loss=0.3767133355140686
Test set avg_accuracy=76.02% avg_sensitivity=32.64%, avg_specificity=96.11% avg_auc=0.8103
Best model saved!! Metric=-40.20082999575302!!
Fold[3] Epoch: 11 [11/100 (11%)] Train loss=0.409212 Test loss=0.576170 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.427143931388855
[5/23] Train loss=0.4263361990451813
[10/23] Train loss=0.37258583307266235
[15/23] Train loss=0.4184287488460541
[20/23] Train loss=0.36683839559555054
Test set avg_accuracy=76.70% avg_sensitivity=35.62%, avg_specificity=95.73% avg_auc=0.8149
Best model saved!! Metric=-36.45442903331515!!
Fold[3] Epoch: 12 [12/100 (12%)] Train loss=0.404142 Test loss=0.554799 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4168458580970764
[5/23] Train loss=0.43141356110572815
[10/23] Train loss=0.36874258518218994
[15/23] Train loss=0.43272605538368225
[20/23] Train loss=0.36551421880722046
Test set avg_accuracy=76.68% avg_sensitivity=35.52%, avg_specificity=95.75% avg_auc=0.8181
Best model saved!! Metric=-36.236732525269524!!
Fold[3] Epoch: 13 [13/100 (13%)] Train loss=0.403127 Test loss=0.543230 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43187639117240906
[5/23] Train loss=0.42592504620552063
[10/23] Train loss=0.37075525522232056
[15/23] Train loss=0.4150390625
[20/23] Train loss=0.3584010899066925
Test set avg_accuracy=76.92% avg_sensitivity=36.32%, avg_specificity=95.73% avg_auc=0.8191
Best model saved!! Metric=-35.12295502060799!!
Fold[3] Epoch: 14 [14/100 (14%)] Train loss=0.401159 Test loss=0.523281 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4105706214904785
[5/23] Train loss=0.4255828261375427
[10/23] Train loss=0.3562423288822174
[15/23] Train loss=0.4374229609966278
[20/23] Train loss=0.3572806417942047
Test set avg_accuracy=77.17% avg_sensitivity=37.78%, avg_specificity=95.41% avg_auc=0.8242
Best model saved!! Metric=-33.23196271947312!!
Fold[3] Epoch: 15 [15/100 (15%)] Train loss=0.400507 Test loss=0.529562 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4291420578956604
[5/23] Train loss=0.420864999294281
[10/23] Train loss=0.36447837948799133
[15/23] Train loss=0.43236905336380005
[20/23] Train loss=0.3510882556438446
Test set avg_accuracy=77.22% avg_sensitivity=37.41%, avg_specificity=95.65% avg_auc=0.8180
Fold[3] Epoch: 16 [16/100 (16%)] Train loss=0.398811 Test loss=0.533169 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4056210517883301
[5/23] Train loss=0.4273701608181
[10/23] Train loss=0.3620537519454956
[15/23] Train loss=0.43024560809135437
[20/23] Train loss=0.3489927351474762
Test set avg_accuracy=76.98% avg_sensitivity=35.72%, avg_specificity=96.08% avg_auc=0.8178
Fold[3] Epoch: 17 [17/100 (17%)] Train loss=0.397241 Test loss=0.563340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3942470848560333
[5/23] Train loss=0.4313426911830902
[10/23] Train loss=0.37382546067237854
[15/23] Train loss=0.4227556586265564
[20/23] Train loss=0.3497168719768524
Test set avg_accuracy=75.77% avg_sensitivity=30.91%, avg_specificity=96.54% avg_auc=0.8094
Fold[3] Epoch: 18 [18/100 (18%)] Train loss=0.399555 Test loss=0.599047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3960982859134674
[5/23] Train loss=0.42197921872138977
[10/23] Train loss=0.385719358921051
[15/23] Train loss=0.4051302373409271
[20/23] Train loss=0.3484436273574829
Test set avg_accuracy=76.54% avg_sensitivity=33.93%, avg_specificity=96.27% avg_auc=0.8059
Fold[3] Epoch: 19 [19/100 (19%)] Train loss=0.396828 Test loss=0.619852 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39188817143440247
[5/23] Train loss=0.41792988777160645
[10/23] Train loss=0.3560606837272644
[15/23] Train loss=0.39547914266586304
[20/23] Train loss=0.34215810894966125
Test set avg_accuracy=77.28% avg_sensitivity=36.82%, avg_specificity=96.02% avg_auc=0.8201
Fold[3] Epoch: 20 [20/100 (20%)] Train loss=0.386841 Test loss=0.572747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39808765053749084
[5/23] Train loss=0.4145098328590393
[10/23] Train loss=0.3464260995388031
[15/23] Train loss=0.3828226625919342
[20/23] Train loss=0.3408876359462738
Test set avg_accuracy=77.70% avg_sensitivity=40.40%, avg_specificity=94.98% avg_auc=0.8320
Best model saved!! Metric=-29.720610473361823!!
Fold[3] Epoch: 21 [21/100 (21%)] Train loss=0.380371 Test loss=0.531348 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40522655844688416
[5/23] Train loss=0.40870848298072815
[10/23] Train loss=0.33755332231521606
[15/23] Train loss=0.387951523065567
[20/23] Train loss=0.3349272906780243
Test set avg_accuracy=77.91% avg_sensitivity=41.56%, avg_specificity=94.75% avg_auc=0.8317
Best model saved!! Metric=-28.616622408637696!!
Fold[3] Epoch: 22 [22/100 (22%)] Train loss=0.378676 Test loss=0.529835 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3828561305999756
[5/23] Train loss=0.40876057744026184
[10/23] Train loss=0.3522629737854004
[15/23] Train loss=0.3864145576953888
[20/23] Train loss=0.3407638967037201
Test set avg_accuracy=77.01% avg_sensitivity=36.82%, avg_specificity=95.62% avg_auc=0.8295
Fold[3] Epoch: 23 [23/100 (23%)] Train loss=0.378967 Test loss=0.554134 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37244144082069397
[5/23] Train loss=0.4037890136241913
[10/23] Train loss=0.3460891544818878
[15/23] Train loss=0.38291534781455994
[20/23] Train loss=0.3325040936470032
Test set avg_accuracy=77.18% avg_sensitivity=35.75%, avg_specificity=96.36% avg_auc=0.8212
Fold[3] Epoch: 24 [24/100 (24%)] Train loss=0.378033 Test loss=0.593760 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3728446662425995
[5/23] Train loss=0.4040209650993347
[10/23] Train loss=0.3554869294166565
[15/23] Train loss=0.36882296204566956
[20/23] Train loss=0.3418286442756653
Test set avg_accuracy=77.96% avg_sensitivity=40.76%, avg_specificity=95.19% avg_auc=0.8382
Best model saved!! Metric=-28.25717169321095!!
Fold[3] Epoch: 25 [25/100 (25%)] Train loss=0.374166 Test loss=0.550347 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37067267298698425
[5/23] Train loss=0.40361908078193665
[10/23] Train loss=0.3453334867954254
[15/23] Train loss=0.36100301146507263
[20/23] Train loss=0.33275118470191956
Test set avg_accuracy=77.72% avg_sensitivity=39.00%, avg_specificity=95.65% avg_auc=0.8392
Fold[3] Epoch: 26 [26/100 (26%)] Train loss=0.371510 Test loss=0.556185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3721461296081543
[5/23] Train loss=0.4078611433506012
[10/23] Train loss=0.3427506983280182
[15/23] Train loss=0.3556641936302185
[20/23] Train loss=0.3261229693889618
Test set avg_accuracy=77.70% avg_sensitivity=38.47%, avg_specificity=95.87% avg_auc=0.8384
Fold[3] Epoch: 27 [27/100 (27%)] Train loss=0.370419 Test loss=0.578516 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36851948499679565
[5/23] Train loss=0.39654672145843506
[10/23] Train loss=0.328229159116745
[15/23] Train loss=0.3581181764602661
[20/23] Train loss=0.31524574756622314
Test set avg_accuracy=77.84% avg_sensitivity=40.60%, avg_specificity=95.08% avg_auc=0.8374
Fold[3] Epoch: 28 [28/100 (28%)] Train loss=0.364145 Test loss=0.548547 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3643641471862793
[5/23] Train loss=0.3989683985710144
[10/23] Train loss=0.32519954442977905
[15/23] Train loss=0.3593783676624298
[20/23] Train loss=0.31492772698402405
Test set avg_accuracy=78.12% avg_sensitivity=41.09%, avg_specificity=95.27% avg_auc=0.8362
Best model saved!! Metric=-27.896783745395666!!
Fold[3] Epoch: 29 [29/100 (29%)] Train loss=0.359049 Test loss=0.550656 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3664557933807373
[5/23] Train loss=0.3960634171962738
[10/23] Train loss=0.31630322337150574
[15/23] Train loss=0.3493683338165283
[20/23] Train loss=0.31587597727775574
Test set avg_accuracy=78.39% avg_sensitivity=43.35%, avg_specificity=94.62% avg_auc=0.8394
Best model saved!! Metric=-25.695316491793854!!
Fold[3] Epoch: 30 [30/100 (30%)] Train loss=0.358235 Test loss=0.541639 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35774436593055725
[5/23] Train loss=0.38857293128967285
[10/23] Train loss=0.3234846889972687
[15/23] Train loss=0.3537696897983551
[20/23] Train loss=0.32053783535957336
Test set avg_accuracy=78.80% avg_sensitivity=44.84%, avg_specificity=94.53% avg_auc=0.8443
Best model saved!! Metric=-23.390335095129636!!
Fold[3] Epoch: 31 [31/100 (31%)] Train loss=0.354259 Test loss=0.528078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3586321771144867
[5/23] Train loss=0.39006537199020386
[10/23] Train loss=0.3266601264476776
[15/23] Train loss=0.3386881947517395
[20/23] Train loss=0.309542179107666
Test set avg_accuracy=78.11% avg_sensitivity=41.33%, avg_specificity=95.15% avg_auc=0.8435
Fold[3] Epoch: 32 [32/100 (32%)] Train loss=0.352319 Test loss=0.545511 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35146790742874146
[5/23] Train loss=0.3920827805995941
[10/23] Train loss=0.31416210532188416
[15/23] Train loss=0.3402535915374756
[20/23] Train loss=0.30476614832878113
Test set avg_accuracy=78.09% avg_sensitivity=41.23%, avg_specificity=95.16% avg_auc=0.8382
Fold[3] Epoch: 33 [33/100 (33%)] Train loss=0.350660 Test loss=0.550026 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34265008568763733
[5/23] Train loss=0.39221081137657166
[10/23] Train loss=0.3115535378456116
[15/23] Train loss=0.352037638425827
[20/23] Train loss=0.30391862988471985
Test set avg_accuracy=77.08% avg_sensitivity=36.62%, avg_specificity=95.82% avg_auc=0.8348
Fold[3] Epoch: 34 [34/100 (34%)] Train loss=0.350938 Test loss=0.565019 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3511875867843628
[5/23] Train loss=0.3874886929988861
[10/23] Train loss=0.3194311261177063
[15/23] Train loss=0.3355090618133545
[20/23] Train loss=0.30039817094802856
Test set avg_accuracy=78.02% avg_sensitivity=41.69%, avg_specificity=94.84% avg_auc=0.8408
Fold[3] Epoch: 35 [35/100 (35%)] Train loss=0.346114 Test loss=0.544121 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3501342236995697
[5/23] Train loss=0.3859306275844574
[10/23] Train loss=0.3063226342201233
[15/23] Train loss=0.32725226879119873
[20/23] Train loss=0.30222204327583313
Test set avg_accuracy=78.43% avg_sensitivity=42.59%, avg_specificity=95.02% avg_auc=0.8459
Fold[3] Epoch: 36 [36/100 (36%)] Train loss=0.343962 Test loss=0.533717 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3464576303958893
[5/23] Train loss=0.3877125084400177
[10/23] Train loss=0.30185675621032715
[15/23] Train loss=0.3326261341571808
[20/23] Train loss=0.2942180335521698
Test set avg_accuracy=78.89% avg_sensitivity=46.70%, avg_specificity=93.79% avg_auc=0.8479
Best model saved!! Metric=-21.825824492208092!!
Fold[3] Epoch: 37 [37/100 (37%)] Train loss=0.339157 Test loss=0.515402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3479963541030884
[5/23] Train loss=0.38285189867019653
[10/23] Train loss=0.30334022641181946
[15/23] Train loss=0.32038748264312744
[20/23] Train loss=0.2873055934906006
Test set avg_accuracy=78.96% avg_sensitivity=45.24%, avg_specificity=94.58% avg_auc=0.8472
Fold[3] Epoch: 38 [38/100 (38%)] Train loss=0.336317 Test loss=0.531119 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3433930277824402
[5/23] Train loss=0.3755970299243927
[10/23] Train loss=0.2957747280597687
[15/23] Train loss=0.32050299644470215
[20/23] Train loss=0.28876760601997375
Test set avg_accuracy=78.48% avg_sensitivity=43.45%, avg_specificity=94.70% avg_auc=0.8432
Fold[3] Epoch: 39 [39/100 (39%)] Train loss=0.332519 Test loss=0.528162 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34115567803382874
[5/23] Train loss=0.37885019183158875
[10/23] Train loss=0.2930426001548767
[15/23] Train loss=0.3195047378540039
[20/23] Train loss=0.29008957743644714
Test set avg_accuracy=78.33% avg_sensitivity=42.89%, avg_specificity=94.75% avg_auc=0.8411
Fold[3] Epoch: 40 [40/100 (40%)] Train loss=0.332625 Test loss=0.525166 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34127724170684814
[5/23] Train loss=0.38059741258621216
[10/23] Train loss=0.2937415540218353
[15/23] Train loss=0.3221345841884613
[20/23] Train loss=0.2863401770591736
Test set avg_accuracy=79.06% avg_sensitivity=46.77%, avg_specificity=94.01% avg_auc=0.8457
Best model saved!! Metric=-21.595150770653753!!
Fold[3] Epoch: 41 [41/100 (41%)] Train loss=0.329593 Test loss=0.512530 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33204612135887146
[5/23] Train loss=0.3714998960494995
[10/23] Train loss=0.29373204708099365
[15/23] Train loss=0.3166620433330536
[20/23] Train loss=0.2845849096775055
Test set avg_accuracy=78.85% avg_sensitivity=45.37%, avg_specificity=94.35% avg_auc=0.8473
Fold[3] Epoch: 42 [42/100 (42%)] Train loss=0.325956 Test loss=0.520628 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33189088106155396
[5/23] Train loss=0.3660382330417633
[10/23] Train loss=0.2889663875102997
[15/23] Train loss=0.3257250487804413
[20/23] Train loss=0.28359901905059814
Test set avg_accuracy=78.86% avg_sensitivity=46.97%, avg_specificity=93.63% avg_auc=0.8478
Fold[3] Epoch: 43 [43/100 (43%)] Train loss=0.323750 Test loss=0.514466 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32463374733924866
[5/23] Train loss=0.36910417675971985
[10/23] Train loss=0.27469900250434875
[15/23] Train loss=0.3092341125011444
[20/23] Train loss=0.2764001190662384
Test set avg_accuracy=78.91% avg_sensitivity=46.80%, avg_specificity=93.78% avg_auc=0.8468
Fold[3] Epoch: 44 [44/100 (44%)] Train loss=0.321640 Test loss=0.520612 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3285190761089325
[5/23] Train loss=0.367794394493103
[10/23] Train loss=0.28087320923805237
[15/23] Train loss=0.31104812026023865
[20/23] Train loss=0.2806534767150879
Test set avg_accuracy=78.46% avg_sensitivity=43.75%, avg_specificity=94.53% avg_auc=0.8427
Fold[3] Epoch: 45 [45/100 (45%)] Train loss=0.322140 Test loss=0.541311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3193874657154083
[5/23] Train loss=0.361930251121521
[10/23] Train loss=0.2822927236557007
[15/23] Train loss=0.296199232339859
[20/23] Train loss=0.2811713218688965
Test set avg_accuracy=77.64% avg_sensitivity=40.40%, avg_specificity=94.88% avg_auc=0.8398
Fold[3] Epoch: 46 [46/100 (46%)] Train loss=0.320618 Test loss=0.559876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31770721077919006
[5/23] Train loss=0.3604291081428528
[10/23] Train loss=0.28551754355430603
[15/23] Train loss=0.3068663775920868
[20/23] Train loss=0.28179964423179626
Test set avg_accuracy=76.21% avg_sensitivity=33.57%, avg_specificity=95.96% avg_auc=0.8320
Fold[3] Epoch: 47 [47/100 (47%)] Train loss=0.320334 Test loss=0.591795 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3255953788757324
[5/23] Train loss=0.3610824644565582
[10/23] Train loss=0.27956098318099976
[15/23] Train loss=0.3020336329936981
[20/23] Train loss=0.2707017958164215
Test set avg_accuracy=78.72% avg_sensitivity=45.77%, avg_specificity=93.98% avg_auc=0.8459
Fold[3] Epoch: 48 [48/100 (48%)] Train loss=0.314508 Test loss=0.523763 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3201891779899597
[5/23] Train loss=0.3551609516143799
[10/23] Train loss=0.2737939953804016
[15/23] Train loss=0.3092782199382782
[20/23] Train loss=0.26168292760849
Test set avg_accuracy=78.98% avg_sensitivity=48.36%, avg_specificity=93.16% avg_auc=0.8470
Best model saved!! Metric=-20.795992540733405!!
Fold[3] Epoch: 49 [49/100 (49%)] Train loss=0.310872 Test loss=0.513251 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32198894023895264
[5/23] Train loss=0.35547494888305664
[10/23] Train loss=0.26915544271469116
[15/23] Train loss=0.30748802423477173
[20/23] Train loss=0.2710295021533966
Test set avg_accuracy=79.03% avg_sensitivity=47.23%, avg_specificity=93.76% avg_auc=0.8468
Fold[3] Epoch: 50 [50/100 (50%)] Train loss=0.308489 Test loss=0.534348 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31015536189079285
[5/23] Train loss=0.35368645191192627
[10/23] Train loss=0.28012895584106445
[15/23] Train loss=0.2950059771537781
[20/23] Train loss=0.2711043655872345
Test set avg_accuracy=77.92% avg_sensitivity=41.19%, avg_specificity=94.93% avg_auc=0.8452
Fold[3] Epoch: 51 [51/100 (51%)] Train loss=0.308028 Test loss=0.554565 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3035964071750641
[5/23] Train loss=0.34910959005355835
[10/23] Train loss=0.26751190423965454
[15/23] Train loss=0.2870250940322876
[20/23] Train loss=0.26978346705436707
Test set avg_accuracy=77.68% avg_sensitivity=41.06%, avg_specificity=94.64% avg_auc=0.8435
Fold[3] Epoch: 52 [52/100 (52%)] Train loss=0.306649 Test loss=0.548221 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30420976877212524
[5/23] Train loss=0.35009974241256714
[10/23] Train loss=0.27493634819984436
[15/23] Train loss=0.2944220304489136
[20/23] Train loss=0.26492708921432495
Test set avg_accuracy=77.73% avg_sensitivity=41.46%, avg_specificity=94.53% avg_auc=0.8442
Fold[3] Epoch: 53 [53/100 (53%)] Train loss=0.306569 Test loss=0.545283 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2984778583049774
[5/23] Train loss=0.35813212394714355
[10/23] Train loss=0.26953306794166565
[15/23] Train loss=0.2890068590641022
[20/23] Train loss=0.2567189931869507
Test set avg_accuracy=78.99% avg_sensitivity=47.40%, avg_specificity=93.63% avg_auc=0.8485
Fold[3] Epoch: 54 [54/100 (54%)] Train loss=0.301299 Test loss=0.514405 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30739837884902954
[5/23] Train loss=0.3559350073337555
[10/23] Train loss=0.25850799679756165
[15/23] Train loss=0.2880012094974518
[20/23] Train loss=0.25497570633888245
Test set avg_accuracy=79.01% avg_sensitivity=48.56%, avg_specificity=93.12% avg_auc=0.8459
Best model saved!! Metric=-20.717904043089153!!
Fold[3] Epoch: 55 [55/100 (55%)] Train loss=0.298819 Test loss=0.524366 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2992238700389862
[5/23] Train loss=0.34375742077827454
[10/23] Train loss=0.2693753242492676
[15/23] Train loss=0.2904728949069977
[20/23] Train loss=0.25866568088531494
Test set avg_accuracy=78.60% avg_sensitivity=44.81%, avg_specificity=94.25% avg_auc=0.8430
Fold[3] Epoch: 56 [56/100 (56%)] Train loss=0.295633 Test loss=0.546983 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29322054982185364
[5/23] Train loss=0.3408181965351105
[10/23] Train loss=0.2682427763938904
[15/23] Train loss=0.2882598042488098
[20/23] Train loss=0.26025626063346863
Test set avg_accuracy=78.87% avg_sensitivity=47.46%, avg_specificity=93.41% avg_auc=0.8447
Fold[3] Epoch: 57 [57/100 (57%)] Train loss=0.295277 Test loss=0.513643 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.293192058801651
[5/23] Train loss=0.3375016152858734
[10/23] Train loss=0.2606860101222992
[15/23] Train loss=0.279829740524292
[20/23] Train loss=0.2523462474346161
Test set avg_accuracy=78.33% avg_sensitivity=44.61%, avg_specificity=93.95% avg_auc=0.8427
Fold[3] Epoch: 58 [58/100 (58%)] Train loss=0.291920 Test loss=0.546340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.298717737197876
[5/23] Train loss=0.33278343081474304
[10/23] Train loss=0.2524004876613617
[15/23] Train loss=0.2704859673976898
[20/23] Train loss=0.2458076924085617
Test set avg_accuracy=78.76% avg_sensitivity=45.27%, avg_specificity=94.27% avg_auc=0.8408
Fold[3] Epoch: 59 [59/100 (59%)] Train loss=0.288653 Test loss=0.531131 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2905179560184479
[5/23] Train loss=0.3417370021343231
[10/23] Train loss=0.24629241228103638
[15/23] Train loss=0.2755688428878784
[20/23] Train loss=0.24748843908309937
Test set avg_accuracy=78.66% avg_sensitivity=46.30%, avg_specificity=93.64% avg_auc=0.8477
Fold[3] Epoch: 60 [60/100 (60%)] Train loss=0.285782 Test loss=0.527620 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2863433361053467
[5/23] Train loss=0.33549243211746216
[10/23] Train loss=0.2466057389974594
[15/23] Train loss=0.26363909244537354
[20/23] Train loss=0.24147535860538483
Test set avg_accuracy=78.90% avg_sensitivity=48.52%, avg_specificity=92.96% avg_auc=0.8460
Fold[3] Epoch: 61 [61/100 (61%)] Train loss=0.279984 Test loss=0.528897 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26992666721343994
[5/23] Train loss=0.3250584304332733
[10/23] Train loss=0.2445177286863327
[15/23] Train loss=0.26591503620147705
[20/23] Train loss=0.24049261212348938
Test set avg_accuracy=78.69% avg_sensitivity=47.16%, avg_specificity=93.29% avg_auc=0.8485
Fold[3] Epoch: 62 [62/100 (62%)] Train loss=0.278714 Test loss=0.537766 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2786528766155243
[5/23] Train loss=0.3253243565559387
[10/23] Train loss=0.24594862759113312
[15/23] Train loss=0.2628861665725708
[20/23] Train loss=0.24525918066501617
Test set avg_accuracy=78.86% avg_sensitivity=47.60%, avg_specificity=93.33% avg_auc=0.8458
Fold[3] Epoch: 63 [63/100 (63%)] Train loss=0.277912 Test loss=0.540683 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2774386405944824
[5/23] Train loss=0.32815980911254883
[10/23] Train loss=0.25665029883384705
[15/23] Train loss=0.2581588625907898
[20/23] Train loss=0.2530500590801239
Test set avg_accuracy=78.49% avg_sensitivity=44.61%, avg_specificity=94.18% avg_auc=0.8466
Fold[3] Epoch: 64 [64/100 (64%)] Train loss=0.277414 Test loss=0.549484 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.278763085603714
[5/23] Train loss=0.31436026096343994
[10/23] Train loss=0.24522404372692108
[15/23] Train loss=0.25509390234947205
[20/23] Train loss=0.25271791219711304
Test set avg_accuracy=77.65% avg_sensitivity=42.29%, avg_specificity=94.02% avg_auc=0.8429
Fold[3] Epoch: 65 [65/100 (65%)] Train loss=0.275910 Test loss=0.570566 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2646510601043701
[5/23] Train loss=0.3120962083339691
[10/23] Train loss=0.2394656240940094
[15/23] Train loss=0.26145753264427185
[20/23] Train loss=0.2345263659954071
Test set avg_accuracy=77.50% avg_sensitivity=40.53%, avg_specificity=94.62% avg_auc=0.8367
Fold[3] Epoch: 66 [66/100 (66%)] Train loss=0.274305 Test loss=0.559571 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27459901571273804
[5/23] Train loss=0.32674503326416016
[10/23] Train loss=0.23718036711215973
[15/23] Train loss=0.25189653038978577
[20/23] Train loss=0.23802968859672546
Test set avg_accuracy=78.65% avg_sensitivity=43.91%, avg_specificity=94.73% avg_auc=0.8418
Fold[3] Epoch: 67 [67/100 (67%)] Train loss=0.272028 Test loss=0.555559 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26988133788108826
[5/23] Train loss=0.32736140489578247
[10/23] Train loss=0.23645304143428802
[15/23] Train loss=0.2624950706958771
[20/23] Train loss=0.23547308146953583
Test set avg_accuracy=78.98% avg_sensitivity=47.86%, avg_specificity=93.39% avg_auc=0.8421
Fold[3] Epoch: 68 [68/100 (68%)] Train loss=0.269318 Test loss=0.538104 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27347803115844727
[5/23] Train loss=0.3103555142879486
[10/23] Train loss=0.23704728484153748
[15/23] Train loss=0.2489214986562729
[20/23] Train loss=0.2299724519252777
Test set avg_accuracy=78.72% avg_sensitivity=47.50%, avg_specificity=93.18% avg_auc=0.8441
Fold[3] Epoch: 69 [69/100 (69%)] Train loss=0.263713 Test loss=0.537888 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2626344859600067
[5/23] Train loss=0.3066091239452362
[10/23] Train loss=0.23216567933559418
[15/23] Train loss=0.2417679727077484
[20/23] Train loss=0.2292204350233078
Test set avg_accuracy=78.33% avg_sensitivity=46.93%, avg_specificity=92.87% avg_auc=0.8403
Fold[3] Epoch: 70 [70/100 (70%)] Train loss=0.261472 Test loss=0.562176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25595054030418396
[5/23] Train loss=0.3126765191555023
[10/23] Train loss=0.2369784265756607
[15/23] Train loss=0.23752784729003906
[20/23] Train loss=0.23462708294391632
Test set avg_accuracy=77.98% avg_sensitivity=43.45%, avg_specificity=93.98% avg_auc=0.8352
Fold[3] Epoch: 71 [71/100 (71%)] Train loss=0.260621 Test loss=0.582695 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2574640214443207
[5/23] Train loss=0.31231337785720825
[10/23] Train loss=0.24681641161441803
[15/23] Train loss=0.2406647950410843
[20/23] Train loss=0.22775807976722717
Test set avg_accuracy=78.62% avg_sensitivity=46.27%, avg_specificity=93.61% avg_auc=0.8409
Fold[3] Epoch: 72 [72/100 (72%)] Train loss=0.257537 Test loss=0.570909 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25204312801361084
[5/23] Train loss=0.31133976578712463
[10/23] Train loss=0.22779880464076996
[15/23] Train loss=0.24093972146511078
[20/23] Train loss=0.22587329149246216
Test set avg_accuracy=78.26% avg_sensitivity=45.70%, avg_specificity=93.33% avg_auc=0.8370
Fold[3] Epoch: 73 [73/100 (73%)] Train loss=0.254460 Test loss=0.581412 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24996554851531982
[5/23] Train loss=0.2970615029335022
[10/23] Train loss=0.2394738644361496
[15/23] Train loss=0.23254594206809998
[20/23] Train loss=0.2398996204137802
Test set avg_accuracy=77.80% avg_sensitivity=41.13%, avg_specificity=94.78% avg_auc=0.8379
Fold[3] Epoch: 74 [74/100 (74%)] Train loss=0.256870 Test loss=0.595331 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24544695019721985
[5/23] Train loss=0.2975865304470062
[10/23] Train loss=0.2311164289712906
[15/23] Train loss=0.2248707413673401
[20/23] Train loss=0.22814975678920746
Test set avg_accuracy=78.18% avg_sensitivity=43.45%, avg_specificity=94.27% avg_auc=0.8348
Fold[3] Epoch: 75 [75/100 (75%)] Train loss=0.248612 Test loss=0.586918 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23710016906261444
[5/23] Train loss=0.30868634581565857
[10/23] Train loss=0.22454318404197693
[15/23] Train loss=0.2226199209690094
[20/23] Train loss=0.2265549600124359
Test set avg_accuracy=77.09% avg_sensitivity=40.30%, avg_specificity=94.13% avg_auc=0.8324
Fold[3] Epoch: 76 [76/100 (76%)] Train loss=0.249773 Test loss=0.630825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24195508658885956
[5/23] Train loss=0.29750514030456543
[10/23] Train loss=0.22235065698623657
[15/23] Train loss=0.22944395244121552
[20/23] Train loss=0.21913808584213257
Test set avg_accuracy=78.25% avg_sensitivity=45.44%, avg_specificity=93.44% avg_auc=0.8382
Fold[3] Epoch: 77 [77/100 (77%)] Train loss=0.247060 Test loss=0.574141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24247941374778748
[5/23] Train loss=0.31065696477890015
[10/23] Train loss=0.2273629605770111
[15/23] Train loss=0.22464892268180847
[20/23] Train loss=0.22270528972148895
Test set avg_accuracy=78.28% avg_sensitivity=43.78%, avg_specificity=94.25% avg_auc=0.8387
Fold[3] Epoch: 78 [78/100 (78%)] Train loss=0.250611 Test loss=0.578197 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2411237508058548
[5/23] Train loss=0.3083592653274536
[10/23] Train loss=0.22625653445720673
[15/23] Train loss=0.25099897384643555
[20/23] Train loss=0.21622082591056824
Test set avg_accuracy=79.06% avg_sensitivity=50.58%, avg_specificity=92.24% avg_auc=0.8328
Fold[3] Epoch: 79 [79/100 (79%)] Train loss=0.252727 Test loss=0.556342 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2534186542034149
[5/23] Train loss=0.3087823688983917
[10/23] Train loss=0.21719799935817719
[15/23] Train loss=0.24306921660900116
[20/23] Train loss=0.22038523852825165
Test set avg_accuracy=78.29% avg_sensitivity=48.86%, avg_specificity=91.92% avg_auc=0.8356
Fold[3] Epoch: 80 [80/100 (80%)] Train loss=0.246316 Test loss=0.576011 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23957207798957825
[5/23] Train loss=0.2950136065483093
[10/23] Train loss=0.21631285548210144
[15/23] Train loss=0.22921594977378845
[20/23] Train loss=0.21214009821414948
Test set avg_accuracy=78.65% avg_sensitivity=48.86%, avg_specificity=92.44% avg_auc=0.8320
Fold[3] Epoch: 81 [81/100 (81%)] Train loss=0.240467 Test loss=0.586996 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24119596183300018
[5/23] Train loss=0.294768363237381
[10/23] Train loss=0.2076687514781952
[15/23] Train loss=0.22717233002185822
[20/23] Train loss=0.21294842660427094
Test set avg_accuracy=78.81% avg_sensitivity=49.22%, avg_specificity=92.52% avg_auc=0.8388
Fold[3] Epoch: 82 [82/100 (82%)] Train loss=0.237956 Test loss=0.564888 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2440354973077774
[5/23] Train loss=0.2933397591114044
[10/23] Train loss=0.20447072386741638
[15/23] Train loss=0.21796318888664246
[20/23] Train loss=0.2147042155265808
Test set avg_accuracy=78.23% avg_sensitivity=45.44%, avg_specificity=93.41% avg_auc=0.8282
Fold[3] Epoch: 83 [83/100 (83%)] Train loss=0.234267 Test loss=0.585410 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22436048090457916
[5/23] Train loss=0.28274643421173096
[10/23] Train loss=0.22188854217529297
[15/23] Train loss=0.2243412733078003
[20/23] Train loss=0.21131740510463715
Test set avg_accuracy=78.14% avg_sensitivity=44.38%, avg_specificity=93.78% avg_auc=0.8281
Fold[3] Epoch: 84 [84/100 (84%)] Train loss=0.236088 Test loss=0.611369 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2199220508337021
[5/23] Train loss=0.28784841299057007
[10/23] Train loss=0.2156371921300888
[15/23] Train loss=0.22296497225761414
[20/23] Train loss=0.2159530520439148
Test set avg_accuracy=78.09% avg_sensitivity=43.05%, avg_specificity=94.32% avg_auc=0.8302
Fold[3] Epoch: 85 [85/100 (85%)] Train loss=0.234766 Test loss=0.619242 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22158169746398926
[5/23] Train loss=0.28413957357406616
[10/23] Train loss=0.21440893411636353
[15/23] Train loss=0.21618561446666718
[20/23] Train loss=0.20400087535381317
Test set avg_accuracy=77.76% avg_sensitivity=44.41%, avg_specificity=93.21% avg_auc=0.8317
Fold[3] Epoch: 86 [86/100 (86%)] Train loss=0.237635 Test loss=0.622973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23101496696472168
[5/23] Train loss=0.2976733148097992
[10/23] Train loss=0.20820915699005127
[15/23] Train loss=0.21197067201137543
[20/23] Train loss=0.21130332350730896
Test set avg_accuracy=77.76% avg_sensitivity=44.44%, avg_specificity=93.20% avg_auc=0.8309
Fold[3] Epoch: 87 [87/100 (87%)] Train loss=0.230953 Test loss=0.615123 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21273057162761688
[5/23] Train loss=0.28514862060546875
[10/23] Train loss=0.20318694412708282
[15/23] Train loss=0.20567388832569122
[20/23] Train loss=0.2029314786195755
Test set avg_accuracy=78.89% avg_sensitivity=50.55%, avg_specificity=92.01% avg_auc=0.8306
Fold[3] Epoch: 88 [88/100 (88%)] Train loss=0.224545 Test loss=0.592740 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2243318408727646
[5/23] Train loss=0.27919068932533264
[10/23] Train loss=0.20095323026180267
[15/23] Train loss=0.198002889752388
[20/23] Train loss=0.19712519645690918
Test set avg_accuracy=77.95% avg_sensitivity=44.78%, avg_specificity=93.32% avg_auc=0.8332
Fold[3] Epoch: 89 [89/100 (89%)] Train loss=0.223449 Test loss=0.621392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20706425607204437
[5/23] Train loss=0.2729721963405609
[10/23] Train loss=0.1975846290588379
[15/23] Train loss=0.201363667845726
[20/23] Train loss=0.20126166939735413
Test set avg_accuracy=78.45% avg_sensitivity=48.86%, avg_specificity=92.15% avg_auc=0.8305
Fold[3] Epoch: 90 [90/100 (90%)] Train loss=0.220015 Test loss=0.607469 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22126159071922302
[5/23] Train loss=0.28779008984565735
[10/23] Train loss=0.19398239254951477
[15/23] Train loss=0.21168747544288635
[20/23] Train loss=0.19427452981472015
Test set avg_accuracy=78.05% avg_sensitivity=47.10%, avg_specificity=92.38% avg_auc=0.8340
Fold[3] Epoch: 91 [91/100 (91%)] Train loss=0.222799 Test loss=0.618038 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2028115689754486
[5/23] Train loss=0.26923465728759766
[10/23] Train loss=0.20014168322086334
[15/23] Train loss=0.19667255878448486
[20/23] Train loss=0.19510412216186523
Test set avg_accuracy=78.30% avg_sensitivity=47.33%, avg_specificity=92.64% avg_auc=0.8259
Fold[3] Epoch: 92 [92/100 (92%)] Train loss=0.216116 Test loss=0.632491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.200944721698761
[5/23] Train loss=0.2782285213470459
[10/23] Train loss=0.18954090774059296
[15/23] Train loss=0.19015267491340637
[20/23] Train loss=0.18837854266166687
Test set avg_accuracy=78.06% avg_sensitivity=46.57%, avg_specificity=92.64% avg_auc=0.8383
Fold[3] Epoch: 93 [93/100 (93%)] Train loss=0.215030 Test loss=0.637045 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20308396220207214
[5/23] Train loss=0.27823933959007263
[10/23] Train loss=0.18592317402362823
[15/23] Train loss=0.18451067805290222
[20/23] Train loss=0.19120460748672485
Test set avg_accuracy=78.66% avg_sensitivity=47.53%, avg_specificity=93.07% avg_auc=0.8225
Fold[3] Epoch: 94 [94/100 (94%)] Train loss=0.212715 Test loss=0.609692 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20564521849155426
[5/23] Train loss=0.28261011838912964
[10/23] Train loss=0.20106764137744904
[15/23] Train loss=0.19898049533367157
[20/23] Train loss=0.19626407325267792
Test set avg_accuracy=78.95% avg_sensitivity=52.17%, avg_specificity=91.35% avg_auc=0.8333
Best model saved!! Metric=-20.200391116252497!!
Fold[3] Epoch: 95 [95/100 (95%)] Train loss=0.220174 Test loss=0.601770 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20555651187896729
[5/23] Train loss=0.26795896887779236
[10/23] Train loss=0.19438105821609497
[15/23] Train loss=0.1835511475801468
[20/23] Train loss=0.1928182691335678
Test set avg_accuracy=78.37% avg_sensitivity=45.44%, avg_specificity=93.63% avg_auc=0.8300
Fold[3] Epoch: 96 [96/100 (96%)] Train loss=0.211982 Test loss=0.651013 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19684623181819916
[5/23] Train loss=0.26362746953964233
[10/23] Train loss=0.205763578414917
[15/23] Train loss=0.19881650805473328
[20/23] Train loss=0.19552408158779144
Test set avg_accuracy=77.69% avg_sensitivity=45.14%, avg_specificity=92.76% avg_auc=0.8307
Fold[3] Epoch: 97 [97/100 (97%)] Train loss=0.211284 Test loss=0.652901 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18794043362140656
[5/23] Train loss=0.2708966135978699
[10/23] Train loss=0.18312563002109528
[15/23] Train loss=0.18860328197479248
[20/23] Train loss=0.19600823521614075
Test set avg_accuracy=77.42% avg_sensitivity=43.35%, avg_specificity=93.20% avg_auc=0.8271
Fold[3] Epoch: 98 [98/100 (98%)] Train loss=0.208563 Test loss=0.649378 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20138631761074066
[5/23] Train loss=0.24920611083507538
[10/23] Train loss=0.1844911277294159
[15/23] Train loss=0.18258750438690186
[20/23] Train loss=0.18574391305446625
Test set avg_accuracy=76.72% avg_sensitivity=38.77%, avg_specificity=94.30% avg_auc=0.8258
Fold[3] Epoch: 99 [99/100 (99%)] Train loss=0.204385 Test loss=0.687724 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19481070339679718
[5/23] Train loss=0.2702848017215729
[10/23] Train loss=0.19139014184474945
[15/23] Train loss=0.19180834293365479
[20/23] Train loss=0.19474056363105774
Test set avg_accuracy=78.18% avg_sensitivity=46.24%, avg_specificity=92.98% avg_auc=0.8256
Fold[3] Epoch: 100 [100/100 (100%)] Train loss=0.208039 Test loss=0.630907 Current lr=[3.9999999999999996e-05]

Fold[3] Best Result: acc=78.9501312335958 sen=52.17247097844113, spe=91.35176651305683, auc=0.8332524015865375!
[0/23] Train loss=0.6932954788208008
[5/23] Train loss=0.6643446683883667
[10/23] Train loss=0.595548152923584
[15/23] Train loss=0.5483900308609009
[20/23] Train loss=0.5306887626647949
Test set avg_accuracy=75.73% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5795
Best model saved!! Metric=-92.31696496356977!!
Fold[4] Epoch: 1 [1/100 (1%)] Train loss=0.582023 Test loss=0.619563 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5793938636779785
[5/23] Train loss=0.583875298500061
[10/23] Train loss=0.5500165820121765
[15/23] Train loss=0.5269303321838379
[20/23] Train loss=0.4980167746543884
Test set avg_accuracy=75.81% avg_sensitivity=1.81%, avg_specificity=99.53% avg_auc=0.6197
Best model saved!! Metric=-86.87358613465604!!
Fold[4] Epoch: 2 [2/100 (2%)] Train loss=0.544345 Test loss=0.587330 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5559670925140381
[5/23] Train loss=0.5518099069595337
[10/23] Train loss=0.5112572312355042
[15/23] Train loss=0.5018412470817566
[20/23] Train loss=0.4576893448829651
Test set avg_accuracy=76.04% avg_sensitivity=10.82%, avg_specificity=96.95% avg_auc=0.6723
Best model saved!! Metric=-74.95647303102267!!
Fold[4] Epoch: 3 [3/100 (3%)] Train loss=0.515010 Test loss=0.567657 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5189555287361145
[5/23] Train loss=0.4936705231666565
[10/23] Train loss=0.4667014479637146
[15/23] Train loss=0.4720492660999298
[20/23] Train loss=0.4148464798927307
Test set avg_accuracy=76.24% avg_sensitivity=18.41%, avg_specificity=94.78% avg_auc=0.7210
Best model saved!! Metric=-64.46745277139506!!
Fold[4] Epoch: 4 [4/100 (4%)] Train loss=0.479821 Test loss=0.556244 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4836066961288452
[5/23] Train loss=0.4558231234550476
[10/23] Train loss=0.42818084359169006
[15/23] Train loss=0.45683813095092773
[20/23] Train loss=0.4006561040878296
Test set avg_accuracy=77.15% avg_sensitivity=24.32%, avg_specificity=94.09% avg_auc=0.7650
Best model saved!! Metric=-53.94023812337347!!
Fold[4] Epoch: 5 [5/100 (5%)] Train loss=0.455172 Test loss=0.521614 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.46188732981681824
[5/23] Train loss=0.4474138021469116
[10/23] Train loss=0.40458881855010986
[15/23] Train loss=0.44221675395965576
[20/23] Train loss=0.40067803859710693
Test set avg_accuracy=78.39% avg_sensitivity=29.88%, avg_specificity=93.93% avg_auc=0.7912
Best model saved!! Metric=-44.67675638705676!!
Fold[4] Epoch: 6 [6/100 (6%)] Train loss=0.442733 Test loss=0.487776 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44912880659103394
[5/23] Train loss=0.4409843385219574
[10/23] Train loss=0.39882105588912964
[15/23] Train loss=0.43858152627944946
[20/23] Train loss=0.39038538932800293
Test set avg_accuracy=79.16% avg_sensitivity=33.20%, avg_specificity=93.89% avg_auc=0.8057
Best model saved!! Metric=-39.17099917305323!!
Fold[4] Epoch: 7 [7/100 (7%)] Train loss=0.436258 Test loss=0.466180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4469107687473297
[5/23] Train loss=0.43339765071868896
[10/23] Train loss=0.39152273535728455
[15/23] Train loss=0.43704870343208313
[20/23] Train loss=0.37922462821006775
Test set avg_accuracy=79.76% avg_sensitivity=36.65%, avg_specificity=93.57% avg_auc=0.8119
Best model saved!! Metric=-34.8209228266151!!
Fold[4] Epoch: 8 [8/100 (8%)] Train loss=0.430406 Test loss=0.454842 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4361039698123932
[5/23] Train loss=0.435619980096817
[10/23] Train loss=0.3807810842990875
[15/23] Train loss=0.43524879217147827
[20/23] Train loss=0.3761358857154846
Test set avg_accuracy=79.41% avg_sensitivity=34.28%, avg_specificity=93.88% avg_auc=0.8180
Fold[4] Epoch: 9 [9/100 (9%)] Train loss=0.427750 Test loss=0.459162 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4244518578052521
[5/23] Train loss=0.4352855086326599
[10/23] Train loss=0.37634891271591187
[15/23] Train loss=0.42301130294799805
[20/23] Train loss=0.3697987496852875
Test set avg_accuracy=79.22% avg_sensitivity=32.73%, avg_specificity=94.11% avg_auc=0.8152
Fold[4] Epoch: 10 [10/100 (10%)] Train loss=0.425264 Test loss=0.479442 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41058188676834106
[5/23] Train loss=0.43018776178359985
[10/23] Train loss=0.39031216502189636
[15/23] Train loss=0.40293586254119873
[20/23] Train loss=0.3701518774032593
Test set avg_accuracy=79.22% avg_sensitivity=32.17%, avg_specificity=94.29% avg_auc=0.8165
Fold[4] Epoch: 11 [11/100 (11%)] Train loss=0.421085 Test loss=0.490321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4090029001235962
[5/23] Train loss=0.41476497054100037
[10/23] Train loss=0.3858247995376587
[15/23] Train loss=0.39384427666664124
[20/23] Train loss=0.3597027659416199
Test set avg_accuracy=79.85% avg_sensitivity=35.49%, avg_specificity=94.07% avg_auc=0.8274
Best model saved!! Metric=-33.8488766739782!!
Fold[4] Epoch: 12 [12/100 (12%)] Train loss=0.413128 Test loss=0.468854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40580490231513977
[5/23] Train loss=0.40516138076782227
[10/23] Train loss=0.3680068850517273
[15/23] Train loss=0.38618555665016174
[20/23] Train loss=0.3616061508655548
Test set avg_accuracy=80.52% avg_sensitivity=38.77%, avg_specificity=93.91% avg_auc=0.8371
Best model saved!! Metric=-29.091618611475894!!
Fold[4] Epoch: 13 [13/100 (13%)] Train loss=0.406487 Test loss=0.444826 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4124244153499603
[5/23] Train loss=0.40559208393096924
[10/23] Train loss=0.374060720205307
[15/23] Train loss=0.3917524516582489
[20/23] Train loss=0.3487819731235504
Test set avg_accuracy=80.55% avg_sensitivity=38.68%, avg_specificity=93.97% avg_auc=0.8406
Best model saved!! Metric=-28.72790882558759!!
Fold[4] Epoch: 14 [14/100 (14%)] Train loss=0.404095 Test loss=0.443337 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.403565913438797
[5/23] Train loss=0.405000239610672
[10/23] Train loss=0.3652760684490204
[15/23] Train loss=0.39150509238243103
[20/23] Train loss=0.35044655203819275
Test set avg_accuracy=80.87% avg_sensitivity=41.14%, avg_specificity=93.60% avg_auc=0.8450
Best model saved!! Metric=-25.891989301946086!!
Fold[4] Epoch: 15 [15/100 (15%)] Train loss=0.403989 Test loss=0.428825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3981446325778961
[5/23] Train loss=0.40196749567985535
[10/23] Train loss=0.3592534065246582
[15/23] Train loss=0.3775956630706787
[20/23] Train loss=0.3431437611579895
Test set avg_accuracy=80.77% avg_sensitivity=39.93%, avg_specificity=93.86% avg_auc=0.8449
Fold[4] Epoch: 16 [16/100 (16%)] Train loss=0.399433 Test loss=0.434081 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39793315529823303
[5/23] Train loss=0.39577731490135193
[10/23] Train loss=0.357626736164093
[15/23] Train loss=0.3755336105823517
[20/23] Train loss=0.33746767044067383
Test set avg_accuracy=81.21% avg_sensitivity=42.69%, avg_specificity=93.56% avg_auc=0.8503
Best model saved!! Metric=-23.507635228520755!!
Fold[4] Epoch: 17 [17/100 (17%)] Train loss=0.396428 Test loss=0.424340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3938634991645813
[5/23] Train loss=0.396310418844223
[10/23] Train loss=0.3541582524776459
[15/23] Train loss=0.369648277759552
[20/23] Train loss=0.3365682065486908
Test set avg_accuracy=80.81% avg_sensitivity=39.80%, avg_specificity=93.95% avg_auc=0.8494
Fold[4] Epoch: 18 [18/100 (18%)] Train loss=0.394667 Test loss=0.426202 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38885611295700073
[5/23] Train loss=0.3893432021141052
[10/23] Train loss=0.3501459062099457
[15/23] Train loss=0.3564472198486328
[20/23] Train loss=0.33625781536102295
Test set avg_accuracy=80.93% avg_sensitivity=41.31%, avg_specificity=93.63% avg_auc=0.8504
Fold[4] Epoch: 19 [19/100 (19%)] Train loss=0.390697 Test loss=0.426172 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3948381841182709
[5/23] Train loss=0.38091400265693665
[10/23] Train loss=0.34134015440940857
[15/23] Train loss=0.35614851117134094
[20/23] Train loss=0.33282583951950073
Test set avg_accuracy=81.36% avg_sensitivity=43.98%, avg_specificity=93.34% avg_auc=0.8555
Best model saved!! Metric=-21.766821445492415!!
Fold[4] Epoch: 20 [20/100 (20%)] Train loss=0.387696 Test loss=0.414136 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3784990608692169
[5/23] Train loss=0.3832099139690399
[10/23] Train loss=0.34500637650489807
[15/23] Train loss=0.3593674302101135
[20/23] Train loss=0.33238133788108826
Test set avg_accuracy=81.08% avg_sensitivity=42.30%, avg_specificity=93.50% avg_auc=0.8519
Fold[4] Epoch: 21 [21/100 (21%)] Train loss=0.385326 Test loss=0.421775 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3786194622516632
[5/23] Train loss=0.38749024271965027
[10/23] Train loss=0.3390565514564514
[15/23] Train loss=0.35896003246307373
[20/23] Train loss=0.3197805881500244
Test set avg_accuracy=81.67% avg_sensitivity=45.62%, avg_specificity=93.23% avg_auc=0.8528
Best model saved!! Metric=-20.190123756237014!!
Fold[4] Epoch: 22 [22/100 (22%)] Train loss=0.385180 Test loss=0.412758 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38448119163513184
[5/23] Train loss=0.3773591220378876
[10/23] Train loss=0.3346162736415863
[15/23] Train loss=0.3416019678115845
[20/23] Train loss=0.33025333285331726
Test set avg_accuracy=81.37% avg_sensitivity=44.33%, avg_specificity=93.24% avg_auc=0.8543
Fold[4] Epoch: 23 [23/100 (23%)] Train loss=0.378792 Test loss=0.422893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3746926188468933
[5/23] Train loss=0.37726640701293945
[10/23] Train loss=0.3363942801952362
[15/23] Train loss=0.34668076038360596
[20/23] Train loss=0.32242274284362793
Test set avg_accuracy=82.26% avg_sensitivity=50.37%, avg_specificity=92.48% avg_auc=0.8547
Best model saved!! Metric=-15.420407184019375!!
Fold[4] Epoch: 24 [24/100 (24%)] Train loss=0.378544 Test loss=0.408347 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37692224979400635
[5/23] Train loss=0.37255871295928955
[10/23] Train loss=0.3326275050640106
[15/23] Train loss=0.34043803811073303
[20/23] Train loss=0.31771084666252136
Test set avg_accuracy=82.62% avg_sensitivity=51.19%, avg_specificity=92.69% avg_auc=0.8531
Best model saved!! Metric=-14.19462302314168!!
Fold[4] Epoch: 25 [25/100 (25%)] Train loss=0.376647 Test loss=0.410273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37533730268478394
[5/23] Train loss=0.3700530230998993
[10/23] Train loss=0.3426938056945801
[15/23] Train loss=0.3368012607097626
[20/23] Train loss=0.3157416880130768
Test set avg_accuracy=82.39% avg_sensitivity=48.86%, avg_specificity=93.13% avg_auc=0.8504
Fold[4] Epoch: 26 [26/100 (26%)] Train loss=0.374592 Test loss=0.419766 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3811708092689514
[5/23] Train loss=0.36465534567832947
[10/23] Train loss=0.31629908084869385
[15/23] Train loss=0.34134945273399353
[20/23] Train loss=0.31364402174949646
Test set avg_accuracy=82.90% avg_sensitivity=58.69%, avg_specificity=90.66% avg_auc=0.8571
Best model saved!! Metric=-8.048318734902901!!
Fold[4] Epoch: 27 [27/100 (27%)] Train loss=0.372089 Test loss=0.404020 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3712906539440155
[5/23] Train loss=0.3691881000995636
[10/23] Train loss=0.3204801380634308
[15/23] Train loss=0.33934319019317627
[20/23] Train loss=0.3220668137073517
Test set avg_accuracy=82.69% avg_sensitivity=55.54%, avg_specificity=91.39% avg_auc=0.8503
Fold[4] Epoch: 28 [28/100 (28%)] Train loss=0.375023 Test loss=0.412802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37590572237968445
[5/23] Train loss=0.3609713315963745
[10/23] Train loss=0.32327643036842346
[15/23] Train loss=0.334911048412323
[20/23] Train loss=0.3179040551185608
Test set avg_accuracy=82.46% avg_sensitivity=52.44%, avg_specificity=92.08% avg_auc=0.8540
Fold[4] Epoch: 29 [29/100 (29%)] Train loss=0.370055 Test loss=0.408998 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3705458641052246
[5/23] Train loss=0.36437129974365234
[10/23] Train loss=0.319690465927124
[15/23] Train loss=0.32991844415664673
[20/23] Train loss=0.31579354405403137
Test set avg_accuracy=82.46% avg_sensitivity=50.67%, avg_specificity=92.65% avg_auc=0.8538
Fold[4] Epoch: 30 [30/100 (30%)] Train loss=0.368992 Test loss=0.407322 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3647359013557434
[5/23] Train loss=0.3616943359375
[10/23] Train loss=0.31575363874435425
[15/23] Train loss=0.342960000038147
[20/23] Train loss=0.309632807970047
Test set avg_accuracy=82.50% avg_sensitivity=54.16%, avg_specificity=91.58% avg_auc=0.8564
Fold[4] Epoch: 31 [31/100 (31%)] Train loss=0.365968 Test loss=0.407993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36086276173591614
[5/23] Train loss=0.3588884174823761
[10/23] Train loss=0.3099936544895172
[15/23] Train loss=0.3275749683380127
[20/23] Train loss=0.30428922176361084
Test set avg_accuracy=82.77% avg_sensitivity=53.77%, avg_specificity=92.07% avg_auc=0.8586
Fold[4] Epoch: 32 [32/100 (32%)] Train loss=0.362795 Test loss=0.409171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3614718019962311
[5/23] Train loss=0.3548326790332794
[10/23] Train loss=0.31760743260383606
[15/23] Train loss=0.3180946111679077
[20/23] Train loss=0.30478888750076294
Test set avg_accuracy=82.74% avg_sensitivity=50.50%, avg_specificity=93.08% avg_auc=0.8613
Fold[4] Epoch: 33 [33/100 (33%)] Train loss=0.361195 Test loss=0.413402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3580878674983978
[5/23] Train loss=0.3525569438934326
[10/23] Train loss=0.312529057264328
[15/23] Train loss=0.32295361161231995
[20/23] Train loss=0.3095402419567108
Test set avg_accuracy=82.83% avg_sensitivity=53.73%, avg_specificity=92.15% avg_auc=0.8621
Fold[4] Epoch: 34 [34/100 (34%)] Train loss=0.358947 Test loss=0.413311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34967416524887085
[5/23] Train loss=0.35191789269447327
[10/23] Train loss=0.3080587387084961
[15/23] Train loss=0.31105297803878784
[20/23] Train loss=0.29745298624038696
Test set avg_accuracy=82.99% avg_sensitivity=53.26%, avg_specificity=92.52% avg_auc=0.8620
Fold[4] Epoch: 35 [35/100 (35%)] Train loss=0.353477 Test loss=0.416803 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35075798630714417
[5/23] Train loss=0.3436337113380432
[10/23] Train loss=0.30993813276290894
[15/23] Train loss=0.3166865110397339
[20/23] Train loss=0.29518213868141174
Test set avg_accuracy=83.10% avg_sensitivity=54.72%, avg_specificity=92.19% avg_auc=0.8630
Fold[4] Epoch: 36 [36/100 (36%)] Train loss=0.350806 Test loss=0.414004 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3528214991092682
[5/23] Train loss=0.3389352560043335
[10/23] Train loss=0.30327361822128296
[15/23] Train loss=0.31297409534454346
[20/23] Train loss=0.3011462688446045
Test set avg_accuracy=83.37% avg_sensitivity=54.33%, avg_specificity=92.68% avg_auc=0.8627
Fold[4] Epoch: 37 [37/100 (37%)] Train loss=0.350621 Test loss=0.410811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3463480770587921
[5/23] Train loss=0.34068408608436584
[10/23] Train loss=0.2981278896331787
[15/23] Train loss=0.3112301230430603
[20/23] Train loss=0.2877923846244812
Test set avg_accuracy=83.57% avg_sensitivity=56.58%, avg_specificity=92.22% avg_auc=0.8624
Best model saved!! Metric=-7.391757061091029!!
Fold[4] Epoch: 38 [38/100 (38%)] Train loss=0.347039 Test loss=0.415765 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34229496121406555
[5/23] Train loss=0.3346693813800812
[10/23] Train loss=0.2999553978443146
[15/23] Train loss=0.30599716305732727
[20/23] Train loss=0.2955964207649231
Test set avg_accuracy=82.89% avg_sensitivity=52.09%, avg_specificity=92.76% avg_auc=0.8609
Fold[4] Epoch: 39 [39/100 (39%)] Train loss=0.343863 Test loss=0.423296 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3425534665584564
[5/23] Train loss=0.34399884939193726
[10/23] Train loss=0.2935797870159149
[15/23] Train loss=0.3118568956851959
[20/23] Train loss=0.2859004735946655
Test set avg_accuracy=83.79% avg_sensitivity=57.65%, avg_specificity=92.16% avg_auc=0.8634
Best model saved!! Metric=-6.057031468514996!!
Fold[4] Epoch: 40 [40/100 (40%)] Train loss=0.343246 Test loss=0.416747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3369598686695099
[5/23] Train loss=0.3348584771156311
[10/23] Train loss=0.29661136865615845
[15/23] Train loss=0.3030504286289215
[20/23] Train loss=0.29156526923179626
Test set avg_accuracy=82.91% avg_sensitivity=51.23%, avg_specificity=93.06% avg_auc=0.8619
Fold[4] Epoch: 41 [41/100 (41%)] Train loss=0.344369 Test loss=0.421367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33621349930763245
[5/23] Train loss=0.3286159932613373
[10/23] Train loss=0.29459086060523987
[15/23] Train loss=0.3047921359539032
[20/23] Train loss=0.2879091501235962
Test set avg_accuracy=83.37% avg_sensitivity=57.91%, avg_specificity=91.53% avg_auc=0.8619
Fold[4] Epoch: 42 [42/100 (42%)] Train loss=0.337931 Test loss=0.425596 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33788666129112244
[5/23] Train loss=0.32759717106819153
[10/23] Train loss=0.2963346540927887
[15/23] Train loss=0.29851800203323364
[20/23] Train loss=0.28121861815452576
Test set avg_accuracy=83.31% avg_sensitivity=54.98%, avg_specificity=92.39% avg_auc=0.8625
Fold[4] Epoch: 43 [43/100 (43%)] Train loss=0.335798 Test loss=0.422950 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33382779359817505
[5/23] Train loss=0.32605838775634766
[10/23] Train loss=0.29255411028862
[15/23] Train loss=0.29144778847694397
[20/23] Train loss=0.2836398482322693
Test set avg_accuracy=83.47% avg_sensitivity=56.19%, avg_specificity=92.22% avg_auc=0.8622
Fold[4] Epoch: 44 [44/100 (44%)] Train loss=0.331332 Test loss=0.426799 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3348003923892975
[5/23] Train loss=0.32213976979255676
[10/23] Train loss=0.28674235939979553
[15/23] Train loss=0.29086560010910034
[20/23] Train loss=0.28021278977394104
Test set avg_accuracy=83.37% avg_sensitivity=56.58%, avg_specificity=91.96% avg_auc=0.8617
Fold[4] Epoch: 45 [45/100 (45%)] Train loss=0.331512 Test loss=0.426335 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32511016726493835
[5/23] Train loss=0.3222677409648895
[10/23] Train loss=0.2868776321411133
[15/23] Train loss=0.28460222482681274
[20/23] Train loss=0.27912360429763794
Test set avg_accuracy=83.55% avg_sensitivity=57.40%, avg_specificity=91.93% avg_auc=0.8630
Fold[4] Epoch: 46 [46/100 (46%)] Train loss=0.328590 Test loss=0.421756 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33013617992401123
[5/23] Train loss=0.3159535527229309
[10/23] Train loss=0.27080991864204407
[15/23] Train loss=0.2807401418685913
[20/23] Train loss=0.273798406124115
Test set avg_accuracy=83.58% avg_sensitivity=56.62%, avg_specificity=92.22% avg_auc=0.8649
Fold[4] Epoch: 47 [47/100 (47%)] Train loss=0.324670 Test loss=0.418464 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32861724495887756
[5/23] Train loss=0.30904725193977356
[10/23] Train loss=0.28172188997268677
[15/23] Train loss=0.28212469816207886
[20/23] Train loss=0.27306637167930603
Test set avg_accuracy=83.38% avg_sensitivity=55.80%, avg_specificity=92.22% avg_auc=0.8640
Fold[4] Epoch: 48 [48/100 (48%)] Train loss=0.322510 Test loss=0.423660 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.328938364982605
[5/23] Train loss=0.3101635277271271
[10/23] Train loss=0.2815268337726593
[15/23] Train loss=0.2858220636844635
[20/23] Train loss=0.2711234986782074
Test set avg_accuracy=83.21% avg_sensitivity=57.18%, avg_specificity=91.56% avg_auc=0.8644
Fold[4] Epoch: 49 [49/100 (49%)] Train loss=0.319638 Test loss=0.424430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3230440616607666
[5/23] Train loss=0.309311181306839
[10/23] Train loss=0.2802930474281311
[15/23] Train loss=0.27366721630096436
[20/23] Train loss=0.2753153443336487
Test set avg_accuracy=83.18% avg_sensitivity=53.00%, avg_specificity=92.86% avg_auc=0.8641
Fold[4] Epoch: 50 [50/100 (50%)] Train loss=0.319808 Test loss=0.423756 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3124324381351471
[5/23] Train loss=0.3099645674228668
[10/23] Train loss=0.2771390378475189
[15/23] Train loss=0.2846721410751343
[20/23] Train loss=0.26496973633766174
Test set avg_accuracy=83.50% avg_sensitivity=56.19%, avg_specificity=92.25% avg_auc=0.8643
Fold[4] Epoch: 51 [51/100 (51%)] Train loss=0.313595 Test loss=0.426182 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31877920031547546
[5/23] Train loss=0.29995447397232056
[10/23] Train loss=0.27608954906463623
[15/23] Train loss=0.2690747082233429
[20/23] Train loss=0.2660118341445923
Test set avg_accuracy=82.97% avg_sensitivity=53.43%, avg_specificity=92.44% avg_auc=0.8632
Fold[4] Epoch: 52 [52/100 (52%)] Train loss=0.313269 Test loss=0.428050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3160351514816284
[5/23] Train loss=0.30437976121902466
[10/23] Train loss=0.26985669136047363
[15/23] Train loss=0.28103166818618774
[20/23] Train loss=0.25763893127441406
Test set avg_accuracy=82.97% avg_sensitivity=52.78%, avg_specificity=92.65% avg_auc=0.8631
Fold[4] Epoch: 53 [53/100 (53%)] Train loss=0.310901 Test loss=0.423678 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30164897441864014
[5/23] Train loss=0.29291871190071106
[10/23] Train loss=0.2756936848163605
[15/23] Train loss=0.27040335536003113
[20/23] Train loss=0.2617972195148468
Test set avg_accuracy=83.10% avg_sensitivity=54.85%, avg_specificity=92.15% avg_auc=0.8650
Fold[4] Epoch: 54 [54/100 (54%)] Train loss=0.306913 Test loss=0.422838 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31036633253097534
[5/23] Train loss=0.3012012839317322
[10/23] Train loss=0.26456591486930847
[15/23] Train loss=0.28322309255599976
[20/23] Train loss=0.2544659376144409
Test set avg_accuracy=83.12% avg_sensitivity=54.25%, avg_specificity=92.37% avg_auc=0.8636
Fold[4] Epoch: 55 [55/100 (55%)] Train loss=0.307501 Test loss=0.430308 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3083531856536865
[5/23] Train loss=0.2971622943878174
[10/23] Train loss=0.2670547664165497
[15/23] Train loss=0.27099138498306274
[20/23] Train loss=0.25665712356567383
Test set avg_accuracy=82.98% avg_sensitivity=54.29%, avg_specificity=92.18% avg_auc=0.8647
Fold[4] Epoch: 56 [56/100 (56%)] Train loss=0.301717 Test loss=0.425751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3071316182613373
[5/23] Train loss=0.29393717646598816
[10/23] Train loss=0.2703145146369934
[15/23] Train loss=0.27074486017227173
[20/23] Train loss=0.2516584098339081
Test set avg_accuracy=83.14% avg_sensitivity=55.41%, avg_specificity=92.03% avg_auc=0.8637
Fold[4] Epoch: 57 [57/100 (57%)] Train loss=0.299500 Test loss=0.427743 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29907965660095215
[5/23] Train loss=0.29362624883651733
[10/23] Train loss=0.26061972975730896
[15/23] Train loss=0.2612501084804535
[20/23] Train loss=0.2496490180492401
Test set avg_accuracy=83.15% avg_sensitivity=54.85%, avg_specificity=92.22% avg_auc=0.8637
Fold[4] Epoch: 58 [58/100 (58%)] Train loss=0.298537 Test loss=0.434212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3002776503562927
[5/23] Train loss=0.28911763429641724
[10/23] Train loss=0.2650226354598999
[15/23] Train loss=0.25814536213874817
[20/23] Train loss=0.24741801619529724
Test set avg_accuracy=82.92% avg_sensitivity=51.92%, avg_specificity=92.86% avg_auc=0.8614
Fold[4] Epoch: 59 [59/100 (59%)] Train loss=0.297075 Test loss=0.437753 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29344794154167175
[5/23] Train loss=0.28433114290237427
[10/23] Train loss=0.27347201108932495
[15/23] Train loss=0.2525620758533478
[20/23] Train loss=0.25290563702583313
Test set avg_accuracy=82.87% avg_sensitivity=51.19%, avg_specificity=93.02% avg_auc=0.8608
Fold[4] Epoch: 60 [60/100 (60%)] Train loss=0.294400 Test loss=0.439447 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29113760590553284
[5/23] Train loss=0.28252097964286804
[10/23] Train loss=0.25680437684059143
[15/23] Train loss=0.24780870974063873
[20/23] Train loss=0.24506959319114685
Test set avg_accuracy=83.23% avg_sensitivity=56.40%, avg_specificity=91.83% avg_auc=0.8649
Fold[4] Epoch: 61 [61/100 (61%)] Train loss=0.289449 Test loss=0.437696 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30187833309173584
[5/23] Train loss=0.28273510932922363
[10/23] Train loss=0.2663028836250305
[15/23] Train loss=0.25903651118278503
[20/23] Train loss=0.24561826884746552
Test set avg_accuracy=82.96% avg_sensitivity=51.62%, avg_specificity=93.01% avg_auc=0.8627
Fold[4] Epoch: 62 [62/100 (62%)] Train loss=0.292856 Test loss=0.444106 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.285190224647522
[5/23] Train loss=0.2715284526348114
[10/23] Train loss=0.25661271810531616
[15/23] Train loss=0.24776063859462738
[20/23] Train loss=0.23929429054260254
Test set avg_accuracy=82.74% avg_sensitivity=49.81%, avg_specificity=93.30% avg_auc=0.8619
Fold[4] Epoch: 63 [63/100 (63%)] Train loss=0.286650 Test loss=0.442042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2917933166027069
[5/23] Train loss=0.2872461676597595
[10/23] Train loss=0.2619200646877289
[15/23] Train loss=0.24735496938228607
[20/23] Train loss=0.23592811822891235
Test set avg_accuracy=82.80% avg_sensitivity=50.32%, avg_specificity=93.21% avg_auc=0.8592
Fold[4] Epoch: 64 [64/100 (64%)] Train loss=0.286378 Test loss=0.441843 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.289777010679245
[5/23] Train loss=0.2776557505130768
[10/23] Train loss=0.2489200383424759
[15/23] Train loss=0.24175448715686798
[20/23] Train loss=0.23725347220897675
Test set avg_accuracy=82.72% avg_sensitivity=50.84%, avg_specificity=92.94% avg_auc=0.8603
Fold[4] Epoch: 65 [65/100 (65%)] Train loss=0.282763 Test loss=0.441798 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2832272946834564
[5/23] Train loss=0.27847009897232056
[10/23] Train loss=0.25450894236564636
[15/23] Train loss=0.23454256355762482
[20/23] Train loss=0.22615501284599304
Test set avg_accuracy=82.87% avg_sensitivity=52.95%, avg_specificity=92.45% avg_auc=0.8616
Fold[4] Epoch: 66 [66/100 (66%)] Train loss=0.281576 Test loss=0.448709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2714892327785492
[5/23] Train loss=0.2727414071559906
[10/23] Train loss=0.258615642786026
[15/23] Train loss=0.24405601620674133
[20/23] Train loss=0.23468828201293945
Test set avg_accuracy=82.78% avg_sensitivity=49.37%, avg_specificity=93.49% avg_auc=0.8602
Fold[4] Epoch: 67 [67/100 (67%)] Train loss=0.285365 Test loss=0.443993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2861510217189789
[5/23] Train loss=0.27496281266212463
[10/23] Train loss=0.254059761762619
[15/23] Train loss=0.24189399182796478
[20/23] Train loss=0.23689796030521393
Test set avg_accuracy=82.72% avg_sensitivity=54.72%, avg_specificity=91.69% avg_auc=0.8623
Fold[4] Epoch: 68 [68/100 (68%)] Train loss=0.278644 Test loss=0.441151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29535868763923645
[5/23] Train loss=0.27905404567718506
[10/23] Train loss=0.24842125177383423
[15/23] Train loss=0.2269226759672165
[20/23] Train loss=0.2253739982843399
Test set avg_accuracy=82.87% avg_sensitivity=52.44%, avg_specificity=92.62% avg_auc=0.8612
Fold[4] Epoch: 69 [69/100 (69%)] Train loss=0.275781 Test loss=0.457602 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27541905641555786
[5/23] Train loss=0.25889408588409424
[10/23] Train loss=0.24329859018325806
[15/23] Train loss=0.23693303763866425
[20/23] Train loss=0.2322855293750763
Test set avg_accuracy=82.48% avg_sensitivity=55.20%, avg_specificity=91.22% avg_auc=0.8630
Fold[4] Epoch: 70 [70/100 (70%)] Train loss=0.272225 Test loss=0.455210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.288527250289917
[5/23] Train loss=0.2629620432853699
[10/23] Train loss=0.24422460794448853
[15/23] Train loss=0.23694629967212677
[20/23] Train loss=0.23354309797286987
Test set avg_accuracy=83.05% avg_sensitivity=55.45%, avg_specificity=91.89% avg_auc=0.8621
Fold[4] Epoch: 71 [71/100 (71%)] Train loss=0.271198 Test loss=0.454001 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.264445036649704
[5/23] Train loss=0.25865045189857483
[10/23] Train loss=0.23160779476165771
[15/23] Train loss=0.22890514135360718
[20/23] Train loss=0.23723474144935608
Test set avg_accuracy=82.25% avg_sensitivity=51.40%, avg_specificity=92.14% avg_auc=0.8600
Fold[4] Epoch: 72 [72/100 (72%)] Train loss=0.266442 Test loss=0.459922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2814810574054718
[5/23] Train loss=0.25924059748649597
[10/23] Train loss=0.2417645901441574
[15/23] Train loss=0.22515030205249786
[20/23] Train loss=0.21645565330982208
Test set avg_accuracy=82.49% avg_sensitivity=55.28%, avg_specificity=91.21% avg_auc=0.8604
Fold[4] Epoch: 73 [73/100 (73%)] Train loss=0.265373 Test loss=0.461085 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2764982283115387
[5/23] Train loss=0.25875404477119446
[10/23] Train loss=0.2386399805545807
[15/23] Train loss=0.22711290419101715
[20/23] Train loss=0.21845068037509918
Test set avg_accuracy=82.65% avg_sensitivity=56.19%, avg_specificity=91.13% avg_auc=0.8609
Fold[4] Epoch: 74 [74/100 (74%)] Train loss=0.261571 Test loss=0.460603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26460370421409607
[5/23] Train loss=0.24714164435863495
[10/23] Train loss=0.2403010129928589
[15/23] Train loss=0.21715831756591797
[20/23] Train loss=0.2219906896352768
Test set avg_accuracy=82.62% avg_sensitivity=58.69%, avg_specificity=90.28% avg_auc=0.8604
Fold[4] Epoch: 75 [75/100 (75%)] Train loss=0.258540 Test loss=0.463744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26489871740341187
[5/23] Train loss=0.24477991461753845
[10/23] Train loss=0.23989123106002808
[15/23] Train loss=0.2212989181280136
[20/23] Train loss=0.21503569185733795
Test set avg_accuracy=82.60% avg_sensitivity=59.77%, avg_specificity=89.91% avg_auc=0.8597
Fold[4] Epoch: 76 [76/100 (76%)] Train loss=0.256631 Test loss=0.462429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2713310718536377
[5/23] Train loss=0.24709512293338776
[10/23] Train loss=0.22872576117515564
[15/23] Train loss=0.21545401215553284
[20/23] Train loss=0.21405324339866638
Test set avg_accuracy=82.45% avg_sensitivity=57.57%, avg_specificity=90.42% avg_auc=0.8602
Fold[4] Epoch: 77 [77/100 (77%)] Train loss=0.255613 Test loss=0.463393 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25962257385253906
[5/23] Train loss=0.24694974720478058
[10/23] Train loss=0.23403356969356537
[15/23] Train loss=0.21804703772068024
[20/23] Train loss=0.22203180193901062
Test set avg_accuracy=82.48% avg_sensitivity=58.78%, avg_specificity=90.08% avg_auc=0.8592
Fold[4] Epoch: 78 [78/100 (78%)] Train loss=0.253195 Test loss=0.462527 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2731715142726898
[5/23] Train loss=0.2428004890680313
[10/23] Train loss=0.2200556993484497
[15/23] Train loss=0.22240214049816132
[20/23] Train loss=0.21789944171905518
Test set avg_accuracy=82.66% avg_sensitivity=59.21%, avg_specificity=90.17% avg_auc=0.8564
Fold[4] Epoch: 79 [79/100 (79%)] Train loss=0.251994 Test loss=0.470062 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26979801058769226
[5/23] Train loss=0.23714753985404968
[10/23] Train loss=0.22694644331932068
[15/23] Train loss=0.21432790160179138
[20/23] Train loss=0.20838728547096252
Test set avg_accuracy=82.46% avg_sensitivity=57.70%, avg_specificity=90.40% avg_auc=0.8584
Fold[4] Epoch: 80 [80/100 (80%)] Train loss=0.251008 Test loss=0.475755 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2531633973121643
[5/23] Train loss=0.2369031012058258
[10/23] Train loss=0.23385778069496155
[15/23] Train loss=0.2113039791584015
[20/23] Train loss=0.20613284409046173
Test set avg_accuracy=82.24% avg_sensitivity=54.76%, avg_specificity=91.04% avg_auc=0.8573
Fold[4] Epoch: 81 [81/100 (81%)] Train loss=0.249901 Test loss=0.473893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2529851496219635
[5/23] Train loss=0.23889517784118652
[10/23] Train loss=0.2386869639158249
[15/23] Train loss=0.21479707956314087
[20/23] Train loss=0.2041161060333252
Test set avg_accuracy=82.17% avg_sensitivity=54.51%, avg_specificity=91.03% avg_auc=0.8528
Fold[4] Epoch: 82 [82/100 (82%)] Train loss=0.248366 Test loss=0.467570 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25943857431411743
[5/23] Train loss=0.23576126992702484
[10/23] Train loss=0.22701495885849
[15/23] Train loss=0.2129952311515808
[20/23] Train loss=0.19973531365394592
Test set avg_accuracy=82.23% avg_sensitivity=53.86%, avg_specificity=91.32% avg_auc=0.8573
Fold[4] Epoch: 83 [83/100 (83%)] Train loss=0.245448 Test loss=0.463694 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24766309559345245
[5/23] Train loss=0.22943471372127533
[10/23] Train loss=0.22235088050365448
[15/23] Train loss=0.20807793736457825
[20/23] Train loss=0.2039221078157425
Test set avg_accuracy=82.63% avg_sensitivity=53.08%, avg_specificity=92.10% avg_auc=0.8567
Fold[4] Epoch: 84 [84/100 (84%)] Train loss=0.242929 Test loss=0.472359 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23965318500995636
[5/23] Train loss=0.2189488410949707
[10/23] Train loss=0.2306213229894638
[15/23] Train loss=0.20435215532779694
[20/23] Train loss=0.19770266115665436
Test set avg_accuracy=82.48% avg_sensitivity=48.77%, avg_specificity=93.28% avg_auc=0.8574
Fold[4] Epoch: 85 [85/100 (85%)] Train loss=0.240196 Test loss=0.484037 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24190425872802734
[5/23] Train loss=0.23248142004013062
[10/23] Train loss=0.22492629289627075
[15/23] Train loss=0.20741935074329376
[20/23] Train loss=0.20603808760643005
Test set avg_accuracy=81.82% avg_sensitivity=46.66%, avg_specificity=93.09% avg_auc=0.8568
Fold[4] Epoch: 86 [86/100 (86%)] Train loss=0.241385 Test loss=0.484833 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23255065083503723
[5/23] Train loss=0.23456759750843048
[10/23] Train loss=0.2274957001209259
[15/23] Train loss=0.19167038798332214
[20/23] Train loss=0.20246802270412445
Test set avg_accuracy=81.59% avg_sensitivity=46.05%, avg_specificity=92.98% avg_auc=0.8536
Fold[4] Epoch: 87 [87/100 (87%)] Train loss=0.236816 Test loss=0.480728 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24273370206356049
[5/23] Train loss=0.21973229944705963
[10/23] Train loss=0.21593868732452393
[15/23] Train loss=0.20056499540805817
[20/23] Train loss=0.19756557047367096
Test set avg_accuracy=82.12% avg_sensitivity=49.98%, avg_specificity=92.43% avg_auc=0.8554
Fold[4] Epoch: 88 [88/100 (88%)] Train loss=0.234219 Test loss=0.476223 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2384633868932724
[5/23] Train loss=0.23181526362895966
[10/23] Train loss=0.21065983176231384
[15/23] Train loss=0.1938977986574173
[20/23] Train loss=0.19254131615161896
Test set avg_accuracy=82.46% avg_sensitivity=51.83%, avg_specificity=92.27% avg_auc=0.8536
Fold[4] Epoch: 89 [89/100 (89%)] Train loss=0.232914 Test loss=0.489489 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23900502920150757
[5/23] Train loss=0.2257889062166214
[10/23] Train loss=0.22536201775074005
[15/23] Train loss=0.19689351320266724
[20/23] Train loss=0.18366967141628265
Test set avg_accuracy=82.21% avg_sensitivity=49.46%, avg_specificity=92.70% avg_auc=0.8566
Fold[4] Epoch: 90 [90/100 (90%)] Train loss=0.229767 Test loss=0.499101 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2273353636264801
[5/23] Train loss=0.21551628410816193
[10/23] Train loss=0.20372113585472107
[15/23] Train loss=0.1903066337108612
[20/23] Train loss=0.19976641237735748
Test set avg_accuracy=82.08% avg_sensitivity=47.99%, avg_specificity=93.01% avg_auc=0.8567
Fold[4] Epoch: 91 [91/100 (91%)] Train loss=0.229090 Test loss=0.497375 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24339967966079712
[5/23] Train loss=0.20996689796447754
[10/23] Train loss=0.20119301974773407
[15/23] Train loss=0.19141842424869537
[20/23] Train loss=0.19119936227798462
Test set avg_accuracy=82.03% avg_sensitivity=46.70%, avg_specificity=93.35% avg_auc=0.8558
Fold[4] Epoch: 92 [92/100 (92%)] Train loss=0.226919 Test loss=0.499787 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22927391529083252
[5/23] Train loss=0.21337303519248962
[10/23] Train loss=0.20541273057460785
[15/23] Train loss=0.1897733062505722
[20/23] Train loss=0.18662025034427643
Test set avg_accuracy=82.07% avg_sensitivity=47.61%, avg_specificity=93.12% avg_auc=0.8552
Fold[4] Epoch: 93 [93/100 (93%)] Train loss=0.223773 Test loss=0.502421 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23208965361118317
[5/23] Train loss=0.20975707471370697
[10/23] Train loss=0.20766933262348175
[15/23] Train loss=0.19189824163913727
[20/23] Train loss=0.18762046098709106
Test set avg_accuracy=81.78% avg_sensitivity=48.86%, avg_specificity=92.33% avg_auc=0.8565
Fold[4] Epoch: 94 [94/100 (94%)] Train loss=0.220650 Test loss=0.495518 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2278520166873932
[5/23] Train loss=0.2253122478723526
[10/23] Train loss=0.2105826735496521
[15/23] Train loss=0.18810845911502838
[20/23] Train loss=0.19749221205711365
Test set avg_accuracy=82.22% avg_sensitivity=52.35%, avg_specificity=91.79% avg_auc=0.8560
Fold[4] Epoch: 95 [95/100 (95%)] Train loss=0.221279 Test loss=0.501340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22919277846813202
[5/23] Train loss=0.21607662737369537
[10/23] Train loss=0.19784483313560486
[15/23] Train loss=0.17963607609272003
[20/23] Train loss=0.18655571341514587
Test set avg_accuracy=81.94% avg_sensitivity=52.39%, avg_specificity=91.40% avg_auc=0.8559
Fold[4] Epoch: 96 [96/100 (96%)] Train loss=0.219779 Test loss=0.510326 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2288481891155243
[5/23] Train loss=0.21661445498466492
[10/23] Train loss=0.20309539139270782
[15/23] Train loss=0.18509377539157867
[20/23] Train loss=0.17823021113872528
Test set avg_accuracy=82.71% avg_sensitivity=58.60%, avg_specificity=90.44% avg_auc=0.8557
Fold[4] Epoch: 97 [97/100 (97%)] Train loss=0.214739 Test loss=0.514883 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22893093526363373
[5/23] Train loss=0.21143509447574615
[10/23] Train loss=0.23001930117607117
[15/23] Train loss=0.24272163212299347
[20/23] Train loss=0.20888228714466095
Test set avg_accuracy=82.40% avg_sensitivity=56.92%, avg_specificity=90.56% avg_auc=0.8495
Fold[4] Epoch: 98 [98/100 (98%)] Train loss=0.246322 Test loss=0.509709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23545975983142853
[5/23] Train loss=0.24785089492797852
[10/23] Train loss=0.23162014782428741
[15/23] Train loss=0.22586815059185028
[20/23] Train loss=0.2102249711751938
Test set avg_accuracy=81.87% avg_sensitivity=56.14%, avg_specificity=90.12% avg_auc=0.8456
Fold[4] Epoch: 99 [99/100 (99%)] Train loss=0.248059 Test loss=0.499978 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2342463880777359
[5/23] Train loss=0.2287272959947586
[10/23] Train loss=0.21151627600193024
[15/23] Train loss=0.19959864020347595
[20/23] Train loss=0.19502048194408417
Test set avg_accuracy=81.89% avg_sensitivity=52.48%, avg_specificity=91.32% avg_auc=0.8453
Fold[4] Epoch: 100 [100/100 (100%)] Train loss=0.234585 Test loss=0.500117 Current lr=[3.9999999999999996e-05]

Fold[4] Best Result: acc=83.78859236002093 sen=57.65416127641224, spe=92.16417910447761, auc=0.8633603579057423!
[0/23] Train loss=0.6996555328369141
[5/23] Train loss=0.6766389608383179
[10/23] Train loss=0.5698033571243286
[15/23] Train loss=0.5544359683990479
[20/23] Train loss=0.5230193138122559
Test set avg_accuracy=74.71% avg_sensitivity=0.17%, avg_specificity=99.94% avg_auc=0.5521
Best model saved!! Metric=-95.96768544051463!!
Fold[5] Epoch: 1 [1/100 (1%)] Train loss=0.582003 Test loss=0.638238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5694563388824463
[5/23] Train loss=0.5915112495422363
[10/23] Train loss=0.5288833379745483
[15/23] Train loss=0.5272666215896606
[20/23] Train loss=0.4944274127483368
Test set avg_accuracy=74.75% avg_sensitivity=1.61%, avg_specificity=99.50% avg_auc=0.6391
Best model saved!! Metric=-86.23332515624712!!
Fold[5] Epoch: 2 [2/100 (2%)] Train loss=0.541984 Test loss=0.600685 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5459426641464233
[5/23] Train loss=0.5467007160186768
[10/23] Train loss=0.4887998700141907
[15/23] Train loss=0.5005288124084473
[20/23] Train loss=0.4527808129787445
Test set avg_accuracy=75.10% avg_sensitivity=9.40%, avg_specificity=97.34% avg_auc=0.7082
Best model saved!! Metric=-73.34045975649934!!
Fold[5] Epoch: 3 [3/100 (3%)] Train loss=0.512168 Test loss=0.572025 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.517657458782196
[5/23] Train loss=0.4904424250125885
[10/23] Train loss=0.4418037533760071
[15/23] Train loss=0.47238489985466003
[20/23] Train loss=0.4110623896121979
Test set avg_accuracy=77.01% avg_sensitivity=22.89%, avg_specificity=95.32% avg_auc=0.7489
Best model saved!! Metric=-55.89044994104448!!
Fold[5] Epoch: 4 [4/100 (4%)] Train loss=0.478807 Test loss=0.557876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48199528455734253
[5/23] Train loss=0.4552737772464752
[10/23] Train loss=0.42570748925209045
[15/23] Train loss=0.47077038884162903
[20/23] Train loss=0.39729851484298706
Test set avg_accuracy=77.61% avg_sensitivity=30.13%, avg_specificity=93.68% avg_auc=0.7768
Best model saved!! Metric=-46.89363174788427!!
Fold[5] Epoch: 5 [5/100 (5%)] Train loss=0.456798 Test loss=0.521387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4577804207801819
[5/23] Train loss=0.44608381390571594
[10/23] Train loss=0.4127104878425598
[15/23] Train loss=0.46459469199180603
[20/23] Train loss=0.39251041412353516
Test set avg_accuracy=78.49% avg_sensitivity=35.89%, avg_specificity=92.91% avg_auc=0.7917
Best model saved!! Metric=-39.537003909044884!!
Fold[5] Epoch: 6 [6/100 (6%)] Train loss=0.444409 Test loss=0.499801 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44238340854644775
[5/23] Train loss=0.43934816122055054
[10/23] Train loss=0.3970423936843872
[15/23] Train loss=0.45195022225379944
[20/23] Train loss=0.3809584975242615
Test set avg_accuracy=79.38% avg_sensitivity=40.48%, avg_specificity=92.55% avg_auc=0.8019
Best model saved!! Metric=-33.39951183025585!!
Fold[5] Epoch: 7 [7/100 (7%)] Train loss=0.434697 Test loss=0.483118 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4362300634384155
[5/23] Train loss=0.4340263307094574
[10/23] Train loss=0.39070042967796326
[15/23] Train loss=0.43956199288368225
[20/23] Train loss=0.3790873885154724
Test set avg_accuracy=79.59% avg_sensitivity=42.01%, avg_specificity=92.31% avg_auc=0.8068
Best model saved!! Metric=-31.40714342651372!!
Fold[5] Epoch: 8 [8/100 (8%)] Train loss=0.428020 Test loss=0.482790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42718279361724854
[5/23] Train loss=0.42668870091438293
[10/23] Train loss=0.39114871621131897
[15/23] Train loss=0.4398958683013916
[20/23] Train loss=0.3741725981235504
Test set avg_accuracy=79.73% avg_sensitivity=43.13%, avg_specificity=92.11% avg_auc=0.8120
Best model saved!! Metric=-29.832249531429397!!
Fold[5] Epoch: 9 [9/100 (9%)] Train loss=0.422833 Test loss=0.476572 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4289836585521698
[5/23] Train loss=0.4249996840953827
[10/23] Train loss=0.38652604818344116
[15/23] Train loss=0.42429429292678833
[20/23] Train loss=0.3694593012332916
Test set avg_accuracy=79.53% avg_sensitivity=42.14%, avg_specificity=92.18% avg_auc=0.8135
Fold[5] Epoch: 10 [10/100 (10%)] Train loss=0.418433 Test loss=0.479100 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4193381071090698
[5/23] Train loss=0.42067062854766846
[10/23] Train loss=0.3812602758407593
[15/23] Train loss=0.42446085810661316
[20/23] Train loss=0.363808810710907
Test set avg_accuracy=79.57% avg_sensitivity=41.56%, avg_specificity=92.44% avg_auc=0.8167
Fold[5] Epoch: 11 [11/100 (11%)] Train loss=0.416429 Test loss=0.478360 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.413425475358963
[5/23] Train loss=0.41231635212898254
[10/23] Train loss=0.38539761304855347
[15/23] Train loss=0.40217041969299316
[20/23] Train loss=0.36566802859306335
Test set avg_accuracy=79.90% avg_sensitivity=42.09%, avg_specificity=92.69% avg_auc=0.8173
Best model saved!! Metric=-29.595386280927514!!
Fold[5] Epoch: 12 [12/100 (12%)] Train loss=0.413018 Test loss=0.482029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.405080109834671
[5/23] Train loss=0.405524343252182
[10/23] Train loss=0.3904423415660858
[15/23] Train loss=0.38382312655448914
[20/23] Train loss=0.35510170459747314
Test set avg_accuracy=79.98% avg_sensitivity=43.25%, avg_specificity=92.41% avg_auc=0.8198
Best model saved!! Metric=-28.376937633239464!!
Fold[5] Epoch: 13 [13/100 (13%)] Train loss=0.407270 Test loss=0.479851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3983308970928192
[5/23] Train loss=0.40840035676956177
[10/23] Train loss=0.3939109742641449
[15/23] Train loss=0.38367927074432373
[20/23] Train loss=0.35280781984329224
Test set avg_accuracy=80.29% avg_sensitivity=44.25%, avg_specificity=92.49% avg_auc=0.8240
Best model saved!! Metric=-26.563379624046053!!
Fold[5] Epoch: 14 [14/100 (14%)] Train loss=0.405312 Test loss=0.473966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.396465927362442
[5/23] Train loss=0.40169432759284973
[10/23] Train loss=0.37819966673851013
[15/23] Train loss=0.3789295256137848
[20/23] Train loss=0.35014915466308594
Test set avg_accuracy=80.49% avg_sensitivity=45.78%, avg_specificity=92.24% avg_auc=0.8254
Best model saved!! Metric=-24.95222516233774!!
Fold[5] Epoch: 15 [15/100 (15%)] Train loss=0.400787 Test loss=0.467740 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3967713415622711
[5/23] Train loss=0.3969006836414337
[10/23] Train loss=0.3644125461578369
[15/23] Train loss=0.3774069845676422
[20/23] Train loss=0.3444417417049408
Test set avg_accuracy=81.00% avg_sensitivity=47.68%, avg_specificity=92.28% avg_auc=0.8291
Best model saved!! Metric=-22.123408150480593!!
Fold[5] Epoch: 16 [16/100 (16%)] Train loss=0.396198 Test loss=0.458416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3942442834377289
[5/23] Train loss=0.39410513639450073
[10/23] Train loss=0.3666912913322449
[15/23] Train loss=0.3768555521965027
[20/23] Train loss=0.3417956829071045
Test set avg_accuracy=81.26% avg_sensitivity=48.68%, avg_specificity=92.28% avg_auc=0.8291
Best model saved!! Metric=-20.87265538972154!!
Fold[5] Epoch: 17 [17/100 (17%)] Train loss=0.392826 Test loss=0.455125 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3949616253376007
[5/23] Train loss=0.3922903835773468
[10/23] Train loss=0.354087769985199
[15/23] Train loss=0.364870548248291
[20/23] Train loss=0.3371497392654419
Test set avg_accuracy=81.25% avg_sensitivity=49.59%, avg_specificity=91.96% avg_auc=0.8317
Best model saved!! Metric=-20.03634763162667!!
Fold[5] Epoch: 18 [18/100 (18%)] Train loss=0.389703 Test loss=0.450179 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3949699103832245
[5/23] Train loss=0.3886544108390808
[10/23] Train loss=0.35375621914863586
[15/23] Train loss=0.3588668704032898
[20/23] Train loss=0.3415262699127197
Test set avg_accuracy=81.20% avg_sensitivity=49.42%, avg_specificity=91.96% avg_auc=0.8336
Fold[5] Epoch: 19 [19/100 (19%)] Train loss=0.388833 Test loss=0.444684 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3929435908794403
[5/23] Train loss=0.38699063658714294
[10/23] Train loss=0.35413432121276855
[15/23] Train loss=0.3580697476863861
[20/23] Train loss=0.32879576086997986
Test set avg_accuracy=81.60% avg_sensitivity=51.49%, avg_specificity=91.79% avg_auc=0.8348
Best model saved!! Metric=-17.634509969638756!!
Fold[5] Epoch: 20 [20/100 (20%)] Train loss=0.385133 Test loss=0.440753 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38219210505485535
[5/23] Train loss=0.385221928358078
[10/23] Train loss=0.34693169593811035
[15/23] Train loss=0.3616948127746582
[20/23] Train loss=0.3293323814868927
Test set avg_accuracy=81.57% avg_sensitivity=51.66%, avg_specificity=91.69% avg_auc=0.8328
Fold[5] Epoch: 21 [21/100 (21%)] Train loss=0.381934 Test loss=0.442737 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3825361430644989
[5/23] Train loss=0.37830376625061035
[10/23] Train loss=0.3447030484676361
[15/23] Train loss=0.3503243923187256
[20/23] Train loss=0.3297575116157532
Test set avg_accuracy=81.70% avg_sensitivity=55.05%, avg_specificity=90.71% avg_auc=0.8335
Best model saved!! Metric=-15.194028271373098!!
Fold[5] Epoch: 22 [22/100 (22%)] Train loss=0.381251 Test loss=0.437806 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3877156674861908
[5/23] Train loss=0.3773331046104431
[10/23] Train loss=0.3436571955680847
[15/23] Train loss=0.36154672503471375
[20/23] Train loss=0.3186700940132141
Test set avg_accuracy=82.07% avg_sensitivity=54.10%, avg_specificity=91.54% avg_auc=0.8319
Best model saved!! Metric=-15.098526645914177!!
Fold[5] Epoch: 23 [23/100 (23%)] Train loss=0.379433 Test loss=0.436680 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38715988397598267
[5/23] Train loss=0.3707214891910553
[10/23] Train loss=0.33772414922714233
[15/23] Train loss=0.35770586133003235
[20/23] Train loss=0.3185150623321533
Test set avg_accuracy=82.11% avg_sensitivity=55.55%, avg_specificity=91.11% avg_auc=0.8349
Best model saved!! Metric=-13.743709718620554!!
Fold[5] Epoch: 24 [24/100 (24%)] Train loss=0.377132 Test loss=0.435823 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3862716257572174
[5/23] Train loss=0.3726101219654083
[10/23] Train loss=0.32653671503067017
[15/23] Train loss=0.34643036127090454
[20/23] Train loss=0.32336488366127014
Test set avg_accuracy=81.84% avg_sensitivity=56.37%, avg_specificity=90.46% avg_auc=0.8391
Best model saved!! Metric=-13.411872812247706!!
Fold[5] Epoch: 25 [25/100 (25%)] Train loss=0.375362 Test loss=0.426376 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3809869587421417
[5/23] Train loss=0.3690393269062042
[10/23] Train loss=0.32882675528526306
[15/23] Train loss=0.3449733257293701
[20/23] Train loss=0.3219539523124695
Test set avg_accuracy=81.68% avg_sensitivity=56.50%, avg_specificity=90.21% avg_auc=0.8411
Fold[5] Epoch: 26 [26/100 (26%)] Train loss=0.372280 Test loss=0.423040 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38253283500671387
[5/23] Train loss=0.3592316210269928
[10/23] Train loss=0.32229912281036377
[15/23] Train loss=0.3476627767086029
[20/23] Train loss=0.31430694460868835
Test set avg_accuracy=81.45% avg_sensitivity=57.53%, avg_specificity=89.55% avg_auc=0.8414
Best model saved!! Metric=-13.31755112889653!!
Fold[5] Epoch: 27 [27/100 (27%)] Train loss=0.369064 Test loss=0.422889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3761625587940216
[5/23] Train loss=0.36228054761886597
[10/23] Train loss=0.32105350494384766
[15/23] Train loss=0.3444865643978119
[20/23] Train loss=0.3104661703109741
Test set avg_accuracy=81.40% avg_sensitivity=58.28%, avg_specificity=89.23% avg_auc=0.8407
Best model saved!! Metric=-13.025795768494314!!
Fold[5] Epoch: 28 [28/100 (28%)] Train loss=0.363735 Test loss=0.429610 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3710736930370331
[5/23] Train loss=0.35766756534576416
[10/23] Train loss=0.3235330283641815
[15/23] Train loss=0.3430432081222534
[20/23] Train loss=0.3101029098033905
Test set avg_accuracy=81.80% avg_sensitivity=58.94%, avg_specificity=89.54% avg_auc=0.8415
Best model saved!! Metric=-11.57493349249242!!
Fold[5] Epoch: 29 [29/100 (29%)] Train loss=0.361996 Test loss=0.423984 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3665039837360382
[5/23] Train loss=0.3565441966056824
[10/23] Train loss=0.32061657309532166
[15/23] Train loss=0.33624863624572754
[20/23] Train loss=0.3070586919784546
Test set avg_accuracy=81.80% avg_sensitivity=60.89%, avg_specificity=88.88% avg_auc=0.8427
Best model saved!! Metric=-10.165805013444842!!
Fold[5] Epoch: 30 [30/100 (30%)] Train loss=0.360639 Test loss=0.424148 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36323222517967224
[5/23] Train loss=0.356966495513916
[10/23] Train loss=0.3248107433319092
[15/23] Train loss=0.3327604830265045
[20/23] Train loss=0.30734625458717346
Test set avg_accuracy=81.85% avg_sensitivity=58.94%, avg_specificity=89.61% avg_auc=0.8433
Fold[5] Epoch: 31 [31/100 (31%)] Train loss=0.359264 Test loss=0.422323 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3553251624107361
[5/23] Train loss=0.35129058361053467
[10/23] Train loss=0.32147684693336487
[15/23] Train loss=0.34250593185424805
[20/23] Train loss=0.30801188945770264
Test set avg_accuracy=81.83% avg_sensitivity=59.19%, avg_specificity=89.49% avg_auc=0.8428
Fold[5] Epoch: 32 [32/100 (32%)] Train loss=0.356395 Test loss=0.425470 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37428808212280273
[5/23] Train loss=0.3478601276874542
[10/23] Train loss=0.32056236267089844
[15/23] Train loss=0.3229389786720276
[20/23] Train loss=0.30113598704338074
Test set avg_accuracy=81.73% avg_sensitivity=58.61%, avg_specificity=89.55% avg_auc=0.8412
Fold[5] Epoch: 33 [33/100 (33%)] Train loss=0.354424 Test loss=0.431714 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.356365442276001
[5/23] Train loss=0.3441546559333801
[10/23] Train loss=0.3211726248264313
[15/23] Train loss=0.32192543148994446
[20/23] Train loss=0.3035541772842407
Test set avg_accuracy=81.77% avg_sensitivity=59.31%, avg_specificity=89.37% avg_auc=0.8431
Fold[5] Epoch: 34 [34/100 (34%)] Train loss=0.351099 Test loss=0.431321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36175423860549927
[5/23] Train loss=0.34687450528144836
[10/23] Train loss=0.32070159912109375
[15/23] Train loss=0.32777002453804016
[20/23] Train loss=0.2949048578739166
Test set avg_accuracy=81.81% avg_sensitivity=60.68%, avg_specificity=88.96% avg_auc=0.8437
Fold[5] Epoch: 35 [35/100 (35%)] Train loss=0.350344 Test loss=0.427635 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36567065119743347
[5/23] Train loss=0.3385579586029053
[10/23] Train loss=0.3146454095840454
[15/23] Train loss=0.31758904457092285
[20/23] Train loss=0.2961263656616211
Test set avg_accuracy=82.11% avg_sensitivity=60.89%, avg_specificity=89.30% avg_auc=0.8440
Best model saved!! Metric=-9.297467688321548!!
Fold[5] Epoch: 36 [36/100 (36%)] Train loss=0.347855 Test loss=0.429240 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34787046909332275
[5/23] Train loss=0.34787821769714355
[10/23] Train loss=0.313337117433548
[15/23] Train loss=0.3215205669403076
[20/23] Train loss=0.2959153354167938
Test set avg_accuracy=82.06% avg_sensitivity=58.86%, avg_specificity=89.91% avg_auc=0.8430
Fold[5] Epoch: 37 [37/100 (37%)] Train loss=0.345714 Test loss=0.431471 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34358251094818115
[5/23] Train loss=0.3336341381072998
[10/23] Train loss=0.3153745234012604
[15/23] Train loss=0.3202013075351715
[20/23] Train loss=0.2958809435367584
Test set avg_accuracy=81.64% avg_sensitivity=55.67%, avg_specificity=90.43% avg_auc=0.8404
Fold[5] Epoch: 38 [38/100 (38%)] Train loss=0.347033 Test loss=0.437047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.345657616853714
[5/23] Train loss=0.34054768085479736
[10/23] Train loss=0.3153077960014343
[15/23] Train loss=0.31262755393981934
[20/23] Train loss=0.2899152338504791
Test set avg_accuracy=81.43% avg_sensitivity=59.48%, avg_specificity=88.86% avg_auc=0.8418
Fold[5] Epoch: 39 [39/100 (39%)] Train loss=0.344628 Test loss=0.438907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3518568277359009
[5/23] Train loss=0.33377617597579956
[10/23] Train loss=0.31135907769203186
[15/23] Train loss=0.3160838782787323
[20/23] Train loss=0.28665366768836975
Test set avg_accuracy=81.20% avg_sensitivity=61.09%, avg_specificity=88.01% avg_auc=0.8417
Fold[5] Epoch: 40 [40/100 (40%)] Train loss=0.340211 Test loss=0.434572 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33975785970687866
[5/23] Train loss=0.3308020234107971
[10/23] Train loss=0.3044877052307129
[15/23] Train loss=0.30652323365211487
[20/23] Train loss=0.2827427089214325
Test set avg_accuracy=81.28% avg_sensitivity=61.47%, avg_specificity=87.98% avg_auc=0.8428
Fold[5] Epoch: 41 [41/100 (41%)] Train loss=0.338306 Test loss=0.438356 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33962297439575195
[5/23] Train loss=0.3255288600921631
[10/23] Train loss=0.29819783568382263
[15/23] Train loss=0.3063306212425232
[20/23] Train loss=0.28596311807632446
Test set avg_accuracy=81.20% avg_sensitivity=64.16%, avg_specificity=86.97% avg_auc=0.8421
Fold[5] Epoch: 42 [42/100 (42%)] Train loss=0.334347 Test loss=0.439780 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3348907232284546
[5/23] Train loss=0.3214024305343628
[10/23] Train loss=0.29750892519950867
[15/23] Train loss=0.3004172146320343
[20/23] Train loss=0.293087899684906
Test set avg_accuracy=81.07% avg_sensitivity=65.15%, avg_specificity=86.45% avg_auc=0.8418
Best model saved!! Metric=-9.14480482803994!!
Fold[5] Epoch: 43 [43/100 (43%)] Train loss=0.332479 Test loss=0.441516 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32886940240859985
[5/23] Train loss=0.3256818950176239
[10/23] Train loss=0.29497408866882324
[15/23] Train loss=0.29473644495010376
[20/23] Train loss=0.28918448090553284
Test set avg_accuracy=81.14% avg_sensitivity=65.81%, avg_specificity=86.33% avg_auc=0.8418
Best model saved!! Metric=-8.541025658573881!!
Fold[5] Epoch: 44 [44/100 (44%)] Train loss=0.329789 Test loss=0.444884 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.343233585357666
[5/23] Train loss=0.3179299831390381
[10/23] Train loss=0.29253268241882324
[15/23] Train loss=0.3091447353363037
[20/23] Train loss=0.28113529086112976
Test set avg_accuracy=81.20% avg_sensitivity=67.96%, avg_specificity=85.68% avg_auc=0.8417
Best model saved!! Metric=-6.975206928554851!!
Fold[5] Epoch: 45 [45/100 (45%)] Train loss=0.330141 Test loss=0.454855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33074983954429626
[5/23] Train loss=0.3221489489078522
[10/23] Train loss=0.3023485839366913
[15/23] Train loss=0.2948424220085144
[20/23] Train loss=0.28048813343048096
Test set avg_accuracy=81.89% avg_sensitivity=61.26%, avg_specificity=88.88% avg_auc=0.8428
Fold[5] Epoch: 46 [46/100 (46%)] Train loss=0.329548 Test loss=0.430238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3324263095855713
[5/23] Train loss=0.3212742209434509
[10/23] Train loss=0.2945253849029541
[15/23] Train loss=0.30350521206855774
[20/23] Train loss=0.2753351628780365
Test set avg_accuracy=82.14% avg_sensitivity=63.99%, avg_specificity=88.28% avg_auc=0.8431
Fold[5] Epoch: 47 [47/100 (47%)] Train loss=0.326826 Test loss=0.438018 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.339460164308548
[5/23] Train loss=0.3193926513195038
[10/23] Train loss=0.28504130244255066
[15/23] Train loss=0.2944609522819519
[20/23] Train loss=0.27326881885528564
Test set avg_accuracy=81.84% avg_sensitivity=63.16%, avg_specificity=88.16% avg_auc=0.8439
Fold[5] Epoch: 48 [48/100 (48%)] Train loss=0.325578 Test loss=0.435745 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3293854594230652
[5/23] Train loss=0.3159557580947876
[10/23] Train loss=0.2977208197116852
[15/23] Train loss=0.2923988103866577
[20/23] Train loss=0.27443915605545044
Test set avg_accuracy=81.96% avg_sensitivity=62.21%, avg_specificity=88.64% avg_auc=0.8412
Fold[5] Epoch: 49 [49/100 (49%)] Train loss=0.322041 Test loss=0.442129 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3257567584514618
[5/23] Train loss=0.3063512444496155
[10/23] Train loss=0.2890579402446747
[15/23] Train loss=0.29003220796585083
[20/23] Train loss=0.26660990715026855
Test set avg_accuracy=81.72% avg_sensitivity=64.03%, avg_specificity=87.70% avg_auc=0.8387
Fold[5] Epoch: 50 [50/100 (50%)] Train loss=0.317536 Test loss=0.449593 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31747230887413025
[5/23] Train loss=0.30577027797698975
[10/23] Train loss=0.2962423264980316
[15/23] Train loss=0.28051209449768066
[20/23] Train loss=0.2588159441947937
Test set avg_accuracy=81.77% avg_sensitivity=63.41%, avg_specificity=87.98% avg_auc=0.8416
Fold[5] Epoch: 51 [51/100 (51%)] Train loss=0.312905 Test loss=0.448419 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31512629985809326
[5/23] Train loss=0.3012937307357788
[10/23] Train loss=0.2916716933250427
[15/23] Train loss=0.28840017318725586
[20/23] Train loss=0.26562997698783875
Test set avg_accuracy=82.04% avg_sensitivity=62.96%, avg_specificity=88.50% avg_auc=0.8445
Fold[5] Epoch: 52 [52/100 (52%)] Train loss=0.312509 Test loss=0.439645 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30507296323776245
[5/23] Train loss=0.30506250262260437
[10/23] Train loss=0.2894730865955353
[15/23] Train loss=0.2813725173473358
[20/23] Train loss=0.2668229043483734
Test set avg_accuracy=82.06% avg_sensitivity=65.44%, avg_specificity=87.69% avg_auc=0.8416
Best model saved!! Metric=-6.648864298857831!!
Fold[5] Epoch: 53 [53/100 (53%)] Train loss=0.309982 Test loss=0.445265 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32395049929618835
[5/23] Train loss=0.3055803179740906
[10/23] Train loss=0.27683308720588684
[15/23] Train loss=0.2862488031387329
[20/23] Train loss=0.2695450484752655
Test set avg_accuracy=81.28% avg_sensitivity=68.13%, avg_specificity=85.73% avg_auc=0.8417
Fold[5] Epoch: 54 [54/100 (54%)] Train loss=0.309516 Test loss=0.458597 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3103445768356323
[5/23] Train loss=0.2966112494468689
[10/23] Train loss=0.2812844514846802
[15/23] Train loss=0.2728983759880066
[20/23] Train loss=0.26039376854896545
Test set avg_accuracy=81.82% avg_sensitivity=68.13%, avg_specificity=86.45% avg_auc=0.8430
Best model saved!! Metric=-5.29446750692286!!
Fold[5] Epoch: 55 [55/100 (55%)] Train loss=0.306073 Test loss=0.451921 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30322736501693726
[5/23] Train loss=0.29311448335647583
[10/23] Train loss=0.27839744091033936
[15/23] Train loss=0.2738845646381378
[20/23] Train loss=0.25334423780441284
Test set avg_accuracy=81.57% avg_sensitivity=68.17%, avg_specificity=86.10% avg_auc=0.8422
Fold[5] Epoch: 56 [56/100 (56%)] Train loss=0.302137 Test loss=0.455314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3222562372684479
[5/23] Train loss=0.28369536995887756
[10/23] Train loss=0.2751442790031433
[15/23] Train loss=0.27088016271591187
[20/23] Train loss=0.24963606894016266
Test set avg_accuracy=82.08% avg_sensitivity=65.44%, avg_specificity=87.72% avg_auc=0.8426
Fold[5] Epoch: 57 [57/100 (57%)] Train loss=0.300909 Test loss=0.449565 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30377650260925293
[5/23] Train loss=0.2897243797779083
[10/23] Train loss=0.27906253933906555
[15/23] Train loss=0.2653663158416748
[20/23] Train loss=0.24970674514770508
Test set avg_accuracy=81.14% avg_sensitivity=66.97%, avg_specificity=85.94% avg_auc=0.8426
Fold[5] Epoch: 58 [58/100 (58%)] Train loss=0.298499 Test loss=0.459886 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30910512804985046
[5/23] Train loss=0.28792956471443176
[10/23] Train loss=0.27963927388191223
[15/23] Train loss=0.2751197814941406
[20/23] Train loss=0.2485705465078354
Test set avg_accuracy=82.59% avg_sensitivity=63.95%, avg_specificity=88.89% avg_auc=0.8460
Fold[5] Epoch: 59 [59/100 (59%)] Train loss=0.296830 Test loss=0.438171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29830077290534973
[5/23] Train loss=0.2748258113861084
[10/23] Train loss=0.2800941467285156
[15/23] Train loss=0.26497766375541687
[20/23] Train loss=0.248308926820755
Test set avg_accuracy=81.67% avg_sensitivity=66.18%, avg_specificity=86.92% avg_auc=0.8410
Fold[5] Epoch: 60 [60/100 (60%)] Train loss=0.293153 Test loss=0.461341 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3056584894657135
[5/23] Train loss=0.2821066975593567
[10/23] Train loss=0.2688368856906891
[15/23] Train loss=0.26650354266166687
[20/23] Train loss=0.24769525229930878
Test set avg_accuracy=81.10% avg_sensitivity=67.38%, avg_specificity=85.74% avg_auc=0.8403
Fold[5] Epoch: 61 [61/100 (61%)] Train loss=0.293452 Test loss=0.464403 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29960596561431885
[5/23] Train loss=0.283579558134079
[10/23] Train loss=0.2708146274089813
[15/23] Train loss=0.25442689657211304
[20/23] Train loss=0.24792778491973877
Test set avg_accuracy=80.81% avg_sensitivity=69.00%, avg_specificity=84.80% avg_auc=0.8396
Fold[5] Epoch: 62 [62/100 (62%)] Train loss=0.290512 Test loss=0.473166 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3089454770088196
[5/23] Train loss=0.2785366177558899
[10/23] Train loss=0.2633352279663086
[15/23] Train loss=0.2628888487815857
[20/23] Train loss=0.24454763531684875
Test set avg_accuracy=81.88% avg_sensitivity=66.14%, avg_specificity=87.21% avg_auc=0.8426
Fold[5] Epoch: 63 [63/100 (63%)] Train loss=0.289805 Test loss=0.457958 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3008683919906616
[5/23] Train loss=0.275346964597702
[10/23] Train loss=0.2617959678173065
[15/23] Train loss=0.26267626881599426
[20/23] Train loss=0.23109614849090576
Test set avg_accuracy=81.60% avg_sensitivity=67.43%, avg_specificity=86.40% avg_auc=0.8429
Fold[5] Epoch: 64 [64/100 (64%)] Train loss=0.284296 Test loss=0.459644 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3120705187320709
[5/23] Train loss=0.26642924547195435
[10/23] Train loss=0.25686296820640564
[15/23] Train loss=0.26306191086769104
[20/23] Train loss=0.2325589805841446
Test set avg_accuracy=81.40% avg_sensitivity=68.38%, avg_specificity=85.81% avg_auc=0.8422
Fold[5] Epoch: 65 [65/100 (65%)] Train loss=0.281209 Test loss=0.465755 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2864888310432434
[5/23] Train loss=0.2583073377609253
[10/23] Train loss=0.25633344054222107
[15/23] Train loss=0.25985828042030334
[20/23] Train loss=0.22600945830345154
Test set avg_accuracy=80.59% avg_sensitivity=69.91%, avg_specificity=84.20% avg_auc=0.8394
Fold[5] Epoch: 66 [66/100 (66%)] Train loss=0.280557 Test loss=0.476760 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3020370900630951
[5/23] Train loss=0.2626990079879761
[10/23] Train loss=0.26425671577453613
[15/23] Train loss=0.2544736862182617
[20/23] Train loss=0.23273982107639313
Test set avg_accuracy=81.47% avg_sensitivity=67.22%, avg_specificity=86.29% avg_auc=0.8394
Fold[5] Epoch: 67 [67/100 (67%)] Train loss=0.279357 Test loss=0.466422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28868162631988525
[5/23] Train loss=0.2574805021286011
[10/23] Train loss=0.25662609934806824
[15/23] Train loss=0.2535918354988098
[20/23] Train loss=0.222904771566391
Test set avg_accuracy=81.02% avg_sensitivity=69.12%, avg_specificity=85.04% avg_auc=0.8400
Fold[5] Epoch: 68 [68/100 (68%)] Train loss=0.276591 Test loss=0.476954 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29774877429008484
[5/23] Train loss=0.25932323932647705
[10/23] Train loss=0.2568330764770508
[15/23] Train loss=0.2537023723125458
[20/23] Train loss=0.22852002084255219
Test set avg_accuracy=81.92% avg_sensitivity=64.28%, avg_specificity=87.88% avg_auc=0.8425
Fold[5] Epoch: 69 [69/100 (69%)] Train loss=0.275440 Test loss=0.463929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2740756571292877
[5/23] Train loss=0.25817638635635376
[10/23] Train loss=0.25273242592811584
[15/23] Train loss=0.24728292226791382
[20/23] Train loss=0.22980287671089172
Test set avg_accuracy=81.21% avg_sensitivity=67.92%, avg_specificity=85.71% avg_auc=0.8395
Fold[5] Epoch: 70 [70/100 (70%)] Train loss=0.274430 Test loss=0.475122 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28492218255996704
[5/23] Train loss=0.25399720668792725
[10/23] Train loss=0.2485351711511612
[15/23] Train loss=0.24227651953697205
[20/23] Train loss=0.21768181025981903
Test set avg_accuracy=81.87% avg_sensitivity=64.82%, avg_specificity=87.65% avg_auc=0.8429
Fold[5] Epoch: 71 [71/100 (71%)] Train loss=0.268544 Test loss=0.461317 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2639339864253998
[5/23] Train loss=0.25233763456344604
[10/23] Train loss=0.26292553544044495
[15/23] Train loss=0.23813381791114807
[20/23] Train loss=0.2284795343875885
Test set avg_accuracy=82.12% avg_sensitivity=63.95%, avg_specificity=88.28% avg_auc=0.8414
Fold[5] Epoch: 72 [72/100 (72%)] Train loss=0.270066 Test loss=0.459781 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2772213816642761
[5/23] Train loss=0.2519597113132477
[10/23] Train loss=0.2620350122451782
[15/23] Train loss=0.25197434425354004
[20/23] Train loss=0.22119207680225372
Test set avg_accuracy=82.49% avg_sensitivity=61.18%, avg_specificity=89.70% avg_auc=0.8420
Fold[5] Epoch: 73 [73/100 (73%)] Train loss=0.269266 Test loss=0.451410 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28193697333335876
[5/23] Train loss=0.24699047207832336
[10/23] Train loss=0.2567325830459595
[15/23] Train loss=0.24369724094867706
[20/23] Train loss=0.21316447854042053
Test set avg_accuracy=82.37% avg_sensitivity=59.81%, avg_specificity=90.00% avg_auc=0.8403
Fold[5] Epoch: 74 [74/100 (74%)] Train loss=0.267117 Test loss=0.453804 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2623056173324585
[5/23] Train loss=0.24631758034229279
[10/23] Train loss=0.2530824542045593
[15/23] Train loss=0.23169547319412231
[20/23] Train loss=0.21210114657878876
Test set avg_accuracy=81.79% avg_sensitivity=63.25%, avg_specificity=88.07% avg_auc=0.8414
Fold[5] Epoch: 75 [75/100 (75%)] Train loss=0.261744 Test loss=0.462798 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2673884630203247
[5/23] Train loss=0.2496364265680313
[10/23] Train loss=0.2566066384315491
[15/23] Train loss=0.22979477047920227
[20/23] Train loss=0.22388754785060883
Test set avg_accuracy=81.38% avg_sensitivity=65.23%, avg_specificity=86.85% avg_auc=0.8351
Fold[5] Epoch: 76 [76/100 (76%)] Train loss=0.258593 Test loss=0.478197 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2669977843761444
[5/23] Train loss=0.24776776134967804
[10/23] Train loss=0.23559045791625977
[15/23] Train loss=0.23080594837665558
[20/23] Train loss=0.21337877213954926
Test set avg_accuracy=82.27% avg_sensitivity=62.71%, avg_specificity=88.89% avg_auc=0.8394
Fold[5] Epoch: 77 [77/100 (77%)] Train loss=0.256887 Test loss=0.463993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2586263120174408
[5/23] Train loss=0.24069394171237946
[10/23] Train loss=0.2469472438097
[15/23] Train loss=0.23992998898029327
[20/23] Train loss=0.21451173722743988
Test set avg_accuracy=82.68% avg_sensitivity=60.64%, avg_specificity=90.14% avg_auc=0.8413
Fold[5] Epoch: 78 [78/100 (78%)] Train loss=0.256262 Test loss=0.459029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2673361301422119
[5/23] Train loss=0.2391185611486435
[10/23] Train loss=0.23662470281124115
[15/23] Train loss=0.2216642051935196
[20/23] Train loss=0.21489229798316956
Test set avg_accuracy=81.94% avg_sensitivity=62.50%, avg_specificity=88.51% avg_auc=0.8405
Fold[5] Epoch: 79 [79/100 (79%)] Train loss=0.257279 Test loss=0.465841 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25728875398635864
[5/23] Train loss=0.24206766486167908
[10/23] Train loss=0.23553955554962158
[15/23] Train loss=0.2320508509874344
[20/23] Train loss=0.20984290540218353
Test set avg_accuracy=81.83% avg_sensitivity=65.60%, avg_specificity=87.32% avg_auc=0.8385
Fold[5] Epoch: 80 [80/100 (80%)] Train loss=0.253494 Test loss=0.485988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25728270411491394
[5/23] Train loss=0.2377828061580658
[10/23] Train loss=0.22655430436134338
[15/23] Train loss=0.2244228720664978
[20/23] Train loss=0.19499407708644867
Test set avg_accuracy=81.20% avg_sensitivity=64.69%, avg_specificity=86.79% avg_auc=0.8374
Fold[5] Epoch: 81 [81/100 (81%)] Train loss=0.249655 Test loss=0.480365 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2593024969100952
[5/23] Train loss=0.2358802855014801
[10/23] Train loss=0.23178991675376892
[15/23] Train loss=0.23129840195178986
[20/23] Train loss=0.20852337777614594
Test set avg_accuracy=81.89% avg_sensitivity=64.32%, avg_specificity=87.84% avg_auc=0.8365
Fold[5] Epoch: 82 [82/100 (82%)] Train loss=0.251202 Test loss=0.478255 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.254058301448822
[5/23] Train loss=0.2315034419298172
[10/23] Train loss=0.22755876183509827
[15/23] Train loss=0.22366701066493988
[20/23] Train loss=0.20110519230365753
Test set avg_accuracy=81.86% avg_sensitivity=63.70%, avg_specificity=88.01% avg_auc=0.8373
Fold[5] Epoch: 83 [83/100 (83%)] Train loss=0.248067 Test loss=0.473150 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2441841959953308
[5/23] Train loss=0.2264619618654251
[10/23] Train loss=0.2356027513742447
[15/23] Train loss=0.21346008777618408
[20/23] Train loss=0.20647551119327545
Test set avg_accuracy=81.54% avg_sensitivity=62.13%, avg_specificity=88.11% avg_auc=0.8364
Fold[5] Epoch: 84 [84/100 (84%)] Train loss=0.244810 Test loss=0.477948 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25298380851745605
[5/23] Train loss=0.22790442407131195
[10/23] Train loss=0.2369386851787567
[15/23] Train loss=0.22664573788642883
[20/23] Train loss=0.2065376341342926
Test set avg_accuracy=82.11% avg_sensitivity=64.36%, avg_specificity=88.12% avg_auc=0.8412
Fold[5] Epoch: 85 [85/100 (85%)] Train loss=0.246106 Test loss=0.476630 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2373041957616806
[5/23] Train loss=0.2322143167257309
[10/23] Train loss=0.2257956713438034
[15/23] Train loss=0.2248724102973938
[20/23] Train loss=0.20298922061920166
Test set avg_accuracy=81.44% avg_sensitivity=66.27%, avg_specificity=86.58% avg_auc=0.8390
Fold[5] Epoch: 86 [86/100 (86%)] Train loss=0.244862 Test loss=0.488555 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2552822530269623
[5/23] Train loss=0.22057534754276276
[10/23] Train loss=0.22489748895168304
[15/23] Train loss=0.20381532609462738
[20/23] Train loss=0.20523768663406372
Test set avg_accuracy=80.89% avg_sensitivity=67.84%, avg_specificity=85.31% avg_auc=0.8369
Fold[5] Epoch: 87 [87/100 (87%)] Train loss=0.238708 Test loss=0.510920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25747182965278625
[5/23] Train loss=0.22141605615615845
[10/23] Train loss=0.2191234678030014
[15/23] Train loss=0.22169949114322662
[20/23] Train loss=0.1944509893655777
Test set avg_accuracy=81.33% avg_sensitivity=69.00%, avg_specificity=85.50% avg_auc=0.8364
Fold[5] Epoch: 88 [88/100 (88%)] Train loss=0.238036 Test loss=0.510950 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25141218304634094
[5/23] Train loss=0.21647188067436218
[10/23] Train loss=0.2118469774723053
[15/23] Train loss=0.22066447138786316
[20/23] Train loss=0.1957130879163742
Test set avg_accuracy=81.06% avg_sensitivity=68.00%, avg_specificity=85.47% avg_auc=0.8306
Fold[5] Epoch: 89 [89/100 (89%)] Train loss=0.236068 Test loss=0.519458 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24883192777633667
[5/23] Train loss=0.21643368899822235
[10/23] Train loss=0.21800364553928375
[15/23] Train loss=0.22267179191112518
[20/23] Train loss=0.19114117324352264
Test set avg_accuracy=82.00% avg_sensitivity=66.76%, avg_specificity=87.16% avg_auc=0.8409
Fold[5] Epoch: 90 [90/100 (90%)] Train loss=0.238796 Test loss=0.486065 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24299083650112152
[5/23] Train loss=0.21682049334049225
[10/23] Train loss=0.22443945705890656
[15/23] Train loss=0.22465188801288605
[20/23] Train loss=0.19966623187065125
Test set avg_accuracy=81.08% avg_sensitivity=65.40%, avg_specificity=86.38% avg_auc=0.8338
Fold[5] Epoch: 91 [91/100 (91%)] Train loss=0.236221 Test loss=0.504196 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24317997694015503
[5/23] Train loss=0.2061726152896881
[10/23] Train loss=0.21234162151813507
[15/23] Train loss=0.21189160645008087
[20/23] Train loss=0.19102239608764648
Test set avg_accuracy=81.23% avg_sensitivity=67.59%, avg_specificity=85.85% avg_auc=0.8383
Fold[5] Epoch: 92 [92/100 (92%)] Train loss=0.230522 Test loss=0.512470 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2352122813463211
[5/23] Train loss=0.21133798360824585
[10/23] Train loss=0.22463104128837585
[15/23] Train loss=0.21009472012519836
[20/23] Train loss=0.19382517039775848
Test set avg_accuracy=81.65% avg_sensitivity=65.85%, avg_specificity=87.00% avg_auc=0.8371
Fold[5] Epoch: 93 [93/100 (93%)] Train loss=0.232951 Test loss=0.503982 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23534002900123596
[5/23] Train loss=0.20944516360759735
[10/23] Train loss=0.2296680212020874
[15/23] Train loss=0.2174929529428482
[20/23] Train loss=0.1973089575767517
Test set avg_accuracy=81.51% avg_sensitivity=61.84%, avg_specificity=88.16% avg_auc=0.8282
Fold[5] Epoch: 94 [94/100 (94%)] Train loss=0.243387 Test loss=0.501933 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2431550770998001
[5/23] Train loss=0.23352083563804626
[10/23] Train loss=0.22606369853019714
[15/23] Train loss=0.21736755967140198
[20/23] Train loss=0.1994996815919876
Test set avg_accuracy=81.82% avg_sensitivity=62.79%, avg_specificity=88.26% avg_auc=0.8371
Fold[5] Epoch: 95 [95/100 (95%)] Train loss=0.237583 Test loss=0.498171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22476308047771454
[5/23] Train loss=0.21601712703704834
[10/23] Train loss=0.2313132882118225
[15/23] Train loss=0.20801334083080292
[20/23] Train loss=0.18906818330287933
Test set avg_accuracy=82.28% avg_sensitivity=61.05%, avg_specificity=89.47% avg_auc=0.8318
Fold[5] Epoch: 96 [96/100 (96%)] Train loss=0.234075 Test loss=0.492946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22476372122764587
[5/23] Train loss=0.20490862429141998
[10/23] Train loss=0.21646644175052643
[15/23] Train loss=0.20932669937610626
[20/23] Train loss=0.18729493021965027
Test set avg_accuracy=81.89% avg_sensitivity=59.89%, avg_specificity=89.34% avg_auc=0.8323
Fold[5] Epoch: 97 [97/100 (97%)] Train loss=0.227985 Test loss=0.494099 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22448894381523132
[5/23] Train loss=0.21016167104244232
[10/23] Train loss=0.20551897585391998
[15/23] Train loss=0.20372413098812103
[20/23] Train loss=0.18978793919086456
Test set avg_accuracy=82.40% avg_sensitivity=62.54%, avg_specificity=89.12% avg_auc=0.8336
Fold[5] Epoch: 98 [98/100 (98%)] Train loss=0.228281 Test loss=0.496513 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22168166935443878
[5/23] Train loss=0.20112542808055878
[10/23] Train loss=0.20599062740802765
[15/23] Train loss=0.19868779182434082
[20/23] Train loss=0.1864572912454605
Test set avg_accuracy=81.60% avg_sensitivity=65.69%, avg_specificity=86.99% avg_auc=0.8349
Fold[5] Epoch: 99 [99/100 (99%)] Train loss=0.219410 Test loss=0.503829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2276645004749298
[5/23] Train loss=0.194257915019989
[10/23] Train loss=0.20510458946228027
[15/23] Train loss=0.20034922659397125
[20/23] Train loss=0.1753874570131302
Test set avg_accuracy=81.35% avg_sensitivity=65.85%, avg_specificity=86.59% avg_auc=0.8361
Fold[5] Epoch: 100 [100/100 (100%)] Train loss=0.216160 Test loss=0.519419 Current lr=[3.9999999999999996e-05]

Fold[5] Best Result: acc=81.82103610675038 sen=68.12913907284768, spe=86.45468553018631, auc=0.8430067178329277!
[0/23] Train loss=0.701093852519989
[5/23] Train loss=0.6780849695205688
[10/23] Train loss=0.5594669580459595
[15/23] Train loss=0.5646980404853821
[20/23] Train loss=0.5317989587783813
Test set avg_accuracy=76.88% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5489
Best model saved!! Metric=-94.23629690835477!!
Fold[6] Epoch: 1 [1/100 (1%)] Train loss=0.586615 Test loss=0.584507 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5612756609916687
[5/23] Train loss=0.6013821363449097
[10/23] Train loss=0.5162724852561951
[15/23] Train loss=0.5325077176094055
[20/23] Train loss=0.510473370552063
Test set avg_accuracy=76.76% avg_sensitivity=0.68%, avg_specificity=99.64% avg_auc=0.5891
Best model saved!! Metric=-89.99781979885385!!
Fold[6] Epoch: 2 [2/100 (2%)] Train loss=0.551320 Test loss=0.566273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.550887942314148
[5/23] Train loss=0.5555017590522766
[10/23] Train loss=0.4837874472141266
[15/23] Train loss=0.5056009888648987
[20/23] Train loss=0.4732472002506256
Test set avg_accuracy=76.21% avg_sensitivity=3.83%, avg_specificity=97.98% avg_auc=0.6670
Best model saved!! Metric=-81.26846483671211!!
Fold[6] Epoch: 3 [3/100 (3%)] Train loss=0.525867 Test loss=0.552126 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5288366079330444
[5/23] Train loss=0.49929091334342957
[10/23] Train loss=0.46676015853881836
[15/23] Train loss=0.4777161180973053
[20/23] Train loss=0.43310779333114624
Test set avg_accuracy=77.65% avg_sensitivity=14.23%, avg_specificity=96.72% avg_auc=0.7193
Best model saved!! Metric=-65.46741826077778!!
Fold[6] Epoch: 4 [4/100 (4%)] Train loss=0.495521 Test loss=0.535491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4977351129055023
[5/23] Train loss=0.463878333568573
[10/23] Train loss=0.4726710617542267
[15/23] Train loss=0.46559080481529236
[20/23] Train loss=0.40488043427467346
Test set avg_accuracy=78.92% avg_sensitivity=23.77%, avg_specificity=95.51% avg_auc=0.7604
Best model saved!! Metric=-51.75555905945362!!
Fold[6] Epoch: 5 [5/100 (5%)] Train loss=0.469728 Test loss=0.521149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4676414728164673
[5/23] Train loss=0.44654861092567444
[10/23] Train loss=0.47965434193611145
[15/23] Train loss=0.4430217742919922
[20/23] Train loss=0.3931276500225067
Test set avg_accuracy=79.74% avg_sensitivity=28.38%, avg_specificity=95.18% avg_auc=0.7751
Best model saved!! Metric=-45.19060933298312!!
Fold[6] Epoch: 6 [6/100 (6%)] Train loss=0.451378 Test loss=0.517175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43893665075302124
[5/23] Train loss=0.43769484758377075
[10/23] Train loss=0.4736122488975525
[15/23] Train loss=0.42477887868881226
[20/23] Train loss=0.393025279045105
Test set avg_accuracy=80.16% avg_sensitivity=33.35%, avg_specificity=94.24% avg_auc=0.7911
Best model saved!! Metric=-39.150866393407625!!
Fold[6] Epoch: 7 [7/100 (7%)] Train loss=0.440596 Test loss=0.492433 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4373922646045685
[5/23] Train loss=0.4270918071269989
[10/23] Train loss=0.47121983766555786
[15/23] Train loss=0.41127726435661316
[20/23] Train loss=0.38208824396133423
Test set avg_accuracy=80.44% avg_sensitivity=33.49%, avg_specificity=94.57% avg_auc=0.7966
Best model saved!! Metric=-37.84522385157621!!
Fold[6] Epoch: 8 [8/100 (8%)] Train loss=0.434568 Test loss=0.478273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43063491582870483
[5/23] Train loss=0.4230917990207672
[10/23] Train loss=0.47277337312698364
[15/23] Train loss=0.4094669818878174
[20/23] Train loss=0.37867000699043274
Test set avg_accuracy=80.76% avg_sensitivity=35.86%, avg_specificity=94.26% avg_auc=0.8080
Best model saved!! Metric=-34.32159753393417!!
Fold[6] Epoch: 9 [9/100 (9%)] Train loss=0.428128 Test loss=0.462170 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43058744072914124
[5/23] Train loss=0.41543692350387573
[10/23] Train loss=0.4667735993862152
[15/23] Train loss=0.39449217915534973
[20/23] Train loss=0.36232665181159973
Test set avg_accuracy=81.12% avg_sensitivity=36.72%, avg_specificity=94.47% avg_auc=0.8132
Best model saved!! Metric=-32.36252043513835!!
Fold[6] Epoch: 10 [10/100 (10%)] Train loss=0.424428 Test loss=0.457294 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4128674268722534
[5/23] Train loss=0.4196459650993347
[10/23] Train loss=0.4693317115306854
[15/23] Train loss=0.39379701018333435
[20/23] Train loss=0.3718838393688202
Test set avg_accuracy=81.12% avg_sensitivity=39.42%, avg_specificity=93.66% avg_auc=0.8208
Best model saved!! Metric=-29.723736778171983!!
Fold[6] Epoch: 11 [11/100 (11%)] Train loss=0.420104 Test loss=0.449532 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41788288950920105
[5/23] Train loss=0.41019049286842346
[10/23] Train loss=0.4610646069049835
[15/23] Train loss=0.38550159335136414
[20/23] Train loss=0.363168329000473
Test set avg_accuracy=81.49% avg_sensitivity=41.42%, avg_specificity=93.54% avg_auc=0.8300
Best model saved!! Metric=-26.550750041608538!!
Fold[6] Epoch: 12 [12/100 (12%)] Train loss=0.415762 Test loss=0.431007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.421466201543808
[5/23] Train loss=0.4038164019584656
[10/23] Train loss=0.46440476179122925
[15/23] Train loss=0.38574275374412537
[20/23] Train loss=0.3577228784561157
Test set avg_accuracy=82.20% avg_sensitivity=41.70%, avg_specificity=94.39% avg_auc=0.8269
Best model saved!! Metric=-25.02401319240283!!
Fold[6] Epoch: 13 [13/100 (13%)] Train loss=0.413605 Test loss=0.438986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4093308448791504
[5/23] Train loss=0.40502673387527466
[10/23] Train loss=0.4583522379398346
[15/23] Train loss=0.380115807056427
[20/23] Train loss=0.35640180110931396
Test set avg_accuracy=81.90% avg_sensitivity=43.02%, avg_specificity=93.59% avg_auc=0.8347
Best model saved!! Metric=-24.020204413969598!!
Fold[6] Epoch: 14 [14/100 (14%)] Train loss=0.409021 Test loss=0.423464 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4244530200958252
[5/23] Train loss=0.39743825793266296
[10/23] Train loss=0.4546676278114319
[15/23] Train loss=0.3730258345603943
[20/23] Train loss=0.35416653752326965
Test set avg_accuracy=82.03% avg_sensitivity=42.66%, avg_specificity=93.87% avg_auc=0.8307
Fold[6] Epoch: 15 [15/100 (15%)] Train loss=0.404804 Test loss=0.432297 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40165194869041443
[5/23] Train loss=0.4004279673099518
[10/23] Train loss=0.44535717368125916
[15/23] Train loss=0.3762414753437042
[20/23] Train loss=0.34901317954063416
Test set avg_accuracy=82.77% avg_sensitivity=46.35%, avg_specificity=93.73% avg_auc=0.8411
Best model saved!! Metric=-19.04011454339508!!
Fold[6] Epoch: 16 [16/100 (16%)] Train loss=0.404567 Test loss=0.410259 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42253577709198
[5/23] Train loss=0.39492562413215637
[10/23] Train loss=0.45377424359321594
[15/23] Train loss=0.3635709881782532
[20/23] Train loss=0.3463495373725891
Test set avg_accuracy=82.62% avg_sensitivity=46.67%, avg_specificity=93.43% avg_auc=0.8389
Fold[6] Epoch: 17 [17/100 (17%)] Train loss=0.400769 Test loss=0.419931 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39968255162239075
[5/23] Train loss=0.39053064584732056
[10/23] Train loss=0.44681915640830994
[15/23] Train loss=0.3609894812107086
[20/23] Train loss=0.33819782733917236
Test set avg_accuracy=82.62% avg_sensitivity=47.03%, avg_specificity=93.32% avg_auc=0.8413
Best model saved!! Metric=-18.902717196194814!!
Fold[6] Epoch: 18 [18/100 (18%)] Train loss=0.397427 Test loss=0.412707 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39987877011299133
[5/23] Train loss=0.3953166604042053
[10/23] Train loss=0.4429946541786194
[15/23] Train loss=0.36125096678733826
[20/23] Train loss=0.3368338644504547
Test set avg_accuracy=82.59% avg_sensitivity=47.08%, avg_specificity=93.28% avg_auc=0.8386
Fold[6] Epoch: 19 [19/100 (19%)] Train loss=0.396489 Test loss=0.417541 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39946937561035156
[5/23] Train loss=0.3871490955352783
[10/23] Train loss=0.44639989733695984
[15/23] Train loss=0.35892951488494873
[20/23] Train loss=0.33460769057273865
Test set avg_accuracy=82.28% avg_sensitivity=44.53%, avg_specificity=93.63% avg_auc=0.8387
Fold[6] Epoch: 20 [20/100 (20%)] Train loss=0.395032 Test loss=0.423028 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38571861386299133
[5/23] Train loss=0.38370558619499207
[10/23] Train loss=0.44012483954429626
[15/23] Train loss=0.3523571491241455
[20/23] Train loss=0.3352484703063965
Test set avg_accuracy=82.66% avg_sensitivity=43.80%, avg_specificity=94.35% avg_auc=0.8360
Fold[6] Epoch: 21 [21/100 (21%)] Train loss=0.392046 Test loss=0.427324 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3874877989292145
[5/23] Train loss=0.3843897879123688
[10/23] Train loss=0.4473228454589844
[15/23] Train loss=0.35669323801994324
[20/23] Train loss=0.333558589220047
Test set avg_accuracy=82.69% avg_sensitivity=43.16%, avg_specificity=94.58% avg_auc=0.8323
Fold[6] Epoch: 22 [22/100 (22%)] Train loss=0.393430 Test loss=0.437925 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38534706830978394
[5/23] Train loss=0.3823452889919281
[10/23] Train loss=0.44786569476127625
[15/23] Train loss=0.35440385341644287
[20/23] Train loss=0.33386051654815674
Test set avg_accuracy=82.84% avg_sensitivity=47.35%, avg_specificity=93.51% avg_auc=0.8353
Best model saved!! Metric=-18.76732493852365!!
Fold[6] Epoch: 23 [23/100 (23%)] Train loss=0.389385 Test loss=0.439413 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3902030289173126
[5/23] Train loss=0.3843526244163513
[10/23] Train loss=0.43048906326293945
[15/23] Train loss=0.34650737047195435
[20/23] Train loss=0.33257627487182617
Test set avg_accuracy=83.65% avg_sensitivity=50.41%, avg_specificity=93.65% avg_auc=0.8523
Best model saved!! Metric=-13.059204406329108!!
Fold[6] Epoch: 24 [24/100 (24%)] Train loss=0.385086 Test loss=0.397090 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39006924629211426
[5/23] Train loss=0.37905022501945496
[10/23] Train loss=0.42985713481903076
[15/23] Train loss=0.3408268392086029
[20/23] Train loss=0.32359668612480164
Test set avg_accuracy=83.63% avg_sensitivity=54.74%, avg_specificity=92.32% avg_auc=0.8496
Best model saved!! Metric=-10.35359767210532!!
Fold[6] Epoch: 25 [25/100 (25%)] Train loss=0.380357 Test loss=0.400096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37690678238868713
[5/23] Train loss=0.37688136100769043
[10/23] Train loss=0.4264256954193115
[15/23] Train loss=0.3418944478034973
[20/23] Train loss=0.31771984696388245
Test set avg_accuracy=83.92% avg_sensitivity=53.56%, avg_specificity=93.06% avg_auc=0.8493
Fold[6] Epoch: 26 [26/100 (26%)] Train loss=0.378239 Test loss=0.402541 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38378551602363586
[5/23] Train loss=0.3725074827671051
[10/23] Train loss=0.4200842082500458
[15/23] Train loss=0.3431732654571533
[20/23] Train loss=0.3153066635131836
Test set avg_accuracy=83.61% avg_sensitivity=50.41%, avg_specificity=93.59% avg_auc=0.8414
Fold[6] Epoch: 27 [27/100 (27%)] Train loss=0.375748 Test loss=0.416504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3691342771053314
[5/23] Train loss=0.3726794719696045
[10/23] Train loss=0.4207996726036072
[15/23] Train loss=0.3380158543586731
[20/23] Train loss=0.3171766996383667
Test set avg_accuracy=83.59% avg_sensitivity=51.00%, avg_specificity=93.39% avg_auc=0.8440
Fold[6] Epoch: 28 [28/100 (28%)] Train loss=0.373613 Test loss=0.417090 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37454473972320557
[5/23] Train loss=0.3677018880844116
[10/23] Train loss=0.4077024459838867
[15/23] Train loss=0.3321095108985901
[20/23] Train loss=0.32427188754081726
Test set avg_accuracy=83.76% avg_sensitivity=57.80%, avg_specificity=91.56% avg_auc=0.8530
Best model saved!! Metric=-7.578075430320963!!
Fold[6] Epoch: 29 [29/100 (29%)] Train loss=0.371017 Test loss=0.398420 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3884822130203247
[5/23] Train loss=0.3613245487213135
[10/23] Train loss=0.40642836689949036
[15/23] Train loss=0.33416157960891724
[20/23] Train loss=0.31897982954978943
Test set avg_accuracy=83.60% avg_sensitivity=55.57%, avg_specificity=92.03% avg_auc=0.8556
Fold[6] Epoch: 30 [30/100 (30%)] Train loss=0.367551 Test loss=0.390723 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37686440348625183
[5/23] Train loss=0.36572763323783875
[10/23] Train loss=0.4004322290420532
[15/23] Train loss=0.3292013704776764
[20/23] Train loss=0.3024808466434479
Test set avg_accuracy=83.59% avg_sensitivity=56.39%, avg_specificity=91.77% avg_auc=0.8503
Fold[6] Epoch: 31 [31/100 (31%)] Train loss=0.363322 Test loss=0.405311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3644430935382843
[5/23] Train loss=0.35695981979370117
[10/23] Train loss=0.40556102991104126
[15/23] Train loss=0.33339864015579224
[20/23] Train loss=0.297320693731308
Test set avg_accuracy=83.79% avg_sensitivity=55.57%, avg_specificity=92.27% avg_auc=0.8547
Fold[6] Epoch: 32 [32/100 (32%)] Train loss=0.363366 Test loss=0.397309 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36645591259002686
[5/23] Train loss=0.3562624752521515
[10/23] Train loss=0.39509323239326477
[15/23] Train loss=0.3141193389892578
[20/23] Train loss=0.3066467046737671
Test set avg_accuracy=83.81% avg_sensitivity=57.07%, avg_specificity=91.85% avg_auc=0.8598
Best model saved!! Metric=-7.287684635499165!!
Fold[6] Epoch: 33 [33/100 (33%)] Train loss=0.361125 Test loss=0.391239 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3634011149406433
[5/23] Train loss=0.34652280807495117
[10/23] Train loss=0.39275017380714417
[15/23] Train loss=0.31556347012519836
[20/23] Train loss=0.29994645714759827
Test set avg_accuracy=83.78% avg_sensitivity=57.48%, avg_specificity=91.68% avg_auc=0.8599
Best model saved!! Metric=-7.071691601114841!!
Fold[6] Epoch: 34 [34/100 (34%)] Train loss=0.357124 Test loss=0.395593 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3619621992111206
[5/23] Train loss=0.34585046768188477
[10/23] Train loss=0.39306333661079407
[15/23] Train loss=0.3194716274738312
[20/23] Train loss=0.29522714018821716
Test set avg_accuracy=83.84% avg_sensitivity=56.48%, avg_specificity=92.07% avg_auc=0.8613
Fold[6] Epoch: 35 [35/100 (35%)] Train loss=0.353171 Test loss=0.393021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35348549485206604
[5/23] Train loss=0.34198668599128723
[10/23] Train loss=0.39020031690597534
[15/23] Train loss=0.3224447965621948
[20/23] Train loss=0.29762208461761475
Test set avg_accuracy=83.89% avg_sensitivity=54.97%, avg_specificity=92.59% avg_auc=0.8591
Fold[6] Epoch: 36 [36/100 (36%)] Train loss=0.352470 Test loss=0.391965 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34987276792526245
[5/23] Train loss=0.34384390711784363
[10/23] Train loss=0.3820596933364868
[15/23] Train loss=0.31023699045181274
[20/23] Train loss=0.2893454432487488
Test set avg_accuracy=83.50% avg_sensitivity=53.92%, avg_specificity=92.40% avg_auc=0.8577
Fold[6] Epoch: 37 [37/100 (37%)] Train loss=0.349330 Test loss=0.396907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3476397395133972
[5/23] Train loss=0.3392922580242157
[10/23] Train loss=0.39582496881484985
[15/23] Train loss=0.31164002418518066
[20/23] Train loss=0.2912517189979553
Test set avg_accuracy=83.31% avg_sensitivity=47.31%, avg_specificity=94.14% avg_auc=0.8531
Fold[6] Epoch: 38 [38/100 (38%)] Train loss=0.349383 Test loss=0.412250 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35036247968673706
[5/23] Train loss=0.3414386212825775
[10/23] Train loss=0.3882364332675934
[15/23] Train loss=0.30726268887519836
[20/23] Train loss=0.2905600666999817
Test set avg_accuracy=83.79% avg_sensitivity=53.56%, avg_specificity=92.88% avg_auc=0.8555
Fold[6] Epoch: 39 [39/100 (39%)] Train loss=0.347175 Test loss=0.413257 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34409353137016296
[5/23] Train loss=0.3346322178840637
[10/23] Train loss=0.38091862201690674
[15/23] Train loss=0.30529850721359253
[20/23] Train loss=0.289105087518692
Test set avg_accuracy=83.58% avg_sensitivity=55.79%, avg_specificity=91.93% avg_auc=0.8564
Fold[6] Epoch: 40 [40/100 (40%)] Train loss=0.341125 Test loss=0.414016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3512507975101471
[5/23] Train loss=0.3436090052127838
[10/23] Train loss=0.36563149094581604
[15/23] Train loss=0.30342596769332886
[20/23] Train loss=0.27510306239128113
Test set avg_accuracy=83.88% avg_sensitivity=59.35%, avg_specificity=91.26% avg_auc=0.8615
Best model saved!! Metric=-5.358693118588602!!
Fold[6] Epoch: 41 [41/100 (41%)] Train loss=0.337435 Test loss=0.399734 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34178972244262695
[5/23] Train loss=0.32508715987205505
[10/23] Train loss=0.37127166986465454
[15/23] Train loss=0.28727591037750244
[20/23] Train loss=0.2749713063240051
Test set avg_accuracy=84.07% avg_sensitivity=58.39%, avg_specificity=91.79% avg_auc=0.8604
Fold[6] Epoch: 42 [42/100 (42%)] Train loss=0.333045 Test loss=0.401848 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3408380150794983
[5/23] Train loss=0.33387458324432373
[10/23] Train loss=0.3603992462158203
[15/23] Train loss=0.2913547456264496
[20/23] Train loss=0.28130999207496643
Test set avg_accuracy=83.95% avg_sensitivity=59.72%, avg_specificity=91.23% avg_auc=0.8629
Best model saved!! Metric=-4.813448468126795!!
Fold[6] Epoch: 43 [43/100 (43%)] Train loss=0.334437 Test loss=0.395607 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3354395925998688
[5/23] Train loss=0.31644898653030396
[10/23] Train loss=0.3582538664340973
[15/23] Train loss=0.2910137474536896
[20/23] Train loss=0.27967190742492676
Test set avg_accuracy=84.12% avg_sensitivity=60.95%, avg_specificity=91.09% avg_auc=0.8642
Best model saved!! Metric=-3.4134857838646564!!
Fold[6] Epoch: 44 [44/100 (44%)] Train loss=0.329181 Test loss=0.393219 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33887314796447754
[5/23] Train loss=0.3283236026763916
[10/23] Train loss=0.3518260419368744
[15/23] Train loss=0.2869938313961029
[20/23] Train loss=0.2726920545101166
Test set avg_accuracy=83.71% avg_sensitivity=59.72%, avg_specificity=90.93% avg_auc=0.8613
Fold[6] Epoch: 45 [45/100 (45%)] Train loss=0.329742 Test loss=0.403429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34202802181243896
[5/23] Train loss=0.3188900649547577
[10/23] Train loss=0.34828922152519226
[15/23] Train loss=0.28584960103034973
[20/23] Train loss=0.28075385093688965
Test set avg_accuracy=84.01% avg_sensitivity=62.00%, avg_specificity=90.63% avg_auc=0.8642
Best model saved!! Metric=-2.944891874023968!!
Fold[6] Epoch: 46 [46/100 (46%)] Train loss=0.328164 Test loss=0.398519 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.342885285615921
[5/23] Train loss=0.3028853237628937
[10/23] Train loss=0.3480129837989807
[15/23] Train loss=0.2822909355163574
[20/23] Train loss=0.27414828538894653
Test set avg_accuracy=83.51% avg_sensitivity=61.86%, avg_specificity=90.02% avg_auc=0.8622
Fold[6] Epoch: 47 [47/100 (47%)] Train loss=0.324799 Test loss=0.402444 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32706528902053833
[5/23] Train loss=0.31036606431007385
[10/23] Train loss=0.34573113918304443
[15/23] Train loss=0.2893311381340027
[20/23] Train loss=0.27842074632644653
Test set avg_accuracy=83.80% avg_sensitivity=62.09%, avg_specificity=90.33% avg_auc=0.8644
Fold[6] Epoch: 48 [48/100 (48%)] Train loss=0.323482 Test loss=0.396320 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3367803692817688
[5/23] Train loss=0.3082440495491028
[10/23] Train loss=0.3470775783061981
[15/23] Train loss=0.29319626092910767
[20/23] Train loss=0.27838191390037537
Test set avg_accuracy=83.81% avg_sensitivity=63.23%, avg_specificity=90.00% avg_auc=0.8661
Best model saved!! Metric=-2.3582110282495816!!
Fold[6] Epoch: 49 [49/100 (49%)] Train loss=0.323396 Test loss=0.397574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3243504464626312
[5/23] Train loss=0.3000152111053467
[10/23] Train loss=0.34079158306121826
[15/23] Train loss=0.29678913950920105
[20/23] Train loss=0.2726922035217285
Test set avg_accuracy=83.77% avg_sensitivity=61.95%, avg_specificity=90.33% avg_auc=0.8645
Fold[6] Epoch: 50 [50/100 (50%)] Train loss=0.321515 Test loss=0.395406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3255438208580017
[5/23] Train loss=0.3104317784309387
[10/23] Train loss=0.33567845821380615
[15/23] Train loss=0.28555840253829956
[20/23] Train loss=0.2611375153064728
Test set avg_accuracy=84.17% avg_sensitivity=60.45%, avg_specificity=91.30% avg_auc=0.8642
Fold[6] Epoch: 51 [51/100 (51%)] Train loss=0.318183 Test loss=0.401448 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31215137243270874
[5/23] Train loss=0.2975882291793823
[10/23] Train loss=0.3400348424911499
[15/23] Train loss=0.27123764157295227
[20/23] Train loss=0.2667398452758789
Test set avg_accuracy=83.71% avg_sensitivity=53.88%, avg_specificity=92.69% avg_auc=0.8620
Fold[6] Epoch: 52 [52/100 (52%)] Train loss=0.315778 Test loss=0.392669 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3165266811847687
[5/23] Train loss=0.3019879460334778
[10/23] Train loss=0.34097912907600403
[15/23] Train loss=0.28110259771347046
[20/23] Train loss=0.26232200860977173
Test set avg_accuracy=83.82% avg_sensitivity=49.68%, avg_specificity=94.09% avg_auc=0.8616
Fold[6] Epoch: 53 [53/100 (53%)] Train loss=0.314836 Test loss=0.390651 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3172823190689087
[5/23] Train loss=0.30949661135673523
[10/23] Train loss=0.3409711420536041
[15/23] Train loss=0.2775951027870178
[20/23] Train loss=0.25629034638404846
Test set avg_accuracy=83.35% avg_sensitivity=47.31%, avg_specificity=94.20% avg_auc=0.8574
Fold[6] Epoch: 54 [54/100 (54%)] Train loss=0.313054 Test loss=0.400057 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3121742904186249
[5/23] Train loss=0.3009353280067444
[10/23] Train loss=0.33761802315711975
[15/23] Train loss=0.2748340964317322
[20/23] Train loss=0.26214295625686646
Test set avg_accuracy=83.57% avg_sensitivity=54.15%, avg_specificity=92.41% avg_auc=0.8601
Fold[6] Epoch: 55 [55/100 (55%)] Train loss=0.311915 Test loss=0.404173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31734976172447205
[5/23] Train loss=0.2959129214286804
[10/23] Train loss=0.32385116815567017
[15/23] Train loss=0.2746144235134125
[20/23] Train loss=0.2604024112224579
Test set avg_accuracy=83.47% avg_sensitivity=62.91%, avg_specificity=89.65% avg_auc=0.8612
Fold[6] Epoch: 56 [56/100 (56%)] Train loss=0.306931 Test loss=0.402199 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3136172890663147
[5/23] Train loss=0.29471156001091003
[10/23] Train loss=0.3254145383834839
[15/23] Train loss=0.26991790533065796
[20/23] Train loss=0.2474288046360016
Test set avg_accuracy=83.54% avg_sensitivity=55.43%, avg_specificity=92.00% avg_auc=0.8626
Fold[6] Epoch: 57 [57/100 (57%)] Train loss=0.305316 Test loss=0.396486 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3058708906173706
[5/23] Train loss=0.2940100431442261
[10/23] Train loss=0.3248562812805176
[15/23] Train loss=0.2674100399017334
[20/23] Train loss=0.24887119233608246
Test set avg_accuracy=83.60% avg_sensitivity=56.25%, avg_specificity=91.82% avg_auc=0.8611
Fold[6] Epoch: 58 [58/100 (58%)] Train loss=0.302344 Test loss=0.399457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30924054980278015
[5/23] Train loss=0.28981444239616394
[10/23] Train loss=0.3184244930744171
[15/23] Train loss=0.26624754071235657
[20/23] Train loss=0.25185149908065796
Test set avg_accuracy=83.81% avg_sensitivity=50.00%, avg_specificity=93.98% avg_auc=0.8564
Fold[6] Epoch: 59 [59/100 (59%)] Train loss=0.302659 Test loss=0.414858 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29896920919418335
[5/23] Train loss=0.28285226225852966
[10/23] Train loss=0.30810266733169556
[15/23] Train loss=0.2870635390281677
[20/23] Train loss=0.2540128529071808
Test set avg_accuracy=83.36% avg_sensitivity=62.00%, avg_specificity=89.79% avg_auc=0.8608
Fold[6] Epoch: 60 [60/100 (60%)] Train loss=0.303099 Test loss=0.409902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2979294955730438
[5/23] Train loss=0.28085118532180786
[10/23] Train loss=0.31200602650642395
[15/23] Train loss=0.25649622082710266
[20/23] Train loss=0.2401474565267563
Test set avg_accuracy=83.88% avg_sensitivity=63.73%, avg_specificity=89.94% avg_auc=0.8596
Fold[6] Epoch: 61 [61/100 (61%)] Train loss=0.296669 Test loss=0.416190 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29241472482681274
[5/23] Train loss=0.28256797790527344
[10/23] Train loss=0.31107354164123535
[15/23] Train loss=0.26114678382873535
[20/23] Train loss=0.24236039817333221
Test set avg_accuracy=83.62% avg_sensitivity=62.00%, avg_specificity=90.12% avg_auc=0.8607
Fold[6] Epoch: 62 [62/100 (62%)] Train loss=0.295868 Test loss=0.411093 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2896236479282379
[5/23] Train loss=0.2757892608642578
[10/23] Train loss=0.30081868171691895
[15/23] Train loss=0.2657068073749542
[20/23] Train loss=0.24811016023159027
Test set avg_accuracy=84.24% avg_sensitivity=62.09%, avg_specificity=90.90% avg_auc=0.8604
Fold[6] Epoch: 63 [63/100 (63%)] Train loss=0.291806 Test loss=0.411933 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2989426553249359
[5/23] Train loss=0.278702050447464
[10/23] Train loss=0.29748865962028503
[15/23] Train loss=0.2605948746204376
[20/23] Train loss=0.24076257646083832
Test set avg_accuracy=83.83% avg_sensitivity=63.05%, avg_specificity=90.08% avg_auc=0.8629
Fold[6] Epoch: 64 [64/100 (64%)] Train loss=0.289850 Test loss=0.414369 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28528207540512085
[5/23] Train loss=0.2611541450023651
[10/23] Train loss=0.294970840215683
[15/23] Train loss=0.25017163157463074
[20/23] Train loss=0.23754924535751343
Test set avg_accuracy=83.73% avg_sensitivity=59.26%, avg_specificity=91.09% avg_auc=0.8597
Fold[6] Epoch: 65 [65/100 (65%)] Train loss=0.285936 Test loss=0.411454 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27652931213378906
[5/23] Train loss=0.26600536704063416
[10/23] Train loss=0.2913394570350647
[15/23] Train loss=0.24809391796588898
[20/23] Train loss=0.2337491661310196
Test set avg_accuracy=84.02% avg_sensitivity=56.71%, avg_specificity=92.23% avg_auc=0.8595
Fold[6] Epoch: 66 [66/100 (66%)] Train loss=0.283515 Test loss=0.407589 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29019853472709656
[5/23] Train loss=0.2564921975135803
[10/23] Train loss=0.29333555698394775
[15/23] Train loss=0.2541569471359253
[20/23] Train loss=0.2282078117132187
Test set avg_accuracy=84.04% avg_sensitivity=55.66%, avg_specificity=92.58% avg_auc=0.8591
Fold[6] Epoch: 67 [67/100 (67%)] Train loss=0.282565 Test loss=0.411000 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2873547375202179
[5/23] Train loss=0.2738383710384369
[10/23] Train loss=0.3050501048564911
[15/23] Train loss=0.24295899271965027
[20/23] Train loss=0.22797921299934387
Test set avg_accuracy=83.45% avg_sensitivity=45.67%, avg_specificity=94.81% avg_auc=0.8570
Fold[6] Epoch: 68 [68/100 (68%)] Train loss=0.282236 Test loss=0.417802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29100996255874634
[5/23] Train loss=0.2579552233219147
[10/23] Train loss=0.2939445674419403
[15/23] Train loss=0.24510174989700317
[20/23] Train loss=0.22527290880680084
Test set avg_accuracy=83.59% avg_sensitivity=52.55%, avg_specificity=92.92% avg_auc=0.8573
Fold[6] Epoch: 69 [69/100 (69%)] Train loss=0.279087 Test loss=0.416949 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2857220470905304
[5/23] Train loss=0.27113988995552063
[10/23] Train loss=0.2840263247489929
[15/23] Train loss=0.23763960599899292
[20/23] Train loss=0.22519990801811218
Test set avg_accuracy=84.00% avg_sensitivity=58.26%, avg_specificity=91.74% avg_auc=0.8574
Fold[6] Epoch: 70 [70/100 (70%)] Train loss=0.276000 Test loss=0.418264 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.273517370223999
[5/23] Train loss=0.2523292899131775
[10/23] Train loss=0.2783929407596588
[15/23] Train loss=0.25668442249298096
[20/23] Train loss=0.22625918686389923
Test set avg_accuracy=83.80% avg_sensitivity=56.98%, avg_specificity=91.86% avg_auc=0.8535
Fold[6] Epoch: 71 [71/100 (71%)] Train loss=0.272239 Test loss=0.419592 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2854801416397095
[5/23] Train loss=0.2539883852005005
[10/23] Train loss=0.2727539837360382
[15/23] Train loss=0.24332891404628754
[20/23] Train loss=0.22170141339302063
Test set avg_accuracy=83.71% avg_sensitivity=60.95%, avg_specificity=90.56% avg_auc=0.8517
Fold[6] Epoch: 72 [72/100 (72%)] Train loss=0.269578 Test loss=0.425447 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2777469754219055
[5/23] Train loss=0.25565704703330994
[10/23] Train loss=0.2758443355560303
[15/23] Train loss=0.23495730757713318
[20/23] Train loss=0.2269841730594635
Test set avg_accuracy=83.66% avg_sensitivity=62.14%, avg_specificity=90.13% avg_auc=0.8557
Fold[6] Epoch: 73 [73/100 (73%)] Train loss=0.267648 Test loss=0.430451 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26637569069862366
[5/23] Train loss=0.24171538650989532
[10/23] Train loss=0.27143001556396484
[15/23] Train loss=0.23145590722560883
[20/23] Train loss=0.22230863571166992
Test set avg_accuracy=83.39% avg_sensitivity=59.22%, avg_specificity=90.66% avg_auc=0.8496
Fold[6] Epoch: 74 [74/100 (74%)] Train loss=0.264355 Test loss=0.435750 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2719686031341553
[5/23] Train loss=0.24541790783405304
[10/23] Train loss=0.2567785382270813
[15/23] Train loss=0.21863262355327606
[20/23] Train loss=0.2179267257452011
Test set avg_accuracy=83.26% avg_sensitivity=59.63%, avg_specificity=90.37% avg_auc=0.8517
Fold[6] Epoch: 75 [75/100 (75%)] Train loss=0.261273 Test loss=0.439296 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2669052481651306
[5/23] Train loss=0.2392098605632782
[10/23] Train loss=0.26188793778419495
[15/23] Train loss=0.20851609110832214
[20/23] Train loss=0.2155037224292755
Test set avg_accuracy=83.48% avg_sensitivity=57.48%, avg_specificity=91.30% avg_auc=0.8537
Fold[6] Epoch: 76 [76/100 (76%)] Train loss=0.259714 Test loss=0.438531 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2658464014530182
[5/23] Train loss=0.2502416670322418
[10/23] Train loss=0.2697032392024994
[15/23] Train loss=0.23185542225837708
[20/23] Train loss=0.20959226787090302
Test set avg_accuracy=83.69% avg_sensitivity=53.28%, avg_specificity=92.84% avg_auc=0.8532
Fold[6] Epoch: 77 [77/100 (77%)] Train loss=0.259852 Test loss=0.432178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2486145943403244
[5/23] Train loss=0.2451391965150833
[10/23] Train loss=0.2852022051811218
[15/23] Train loss=0.2207837700843811
[20/23] Train loss=0.21020355820655823
Test set avg_accuracy=83.91% avg_sensitivity=53.33%, avg_specificity=93.11% avg_auc=0.8480
Fold[6] Epoch: 78 [78/100 (78%)] Train loss=0.257678 Test loss=0.430218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2518977224826813
[5/23] Train loss=0.23314526677131653
[10/23] Train loss=0.25991421937942505
[15/23] Train loss=0.22910653054714203
[20/23] Train loss=0.20520184934139252
Test set avg_accuracy=83.95% avg_sensitivity=54.79%, avg_specificity=92.71% avg_auc=0.8488
Fold[6] Epoch: 79 [79/100 (79%)] Train loss=0.254636 Test loss=0.437425 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26277729868888855
[5/23] Train loss=0.2372942566871643
[10/23] Train loss=0.2438734620809555
[15/23] Train loss=0.2338165044784546
[20/23] Train loss=0.2001206874847412
Test set avg_accuracy=84.25% avg_sensitivity=58.53%, avg_specificity=91.99% avg_auc=0.8499
Fold[6] Epoch: 80 [80/100 (80%)] Train loss=0.252489 Test loss=0.432791 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25525352358818054
[5/23] Train loss=0.233342707157135
[10/23] Train loss=0.2548845410346985
[15/23] Train loss=0.22021088004112244
[20/23] Train loss=0.20939281582832336
Test set avg_accuracy=83.68% avg_sensitivity=59.44%, avg_specificity=90.97% avg_auc=0.8435
Fold[6] Epoch: 81 [81/100 (81%)] Train loss=0.249154 Test loss=0.448424 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2553846538066864
[5/23] Train loss=0.23746153712272644
[10/23] Train loss=0.24813178181648254
[15/23] Train loss=0.21857719123363495
[20/23] Train loss=0.19041049480438232
Test set avg_accuracy=83.45% avg_sensitivity=61.59%, avg_specificity=90.02% avg_auc=0.8490
Fold[6] Epoch: 82 [82/100 (82%)] Train loss=0.246540 Test loss=0.449501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25251972675323486
[5/23] Train loss=0.23003129661083221
[10/23] Train loss=0.24701820313930511
[15/23] Train loss=0.20992055535316467
[20/23] Train loss=0.20245318114757538
Test set avg_accuracy=83.38% avg_sensitivity=60.77%, avg_specificity=90.18% avg_auc=0.8491
Fold[6] Epoch: 83 [83/100 (83%)] Train loss=0.243163 Test loss=0.448463 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25318655371665955
[5/23] Train loss=0.21803778409957886
[10/23] Train loss=0.24406172335147858
[15/23] Train loss=0.20115745067596436
[20/23] Train loss=0.20246447622776031
Test set avg_accuracy=82.76% avg_sensitivity=62.68%, avg_specificity=88.80% avg_auc=0.8401
Fold[6] Epoch: 84 [84/100 (84%)] Train loss=0.240810 Test loss=0.470744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2497568428516388
[5/23] Train loss=0.21410973370075226
[10/23] Train loss=0.23039180040359497
[15/23] Train loss=0.20847491919994354
[20/23] Train loss=0.20610520243644714
Test set avg_accuracy=82.91% avg_sensitivity=66.97%, avg_specificity=87.71% avg_auc=0.8437
Fold[6] Epoch: 85 [85/100 (85%)] Train loss=0.236195 Test loss=0.486007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2390868067741394
[5/23] Train loss=0.21653984487056732
[10/23] Train loss=0.23039036989212036
[15/23] Train loss=0.21024282276630402
[20/23] Train loss=0.19189615547657013
Test set avg_accuracy=83.40% avg_sensitivity=62.73%, avg_specificity=89.61% avg_auc=0.8471
Fold[6] Epoch: 86 [86/100 (86%)] Train loss=0.241854 Test loss=0.461576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23662184178829193
[5/23] Train loss=0.2127869725227356
[10/23] Train loss=0.2369348257780075
[15/23] Train loss=0.2158452272415161
[20/23] Train loss=0.2055717557668686
Test set avg_accuracy=82.15% avg_sensitivity=63.78%, avg_specificity=87.68% avg_auc=0.8425
Fold[6] Epoch: 87 [87/100 (87%)] Train loss=0.236049 Test loss=0.472714 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23944763839244843
[5/23] Train loss=0.22793452441692352
[10/23] Train loss=0.24027682840824127
[15/23] Train loss=0.21522918343544006
[20/23] Train loss=0.1925087720155716
Test set avg_accuracy=83.51% avg_sensitivity=62.32%, avg_specificity=89.89% avg_auc=0.8423
Fold[6] Epoch: 88 [88/100 (88%)] Train loss=0.238779 Test loss=0.468560 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25462445616722107
[5/23] Train loss=0.22522364556789398
[10/23] Train loss=0.23417611420154572
[15/23] Train loss=0.21796846389770508
[20/23] Train loss=0.19373778998851776
Test set avg_accuracy=83.54% avg_sensitivity=66.42%, avg_specificity=88.69% avg_auc=0.8416
Fold[6] Epoch: 89 [89/100 (89%)] Train loss=0.241196 Test loss=0.474190 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2431795746088028
[5/23] Train loss=0.20733404159545898
[10/23] Train loss=0.2272031158208847
[15/23] Train loss=0.2175263613462448
[20/23] Train loss=0.19956271350383759
Test set avg_accuracy=83.89% avg_sensitivity=61.54%, avg_specificity=90.61% avg_auc=0.8446
Fold[6] Epoch: 90 [90/100 (90%)] Train loss=0.235793 Test loss=0.463878 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24832239747047424
[5/23] Train loss=0.2150876522064209
[10/23] Train loss=0.21565470099449158
[15/23] Train loss=0.20773833990097046
[20/23] Train loss=0.18593809008598328
Test set avg_accuracy=83.57% avg_sensitivity=63.09%, avg_specificity=89.72% avg_auc=0.8430
Fold[6] Epoch: 91 [91/100 (91%)] Train loss=0.233959 Test loss=0.473150 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24072065949440002
[5/23] Train loss=0.21101483702659607
[10/23] Train loss=0.23097915947437286
[15/23] Train loss=0.20014269649982452
[20/23] Train loss=0.18620476126670837
Test set avg_accuracy=83.28% avg_sensitivity=57.44%, avg_specificity=91.05% avg_auc=0.8446
Fold[6] Epoch: 92 [92/100 (92%)] Train loss=0.231774 Test loss=0.463908 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2271188348531723
[5/23] Train loss=0.20364639163017273
[10/23] Train loss=0.217866912484169
[15/23] Train loss=0.19436495006084442
[20/23] Train loss=0.19134952127933502
Test set avg_accuracy=83.73% avg_sensitivity=53.47%, avg_specificity=92.84% avg_auc=0.8373
Fold[6] Epoch: 93 [93/100 (93%)] Train loss=0.227671 Test loss=0.458170 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2369801551103592
[5/23] Train loss=0.1982041299343109
[10/23] Train loss=0.23325686156749725
[15/23] Train loss=0.1958126723766327
[20/23] Train loss=0.17801441252231598
Test set avg_accuracy=83.61% avg_sensitivity=50.23%, avg_specificity=93.65% avg_auc=0.8351
Fold[6] Epoch: 94 [94/100 (94%)] Train loss=0.228687 Test loss=0.464775 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24031919240951538
[5/23] Train loss=0.2050570845603943
[10/23] Train loss=0.2280893474817276
[15/23] Train loss=0.19638726115226746
[20/23] Train loss=0.18250156939029694
Test set avg_accuracy=83.64% avg_sensitivity=51.41%, avg_specificity=93.33% avg_auc=0.8368
Fold[6] Epoch: 95 [95/100 (95%)] Train loss=0.226062 Test loss=0.461757 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21694794297218323
[5/23] Train loss=0.20752815902233124
[10/23] Train loss=0.24554911255836487
[15/23] Train loss=0.20796442031860352
[20/23] Train loss=0.17873243987560272
Test set avg_accuracy=82.88% avg_sensitivity=44.89%, avg_specificity=94.31% avg_auc=0.8317
Fold[6] Epoch: 96 [96/100 (96%)] Train loss=0.231040 Test loss=0.467738 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23099172115325928
[5/23] Train loss=0.20533183217048645
[10/23] Train loss=0.24231120944023132
[15/23] Train loss=0.21491330862045288
[20/23] Train loss=0.19113309681415558
Test set avg_accuracy=83.20% avg_sensitivity=53.24%, avg_specificity=92.21% avg_auc=0.8417
Fold[6] Epoch: 97 [97/100 (97%)] Train loss=0.233454 Test loss=0.470033 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21983417868614197
[5/23] Train loss=0.20339153707027435
[10/23] Train loss=0.22184602916240692
[15/23] Train loss=0.20218037068843842
[20/23] Train loss=0.18096935749053955
Test set avg_accuracy=82.71% avg_sensitivity=63.32%, avg_specificity=88.54% avg_auc=0.8380
Fold[6] Epoch: 98 [98/100 (98%)] Train loss=0.222504 Test loss=0.488383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22186346352100372
[5/23] Train loss=0.203224778175354
[10/23] Train loss=0.21626853942871094
[15/23] Train loss=0.1816914826631546
[20/23] Train loss=0.16593782603740692
Test set avg_accuracy=83.19% avg_sensitivity=56.43%, avg_specificity=91.23% avg_auc=0.8381
Fold[6] Epoch: 99 [99/100 (99%)] Train loss=0.217492 Test loss=0.480329 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21355293691158295
[5/23] Train loss=0.20172430574893951
[10/23] Train loss=0.20886477828025818
[15/23] Train loss=0.18904472887516022
[20/23] Train loss=0.16956911981105804
Test set avg_accuracy=83.36% avg_sensitivity=57.39%, avg_specificity=91.18% avg_auc=0.8420
Fold[6] Epoch: 100 [100/100 (100%)] Train loss=0.210934 Test loss=0.476642 Current lr=[3.9999999999999996e-05]

Fold[6] Best Result: acc=83.80801687763713 sen=63.22992700729927, spe=89.99725576289791, auc=0.8660658932391612!
[0/23] Train loss=0.7193781137466431
[5/23] Train loss=0.6879616379737854
[10/23] Train loss=0.5633221864700317
[15/23] Train loss=0.550679087638855
[20/23] Train loss=0.5335618853569031
Test set avg_accuracy=75.58% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5653
Best model saved!! Metric=-93.89019193091778!!
Fold[7] Epoch: 1 [1/100 (1%)] Train loss=0.586651 Test loss=0.615511 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5692259669303894
[5/23] Train loss=0.6018725633621216
[10/23] Train loss=0.5120799541473389
[15/23] Train loss=0.5203021764755249
[20/23] Train loss=0.5081568956375122
Test set avg_accuracy=75.53% avg_sensitivity=0.30%, avg_specificity=99.83% avg_auc=0.6013
Best model saved!! Metric=-90.20485400337158!!
Fold[7] Epoch: 2 [2/100 (2%)] Train loss=0.550133 Test loss=0.579244 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5455210208892822
[5/23] Train loss=0.5470060110092163
[10/23] Train loss=0.48279237747192383
[15/23] Train loss=0.49244606494903564
[20/23] Train loss=0.46616846323013306
Test set avg_accuracy=76.54% avg_sensitivity=9.34%, avg_specificity=98.25% avg_auc=0.6590
Best model saved!! Metric=-75.96366339323905!!
Fold[7] Epoch: 3 [3/100 (3%)] Train loss=0.518235 Test loss=0.585372 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5140463709831238
[5/23] Train loss=0.48938971757888794
[10/23] Train loss=0.47505077719688416
[15/23] Train loss=0.4640500247478485
[20/23] Train loss=0.4245198667049408
Test set avg_accuracy=77.50% avg_sensitivity=15.49%, avg_specificity=97.53% avg_auc=0.7172
Best model saved!! Metric=-63.757356745600205!!
Fold[7] Epoch: 4 [4/100 (4%)] Train loss=0.484335 Test loss=0.611914 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4828988313674927
[5/23] Train loss=0.4598216116428375
[10/23] Train loss=0.46977975964546204
[15/23] Train loss=0.4722062349319458
[20/23] Train loss=0.4049607515335083
Test set avg_accuracy=78.66% avg_sensitivity=22.23%, avg_specificity=96.89% avg_auc=0.7497
Best model saved!! Metric=-53.263830027920875!!
Fold[7] Epoch: 5 [5/100 (5%)] Train loss=0.462666 Test loss=0.576770 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4670923352241516
[5/23] Train loss=0.44760772585868835
[10/23] Train loss=0.469308078289032
[15/23] Train loss=0.43504154682159424
[20/23] Train loss=0.39984607696533203
Test set avg_accuracy=79.56% avg_sensitivity=25.98%, avg_specificity=96.87% avg_auc=0.7619
Best model saved!! Metric=-47.38995408295735!!
Fold[7] Epoch: 6 [6/100 (6%)] Train loss=0.448620 Test loss=0.551389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4368343651294708
[5/23] Train loss=0.44203609228134155
[10/23] Train loss=0.4766382873058319
[15/23] Train loss=0.42845049500465393
[20/23] Train loss=0.390271931886673
Test set avg_accuracy=79.90% avg_sensitivity=28.80%, avg_specificity=96.40% avg_auc=0.7793
Best model saved!! Metric=-42.97020621120272!!
Fold[7] Epoch: 7 [7/100 (7%)] Train loss=0.440376 Test loss=0.525215 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43900156021118164
[5/23] Train loss=0.43012535572052
[10/23] Train loss=0.46569985151290894
[15/23] Train loss=0.42168691754341125
[20/23] Train loss=0.38027137517929077
Test set avg_accuracy=79.93% avg_sensitivity=30.67%, avg_specificity=95.84% avg_auc=0.7958
Best model saved!! Metric=-39.98152378385532!!
Fold[7] Epoch: 8 [8/100 (8%)] Train loss=0.433594 Test loss=0.488979 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4401523768901825
[5/23] Train loss=0.4271107614040375
[10/23] Train loss=0.4725356698036194
[15/23] Train loss=0.3947058320045471
[20/23] Train loss=0.3873918056488037
Test set avg_accuracy=80.17% avg_sensitivity=31.02%, avg_specificity=96.04% avg_auc=0.7967
Best model saved!! Metric=-39.10255550935527!!
Fold[7] Epoch: 9 [9/100 (9%)] Train loss=0.429144 Test loss=0.499167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42421698570251465
[5/23] Train loss=0.41858232021331787
[10/23] Train loss=0.471965491771698
[15/23] Train loss=0.39942681789398193
[20/23] Train loss=0.3791275918483734
Test set avg_accuracy=80.55% avg_sensitivity=33.19%, avg_specificity=95.85% avg_auc=0.8013
Best model saved!! Metric=-36.27749315461969!!
Fold[7] Epoch: 10 [10/100 (10%)] Train loss=0.425663 Test loss=0.491828 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4280073642730713
[5/23] Train loss=0.41617152094841003
[10/23] Train loss=0.466079980134964
[15/23] Train loss=0.4063960313796997
[20/23] Train loss=0.37248119711875916
Test set avg_accuracy=80.44% avg_sensitivity=32.08%, avg_specificity=96.06% avg_auc=0.8043
Fold[7] Epoch: 11 [11/100 (11%)] Train loss=0.423251 Test loss=0.488581 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42075759172439575
[5/23] Train loss=0.41649162769317627
[10/23] Train loss=0.46594372391700745
[15/23] Train loss=0.3890562653541565
[20/23] Train loss=0.36873364448547363
Test set avg_accuracy=80.58% avg_sensitivity=32.64%, avg_specificity=96.07% avg_auc=0.8049
Best model saved!! Metric=-36.21893258005929!!
Fold[7] Epoch: 12 [12/100 (12%)] Train loss=0.420026 Test loss=0.496808 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.407892644405365
[5/23] Train loss=0.4104730486869812
[10/23] Train loss=0.46597355604171753
[15/23] Train loss=0.3775406777858734
[20/23] Train loss=0.36562618613243103
Test set avg_accuracy=80.60% avg_sensitivity=31.48%, avg_specificity=96.47% avg_auc=0.8027
Fold[7] Epoch: 13 [13/100 (13%)] Train loss=0.419138 Test loss=0.503913 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4082958400249481
[5/23] Train loss=0.40293601155281067
[10/23] Train loss=0.4703882336616516
[15/23] Train loss=0.38076919317245483
[20/23] Train loss=0.3590623736381531
Test set avg_accuracy=80.61% avg_sensitivity=32.12%, avg_specificity=96.28% avg_auc=0.8072
Fold[7] Epoch: 14 [14/100 (14%)] Train loss=0.417535 Test loss=0.504587 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4055638909339905
[5/23] Train loss=0.4078560769557953
[10/23] Train loss=0.4587751030921936
[15/23] Train loss=0.37315744161605835
[20/23] Train loss=0.3635881841182709
Test set avg_accuracy=81.48% avg_sensitivity=38.57%, avg_specificity=95.34% avg_auc=0.8214
Best model saved!! Metric=-28.47427741726905!!
Fold[7] Epoch: 15 [15/100 (15%)] Train loss=0.410249 Test loss=0.458678 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4127766788005829
[5/23] Train loss=0.40352046489715576
[10/23] Train loss=0.4525975286960602
[15/23] Train loss=0.3703983724117279
[20/23] Train loss=0.3608309328556061
Test set avg_accuracy=81.98% avg_sensitivity=41.42%, avg_specificity=95.08% avg_auc=0.8318
Best model saved!! Metric=-24.336482427786397!!
Fold[7] Epoch: 16 [16/100 (16%)] Train loss=0.404893 Test loss=0.436690 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4100453853607178
[5/23] Train loss=0.39621493220329285
[10/23] Train loss=0.4544405937194824
[15/23] Train loss=0.36629271507263184
[20/23] Train loss=0.35255008935928345
Test set avg_accuracy=81.93% avg_sensitivity=40.49%, avg_specificity=95.31% avg_auc=0.8293
Fold[7] Epoch: 17 [17/100 (17%)] Train loss=0.401160 Test loss=0.447030 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39486438035964966
[5/23] Train loss=0.3973534107208252
[10/23] Train loss=0.45154210925102234
[15/23] Train loss=0.3592454791069031
[20/23] Train loss=0.34856608510017395
Test set avg_accuracy=80.95% avg_sensitivity=35.11%, avg_specificity=95.76% avg_auc=0.8248
Fold[7] Epoch: 18 [18/100 (18%)] Train loss=0.402352 Test loss=0.470874 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39110109210014343
[5/23] Train loss=0.39323922991752625
[10/23] Train loss=0.45517587661743164
[15/23] Train loss=0.37187233567237854
[20/23] Train loss=0.3483218252658844
Test set avg_accuracy=81.39% avg_sensitivity=37.46%, avg_specificity=95.58% avg_auc=0.8254
Fold[7] Epoch: 19 [19/100 (19%)] Train loss=0.401074 Test loss=0.471682 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39694952964782715
[5/23] Train loss=0.3905582129955292
[10/23] Train loss=0.44426506757736206
[15/23] Train loss=0.36030757427215576
[20/23] Train loss=0.34844785928726196
Test set avg_accuracy=82.28% avg_sensitivity=43.69%, avg_specificity=94.75% avg_auc=0.8386
Best model saved!! Metric=-21.42199123897934!!
Fold[7] Epoch: 20 [20/100 (20%)] Train loss=0.393787 Test loss=0.427601 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40330085158348083
[5/23] Train loss=0.3954300582408905
[10/23] Train loss=0.4411013424396515
[15/23] Train loss=0.35866326093673706
[20/23] Train loss=0.34860897064208984
Test set avg_accuracy=82.02% avg_sensitivity=41.00%, avg_specificity=95.27% avg_auc=0.8363
Fold[7] Epoch: 21 [21/100 (21%)] Train loss=0.391948 Test loss=0.446869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38372570276260376
[5/23] Train loss=0.38872626423835754
[10/23] Train loss=0.43854543566703796
[15/23] Train loss=0.3587961792945862
[20/23] Train loss=0.3387104570865631
Test set avg_accuracy=81.62% avg_sensitivity=40.91%, avg_specificity=94.78% avg_auc=0.8358
Fold[7] Epoch: 22 [22/100 (22%)] Train loss=0.391196 Test loss=0.443481 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39079248905181885
[5/23] Train loss=0.3857199549674988
[10/23] Train loss=0.43794652819633484
[15/23] Train loss=0.3458419740200043
[20/23] Train loss=0.33008795976638794
Test set avg_accuracy=81.88% avg_sensitivity=42.62%, avg_specificity=94.56% avg_auc=0.8402
Fold[7] Epoch: 23 [23/100 (23%)] Train loss=0.386695 Test loss=0.439581 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3891785740852356
[5/23] Train loss=0.382534921169281
[10/23] Train loss=0.4328192472457886
[15/23] Train loss=0.34610170125961304
[20/23] Train loss=0.3298964500427246
Test set avg_accuracy=82.09% avg_sensitivity=44.88%, avg_specificity=94.12% avg_auc=0.8408
Best model saved!! Metric=-20.82610989704647!!
Fold[7] Epoch: 24 [24/100 (24%)] Train loss=0.381205 Test loss=0.434442 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3815906047821045
[5/23] Train loss=0.3784708082675934
[10/23] Train loss=0.4316122829914093
[15/23] Train loss=0.34826862812042236
[20/23] Train loss=0.3274129629135132
Test set avg_accuracy=82.16% avg_sensitivity=41.47%, avg_specificity=95.30% avg_auc=0.8399
Fold[7] Epoch: 25 [25/100 (25%)] Train loss=0.380901 Test loss=0.445569 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3748694956302643
[5/23] Train loss=0.38114020228385925
[10/23] Train loss=0.4303441047668457
[15/23] Train loss=0.33650022745132446
[20/23] Train loss=0.3258560001850128
Test set avg_accuracy=82.36% avg_sensitivity=46.37%, avg_specificity=93.99% avg_auc=0.8418
Best model saved!! Metric=-19.08963650027032!!
Fold[7] Epoch: 26 [26/100 (26%)] Train loss=0.377539 Test loss=0.434522 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3783682584762573
[5/23] Train loss=0.3765992522239685
[10/23] Train loss=0.4267752170562744
[15/23] Train loss=0.3364979028701782
[20/23] Train loss=0.322068989276886
Test set avg_accuracy=82.54% avg_sensitivity=47.70%, avg_specificity=93.80% avg_auc=0.8421
Best model saved!! Metric=-17.753902776157616!!
Fold[7] Epoch: 27 [27/100 (27%)] Train loss=0.373224 Test loss=0.432573 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3778439462184906
[5/23] Train loss=0.3822704553604126
[10/23] Train loss=0.4211046099662781
[15/23] Train loss=0.3397163450717926
[20/23] Train loss=0.3226224482059479
Test set avg_accuracy=82.43% avg_sensitivity=46.72%, avg_specificity=93.96% avg_auc=0.8464
Fold[7] Epoch: 28 [28/100 (28%)] Train loss=0.372053 Test loss=0.418773 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.371859073638916
[5/23] Train loss=0.37624531984329224
[10/23] Train loss=0.4145412743091583
[15/23] Train loss=0.32755395770072937
[20/23] Train loss=0.3160203993320465
Test set avg_accuracy=82.47% avg_sensitivity=48.51%, avg_specificity=93.44% avg_auc=0.8463
Best model saved!! Metric=-16.950067685540237!!
Fold[7] Epoch: 29 [29/100 (29%)] Train loss=0.370579 Test loss=0.426263 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37182608246803284
[5/23] Train loss=0.36704400181770325
[10/23] Train loss=0.4101504981517792
[15/23] Train loss=0.33064526319503784
[20/23] Train loss=0.3178764879703522
Test set avg_accuracy=82.53% avg_sensitivity=47.91%, avg_specificity=93.72% avg_auc=0.8504
Best model saved!! Metric=-16.800603055115502!!
Fold[7] Epoch: 30 [30/100 (30%)] Train loss=0.367196 Test loss=0.421561 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36700665950775146
[5/23] Train loss=0.3659262955188751
[10/23] Train loss=0.4118266999721527
[15/23] Train loss=0.3248770833015442
[20/23] Train loss=0.31335529685020447
Test set avg_accuracy=82.43% avg_sensitivity=46.33%, avg_specificity=94.09% avg_auc=0.8502
Fold[7] Epoch: 31 [31/100 (31%)] Train loss=0.365184 Test loss=0.423116 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3632809817790985
[5/23] Train loss=0.366997629404068
[10/23] Train loss=0.42073944211006165
[15/23] Train loss=0.31897541880607605
[20/23] Train loss=0.30344200134277344
Test set avg_accuracy=82.08% avg_sensitivity=39.21%, avg_specificity=95.93% avg_auc=0.8430
Fold[7] Epoch: 32 [32/100 (32%)] Train loss=0.369206 Test loss=0.458832 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3605383038520813
[5/23] Train loss=0.36534491181373596
[10/23] Train loss=0.4163160026073456
[15/23] Train loss=0.3444816470146179
[20/23] Train loss=0.3140343725681305
Test set avg_accuracy=82.71% avg_sensitivity=48.68%, avg_specificity=93.70% avg_auc=0.8512
Best model saved!! Metric=-15.78966526309717!!
Fold[7] Epoch: 33 [33/100 (33%)] Train loss=0.368429 Test loss=0.430026 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36034923791885376
[5/23] Train loss=0.36705517768859863
[10/23] Train loss=0.4217551052570343
[15/23] Train loss=0.32561805844306946
[20/23] Train loss=0.3145482838153839
Test set avg_accuracy=82.18% avg_sensitivity=40.53%, avg_specificity=95.63% avg_auc=0.8482
Fold[7] Epoch: 34 [34/100 (34%)] Train loss=0.363264 Test loss=0.434918 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35569822788238525
[5/23] Train loss=0.3605212867259979
[10/23] Train loss=0.41189953684806824
[15/23] Train loss=0.32443302869796753
[20/23] Train loss=0.3065490424633026
Test set avg_accuracy=83.24% avg_sensitivity=52.22%, avg_specificity=93.26% avg_auc=0.8554
Best model saved!! Metric=-11.744837821243713!!
Fold[7] Epoch: 35 [35/100 (35%)] Train loss=0.357120 Test loss=0.414546 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3593297600746155
[5/23] Train loss=0.3574390709400177
[10/23] Train loss=0.39535969495773315
[15/23] Train loss=0.3107377290725708
[20/23] Train loss=0.2980585992336273
Test set avg_accuracy=83.23% avg_sensitivity=50.21%, avg_specificity=93.89% avg_auc=0.8531
Fold[7] Epoch: 36 [36/100 (36%)] Train loss=0.352207 Test loss=0.423524 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3484007716178894
[5/23] Train loss=0.35272499918937683
[10/23] Train loss=0.39371076226234436
[15/23] Train loss=0.3229723572731018
[20/23] Train loss=0.30133238434791565
Test set avg_accuracy=83.67% avg_sensitivity=55.76%, avg_specificity=92.68% avg_auc=0.8558
Best model saved!! Metric=-8.31349133367952!!
Fold[7] Epoch: 37 [37/100 (37%)] Train loss=0.351048 Test loss=0.418979 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35209453105926514
[5/23] Train loss=0.3571268618106842
[10/23] Train loss=0.4024290442466736
[15/23] Train loss=0.29982972145080566
[20/23] Train loss=0.2964760959148407
Test set avg_accuracy=83.08% avg_sensitivity=47.61%, avg_specificity=94.54% avg_auc=0.8545
Fold[7] Epoch: 38 [38/100 (38%)] Train loss=0.350360 Test loss=0.422049 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3505867123603821
[5/23] Train loss=0.3569113612174988
[10/23] Train loss=0.39225107431411743
[15/23] Train loss=0.3186185359954834
[20/23] Train loss=0.2923455536365509
Test set avg_accuracy=82.99% avg_sensitivity=49.74%, avg_specificity=93.73% avg_auc=0.8565
Fold[7] Epoch: 39 [39/100 (39%)] Train loss=0.350734 Test loss=0.419027 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.346574068069458
[5/23] Train loss=0.36219295859336853
[10/23] Train loss=0.39031481742858887
[15/23] Train loss=0.30780228972435
[20/23] Train loss=0.29592421650886536
Test set avg_accuracy=82.48% avg_sensitivity=44.62%, avg_specificity=94.71% avg_auc=0.8542
Fold[7] Epoch: 40 [40/100 (40%)] Train loss=0.347833 Test loss=0.424716 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3437272608280182
[5/23] Train loss=0.3542535901069641
[10/23] Train loss=0.4022616147994995
[15/23] Train loss=0.32524725794792175
[20/23] Train loss=0.29636749625205994
Test set avg_accuracy=83.18% avg_sensitivity=57.30%, avg_specificity=91.54% avg_auc=0.8571
Best model saved!! Metric=-8.275692479363514!!
Fold[7] Epoch: 41 [41/100 (41%)] Train loss=0.352709 Test loss=0.407850 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3496619164943695
[5/23] Train loss=0.34641796350479126
[10/23] Train loss=0.4010384976863861
[15/23] Train loss=0.2998702824115753
[20/23] Train loss=0.2917281687259674
Test set avg_accuracy=82.80% avg_sensitivity=45.52%, avg_specificity=94.85% avg_auc=0.8550
Fold[7] Epoch: 42 [42/100 (42%)] Train loss=0.343853 Test loss=0.416221 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3401752710342407
[5/23] Train loss=0.3433198630809784
[10/23] Train loss=0.3835085332393646
[15/23] Train loss=0.30116114020347595
[20/23] Train loss=0.28417277336120605
Test set avg_accuracy=82.85% avg_sensitivity=49.62%, avg_specificity=93.59% avg_auc=0.8558
Fold[7] Epoch: 43 [43/100 (43%)] Train loss=0.339436 Test loss=0.414821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33687853813171387
[5/23] Train loss=0.342648983001709
[10/23] Train loss=0.3744000196456909
[15/23] Train loss=0.3002875745296478
[20/23] Train loss=0.28571656346321106
Test set avg_accuracy=83.41% avg_sensitivity=52.13%, avg_specificity=93.51% avg_auc=0.8533
Fold[7] Epoch: 44 [44/100 (44%)] Train loss=0.336314 Test loss=0.433395 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3294033110141754
[5/23] Train loss=0.341487854719162
[10/23] Train loss=0.3704648017883301
[15/23] Train loss=0.29974666237831116
[20/23] Train loss=0.27756208181381226
Test set avg_accuracy=83.72% avg_sensitivity=52.82%, avg_specificity=93.70% avg_auc=0.8561
Fold[7] Epoch: 45 [45/100 (45%)] Train loss=0.331951 Test loss=0.420055 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3343947231769562
[5/23] Train loss=0.3377933204174042
[10/23] Train loss=0.3785055875778198
[15/23] Train loss=0.29758182168006897
[20/23] Train loss=0.28524094820022583
Test set avg_accuracy=82.93% avg_sensitivity=47.61%, avg_specificity=94.34% avg_auc=0.8544
Fold[7] Epoch: 46 [46/100 (46%)] Train loss=0.332971 Test loss=0.422086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3330977261066437
[5/23] Train loss=0.3334544897079468
[10/23] Train loss=0.3702436089515686
[15/23] Train loss=0.2989908754825592
[20/23] Train loss=0.27648022770881653
Test set avg_accuracy=83.92% avg_sensitivity=55.63%, avg_specificity=93.05% avg_auc=0.8566
Best model saved!! Metric=-7.742170223881242!!
Fold[7] Epoch: 47 [47/100 (47%)] Train loss=0.329433 Test loss=0.417041 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.333910197019577
[5/23] Train loss=0.3340736925601959
[10/23] Train loss=0.36176684498786926
[15/23] Train loss=0.2817763090133667
[20/23] Train loss=0.28045782446861267
Test set avg_accuracy=83.53% avg_sensitivity=53.28%, avg_specificity=93.30% avg_auc=0.8574
Fold[7] Epoch: 48 [48/100 (48%)] Train loss=0.324917 Test loss=0.420586 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3153054714202881
[5/23] Train loss=0.32412493228912354
[10/23] Train loss=0.3567740023136139
[15/23] Train loss=0.2808113396167755
[20/23] Train loss=0.2731931507587433
Test set avg_accuracy=83.40% avg_sensitivity=52.39%, avg_specificity=93.41% avg_auc=0.8571
Fold[7] Epoch: 49 [49/100 (49%)] Train loss=0.325611 Test loss=0.414778 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3234182596206665
[5/23] Train loss=0.3326171934604645
[10/23] Train loss=0.3627173900604248
[15/23] Train loss=0.27735427021980286
[20/23] Train loss=0.2728384733200073
Test set avg_accuracy=82.71% avg_sensitivity=49.70%, avg_specificity=93.37% avg_auc=0.8528
Fold[7] Epoch: 50 [50/100 (50%)] Train loss=0.323479 Test loss=0.429339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3286794126033783
[5/23] Train loss=0.32783040404319763
[10/23] Train loss=0.35293176770210266
[15/23] Train loss=0.2779112756252289
[20/23] Train loss=0.27441585063934326
Test set avg_accuracy=83.16% avg_sensitivity=50.73%, avg_specificity=93.63% avg_auc=0.8534
Fold[7] Epoch: 51 [51/100 (51%)] Train loss=0.320043 Test loss=0.429865 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3204715847969055
[5/23] Train loss=0.3174901306629181
[10/23] Train loss=0.35845431685447693
[15/23] Train loss=0.2759200930595398
[20/23] Train loss=0.2734290361404419
Test set avg_accuracy=83.00% avg_sensitivity=52.01%, avg_specificity=93.01% avg_auc=0.8546
Fold[7] Epoch: 52 [52/100 (52%)] Train loss=0.316477 Test loss=0.434238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3141738772392273
[5/23] Train loss=0.32131463289260864
[10/23] Train loss=0.3491666316986084
[15/23] Train loss=0.2750300168991089
[20/23] Train loss=0.272553414106369
Test set avg_accuracy=83.46% avg_sensitivity=52.43%, avg_specificity=93.48% avg_auc=0.8561
Fold[7] Epoch: 53 [53/100 (53%)] Train loss=0.314908 Test loss=0.425037 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31683972477912903
[5/23] Train loss=0.32148224115371704
[10/23] Train loss=0.3460385799407959
[15/23] Train loss=0.27928611636161804
[20/23] Train loss=0.25926533341407776
Test set avg_accuracy=83.75% avg_sensitivity=54.01%, avg_specificity=93.36% avg_auc=0.8598
Fold[7] Epoch: 54 [54/100 (54%)] Train loss=0.312988 Test loss=0.413372 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3167977035045624
[5/23] Train loss=0.31701141595840454
[10/23] Train loss=0.34409740567207336
[15/23] Train loss=0.27039802074432373
[20/23] Train loss=0.2643115818500519
Test set avg_accuracy=83.31% avg_sensitivity=47.44%, avg_specificity=94.90% avg_auc=0.8595
Fold[7] Epoch: 55 [55/100 (55%)] Train loss=0.314128 Test loss=0.411385 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3083702027797699
[5/23] Train loss=0.3123267889022827
[10/23] Train loss=0.3474266231060028
[15/23] Train loss=0.2848401367664337
[20/23] Train loss=0.2636619210243225
Test set avg_accuracy=83.94% avg_sensitivity=55.25%, avg_specificity=93.21% avg_auc=0.8579
Fold[7] Epoch: 56 [56/100 (56%)] Train loss=0.310144 Test loss=0.416855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3150753676891327
[5/23] Train loss=0.3162387013435364
[10/23] Train loss=0.3378317654132843
[15/23] Train loss=0.2586984932422638
[20/23] Train loss=0.2580021917819977
Test set avg_accuracy=83.40% avg_sensitivity=55.59%, avg_specificity=92.38% avg_auc=0.8585
Fold[7] Epoch: 57 [57/100 (57%)] Train loss=0.305262 Test loss=0.423403 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3053094148635864
[5/23] Train loss=0.3049831688404083
[10/23] Train loss=0.334617555141449
[15/23] Train loss=0.26825350522994995
[20/23] Train loss=0.2602120637893677
Test set avg_accuracy=83.24% avg_sensitivity=52.69%, avg_specificity=93.11% avg_auc=0.8580
Fold[7] Epoch: 58 [58/100 (58%)] Train loss=0.306761 Test loss=0.418428 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.318539559841156
[5/23] Train loss=0.302089661359787
[10/23] Train loss=0.3543698787689209
[15/23] Train loss=0.2707332968711853
[20/23] Train loss=0.2592691481113434
Test set avg_accuracy=82.86% avg_sensitivity=47.40%, avg_specificity=94.32% avg_auc=0.8549
Fold[7] Epoch: 59 [59/100 (59%)] Train loss=0.307268 Test loss=0.431726 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3022642433643341
[5/23] Train loss=0.3033128082752228
[10/23] Train loss=0.33183443546295166
[15/23] Train loss=0.2671695351600647
[20/23] Train loss=0.25049513578414917
Test set avg_accuracy=83.46% avg_sensitivity=51.96%, avg_specificity=93.63% avg_auc=0.8586
Fold[7] Epoch: 60 [60/100 (60%)] Train loss=0.303879 Test loss=0.428550 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30231061577796936
[5/23] Train loss=0.306953102350235
[10/23] Train loss=0.3294554650783539
[15/23] Train loss=0.25748154520988464
[20/23] Train loss=0.25537315011024475
Test set avg_accuracy=83.50% avg_sensitivity=54.22%, avg_specificity=92.96% avg_auc=0.8623
Fold[7] Epoch: 61 [61/100 (61%)] Train loss=0.301041 Test loss=0.410865 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2969599664211273
[5/23] Train loss=0.29837337136268616
[10/23] Train loss=0.32016050815582275
[15/23] Train loss=0.2657436728477478
[20/23] Train loss=0.24561594426631927
Test set avg_accuracy=83.47% avg_sensitivity=51.83%, avg_specificity=93.69% avg_auc=0.8582
Fold[7] Epoch: 62 [62/100 (62%)] Train loss=0.296546 Test loss=0.416637 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31305748224258423
[5/23] Train loss=0.3017144501209259
[10/23] Train loss=0.32902368903160095
[15/23] Train loss=0.2614074647426605
[20/23] Train loss=0.24967311322689056
Test set avg_accuracy=83.48% avg_sensitivity=52.77%, avg_specificity=93.40% avg_auc=0.8598
Fold[7] Epoch: 63 [63/100 (63%)] Train loss=0.298262 Test loss=0.414768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29908329248428345
[5/23] Train loss=0.28836381435394287
[10/23] Train loss=0.3323493003845215
[15/23] Train loss=0.2571595013141632
[20/23] Train loss=0.24875189363956451
Test set avg_accuracy=82.77% avg_sensitivity=45.26%, avg_specificity=94.89% avg_auc=0.8568
Fold[7] Epoch: 64 [64/100 (64%)] Train loss=0.297602 Test loss=0.433939 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2988612949848175
[5/23] Train loss=0.30181217193603516
[10/23] Train loss=0.3259187936782837
[15/23] Train loss=0.27119818329811096
[20/23] Train loss=0.24609535932540894
Test set avg_accuracy=83.46% avg_sensitivity=50.09%, avg_specificity=94.24% avg_auc=0.8562
Fold[7] Epoch: 65 [65/100 (65%)] Train loss=0.296094 Test loss=0.427471 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29018938541412354
[5/23] Train loss=0.288772314786911
[10/23] Train loss=0.32026341557502747
[15/23] Train loss=0.24971650540828705
[20/23] Train loss=0.25144776701927185
Test set avg_accuracy=83.29% avg_sensitivity=50.51%, avg_specificity=93.88% avg_auc=0.8564
Fold[7] Epoch: 66 [66/100 (66%)] Train loss=0.289419 Test loss=0.436912 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2944968640804291
[5/23] Train loss=0.3001156747341156
[10/23] Train loss=0.3053073287010193
[15/23] Train loss=0.2591923177242279
[20/23] Train loss=0.2417050302028656
Test set avg_accuracy=83.67% avg_sensitivity=57.17%, avg_specificity=92.23% avg_auc=0.8570
Best model saved!! Metric=-7.234658963340362!!
Fold[7] Epoch: 67 [67/100 (67%)] Train loss=0.287179 Test loss=0.428283 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28960391879081726
[5/23] Train loss=0.2905846834182739
[10/23] Train loss=0.31375381350517273
[15/23] Train loss=0.24632027745246887
[20/23] Train loss=0.23277749121189117
Test set avg_accuracy=83.95% avg_sensitivity=54.82%, avg_specificity=93.36% avg_auc=0.8576
Fold[7] Epoch: 68 [68/100 (68%)] Train loss=0.284782 Test loss=0.434504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28260549902915955
[5/23] Train loss=0.28268328309059143
[10/23] Train loss=0.3039467930793762
[15/23] Train loss=0.24023762345314026
[20/23] Train loss=0.2348940372467041
Test set avg_accuracy=83.40% avg_sensitivity=53.20%, avg_specificity=93.15% avg_auc=0.8562
Fold[7] Epoch: 69 [69/100 (69%)] Train loss=0.279015 Test loss=0.421195 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29320839047431946
[5/23] Train loss=0.2801143527030945
[10/23] Train loss=0.30453142523765564
[15/23] Train loss=0.25155922770500183
[20/23] Train loss=0.2378828376531601
Test set avg_accuracy=83.41% avg_sensitivity=58.32%, avg_specificity=91.51% avg_auc=0.8578
Best model saved!! Metric=-6.97954664328638!!
Fold[7] Epoch: 70 [70/100 (70%)] Train loss=0.283157 Test loss=0.431843 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27907079458236694
[5/23] Train loss=0.2853126525878906
[10/23] Train loss=0.29834601283073425
[15/23] Train loss=0.24496755003929138
[20/23] Train loss=0.2353128343820572
Test set avg_accuracy=83.49% avg_sensitivity=55.20%, avg_specificity=92.63% avg_auc=0.8585
Fold[7] Epoch: 71 [71/100 (71%)] Train loss=0.278639 Test loss=0.435226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2813524305820465
[5/23] Train loss=0.27089792490005493
[10/23] Train loss=0.2992512583732605
[15/23] Train loss=0.245143324136734
[20/23] Train loss=0.23663094639778137
Test set avg_accuracy=83.22% avg_sensitivity=50.34%, avg_specificity=93.84% avg_auc=0.8543
Fold[7] Epoch: 72 [72/100 (72%)] Train loss=0.278421 Test loss=0.446492 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27975836396217346
[5/23] Train loss=0.2790810465812683
[10/23] Train loss=0.29874861240386963
[15/23] Train loss=0.24015459418296814
[20/23] Train loss=0.2313500940799713
Test set avg_accuracy=83.75% avg_sensitivity=49.83%, avg_specificity=94.71% avg_auc=0.8545
Fold[7] Epoch: 73 [73/100 (73%)] Train loss=0.277678 Test loss=0.449262 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2831512689590454
[5/23] Train loss=0.2803739011287689
[10/23] Train loss=0.29541197419166565
[15/23] Train loss=0.23712702095508575
[20/23] Train loss=0.22465132176876068
Test set avg_accuracy=83.64% avg_sensitivity=51.49%, avg_specificity=94.02% avg_auc=0.8567
Fold[7] Epoch: 74 [74/100 (74%)] Train loss=0.273659 Test loss=0.451776 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2711319029331207
[5/23] Train loss=0.2759236693382263
[10/23] Train loss=0.2930819094181061
[15/23] Train loss=0.24028731882572174
[20/23] Train loss=0.22427023947238922
Test set avg_accuracy=82.73% avg_sensitivity=48.21%, avg_specificity=93.88% avg_auc=0.8559
Fold[7] Epoch: 75 [75/100 (75%)] Train loss=0.273384 Test loss=0.454599 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2762490212917328
[5/23] Train loss=0.2652137279510498
[10/23] Train loss=0.28986677527427673
[15/23] Train loss=0.23205901682376862
[20/23] Train loss=0.22805041074752808
Test set avg_accuracy=83.23% avg_sensitivity=48.89%, avg_specificity=94.32% avg_auc=0.8567
Fold[7] Epoch: 76 [76/100 (76%)] Train loss=0.272637 Test loss=0.455259 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26136794686317444
[5/23] Train loss=0.26547878980636597
[10/23] Train loss=0.290753036737442
[15/23] Train loss=0.23221571743488312
[20/23] Train loss=0.22312583029270172
Test set avg_accuracy=84.21% avg_sensitivity=59.68%, avg_specificity=92.13% avg_auc=0.8585
Best model saved!! Metric=-4.131507344594528!!
Fold[7] Epoch: 77 [77/100 (77%)] Train loss=0.264910 Test loss=0.433836 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2814907133579254
[5/23] Train loss=0.2652618885040283
[10/23] Train loss=0.2796247601509094
[15/23] Train loss=0.223256915807724
[20/23] Train loss=0.22186508774757385
Test set avg_accuracy=83.76% avg_sensitivity=56.66%, avg_specificity=92.52% avg_auc=0.8574
Fold[7] Epoch: 78 [78/100 (78%)] Train loss=0.263463 Test loss=0.444603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27427375316619873
[5/23] Train loss=0.257289320230484
[10/23] Train loss=0.2724319398403168
[15/23] Train loss=0.23125112056732178
[20/23] Train loss=0.20855018496513367
Test set avg_accuracy=84.23% avg_sensitivity=58.32%, avg_specificity=92.60% avg_auc=0.8569
Fold[7] Epoch: 79 [79/100 (79%)] Train loss=0.259445 Test loss=0.444541 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2666914165019989
[5/23] Train loss=0.25029289722442627
[10/23] Train loss=0.2721345126628876
[15/23] Train loss=0.22152258455753326
[20/23] Train loss=0.21884876489639282
Test set avg_accuracy=83.94% avg_sensitivity=54.52%, avg_specificity=93.44% avg_auc=0.8587
Fold[7] Epoch: 80 [80/100 (80%)] Train loss=0.259105 Test loss=0.427310 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2654741704463959
[5/23] Train loss=0.26822206377983093
[10/23] Train loss=0.27840369939804077
[15/23] Train loss=0.2416878193616867
[20/23] Train loss=0.22292089462280273
Test set avg_accuracy=83.48% avg_sensitivity=53.07%, avg_specificity=93.30% avg_auc=0.8570
Fold[7] Epoch: 81 [81/100 (81%)] Train loss=0.265057 Test loss=0.431020 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26165205240249634
[5/23] Train loss=0.25832223892211914
[10/23] Train loss=0.299958199262619
[15/23] Train loss=0.22898516058921814
[20/23] Train loss=0.2211684286594391
Test set avg_accuracy=83.02% avg_sensitivity=45.86%, avg_specificity=95.02% avg_auc=0.8559
Fold[7] Epoch: 82 [82/100 (82%)] Train loss=0.266279 Test loss=0.450815 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27960002422332764
[5/23] Train loss=0.25604039430618286
[10/23] Train loss=0.2895067036151886
[15/23] Train loss=0.2227509468793869
[20/23] Train loss=0.21872186660766602
Test set avg_accuracy=83.01% avg_sensitivity=45.26%, avg_specificity=95.20% avg_auc=0.8530
Fold[7] Epoch: 83 [83/100 (83%)] Train loss=0.264999 Test loss=0.475250 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26613542437553406
[5/23] Train loss=0.26373186707496643
[10/23] Train loss=0.2685491740703583
[15/23] Train loss=0.22886449098587036
[20/23] Train loss=0.21805226802825928
Test set avg_accuracy=83.32% avg_sensitivity=52.01%, avg_specificity=93.44% avg_auc=0.8526
Fold[7] Epoch: 84 [84/100 (84%)] Train loss=0.259541 Test loss=0.481658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2594028413295746
[5/23] Train loss=0.2557264566421509
[10/23] Train loss=0.26305457949638367
[15/23] Train loss=0.22419312596321106
[20/23] Train loss=0.21447715163230896
Test set avg_accuracy=83.51% avg_sensitivity=55.89%, avg_specificity=92.43% avg_auc=0.8558
Fold[7] Epoch: 85 [85/100 (85%)] Train loss=0.250786 Test loss=0.453137 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25981375575065613
[5/23] Train loss=0.24691975116729736
[10/23] Train loss=0.26051267981529236
[15/23] Train loss=0.2215818166732788
[20/23] Train loss=0.20445314049720764
Test set avg_accuracy=83.55% avg_sensitivity=55.33%, avg_specificity=92.67% avg_auc=0.8577
Fold[7] Epoch: 86 [86/100 (86%)] Train loss=0.248845 Test loss=0.452960 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25124940276145935
[5/23] Train loss=0.24677589535713196
[10/23] Train loss=0.2656000852584839
[15/23] Train loss=0.21759866178035736
[20/23] Train loss=0.21269303560256958
Test set avg_accuracy=83.72% avg_sensitivity=58.15%, avg_specificity=91.98% avg_auc=0.8570
Fold[7] Epoch: 87 [87/100 (87%)] Train loss=0.252605 Test loss=0.433549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25676506757736206
[5/23] Train loss=0.24600327014923096
[10/23] Train loss=0.26167210936546326
[15/23] Train loss=0.2283865064382553
[20/23] Train loss=0.20545803010463715
Test set avg_accuracy=83.36% avg_sensitivity=50.60%, avg_specificity=93.95% avg_auc=0.8553
Fold[7] Epoch: 88 [88/100 (88%)] Train loss=0.254344 Test loss=0.451501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2496013343334198
[5/23] Train loss=0.26210740208625793
[10/23] Train loss=0.2634744644165039
[15/23] Train loss=0.2124926894903183
[20/23] Train loss=0.20639561116695404
Test set avg_accuracy=83.69% avg_sensitivity=51.15%, avg_specificity=94.20% avg_auc=0.8554
Fold[7] Epoch: 89 [89/100 (89%)] Train loss=0.251025 Test loss=0.451840 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23892250657081604
[5/23] Train loss=0.24718990921974182
[10/23] Train loss=0.2584773898124695
[15/23] Train loss=0.21764568984508514
[20/23] Train loss=0.20364253222942352
Test set avg_accuracy=83.28% avg_sensitivity=51.83%, avg_specificity=93.44% avg_auc=0.8540
Fold[7] Epoch: 90 [90/100 (90%)] Train loss=0.247600 Test loss=0.466789 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23611828684806824
[5/23] Train loss=0.24862758815288544
[10/23] Train loss=0.25291523337364197
[15/23] Train loss=0.2203424572944641
[20/23] Train loss=0.21329912543296814
Test set avg_accuracy=83.30% avg_sensitivity=53.75%, avg_specificity=92.85% avg_auc=0.8517
Fold[7] Epoch: 91 [91/100 (91%)] Train loss=0.242473 Test loss=0.487225 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2375173419713974
[5/23] Train loss=0.2539520859718323
[10/23] Train loss=0.24500001966953278
[15/23] Train loss=0.21273639798164368
[20/23] Train loss=0.1925627887248993
Test set avg_accuracy=83.11% avg_sensitivity=56.10%, avg_specificity=91.84% avg_auc=0.8590
Fold[7] Epoch: 92 [92/100 (92%)] Train loss=0.241871 Test loss=0.463643 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24353018403053284
[5/23] Train loss=0.23231306672096252
[10/23] Train loss=0.2499236911535263
[15/23] Train loss=0.19954539835453033
[20/23] Train loss=0.20120137929916382
Test set avg_accuracy=83.36% avg_sensitivity=54.74%, avg_specificity=92.61% avg_auc=0.8510
Fold[7] Epoch: 93 [93/100 (93%)] Train loss=0.238056 Test loss=0.470719 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2336832731962204
[5/23] Train loss=0.22670304775238037
[10/23] Train loss=0.23956570029258728
[15/23] Train loss=0.20209209620952606
[20/23] Train loss=0.2025213986635208
Test set avg_accuracy=83.53% avg_sensitivity=54.48%, avg_specificity=92.92% avg_auc=0.8527
Fold[7] Epoch: 94 [94/100 (94%)] Train loss=0.234047 Test loss=0.468675 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24995610117912292
[5/23] Train loss=0.23354777693748474
[10/23] Train loss=0.24739965796470642
[15/23] Train loss=0.2100456953048706
[20/23] Train loss=0.19559115171432495
Test set avg_accuracy=82.85% avg_sensitivity=47.48%, avg_specificity=94.28% avg_auc=0.8465
Fold[7] Epoch: 95 [95/100 (95%)] Train loss=0.235025 Test loss=0.466574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2338491529226303
[5/23] Train loss=0.23498819768428802
[10/23] Train loss=0.23890186846256256
[15/23] Train loss=0.20205949246883392
[20/23] Train loss=0.17983423173427582
Test set avg_accuracy=82.61% avg_sensitivity=47.74%, avg_specificity=93.88% avg_auc=0.8472
Fold[7] Epoch: 96 [96/100 (96%)] Train loss=0.229408 Test loss=0.485842 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23268885910511017
[5/23] Train loss=0.23137125372886658
[10/23] Train loss=0.2422078251838684
[15/23] Train loss=0.1992693841457367
[20/23] Train loss=0.18144656717777252
Test set avg_accuracy=82.73% avg_sensitivity=50.13%, avg_specificity=93.26% avg_auc=0.8512
Fold[7] Epoch: 97 [97/100 (97%)] Train loss=0.229143 Test loss=0.473502 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22407470643520355
[5/23] Train loss=0.22740669548511505
[10/23] Train loss=0.23122215270996094
[15/23] Train loss=0.19627311825752258
[20/23] Train loss=0.19443847239017487
Test set avg_accuracy=82.67% avg_sensitivity=50.73%, avg_specificity=92.99% avg_auc=0.8487
Fold[7] Epoch: 98 [98/100 (98%)] Train loss=0.228037 Test loss=0.481782 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23347888886928558
[5/23] Train loss=0.22054162621498108
[10/23] Train loss=0.22581087052822113
[15/23] Train loss=0.19668516516685486
[20/23] Train loss=0.18430592119693756
Test set avg_accuracy=83.20% avg_sensitivity=54.39%, avg_specificity=92.50% avg_auc=0.8512
Fold[7] Epoch: 99 [99/100 (99%)] Train loss=0.224821 Test loss=0.480821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2065013349056244
[5/23] Train loss=0.22766649723052979
[10/23] Train loss=0.2259410321712494
[15/23] Train loss=0.19045117497444153
[20/23] Train loss=0.1766703575849533
Test set avg_accuracy=82.76% avg_sensitivity=53.20%, avg_specificity=92.31% avg_auc=0.8508
Fold[7] Epoch: 100 [100/100 (100%)] Train loss=0.222461 Test loss=0.487124 Current lr=[3.9999999999999996e-05]

Fold[7] Best Result: acc=84.20833333333333 sen=59.684300341296925, spe=92.13065049614112, auc=0.8584520848463411!
[0/23] Train loss=0.712537944316864
[5/23] Train loss=0.6863129734992981
[10/23] Train loss=0.5550343990325928
[15/23] Train loss=0.5706440806388855
[20/23] Train loss=0.5315546989440918
Test set avg_accuracy=76.87% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5459
Best model saved!! Metric=-94.54193735254927!!
Fold[8] Epoch: 1 [1/100 (1%)] Train loss=0.587557 Test loss=0.581940 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5662225484848022
[5/23] Train loss=0.5927927494049072
[10/23] Train loss=0.5067248344421387
[15/23] Train loss=0.5327615141868591
[20/23] Train loss=0.49876174330711365
Test set avg_accuracy=76.73% avg_sensitivity=0.99%, avg_specificity=99.52% avg_auc=0.6085
Best model saved!! Metric=-87.90814604924864!!
Fold[8] Epoch: 2 [2/100 (2%)] Train loss=0.545767 Test loss=0.546409 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5429593324661255
[5/23] Train loss=0.5412217974662781
[10/23] Train loss=0.4781814217567444
[15/23] Train loss=0.4789593517780304
[20/23] Train loss=0.44351041316986084
Test set avg_accuracy=77.37% avg_sensitivity=6.60%, avg_specificity=98.67% avg_auc=0.6786
Best model saved!! Metric=-75.49581757749158!!
Fold[8] Epoch: 3 [3/100 (3%)] Train loss=0.510396 Test loss=0.559368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5144699215888977
[5/23] Train loss=0.49277210235595703
[10/23] Train loss=0.4771348237991333
[15/23] Train loss=0.43695446848869324
[20/23] Train loss=0.41970857977867126
Test set avg_accuracy=78.06% avg_sensitivity=11.90%, avg_specificity=97.97% avg_auc=0.7116
Best model saved!! Metric=-66.90226645248458!!
Fold[8] Epoch: 4 [4/100 (4%)] Train loss=0.482821 Test loss=0.577115 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48624083399772644
[5/23] Train loss=0.46560779213905334
[10/23] Train loss=0.4850357174873352
[15/23] Train loss=0.4330623745918274
[20/23] Train loss=0.4020490348339081
Test set avg_accuracy=78.70% avg_sensitivity=15.87%, avg_specificity=97.61% avg_auc=0.7340
Best model saved!! Metric=-60.41631410414794!!
Fold[8] Epoch: 5 [5/100 (5%)] Train loss=0.467984 Test loss=0.567886 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.46173161268234253
[5/23] Train loss=0.4517022967338562
[10/23] Train loss=0.4811754822731018
[15/23] Train loss=0.4354138970375061
[20/23] Train loss=0.38525012135505676
Test set avg_accuracy=79.28% avg_sensitivity=19.99%, avg_specificity=97.12% avg_auc=0.7548
Best model saved!! Metric=-54.1339642328796!!
Fold[8] Epoch: 6 [6/100 (6%)] Train loss=0.457176 Test loss=0.554993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43875283002853394
[5/23] Train loss=0.4442392885684967
[10/23] Train loss=0.46948015689849854
[15/23] Train loss=0.4230388104915619
[20/23] Train loss=0.3839767575263977
Test set avg_accuracy=79.85% avg_sensitivity=24.26%, avg_specificity=96.58% avg_auc=0.7646
Best model saved!! Metric=-48.84837234728549!!
Fold[8] Epoch: 7 [7/100 (7%)] Train loss=0.446135 Test loss=0.533431 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4320073127746582
[5/23] Train loss=0.43315380811691284
[10/23] Train loss=0.47378772497177124
[15/23] Train loss=0.41502565145492554
[20/23] Train loss=0.38186267018318176
Test set avg_accuracy=79.98% avg_sensitivity=23.51%, avg_specificity=96.97% avg_auc=0.7673
Best model saved!! Metric=-48.81630962144272!!
Fold[8] Epoch: 8 [8/100 (8%)] Train loss=0.443678 Test loss=0.550837 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4265778958797455
[5/23] Train loss=0.4265393316745758
[10/23] Train loss=0.48016661405563354
[15/23] Train loss=0.42666351795196533
[20/23] Train loss=0.37501344084739685
Test set avg_accuracy=80.45% avg_sensitivity=25.40%, avg_specificity=97.01% avg_auc=0.7884
Best model saved!! Metric=-44.29974342061485!!
Fold[8] Epoch: 9 [9/100 (9%)] Train loss=0.438883 Test loss=0.533409 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42691570520401
[5/23] Train loss=0.42516839504241943
[10/23] Train loss=0.4671580195426941
[15/23] Train loss=0.4178435504436493
[20/23] Train loss=0.38429731130599976
Test set avg_accuracy=80.78% avg_sensitivity=28.08%, avg_specificity=96.64% avg_auc=0.8051
Best model saved!! Metric=-39.997200800015506!!
Fold[8] Epoch: 10 [10/100 (10%)] Train loss=0.431161 Test loss=0.485222 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4268040657043457
[5/23] Train loss=0.4219839572906494
[10/23] Train loss=0.46081703901290894
[15/23] Train loss=0.4071579873561859
[20/23] Train loss=0.37419062852859497
Test set avg_accuracy=81.11% avg_sensitivity=29.96%, avg_specificity=96.51% avg_auc=0.8102
Best model saved!! Metric=-37.40420171469863!!
Fold[8] Epoch: 11 [11/100 (11%)] Train loss=0.425710 Test loss=0.493707 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4175932705402374
[5/23] Train loss=0.4133932888507843
[10/23] Train loss=0.4670512080192566
[15/23] Train loss=0.40258949995040894
[20/23] Train loss=0.36321699619293213
Test set avg_accuracy=80.98% avg_sensitivity=29.51%, avg_specificity=96.46% avg_auc=0.8153
Fold[8] Epoch: 12 [12/100 (12%)] Train loss=0.421659 Test loss=0.486632 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4108501672744751
[5/23] Train loss=0.41381072998046875
[10/23] Train loss=0.4621172547340393
[15/23] Train loss=0.4066241383552551
[20/23] Train loss=0.36789193749427795
Test set avg_accuracy=81.18% avg_sensitivity=31.05%, avg_specificity=96.27% avg_auc=0.8180
Best model saved!! Metric=-35.69638796586986!!
Fold[8] Epoch: 13 [13/100 (13%)] Train loss=0.417813 Test loss=0.469064 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41339242458343506
[5/23] Train loss=0.4120967984199524
[10/23] Train loss=0.45194312930107117
[15/23] Train loss=0.3977603018283844
[20/23] Train loss=0.3573521375656128
Test set avg_accuracy=81.70% avg_sensitivity=34.33%, avg_specificity=95.95% avg_auc=0.8250
Best model saved!! Metric=-31.518302212468043!!
Fold[8] Epoch: 14 [14/100 (14%)] Train loss=0.414073 Test loss=0.445947 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4132295846939087
[5/23] Train loss=0.4023421108722687
[10/23] Train loss=0.45328250527381897
[15/23] Train loss=0.3890083432197571
[20/23] Train loss=0.35640692710876465
Test set avg_accuracy=81.92% avg_sensitivity=34.77%, avg_specificity=96.10% avg_auc=0.8284
Best model saved!! Metric=-30.37045546219312!!
Fold[8] Epoch: 15 [15/100 (15%)] Train loss=0.408143 Test loss=0.445007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41478490829467773
[5/23] Train loss=0.400429368019104
[10/23] Train loss=0.45208221673965454
[15/23] Train loss=0.3813559412956238
[20/23] Train loss=0.34921008348464966
Test set avg_accuracy=82.27% avg_sensitivity=37.20%, avg_specificity=95.84% avg_auc=0.8347
Best model saved!! Metric=-27.220956766167156!!
Fold[8] Epoch: 16 [16/100 (16%)] Train loss=0.405177 Test loss=0.433744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40279802680015564
[5/23] Train loss=0.40027400851249695
[10/23] Train loss=0.446965754032135
[15/23] Train loss=0.3795768916606903
[20/23] Train loss=0.3373478353023529
Test set avg_accuracy=82.52% avg_sensitivity=38.00%, avg_specificity=95.92% avg_auc=0.8429
Best model saved!! Metric=-25.268275038610074!!
Fold[8] Epoch: 17 [17/100 (17%)] Train loss=0.404000 Test loss=0.421276 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3978431820869446
[5/23] Train loss=0.38972657918930054
[10/23] Train loss=0.4457576870918274
[15/23] Train loss=0.37042030692100525
[20/23] Train loss=0.3476404547691345
Test set avg_accuracy=82.83% avg_sensitivity=42.16%, avg_specificity=95.07% avg_auc=0.8501
Best model saved!! Metric=-20.91529842455714!!
Fold[8] Epoch: 18 [18/100 (18%)] Train loss=0.399115 Test loss=0.401498 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4011242985725403
[5/23] Train loss=0.39372679591178894
[10/23] Train loss=0.4476006031036377
[15/23] Train loss=0.3713500499725342
[20/23] Train loss=0.34203094244003296
Test set avg_accuracy=82.59% avg_sensitivity=41.07%, avg_specificity=95.09% avg_auc=0.8488
Fold[8] Epoch: 19 [19/100 (19%)] Train loss=0.396290 Test loss=0.408079 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38957393169403076
[5/23] Train loss=0.3960739076137543
[10/23] Train loss=0.44576495885849
[15/23] Train loss=0.3636682629585266
[20/23] Train loss=0.33962976932525635
Test set avg_accuracy=82.47% avg_sensitivity=39.43%, avg_specificity=95.42% avg_auc=0.8494
Fold[8] Epoch: 20 [20/100 (20%)] Train loss=0.394963 Test loss=0.415171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3892752528190613
[5/23] Train loss=0.3882545232772827
[10/23] Train loss=0.4432651102542877
[15/23] Train loss=0.36611494421958923
[20/23] Train loss=0.33196255564689636
Test set avg_accuracy=82.31% avg_sensitivity=37.85%, avg_specificity=95.69% avg_auc=0.8461
Fold[8] Epoch: 21 [21/100 (21%)] Train loss=0.393986 Test loss=0.431758 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3845890462398529
[5/23] Train loss=0.3838255703449249
[10/23] Train loss=0.4385896921157837
[15/23] Train loss=0.3653976023197174
[20/23] Train loss=0.33265233039855957
Test set avg_accuracy=83.03% avg_sensitivity=43.60%, avg_specificity=94.89% avg_auc=0.8537
Best model saved!! Metric=-19.103867945141907!!
Fold[8] Epoch: 22 [22/100 (22%)] Train loss=0.390143 Test loss=0.406447 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3885008692741394
[5/23] Train loss=0.38569390773773193
[10/23] Train loss=0.43371886014938354
[15/23] Train loss=0.36830979585647583
[20/23] Train loss=0.3284859359264374
Test set avg_accuracy=83.08% avg_sensitivity=43.60%, avg_specificity=94.95% avg_auc=0.8531
Best model saved!! Metric=-19.054919387528155!!
Fold[8] Epoch: 23 [23/100 (23%)] Train loss=0.389267 Test loss=0.416580 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38057348132133484
[5/23] Train loss=0.37712639570236206
[10/23] Train loss=0.4294126033782959
[15/23] Train loss=0.3562661111354828
[20/23] Train loss=0.3294740915298462
Test set avg_accuracy=83.16% avg_sensitivity=45.73%, avg_specificity=94.42% avg_auc=0.8585
Best model saved!! Metric=-16.843638613053724!!
Fold[8] Epoch: 24 [24/100 (24%)] Train loss=0.383218 Test loss=0.402444 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3818826973438263
[5/23] Train loss=0.3767679035663605
[10/23] Train loss=0.4303644597530365
[15/23] Train loss=0.34638267755508423
[20/23] Train loss=0.32145804166793823
Test set avg_accuracy=82.99% avg_sensitivity=45.83%, avg_specificity=94.18% avg_auc=0.8584
Fold[8] Epoch: 25 [25/100 (25%)] Train loss=0.380402 Test loss=0.399458 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38044068217277527
[5/23] Train loss=0.3717566728591919
[10/23] Train loss=0.43108227849006653
[15/23] Train loss=0.3436237573623657
[20/23] Train loss=0.3190707564353943
Test set avg_accuracy=83.20% avg_sensitivity=46.78%, avg_specificity=94.16% avg_auc=0.8570
Best model saved!! Metric=-16.162973375385853!!
Fold[8] Epoch: 26 [26/100 (26%)] Train loss=0.376464 Test loss=0.401751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3820192515850067
[5/23] Train loss=0.37412336468696594
[10/23] Train loss=0.4247296154499054
[15/23] Train loss=0.3441036343574524
[20/23] Train loss=0.31268978118896484
Test set avg_accuracy=82.64% avg_sensitivity=44.79%, avg_specificity=94.03% avg_auc=0.8570
Fold[8] Epoch: 27 [27/100 (27%)] Train loss=0.374718 Test loss=0.408829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3677826225757599
[5/23] Train loss=0.36955371499061584
[10/23] Train loss=0.4288252592086792
[15/23] Train loss=0.34545832872390747
[20/23] Train loss=0.31299132108688354
Test set avg_accuracy=82.77% avg_sensitivity=42.11%, avg_specificity=95.00% avg_auc=0.8538
Fold[8] Epoch: 28 [28/100 (28%)] Train loss=0.374067 Test loss=0.420027 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3633313775062561
[5/23] Train loss=0.3749147951602936
[10/23] Train loss=0.4275710880756378
[15/23] Train loss=0.36056068539619446
[20/23] Train loss=0.3224688768386841
Test set avg_accuracy=81.88% avg_sensitivity=36.36%, avg_specificity=95.58% avg_auc=0.8454
Fold[8] Epoch: 29 [29/100 (29%)] Train loss=0.378133 Test loss=0.455329 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3894113600254059
[5/23] Train loss=0.37814444303512573
[10/23] Train loss=0.4064795970916748
[15/23] Train loss=0.3457261025905609
[20/23] Train loss=0.3089057505130768
Test set avg_accuracy=83.16% avg_sensitivity=51.59%, avg_specificity=92.66% avg_auc=0.8480
Best model saved!! Metric=-13.798593095717546!!
Fold[8] Epoch: 30 [30/100 (30%)] Train loss=0.382796 Test loss=0.394040 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.377911239862442
[5/23] Train loss=0.3752691149711609
[10/23] Train loss=0.4226454496383667
[15/23] Train loss=0.34934985637664795
[20/23] Train loss=0.3122270107269287
Test set avg_accuracy=83.63% avg_sensitivity=50.00%, avg_specificity=93.75% avg_auc=0.8638
Best model saved!! Metric=-12.244622591475517!!
Fold[8] Epoch: 31 [31/100 (31%)] Train loss=0.377627 Test loss=0.386253 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37445130944252014
[5/23] Train loss=0.3618500828742981
[10/23] Train loss=0.41938668489456177
[15/23] Train loss=0.33906272053718567
[20/23] Train loss=0.3171672821044922
Test set avg_accuracy=83.60% avg_sensitivity=51.19%, avg_specificity=93.36% avg_auc=0.8626
Best model saved!! Metric=-11.588958043591845!!
Fold[8] Epoch: 32 [32/100 (32%)] Train loss=0.370746 Test loss=0.384062 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37342625856399536
[5/23] Train loss=0.3611990213394165
[10/23] Train loss=0.42148464918136597
[15/23] Train loss=0.3372702896595001
[20/23] Train loss=0.308389812707901
Test set avg_accuracy=83.19% avg_sensitivity=48.76%, avg_specificity=93.55% avg_auc=0.8586
Fold[8] Epoch: 33 [33/100 (33%)] Train loss=0.368376 Test loss=0.392536 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3648448586463928
[5/23] Train loss=0.35407090187072754
[10/23] Train loss=0.41090553998947144
[15/23] Train loss=0.33325251936912537
[20/23] Train loss=0.2991396188735962
Test set avg_accuracy=83.28% avg_sensitivity=49.11%, avg_specificity=93.57% avg_auc=0.8600
Fold[8] Epoch: 34 [34/100 (34%)] Train loss=0.362685 Test loss=0.397038 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35866180062294006
[5/23] Train loss=0.35662147402763367
[10/23] Train loss=0.40438374876976013
[15/23] Train loss=0.33221298456192017
[20/23] Train loss=0.30022987723350525
Test set avg_accuracy=83.56% avg_sensitivity=50.99%, avg_specificity=93.36% avg_auc=0.8637
Fold[8] Epoch: 35 [35/100 (35%)] Train loss=0.359815 Test loss=0.394206 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3646375238895416
[5/23] Train loss=0.35899314284324646
[10/23] Train loss=0.3991147577762604
[15/23] Train loss=0.3305078148841858
[20/23] Train loss=0.30724602937698364
Test set avg_accuracy=83.32% avg_sensitivity=51.19%, avg_specificity=92.98% avg_auc=0.8635
Fold[8] Epoch: 36 [36/100 (36%)] Train loss=0.359915 Test loss=0.397360 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35882315039634705
[5/23] Train loss=0.3500806391239166
[10/23] Train loss=0.39536887407302856
[15/23] Train loss=0.3189779222011566
[20/23] Train loss=0.294651061296463
Test set avg_accuracy=83.30% avg_sensitivity=54.07%, avg_specificity=92.10% avg_auc=0.8652
Best model saved!! Metric=-10.004121087738813!!
Fold[8] Epoch: 37 [37/100 (37%)] Train loss=0.356093 Test loss=0.388281 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3477391004562378
[5/23] Train loss=0.34123197197914124
[10/23] Train loss=0.3965594172477722
[15/23] Train loss=0.322978675365448
[20/23] Train loss=0.2975524067878723
Test set avg_accuracy=83.65% avg_sensitivity=53.42%, avg_specificity=92.75% avg_auc=0.8669
Best model saved!! Metric=-9.492965921077392!!
Fold[8] Epoch: 38 [38/100 (38%)] Train loss=0.352378 Test loss=0.384714 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34952694177627563
[5/23] Train loss=0.33836570382118225
[10/23] Train loss=0.39442262053489685
[15/23] Train loss=0.314120888710022
[20/23] Train loss=0.2949568033218384
Test set avg_accuracy=83.37% avg_sensitivity=51.19%, avg_specificity=93.06% avg_auc=0.8653
Fold[8] Epoch: 39 [39/100 (39%)] Train loss=0.352180 Test loss=0.392640 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3499889671802521
[5/23] Train loss=0.33660122752189636
[10/23] Train loss=0.39252254366874695
[15/23] Train loss=0.3216388523578644
[20/23] Train loss=0.2847917377948761
Test set avg_accuracy=83.28% avg_sensitivity=49.16%, avg_specificity=93.55% avg_auc=0.8647
Fold[8] Epoch: 40 [40/100 (40%)] Train loss=0.349107 Test loss=0.399115 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3454332649707794
[5/23] Train loss=0.33714237809181213
[10/23] Train loss=0.38510552048683167
[15/23] Train loss=0.31522583961486816
[20/23] Train loss=0.2877925932407379
Test set avg_accuracy=82.90% avg_sensitivity=48.36%, avg_specificity=93.30% avg_auc=0.8637
Fold[8] Epoch: 41 [41/100 (41%)] Train loss=0.347475 Test loss=0.400157 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3468106687068939
[5/23] Train loss=0.34502044320106506
[10/23] Train loss=0.3895624279975891
[15/23] Train loss=0.31244152784347534
[20/23] Train loss=0.28147539496421814
Test set avg_accuracy=83.40% avg_sensitivity=50.50%, avg_specificity=93.30% avg_auc=0.8628
Fold[8] Epoch: 42 [42/100 (42%)] Train loss=0.344125 Test loss=0.404387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3408386707305908
[5/23] Train loss=0.3357459604740143
[10/23] Train loss=0.3820303678512573
[15/23] Train loss=0.31121325492858887
[20/23] Train loss=0.2844187319278717
Test set avg_accuracy=83.53% avg_sensitivity=52.53%, avg_specificity=92.86% avg_auc=0.8631
Fold[8] Epoch: 43 [43/100 (43%)] Train loss=0.342866 Test loss=0.393893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3467866778373718
[5/23] Train loss=0.33472639322280884
[10/23] Train loss=0.3759566843509674
[15/23] Train loss=0.3140184283256531
[20/23] Train loss=0.2894006073474884
Test set avg_accuracy=83.43% avg_sensitivity=50.45%, avg_specificity=93.36% avg_auc=0.8600
Fold[8] Epoch: 44 [44/100 (44%)] Train loss=0.341587 Test loss=0.408268 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34361544251441956
[5/23] Train loss=0.3329163193702698
[10/23] Train loss=0.36987408995628357
[15/23] Train loss=0.29993757605552673
[20/23] Train loss=0.2806267738342285
Test set avg_accuracy=83.84% avg_sensitivity=56.25%, avg_specificity=92.15% avg_auc=0.8662
Best model saved!! Metric=-7.140217381871201!!
Fold[8] Epoch: 45 [45/100 (45%)] Train loss=0.341961 Test loss=0.390738 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3374689817428589
[5/23] Train loss=0.32761308550834656
[10/23] Train loss=0.3791520595550537
[15/23] Train loss=0.3002297878265381
[20/23] Train loss=0.2797352969646454
Test set avg_accuracy=83.49% avg_sensitivity=52.43%, avg_specificity=92.83% avg_auc=0.8641
Fold[8] Epoch: 46 [46/100 (46%)] Train loss=0.339075 Test loss=0.405981 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3261035978794098
[5/23] Train loss=0.3224889934062958
[10/23] Train loss=0.3680982291698456
[15/23] Train loss=0.303079754114151
[20/23] Train loss=0.27580466866493225
Test set avg_accuracy=83.34% avg_sensitivity=50.69%, avg_specificity=93.16% avg_auc=0.8633
Fold[8] Epoch: 47 [47/100 (47%)] Train loss=0.335037 Test loss=0.407126 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3329930901527405
[5/23] Train loss=0.32469895482063293
[10/23] Train loss=0.3639662265777588
[15/23] Train loss=0.31352123618125916
[20/23] Train loss=0.27836892008781433
Test set avg_accuracy=82.73% avg_sensitivity=46.83%, avg_specificity=93.54% avg_auc=0.8617
Fold[8] Epoch: 48 [48/100 (48%)] Train loss=0.335867 Test loss=0.407172 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3382696211338043
[5/23] Train loss=0.33072134852409363
[10/23] Train loss=0.3639777898788452
[15/23] Train loss=0.2993943691253662
[20/23] Train loss=0.27058324217796326
Test set avg_accuracy=83.58% avg_sensitivity=55.95%, avg_specificity=91.89% avg_auc=0.8653
Fold[8] Epoch: 49 [49/100 (49%)] Train loss=0.334535 Test loss=0.394026 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34222057461738586
[5/23] Train loss=0.3145754933357239
[10/23] Train loss=0.3630094826221466
[15/23] Train loss=0.2968461811542511
[20/23] Train loss=0.2769889831542969
Test set avg_accuracy=83.49% avg_sensitivity=53.67%, avg_specificity=92.46% avg_auc=0.8606
Fold[8] Epoch: 50 [50/100 (50%)] Train loss=0.329311 Test loss=0.406992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33579757809638977
[5/23] Train loss=0.3148236870765686
[10/23] Train loss=0.3575747013092041
[15/23] Train loss=0.2863844335079193
[20/23] Train loss=0.27036252617836
Test set avg_accuracy=83.71% avg_sensitivity=54.46%, avg_specificity=92.51% avg_auc=0.8640
Fold[8] Epoch: 51 [51/100 (51%)] Train loss=0.324829 Test loss=0.404077 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3346649408340454
[5/23] Train loss=0.307062029838562
[10/23] Train loss=0.3515159487724304
[15/23] Train loss=0.2815192937850952
[20/23] Train loss=0.2699403166770935
Test set avg_accuracy=83.52% avg_sensitivity=54.37%, avg_specificity=92.30% avg_auc=0.8600
Fold[8] Epoch: 52 [52/100 (52%)] Train loss=0.320717 Test loss=0.402804 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32411086559295654
[5/23] Train loss=0.30796560645103455
[10/23] Train loss=0.35074540972709656
[15/23] Train loss=0.2800390422344208
[20/23] Train loss=0.2724425494670868
Test set avg_accuracy=83.47% avg_sensitivity=53.08%, avg_specificity=92.61% avg_auc=0.8643
Fold[8] Epoch: 53 [53/100 (53%)] Train loss=0.319904 Test loss=0.405706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.318168967962265
[5/23] Train loss=0.3085399568080902
[10/23] Train loss=0.35281938314437866
[15/23] Train loss=0.2804906368255615
[20/23] Train loss=0.2621647119522095
Test set avg_accuracy=82.95% avg_sensitivity=50.40%, avg_specificity=92.75% avg_auc=0.8594
Fold[8] Epoch: 54 [54/100 (54%)] Train loss=0.317365 Test loss=0.410741 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3203575313091278
[5/23] Train loss=0.3079746961593628
[10/23] Train loss=0.34317564964294434
[15/23] Train loss=0.2683231830596924
[20/23] Train loss=0.2610253095626831
Test set avg_accuracy=83.35% avg_sensitivity=53.22%, avg_specificity=92.42% avg_auc=0.8640
Fold[8] Epoch: 55 [55/100 (55%)] Train loss=0.316949 Test loss=0.402411 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3184029459953308
[5/23] Train loss=0.2975580096244812
[10/23] Train loss=0.35203370451927185
[15/23] Train loss=0.27302539348602295
[20/23] Train loss=0.2601000964641571
Test set avg_accuracy=83.40% avg_sensitivity=54.41%, avg_specificity=92.12% avg_auc=0.8644
Fold[8] Epoch: 56 [56/100 (56%)] Train loss=0.312533 Test loss=0.402212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3185669779777527
[5/23] Train loss=0.30261141061782837
[10/23] Train loss=0.35454192757606506
[15/23] Train loss=0.28012627363204956
[20/23] Train loss=0.258765310049057
Test set avg_accuracy=82.95% avg_sensitivity=50.00%, avg_specificity=92.86% avg_auc=0.8628
Fold[8] Epoch: 57 [57/100 (57%)] Train loss=0.316547 Test loss=0.417863 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3135126233100891
[5/23] Train loss=0.29968175292015076
[10/23] Train loss=0.34626030921936035
[15/23] Train loss=0.2754189372062683
[20/23] Train loss=0.2597484290599823
Test set avg_accuracy=82.85% avg_sensitivity=49.36%, avg_specificity=92.92% avg_auc=0.8567
Fold[8] Epoch: 58 [58/100 (58%)] Train loss=0.314664 Test loss=0.407316 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3072681725025177
[5/23] Train loss=0.3101145029067993
[10/23] Train loss=0.3291451930999756
[15/23] Train loss=0.2703448534011841
[20/23] Train loss=0.2589707672595978
Test set avg_accuracy=83.20% avg_sensitivity=54.56%, avg_specificity=91.82% avg_auc=0.8589
Fold[8] Epoch: 59 [59/100 (59%)] Train loss=0.308928 Test loss=0.407383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3056379556655884
[5/23] Train loss=0.30526405572891235
[10/23] Train loss=0.3300783932209015
[15/23] Train loss=0.2660095989704132
[20/23] Train loss=0.25460416078567505
Test set avg_accuracy=83.45% avg_sensitivity=54.12%, avg_specificity=92.28% avg_auc=0.8624
Fold[8] Epoch: 60 [60/100 (60%)] Train loss=0.305465 Test loss=0.418482 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3137238025665283
[5/23] Train loss=0.2883828580379486
[10/23] Train loss=0.31935593485832214
[15/23] Train loss=0.2598346471786499
[20/23] Train loss=0.25880298018455505
Test set avg_accuracy=83.49% avg_sensitivity=57.74%, avg_specificity=91.24% avg_auc=0.8570
Fold[8] Epoch: 61 [61/100 (61%)] Train loss=0.301885 Test loss=0.409046 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3198924958705902
[5/23] Train loss=0.2863343060016632
[10/23] Train loss=0.3177308738231659
[15/23] Train loss=0.2525444030761719
[20/23] Train loss=0.24733619391918182
Test set avg_accuracy=83.26% avg_sensitivity=52.88%, avg_specificity=92.40% avg_auc=0.8595
Fold[8] Epoch: 62 [62/100 (62%)] Train loss=0.300606 Test loss=0.419822 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30500271916389465
[5/23] Train loss=0.2785044014453888
[10/23] Train loss=0.3157767355442047
[15/23] Train loss=0.25385168194770813
[20/23] Train loss=0.24314120411872864
Test set avg_accuracy=83.25% avg_sensitivity=54.51%, avg_specificity=91.89% avg_auc=0.8607
Fold[8] Epoch: 63 [63/100 (63%)] Train loss=0.296266 Test loss=0.412142 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3112352192401886
[5/23] Train loss=0.2809086740016937
[10/23] Train loss=0.3214896619319916
[15/23] Train loss=0.2524637281894684
[20/23] Train loss=0.2473575919866562
Test set avg_accuracy=82.71% avg_sensitivity=50.30%, avg_specificity=92.46% avg_auc=0.8564
Fold[8] Epoch: 64 [64/100 (64%)] Train loss=0.300125 Test loss=0.428117 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29196271300315857
[5/23] Train loss=0.2701636254787445
[10/23] Train loss=0.3196045756340027
[15/23] Train loss=0.2516622543334961
[20/23] Train loss=0.24757085740566254
Test set avg_accuracy=82.79% avg_sensitivity=50.20%, avg_specificity=92.60% avg_auc=0.8577
Fold[8] Epoch: 65 [65/100 (65%)] Train loss=0.293742 Test loss=0.421224 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30331581830978394
[5/23] Train loss=0.2782343029975891
[10/23] Train loss=0.31256622076034546
[15/23] Train loss=0.25110360980033875
[20/23] Train loss=0.24619390070438385
Test set avg_accuracy=82.39% avg_sensitivity=46.78%, avg_specificity=93.10% avg_auc=0.8499
Fold[8] Epoch: 66 [66/100 (66%)] Train loss=0.295457 Test loss=0.432238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29461973905563354
[5/23] Train loss=0.28229042887687683
[10/23] Train loss=0.3098839819431305
[15/23] Train loss=0.2568231523036957
[20/23] Train loss=0.23897366225719452
Test set avg_accuracy=82.20% avg_sensitivity=45.54%, avg_specificity=93.24% avg_auc=0.8484
Fold[8] Epoch: 67 [67/100 (67%)] Train loss=0.297370 Test loss=0.430907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29231563210487366
[5/23] Train loss=0.2918859124183655
[10/23] Train loss=0.3142807185649872
[15/23] Train loss=0.26736506819725037
[20/23] Train loss=0.24310018122196198
Test set avg_accuracy=82.93% avg_sensitivity=50.64%, avg_specificity=92.64% avg_auc=0.8520
Fold[8] Epoch: 68 [68/100 (68%)] Train loss=0.294113 Test loss=0.426969 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29135191440582275
[5/23] Train loss=0.2743440866470337
[10/23] Train loss=0.2990809977054596
[15/23] Train loss=0.23941658437252045
[20/23] Train loss=0.24421744048595428
Test set avg_accuracy=83.48% avg_sensitivity=56.89%, avg_specificity=91.48% avg_auc=0.8538
Fold[8] Epoch: 69 [69/100 (69%)] Train loss=0.288789 Test loss=0.427791 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3024376332759857
[5/23] Train loss=0.2721113860607147
[10/23] Train loss=0.2973940968513489
[15/23] Train loss=0.24044354259967804
[20/23] Train loss=0.2349611222743988
Test set avg_accuracy=83.06% avg_sensitivity=55.56%, avg_specificity=91.34% avg_auc=0.8513
Fold[8] Epoch: 70 [70/100 (70%)] Train loss=0.285932 Test loss=0.425481 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2893902063369751
[5/23] Train loss=0.2678658366203308
[10/23] Train loss=0.3011869490146637
[15/23] Train loss=0.23564068973064423
[20/23] Train loss=0.23236121237277985
Test set avg_accuracy=83.27% avg_sensitivity=52.98%, avg_specificity=92.39% avg_auc=0.8510
Fold[8] Epoch: 71 [71/100 (71%)] Train loss=0.282928 Test loss=0.432052 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2847551107406616
[5/23] Train loss=0.27052050828933716
[10/23] Train loss=0.2940604090690613
[15/23] Train loss=0.22687551379203796
[20/23] Train loss=0.233851820230484
Test set avg_accuracy=83.45% avg_sensitivity=54.81%, avg_specificity=92.07% avg_auc=0.8569
Fold[8] Epoch: 72 [72/100 (72%)] Train loss=0.283204 Test loss=0.428591 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28849655389785767
[5/23] Train loss=0.2591172456741333
[10/23] Train loss=0.30097439885139465
[15/23] Train loss=0.23089368641376495
[20/23] Train loss=0.23474714159965515
Test set avg_accuracy=83.12% avg_sensitivity=52.43%, avg_specificity=92.36% avg_auc=0.8523
Fold[8] Epoch: 73 [73/100 (73%)] Train loss=0.279265 Test loss=0.422472 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2841269373893738
[5/23] Train loss=0.26204967498779297
[10/23] Train loss=0.29449254274368286
[15/23] Train loss=0.2370542585849762
[20/23] Train loss=0.22776401042938232
Test set avg_accuracy=83.10% avg_sensitivity=47.72%, avg_specificity=93.75% avg_auc=0.8560
Fold[8] Epoch: 74 [74/100 (74%)] Train loss=0.277628 Test loss=0.429801 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27883899211883545
[5/23] Train loss=0.26246991753578186
[10/23] Train loss=0.29756176471710205
[15/23] Train loss=0.2297971397638321
[20/23] Train loss=0.22386889159679413
Test set avg_accuracy=83.11% avg_sensitivity=50.79%, avg_specificity=92.83% avg_auc=0.8511
Fold[8] Epoch: 75 [75/100 (75%)] Train loss=0.275398 Test loss=0.436435 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27399343252182007
[5/23] Train loss=0.25630608201026917
[10/23] Train loss=0.2800062894821167
[15/23] Train loss=0.2174825817346573
[20/23] Train loss=0.2236785888671875
Test set avg_accuracy=83.42% avg_sensitivity=56.05%, avg_specificity=91.66% avg_auc=0.8536
Fold[8] Epoch: 76 [76/100 (76%)] Train loss=0.271223 Test loss=0.429547 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26769042015075684
[5/23] Train loss=0.2541850209236145
[10/23] Train loss=0.27848705649375916
[15/23] Train loss=0.221595898270607
[20/23] Train loss=0.2209203988313675
Test set avg_accuracy=83.55% avg_sensitivity=53.03%, avg_specificity=92.73% avg_auc=0.8496
Fold[8] Epoch: 77 [77/100 (77%)] Train loss=0.268123 Test loss=0.440859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26114770770072937
[5/23] Train loss=0.2564551830291748
[10/23] Train loss=0.2739330232143402
[15/23] Train loss=0.2193969488143921
[20/23] Train loss=0.22153182327747345
Test set avg_accuracy=83.55% avg_sensitivity=60.02%, avg_specificity=90.63% avg_auc=0.8435
Fold[8] Epoch: 78 [78/100 (78%)] Train loss=0.263509 Test loss=0.445137 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.273645281791687
[5/23] Train loss=0.24493852257728577
[10/23] Train loss=0.2812087833881378
[15/23] Train loss=0.22431907057762146
[20/23] Train loss=0.22441251575946808
Test set avg_accuracy=83.50% avg_sensitivity=55.21%, avg_specificity=92.01% avg_auc=0.8472
Fold[8] Epoch: 79 [79/100 (79%)] Train loss=0.266886 Test loss=0.436245 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2755994498729706
[5/23] Train loss=0.2501005530357361
[10/23] Train loss=0.27230963110923767
[15/23] Train loss=0.22014330327510834
[20/23] Train loss=0.21818405389785767
Test set avg_accuracy=83.91% avg_sensitivity=58.88%, avg_specificity=91.45% avg_auc=0.8583
Best model saved!! Metric=-5.930319840626087!!
Fold[8] Epoch: 80 [80/100 (80%)] Train loss=0.268299 Test loss=0.426460 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2652236819267273
[5/23] Train loss=0.25145795941352844
[10/23] Train loss=0.26951831579208374
[15/23] Train loss=0.21296259760856628
[20/23] Train loss=0.2216474711894989
Test set avg_accuracy=83.41% avg_sensitivity=56.10%, avg_specificity=91.63% avg_auc=0.8557
Fold[8] Epoch: 81 [81/100 (81%)] Train loss=0.265209 Test loss=0.434320 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26790672540664673
[5/23] Train loss=0.252637654542923
[10/23] Train loss=0.27077287435531616
[15/23] Train loss=0.22772431373596191
[20/23] Train loss=0.21320532262325287
Test set avg_accuracy=83.80% avg_sensitivity=57.74%, avg_specificity=91.64% avg_auc=0.8572
Fold[8] Epoch: 82 [82/100 (82%)] Train loss=0.269034 Test loss=0.430200 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2644573748111725
[5/23] Train loss=0.24468117952346802
[10/23] Train loss=0.2735942304134369
[15/23] Train loss=0.21331870555877686
[20/23] Train loss=0.2240973263978958
Test set avg_accuracy=83.27% avg_sensitivity=51.14%, avg_specificity=92.94% avg_auc=0.8586
Fold[8] Epoch: 83 [83/100 (83%)] Train loss=0.265734 Test loss=0.439029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2632496654987335
[5/23] Train loss=0.24839366972446442
[10/23] Train loss=0.2667248547077179
[15/23] Train loss=0.21215300261974335
[20/23] Train loss=0.22219052910804749
Test set avg_accuracy=82.90% avg_sensitivity=50.84%, avg_specificity=92.55% avg_auc=0.8498
Fold[8] Epoch: 84 [84/100 (84%)] Train loss=0.259679 Test loss=0.441925 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25166013836860657
[5/23] Train loss=0.24473176896572113
[10/23] Train loss=0.26675283908843994
[15/23] Train loss=0.20669403672218323
[20/23] Train loss=0.21265166997909546
Test set avg_accuracy=84.12% avg_sensitivity=55.16%, avg_specificity=92.83% avg_auc=0.8537
Fold[8] Epoch: 85 [85/100 (85%)] Train loss=0.259072 Test loss=0.434082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2578286826610565
[5/23] Train loss=0.2502768337726593
[10/23] Train loss=0.26369643211364746
[15/23] Train loss=0.20790515840053558
[20/23] Train loss=0.20106001198291779
Test set avg_accuracy=83.68% avg_sensitivity=52.68%, avg_specificity=93.01% avg_auc=0.8477
Fold[8] Epoch: 86 [86/100 (86%)] Train loss=0.252750 Test loss=0.451649 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26058557629585266
[5/23] Train loss=0.24367862939834595
[10/23] Train loss=0.26283180713653564
[15/23] Train loss=0.20383542776107788
[20/23] Train loss=0.20686328411102295
Test set avg_accuracy=83.74% avg_sensitivity=54.22%, avg_specificity=92.63% avg_auc=0.8507
Fold[8] Epoch: 87 [87/100 (87%)] Train loss=0.251009 Test loss=0.460814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2639802396297455
[5/23] Train loss=0.240623340010643
[10/23] Train loss=0.2536938488483429
[15/23] Train loss=0.19686336815357208
[20/23] Train loss=0.2017679512500763
Test set avg_accuracy=82.94% avg_sensitivity=57.94%, avg_specificity=90.46% avg_auc=0.8428
Fold[8] Epoch: 88 [88/100 (88%)] Train loss=0.249491 Test loss=0.447961 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2448791265487671
[5/23] Train loss=0.24126800894737244
[10/23] Train loss=0.25176429748535156
[15/23] Train loss=0.19625885784626007
[20/23] Train loss=0.20120568573474884
Test set avg_accuracy=83.53% avg_sensitivity=57.14%, avg_specificity=91.48% avg_auc=0.8443
Fold[8] Epoch: 89 [89/100 (89%)] Train loss=0.244753 Test loss=0.461629 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27171313762664795
[5/23] Train loss=0.24234141409397125
[10/23] Train loss=0.24247008562088013
[15/23] Train loss=0.2084057331085205
[20/23] Train loss=0.2035430520772934
Test set avg_accuracy=84.00% avg_sensitivity=61.16%, avg_specificity=90.88% avg_auc=0.8432
Best model saved!! Metric=-5.636957043479676!!
Fold[8] Epoch: 90 [90/100 (90%)] Train loss=0.248950 Test loss=0.452208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2590784430503845
[5/23] Train loss=0.25537416338920593
[10/23] Train loss=0.2605927586555481
[15/23] Train loss=0.19671623408794403
[20/23] Train loss=0.21255959570407867
Test set avg_accuracy=84.00% avg_sensitivity=57.84%, avg_specificity=91.88% avg_auc=0.8578
Fold[8] Epoch: 91 [91/100 (91%)] Train loss=0.259942 Test loss=0.446054 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25463971495628357
[5/23] Train loss=0.22978343069553375
[10/23] Train loss=0.2714414596557617
[15/23] Train loss=0.21280421316623688
[20/23] Train loss=0.20640087127685547
Test set avg_accuracy=83.40% avg_sensitivity=52.23%, avg_specificity=92.78% avg_auc=0.8542
Fold[8] Epoch: 92 [92/100 (92%)] Train loss=0.255125 Test loss=0.437376 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25465068221092224
[5/23] Train loss=0.2416904866695404
[10/23] Train loss=0.2532418668270111
[15/23] Train loss=0.19271695613861084
[20/23] Train loss=0.20049914717674255
Test set avg_accuracy=83.89% avg_sensitivity=56.80%, avg_specificity=92.04% avg_auc=0.8553
Fold[8] Epoch: 93 [93/100 (93%)] Train loss=0.245498 Test loss=0.445189 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23472733795642853
[5/23] Train loss=0.23778332769870758
[10/23] Train loss=0.2484900802373886
[15/23] Train loss=0.18882346153259277
[20/23] Train loss=0.19727849960327148
Test set avg_accuracy=82.98% avg_sensitivity=52.23%, avg_specificity=92.24% avg_auc=0.8472
Fold[8] Epoch: 94 [94/100 (94%)] Train loss=0.241399 Test loss=0.462810 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24088816344738007
[5/23] Train loss=0.23187240958213806
[10/23] Train loss=0.24756145477294922
[15/23] Train loss=0.1896110624074936
[20/23] Train loss=0.19722290337085724
Test set avg_accuracy=82.88% avg_sensitivity=52.03%, avg_specificity=92.16% avg_auc=0.8450
Fold[8] Epoch: 95 [95/100 (95%)] Train loss=0.236163 Test loss=0.472813 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25040316581726074
[5/23] Train loss=0.2261742800474167
[10/23] Train loss=0.23372571170330048
[15/23] Train loss=0.18776042759418488
[20/23] Train loss=0.19662240147590637
Test set avg_accuracy=83.49% avg_sensitivity=56.35%, avg_specificity=91.66% avg_auc=0.8475
Fold[8] Epoch: 96 [96/100 (96%)] Train loss=0.236970 Test loss=0.481914 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23017317056655884
[5/23] Train loss=0.22037333250045776
[10/23] Train loss=0.23169802129268646
[15/23] Train loss=0.17821860313415527
[20/23] Train loss=0.19182753562927246
Test set avg_accuracy=83.57% avg_sensitivity=60.12%, avg_specificity=90.63% avg_auc=0.8395
Fold[8] Epoch: 97 [97/100 (97%)] Train loss=0.231308 Test loss=0.473960 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2413860559463501
[5/23] Train loss=0.22867189347743988
[10/23] Train loss=0.22174334526062012
[15/23] Train loss=0.17767255008220673
[20/23] Train loss=0.18602685630321503
Test set avg_accuracy=82.07% avg_sensitivity=49.36%, avg_specificity=91.91% avg_auc=0.8326
Fold[8] Epoch: 98 [98/100 (98%)] Train loss=0.229795 Test loss=0.507330 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22083203494548798
[5/23] Train loss=0.211501806974411
[10/23] Train loss=0.22592070698738098
[15/23] Train loss=0.18105046451091766
[20/23] Train loss=0.18180444836616516
Test set avg_accuracy=83.27% avg_sensitivity=58.38%, avg_specificity=90.76% avg_auc=0.8427
Fold[8] Epoch: 99 [99/100 (99%)] Train loss=0.228206 Test loss=0.470069 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2444109469652176
[5/23] Train loss=0.21338744461536407
[10/23] Train loss=0.2171231061220169
[15/23] Train loss=0.17565222084522247
[20/23] Train loss=0.18797241151332855
Test set avg_accuracy=83.45% avg_sensitivity=59.97%, avg_specificity=90.52% avg_auc=0.8526
Fold[8] Epoch: 100 [100/100 (100%)] Train loss=0.226193 Test loss=0.475811 Current lr=[3.9999999999999996e-05]

Fold[8] Best Result: acc=84.00458978772232 sen=61.16071428571429, spe=90.87923570682192, auc=0.8431850317626179!
[0/23] Train loss=0.703381359577179
[5/23] Train loss=0.6878501176834106
[10/23] Train loss=0.5610153675079346
[15/23] Train loss=0.565904974937439
[20/23] Train loss=0.5586227178573608
Test set avg_accuracy=74.67% avg_sensitivity=0.19%, avg_specificity=100.00% avg_auc=0.6154
Best model saved!! Metric=-89.60529971350277!!
Fold[9] Epoch: 1 [1/100 (1%)] Train loss=0.583154 Test loss=0.605780 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5735599994659424
[5/23] Train loss=0.5880376100540161
[10/23] Train loss=0.5057389140129089
[15/23] Train loss=0.5276822447776794
[20/23] Train loss=0.5098665356636047
Test set avg_accuracy=75.54% avg_sensitivity=5.63%, avg_specificity=99.32% avg_auc=0.6910
Best model saved!! Metric=-76.4172212266398!!
Fold[9] Epoch: 2 [2/100 (2%)] Train loss=0.538483 Test loss=0.555210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5411891937255859
[5/23] Train loss=0.532459020614624
[10/23] Train loss=0.47453683614730835
[15/23] Train loss=0.47019270062446594
[20/23] Train loss=0.47139644622802734
Test set avg_accuracy=76.37% avg_sensitivity=16.46%, avg_specificity=96.74% avg_auc=0.7449
Best model saved!! Metric=-61.94546475344866!!
Fold[9] Epoch: 3 [3/100 (3%)] Train loss=0.502592 Test loss=0.523595 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.49797970056533813
[5/23] Train loss=0.4805144965648651
[10/23] Train loss=0.473870187997818
[15/23] Train loss=0.434417724609375
[20/23] Train loss=0.44727370142936707
Test set avg_accuracy=77.82% avg_sensitivity=25.66%, avg_specificity=95.56% avg_auc=0.7738
Best model saved!! Metric=-49.580847647688074!!
Fold[9] Epoch: 4 [4/100 (4%)] Train loss=0.470620 Test loss=0.536379 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.46480637788772583
[5/23] Train loss=0.4604019820690155
[10/23] Train loss=0.476220041513443
[15/23] Train loss=0.42480072379112244
[20/23] Train loss=0.4434828460216522
Test set avg_accuracy=77.81% avg_sensitivity=25.89%, avg_specificity=95.46% avg_auc=0.7852
Best model saved!! Metric=-48.31435203820561!!
Fold[9] Epoch: 5 [5/100 (5%)] Train loss=0.457129 Test loss=0.527257 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4447972774505615
[5/23] Train loss=0.4477580487728119
[10/23] Train loss=0.48308274149894714
[15/23] Train loss=0.41483569145202637
[20/23] Train loss=0.44315189123153687
Test set avg_accuracy=78.01% avg_sensitivity=26.17%, avg_specificity=95.64% avg_auc=0.7955
Best model saved!! Metric=-46.63871523218553!!
Fold[9] Epoch: 6 [6/100 (6%)] Train loss=0.447628 Test loss=0.517122 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4399133026599884
[5/23] Train loss=0.43963468074798584
[10/23] Train loss=0.4899248778820038
[15/23] Train loss=0.42525964975357056
[20/23] Train loss=0.4266520142555237
Test set avg_accuracy=77.98% avg_sensitivity=27.24%, avg_specificity=95.24% avg_auc=0.8041
Best model saved!! Metric=-45.121090268299234!!
Fold[9] Epoch: 7 [7/100 (7%)] Train loss=0.441322 Test loss=0.514018 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4373427927494049
[5/23] Train loss=0.4290919601917267
[10/23] Train loss=0.4737207591533661
[15/23] Train loss=0.4268885552883148
[20/23] Train loss=0.4176614582538605
Test set avg_accuracy=79.06% avg_sensitivity=33.05%, avg_specificity=94.70% avg_auc=0.8130
Best model saved!! Metric=-37.887315420573444!!
Fold[9] Epoch: 8 [8/100 (8%)] Train loss=0.431909 Test loss=0.486384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.423512727022171
[5/23] Train loss=0.43024811148643494
[10/23] Train loss=0.4645519554615021
[15/23] Train loss=0.41420406103134155
[20/23] Train loss=0.41330966353416443
Test set avg_accuracy=79.66% avg_sensitivity=37.24%, avg_specificity=94.09% avg_auc=0.8156
Best model saved!! Metric=-33.45740164823438!!
Fold[9] Epoch: 9 [9/100 (9%)] Train loss=0.424869 Test loss=0.478082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4137740731239319
[5/23] Train loss=0.4190073609352112
[10/23] Train loss=0.4602010250091553
[15/23] Train loss=0.40300536155700684
[20/23] Train loss=0.40935462713241577
Test set avg_accuracy=79.43% avg_sensitivity=35.66%, avg_specificity=94.32% avg_auc=0.8173
Fold[9] Epoch: 10 [10/100 (10%)] Train loss=0.419017 Test loss=0.486828 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40715664625167847
[5/23] Train loss=0.4107429087162018
[10/23] Train loss=0.46765419840812683
[15/23] Train loss=0.39293456077575684
[20/23] Train loss=0.40425360202789307
Test set avg_accuracy=79.35% avg_sensitivity=34.82%, avg_specificity=94.50% avg_auc=0.8210
Fold[9] Epoch: 11 [11/100 (11%)] Train loss=0.418648 Test loss=0.488091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.405286580324173
[5/23] Train loss=0.4115191400051117
[10/23] Train loss=0.473735511302948
[15/23] Train loss=0.4049636423587799
[20/23] Train loss=0.401903361082077
Test set avg_accuracy=79.56% avg_sensitivity=36.17%, avg_specificity=94.32% avg_auc=0.8262
Best model saved!! Metric=-33.32354820782765!!
Fold[9] Epoch: 12 [12/100 (12%)] Train loss=0.415224 Test loss=0.474888 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4015997648239136
[5/23] Train loss=0.40683019161224365
[10/23] Train loss=0.4581165015697479
[15/23] Train loss=0.39636752009391785
[20/23] Train loss=0.3910629153251648
Test set avg_accuracy=79.91% avg_sensitivity=39.84%, avg_specificity=93.53% avg_auc=0.8299
Best model saved!! Metric=-29.73308208022106!!
Fold[9] Epoch: 13 [13/100 (13%)] Train loss=0.406523 Test loss=0.461530 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40099862217903137
[5/23] Train loss=0.4049549400806427
[10/23] Train loss=0.4571016728878021
[15/23] Train loss=0.38332581520080566
[20/23] Train loss=0.39319443702697754
Test set avg_accuracy=79.93% avg_sensitivity=40.40%, avg_specificity=93.37% avg_auc=0.8321
Best model saved!! Metric=-29.0829856042169!!
Fold[9] Epoch: 14 [14/100 (14%)] Train loss=0.402146 Test loss=0.460751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40411996841430664
[5/23] Train loss=0.39394816756248474
[10/23] Train loss=0.4520080089569092
[15/23] Train loss=0.3790375888347626
[20/23] Train loss=0.38657328486442566
Test set avg_accuracy=79.99% avg_sensitivity=40.26%, avg_specificity=93.50% avg_auc=0.8342
Best model saved!! Metric=-28.831353500017812!!
Fold[9] Epoch: 15 [15/100 (15%)] Train loss=0.399605 Test loss=0.458847 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3894994854927063
[5/23] Train loss=0.3931069076061249
[10/23] Train loss=0.4567907452583313
[15/23] Train loss=0.37714439630508423
[20/23] Train loss=0.3867904543876648
Test set avg_accuracy=80.46% avg_sensitivity=41.75%, avg_specificity=93.63% avg_auc=0.8384
Best model saved!! Metric=-26.320411064770475!!
Fold[9] Epoch: 16 [16/100 (16%)] Train loss=0.396042 Test loss=0.455197 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38794127106666565
[5/23] Train loss=0.3922501802444458
[10/23] Train loss=0.45502009987831116
[15/23] Train loss=0.36907845735549927
[20/23] Train loss=0.3826800584793091
Test set avg_accuracy=80.65% avg_sensitivity=42.96%, avg_specificity=93.47% avg_auc=0.8379
Best model saved!! Metric=-25.138260547277504!!
Fold[9] Epoch: 17 [17/100 (17%)] Train loss=0.392788 Test loss=0.450787 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39045974612236023
[5/23] Train loss=0.39091432094573975
[10/23] Train loss=0.44601720571517944
[15/23] Train loss=0.37621238827705383
[20/23] Train loss=0.37726327776908875
Test set avg_accuracy=80.78% avg_sensitivity=43.38%, avg_specificity=93.50% avg_auc=0.8397
Best model saved!! Metric=-24.377852619052845!!
Fold[9] Epoch: 18 [18/100 (18%)] Train loss=0.390403 Test loss=0.450729 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3859284222126007
[5/23] Train loss=0.3876056373119354
[10/23] Train loss=0.4368186891078949
[15/23] Train loss=0.3652128279209137
[20/23] Train loss=0.37118589878082275
Test set avg_accuracy=80.53% avg_sensitivity=44.96%, avg_specificity=92.63% avg_auc=0.8420
Best model saved!! Metric=-23.67829243885913!!
Fold[9] Epoch: 19 [19/100 (19%)] Train loss=0.384692 Test loss=0.440479 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3831871449947357
[5/23] Train loss=0.3839656114578247
[10/23] Train loss=0.437346875667572
[15/23] Train loss=0.3644256293773651
[20/23] Train loss=0.36650803685188293
Test set avg_accuracy=80.77% avg_sensitivity=45.14%, avg_specificity=92.88% avg_auc=0.8437
Best model saved!! Metric=-22.836485959787268!!
Fold[9] Epoch: 20 [20/100 (20%)] Train loss=0.382854 Test loss=0.435461 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3791543245315552
[5/23] Train loss=0.382344514131546
[10/23] Train loss=0.4357287883758545
[15/23] Train loss=0.35773780941963196
[20/23] Train loss=0.37059178948402405
Test set avg_accuracy=80.97% avg_sensitivity=46.35%, avg_specificity=92.74% avg_auc=0.8437
Best model saved!! Metric=-21.574241891975543!!
Fold[9] Epoch: 21 [21/100 (21%)] Train loss=0.378501 Test loss=0.437415 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37768805027008057
[5/23] Train loss=0.37810268998146057
[10/23] Train loss=0.434743195772171
[15/23] Train loss=0.3551730513572693
[20/23] Train loss=0.3575834035873413
Test set avg_accuracy=80.79% avg_sensitivity=46.12%, avg_specificity=92.58% avg_auc=0.8443
Fold[9] Epoch: 22 [22/100 (22%)] Train loss=0.376345 Test loss=0.435603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3718261420726776
[5/23] Train loss=0.3734533488750458
[10/23] Train loss=0.4300752878189087
[15/23] Train loss=0.34962573647499084
[20/23] Train loss=0.36024200916290283
Test set avg_accuracy=80.96% avg_sensitivity=46.72%, avg_specificity=92.60% avg_auc=0.8430
Best model saved!! Metric=-21.422120662589542!!
Fold[9] Epoch: 23 [23/100 (23%)] Train loss=0.371476 Test loss=0.439004 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37151649594306946
[5/23] Train loss=0.37317636609077454
[10/23] Train loss=0.43160703778266907
[15/23] Train loss=0.3428559899330139
[20/23] Train loss=0.35839247703552246
Test set avg_accuracy=80.67% avg_sensitivity=46.86%, avg_specificity=92.17% avg_auc=0.8436
Fold[9] Epoch: 24 [24/100 (24%)] Train loss=0.370633 Test loss=0.434679 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3663552701473236
[5/23] Train loss=0.36845189332962036
[10/23] Train loss=0.431974858045578
[15/23] Train loss=0.3482109308242798
[20/23] Train loss=0.3543473780155182
Test set avg_accuracy=80.94% avg_sensitivity=46.95%, avg_specificity=92.50% avg_auc=0.8427
Best model saved!! Metric=-21.323745230798295!!
Fold[9] Epoch: 25 [25/100 (25%)] Train loss=0.369417 Test loss=0.439726 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3579173684120178
[5/23] Train loss=0.37081825733184814
[10/23] Train loss=0.42725062370300293
[15/23] Train loss=0.3482401371002197
[20/23] Train loss=0.3487834334373474
Test set avg_accuracy=80.63% avg_sensitivity=47.61%, avg_specificity=91.86% avg_auc=0.8405
Fold[9] Epoch: 26 [26/100 (26%)] Train loss=0.366809 Test loss=0.443485 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3566065728664398
[5/23] Train loss=0.3665468990802765
[10/23] Train loss=0.41114675998687744
[15/23] Train loss=0.33933135867118835
[20/23] Train loss=0.3462415635585785
Test set avg_accuracy=80.54% avg_sensitivity=50.12%, avg_specificity=90.89% avg_auc=0.8434
Best model saved!! Metric=-20.112227784092525!!
Fold[9] Epoch: 27 [27/100 (27%)] Train loss=0.361981 Test loss=0.435494 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.357541561126709
[5/23] Train loss=0.36476272344589233
[10/23] Train loss=0.4174264371395111
[15/23] Train loss=0.3445321321487427
[20/23] Train loss=0.3500550091266632
Test set avg_accuracy=80.76% avg_sensitivity=50.07%, avg_specificity=91.19% avg_auc=0.8408
Best model saved!! Metric=-19.904216138819077!!
Fold[9] Epoch: 28 [28/100 (28%)] Train loss=0.360991 Test loss=0.437705 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3598344624042511
[5/23] Train loss=0.3652181923389435
[10/23] Train loss=0.40859511494636536
[15/23] Train loss=0.3426051139831543
[20/23] Train loss=0.3536107838153839
Test set avg_accuracy=81.57% avg_sensitivity=53.65%, avg_specificity=91.07% avg_auc=0.8464
Best model saved!! Metric=-15.07656313028566!!
Fold[9] Epoch: 29 [29/100 (29%)] Train loss=0.359960 Test loss=0.430442 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36486342549324036
[5/23] Train loss=0.35357895493507385
[10/23] Train loss=0.4150652289390564
[15/23] Train loss=0.3293786644935608
[20/23] Train loss=0.3427909016609192
Test set avg_accuracy=80.72% avg_sensitivity=47.75%, avg_specificity=91.94% avg_auc=0.8439
Fold[9] Epoch: 30 [30/100 (30%)] Train loss=0.357501 Test loss=0.442987 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3514564037322998
[5/23] Train loss=0.3569347858428955
[10/23] Train loss=0.41160300374031067
[15/23] Train loss=0.32923129200935364
[20/23] Train loss=0.34549790620803833
Test set avg_accuracy=80.94% avg_sensitivity=47.33%, avg_specificity=92.38% avg_auc=0.8431
Fold[9] Epoch: 31 [31/100 (31%)] Train loss=0.356547 Test loss=0.452441 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3477826714515686
[5/23] Train loss=0.3575732111930847
[10/23] Train loss=0.41044604778289795
[15/23] Train loss=0.33273574709892273
[20/23] Train loss=0.3313054144382477
Test set avg_accuracy=81.07% avg_sensitivity=49.37%, avg_specificity=91.86% avg_auc=0.8407
Fold[9] Epoch: 32 [32/100 (32%)] Train loss=0.354241 Test loss=0.459238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3436826467514038
[5/23] Train loss=0.3558153808116913
[10/23] Train loss=0.4016762673854828
[15/23] Train loss=0.32226690649986267
[20/23] Train loss=0.329988569021225
Test set avg_accuracy=81.42% avg_sensitivity=53.84%, avg_specificity=90.80% avg_auc=0.8450
Fold[9] Epoch: 33 [33/100 (33%)] Train loss=0.349124 Test loss=0.445123 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35039621591567993
[5/23] Train loss=0.3484061658382416
[10/23] Train loss=0.4000913202762604
[15/23] Train loss=0.32588836550712585
[20/23] Train loss=0.33107081055641174
Test set avg_accuracy=81.25% avg_sensitivity=50.77%, avg_specificity=91.62% avg_auc=0.8433
Fold[9] Epoch: 34 [34/100 (34%)] Train loss=0.345212 Test loss=0.446581 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3387405574321747
[5/23] Train loss=0.35193005204200745
[10/23] Train loss=0.39177045226097107
[15/23] Train loss=0.3162383437156677
[20/23] Train loss=0.33183151483535767
Test set avg_accuracy=81.25% avg_sensitivity=54.07%, avg_specificity=90.50% avg_auc=0.8436
Fold[9] Epoch: 35 [35/100 (35%)] Train loss=0.342594 Test loss=0.444861 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.334602952003479
[5/23] Train loss=0.34375840425491333
[10/23] Train loss=0.3893229067325592
[15/23] Train loss=0.32296985387802124
[20/23] Train loss=0.33044496178627014
Test set avg_accuracy=81.42% avg_sensitivity=50.21%, avg_specificity=92.03% avg_auc=0.8415
Fold[9] Epoch: 36 [36/100 (36%)] Train loss=0.340655 Test loss=0.454338 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33313867449760437
[5/23] Train loss=0.34627434611320496
[10/23] Train loss=0.3914497196674347
[15/23] Train loss=0.3136516809463501
[20/23] Train loss=0.3211672604084015
Test set avg_accuracy=81.37% avg_sensitivity=53.42%, avg_specificity=90.88% avg_auc=0.8438
Fold[9] Epoch: 37 [37/100 (37%)] Train loss=0.337586 Test loss=0.448383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.334391325712204
[5/23] Train loss=0.34020087122917175
[10/23] Train loss=0.382799357175827
[15/23] Train loss=0.30731335282325745
[20/23] Train loss=0.3243524432182312
Test set avg_accuracy=81.63% avg_sensitivity=54.95%, avg_specificity=90.70% avg_auc=0.8436
Best model saved!! Metric=-14.354105782925597!!
Fold[9] Epoch: 38 [38/100 (38%)] Train loss=0.333295 Test loss=0.447331 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34426963329315186
[5/23] Train loss=0.33252406120300293
[10/23] Train loss=0.3735092878341675
[15/23] Train loss=0.3043035864830017
[20/23] Train loss=0.3249240219593048
Test set avg_accuracy=81.97% avg_sensitivity=55.18%, avg_specificity=91.08% avg_auc=0.8449
Best model saved!! Metric=-13.269700117025602!!
Fold[9] Epoch: 39 [39/100 (39%)] Train loss=0.331693 Test loss=0.447377 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32723337411880493
[5/23] Train loss=0.3317803144454956
[10/23] Train loss=0.3875039517879486
[15/23] Train loss=0.30643296241760254
[20/23] Train loss=0.317746102809906
Test set avg_accuracy=81.89% avg_sensitivity=51.88%, avg_specificity=92.09% avg_auc=0.8437
Fold[9] Epoch: 40 [40/100 (40%)] Train loss=0.330654 Test loss=0.453846 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33102184534072876
[5/23] Train loss=0.332809180021286
[10/23] Train loss=0.3762497007846832
[15/23] Train loss=0.2992005944252014
[20/23] Train loss=0.31052500009536743
Test set avg_accuracy=81.72% avg_sensitivity=53.79%, avg_specificity=91.22% avg_auc=0.8440
Fold[9] Epoch: 41 [41/100 (41%)] Train loss=0.327083 Test loss=0.451321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3237343728542328
[5/23] Train loss=0.32958531379699707
[10/23] Train loss=0.36836153268814087
[15/23] Train loss=0.3056921660900116
[20/23] Train loss=0.31524744629859924
Test set avg_accuracy=81.46% avg_sensitivity=51.70%, avg_specificity=91.59% avg_auc=0.8431
Fold[9] Epoch: 42 [42/100 (42%)] Train loss=0.325641 Test loss=0.459878 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3181019723415375
[5/23] Train loss=0.33199357986450195
[10/23] Train loss=0.3665534555912018
[15/23] Train loss=0.2978866696357727
[20/23] Train loss=0.3052584230899811
Test set avg_accuracy=81.50% avg_sensitivity=54.02%, avg_specificity=90.84% avg_auc=0.8438
Fold[9] Epoch: 43 [43/100 (43%)] Train loss=0.325108 Test loss=0.460863 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3158348798751831
[5/23] Train loss=0.33555370569229126
[10/23] Train loss=0.3635905086994171
[15/23] Train loss=0.29153603315353394
[20/23] Train loss=0.30955249071121216
Test set avg_accuracy=81.77% avg_sensitivity=54.35%, avg_specificity=91.10% avg_auc=0.8408
Fold[9] Epoch: 44 [44/100 (44%)] Train loss=0.324265 Test loss=0.467962 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31798768043518066
[5/23] Train loss=0.3275105953216553
[10/23] Train loss=0.3697526454925537
[15/23] Train loss=0.3031710386276245
[20/23] Train loss=0.3134143352508545
Test set avg_accuracy=81.32% avg_sensitivity=52.35%, avg_specificity=91.18% avg_auc=0.8415
Fold[9] Epoch: 45 [45/100 (45%)] Train loss=0.323142 Test loss=0.461685 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3237348794937134
[5/23] Train loss=0.32174205780029297
[10/23] Train loss=0.3489187955856323
[15/23] Train loss=0.29442867636680603
[20/23] Train loss=0.29977601766586304
Test set avg_accuracy=81.82% avg_sensitivity=59.04%, avg_specificity=89.56% avg_auc=0.8454
Best model saved!! Metric=-11.03570132473574!!
Fold[9] Epoch: 46 [46/100 (46%)] Train loss=0.316649 Test loss=0.453033 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31781646609306335
[5/23] Train loss=0.3152235448360443
[10/23] Train loss=0.34529080986976624
[15/23] Train loss=0.28403979539871216
[20/23] Train loss=0.2999288737773895
Test set avg_accuracy=81.38% avg_sensitivity=52.35%, avg_specificity=91.26% avg_auc=0.8427
Fold[9] Epoch: 47 [47/100 (47%)] Train loss=0.313481 Test loss=0.461610 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3075106739997864
[5/23] Train loss=0.3152981400489807
[10/23] Train loss=0.3505275249481201
[15/23] Train loss=0.28114715218544006
[20/23] Train loss=0.28745827078819275
Test set avg_accuracy=81.38% avg_sensitivity=57.18%, avg_specificity=89.61% avg_auc=0.8426
Fold[9] Epoch: 48 [48/100 (48%)] Train loss=0.310076 Test loss=0.461983 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.309215247631073
[5/23] Train loss=0.30622628331184387
[10/23] Train loss=0.34089189767837524
[15/23] Train loss=0.273104727268219
[20/23] Train loss=0.2868597209453583
Test set avg_accuracy=81.79% avg_sensitivity=56.67%, avg_specificity=90.34% avg_auc=0.8429
Fold[9] Epoch: 49 [49/100 (49%)] Train loss=0.304489 Test loss=0.466834 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.307684987783432
[5/23] Train loss=0.30779433250427246
[10/23] Train loss=0.3304545283317566
[15/23] Train loss=0.2779567241668701
[20/23] Train loss=0.286388635635376
Test set avg_accuracy=81.66% avg_sensitivity=56.07%, avg_specificity=90.37% avg_auc=0.8415
Fold[9] Epoch: 50 [50/100 (50%)] Train loss=0.302591 Test loss=0.467343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30329471826553345
[5/23] Train loss=0.30654239654541016
[10/23] Train loss=0.3355075418949127
[15/23] Train loss=0.2664582431316376
[20/23] Train loss=0.2870319187641144
Test set avg_accuracy=81.88% avg_sensitivity=54.02%, avg_specificity=91.35% avg_auc=0.8427
Fold[9] Epoch: 51 [51/100 (51%)] Train loss=0.300890 Test loss=0.464431 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29954156279563904
[5/23] Train loss=0.29741910099983215
[10/23] Train loss=0.3366983234882355
[15/23] Train loss=0.266163170337677
[20/23] Train loss=0.29429224133491516
Test set avg_accuracy=81.75% avg_sensitivity=50.67%, avg_specificity=92.31% avg_auc=0.8427
Fold[9] Epoch: 52 [52/100 (52%)] Train loss=0.301776 Test loss=0.464029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30732810497283936
[5/23] Train loss=0.3029036223888397
[10/23] Train loss=0.32874834537506104
[15/23] Train loss=0.2667774558067322
[20/23] Train loss=0.2779819071292877
Test set avg_accuracy=82.01% avg_sensitivity=54.95%, avg_specificity=91.21% avg_auc=0.8431
Fold[9] Epoch: 53 [53/100 (53%)] Train loss=0.296898 Test loss=0.469089 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29171669483184814
[5/23] Train loss=0.30333131551742554
[10/23] Train loss=0.328534334897995
[15/23] Train loss=0.2661716938018799
[20/23] Train loss=0.2775282561779022
Test set avg_accuracy=81.91% avg_sensitivity=52.39%, avg_specificity=91.95% avg_auc=0.8429
Fold[9] Epoch: 54 [54/100 (54%)] Train loss=0.298304 Test loss=0.474116 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2993498742580414
[5/23] Train loss=0.2960037589073181
[10/23] Train loss=0.3364454507827759
[15/23] Train loss=0.2612902522087097
[20/23] Train loss=0.2830718755722046
Test set avg_accuracy=81.49% avg_sensitivity=50.81%, avg_specificity=91.92% avg_auc=0.8402
Fold[9] Epoch: 55 [55/100 (55%)] Train loss=0.299754 Test loss=0.473627 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28615838289260864
[5/23] Train loss=0.3057238459587097
[10/23] Train loss=0.30874720215797424
[15/23] Train loss=0.25194621086120605
[20/23] Train loss=0.273345023393631
Test set avg_accuracy=81.72% avg_sensitivity=61.60%, avg_specificity=88.57% avg_auc=0.8412
Best model saved!! Metric=-9.988084784571953!!
Fold[9] Epoch: 56 [56/100 (56%)] Train loss=0.290467 Test loss=0.468808 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2957075238227844
[5/23] Train loss=0.29549136757850647
[10/23] Train loss=0.3162033259868622
[15/23] Train loss=0.25084733963012695
[20/23] Train loss=0.27874934673309326
Test set avg_accuracy=82.01% avg_sensitivity=56.90%, avg_specificity=90.54% avg_auc=0.8427
Fold[9] Epoch: 57 [57/100 (57%)] Train loss=0.287729 Test loss=0.473658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2889082431793213
[5/23] Train loss=0.2953466475009918
[10/23] Train loss=0.31263023614883423
[15/23] Train loss=0.25030311942100525
[20/23] Train loss=0.27011561393737793
Test set avg_accuracy=81.66% avg_sensitivity=57.37%, avg_specificity=89.93% avg_auc=0.8425
Fold[9] Epoch: 58 [58/100 (58%)] Train loss=0.283188 Test loss=0.474311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2760213315486908
[5/23] Train loss=0.29000982642173767
[10/23] Train loss=0.30976924300193787
[15/23] Train loss=0.24547727406024933
[20/23] Train loss=0.26355552673339844
Test set avg_accuracy=82.32% avg_sensitivity=56.11%, avg_specificity=91.24% avg_auc=0.8445
Fold[9] Epoch: 59 [59/100 (59%)] Train loss=0.279154 Test loss=0.471112 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28050437569618225
[5/23] Train loss=0.27859872579574585
[10/23] Train loss=0.3162825405597687
[15/23] Train loss=0.2436818927526474
[20/23] Train loss=0.25926414132118225
Test set avg_accuracy=81.98% avg_sensitivity=53.32%, avg_specificity=91.73% avg_auc=0.8428
Fold[9] Epoch: 60 [60/100 (60%)] Train loss=0.277965 Test loss=0.472630 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2820281386375427
[5/23] Train loss=0.2769586443901062
[10/23] Train loss=0.2944580316543579
[15/23] Train loss=0.23506174981594086
[20/23] Train loss=0.2581753730773926
Test set avg_accuracy=82.08% avg_sensitivity=57.09%, avg_specificity=90.58% avg_auc=0.8428
Fold[9] Epoch: 61 [61/100 (61%)] Train loss=0.273164 Test loss=0.483318 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2740107476711273
[5/23] Train loss=0.2767711579799652
[10/23] Train loss=0.28898337483406067
[15/23] Train loss=0.24075578153133392
[20/23] Train loss=0.2483755350112915
Test set avg_accuracy=82.11% avg_sensitivity=56.86%, avg_specificity=90.70% avg_auc=0.8412
Fold[9] Epoch: 62 [62/100 (62%)] Train loss=0.273710 Test loss=0.477064 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2700761556625366
[5/23] Train loss=0.27107053995132446
[10/23] Train loss=0.291115403175354
[15/23] Train loss=0.23351600766181946
[20/23] Train loss=0.25699496269226074
Test set avg_accuracy=81.95% avg_sensitivity=56.39%, avg_specificity=90.64% avg_auc=0.8410
Fold[9] Epoch: 63 [63/100 (63%)] Train loss=0.269946 Test loss=0.482158 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2766943871974945
[5/23] Train loss=0.27003589272499084
[10/23] Train loss=0.2817463278770447
[15/23] Train loss=0.23499120771884918
[20/23] Train loss=0.24835583567619324
Test set avg_accuracy=81.64% avg_sensitivity=55.46%, avg_specificity=90.54% avg_auc=0.8385
Fold[9] Epoch: 64 [64/100 (64%)] Train loss=0.268924 Test loss=0.489976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26876962184906006
[5/23] Train loss=0.2644600570201874
[10/23] Train loss=0.28580528497695923
[15/23] Train loss=0.2273150533437729
[20/23] Train loss=0.2652035653591156
Test set avg_accuracy=82.11% avg_sensitivity=55.09%, avg_specificity=91.30% avg_auc=0.8401
Fold[9] Epoch: 65 [65/100 (65%)] Train loss=0.266618 Test loss=0.479367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27661392092704773
[5/23] Train loss=0.26670047640800476
[10/23] Train loss=0.28215447068214417
[15/23] Train loss=0.22284720838069916
[20/23] Train loss=0.2517775297164917
Test set avg_accuracy=81.97% avg_sensitivity=53.23%, avg_specificity=91.75% avg_auc=0.8391
Fold[9] Epoch: 66 [66/100 (66%)] Train loss=0.264410 Test loss=0.493942 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26324403285980225
[5/23] Train loss=0.26652970910072327
[10/23] Train loss=0.3098428249359131
[15/23] Train loss=0.24506708979606628
[20/23] Train loss=0.2535618245601654
Test set avg_accuracy=82.11% avg_sensitivity=49.47%, avg_specificity=93.22% avg_auc=0.8393
Fold[9] Epoch: 67 [67/100 (67%)] Train loss=0.272021 Test loss=0.508338 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27548250555992126
[5/23] Train loss=0.2810816466808319
[10/23] Train loss=0.2874743938446045
[15/23] Train loss=0.2443578839302063
[20/23] Train loss=0.24356037378311157
Test set avg_accuracy=81.32% avg_sensitivity=49.79%, avg_specificity=92.05% avg_auc=0.8373
Fold[9] Epoch: 68 [68/100 (68%)] Train loss=0.274147 Test loss=0.486558 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25961586833000183
[5/23] Train loss=0.284124493598938
[10/23] Train loss=0.2777934670448303
[15/23] Train loss=0.22341087460517883
[20/23] Train loss=0.24701809883117676
Test set avg_accuracy=82.28% avg_sensitivity=57.97%, avg_specificity=90.54% avg_auc=0.8423
Fold[9] Epoch: 69 [69/100 (69%)] Train loss=0.264796 Test loss=0.491273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2597281038761139
[5/23] Train loss=0.2644414007663727
[10/23] Train loss=0.2829807996749878
[15/23] Train loss=0.22350341081619263
[20/23] Train loss=0.2407204657793045
Test set avg_accuracy=81.82% avg_sensitivity=61.46%, avg_specificity=88.74% avg_auc=0.8380
Fold[9] Epoch: 70 [70/100 (70%)] Train loss=0.256928 Test loss=0.497992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2787806987762451
[5/23] Train loss=0.2635568678379059
[10/23] Train loss=0.2691085636615753
[15/23] Train loss=0.21715067327022552
[20/23] Train loss=0.23455125093460083
Test set avg_accuracy=82.22% avg_sensitivity=57.32%, avg_specificity=90.69% avg_auc=0.8401
Fold[9] Epoch: 71 [71/100 (71%)] Train loss=0.256398 Test loss=0.490147 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2573515772819519
[5/23] Train loss=0.27382463216781616
[10/23] Train loss=0.2670222222805023
[15/23] Train loss=0.21764084696769714
[20/23] Train loss=0.23305730521678925
Test set avg_accuracy=82.29% avg_sensitivity=53.32%, avg_specificity=92.14% avg_auc=0.8391
Fold[9] Epoch: 72 [72/100 (72%)] Train loss=0.250393 Test loss=0.491422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2530438005924225
[5/23] Train loss=0.26058661937713623
[10/23] Train loss=0.27725234627723694
[15/23] Train loss=0.20711922645568848
[20/23] Train loss=0.23332710564136505
Test set avg_accuracy=82.23% avg_sensitivity=53.51%, avg_specificity=92.00% avg_auc=0.8381
Fold[9] Epoch: 73 [73/100 (73%)] Train loss=0.252008 Test loss=0.491839 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24461419880390167
[5/23] Train loss=0.2544250786304474
[10/23] Train loss=0.2610684037208557
[15/23] Train loss=0.21682289242744446
[20/23] Train loss=0.22556434571743011
Test set avg_accuracy=82.55% avg_sensitivity=57.51%, avg_specificity=91.07% avg_auc=0.8417
Fold[9] Epoch: 74 [74/100 (74%)] Train loss=0.250075 Test loss=0.486617 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23927326500415802
[5/23] Train loss=0.25749561190605164
[10/23] Train loss=0.25243377685546875
[15/23] Train loss=0.21000027656555176
[20/23] Train loss=0.22599121928215027
Test set avg_accuracy=82.35% avg_sensitivity=52.25%, avg_specificity=92.58% avg_auc=0.8392
Fold[9] Epoch: 75 [75/100 (75%)] Train loss=0.251560 Test loss=0.496203 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2601439356803894
[5/23] Train loss=0.2554120123386383
[10/23] Train loss=0.25825735926628113
[15/23] Train loss=0.22053174674510956
[20/23] Train loss=0.22923295199871063
Test set avg_accuracy=82.12% avg_sensitivity=61.51%, avg_specificity=89.14% avg_auc=0.8368
Best model saved!! Metric=-9.554194964428305!!
Fold[9] Epoch: 76 [76/100 (76%)] Train loss=0.253738 Test loss=0.504091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2555234730243683
[5/23] Train loss=0.2568177282810211
[10/23] Train loss=0.26933276653289795
[15/23] Train loss=0.21141259372234344
[20/23] Train loss=0.22330941259860992
Test set avg_accuracy=82.49% avg_sensitivity=57.83%, avg_specificity=90.88% avg_auc=0.8402
Fold[9] Epoch: 77 [77/100 (77%)] Train loss=0.247967 Test loss=0.500526 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2495146244764328
[5/23] Train loss=0.24944376945495605
[10/23] Train loss=0.24513554573059082
[15/23] Train loss=0.19833731651306152
[20/23] Train loss=0.21536079049110413
Test set avg_accuracy=82.36% avg_sensitivity=58.39%, avg_specificity=90.51% avg_auc=0.8400
Fold[9] Epoch: 78 [78/100 (78%)] Train loss=0.240059 Test loss=0.497129 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2342889904975891
[5/23] Train loss=0.25945818424224854
[10/23] Train loss=0.24393533170223236
[15/23] Train loss=0.2009737640619278
[20/23] Train loss=0.21518532931804657
Test set avg_accuracy=81.78% avg_sensitivity=57.79%, avg_specificity=89.94% avg_auc=0.8410
Fold[9] Epoch: 79 [79/100 (79%)] Train loss=0.235544 Test loss=0.502149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2304060310125351
[5/23] Train loss=0.23312516510486603
[10/23] Train loss=0.24394354224205017
[15/23] Train loss=0.19435878098011017
[20/23] Train loss=0.21905991435050964
Test set avg_accuracy=81.47% avg_sensitivity=54.72%, avg_specificity=90.58% avg_auc=0.8398
Fold[9] Epoch: 80 [80/100 (80%)] Train loss=0.234388 Test loss=0.508797 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23182135820388794
[5/23] Train loss=0.23760375380516052
[10/23] Train loss=0.2404421865940094
[15/23] Train loss=0.19449664652347565
[20/23] Train loss=0.2198132872581482
Test set avg_accuracy=82.01% avg_sensitivity=55.09%, avg_specificity=91.16% avg_auc=0.8310
Fold[9] Epoch: 81 [81/100 (81%)] Train loss=0.229752 Test loss=0.515552 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2343904972076416
[5/23] Train loss=0.24561461806297302
[10/23] Train loss=0.23516373336315155
[15/23] Train loss=0.1884184181690216
[20/23] Train loss=0.20864064991474152
Test set avg_accuracy=82.12% avg_sensitivity=57.04%, avg_specificity=90.65% avg_auc=0.8353
Fold[9] Epoch: 82 [82/100 (82%)] Train loss=0.229114 Test loss=0.519200 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23174770176410675
[5/23] Train loss=0.24761129915714264
[10/23] Train loss=0.2273986041545868
[15/23] Train loss=0.19435755908489227
[20/23] Train loss=0.20693086087703705
Test set avg_accuracy=82.11% avg_sensitivity=57.97%, avg_specificity=90.32% avg_auc=0.8374
Fold[9] Epoch: 83 [83/100 (83%)] Train loss=0.226308 Test loss=0.521563 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22528652846813202
[5/23] Train loss=0.233766108751297
[10/23] Train loss=0.22556035220623016
[15/23] Train loss=0.1860157549381256
[20/23] Train loss=0.19959063827991486
Test set avg_accuracy=81.81% avg_sensitivity=59.74%, avg_specificity=89.31% avg_auc=0.8380
Fold[9] Epoch: 84 [84/100 (84%)] Train loss=0.221932 Test loss=0.523103 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21668164432048798
[5/23] Train loss=0.22062943875789642
[10/23] Train loss=0.21827615797519684
[15/23] Train loss=0.17987115681171417
[20/23] Train loss=0.19925203919410706
Test set avg_accuracy=82.23% avg_sensitivity=59.18%, avg_specificity=90.07% avg_auc=0.8354
Fold[9] Epoch: 85 [85/100 (85%)] Train loss=0.218943 Test loss=0.515405 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21871154010295868
[5/23] Train loss=0.24562685191631317
[10/23] Train loss=0.2267238199710846
[15/23] Train loss=0.18192866444587708
[20/23] Train loss=0.20653963088989258
Test set avg_accuracy=81.99% avg_sensitivity=59.93%, avg_specificity=89.50% avg_auc=0.8377
Fold[9] Epoch: 86 [86/100 (86%)] Train loss=0.218848 Test loss=0.522996 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21420586109161377
[5/23] Train loss=0.22229894995689392
[10/23] Train loss=0.22458259761333466
[15/23] Train loss=0.17207761108875275
[20/23] Train loss=0.19565194845199585
Test set avg_accuracy=82.01% avg_sensitivity=61.18%, avg_specificity=89.09% avg_auc=0.8370
Fold[9] Epoch: 87 [87/100 (87%)] Train loss=0.216807 Test loss=0.527549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22068139910697937
[5/23] Train loss=0.21831999719142914
[10/23] Train loss=0.22298677265644073
[15/23] Train loss=0.1829482614994049
[20/23] Train loss=0.21157220005989075
Test set avg_accuracy=82.21% avg_sensitivity=55.09%, avg_specificity=91.43% avg_auc=0.8329
Fold[9] Epoch: 88 [88/100 (88%)] Train loss=0.219266 Test loss=0.521166 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22001512348651886
[5/23] Train loss=0.2457103133201599
[10/23] Train loss=0.22972898185253143
[15/23] Train loss=0.1974698305130005
[20/23] Train loss=0.2056598663330078
Test set avg_accuracy=81.85% avg_sensitivity=55.09%, avg_specificity=90.96% avg_auc=0.8382
Fold[9] Epoch: 89 [89/100 (89%)] Train loss=0.226493 Test loss=0.530288 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2196841984987259
[5/23] Train loss=0.23381495475769043
[10/23] Train loss=0.22038261592388153
[15/23] Train loss=0.17708435654640198
[20/23] Train loss=0.1913224160671234
Test set avg_accuracy=81.71% avg_sensitivity=56.53%, avg_specificity=90.28% avg_auc=0.8345
Fold[9] Epoch: 90 [90/100 (90%)] Train loss=0.216075 Test loss=0.527541 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2174406498670578
[5/23] Train loss=0.22790537774562836
[10/23] Train loss=0.20521776378154755
[15/23] Train loss=0.168740913271904
[20/23] Train loss=0.19549639523029327
Test set avg_accuracy=82.01% avg_sensitivity=60.44%, avg_specificity=89.34% avg_auc=0.8343
Fold[9] Epoch: 91 [91/100 (91%)] Train loss=0.213116 Test loss=0.529588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20394040644168854
[5/23] Train loss=0.22061927616596222
[10/23] Train loss=0.20237433910369873
[15/23] Train loss=0.16610877215862274
[20/23] Train loss=0.1894456148147583
Test set avg_accuracy=81.66% avg_sensitivity=63.55%, avg_specificity=87.82% avg_auc=0.8339
Fold[9] Epoch: 92 [92/100 (92%)] Train loss=0.208441 Test loss=0.554099 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20540393888950348
[5/23] Train loss=0.21151044964790344
[10/23] Train loss=0.20457804203033447
[15/23] Train loss=0.16476766765117645
[20/23] Train loss=0.19050532579421997
Test set avg_accuracy=81.42% avg_sensitivity=64.57%, avg_specificity=87.14% avg_auc=0.8318
Fold[9] Epoch: 93 [93/100 (93%)] Train loss=0.204619 Test loss=0.549688 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21575865149497986
[5/23] Train loss=0.2145979255437851
[10/23] Train loss=0.208063542842865
[15/23] Train loss=0.16690105199813843
[20/23] Train loss=0.1905386745929718
Test set avg_accuracy=81.39% avg_sensitivity=60.02%, avg_specificity=88.66% avg_auc=0.8353
Fold[9] Epoch: 94 [94/100 (94%)] Train loss=0.203472 Test loss=0.549902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.205006942152977
[5/23] Train loss=0.21010370552539825
[10/23] Train loss=0.20031392574310303
[15/23] Train loss=0.16654197871685028
[20/23] Train loss=0.19112759828567505
Test set avg_accuracy=81.31% avg_sensitivity=60.53%, avg_specificity=88.38% avg_auc=0.8329
Fold[9] Epoch: 95 [95/100 (95%)] Train loss=0.202314 Test loss=0.536973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20484066009521484
[5/23] Train loss=0.2126653492450714
[10/23] Train loss=0.19570474326610565
[15/23] Train loss=0.1492871642112732
[20/23] Train loss=0.18827107548713684
Test set avg_accuracy=82.08% avg_sensitivity=58.58%, avg_specificity=90.07% avg_auc=0.8365
Fold[9] Epoch: 96 [96/100 (96%)] Train loss=0.201921 Test loss=0.545993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18500052392482758
[5/23] Train loss=0.20122180879116058
[10/23] Train loss=0.2010364681482315
[15/23] Train loss=0.15533867478370667
[20/23] Train loss=0.19964544475078583
Test set avg_accuracy=81.78% avg_sensitivity=58.34%, avg_specificity=89.75% avg_auc=0.8341
Fold[9] Epoch: 97 [97/100 (97%)] Train loss=0.197664 Test loss=0.558180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19398830831050873
[5/23] Train loss=0.2050912231206894
[10/23] Train loss=0.19622908532619476
[15/23] Train loss=0.1539507955312729
[20/23] Train loss=0.1800849586725235
Test set avg_accuracy=81.69% avg_sensitivity=51.88%, avg_specificity=91.82% avg_auc=0.8348
Fold[9] Epoch: 98 [98/100 (98%)] Train loss=0.199779 Test loss=0.563063 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19846111536026
[5/23] Train loss=0.2128327190876007
[10/23] Train loss=0.20029647648334503
[15/23] Train loss=0.1621001660823822
[20/23] Train loss=0.1862429976463318
Test set avg_accuracy=81.95% avg_sensitivity=52.39%, avg_specificity=92.00% avg_auc=0.8316
Fold[9] Epoch: 99 [99/100 (99%)] Train loss=0.197919 Test loss=0.546185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20503747463226318
[5/23] Train loss=0.20470787584781647
[10/23] Train loss=0.1928306668996811
[15/23] Train loss=0.1560146063566208
[20/23] Train loss=0.17621375620365143
Test set avg_accuracy=81.83% avg_sensitivity=56.21%, avg_specificity=90.54% avg_auc=0.8335
Fold[9] Epoch: 100 [100/100 (100%)] Train loss=0.198285 Test loss=0.553635 Current lr=[3.9999999999999996e-05]

Fold[9] Best Result: acc=82.12389380530973 sen=61.50627615062761, spe=89.13662239089184, auc=0.836790126887425!
[0/23] Train loss=0.7181662321090698
[5/23] Train loss=0.6888140439987183
[10/23] Train loss=0.5549305081367493
[15/23] Train loss=0.5778442025184631
[20/23] Train loss=0.6017982959747314
Test set avg_accuracy=77.55% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5486
Best model saved!! Metric=-93.58807036947869!!
Fold[10] Epoch: 1 [1/100 (1%)] Train loss=0.592417 Test loss=0.564711 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5627309679985046
[5/23] Train loss=0.6067144870758057
[10/23] Train loss=0.5274264216423035
[15/23] Train loss=0.5494990348815918
[20/23] Train loss=0.5900941491127014
Test set avg_accuracy=77.55% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5652
Best model saved!! Metric=-91.92919308616045!!
Fold[10] Epoch: 2 [2/100 (2%)] Train loss=0.558694 Test loss=0.548060 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5521474480628967
[5/23] Train loss=0.5785550475120544
[10/23] Train loss=0.5069818496704102
[15/23] Train loss=0.531045138835907
[20/23] Train loss=0.5807464718818665
Test set avg_accuracy=77.42% avg_sensitivity=1.64%, avg_specificity=99.35% avg_auc=0.6293
Best model saved!! Metric=-84.66004990996004!!
Fold[10] Epoch: 3 [3/100 (3%)] Train loss=0.541703 Test loss=0.557772 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5382121205329895
[5/23] Train loss=0.5423802733421326
[10/23] Train loss=0.49675342440605164
[15/23] Train loss=0.4885666072368622
[20/23] Train loss=0.5862014889717102
Test set avg_accuracy=77.99% avg_sensitivity=6.22%, avg_specificity=98.77% avg_auc=0.6729
Best model saved!! Metric=-75.73626409248844!!
Fold[10] Epoch: 4 [4/100 (4%)] Train loss=0.522654 Test loss=0.570821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5300655961036682
[5/23] Train loss=0.501276433467865
[10/23] Train loss=0.48651474714279175
[15/23] Train loss=0.4561331570148468
[20/23] Train loss=0.5823981165885925
Test set avg_accuracy=78.45% avg_sensitivity=9.76%, avg_specificity=98.33% avg_auc=0.7058
Best model saved!! Metric=-68.87014458633523!!
Fold[10] Epoch: 5 [5/100 (5%)] Train loss=0.502064 Test loss=0.557905 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5046265721321106
[5/23] Train loss=0.4725421369075775
[10/23] Train loss=0.4751528799533844
[15/23] Train loss=0.44466066360473633
[20/23] Train loss=0.564688503742218
Test set avg_accuracy=79.40% avg_sensitivity=15.06%, avg_specificity=98.02% avg_auc=0.7442
Best model saved!! Metric=-59.10339181454481!!
Fold[10] Epoch: 6 [6/100 (6%)] Train loss=0.482012 Test loss=0.544742 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4651753902435303
[5/23] Train loss=0.4582783579826355
[10/23] Train loss=0.4738650918006897
[15/23] Train loss=0.43470460176467896
[20/23] Train loss=0.551001787185669
Test set avg_accuracy=79.88% avg_sensitivity=19.17%, avg_specificity=97.46% avg_auc=0.7628
Best model saved!! Metric=-53.2086976066187!!
Fold[10] Epoch: 7 [7/100 (7%)] Train loss=0.467022 Test loss=0.525728 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4468696415424347
[5/23] Train loss=0.4510713517665863
[10/23] Train loss=0.470703661441803
[15/23] Train loss=0.4236445128917694
[20/23] Train loss=0.556658923625946
Test set avg_accuracy=80.27% avg_sensitivity=20.66%, avg_specificity=97.52% avg_auc=0.7704
Best model saved!! Metric=-50.524565320497445!!
Fold[10] Epoch: 8 [8/100 (8%)] Train loss=0.459270 Test loss=0.518849 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44232887029647827
[5/23] Train loss=0.44582951068878174
[10/23] Train loss=0.4880806505680084
[15/23] Train loss=0.42676690220832825
[20/23] Train loss=0.5405853390693665
Test set avg_accuracy=80.70% avg_sensitivity=22.56%, avg_specificity=97.53% avg_auc=0.7847
Best model saved!! Metric=-46.7339970930947!!
Fold[10] Epoch: 9 [9/100 (9%)] Train loss=0.451646 Test loss=0.514855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4370327293872833
[5/23] Train loss=0.4346638321876526
[10/23] Train loss=0.4726622998714447
[15/23] Train loss=0.43390369415283203
[20/23] Train loss=0.5131416916847229
Test set avg_accuracy=81.05% avg_sensitivity=26.52%, avg_specificity=96.83% avg_auc=0.8047
Best model saved!! Metric=-41.13049794301257!!
Fold[10] Epoch: 10 [10/100 (10%)] Train loss=0.442095 Test loss=0.479788 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42183756828308105
[5/23] Train loss=0.42951223254203796
[10/23] Train loss=0.4649134576320648
[15/23] Train loss=0.41433730721473694
[20/23] Train loss=0.5085653066635132
Test set avg_accuracy=80.98% avg_sensitivity=28.78%, avg_specificity=96.09% avg_auc=0.8088
Best model saved!! Metric=-39.271583249299965!!
Fold[10] Epoch: 11 [11/100 (11%)] Train loss=0.433078 Test loss=0.475879 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42202022671699524
[5/23] Train loss=0.4236350953578949
[10/23] Train loss=0.4685971736907959
[15/23] Train loss=0.408088743686676
[20/23] Train loss=0.5178593397140503
Test set avg_accuracy=81.20% avg_sensitivity=28.83%, avg_specificity=96.36% avg_auc=0.8090
Best model saved!! Metric=-38.720672774106006!!
Fold[10] Epoch: 12 [12/100 (12%)] Train loss=0.428594 Test loss=0.489383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40935200452804565
[5/23] Train loss=0.41932711005210876
[10/23] Train loss=0.4680115580558777
[15/23] Train loss=0.4036925435066223
[20/23] Train loss=0.5324574112892151
Test set avg_accuracy=80.97% avg_sensitivity=27.95%, avg_specificity=96.31% avg_auc=0.8108
Fold[10] Epoch: 13 [13/100 (13%)] Train loss=0.431886 Test loss=0.482286 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.414644718170166
[5/23] Train loss=0.4170713722705841
[10/23] Train loss=0.47464922070503235
[15/23] Train loss=0.41750121116638184
[20/23] Train loss=0.49778664112091064
Test set avg_accuracy=81.49% avg_sensitivity=31.50%, avg_specificity=95.95% avg_auc=0.8224
Best model saved!! Metric=-34.82076717532676!!
Fold[10] Epoch: 14 [14/100 (14%)] Train loss=0.426153 Test loss=0.458312 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40809234976768494
[5/23] Train loss=0.40955784916877747
[10/23] Train loss=0.45351463556289673
[15/23] Train loss=0.4034276604652405
[20/23] Train loss=0.4879845678806305
Test set avg_accuracy=81.93% avg_sensitivity=34.84%, avg_specificity=95.55% avg_auc=0.8273
Best model saved!! Metric=-30.948280119937188!!
Fold[10] Epoch: 15 [15/100 (15%)] Train loss=0.420289 Test loss=0.436745 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41594207286834717
[5/23] Train loss=0.4136209487915039
[10/23] Train loss=0.4546099007129669
[15/23] Train loss=0.39196985960006714
[20/23] Train loss=0.4991376996040344
Test set avg_accuracy=81.56% avg_sensitivity=33.92%, avg_specificity=95.35% avg_auc=0.8268
Fold[10] Epoch: 16 [16/100 (16%)] Train loss=0.415152 Test loss=0.440764 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40124472975730896
[5/23] Train loss=0.40653249621391296
[10/23] Train loss=0.4557848274707794
[15/23] Train loss=0.3925301432609558
[20/23] Train loss=0.4928695261478424
Test set avg_accuracy=81.91% avg_sensitivity=35.20%, avg_specificity=95.43% avg_auc=0.8305
Best model saved!! Metric=-30.405121501025192!!
Fold[10] Epoch: 17 [17/100 (17%)] Train loss=0.411776 Test loss=0.437576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39986327290534973
[5/23] Train loss=0.4065559208393097
[10/23] Train loss=0.4576208293437958
[15/23] Train loss=0.3874305486679077
[20/23] Train loss=0.5109344720840454
Test set avg_accuracy=81.83% avg_sensitivity=34.74%, avg_specificity=95.46% avg_auc=0.8249
Fold[10] Epoch: 18 [18/100 (18%)] Train loss=0.411560 Test loss=0.442460 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3995824456214905
[5/23] Train loss=0.4029664397239685
[10/23] Train loss=0.4542105495929718
[15/23] Train loss=0.39332085847854614
[20/23] Train loss=0.4989655613899231
Test set avg_accuracy=81.87% avg_sensitivity=36.23%, avg_specificity=95.08% avg_auc=0.8327
Best model saved!! Metric=-29.558557128757286!!
Fold[10] Epoch: 19 [19/100 (19%)] Train loss=0.409398 Test loss=0.434748 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39558571577072144
[5/23] Train loss=0.4028559923171997
[10/23] Train loss=0.44429445266723633
[15/23] Train loss=0.3788594901561737
[20/23] Train loss=0.49487170577049255
Test set avg_accuracy=82.53% avg_sensitivity=40.65%, avg_specificity=94.65% avg_auc=0.8391
Best model saved!! Metric=-24.26743829123868!!
Fold[10] Epoch: 20 [20/100 (20%)] Train loss=0.406338 Test loss=0.423759 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3951670229434967
[5/23] Train loss=0.3983953893184662
[10/23] Train loss=0.44325879216194153
[15/23] Train loss=0.3787534534931183
[20/23] Train loss=0.4961640536785126
Test set avg_accuracy=82.18% avg_sensitivity=38.75%, avg_specificity=94.75% avg_auc=0.8322
Fold[10] Epoch: 21 [21/100 (21%)] Train loss=0.401122 Test loss=0.441131 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3871019184589386
[5/23] Train loss=0.3897966742515564
[10/23] Train loss=0.44446584582328796
[15/23] Train loss=0.37162184715270996
[20/23] Train loss=0.5069084763526917
Test set avg_accuracy=82.41% avg_sensitivity=39.47%, avg_specificity=94.84% avg_auc=0.8397
Fold[10] Epoch: 22 [22/100 (22%)] Train loss=0.399963 Test loss=0.433994 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3856070041656494
[5/23] Train loss=0.3972640931606293
[10/23] Train loss=0.4424421489238739
[15/23] Train loss=0.38375693559646606
[20/23] Train loss=0.4878118634223938
Test set avg_accuracy=81.75% avg_sensitivity=34.28%, avg_specificity=95.49% avg_auc=0.8356
Fold[10] Epoch: 23 [23/100 (23%)] Train loss=0.399250 Test loss=0.448306 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3849002420902252
[5/23] Train loss=0.3974659740924835
[10/23] Train loss=0.4397803544998169
[15/23] Train loss=0.37662819027900696
[20/23] Train loss=0.45592808723449707
Test set avg_accuracy=82.71% avg_sensitivity=43.06%, avg_specificity=94.19% avg_auc=0.8467
Best model saved!! Metric=-21.373210268150636!!
Fold[10] Epoch: 24 [24/100 (24%)] Train loss=0.393034 Test loss=0.411327 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3852420747280121
[5/23] Train loss=0.39001208543777466
[10/23] Train loss=0.43444502353668213
[15/23] Train loss=0.3669935464859009
[20/23] Train loss=0.48326581716537476
Test set avg_accuracy=82.93% avg_sensitivity=42.09%, avg_specificity=94.75% avg_auc=0.8499
Best model saved!! Metric=-21.241164157571028!!
Fold[10] Epoch: 25 [25/100 (25%)] Train loss=0.389025 Test loss=0.401574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3799643814563751
[5/23] Train loss=0.3829922378063202
[10/23] Train loss=0.4265715181827545
[15/23] Train loss=0.36739978194236755
[20/23] Train loss=0.4782736003398895
Test set avg_accuracy=82.91% avg_sensitivity=42.70%, avg_specificity=94.54% avg_auc=0.8512
Best model saved!! Metric=-20.72592485811014!!
Fold[10] Epoch: 26 [26/100 (26%)] Train loss=0.386212 Test loss=0.409708 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3698942959308624
[5/23] Train loss=0.38667798042297363
[10/23] Train loss=0.43646079301834106
[15/23] Train loss=0.37080278992652893
[20/23] Train loss=0.4602479040622711
Test set avg_accuracy=82.76% avg_sensitivity=42.29%, avg_specificity=94.47% avg_auc=0.8453
Fold[10] Epoch: 27 [27/100 (27%)] Train loss=0.385340 Test loss=0.411390 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3696274757385254
[5/23] Train loss=0.38607320189476013
[10/23] Train loss=0.42766818404197693
[15/23] Train loss=0.3602311611175537
[20/23] Train loss=0.4621145725250244
Test set avg_accuracy=82.95% avg_sensitivity=44.30%, avg_specificity=94.14% avg_auc=0.8541
Best model saved!! Metric=-19.1976074582229!!
Fold[10] Epoch: 28 [28/100 (28%)] Train loss=0.382504 Test loss=0.401313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3747134208679199
[5/23] Train loss=0.38345104455947876
[10/23] Train loss=0.42556580901145935
[15/23] Train loss=0.3533611595630646
[20/23] Train loss=0.459248423576355
Test set avg_accuracy=82.95% avg_sensitivity=44.66%, avg_specificity=94.04% avg_auc=0.8552
Best model saved!! Metric=-18.838090109070027!!
Fold[10] Epoch: 29 [29/100 (29%)] Train loss=0.381282 Test loss=0.404021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3652278482913971
[5/23] Train loss=0.37813714146614075
[10/23] Train loss=0.4275064170360565
[15/23] Train loss=0.3535875678062439
[20/23] Train loss=0.4776202142238617
Test set avg_accuracy=82.53% avg_sensitivity=45.17%, avg_specificity=93.34% avg_auc=0.8388
Fold[10] Epoch: 30 [30/100 (30%)] Train loss=0.376668 Test loss=0.427035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3718932271003723
[5/23] Train loss=0.3745219111442566
[10/23] Train loss=0.42397356033325195
[15/23] Train loss=0.34776753187179565
[20/23] Train loss=0.4823363423347473
Test set avg_accuracy=82.60% avg_sensitivity=44.40%, avg_specificity=93.65% avg_auc=0.8538
Fold[10] Epoch: 31 [31/100 (31%)] Train loss=0.374184 Test loss=0.413044 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3658258318901062
[5/23] Train loss=0.3775261640548706
[10/23] Train loss=0.43432027101516724
[15/23] Train loss=0.3492218255996704
[20/23] Train loss=0.45924168825149536
Test set avg_accuracy=82.85% avg_sensitivity=40.34%, avg_specificity=95.15% avg_auc=0.8475
Fold[10] Epoch: 32 [32/100 (32%)] Train loss=0.374972 Test loss=0.413773 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3624482750892639
[5/23] Train loss=0.3755558133125305
[10/23] Train loss=0.41278618574142456
[15/23] Train loss=0.3411763906478882
[20/23] Train loss=0.43863749504089355
Test set avg_accuracy=83.31% avg_sensitivity=47.48%, avg_specificity=93.68% avg_auc=0.8591
Best model saved!! Metric=-15.618080236802712!!
Fold[10] Epoch: 33 [33/100 (33%)] Train loss=0.368590 Test loss=0.386591 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36220958828926086
[5/23] Train loss=0.3709714710712433
[10/23] Train loss=0.41481253504753113
[15/23] Train loss=0.3406164348125458
[20/23] Train loss=0.4565671682357788
Test set avg_accuracy=83.44% avg_sensitivity=47.43%, avg_specificity=93.86% avg_auc=0.8580
Best model saved!! Metric=-15.472780144238076!!
Fold[10] Epoch: 34 [34/100 (34%)] Train loss=0.365573 Test loss=0.394484 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3563584089279175
[5/23] Train loss=0.36517149209976196
[10/23] Train loss=0.4032277762889862
[15/23] Train loss=0.3286779522895813
[20/23] Train loss=0.4549778699874878
Test set avg_accuracy=82.72% avg_sensitivity=46.15%, avg_specificity=93.31% avg_auc=0.8544
Fold[10] Epoch: 35 [35/100 (35%)] Train loss=0.362413 Test loss=0.410796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35714754462242126
[5/23] Train loss=0.3726475238800049
[10/23] Train loss=0.41179358959198
[15/23] Train loss=0.3315472900867462
[20/23] Train loss=0.43228837847709656
Test set avg_accuracy=82.80% avg_sensitivity=48.15%, avg_specificity=92.83% avg_auc=0.8580
Fold[10] Epoch: 36 [36/100 (36%)] Train loss=0.360230 Test loss=0.406689 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35267993807792664
[5/23] Train loss=0.36335134506225586
[10/23] Train loss=0.39634108543395996
[15/23] Train loss=0.32458528876304626
[20/23] Train loss=0.4361661672592163
Test set avg_accuracy=83.46% avg_sensitivity=52.62%, avg_specificity=92.39% avg_auc=0.8599
Best model saved!! Metric=-11.543699485371386!!
Fold[10] Epoch: 37 [37/100 (37%)] Train loss=0.356028 Test loss=0.393162 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34910547733306885
[5/23] Train loss=0.3613361120223999
[10/23] Train loss=0.39418864250183105
[15/23] Train loss=0.3229416608810425
[20/23] Train loss=0.4499358832836151
Test set avg_accuracy=83.30% avg_sensitivity=52.98%, avg_specificity=92.07% avg_auc=0.8597
Fold[10] Epoch: 38 [38/100 (38%)] Train loss=0.353071 Test loss=0.402657 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34573689103126526
[5/23] Train loss=0.36470603942871094
[10/23] Train loss=0.3967873454093933
[15/23] Train loss=0.3215700387954712
[20/23] Train loss=0.44704827666282654
Test set avg_accuracy=83.48% avg_sensitivity=49.95%, avg_specificity=93.19% avg_auc=0.8596
Fold[10] Epoch: 39 [39/100 (39%)] Train loss=0.353601 Test loss=0.395417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3501121699810028
[5/23] Train loss=0.35101261734962463
[10/23] Train loss=0.3894072473049164
[15/23] Train loss=0.32184138894081116
[20/23] Train loss=0.46235066652297974
Test set avg_accuracy=83.26% avg_sensitivity=46.56%, avg_specificity=93.89% avg_auc=0.8592
Fold[10] Epoch: 40 [40/100 (40%)] Train loss=0.351741 Test loss=0.398426 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34293845295906067
[5/23] Train loss=0.3574608862400055
[10/23] Train loss=0.41801515221595764
[15/23] Train loss=0.32794496417045593
[20/23] Train loss=0.4301002025604248
Test set avg_accuracy=83.25% avg_sensitivity=44.50%, avg_specificity=94.47% avg_auc=0.8597
Fold[10] Epoch: 41 [41/100 (41%)] Train loss=0.352972 Test loss=0.395112 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34762176871299744
[5/23] Train loss=0.35766535997390747
[10/23] Train loss=0.3887373208999634
[15/23] Train loss=0.32445433735847473
[20/23] Train loss=0.40965035557746887
Test set avg_accuracy=82.86% avg_sensitivity=47.53%, avg_specificity=93.08% avg_auc=0.8624
Fold[10] Epoch: 42 [42/100 (42%)] Train loss=0.350814 Test loss=0.399368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3378911316394806
[5/23] Train loss=0.3522234559059143
[10/23] Train loss=0.38682126998901367
[15/23] Train loss=0.3221436142921448
[20/23] Train loss=0.43184903264045715
Test set avg_accuracy=83.58% avg_sensitivity=53.08%, avg_specificity=92.40% avg_auc=0.8658
Best model saved!! Metric=-10.358087718740535!!
Fold[10] Epoch: 43 [43/100 (43%)] Train loss=0.348216 Test loss=0.386121 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33660298585891724
[5/23] Train loss=0.35046836733818054
[10/23] Train loss=0.3784342110157013
[15/23] Train loss=0.31941160559654236
[20/23] Train loss=0.4130280315876007
Test set avg_accuracy=82.81% avg_sensitivity=48.51%, avg_specificity=92.74% avg_auc=0.8530
Fold[10] Epoch: 44 [44/100 (44%)] Train loss=0.342984 Test loss=0.424700 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33353450894355774
[5/23] Train loss=0.34464141726493835
[10/23] Train loss=0.3765257000923157
[15/23] Train loss=0.3041967451572418
[20/23] Train loss=0.425295889377594
Test set avg_accuracy=83.48% avg_sensitivity=54.37%, avg_specificity=91.91% avg_auc=0.8560
Fold[10] Epoch: 45 [45/100 (45%)] Train loss=0.340067 Test loss=0.396239 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3387385308742523
[5/23] Train loss=0.3389304578304291
[10/23] Train loss=0.37770700454711914
[15/23] Train loss=0.3064230680465698
[20/23] Train loss=0.4216892123222351
Test set avg_accuracy=82.80% avg_sensitivity=45.02%, avg_specificity=93.74% avg_auc=0.8557
Fold[10] Epoch: 46 [46/100 (46%)] Train loss=0.338043 Test loss=0.410268 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33024680614471436
[5/23] Train loss=0.3428768515586853
[10/23] Train loss=0.3765679597854614
[15/23] Train loss=0.30084025859832764
[20/23] Train loss=0.4274292290210724
Test set avg_accuracy=82.87% avg_sensitivity=47.17%, avg_specificity=93.20% avg_auc=0.8624
Fold[10] Epoch: 47 [47/100 (47%)] Train loss=0.337619 Test loss=0.395793 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33006927371025085
[5/23] Train loss=0.33498305082321167
[10/23] Train loss=0.37014660239219666
[15/23] Train loss=0.30683767795562744
[20/23] Train loss=0.3971426784992218
Test set avg_accuracy=83.25% avg_sensitivity=49.38%, avg_specificity=93.05% avg_auc=0.8594
Fold[10] Epoch: 48 [48/100 (48%)] Train loss=0.332160 Test loss=0.404466 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32330214977264404
[5/23] Train loss=0.3300112783908844
[10/23] Train loss=0.36640211939811707
[15/23] Train loss=0.2995242476463318
[20/23] Train loss=0.39771953225135803
Test set avg_accuracy=83.09% avg_sensitivity=49.49%, avg_specificity=92.82% avg_auc=0.8600
Fold[10] Epoch: 49 [49/100 (49%)] Train loss=0.331862 Test loss=0.413546 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32265231013298035
[5/23] Train loss=0.3346560597419739
[10/23] Train loss=0.364283949136734
[15/23] Train loss=0.2981037199497223
[20/23] Train loss=0.40271690487861633
Test set avg_accuracy=82.92% avg_sensitivity=51.13%, avg_specificity=92.12% avg_auc=0.8527
Fold[10] Epoch: 50 [50/100 (50%)] Train loss=0.329092 Test loss=0.402479 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32514727115631104
[5/23] Train loss=0.3283156454563141
[10/23] Train loss=0.35890424251556396
[15/23] Train loss=0.29188254475593567
[20/23] Train loss=0.40329161286354065
Test set avg_accuracy=83.30% avg_sensitivity=51.49%, avg_specificity=92.50% avg_auc=0.8575
Fold[10] Epoch: 51 [51/100 (51%)] Train loss=0.325847 Test loss=0.406516 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32025930285453796
[5/23] Train loss=0.31839263439178467
[10/23] Train loss=0.3520270884037018
[15/23] Train loss=0.28656116127967834
[20/23] Train loss=0.3925599753856659
Test set avg_accuracy=83.24% avg_sensitivity=49.90%, avg_specificity=92.89% avg_auc=0.8632
Fold[10] Epoch: 52 [52/100 (52%)] Train loss=0.322185 Test loss=0.408855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3138158321380615
[5/23] Train loss=0.33196526765823364
[10/23] Train loss=0.3493134081363678
[15/23] Train loss=0.28716763854026794
[20/23] Train loss=0.4034777879714966
Test set avg_accuracy=83.89% avg_sensitivity=55.34%, avg_specificity=92.15% avg_auc=0.8611
Best model saved!! Metric=-8.510104455079144!!
Fold[10] Epoch: 53 [53/100 (53%)] Train loss=0.318410 Test loss=0.406795 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30699533224105835
[5/23] Train loss=0.3158811926841736
[10/23] Train loss=0.34805595874786377
[15/23] Train loss=0.28109481930732727
[20/23] Train loss=0.39962512254714966
Test set avg_accuracy=83.32% avg_sensitivity=51.54%, avg_specificity=92.52% avg_auc=0.8619
Fold[10] Epoch: 54 [54/100 (54%)] Train loss=0.315158 Test loss=0.409416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3162470757961273
[5/23] Train loss=0.31599605083465576
[10/23] Train loss=0.34830886125564575
[15/23] Train loss=0.2706352174282074
[20/23] Train loss=0.40300413966178894
Test set avg_accuracy=83.44% avg_sensitivity=51.13%, avg_specificity=92.79% avg_auc=0.8515
Fold[10] Epoch: 55 [55/100 (55%)] Train loss=0.312316 Test loss=0.414769 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.308975487947464
[5/23] Train loss=0.3180323839187622
[10/23] Train loss=0.34658318758010864
[15/23] Train loss=0.2676740288734436
[20/23] Train loss=0.399624228477478
Test set avg_accuracy=82.92% avg_sensitivity=50.51%, avg_specificity=92.30% avg_auc=0.8423
Fold[10] Epoch: 56 [56/100 (56%)] Train loss=0.312338 Test loss=0.416132 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3040875196456909
[5/23] Train loss=0.31086012721061707
[10/23] Train loss=0.33955350518226624
[15/23] Train loss=0.2807130217552185
[20/23] Train loss=0.3890339434146881
Test set avg_accuracy=82.92% avg_sensitivity=49.38%, avg_specificity=92.62% avg_auc=0.8491
Fold[10] Epoch: 57 [57/100 (57%)] Train loss=0.313086 Test loss=0.419999 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3076328933238983
[5/23] Train loss=0.31839245557785034
[10/23] Train loss=0.3291317820549011
[15/23] Train loss=0.2749282419681549
[20/23] Train loss=0.37770605087280273
Test set avg_accuracy=83.38% avg_sensitivity=54.16%, avg_specificity=91.84% avg_auc=0.8605
Fold[10] Epoch: 58 [58/100 (58%)] Train loss=0.309764 Test loss=0.409668 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3050517439842224
[5/23] Train loss=0.3064756989479065
[10/23] Train loss=0.32697775959968567
[15/23] Train loss=0.27021312713623047
[20/23] Train loss=0.37599751353263855
Test set avg_accuracy=83.63% avg_sensitivity=53.75%, avg_specificity=92.28% avg_auc=0.8549
Fold[10] Epoch: 59 [59/100 (59%)] Train loss=0.303117 Test loss=0.427260 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2937265634536743
[5/23] Train loss=0.30941206216812134
[10/23] Train loss=0.32309114933013916
[15/23] Train loss=0.2599763572216034
[20/23] Train loss=0.3757891058921814
Test set avg_accuracy=83.53% avg_sensitivity=57.25%, avg_specificity=91.14% avg_auc=0.8554
Fold[10] Epoch: 60 [60/100 (60%)] Train loss=0.300706 Test loss=0.424591 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29864051938056946
[5/23] Train loss=0.3039703071117401
[10/23] Train loss=0.32109129428863525
[15/23] Train loss=0.26584890484809875
[20/23] Train loss=0.3789777457714081
Test set avg_accuracy=83.48% avg_sensitivity=55.29%, avg_specificity=91.64% avg_auc=0.8409
Fold[10] Epoch: 61 [61/100 (61%)] Train loss=0.300705 Test loss=0.434208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29225704073905945
[5/23] Train loss=0.29671671986579895
[10/23] Train loss=0.32108455896377563
[15/23] Train loss=0.25125813484191895
[20/23] Train loss=0.38359811902046204
Test set avg_accuracy=83.28% avg_sensitivity=53.75%, avg_specificity=91.82% avg_auc=0.8628
Fold[10] Epoch: 62 [62/100 (62%)] Train loss=0.299554 Test loss=0.429092 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29088327288627625
[5/23] Train loss=0.28884831070899963
[10/23] Train loss=0.31722673773765564
[15/23] Train loss=0.24766063690185547
[20/23] Train loss=0.40051397681236267
Test set avg_accuracy=83.93% avg_sensitivity=50.21%, avg_specificity=93.69% avg_auc=0.8508
Fold[10] Epoch: 63 [63/100 (63%)] Train loss=0.299667 Test loss=0.412568 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2978452742099762
[5/23] Train loss=0.2920542061328888
[10/23] Train loss=0.3291808068752289
[15/23] Train loss=0.26323679089546204
[20/23] Train loss=0.38264042139053345
Test set avg_accuracy=83.24% avg_sensitivity=45.53%, avg_specificity=94.16% avg_auc=0.8452
Fold[10] Epoch: 64 [64/100 (64%)] Train loss=0.300173 Test loss=0.411138 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3062494099140167
[5/23] Train loss=0.30527082085609436
[10/23] Train loss=0.321745902299881
[15/23] Train loss=0.2722114622592926
[20/23] Train loss=0.3771277666091919
Test set avg_accuracy=82.96% avg_sensitivity=47.12%, avg_specificity=93.34% avg_auc=0.8535
Fold[10] Epoch: 65 [65/100 (65%)] Train loss=0.304840 Test loss=0.418845 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29154542088508606
[5/23] Train loss=0.3054664433002472
[10/23] Train loss=0.3060460686683655
[15/23] Train loss=0.2526935636997223
[20/23] Train loss=0.35290858149528503
Test set avg_accuracy=83.55% avg_sensitivity=52.31%, avg_specificity=92.59% avg_auc=0.8602
Fold[10] Epoch: 66 [66/100 (66%)] Train loss=0.293712 Test loss=0.439693 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2799724042415619
[5/23] Train loss=0.286845862865448
[10/23] Train loss=0.30152690410614014
[15/23] Train loss=0.23611114919185638
[20/23] Train loss=0.39618197083473206
Test set avg_accuracy=83.15% avg_sensitivity=52.57%, avg_specificity=92.00% avg_auc=0.8442
Fold[10] Epoch: 67 [67/100 (67%)] Train loss=0.287949 Test loss=0.435920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28094029426574707
[5/23] Train loss=0.2793116867542267
[10/23] Train loss=0.2883751392364502
[15/23] Train loss=0.23901963233947754
[20/23] Train loss=0.37336981296539307
Test set avg_accuracy=84.06% avg_sensitivity=51.59%, avg_specificity=93.46% avg_auc=0.8546
Fold[10] Epoch: 68 [68/100 (68%)] Train loss=0.284544 Test loss=0.424619 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28544875979423523
[5/23] Train loss=0.2742123603820801
[10/23] Train loss=0.3075621426105499
[15/23] Train loss=0.25493213534355164
[20/23] Train loss=0.3724965751171112
Test set avg_accuracy=83.48% avg_sensitivity=45.02%, avg_specificity=94.62% avg_auc=0.8448
Fold[10] Epoch: 69 [69/100 (69%)] Train loss=0.285490 Test loss=0.433357 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28399938344955444
[5/23] Train loss=0.2917935848236084
[10/23] Train loss=0.306220144033432
[15/23] Train loss=0.2722204327583313
[20/23] Train loss=0.3898978531360626
Test set avg_accuracy=82.21% avg_sensitivity=35.77%, avg_specificity=95.66% avg_auc=0.8483
Fold[10] Epoch: 70 [70/100 (70%)] Train loss=0.299529 Test loss=0.435306 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28634193539619446
[5/23] Train loss=0.3025330603122711
[10/23] Train loss=0.30597984790802
[15/23] Train loss=0.25195711851119995
[20/23] Train loss=0.363154798746109
Test set avg_accuracy=84.24% avg_sensitivity=54.27%, avg_specificity=92.92% avg_auc=0.8474
Fold[10] Epoch: 71 [71/100 (71%)] Train loss=0.295159 Test loss=0.418065 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27796003222465515
[5/23] Train loss=0.29576870799064636
[10/23] Train loss=0.3055093586444855
[15/23] Train loss=0.25577512383461
[20/23] Train loss=0.3628355860710144
Test set avg_accuracy=83.30% avg_sensitivity=50.51%, avg_specificity=92.79% avg_auc=0.8532
Fold[10] Epoch: 72 [72/100 (72%)] Train loss=0.289511 Test loss=0.441887 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2786114513874054
[5/23] Train loss=0.28705334663391113
[10/23] Train loss=0.2858910858631134
[15/23] Train loss=0.24038052558898926
[20/23] Train loss=0.3526635468006134
Test set avg_accuracy=83.18% avg_sensitivity=52.16%, avg_specificity=92.16% avg_auc=0.8351
Fold[10] Epoch: 73 [73/100 (73%)] Train loss=0.281721 Test loss=0.447975 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.268423467874527
[5/23] Train loss=0.2817291021347046
[10/23] Train loss=0.2812395989894867
[15/23] Train loss=0.23957142233848572
[20/23] Train loss=0.34487053751945496
Test set avg_accuracy=83.16% avg_sensitivity=48.30%, avg_specificity=93.25% avg_auc=0.8453
Fold[10] Epoch: 74 [74/100 (74%)] Train loss=0.278995 Test loss=0.444465 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2844436764717102
[5/23] Train loss=0.2758839726448059
[10/23] Train loss=0.27672070264816284
[15/23] Train loss=0.23302116990089417
[20/23] Train loss=0.35548168420791626
Test set avg_accuracy=83.17% avg_sensitivity=58.43%, avg_specificity=90.33% avg_auc=0.8206
Fold[10] Epoch: 75 [75/100 (75%)] Train loss=0.275468 Test loss=0.452039 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27121180295944214
[5/23] Train loss=0.27044564485549927
[10/23] Train loss=0.2768215835094452
[15/23] Train loss=0.227194681763649
[20/23] Train loss=0.34142008423805237
Test set avg_accuracy=83.51% avg_sensitivity=54.32%, avg_specificity=91.95% avg_auc=0.8557
Fold[10] Epoch: 76 [76/100 (76%)] Train loss=0.270791 Test loss=0.460358 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25811535120010376
[5/23] Train loss=0.26310503482818604
[10/23] Train loss=0.28358086943626404
[15/23] Train loss=0.22521629929542542
[20/23] Train loss=0.3524772822856903
Test set avg_accuracy=83.26% avg_sensitivity=56.94%, avg_specificity=90.88% avg_auc=0.8467
Fold[10] Epoch: 77 [77/100 (77%)] Train loss=0.268472 Test loss=0.444758 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25206243991851807
[5/23] Train loss=0.2721845805644989
[10/23] Train loss=0.2595463693141937
[15/23] Train loss=0.22430860996246338
[20/23] Train loss=0.31905597448349
Test set avg_accuracy=83.79% avg_sensitivity=54.16%, avg_specificity=92.37% avg_auc=0.8507
Fold[10] Epoch: 78 [78/100 (78%)] Train loss=0.263110 Test loss=0.449913 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2654111981391907
[5/23] Train loss=0.2617082893848419
[10/23] Train loss=0.2670598030090332
[15/23] Train loss=0.21561263501644135
[20/23] Train loss=0.33713316917419434
Test set avg_accuracy=83.54% avg_sensitivity=57.40%, avg_specificity=91.11% avg_auc=0.8449
Fold[10] Epoch: 79 [79/100 (79%)] Train loss=0.261001 Test loss=0.442671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2675829529762268
[5/23] Train loss=0.26695457100868225
[10/23] Train loss=0.2623027265071869
[15/23] Train loss=0.21943698823451996
[20/23] Train loss=0.3187248110771179
Test set avg_accuracy=83.28% avg_sensitivity=55.76%, avg_specificity=91.24% avg_auc=0.8418
Fold[10] Epoch: 80 [80/100 (80%)] Train loss=0.259525 Test loss=0.464230 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24685902893543243
[5/23] Train loss=0.2509598135948181
[10/23] Train loss=0.26105284690856934
[15/23] Train loss=0.20555971562862396
[20/23] Train loss=0.33282604813575745
Test set avg_accuracy=82.87% avg_sensitivity=58.17%, avg_specificity=90.02% avg_auc=0.8401
Fold[10] Epoch: 81 [81/100 (81%)] Train loss=0.255877 Test loss=0.464762 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2437821328639984
[5/23] Train loss=0.2446802407503128
[10/23] Train loss=0.25006458163261414
[15/23] Train loss=0.20837266743183136
[20/23] Train loss=0.31293708086013794
Test set avg_accuracy=83.54% avg_sensitivity=52.83%, avg_specificity=92.43% avg_auc=0.8472
Fold[10] Epoch: 82 [82/100 (82%)] Train loss=0.249437 Test loss=0.478577 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2495996356010437
[5/23] Train loss=0.24851039052009583
[10/23] Train loss=0.2576516270637512
[15/23] Train loss=0.20969614386558533
[20/23] Train loss=0.31936702132225037
Test set avg_accuracy=83.79% avg_sensitivity=56.68%, avg_specificity=91.64% avg_auc=0.8513
Fold[10] Epoch: 83 [83/100 (83%)] Train loss=0.249812 Test loss=0.463474 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24101729691028595
[5/23] Train loss=0.247430682182312
[10/23] Train loss=0.2458040714263916
[15/23] Train loss=0.19847053289413452
[20/23] Train loss=0.3213553726673126
Test set avg_accuracy=83.28% avg_sensitivity=59.04%, avg_specificity=90.29% avg_auc=0.8321
Fold[10] Epoch: 84 [84/100 (84%)] Train loss=0.246386 Test loss=0.465510 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2422284632921219
[5/23] Train loss=0.23217308521270752
[10/23] Train loss=0.2506815791130066
[15/23] Train loss=0.20187489688396454
[20/23] Train loss=0.3124406635761261
Test set avg_accuracy=82.94% avg_sensitivity=52.16%, avg_specificity=91.85% avg_auc=0.8340
Fold[10] Epoch: 85 [85/100 (85%)] Train loss=0.246104 Test loss=0.476006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23969011008739471
[5/23] Train loss=0.24015915393829346
[10/23] Train loss=0.24067653715610504
[15/23] Train loss=0.19662266969680786
[20/23] Train loss=0.30932796001434326
Test set avg_accuracy=82.76% avg_sensitivity=56.94%, avg_specificity=90.23% avg_auc=0.8348
Fold[10] Epoch: 86 [86/100 (86%)] Train loss=0.241224 Test loss=0.479796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2330007553100586
[5/23] Train loss=0.24352575838565826
[10/23] Train loss=0.24010463058948517
[15/23] Train loss=0.1999853253364563
[20/23] Train loss=0.3450641632080078
Test set avg_accuracy=83.55% avg_sensitivity=60.17%, avg_specificity=90.32% avg_auc=0.8448
Best model saved!! Metric=-7.4719597983161385!!
Fold[10] Epoch: 87 [87/100 (87%)] Train loss=0.243089 Test loss=0.465208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2288106381893158
[5/23] Train loss=0.2337023913860321
[10/23] Train loss=0.24427564442157745
[15/23] Train loss=0.19993983209133148
[20/23] Train loss=0.32091784477233887
Test set avg_accuracy=83.08% avg_sensitivity=57.91%, avg_specificity=90.36% avg_auc=0.8281
Fold[10] Epoch: 88 [88/100 (88%)] Train loss=0.244742 Test loss=0.473489 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24193774163722992
[5/23] Train loss=0.2509981691837311
[10/23] Train loss=0.26695945858955383
[15/23] Train loss=0.20693455636501312
[20/23] Train loss=0.29761555790901184
Test set avg_accuracy=82.79% avg_sensitivity=37.87%, avg_specificity=95.79% avg_auc=0.8406
Fold[10] Epoch: 89 [89/100 (89%)] Train loss=0.251997 Test loss=0.470311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24074812233448029
[5/23] Train loss=0.25201261043548584
[10/23] Train loss=0.24804633855819702
[15/23] Train loss=0.19059322774410248
[20/23] Train loss=0.3102327585220337
Test set avg_accuracy=83.02% avg_sensitivity=51.28%, avg_specificity=92.21% avg_auc=0.8271
Fold[10] Epoch: 90 [90/100 (90%)] Train loss=0.243869 Test loss=0.459383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24017436802387238
[5/23] Train loss=0.24578659236431122
[10/23] Train loss=0.23905548453330994
[15/23] Train loss=0.19752377271652222
[20/23] Train loss=0.3054669201374054
Test set avg_accuracy=83.13% avg_sensitivity=55.70%, avg_specificity=91.06% avg_auc=0.8428
Fold[10] Epoch: 91 [91/100 (91%)] Train loss=0.241957 Test loss=0.493723 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23141515254974365
[5/23] Train loss=0.23667484521865845
[10/23] Train loss=0.23055575788021088
[15/23] Train loss=0.1967119574546814
[20/23] Train loss=0.314363956451416
Test set avg_accuracy=83.14% avg_sensitivity=58.89%, avg_specificity=90.15% avg_auc=0.8411
Fold[10] Epoch: 92 [92/100 (92%)] Train loss=0.238869 Test loss=0.478881 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2447391301393509
[5/23] Train loss=0.22412599623203278
[10/23] Train loss=0.23804043233394623
[15/23] Train loss=0.19521799683570862
[20/23] Train loss=0.3135695457458496
Test set avg_accuracy=82.66% avg_sensitivity=46.51%, avg_specificity=93.13% avg_auc=0.8375
Fold[10] Epoch: 93 [93/100 (93%)] Train loss=0.241632 Test loss=0.491677 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2374996691942215
[5/23] Train loss=0.22659878432750702
[10/23] Train loss=0.21901312470436096
[15/23] Train loss=0.17992673814296722
[20/23] Train loss=0.3158402442932129
Test set avg_accuracy=83.02% avg_sensitivity=52.83%, avg_specificity=91.76% avg_auc=0.8279
Fold[10] Epoch: 94 [94/100 (94%)] Train loss=0.230405 Test loss=0.509351 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23549123108386993
[5/23] Train loss=0.21679534018039703
[10/23] Train loss=0.21856790781021118
[15/23] Train loss=0.17920058965682983
[20/23] Train loss=0.30684810876846313
Test set avg_accuracy=82.63% avg_sensitivity=52.77%, avg_specificity=91.27% avg_auc=0.8375
Fold[10] Epoch: 95 [95/100 (95%)] Train loss=0.229535 Test loss=0.475026 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22893746197223663
[5/23] Train loss=0.22132666409015656
[10/23] Train loss=0.21296203136444092
[15/23] Train loss=0.17826451361179352
[20/23] Train loss=0.28251051902770996
Test set avg_accuracy=83.74% avg_sensitivity=53.96%, avg_specificity=92.36% avg_auc=0.8491
Fold[10] Epoch: 96 [96/100 (96%)] Train loss=0.225295 Test loss=0.499321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22364948689937592
[5/23] Train loss=0.22300001978874207
[10/23] Train loss=0.21666696667671204
[15/23] Train loss=0.1799052208662033
[20/23] Train loss=0.30778729915618896
Test set avg_accuracy=83.51% avg_sensitivity=54.93%, avg_specificity=91.78% avg_auc=0.8323
Fold[10] Epoch: 97 [97/100 (97%)] Train loss=0.223413 Test loss=0.496050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21995066106319427
[5/23] Train loss=0.20221857726573944
[10/23] Train loss=0.21315725147724152
[15/23] Train loss=0.18393467366695404
[20/23] Train loss=0.2884230315685272
Test set avg_accuracy=82.60% avg_sensitivity=52.31%, avg_specificity=91.36% avg_auc=0.8351
Fold[10] Epoch: 98 [98/100 (98%)] Train loss=0.220506 Test loss=0.493233 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21646754443645477
[5/23] Train loss=0.2163257598876953
[10/23] Train loss=0.22119644284248352
[15/23] Train loss=0.16767989099025726
[20/23] Train loss=0.27669382095336914
Test set avg_accuracy=83.21% avg_sensitivity=52.06%, avg_specificity=92.22% avg_auc=0.8346
Fold[10] Epoch: 99 [99/100 (99%)] Train loss=0.218320 Test loss=0.484409 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21148042380809784
[5/23] Train loss=0.22061105072498322
[10/23] Train loss=0.214302197098732
[15/23] Train loss=0.1737024039030075
[20/23] Train loss=0.2821020185947418
Test set avg_accuracy=83.08% avg_sensitivity=55.29%, avg_specificity=91.12% avg_auc=0.8345
Fold[10] Epoch: 100 [100/100 (100%)] Train loss=0.214567 Test loss=0.502809 Current lr=[3.9999999999999996e-05]

Fold[10] Best Result: acc=83.5524798154556 sen=60.17471736896197, spe=90.31826293872695, auc=0.8448258007853935!
Final Avg Result: avg_acc=82.546623% avg_sen=60.209700% avg_spe=90.000706% avg_auc=0.845208
