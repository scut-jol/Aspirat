/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/23] Train loss=0.6822942495346069
[5/23] Train loss=0.6157246828079224
[10/23] Train loss=0.5505361557006836
[15/23] Train loss=0.5377202033996582
[20/23] Train loss=0.4985601305961609
Test set avg_accuracy=74.71% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7650
Best model saved!! Metric=-74.79297867385395!!
Fold[1] Epoch: 1 [1/100 (1%)] Train loss=0.559252 Test loss=0.621029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40343913435935974
[5/23] Train loss=0.5330003499984741
[10/23] Train loss=0.44812607765197754
[15/23] Train loss=0.4663017988204956
[20/23] Train loss=0.4200744330883026
Test set avg_accuracy=75.17% avg_sensitivity=8.18%, avg_specificity=97.85% avg_auc=0.8291
Best model saved!! Metric=-61.88710535953852!!
Fold[1] Epoch: 2 [2/100 (2%)] Train loss=0.463947 Test loss=0.536567 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3325428068637848
[5/23] Train loss=0.4841723144054413
[10/23] Train loss=0.39406153559684753
[15/23] Train loss=0.4037882387638092
[20/23] Train loss=0.3447454273700714
Test set avg_accuracy=78.84% avg_sensitivity=32.02%, avg_specificity=94.68% avg_auc=0.8638
Best model saved!! Metric=-34.07560172896795!!
Fold[1] Epoch: 3 [3/100 (3%)] Train loss=0.409897 Test loss=0.458015 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3053480088710785
[5/23] Train loss=0.43649065494537354
[10/23] Train loss=0.37114763259887695
[15/23] Train loss=0.4079410135746002
[20/23] Train loss=0.32711076736450195
Test set avg_accuracy=80.87% avg_sensitivity=44.91%, avg_specificity=93.05% avg_auc=0.8765
Best model saved!! Metric=-19.51639942085744!!
Fold[1] Epoch: 4 [4/100 (4%)] Train loss=0.391152 Test loss=0.417682 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30225643515586853
[5/23] Train loss=0.4288918077945709
[10/23] Train loss=0.36116862297058105
[15/23] Train loss=0.37458667159080505
[20/23] Train loss=0.32018011808395386
Test set avg_accuracy=82.04% avg_sensitivity=48.62%, avg_specificity=93.35% avg_auc=0.8843
Best model saved!! Metric=-13.56344354570372!!
Fold[1] Epoch: 5 [5/100 (5%)] Train loss=0.377510 Test loss=0.399192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27681130170822144
[5/23] Train loss=0.424782931804657
[10/23] Train loss=0.35798656940460205
[15/23] Train loss=0.35593220591545105
[20/23] Train loss=0.3139207065105438
Test set avg_accuracy=82.63% avg_sensitivity=46.75%, avg_specificity=94.78% avg_auc=0.8895
Best model saved!! Metric=-12.886780526783713!!
Fold[1] Epoch: 6 [6/100 (6%)] Train loss=0.370552 Test loss=0.395341 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2484661191701889
[5/23] Train loss=0.4201784133911133
[10/23] Train loss=0.3535754382610321
[15/23] Train loss=0.34335559606552124
[20/23] Train loss=0.30590054392814636
Test set avg_accuracy=83.42% avg_sensitivity=46.58%, avg_specificity=95.88% avg_auc=0.8936
Best model saved!! Metric=-10.756691142120275!!
Fold[1] Epoch: 7 [7/100 (7%)] Train loss=0.366114 Test loss=0.387940 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2403702288866043
[5/23] Train loss=0.42084166407585144
[10/23] Train loss=0.3455594778060913
[15/23] Train loss=0.3292367458343506
[20/23] Train loss=0.2908247113227844
Test set avg_accuracy=84.41% avg_sensitivity=50.94%, avg_specificity=95.74% avg_auc=0.9008
Best model saved!! Metric=-4.827436725863347!!
Fold[1] Epoch: 8 [8/100 (8%)] Train loss=0.361365 Test loss=0.365621 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23692384362220764
[5/23] Train loss=0.4215637147426605
[10/23] Train loss=0.33034762740135193
[15/23] Train loss=0.32164454460144043
[20/23] Train loss=0.2840046286582947
Test set avg_accuracy=84.35% avg_sensitivity=49.39%, avg_specificity=96.19% avg_auc=0.9057
Fold[1] Epoch: 9 [9/100 (9%)] Train loss=0.354943 Test loss=0.363499 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22682438790798187
[5/23] Train loss=0.4214712083339691
[10/23] Train loss=0.312928706407547
[15/23] Train loss=0.31674861907958984
[20/23] Train loss=0.27939465641975403
Test set avg_accuracy=86.03% avg_sensitivity=60.37%, avg_specificity=94.71% avg_auc=0.9111
Best model saved!! Metric=6.226749709951639!!
Fold[1] Epoch: 10 [10/100 (10%)] Train loss=0.344332 Test loss=0.337707 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22431829571723938
[5/23] Train loss=0.43135976791381836
[10/23] Train loss=0.2908951938152313
[15/23] Train loss=0.29774636030197144
[20/23] Train loss=0.2627444267272949
Test set avg_accuracy=87.26% avg_sensitivity=65.54%, avg_specificity=94.62% avg_auc=0.9175
Best model saved!! Metric=13.169599002397725!!
Fold[1] Epoch: 11 [11/100 (11%)] Train loss=0.332689 Test loss=0.315764 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2271704375743866
[5/23] Train loss=0.4265473783016205
[10/23] Train loss=0.27329403162002563
[15/23] Train loss=0.2861151099205017
[20/23] Train loss=0.2489047348499298
Test set avg_accuracy=87.60% avg_sensitivity=68.80%, avg_specificity=93.97% avg_auc=0.9219
Best model saved!! Metric=16.558892973509003!!
Fold[1] Epoch: 12 [12/100 (12%)] Train loss=0.321651 Test loss=0.304459 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2167333960533142
[5/23] Train loss=0.40397220849990845
[10/23] Train loss=0.2675051689147949
[15/23] Train loss=0.27977657318115234
[20/23] Train loss=0.23883259296417236
Test set avg_accuracy=88.00% avg_sensitivity=70.87%, avg_specificity=93.80% avg_auc=0.9252
Best model saved!! Metric=19.19982272117386!!
Fold[1] Epoch: 13 [13/100 (13%)] Train loss=0.310445 Test loss=0.297735 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21486568450927734
[5/23] Train loss=0.39301759004592896
[10/23] Train loss=0.26442185044288635
[15/23] Train loss=0.26922157406806946
[20/23] Train loss=0.2313608080148697
Test set avg_accuracy=88.54% avg_sensitivity=72.50%, avg_specificity=93.97% avg_auc=0.9292
Best model saved!! Metric=21.926547734228862!!
Fold[1] Epoch: 14 [14/100 (14%)] Train loss=0.307815 Test loss=0.289552 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19684892892837524
[5/23] Train loss=0.38065868616104126
[10/23] Train loss=0.2666771709918976
[15/23] Train loss=0.2587392330169678
[20/23] Train loss=0.221274271607399
Test set avg_accuracy=88.53% avg_sensitivity=70.95%, avg_specificity=94.48% avg_auc=0.9309
Fold[1] Epoch: 15 [15/100 (15%)] Train loss=0.301267 Test loss=0.287464 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19130222499370575
[5/23] Train loss=0.37974247336387634
[10/23] Train loss=0.2612675130367279
[15/23] Train loss=0.2448306530714035
[20/23] Train loss=0.22219139337539673
Test set avg_accuracy=88.91% avg_sensitivity=72.62%, avg_specificity=94.42% avg_auc=0.9327
Best model saved!! Metric=23.218643801344474!!
Fold[1] Epoch: 16 [16/100 (16%)] Train loss=0.297851 Test loss=0.283706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18679216504096985
[5/23] Train loss=0.3690609931945801
[10/23] Train loss=0.2559903562068939
[15/23] Train loss=0.24115410447120667
[20/23] Train loss=0.2137768417596817
Test set avg_accuracy=89.09% avg_sensitivity=72.25%, avg_specificity=94.79% avg_auc=0.9354
Best model saved!! Metric=23.679392073490575!!
Fold[1] Epoch: 17 [17/100 (17%)] Train loss=0.295512 Test loss=0.278144 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18274320662021637
[5/23] Train loss=0.3820061683654785
[10/23] Train loss=0.2534083425998688
[15/23] Train loss=0.24417008459568024
[20/23] Train loss=0.21954743564128876
Test set avg_accuracy=89.06% avg_sensitivity=73.47%, avg_specificity=94.34% avg_auc=0.9365
Best model saved!! Metric=24.524449640872156!!
Fold[1] Epoch: 18 [18/100 (18%)] Train loss=0.290593 Test loss=0.276441 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18604667484760284
[5/23] Train loss=0.3771723210811615
[10/23] Train loss=0.259310781955719
[15/23] Train loss=0.2342774122953415
[20/23] Train loss=0.21063987910747528
Test set avg_accuracy=89.39% avg_sensitivity=74.61%, avg_specificity=94.40% avg_auc=0.9385
Best model saved!! Metric=26.248698872804987!!
Fold[1] Epoch: 19 [19/100 (19%)] Train loss=0.287076 Test loss=0.271078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17841973900794983
[5/23] Train loss=0.3669206500053406
[10/23] Train loss=0.24660508334636688
[15/23] Train loss=0.23153631389141083
[20/23] Train loss=0.2078721672296524
Test set avg_accuracy=89.34% avg_sensitivity=74.49%, avg_specificity=94.37% avg_auc=0.9388
Fold[1] Epoch: 20 [20/100 (20%)] Train loss=0.281298 Test loss=0.270054 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1821650117635727
[5/23] Train loss=0.3681122362613678
[10/23] Train loss=0.23778857290744781
[15/23] Train loss=0.22581636905670166
[20/23] Train loss=0.2058231383562088
Test set avg_accuracy=89.62% avg_sensitivity=77.22%, avg_specificity=93.82% avg_auc=0.9397
Best model saved!! Metric=28.62594436638608!!
Fold[1] Epoch: 21 [21/100 (21%)] Train loss=0.277161 Test loss=0.269160 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17427805066108704
[5/23] Train loss=0.3650859296321869
[10/23] Train loss=0.23750601708889008
[15/23] Train loss=0.21818377077579498
[20/23] Train loss=0.19745704531669617
Test set avg_accuracy=89.29% avg_sensitivity=75.96%, avg_specificity=93.80% avg_auc=0.9400
Fold[1] Epoch: 22 [22/100 (22%)] Train loss=0.274567 Test loss=0.268674 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17503218352794647
[5/23] Train loss=0.3671775162220001
[10/23] Train loss=0.23529894649982452
[15/23] Train loss=0.2200222611427307
[20/23] Train loss=0.20233193039894104
Test set avg_accuracy=89.35% avg_sensitivity=75.83%, avg_specificity=93.93% avg_auc=0.9400
Fold[1] Epoch: 23 [23/100 (23%)] Train loss=0.271463 Test loss=0.267259 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17570459842681885
[5/23] Train loss=0.35947343707084656
[10/23] Train loss=0.23340457677841187
[15/23] Train loss=0.21860508620738983
[20/23] Train loss=0.19545765221118927
Test set avg_accuracy=89.60% avg_sensitivity=76.20%, avg_specificity=94.13% avg_auc=0.9401
Fold[1] Epoch: 24 [24/100 (24%)] Train loss=0.268995 Test loss=0.266842 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17198961973190308
[5/23] Train loss=0.3575286567211151
[10/23] Train loss=0.22251801192760468
[15/23] Train loss=0.21273910999298096
[20/23] Train loss=0.19443991780281067
Test set avg_accuracy=89.52% avg_sensitivity=78.07%, avg_specificity=93.39% avg_auc=0.9419
Best model saved!! Metric=29.165327157196558!!
Fold[1] Epoch: 25 [25/100 (25%)] Train loss=0.266113 Test loss=0.265629 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17393143475055695
[5/23] Train loss=0.36189380288124084
[10/23] Train loss=0.21680191159248352
[15/23] Train loss=0.2105785459280014
[20/23] Train loss=0.19096311926841736
Test set avg_accuracy=89.79% avg_sensitivity=76.69%, avg_specificity=94.23% avg_auc=0.9412
Fold[1] Epoch: 26 [26/100 (26%)] Train loss=0.264620 Test loss=0.264430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17408715188503265
[5/23] Train loss=0.35232439637184143
[10/23] Train loss=0.22215212881565094
[15/23] Train loss=0.20618945360183716
[20/23] Train loss=0.1916842758655548
Test set avg_accuracy=89.91% avg_sensitivity=77.18%, avg_specificity=94.22% avg_auc=0.9426
Best model saved!! Metric=29.556996348491772!!
Fold[1] Epoch: 27 [27/100 (27%)] Train loss=0.261629 Test loss=0.262262 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15909597277641296
[5/23] Train loss=0.3516036570072174
[10/23] Train loss=0.21391980350017548
[15/23] Train loss=0.21149173378944397
[20/23] Train loss=0.18417811393737793
Test set avg_accuracy=89.68% avg_sensitivity=77.05%, avg_specificity=93.95% avg_auc=0.9415
Fold[1] Epoch: 28 [28/100 (28%)] Train loss=0.261381 Test loss=0.263830 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16225631535053253
[5/23] Train loss=0.34979650378227234
[10/23] Train loss=0.21552273631095886
[15/23] Train loss=0.2066432237625122
[20/23] Train loss=0.18467922508716583
Test set avg_accuracy=89.77% avg_sensitivity=77.34%, avg_specificity=93.98% avg_auc=0.9422
Fold[1] Epoch: 29 [29/100 (29%)] Train loss=0.258658 Test loss=0.263375 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16345155239105225
[5/23] Train loss=0.3462856113910675
[10/23] Train loss=0.22296813130378723
[15/23] Train loss=0.20353028178215027
[20/23] Train loss=0.18340888619422913
Test set avg_accuracy=89.57% avg_sensitivity=76.93%, avg_specificity=93.84% avg_auc=0.9421
Fold[1] Epoch: 30 [30/100 (30%)] Train loss=0.257095 Test loss=0.264016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15744642913341522
[5/23] Train loss=0.33606448769569397
[10/23] Train loss=0.21472415328025818
[15/23] Train loss=0.1964556872844696
[20/23] Train loss=0.17721667885780334
Test set avg_accuracy=89.64% avg_sensitivity=77.46%, avg_specificity=93.76% avg_auc=0.9426
Fold[1] Epoch: 31 [31/100 (31%)] Train loss=0.252890 Test loss=0.264479 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15681670606136322
[5/23] Train loss=0.34959763288497925
[10/23] Train loss=0.2079486846923828
[15/23] Train loss=0.19977866113185883
[20/23] Train loss=0.17729902267456055
Test set avg_accuracy=89.43% avg_sensitivity=76.48%, avg_specificity=93.82% avg_auc=0.9410
Fold[1] Epoch: 32 [32/100 (32%)] Train loss=0.250078 Test loss=0.266920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1566707342863083
[5/23] Train loss=0.34095072746276855
[10/23] Train loss=0.22510814666748047
[15/23] Train loss=0.1966165453195572
[20/23] Train loss=0.18033578991889954
Test set avg_accuracy=89.67% avg_sensitivity=77.71%, avg_specificity=93.72% avg_auc=0.9415
Fold[1] Epoch: 33 [33/100 (33%)] Train loss=0.250181 Test loss=0.266872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1553211361169815
[5/23] Train loss=0.3309062719345093
[10/23] Train loss=0.20048820972442627
[15/23] Train loss=0.19320568442344666
[20/23] Train loss=0.17289720475673676
Test set avg_accuracy=89.62% avg_sensitivity=76.77%, avg_specificity=93.97% avg_auc=0.9415
Fold[1] Epoch: 34 [34/100 (34%)] Train loss=0.246892 Test loss=0.265712 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1597432792186737
[5/23] Train loss=0.3364567458629608
[10/23] Train loss=0.21457557380199432
[15/23] Train loss=0.19825544953346252
[20/23] Train loss=0.17665883898735046
Test set avg_accuracy=89.58% avg_sensitivity=77.54%, avg_specificity=93.65% avg_auc=0.9408
Fold[1] Epoch: 35 [35/100 (35%)] Train loss=0.246261 Test loss=0.268353 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1491195559501648
[5/23] Train loss=0.3295297622680664
[10/23] Train loss=0.2078838348388672
[15/23] Train loss=0.18525563180446625
[20/23] Train loss=0.1682519018650055
Test set avg_accuracy=89.67% avg_sensitivity=78.15%, avg_specificity=93.57% avg_auc=0.9402
Fold[1] Epoch: 36 [36/100 (36%)] Train loss=0.242261 Test loss=0.270915 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1479228287935257
[5/23] Train loss=0.3314843773841858
[10/23] Train loss=0.20081490278244019
[15/23] Train loss=0.18908512592315674
[20/23] Train loss=0.1664620190858841
Test set avg_accuracy=89.79% avg_sensitivity=78.11%, avg_specificity=93.75% avg_auc=0.9415
Best model saved!! Metric=29.802488769009948!!
Fold[1] Epoch: 37 [37/100 (37%)] Train loss=0.240477 Test loss=0.267985 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14573903381824493
[5/23] Train loss=0.32706889510154724
[10/23] Train loss=0.20846404135227203
[15/23] Train loss=0.18344330787658691
[20/23] Train loss=0.1713683307170868
Test set avg_accuracy=89.62% avg_sensitivity=77.83%, avg_specificity=93.61% avg_auc=0.9410
Fold[1] Epoch: 38 [38/100 (38%)] Train loss=0.239880 Test loss=0.269069 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15194585919380188
[5/23] Train loss=0.3111146092414856
[10/23] Train loss=0.20511114597320557
[15/23] Train loss=0.1903022676706314
[20/23] Train loss=0.16624298691749573
Test set avg_accuracy=89.58% avg_sensitivity=75.63%, avg_specificity=94.30% avg_auc=0.9399
Fold[1] Epoch: 39 [39/100 (39%)] Train loss=0.237909 Test loss=0.268827 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15089000761508942
[5/23] Train loss=0.3193669617176056
[10/23] Train loss=0.20485517382621765
[15/23] Train loss=0.17986713349819183
[20/23] Train loss=0.16137035191059113
Test set avg_accuracy=89.74% avg_sensitivity=77.38%, avg_specificity=93.93% avg_auc=0.9412
Fold[1] Epoch: 40 [40/100 (40%)] Train loss=0.238427 Test loss=0.267217 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14573729038238525
[5/23] Train loss=0.3333185613155365
[10/23] Train loss=0.19573044776916504
[15/23] Train loss=0.1933346837759018
[20/23] Train loss=0.15666647255420685
Test set avg_accuracy=89.39% avg_sensitivity=75.10%, avg_specificity=94.23% avg_auc=0.9369
Fold[1] Epoch: 41 [41/100 (41%)] Train loss=0.235311 Test loss=0.274976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15167905390262604
[5/23] Train loss=0.3183443248271942
[10/23] Train loss=0.20539721846580505
[15/23] Train loss=0.18070925772190094
[20/23] Train loss=0.16499251127243042
Test set avg_accuracy=89.60% avg_sensitivity=77.75%, avg_specificity=93.61% avg_auc=0.9406
Fold[1] Epoch: 42 [42/100 (42%)] Train loss=0.233486 Test loss=0.269977 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14178034663200378
[5/23] Train loss=0.32675185799598694
[10/23] Train loss=0.19890351593494415
[15/23] Train loss=0.18061557412147522
[20/23] Train loss=0.16677221655845642
Test set avg_accuracy=89.63% avg_sensitivity=76.93%, avg_specificity=93.93% avg_auc=0.9372
Fold[1] Epoch: 43 [43/100 (43%)] Train loss=0.233862 Test loss=0.275639 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14239957928657532
[5/23] Train loss=0.3168608248233795
[10/23] Train loss=0.2004799097776413
[15/23] Train loss=0.18102312088012695
[20/23] Train loss=0.15908129513263702
Test set avg_accuracy=89.68% avg_sensitivity=77.22%, avg_specificity=93.90% avg_auc=0.9389
Fold[1] Epoch: 44 [44/100 (44%)] Train loss=0.229731 Test loss=0.272211 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14504000544548035
[5/23] Train loss=0.3095918893814087
[10/23] Train loss=0.20348034799098969
[15/23] Train loss=0.1759350299835205
[20/23] Train loss=0.1622140109539032
Test set avg_accuracy=89.58% avg_sensitivity=77.30%, avg_specificity=93.73% avg_auc=0.9393
Fold[1] Epoch: 45 [45/100 (45%)] Train loss=0.230066 Test loss=0.272750 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14603739976882935
[5/23] Train loss=0.3055463433265686
[10/23] Train loss=0.19589665532112122
[15/23] Train loss=0.17244277894496918
[20/23] Train loss=0.16077759861946106
Test set avg_accuracy=89.47% avg_sensitivity=76.48%, avg_specificity=93.86% avg_auc=0.9378
Fold[1] Epoch: 46 [46/100 (46%)] Train loss=0.229265 Test loss=0.274193 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1355501264333725
[5/23] Train loss=0.2983746826648712
[10/23] Train loss=0.19743475317955017
[15/23] Train loss=0.17748673260211945
[20/23] Train loss=0.1561523675918579
Test set avg_accuracy=89.23% avg_sensitivity=75.87%, avg_specificity=93.75% avg_auc=0.9387
Fold[1] Epoch: 47 [47/100 (47%)] Train loss=0.225685 Test loss=0.273266 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1411251723766327
[5/23] Train loss=0.30249476432800293
[10/23] Train loss=0.1974211037158966
[15/23] Train loss=0.17541146278381348
[20/23] Train loss=0.14762380719184875
Test set avg_accuracy=89.22% avg_sensitivity=76.93%, avg_specificity=93.38% avg_auc=0.9384
Fold[1] Epoch: 48 [48/100 (48%)] Train loss=0.224551 Test loss=0.275795 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13384784758090973
[5/23] Train loss=0.29404303431510925
[10/23] Train loss=0.19033174216747284
[15/23] Train loss=0.1738716959953308
[20/23] Train loss=0.15135666728019714
Test set avg_accuracy=89.37% avg_sensitivity=77.34%, avg_specificity=93.45% avg_auc=0.9383
Fold[1] Epoch: 49 [49/100 (49%)] Train loss=0.222334 Test loss=0.275903 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14414925873279572
[5/23] Train loss=0.3096667528152466
[10/23] Train loss=0.19589433073997498
[15/23] Train loss=0.17293034493923187
[20/23] Train loss=0.15035131573677063
Test set avg_accuracy=89.40% avg_sensitivity=77.95%, avg_specificity=93.28% avg_auc=0.9384
Fold[1] Epoch: 50 [50/100 (50%)] Train loss=0.219777 Test loss=0.276397 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13658711314201355
[5/23] Train loss=0.29279035329818726
[10/23] Train loss=0.19428737461566925
[15/23] Train loss=0.17109113931655884
[20/23] Train loss=0.14792867004871368
Test set avg_accuracy=89.44% avg_sensitivity=79.09%, avg_specificity=92.95% avg_auc=0.9380
Fold[1] Epoch: 51 [51/100 (51%)] Train loss=0.217303 Test loss=0.280338 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1366334855556488
[5/23] Train loss=0.28994280099868774
[10/23] Train loss=0.19553768634796143
[15/23] Train loss=0.17249561846256256
[20/23] Train loss=0.1486722081899643
Test set avg_accuracy=89.24% avg_sensitivity=76.61%, avg_specificity=93.51% avg_auc=0.9376
Fold[1] Epoch: 52 [52/100 (52%)] Train loss=0.216937 Test loss=0.276509 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13419587910175323
[5/23] Train loss=0.2885860800743103
[10/23] Train loss=0.1927887499332428
[15/23] Train loss=0.16758225858211517
[20/23] Train loss=0.14722543954849243
Test set avg_accuracy=89.33% avg_sensitivity=77.58%, avg_specificity=93.31% avg_auc=0.9388
Fold[1] Epoch: 53 [53/100 (53%)] Train loss=0.215857 Test loss=0.276180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1375739425420761
[5/23] Train loss=0.27446919679641724
[10/23] Train loss=0.186987966299057
[15/23] Train loss=0.16064484417438507
[20/23] Train loss=0.14876696467399597
Test set avg_accuracy=89.21% avg_sensitivity=77.10%, avg_specificity=93.31% avg_auc=0.9383
Fold[1] Epoch: 54 [54/100 (54%)] Train loss=0.212532 Test loss=0.276702 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13474144041538239
[5/23] Train loss=0.2712993621826172
[10/23] Train loss=0.18103031814098358
[15/23] Train loss=0.15900684893131256
[20/23] Train loss=0.14964227378368378
Test set avg_accuracy=89.32% avg_sensitivity=77.66%, avg_specificity=93.27% avg_auc=0.9390
Fold[1] Epoch: 55 [55/100 (55%)] Train loss=0.211315 Test loss=0.276300 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12445046752691269
[5/23] Train loss=0.2860211431980133
[10/23] Train loss=0.18681630492210388
[15/23] Train loss=0.15894100069999695
[20/23] Train loss=0.15316548943519592
Test set avg_accuracy=89.24% avg_sensitivity=77.22%, avg_specificity=93.31% avg_auc=0.9384
Fold[1] Epoch: 56 [56/100 (56%)] Train loss=0.210764 Test loss=0.277631 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12792596220970154
[5/23] Train loss=0.2845020294189453
[10/23] Train loss=0.1853402554988861
[15/23] Train loss=0.1683952957391739
[20/23] Train loss=0.14762601256370544
Test set avg_accuracy=89.47% avg_sensitivity=78.72%, avg_specificity=93.10% avg_auc=0.9382
Fold[1] Epoch: 57 [57/100 (57%)] Train loss=0.209423 Test loss=0.279790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12931649386882782
[5/23] Train loss=0.2733120620250702
[10/23] Train loss=0.18190845847129822
[15/23] Train loss=0.16008423268795013
[20/23] Train loss=0.137908935546875
Test set avg_accuracy=89.49% avg_sensitivity=78.76%, avg_specificity=93.11% avg_auc=0.9393
Fold[1] Epoch: 58 [58/100 (58%)] Train loss=0.206189 Test loss=0.276261 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13521400094032288
[5/23] Train loss=0.2784709930419922
[10/23] Train loss=0.1892472356557846
[15/23] Train loss=0.15626764297485352
[20/23] Train loss=0.144775390625
Test set avg_accuracy=89.60% avg_sensitivity=79.25%, avg_specificity=93.10% avg_auc=0.9387
Best model saved!! Metric=29.819150019299784!!
Fold[1] Epoch: 59 [59/100 (59%)] Train loss=0.207407 Test loss=0.278802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13124117255210876
[5/23] Train loss=0.28171858191490173
[10/23] Train loss=0.17646974325180054
[15/23] Train loss=0.15444158017635345
[20/23] Train loss=0.14561870694160461
Test set avg_accuracy=89.42% avg_sensitivity=78.52%, avg_specificity=93.11% avg_auc=0.9387
Fold[1] Epoch: 60 [60/100 (60%)] Train loss=0.204454 Test loss=0.280124 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12788912653923035
[5/23] Train loss=0.27418962121009827
[10/23] Train loss=0.1860455721616745
[15/23] Train loss=0.15574084222316742
[20/23] Train loss=0.1391080766916275
Test set avg_accuracy=89.42% avg_sensitivity=79.41%, avg_specificity=92.81% avg_auc=0.9395
Fold[1] Epoch: 61 [61/100 (61%)] Train loss=0.202123 Test loss=0.278002 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12891912460327148
[5/23] Train loss=0.27347952127456665
[10/23] Train loss=0.17574065923690796
[15/23] Train loss=0.1496465504169464
[20/23] Train loss=0.1418108195066452
Test set avg_accuracy=89.23% avg_sensitivity=77.91%, avg_specificity=93.06% avg_auc=0.9371
Fold[1] Epoch: 62 [62/100 (62%)] Train loss=0.199662 Test loss=0.283798 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12537896633148193
[5/23] Train loss=0.26458460092544556
[10/23] Train loss=0.18487213551998138
[15/23] Train loss=0.1502830982208252
[20/23] Train loss=0.14047276973724365
Test set avg_accuracy=89.09% avg_sensitivity=76.81%, avg_specificity=93.25% avg_auc=0.9373
Fold[1] Epoch: 63 [63/100 (63%)] Train loss=0.198165 Test loss=0.281187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12302950024604797
[5/23] Train loss=0.26902589201927185
[10/23] Train loss=0.18808011710643768
[15/23] Train loss=0.14943166077136993
[20/23] Train loss=0.13881774246692657
Test set avg_accuracy=89.43% avg_sensitivity=78.11%, avg_specificity=93.27% avg_auc=0.9388
Fold[1] Epoch: 64 [64/100 (64%)] Train loss=0.198490 Test loss=0.280814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12895138561725616
[5/23] Train loss=0.2660985589027405
[10/23] Train loss=0.17514926195144653
[15/23] Train loss=0.15658558905124664
[20/23] Train loss=0.13431383669376373
Test set avg_accuracy=89.24% avg_sensitivity=78.28%, avg_specificity=92.95% avg_auc=0.9377
Fold[1] Epoch: 65 [65/100 (65%)] Train loss=0.195458 Test loss=0.282434 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12376154214143753
[5/23] Train loss=0.2596244215965271
[10/23] Train loss=0.17966854572296143
[15/23] Train loss=0.14693617820739746
[20/23] Train loss=0.13461680710315704
Test set avg_accuracy=89.47% avg_sensitivity=78.48%, avg_specificity=93.18% avg_auc=0.9377
Fold[1] Epoch: 66 [66/100 (66%)] Train loss=0.191601 Test loss=0.283915 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12569719552993774
[5/23] Train loss=0.2580544054508209
[10/23] Train loss=0.1760161966085434
[15/23] Train loss=0.15335677564144135
[20/23] Train loss=0.12784503400325775
Test set avg_accuracy=89.15% avg_sensitivity=76.77%, avg_specificity=93.34% avg_auc=0.9368
Fold[1] Epoch: 67 [67/100 (67%)] Train loss=0.191521 Test loss=0.284799 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.120778389275074
[5/23] Train loss=0.24789473414421082
[10/23] Train loss=0.17766961455345154
[15/23] Train loss=0.14284434914588928
[20/23] Train loss=0.1306009143590927
Test set avg_accuracy=89.35% avg_sensitivity=78.03%, avg_specificity=93.18% avg_auc=0.9373
Fold[1] Epoch: 68 [68/100 (68%)] Train loss=0.188848 Test loss=0.285394 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1233852282166481
[5/23] Train loss=0.24832093715667725
[10/23] Train loss=0.1804051399230957
[15/23] Train loss=0.14297565817832947
[20/23] Train loss=0.1224810928106308
Test set avg_accuracy=89.34% avg_sensitivity=79.05%, avg_specificity=92.83% avg_auc=0.9394
Fold[1] Epoch: 69 [69/100 (69%)] Train loss=0.187940 Test loss=0.281968 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11350341886281967
[5/23] Train loss=0.24431104958057404
[10/23] Train loss=0.1747279018163681
[15/23] Train loss=0.14259013533592224
[20/23] Train loss=0.136456698179245
Test set avg_accuracy=89.47% avg_sensitivity=78.64%, avg_specificity=93.13% avg_auc=0.9366
Fold[1] Epoch: 70 [70/100 (70%)] Train loss=0.185517 Test loss=0.287370 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11929263174533844
[5/23] Train loss=0.2633822560310364
[10/23] Train loss=0.17503364384174347
[15/23] Train loss=0.15180109441280365
[20/23] Train loss=0.1283465474843979
Test set avg_accuracy=89.17% avg_sensitivity=77.91%, avg_specificity=92.98% avg_auc=0.9368
Fold[1] Epoch: 71 [71/100 (71%)] Train loss=0.183865 Test loss=0.287111 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12037018686532974
[5/23] Train loss=0.23753981292247772
[10/23] Train loss=0.16435371339321136
[15/23] Train loss=0.1348899006843567
[20/23] Train loss=0.1337338536977768
Test set avg_accuracy=89.41% avg_sensitivity=77.91%, avg_specificity=93.31% avg_auc=0.9377
Fold[1] Epoch: 72 [72/100 (72%)] Train loss=0.182624 Test loss=0.284469 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11758556962013245
[5/23] Train loss=0.24247196316719055
[10/23] Train loss=0.16587494313716888
[15/23] Train loss=0.14386260509490967
[20/23] Train loss=0.12795518338680267
Test set avg_accuracy=89.27% avg_sensitivity=77.18%, avg_specificity=93.36% avg_auc=0.9365
Fold[1] Epoch: 73 [73/100 (73%)] Train loss=0.181525 Test loss=0.287086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11149038374423981
[5/23] Train loss=0.24317315220832825
[10/23] Train loss=0.17032253742218018
[15/23] Train loss=0.13189511001110077
[20/23] Train loss=0.12714950740337372
Test set avg_accuracy=89.20% avg_sensitivity=77.30%, avg_specificity=93.23% avg_auc=0.9354
Fold[1] Epoch: 74 [74/100 (74%)] Train loss=0.178744 Test loss=0.289513 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11272398382425308
[5/23] Train loss=0.23091356456279755
[10/23] Train loss=0.169157937169075
[15/23] Train loss=0.1407078355550766
[20/23] Train loss=0.12118680775165558
Test set avg_accuracy=89.14% avg_sensitivity=77.95%, avg_specificity=92.92% avg_auc=0.9356
Fold[1] Epoch: 75 [75/100 (75%)] Train loss=0.176978 Test loss=0.292080 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11032204329967499
[5/23] Train loss=0.2277095764875412
[10/23] Train loss=0.1588236689567566
[15/23] Train loss=0.13358137011528015
[20/23] Train loss=0.12246926873922348
Test set avg_accuracy=89.34% avg_sensitivity=76.89%, avg_specificity=93.56% avg_auc=0.9348
Fold[1] Epoch: 76 [76/100 (76%)] Train loss=0.174777 Test loss=0.288229 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11552631855010986
[5/23] Train loss=0.2272752821445465
[10/23] Train loss=0.16654857993125916
[15/23] Train loss=0.132473424077034
[20/23] Train loss=0.11995614320039749
Test set avg_accuracy=88.94% avg_sensitivity=77.62%, avg_specificity=92.77% avg_auc=0.9366
Fold[1] Epoch: 77 [77/100 (77%)] Train loss=0.171597 Test loss=0.291670 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10804135352373123
[5/23] Train loss=0.23695862293243408
[10/23] Train loss=0.16435123980045319
[15/23] Train loss=0.13085275888442993
[20/23] Train loss=0.12056775391101837
Test set avg_accuracy=88.87% avg_sensitivity=76.73%, avg_specificity=92.98% avg_auc=0.9357
Fold[1] Epoch: 78 [78/100 (78%)] Train loss=0.172153 Test loss=0.291648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10689396411180496
[5/23] Train loss=0.2244790494441986
[10/23] Train loss=0.16556279361248016
[15/23] Train loss=0.12809394299983978
[20/23] Train loss=0.12147383391857147
Test set avg_accuracy=88.86% avg_sensitivity=75.39%, avg_specificity=93.42% avg_auc=0.9329
Fold[1] Epoch: 79 [79/100 (79%)] Train loss=0.167913 Test loss=0.296548 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11572775989770889
[5/23] Train loss=0.2230689525604248
[10/23] Train loss=0.15883204340934753
[15/23] Train loss=0.1292157769203186
[20/23] Train loss=0.10933097451925278
Test set avg_accuracy=89.21% avg_sensitivity=79.09%, avg_specificity=92.63% avg_auc=0.9371
Fold[1] Epoch: 80 [80/100 (80%)] Train loss=0.166670 Test loss=0.294222 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11322668194770813
[5/23] Train loss=0.2333347350358963
[10/23] Train loss=0.1642025113105774
[15/23] Train loss=0.1307966262102127
[20/23] Train loss=0.11124821752309799
Test set avg_accuracy=89.19% avg_sensitivity=77.42%, avg_specificity=93.17% avg_auc=0.9354
Fold[1] Epoch: 81 [81/100 (81%)] Train loss=0.168424 Test loss=0.293397 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10519128292798996
[5/23] Train loss=0.21798819303512573
[10/23] Train loss=0.15373274683952332
[15/23] Train loss=0.12286698818206787
[20/23] Train loss=0.108493871986866
Test set avg_accuracy=89.06% avg_sensitivity=77.18%, avg_specificity=93.09% avg_auc=0.9355
Fold[1] Epoch: 82 [82/100 (82%)] Train loss=0.164919 Test loss=0.294133 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09656354784965515
[5/23] Train loss=0.2112540900707245
[10/23] Train loss=0.15522439777851105
[15/23] Train loss=0.130631223320961
[20/23] Train loss=0.11004282534122467
Test set avg_accuracy=88.98% avg_sensitivity=76.36%, avg_specificity=93.25% avg_auc=0.9359
Fold[1] Epoch: 83 [83/100 (83%)] Train loss=0.160778 Test loss=0.291611 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10021823644638062
[5/23] Train loss=0.22213716804981232
[10/23] Train loss=0.14815792441368103
[15/23] Train loss=0.13019722700119019
[20/23] Train loss=0.11355641484260559
Test set avg_accuracy=89.35% avg_sensitivity=77.66%, avg_specificity=93.31% avg_auc=0.9360
Fold[1] Epoch: 84 [84/100 (84%)] Train loss=0.159114 Test loss=0.294077 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.0969943031668663
[5/23] Train loss=0.21442289650440216
[10/23] Train loss=0.15195344388484955
[15/23] Train loss=0.122665636241436
[20/23] Train loss=0.11221923679113388
Test set avg_accuracy=89.21% avg_sensitivity=78.60%, avg_specificity=92.80% avg_auc=0.9350
Fold[1] Epoch: 85 [85/100 (85%)] Train loss=0.157003 Test loss=0.297628 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10221653431653976
[5/23] Train loss=0.21578949689865112
[10/23] Train loss=0.15072296559810638
[15/23] Train loss=0.12686161696910858
[20/23] Train loss=0.10251608490943909
Test set avg_accuracy=89.19% avg_sensitivity=78.89%, avg_specificity=92.67% avg_auc=0.9347
Fold[1] Epoch: 86 [86/100 (86%)] Train loss=0.155866 Test loss=0.302967 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09636038541793823
[5/23] Train loss=0.21225067973136902
[10/23] Train loss=0.1381426453590393
[15/23] Train loss=0.12317442893981934
[20/23] Train loss=0.11231178790330887
Test set avg_accuracy=89.24% avg_sensitivity=79.45%, avg_specificity=92.55% avg_auc=0.9354
Fold[1] Epoch: 87 [87/100 (87%)] Train loss=0.154593 Test loss=0.301319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1002442017197609
[5/23] Train loss=0.20819413661956787
[10/23] Train loss=0.14285758137702942
[15/23] Train loss=0.120602548122406
[20/23] Train loss=0.11050421744585037
Test set avg_accuracy=89.19% avg_sensitivity=79.50%, avg_specificity=92.47% avg_auc=0.9346
Fold[1] Epoch: 88 [88/100 (88%)] Train loss=0.151776 Test loss=0.304273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10029441863298416
[5/23] Train loss=0.2028430700302124
[10/23] Train loss=0.13741564750671387
[15/23] Train loss=0.1173805296421051
[20/23] Train loss=0.10745760053396225
Test set avg_accuracy=89.00% avg_sensitivity=78.36%, avg_specificity=92.61% avg_auc=0.9334
Fold[1] Epoch: 89 [89/100 (89%)] Train loss=0.148433 Test loss=0.306331 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10711222887039185
[5/23] Train loss=0.19991764426231384
[10/23] Train loss=0.13488507270812988
[15/23] Train loss=0.12166530638933182
[20/23] Train loss=0.10863760858774185
Test set avg_accuracy=89.24% avg_sensitivity=80.15%, avg_specificity=92.32% avg_auc=0.9356
Fold[1] Epoch: 90 [90/100 (90%)] Train loss=0.148701 Test loss=0.306854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09667759388685226
[5/23] Train loss=0.19686561822891235
[10/23] Train loss=0.13317973911762238
[15/23] Train loss=0.10871724784374237
[20/23] Train loss=0.09929484128952026
Test set avg_accuracy=89.07% avg_sensitivity=80.96%, avg_specificity=91.82% avg_auc=0.9353
Fold[1] Epoch: 91 [91/100 (91%)] Train loss=0.144207 Test loss=0.310620 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09313242882490158
[5/23] Train loss=0.18904580175876617
[10/23] Train loss=0.13867218792438507
[15/23] Train loss=0.11330112814903259
[20/23] Train loss=0.10154208540916443
Test set avg_accuracy=89.10% avg_sensitivity=80.19%, avg_specificity=92.12% avg_auc=0.9338
Fold[1] Epoch: 92 [92/100 (92%)] Train loss=0.142149 Test loss=0.313706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09696301072835922
[5/23] Train loss=0.18729518353939056
[10/23] Train loss=0.13776390254497528
[15/23] Train loss=0.11724230647087097
[20/23] Train loss=0.09655752778053284
Test set avg_accuracy=88.93% avg_sensitivity=79.78%, avg_specificity=92.03% avg_auc=0.9323
Fold[1] Epoch: 93 [93/100 (93%)] Train loss=0.139720 Test loss=0.317032 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.0944008007645607
[5/23] Train loss=0.1844848096370697
[10/23] Train loss=0.13148091733455658
[15/23] Train loss=0.11417783796787262
[20/23] Train loss=0.09433150291442871
Test set avg_accuracy=88.88% avg_sensitivity=80.55%, avg_specificity=91.70% avg_auc=0.9329
Fold[1] Epoch: 94 [94/100 (94%)] Train loss=0.138335 Test loss=0.324634 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.0971507728099823
[5/23] Train loss=0.18093432486057281
[10/23] Train loss=0.1284635215997696
[15/23] Train loss=0.11648396402597427
[20/23] Train loss=0.09730322659015656
Test set avg_accuracy=88.98% avg_sensitivity=81.08%, avg_specificity=91.66% avg_auc=0.9343
Fold[1] Epoch: 95 [95/100 (95%)] Train loss=0.135314 Test loss=0.322732 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09940417855978012
[5/23] Train loss=0.1773935705423355
[10/23] Train loss=0.1318172812461853
[15/23] Train loss=0.11426570266485214
[20/23] Train loss=0.09412747621536255
Test set avg_accuracy=88.74% avg_sensitivity=79.70%, avg_specificity=91.81% avg_auc=0.9324
Fold[1] Epoch: 96 [96/100 (96%)] Train loss=0.134713 Test loss=0.322118 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09450377523899078
[5/23] Train loss=0.1740894913673401
[10/23] Train loss=0.12514111399650574
[15/23] Train loss=0.09800528734922409
[20/23] Train loss=0.09117323160171509
Test set avg_accuracy=88.94% avg_sensitivity=81.12%, avg_specificity=91.59% avg_auc=0.9341
Fold[1] Epoch: 97 [97/100 (97%)] Train loss=0.130829 Test loss=0.320796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.0947023257613182
[5/23] Train loss=0.17220982909202576
[10/23] Train loss=0.12137918919324875
[15/23] Train loss=0.10352452844381332
[20/23] Train loss=0.09552140533924103
Test set avg_accuracy=88.78% avg_sensitivity=81.53%, avg_specificity=91.23% avg_auc=0.9342
Fold[1] Epoch: 98 [98/100 (98%)] Train loss=0.130257 Test loss=0.323075 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09003493934869766
[5/23] Train loss=0.1678585261106491
[10/23] Train loss=0.12875384092330933
[15/23] Train loss=0.11030713468790054
[20/23] Train loss=0.09511178731918335
Test set avg_accuracy=88.82% avg_sensitivity=82.38%, avg_specificity=90.99% avg_auc=0.9330
Fold[1] Epoch: 99 [99/100 (99%)] Train loss=0.128743 Test loss=0.334409 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.08487186580896378
[5/23] Train loss=0.16935867071151733
[10/23] Train loss=0.11925038695335388
[15/23] Train loss=0.10548017919063568
[20/23] Train loss=0.0960189551115036
Test set avg_accuracy=88.91% avg_sensitivity=81.73%, avg_specificity=91.34% avg_auc=0.9302
Fold[1] Epoch: 100 [100/100 (100%)] Train loss=0.126990 Test loss=0.338495 Current lr=[3.9999999999999996e-05]

Fold[1] Best Result: acc=89.59876543209877 sen=79.2514239218877, spe=93.1010740842743, auc=0.9386788658103901!
[0/23] Train loss=0.6807491779327393
[5/23] Train loss=0.6088584661483765
[10/23] Train loss=0.5505661368370056
[15/23] Train loss=0.5474537014961243
[20/23] Train loss=0.5133541226387024
Test set avg_accuracy=76.92% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6068
Best model saved!! Metric=-88.39491930312509!!
Fold[2] Epoch: 1 [1/100 (1%)] Train loss=0.565125 Test loss=0.537474 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5153892636299133
[5/23] Train loss=0.5584607124328613
[10/23] Train loss=0.48589038848876953
[15/23] Train loss=0.4667453169822693
[20/23] Train loss=0.42744195461273193
Test set avg_accuracy=77.13% avg_sensitivity=8.32%, avg_specificity=97.78% avg_auc=0.7485
Best model saved!! Metric=-67.9294900281077!!
Fold[2] Epoch: 2 [2/100 (2%)] Train loss=0.485576 Test loss=0.479995 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.415228933095932
[5/23] Train loss=0.4978150427341461
[10/23] Train loss=0.40805453062057495
[15/23] Train loss=0.4260816276073456
[20/23] Train loss=0.37128376960754395
Test set avg_accuracy=79.91% avg_sensitivity=31.37%, avg_specificity=94.47% avg_auc=0.8234
Best model saved!! Metric=-37.9114773049373!!
Fold[2] Epoch: 3 [3/100 (3%)] Train loss=0.426363 Test loss=0.420437 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36992311477661133
[5/23] Train loss=0.45934244990348816
[10/23] Train loss=0.3627830147743225
[15/23] Train loss=0.39371970295906067
[20/23] Train loss=0.33375173807144165
Test set avg_accuracy=81.61% avg_sensitivity=40.24%, avg_specificity=94.02% avg_auc=0.8491
Best model saved!! Metric=-25.228199750531267!!
Fold[2] Epoch: 4 [4/100 (4%)] Train loss=0.391902 Test loss=0.395298 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3490915596485138
[5/23] Train loss=0.4498398005962372
[10/23] Train loss=0.3394226133823395
[15/23] Train loss=0.368961364030838
[20/23] Train loss=0.32177531719207764
Test set avg_accuracy=83.26% avg_sensitivity=49.82%, avg_specificity=93.29% avg_auc=0.8637
Best model saved!! Metric=-13.269546960564469!!
Fold[2] Epoch: 5 [5/100 (5%)] Train loss=0.375770 Test loss=0.377887 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34341034293174744
[5/23] Train loss=0.44353625178337097
[10/23] Train loss=0.33014732599258423
[15/23] Train loss=0.337240993976593
[20/23] Train loss=0.29713737964630127
Test set avg_accuracy=84.91% avg_sensitivity=52.89%, avg_specificity=94.52% avg_auc=0.8795
Best model saved!! Metric=-5.719249244119624!!
Fold[2] Epoch: 6 [6/100 (6%)] Train loss=0.361434 Test loss=0.354684 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.317682683467865
[5/23] Train loss=0.42606642842292786
[10/23] Train loss=0.3030024468898773
[15/23] Train loss=0.3119214177131653
[20/23] Train loss=0.2750762701034546
Test set avg_accuracy=85.87% avg_sensitivity=60.26%, avg_specificity=93.56% avg_auc=0.8924
Best model saved!! Metric=2.9308263657349714!!
Fold[2] Epoch: 7 [7/100 (7%)] Train loss=0.348536 Test loss=0.335956 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30036744475364685
[5/23] Train loss=0.41213375329971313
[10/23] Train loss=0.2942911386489868
[15/23] Train loss=0.2979205846786499
[20/23] Train loss=0.2671317458152771
Test set avg_accuracy=86.78% avg_sensitivity=63.07%, avg_specificity=93.90% avg_auc=0.9014
Best model saved!! Metric=7.878496618307475!!
Fold[2] Epoch: 8 [8/100 (8%)] Train loss=0.337741 Test loss=0.322447 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28056076169013977
[5/23] Train loss=0.40955981612205505
[10/23] Train loss=0.28547659516334534
[15/23] Train loss=0.28473126888275146
[20/23] Train loss=0.24414333701133728
Test set avg_accuracy=86.94% avg_sensitivity=69.12%, avg_specificity=92.28% avg_auc=0.9083
Best model saved!! Metric=13.173746396048552!!
Fold[2] Epoch: 9 [9/100 (9%)] Train loss=0.325713 Test loss=0.316772 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27755317091941833
[5/23] Train loss=0.4082668423652649
[10/23] Train loss=0.2704795300960541
[15/23] Train loss=0.2765597701072693
[20/23] Train loss=0.2369934767484665
Test set avg_accuracy=87.17% avg_sensitivity=69.35%, avg_specificity=92.51% avg_auc=0.9093
Best model saved!! Metric=13.95809773273815!!
Fold[2] Epoch: 10 [10/100 (10%)] Train loss=0.317392 Test loss=0.317696 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26795825362205505
[5/23] Train loss=0.3886681795120239
[10/23] Train loss=0.25264644622802734
[15/23] Train loss=0.25802817940711975
[20/23] Train loss=0.24258138239383698
Test set avg_accuracy=87.39% avg_sensitivity=68.17%, avg_specificity=93.15% avg_auc=0.9085
Fold[2] Epoch: 11 [11/100 (11%)] Train loss=0.310068 Test loss=0.318931 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24974098801612854
[5/23] Train loss=0.40219947695732117
[10/23] Train loss=0.26118117570877075
[15/23] Train loss=0.25034549832344055
[20/23] Train loss=0.22415803372859955
Test set avg_accuracy=87.18% avg_sensitivity=68.17%, avg_specificity=92.88% avg_auc=0.9112
Fold[2] Epoch: 12 [12/100 (12%)] Train loss=0.303269 Test loss=0.315141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24283918738365173
[5/23] Train loss=0.3925277292728424
[10/23] Train loss=0.2525194585323334
[15/23] Train loss=0.2469727098941803
[20/23] Train loss=0.22924625873565674
Test set avg_accuracy=87.08% avg_sensitivity=69.08%, avg_specificity=92.49% avg_auc=0.9083
Fold[2] Epoch: 13 [13/100 (13%)] Train loss=0.296948 Test loss=0.324600 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24147911369800568
[5/23] Train loss=0.38702666759490967
[10/23] Train loss=0.24605560302734375
[15/23] Train loss=0.24683411419391632
[20/23] Train loss=0.2187652289867401
Test set avg_accuracy=87.40% avg_sensitivity=69.03%, avg_specificity=92.91% avg_auc=0.9128
Best model saved!! Metric=14.617396000817358!!
Fold[2] Epoch: 14 [14/100 (14%)] Train loss=0.292673 Test loss=0.314867 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2401241809129715
[5/23] Train loss=0.38022857904434204
[10/23] Train loss=0.23807860910892487
[15/23] Train loss=0.24974022805690765
[20/23] Train loss=0.21179533004760742
Test set avg_accuracy=87.68% avg_sensitivity=67.90%, avg_specificity=93.61% avg_auc=0.9172
Best model saved!! Metric=14.915144684770542!!
Fold[2] Epoch: 15 [15/100 (15%)] Train loss=0.292954 Test loss=0.303167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23040810227394104
[5/23] Train loss=0.36904215812683105
[10/23] Train loss=0.24286970496177673
[15/23] Train loss=0.23820793628692627
[20/23] Train loss=0.20604637265205383
Test set avg_accuracy=87.90% avg_sensitivity=68.13%, avg_specificity=93.83% avg_auc=0.9184
Best model saved!! Metric=15.694379111652111!!
Fold[2] Epoch: 16 [16/100 (16%)] Train loss=0.285054 Test loss=0.300189 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23138435184955597
[5/23] Train loss=0.37956702709198
[10/23] Train loss=0.24597260355949402
[15/23] Train loss=0.23008552193641663
[20/23] Train loss=0.20944711565971375
Test set avg_accuracy=87.56% avg_sensitivity=67.36%, avg_specificity=93.63% avg_auc=0.9125
Fold[2] Epoch: 17 [17/100 (17%)] Train loss=0.280660 Test loss=0.312687 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22639909386634827
[5/23] Train loss=0.378913551568985
[10/23] Train loss=0.23317645490169525
[15/23] Train loss=0.23326276242733002
[20/23] Train loss=0.20348748564720154
Test set avg_accuracy=87.73% avg_sensitivity=68.94%, avg_specificity=93.37% avg_auc=0.9177
Best model saved!! Metric=15.810386104622962!!
Fold[2] Epoch: 18 [18/100 (18%)] Train loss=0.279348 Test loss=0.304385 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2253049612045288
[5/23] Train loss=0.36484062671661377
[10/23] Train loss=0.23325547575950623
[15/23] Train loss=0.23676852881908417
[20/23] Train loss=0.2088470458984375
Test set avg_accuracy=87.72% avg_sensitivity=66.95%, avg_specificity=93.95% avg_auc=0.9141
Fold[2] Epoch: 19 [19/100 (19%)] Train loss=0.275967 Test loss=0.307086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22334644198417664
[5/23] Train loss=0.37230783700942993
[10/23] Train loss=0.2320234179496765
[15/23] Train loss=0.23690678179264069
[20/23] Train loss=0.19182483851909637
Test set avg_accuracy=87.58% avg_sensitivity=65.91%, avg_specificity=94.09% avg_auc=0.9150
Fold[2] Epoch: 20 [20/100 (20%)] Train loss=0.272835 Test loss=0.304607 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22380205988883972
[5/23] Train loss=0.36594197154045105
[10/23] Train loss=0.22316831350326538
[15/23] Train loss=0.2308957874774933
[20/23] Train loss=0.19543109834194183
Test set avg_accuracy=87.48% avg_sensitivity=65.37%, avg_specificity=94.11% avg_auc=0.9120
Fold[2] Epoch: 21 [21/100 (21%)] Train loss=0.270729 Test loss=0.309436 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21607419848442078
[5/23] Train loss=0.3620763421058655
[10/23] Train loss=0.2245863676071167
[15/23] Train loss=0.2257944941520691
[20/23] Train loss=0.19738169014453888
Test set avg_accuracy=87.74% avg_sensitivity=67.68%, avg_specificity=93.76% avg_auc=0.9157
Fold[2] Epoch: 22 [22/100 (22%)] Train loss=0.266972 Test loss=0.307544 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22679701447486877
[5/23] Train loss=0.3613508641719818
[10/23] Train loss=0.22257952392101288
[15/23] Train loss=0.22762317955493927
[20/23] Train loss=0.19323377311229706
Test set avg_accuracy=87.70% avg_sensitivity=67.13%, avg_specificity=93.87% avg_auc=0.9150
Fold[2] Epoch: 23 [23/100 (23%)] Train loss=0.267234 Test loss=0.307249 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2278531938791275
[5/23] Train loss=0.3604726791381836
[10/23] Train loss=0.22066955268383026
[15/23] Train loss=0.213531494140625
[20/23] Train loss=0.1871577650308609
Test set avg_accuracy=87.62% avg_sensitivity=65.14%, avg_specificity=94.36% avg_auc=0.9172
Fold[2] Epoch: 24 [24/100 (24%)] Train loss=0.264047 Test loss=0.298911 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21319374442100525
[5/23] Train loss=0.3521014153957367
[10/23] Train loss=0.21849316358566284
[15/23] Train loss=0.22053198516368866
[20/23] Train loss=0.18250539898872375
Test set avg_accuracy=87.27% avg_sensitivity=64.42%, avg_specificity=94.13% avg_auc=0.9139
Fold[2] Epoch: 25 [25/100 (25%)] Train loss=0.260832 Test loss=0.306016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21310903131961823
[5/23] Train loss=0.35008856654167175
[10/23] Train loss=0.22018085420131683
[15/23] Train loss=0.20664915442466736
[20/23] Train loss=0.185776486992836
Test set avg_accuracy=87.56% avg_sensitivity=63.52%, avg_specificity=94.78% avg_auc=0.9142
Fold[2] Epoch: 26 [26/100 (26%)] Train loss=0.258930 Test loss=0.303019 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2118692845106125
[5/23] Train loss=0.3641071021556854
[10/23] Train loss=0.2145012468099594
[15/23] Train loss=0.20314359664916992
[20/23] Train loss=0.19068267941474915
Test set avg_accuracy=87.50% avg_sensitivity=63.07%, avg_specificity=94.83% avg_auc=0.9144
Fold[2] Epoch: 27 [27/100 (27%)] Train loss=0.258753 Test loss=0.302852 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2117861956357956
[5/23] Train loss=0.3410646617412567
[10/23] Train loss=0.21728873252868652
[15/23] Train loss=0.20384810864925385
[20/23] Train loss=0.1845703125
Test set avg_accuracy=87.41% avg_sensitivity=62.61%, avg_specificity=94.85% avg_auc=0.9141
Fold[2] Epoch: 28 [28/100 (28%)] Train loss=0.256211 Test loss=0.302209 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2007213532924652
[5/23] Train loss=0.3500435948371887
[10/23] Train loss=0.21853825449943542
[15/23] Train loss=0.20274758338928223
[20/23] Train loss=0.18099281191825867
Test set avg_accuracy=87.52% avg_sensitivity=61.84%, avg_specificity=95.23% avg_auc=0.9164
Fold[2] Epoch: 29 [29/100 (29%)] Train loss=0.254713 Test loss=0.298389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20555569231510162
[5/23] Train loss=0.3446602523326874
[10/23] Train loss=0.21578556299209595
[15/23] Train loss=0.20964698493480682
[20/23] Train loss=0.17973072826862335
Test set avg_accuracy=87.53% avg_sensitivity=60.31%, avg_specificity=95.70% avg_auc=0.9126
Fold[2] Epoch: 30 [30/100 (30%)] Train loss=0.254156 Test loss=0.305434 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21031202375888824
[5/23] Train loss=0.3312548100948334
[10/23] Train loss=0.22153039276599884
[15/23] Train loss=0.20558765530586243
[20/23] Train loss=0.17649045586585999
Test set avg_accuracy=87.32% avg_sensitivity=59.54%, avg_specificity=95.66% avg_auc=0.9134
Fold[2] Epoch: 31 [31/100 (31%)] Train loss=0.252184 Test loss=0.304035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20273761451244354
[5/23] Train loss=0.34088796377182007
[10/23] Train loss=0.2191222906112671
[15/23] Train loss=0.2125123143196106
[20/23] Train loss=0.1774643510580063
Test set avg_accuracy=87.12% avg_sensitivity=59.18%, avg_specificity=95.50% avg_auc=0.9113
Fold[2] Epoch: 32 [32/100 (32%)] Train loss=0.252179 Test loss=0.305662 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19546286761760712
[5/23] Train loss=0.3321160674095154
[10/23] Train loss=0.21937650442123413
[15/23] Train loss=0.2012515366077423
[20/23] Train loss=0.17412449419498444
Test set avg_accuracy=87.29% avg_sensitivity=59.45%, avg_specificity=95.65% avg_auc=0.9134
Fold[2] Epoch: 33 [33/100 (33%)] Train loss=0.249718 Test loss=0.305130 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20029497146606445
[5/23] Train loss=0.3340376317501068
[10/23] Train loss=0.21761466562747955
[15/23] Train loss=0.20029430091381073
[20/23] Train loss=0.16981807351112366
Test set avg_accuracy=87.49% avg_sensitivity=59.22%, avg_specificity=95.97% avg_auc=0.9119
Fold[2] Epoch: 34 [34/100 (34%)] Train loss=0.247221 Test loss=0.310441 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20204570889472961
[5/23] Train loss=0.33717918395996094
[10/23] Train loss=0.21677088737487793
[15/23] Train loss=0.19604390859603882
[20/23] Train loss=0.16936394572257996
Test set avg_accuracy=87.55% avg_sensitivity=56.78%, avg_specificity=96.79% avg_auc=0.9150
Fold[2] Epoch: 35 [35/100 (35%)] Train loss=0.247919 Test loss=0.309938 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20144161581993103
[5/23] Train loss=0.34294968843460083
[10/23] Train loss=0.22204236686229706
[15/23] Train loss=0.19242921471595764
[20/23] Train loss=0.17575813829898834
Test set avg_accuracy=87.52% avg_sensitivity=54.29%, avg_specificity=97.49% avg_auc=0.9153
Fold[2] Epoch: 36 [36/100 (36%)] Train loss=0.247731 Test loss=0.318039 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21024267375469208
[5/23] Train loss=0.344814658164978
[10/23] Train loss=0.22271320223808289
[15/23] Train loss=0.1880127340555191
[20/23] Train loss=0.16859756410121918
Test set avg_accuracy=87.48% avg_sensitivity=55.11%, avg_specificity=97.19% avg_auc=0.9140
Fold[2] Epoch: 37 [37/100 (37%)] Train loss=0.245152 Test loss=0.310729 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19917188584804535
[5/23] Train loss=0.32975947856903076
[10/23] Train loss=0.2249477654695511
[15/23] Train loss=0.18339446187019348
[20/23] Train loss=0.1679326593875885
Test set avg_accuracy=87.52% avg_sensitivity=56.06%, avg_specificity=96.96% avg_auc=0.9125
Fold[2] Epoch: 38 [38/100 (38%)] Train loss=0.242225 Test loss=0.316170 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19718579947948456
[5/23] Train loss=0.3333294987678528
[10/23] Train loss=0.2226865440607071
[15/23] Train loss=0.1821747124195099
[20/23] Train loss=0.16656537353992462
Test set avg_accuracy=87.75% avg_sensitivity=57.19%, avg_specificity=96.92% avg_auc=0.9152
Fold[2] Epoch: 39 [39/100 (39%)] Train loss=0.243484 Test loss=0.308259 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20247133076190948
[5/23] Train loss=0.35026970505714417
[10/23] Train loss=0.20516392588615417
[15/23] Train loss=0.18229903280735016
[20/23] Train loss=0.16202951967716217
Test set avg_accuracy=87.41% avg_sensitivity=54.39%, avg_specificity=97.31% avg_auc=0.9117
Fold[2] Epoch: 40 [40/100 (40%)] Train loss=0.240164 Test loss=0.317602 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1951463520526886
[5/23] Train loss=0.3466542959213257
[10/23] Train loss=0.19971325993537903
[15/23] Train loss=0.1826505810022354
[20/23] Train loss=0.15541823208332062
Test set avg_accuracy=87.52% avg_sensitivity=58.14%, avg_specificity=96.34% avg_auc=0.9137
Fold[2] Epoch: 41 [41/100 (41%)] Train loss=0.237961 Test loss=0.306898 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1950719654560089
[5/23] Train loss=0.3434291481971741
[10/23] Train loss=0.20435276627540588
[15/23] Train loss=0.18903808295726776
[20/23] Train loss=0.1663355678319931
Test set avg_accuracy=87.86% avg_sensitivity=60.44%, avg_specificity=96.08% avg_auc=0.9180
Fold[2] Epoch: 42 [42/100 (42%)] Train loss=0.236019 Test loss=0.299202 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19198180735111237
[5/23] Train loss=0.337154358625412
[10/23] Train loss=0.2043558955192566
[15/23] Train loss=0.1766316443681717
[20/23] Train loss=0.16180619597434998
Test set avg_accuracy=87.87% avg_sensitivity=59.00%, avg_specificity=96.53% avg_auc=0.9184
Fold[2] Epoch: 43 [43/100 (43%)] Train loss=0.231764 Test loss=0.301320 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1944914311170578
[5/23] Train loss=0.33902832865715027
[10/23] Train loss=0.20070259273052216
[15/23] Train loss=0.17953604459762573
[20/23] Train loss=0.15733063220977783
Test set avg_accuracy=87.68% avg_sensitivity=58.18%, avg_specificity=96.53% avg_auc=0.9139
Fold[2] Epoch: 44 [44/100 (44%)] Train loss=0.230621 Test loss=0.309122 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18843518197536469
[5/23] Train loss=0.3282109797000885
[10/23] Train loss=0.2037382274866104
[15/23] Train loss=0.18191349506378174
[20/23] Train loss=0.1593363732099533
Test set avg_accuracy=87.72% avg_sensitivity=58.54%, avg_specificity=96.47% avg_auc=0.9141
Fold[2] Epoch: 45 [45/100 (45%)] Train loss=0.227990 Test loss=0.309904 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18387268483638763
[5/23] Train loss=0.33533111214637756
[10/23] Train loss=0.19800394773483276
[15/23] Train loss=0.16854991018772125
[20/23] Train loss=0.15681113302707672
Test set avg_accuracy=87.64% avg_sensitivity=57.73%, avg_specificity=96.61% avg_auc=0.9156
Fold[2] Epoch: 46 [46/100 (46%)] Train loss=0.227580 Test loss=0.306160 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18633732199668884
[5/23] Train loss=0.32233235239982605
[10/23] Train loss=0.19519364833831787
[15/23] Train loss=0.17341914772987366
[20/23] Train loss=0.15205007791519165
Test set avg_accuracy=87.76% avg_sensitivity=58.00%, avg_specificity=96.69% avg_auc=0.9175
Fold[2] Epoch: 47 [47/100 (47%)] Train loss=0.225645 Test loss=0.304436 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19198088347911835
[5/23] Train loss=0.3177942931652069
[10/23] Train loss=0.20052851736545563
[15/23] Train loss=0.17885944247245789
[20/23] Train loss=0.15693990886211395
Test set avg_accuracy=88.09% avg_sensitivity=59.99%, avg_specificity=96.51% avg_auc=0.9182
Fold[2] Epoch: 48 [48/100 (48%)] Train loss=0.226445 Test loss=0.303097 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.185915008187294
[5/23] Train loss=0.32335537672042847
[10/23] Train loss=0.19147787988185883
[15/23] Train loss=0.17637591063976288
[20/23] Train loss=0.1525644212961197
Test set avg_accuracy=87.78% avg_sensitivity=58.09%, avg_specificity=96.69% avg_auc=0.9141
Fold[2] Epoch: 49 [49/100 (49%)] Train loss=0.224224 Test loss=0.309809 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18615224957466125
[5/23] Train loss=0.330791711807251
[10/23] Train loss=0.18478453159332275
[15/23] Train loss=0.17306090891361237
[20/23] Train loss=0.148646742105484
Test set avg_accuracy=87.75% avg_sensitivity=59.13%, avg_specificity=96.34% avg_auc=0.9156
Fold[2] Epoch: 50 [50/100 (50%)] Train loss=0.221656 Test loss=0.309165 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1790952980518341
[5/23] Train loss=0.30410927534103394
[10/23] Train loss=0.19120919704437256
[15/23] Train loss=0.16508080065250397
[20/23] Train loss=0.1521710902452469
Test set avg_accuracy=87.93% avg_sensitivity=60.17%, avg_specificity=96.26% avg_auc=0.9166
Fold[2] Epoch: 51 [51/100 (51%)] Train loss=0.217575 Test loss=0.303212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1898840367794037
[5/23] Train loss=0.3147437870502472
[10/23] Train loss=0.18797042965888977
[15/23] Train loss=0.16688242554664612
[20/23] Train loss=0.15321223437786102
Test set avg_accuracy=88.05% avg_sensitivity=61.08%, avg_specificity=96.15% avg_auc=0.9166
Fold[2] Epoch: 52 [52/100 (52%)] Train loss=0.215420 Test loss=0.304759 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18484601378440857
[5/23] Train loss=0.3154967427253723
[10/23] Train loss=0.19574548304080963
[15/23] Train loss=0.16399255394935608
[20/23] Train loss=0.14796754717826843
Test set avg_accuracy=87.84% avg_sensitivity=58.14%, avg_specificity=96.74% avg_auc=0.9103
Fold[2] Epoch: 53 [53/100 (53%)] Train loss=0.216113 Test loss=0.316238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17956028878688812
[5/23] Train loss=0.29890570044517517
[10/23] Train loss=0.1904228776693344
[15/23] Train loss=0.15820394456386566
[20/23] Train loss=0.1450396478176117
Test set avg_accuracy=88.08% avg_sensitivity=63.56%, avg_specificity=95.43% avg_auc=0.9223
Fold[2] Epoch: 54 [54/100 (54%)] Train loss=0.213405 Test loss=0.291041 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17946147918701172
[5/23] Train loss=0.3020024597644806
[10/23] Train loss=0.18366850912570953
[15/23] Train loss=0.15901102125644684
[20/23] Train loss=0.14723075926303864
Test set avg_accuracy=87.81% avg_sensitivity=59.86%, avg_specificity=96.20% avg_auc=0.9117
Fold[2] Epoch: 55 [55/100 (55%)] Train loss=0.212959 Test loss=0.312149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.184268519282341
[5/23] Train loss=0.287665456533432
[10/23] Train loss=0.18888263404369354
[15/23] Train loss=0.16787144541740417
[20/23] Train loss=0.14490661025047302
Test set avg_accuracy=87.87% avg_sensitivity=61.39%, avg_specificity=95.81% avg_auc=0.9163
Fold[2] Epoch: 56 [56/100 (56%)] Train loss=0.211146 Test loss=0.306465 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17720264196395874
[5/23] Train loss=0.2880822718143463
[10/23] Train loss=0.185292050242424
[15/23] Train loss=0.16133154928684235
[20/23] Train loss=0.14903104305267334
Test set avg_accuracy=87.90% avg_sensitivity=60.62%, avg_specificity=96.08% avg_auc=0.9167
Fold[2] Epoch: 57 [57/100 (57%)] Train loss=0.209647 Test loss=0.307923 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17862851917743683
[5/23] Train loss=0.30325254797935486
[10/23] Train loss=0.19037993252277374
[15/23] Train loss=0.15825986862182617
[20/23] Train loss=0.14674827456474304
Test set avg_accuracy=88.18% avg_sensitivity=62.03%, avg_specificity=96.03% avg_auc=0.9184
Fold[2] Epoch: 58 [58/100 (58%)] Train loss=0.207232 Test loss=0.300844 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1815289855003357
[5/23] Train loss=0.28870105743408203
[10/23] Train loss=0.19334030151367188
[15/23] Train loss=0.16348698735237122
[20/23] Train loss=0.13817694783210754
Test set avg_accuracy=87.90% avg_sensitivity=59.31%, avg_specificity=96.47% avg_auc=0.9195
Fold[2] Epoch: 59 [59/100 (59%)] Train loss=0.207398 Test loss=0.304966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17907874286174774
[5/23] Train loss=0.2848098576068878
[10/23] Train loss=0.18404388427734375
[15/23] Train loss=0.1544368416070938
[20/23] Train loss=0.1370084136724472
Test set avg_accuracy=87.70% avg_sensitivity=58.77%, avg_specificity=96.38% avg_auc=0.9157
Fold[2] Epoch: 60 [60/100 (60%)] Train loss=0.203108 Test loss=0.314096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1760944128036499
[5/23] Train loss=0.2914077639579773
[10/23] Train loss=0.18993665277957916
[15/23] Train loss=0.15444009006023407
[20/23] Train loss=0.14056356251239777
Test set avg_accuracy=87.95% avg_sensitivity=59.90%, avg_specificity=96.37% avg_auc=0.9189
Fold[2] Epoch: 61 [61/100 (61%)] Train loss=0.204289 Test loss=0.305384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1763792335987091
[5/23] Train loss=0.28090301156044006
[10/23] Train loss=0.17924699187278748
[15/23] Train loss=0.15357235074043274
[20/23] Train loss=0.1364009529352188
Test set avg_accuracy=87.87% avg_sensitivity=59.22%, avg_specificity=96.46% avg_auc=0.9155
Fold[2] Epoch: 62 [62/100 (62%)] Train loss=0.199599 Test loss=0.314007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17386096715927124
[5/23] Train loss=0.2804526686668396
[10/23] Train loss=0.17543521523475647
[15/23] Train loss=0.14991553127765656
[20/23] Train loss=0.13838446140289307
Test set avg_accuracy=87.63% avg_sensitivity=61.35%, avg_specificity=95.51% avg_auc=0.9120
Fold[2] Epoch: 63 [63/100 (63%)] Train loss=0.197766 Test loss=0.316481 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1776113659143448
[5/23] Train loss=0.27948376536369324
[10/23] Train loss=0.18879033625125885
[15/23] Train loss=0.1534239649772644
[20/23] Train loss=0.13578209280967712
Test set avg_accuracy=87.98% avg_sensitivity=62.52%, avg_specificity=95.62% avg_auc=0.9165
Fold[2] Epoch: 64 [64/100 (64%)] Train loss=0.197462 Test loss=0.309187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1683894395828247
[5/23] Train loss=0.2711597979068756
[10/23] Train loss=0.17256709933280945
[15/23] Train loss=0.15149323642253876
[20/23] Train loss=0.13423743844032288
Test set avg_accuracy=88.33% avg_sensitivity=64.51%, avg_specificity=95.47% avg_auc=0.9177
Fold[2] Epoch: 65 [65/100 (65%)] Train loss=0.194772 Test loss=0.306261 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16800560057163239
[5/23] Train loss=0.2822360396385193
[10/23] Train loss=0.1716519147157669
[15/23] Train loss=0.14375713467597961
[20/23] Train loss=0.13554590940475464
Test set avg_accuracy=87.91% avg_sensitivity=64.65%, avg_specificity=94.89% avg_auc=0.9157
Fold[2] Epoch: 66 [66/100 (66%)] Train loss=0.192840 Test loss=0.310268 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17224065959453583
[5/23] Train loss=0.26129674911499023
[10/23] Train loss=0.1715056151151657
[15/23] Train loss=0.14347153902053833
[20/23] Train loss=0.12976965308189392
Test set avg_accuracy=87.79% avg_sensitivity=65.55%, avg_specificity=94.47% avg_auc=0.9177
Fold[2] Epoch: 67 [67/100 (67%)] Train loss=0.191360 Test loss=0.308958 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16396427154541016
[5/23] Train loss=0.2584610879421234
[10/23] Train loss=0.17547331750392914
[15/23] Train loss=0.1492210179567337
[20/23] Train loss=0.13405920565128326
Test set avg_accuracy=87.67% avg_sensitivity=63.02%, avg_specificity=95.06% avg_auc=0.9142
Fold[2] Epoch: 68 [68/100 (68%)] Train loss=0.190019 Test loss=0.313782 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1743132323026657
[5/23] Train loss=0.2680354714393616
[10/23] Train loss=0.1753378063440323
[15/23] Train loss=0.14535745978355408
[20/23] Train loss=0.13233132660388947
Test set avg_accuracy=87.28% avg_sensitivity=59.36%, avg_specificity=95.66% avg_auc=0.9130
Fold[2] Epoch: 69 [69/100 (69%)] Train loss=0.188168 Test loss=0.323958 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15837743878364563
[5/23] Train loss=0.26198142766952515
[10/23] Train loss=0.16858111321926117
[15/23] Train loss=0.1353870928287506
[20/23] Train loss=0.13046413660049438
Test set avg_accuracy=87.18% avg_sensitivity=61.30%, avg_specificity=94.94% avg_auc=0.9134
Fold[2] Epoch: 70 [70/100 (70%)] Train loss=0.185696 Test loss=0.315973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16223661601543427
[5/23] Train loss=0.24815693497657776
[10/23] Train loss=0.16217659413814545
[15/23] Train loss=0.14431707561016083
[20/23] Train loss=0.12457424402236938
Test set avg_accuracy=87.31% avg_sensitivity=61.26%, avg_specificity=95.13% avg_auc=0.9132
Fold[2] Epoch: 71 [71/100 (71%)] Train loss=0.185172 Test loss=0.316076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1677285134792328
[5/23] Train loss=0.25762683153152466
[10/23] Train loss=0.16581392288208008
[15/23] Train loss=0.1394892930984497
[20/23] Train loss=0.12296295911073685
Test set avg_accuracy=87.79% avg_sensitivity=62.70%, avg_specificity=95.32% avg_auc=0.9163
Fold[2] Epoch: 72 [72/100 (72%)] Train loss=0.183770 Test loss=0.313141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16605474054813385
[5/23] Train loss=0.2592889666557312
[10/23] Train loss=0.16827666759490967
[15/23] Train loss=0.13967444002628326
[20/23] Train loss=0.1232653260231018
Test set avg_accuracy=87.37% avg_sensitivity=60.26%, avg_specificity=95.50% avg_auc=0.9119
Fold[2] Epoch: 73 [73/100 (73%)] Train loss=0.183258 Test loss=0.323149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1633351445198059
[5/23] Train loss=0.24708035588264465
[10/23] Train loss=0.16718783974647522
[15/23] Train loss=0.13988347351551056
[20/23] Train loss=0.12269755452871323
Test set avg_accuracy=87.88% avg_sensitivity=62.84%, avg_specificity=95.39% avg_auc=0.9170
Fold[2] Epoch: 74 [74/100 (74%)] Train loss=0.179844 Test loss=0.312842 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16692133247852325
[5/23] Train loss=0.2547067403793335
[10/23] Train loss=0.1621035784482956
[15/23] Train loss=0.1263972967863083
[20/23] Train loss=0.125717431306839
Test set avg_accuracy=87.82% avg_sensitivity=60.53%, avg_specificity=96.01% avg_auc=0.9162
Fold[2] Epoch: 75 [75/100 (75%)] Train loss=0.177461 Test loss=0.321790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1592925488948822
[5/23] Train loss=0.2515268623828888
[10/23] Train loss=0.16893252730369568
[15/23] Train loss=0.1374291479587555
[20/23] Train loss=0.12306921929121017
Test set avg_accuracy=87.55% avg_sensitivity=58.54%, avg_specificity=96.26% avg_auc=0.9108
Fold[2] Epoch: 76 [76/100 (76%)] Train loss=0.176915 Test loss=0.327802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15518084168434143
[5/23] Train loss=0.2598716616630554
[10/23] Train loss=0.1617404818534851
[15/23] Train loss=0.14083032310009003
[20/23] Train loss=0.12068299949169159
Test set avg_accuracy=87.16% avg_sensitivity=58.95%, avg_specificity=95.62% avg_auc=0.9136
Fold[2] Epoch: 77 [77/100 (77%)] Train loss=0.175517 Test loss=0.323682 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15316538512706757
[5/23] Train loss=0.2477254420518875
[10/23] Train loss=0.15238024294376373
[15/23] Train loss=0.12987081706523895
[20/23] Train loss=0.12096420675516129
Test set avg_accuracy=87.33% avg_sensitivity=59.04%, avg_specificity=95.82% avg_auc=0.9109
Fold[2] Epoch: 78 [78/100 (78%)] Train loss=0.172613 Test loss=0.328512 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1545129418373108
[5/23] Train loss=0.24213182926177979
[10/23] Train loss=0.16673168540000916
[15/23] Train loss=0.13532641530036926
[20/23] Train loss=0.12132018804550171
Test set avg_accuracy=87.34% avg_sensitivity=59.18%, avg_specificity=95.80% avg_auc=0.9132
Fold[2] Epoch: 79 [79/100 (79%)] Train loss=0.170805 Test loss=0.325330 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15178357064723969
[5/23] Train loss=0.23386721312999725
[10/23] Train loss=0.15361452102661133
[15/23] Train loss=0.12910015881061554
[20/23] Train loss=0.10907487571239471
Test set avg_accuracy=87.38% avg_sensitivity=58.91%, avg_specificity=95.92% avg_auc=0.9117
Fold[2] Epoch: 80 [80/100 (80%)] Train loss=0.167415 Test loss=0.328907 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14407360553741455
[5/23] Train loss=0.24103766679763794
[10/23] Train loss=0.1495228111743927
[15/23] Train loss=0.12956717610359192
[20/23] Train loss=0.11049166321754456
Test set avg_accuracy=87.47% avg_sensitivity=57.78%, avg_specificity=96.38% avg_auc=0.9136
Fold[2] Epoch: 81 [81/100 (81%)] Train loss=0.167068 Test loss=0.329101 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15292826294898987
[5/23] Train loss=0.23633043467998505
[10/23] Train loss=0.14949887990951538
[15/23] Train loss=0.12492989748716354
[20/23] Train loss=0.11059557646512985
Test set avg_accuracy=87.47% avg_sensitivity=64.38%, avg_specificity=94.40% avg_auc=0.9102
Fold[2] Epoch: 82 [82/100 (82%)] Train loss=0.165643 Test loss=0.327454 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14968496561050415
[5/23] Train loss=0.22276875376701355
[10/23] Train loss=0.15233826637268066
[15/23] Train loss=0.12394754588603973
[20/23] Train loss=0.11654023081064224
Test set avg_accuracy=87.17% avg_sensitivity=63.52%, avg_specificity=94.26% avg_auc=0.9076
Fold[2] Epoch: 83 [83/100 (83%)] Train loss=0.164193 Test loss=0.330703 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15027955174446106
[5/23] Train loss=0.2165166288614273
[10/23] Train loss=0.14253191649913788
[15/23] Train loss=0.12636227905750275
[20/23] Train loss=0.11918728798627853
Test set avg_accuracy=87.98% avg_sensitivity=66.18%, avg_specificity=94.52% avg_auc=0.9166
Fold[2] Epoch: 84 [84/100 (84%)] Train loss=0.161006 Test loss=0.319130 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14700858294963837
[5/23] Train loss=0.2248799353837967
[10/23] Train loss=0.15196438133716583
[15/23] Train loss=0.12352798134088516
[20/23] Train loss=0.1059611514210701
Test set avg_accuracy=87.68% avg_sensitivity=66.09%, avg_specificity=94.15% avg_auc=0.9125
Fold[2] Epoch: 85 [85/100 (85%)] Train loss=0.159091 Test loss=0.327537 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1462477594614029
[5/23] Train loss=0.21734100580215454
[10/23] Train loss=0.14727237820625305
[15/23] Train loss=0.1266883760690689
[20/23] Train loss=0.10445046424865723
Test set avg_accuracy=87.56% avg_sensitivity=65.60%, avg_specificity=94.15% avg_auc=0.9177
Fold[2] Epoch: 86 [86/100 (86%)] Train loss=0.156086 Test loss=0.322361 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1461767554283142
[5/23] Train loss=0.2212548553943634
[10/23] Train loss=0.14115940034389496
[15/23] Train loss=0.11283379793167114
[20/23] Train loss=0.10867194086313248
Test set avg_accuracy=87.55% avg_sensitivity=60.71%, avg_specificity=95.61% avg_auc=0.9136
Fold[2] Epoch: 87 [87/100 (87%)] Train loss=0.153972 Test loss=0.331153 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1494341790676117
[5/23] Train loss=0.22309081256389618
[10/23] Train loss=0.1456388533115387
[15/23] Train loss=0.12203895300626755
[20/23] Train loss=0.10662077367305756
Test set avg_accuracy=87.79% avg_sensitivity=65.60%, avg_specificity=94.45% avg_auc=0.9175
Fold[2] Epoch: 88 [88/100 (88%)] Train loss=0.153886 Test loss=0.324021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14259877800941467
[5/23] Train loss=0.21607962250709534
[10/23] Train loss=0.14351367950439453
[15/23] Train loss=0.11846865713596344
[20/23] Train loss=0.10380971431732178
Test set avg_accuracy=87.07% avg_sensitivity=60.85%, avg_specificity=94.94% avg_auc=0.9098
Fold[2] Epoch: 89 [89/100 (89%)] Train loss=0.152581 Test loss=0.333093 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14572523534297943
[5/23] Train loss=0.21181553602218628
[10/23] Train loss=0.13920080661773682
[15/23] Train loss=0.11499207466840744
[20/23] Train loss=0.1031438559293747
Test set avg_accuracy=87.31% avg_sensitivity=62.52%, avg_specificity=94.75% avg_auc=0.9126
Fold[2] Epoch: 90 [90/100 (90%)] Train loss=0.151417 Test loss=0.328922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1433228701353073
[5/23] Train loss=0.2022702991962433
[10/23] Train loss=0.13390712440013885
[15/23] Train loss=0.11768028885126114
[20/23] Train loss=0.09960513561964035
Test set avg_accuracy=87.00% avg_sensitivity=65.55%, avg_specificity=93.44% avg_auc=0.9114
Fold[2] Epoch: 91 [91/100 (91%)] Train loss=0.146987 Test loss=0.333899 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14041027426719666
[5/23] Train loss=0.2014523595571518
[10/23] Train loss=0.1402963399887085
[15/23] Train loss=0.11524675786495209
[20/23] Train loss=0.10032221674919128
Test set avg_accuracy=88.44% avg_sensitivity=68.13%, avg_specificity=94.53% avg_auc=0.9188
Best model saved!! Metric=16.983814987056576!!
Fold[2] Epoch: 92 [92/100 (92%)] Train loss=0.146507 Test loss=0.322032 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13942165672779083
[5/23] Train loss=0.19528092443943024
[10/23] Train loss=0.13688938319683075
[15/23] Train loss=0.11172164231538773
[20/23] Train loss=0.10280623286962509
Test set avg_accuracy=88.16% avg_sensitivity=68.22%, avg_specificity=94.14% avg_auc=0.9188
Fold[2] Epoch: 93 [93/100 (93%)] Train loss=0.145465 Test loss=0.324857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13766571879386902
[5/23] Train loss=0.2034330666065216
[10/23] Train loss=0.14135220646858215
[15/23] Train loss=0.10710994899272919
[20/23] Train loss=0.09072186797857285
Test set avg_accuracy=87.98% avg_sensitivity=68.81%, avg_specificity=93.73% avg_auc=0.9160
Fold[2] Epoch: 94 [94/100 (94%)] Train loss=0.142353 Test loss=0.331592 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1388002336025238
[5/23] Train loss=0.19823743402957916
[10/23] Train loss=0.13106176257133484
[15/23] Train loss=0.10988646745681763
[20/23] Train loss=0.103802889585495
Test set avg_accuracy=87.91% avg_sensitivity=66.77%, avg_specificity=94.25% avg_auc=0.9150
Fold[2] Epoch: 95 [95/100 (95%)] Train loss=0.141891 Test loss=0.332154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13043679296970367
[5/23] Train loss=0.19043050706386566
[10/23] Train loss=0.11891842633485794
[15/23] Train loss=0.10738620162010193
[20/23] Train loss=0.09221019595861435
Test set avg_accuracy=87.23% avg_sensitivity=63.07%, avg_specificity=94.48% avg_auc=0.9123
Fold[2] Epoch: 96 [96/100 (96%)] Train loss=0.137462 Test loss=0.339677 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13366582989692688
[5/23] Train loss=0.17524012923240662
[10/23] Train loss=0.13761264085769653
[15/23] Train loss=0.10652653127908707
[20/23] Train loss=0.09443844854831696
Test set avg_accuracy=86.97% avg_sensitivity=63.74%, avg_specificity=93.94% avg_auc=0.9096
Fold[2] Epoch: 97 [97/100 (97%)] Train loss=0.138308 Test loss=0.343144 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1284923106431961
[5/23] Train loss=0.1774459183216095
[10/23] Train loss=0.1291118860244751
[15/23] Train loss=0.10690975934267044
[20/23] Train loss=0.09344245493412018
Test set avg_accuracy=87.55% avg_sensitivity=64.92%, avg_specificity=94.34% avg_auc=0.9098
Fold[2] Epoch: 98 [98/100 (98%)] Train loss=0.135223 Test loss=0.341833 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11906901001930237
[5/23] Train loss=0.19257092475891113
[10/23] Train loss=0.13146370649337769
[15/23] Train loss=0.1120581105351448
[20/23] Train loss=0.0884355753660202
Test set avg_accuracy=87.20% avg_sensitivity=63.07%, avg_specificity=94.44% avg_auc=0.9099
Fold[2] Epoch: 99 [99/100 (99%)] Train loss=0.133766 Test loss=0.345933 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12384345382452011
[5/23] Train loss=0.17738524079322815
[10/23] Train loss=0.12529447674751282
[15/23] Train loss=0.10522862523794174
[20/23] Train loss=0.08685573935508728
Test set avg_accuracy=87.44% avg_sensitivity=64.24%, avg_specificity=94.40% avg_auc=0.9139
Fold[2] Epoch: 100 [100/100 (100%)] Train loss=0.127172 Test loss=0.340509 Current lr=[3.9999999999999996e-05]

Fold[2] Best Result: acc=88.44027125717267 sen=68.12839059674502, spe=94.53411094534111, auc=0.9188104218779778!
[0/23] Train loss=0.6941179633140564
[5/23] Train loss=0.6613523364067078
[10/23] Train loss=0.5534225106239319
[15/23] Train loss=0.5328390002250671
[20/23] Train loss=0.4997473359107971
Test set avg_accuracy=68.35% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7946
Best model saved!! Metric=-78.19395186338348!!
Fold[3] Epoch: 1 [1/100 (1%)] Train loss=0.548054 Test loss=0.699077 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48741647601127625
[5/23] Train loss=0.5373821258544922
[10/23] Train loss=0.4426409602165222
[15/23] Train loss=0.42495468258857727
[20/23] Train loss=0.3779538869857788
Test set avg_accuracy=72.61% avg_sensitivity=24.48%, avg_specificity=94.90% avg_auc=0.8471
Best model saved!! Metric=-49.3048508159719!!
Fold[3] Epoch: 2 [2/100 (2%)] Train loss=0.436114 Test loss=0.567238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3770099878311157
[5/23] Train loss=0.46901950240135193
[10/23] Train loss=0.3920561969280243
[15/23] Train loss=0.3997601270675659
[20/23] Train loss=0.34440675377845764
Test set avg_accuracy=78.07% avg_sensitivity=46.87%, avg_specificity=92.52% avg_auc=0.8674
Best model saved!! Metric=-21.80804020425066!!
Fold[3] Epoch: 3 [3/100 (3%)] Train loss=0.392375 Test loss=0.464793 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3523154556751251
[5/23] Train loss=0.439910352230072
[10/23] Train loss=0.34420982003211975
[15/23] Train loss=0.373909056186676
[20/23] Train loss=0.32781147956848145
Test set avg_accuracy=78.67% avg_sensitivity=46.93%, avg_specificity=93.36% avg_auc=0.8774
Best model saved!! Metric=-19.299182530766572!!
Fold[3] Epoch: 4 [4/100 (4%)] Train loss=0.370535 Test loss=0.441504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33564186096191406
[5/23] Train loss=0.45626649260520935
[10/23] Train loss=0.33913469314575195
[15/23] Train loss=0.35009482502937317
[20/23] Train loss=0.30303579568862915
Test set avg_accuracy=79.44% avg_sensitivity=51.67%, avg_specificity=92.30% avg_auc=0.8812
Best model saved!! Metric=-14.455796901169734!!
Fold[3] Epoch: 5 [5/100 (5%)] Train loss=0.356448 Test loss=0.438167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3159874677658081
[5/23] Train loss=0.4386883080005646
[10/23] Train loss=0.3190055191516876
[15/23] Train loss=0.33742716908454895
[20/23] Train loss=0.2831447124481201
Test set avg_accuracy=80.06% avg_sensitivity=56.72%, avg_specificity=90.88% avg_auc=0.8847
Best model saved!! Metric=-9.872950281792523!!
Fold[3] Epoch: 6 [6/100 (6%)] Train loss=0.342758 Test loss=0.420234 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2909069359302521
[5/23] Train loss=0.43001124262809753
[10/23] Train loss=0.2942557632923126
[15/23] Train loss=0.30796557664871216
[20/23] Train loss=0.27016568183898926
Test set avg_accuracy=81.06% avg_sensitivity=60.40%, avg_specificity=90.63% avg_auc=0.8880
Best model saved!! Metric=-5.108924335830194!!
Fold[3] Epoch: 7 [7/100 (7%)] Train loss=0.330118 Test loss=0.407306 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28636443614959717
[5/23] Train loss=0.4491278827190399
[10/23] Train loss=0.2796574831008911
[15/23] Train loss=0.27928486466407776
[20/23] Train loss=0.2541361153125763
Test set avg_accuracy=81.48% avg_sensitivity=63.58%, avg_specificity=89.77% avg_auc=0.8913
Best model saved!! Metric=-2.0414413372457902!!
Fold[3] Epoch: 8 [8/100 (8%)] Train loss=0.319348 Test loss=0.404003 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2751801311969757
[5/23] Train loss=0.42101457715034485
[10/23] Train loss=0.2682691216468811
[15/23] Train loss=0.27737709879875183
[20/23] Train loss=0.2430829554796219
Test set avg_accuracy=81.69% avg_sensitivity=64.58%, avg_specificity=89.62% avg_auc=0.8943
Best model saved!! Metric=-0.6821603566606074!!
Fold[3] Epoch: 9 [9/100 (9%)] Train loss=0.306920 Test loss=0.400878 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2571316659450531
[5/23] Train loss=0.4196603298187256
[10/23] Train loss=0.2516213655471802
[15/23] Train loss=0.26486828923225403
[20/23] Train loss=0.24008139967918396
Test set avg_accuracy=82.30% avg_sensitivity=66.14%, avg_specificity=89.78% avg_auc=0.8963
Best model saved!! Metric=1.8501318373559914!!
Fold[3] Epoch: 10 [10/100 (10%)] Train loss=0.299712 Test loss=0.398679 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2456519901752472
[5/23] Train loss=0.4133663475513458
[10/23] Train loss=0.2499988079071045
[15/23] Train loss=0.25288692116737366
[20/23] Train loss=0.22757244110107422
Test set avg_accuracy=82.47% avg_sensitivity=66.57%, avg_specificity=89.83% avg_auc=0.9002
Best model saved!! Metric=2.8902987993135545!!
Fold[3] Epoch: 11 [11/100 (11%)] Train loss=0.289784 Test loss=0.397726 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24504777789115906
[5/23] Train loss=0.4147813022136688
[10/23] Train loss=0.24758516252040863
[15/23] Train loss=0.24070456624031067
[20/23] Train loss=0.22220665216445923
Test set avg_accuracy=82.80% avg_sensitivity=66.77%, avg_specificity=90.23% avg_auc=0.9031
Best model saved!! Metric=4.113321735922474!!
Fold[3] Epoch: 12 [12/100 (12%)] Train loss=0.287004 Test loss=0.391428 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.244439959526062
[5/23] Train loss=0.42897218465805054
[10/23] Train loss=0.2430555373430252
[15/23] Train loss=0.24084286391735077
[20/23] Train loss=0.21369312703609467
Test set avg_accuracy=82.73% avg_sensitivity=65.77%, avg_specificity=90.58% avg_auc=0.9056
Fold[3] Epoch: 13 [13/100 (13%)] Train loss=0.282150 Test loss=0.386654 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23036973178386688
[5/23] Train loss=0.4107140302658081
[10/23] Train loss=0.22793881595134735
[15/23] Train loss=0.22837136685848236
[20/23] Train loss=0.21256838738918304
Test set avg_accuracy=83.20% avg_sensitivity=66.57%, avg_specificity=90.91% avg_auc=0.9075
Best model saved!! Metric=5.4214943160992615!!
Fold[3] Epoch: 14 [14/100 (14%)] Train loss=0.276768 Test loss=0.390303 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22708922624588013
[5/23] Train loss=0.4144155979156494
[10/23] Train loss=0.22241637110710144
[15/23] Train loss=0.23182126879692078
[20/23] Train loss=0.21443969011306763
Test set avg_accuracy=83.39% avg_sensitivity=67.46%, avg_specificity=90.77% avg_auc=0.9089
Best model saved!! Metric=6.508303598143935!!
Fold[3] Epoch: 15 [15/100 (15%)] Train loss=0.273489 Test loss=0.385887 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22359344363212585
[5/23] Train loss=0.4028303623199463
[10/23] Train loss=0.23394207656383514
[15/23] Train loss=0.22166502475738525
[20/23] Train loss=0.19335176050662994
Test set avg_accuracy=83.42% avg_sensitivity=68.06%, avg_specificity=90.54% avg_auc=0.9095
Best model saved!! Metric=6.973603504184025!!
Fold[3] Epoch: 16 [16/100 (16%)] Train loss=0.267708 Test loss=0.384724 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22036269307136536
[5/23] Train loss=0.3956247568130493
[10/23] Train loss=0.2198317050933838
[15/23] Train loss=0.2172178477048874
[20/23] Train loss=0.20629797875881195
Test set avg_accuracy=83.35% avg_sensitivity=68.03%, avg_specificity=90.45% avg_auc=0.9100
Fold[3] Epoch: 17 [17/100 (17%)] Train loss=0.264583 Test loss=0.377930 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22669079899787903
[5/23] Train loss=0.37909045815467834
[10/23] Train loss=0.2265438735485077
[15/23] Train loss=0.21901550889015198
[20/23] Train loss=0.19655491411685944
Test set avg_accuracy=83.55% avg_sensitivity=67.93%, avg_specificity=90.78% avg_auc=0.9119
Best model saved!! Metric=7.446460662486187!!
Fold[3] Epoch: 18 [18/100 (18%)] Train loss=0.263828 Test loss=0.379301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2243334949016571
[5/23] Train loss=0.37847086787223816
[10/23] Train loss=0.2191871553659439
[15/23] Train loss=0.21795552968978882
[20/23] Train loss=0.19874471426010132
Test set avg_accuracy=83.31% avg_sensitivity=66.87%, avg_specificity=90.92% avg_auc=0.9106
Fold[3] Epoch: 19 [19/100 (19%)] Train loss=0.257876 Test loss=0.386132 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2110712230205536
[5/23] Train loss=0.38662949204444885
[10/23] Train loss=0.21529555320739746
[15/23] Train loss=0.21439193189144135
[20/23] Train loss=0.19114965200424194
Test set avg_accuracy=83.51% avg_sensitivity=67.43%, avg_specificity=90.95% avg_auc=0.9115
Fold[3] Epoch: 20 [20/100 (20%)] Train loss=0.259677 Test loss=0.379576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21103128790855408
[5/23] Train loss=0.39841628074645996
[10/23] Train loss=0.2068849354982376
[15/23] Train loss=0.20554322004318237
[20/23] Train loss=0.1876356154680252
Test set avg_accuracy=83.78% avg_sensitivity=67.20%, avg_specificity=91.46% avg_auc=0.9129
Best model saved!! Metric=7.728708943479651!!
Fold[3] Epoch: 21 [21/100 (21%)] Train loss=0.254053 Test loss=0.376891 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21623285114765167
[5/23] Train loss=0.37778836488723755
[10/23] Train loss=0.20995651185512543
[15/23] Train loss=0.20201461017131805
[20/23] Train loss=0.19441106915473938
Test set avg_accuracy=83.71% avg_sensitivity=67.20%, avg_specificity=91.35% avg_auc=0.9122
Fold[3] Epoch: 22 [22/100 (22%)] Train loss=0.252501 Test loss=0.374034 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20956698060035706
[5/23] Train loss=0.37703290581703186
[10/23] Train loss=0.21424061059951782
[15/23] Train loss=0.20680323243141174
[20/23] Train loss=0.19082807004451752
Test set avg_accuracy=83.51% avg_sensitivity=66.17%, avg_specificity=91.54% avg_auc=0.9124
Fold[3] Epoch: 23 [23/100 (23%)] Train loss=0.250018 Test loss=0.375769 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20572389662265778
[5/23] Train loss=0.3838965892791748
[10/23] Train loss=0.21598580479621887
[15/23] Train loss=0.19958198070526123
[20/23] Train loss=0.1826339066028595
Test set avg_accuracy=83.36% avg_sensitivity=63.85%, avg_specificity=92.40% avg_auc=0.9121
Fold[3] Epoch: 24 [24/100 (24%)] Train loss=0.248218 Test loss=0.382632 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20533545315265656
[5/23] Train loss=0.3648862838745117
[10/23] Train loss=0.2046905905008316
[15/23] Train loss=0.1990787237882614
[20/23] Train loss=0.18301759660243988
Test set avg_accuracy=83.71% avg_sensitivity=65.34%, avg_specificity=92.21% avg_auc=0.9137
Fold[3] Epoch: 25 [25/100 (25%)] Train loss=0.245241 Test loss=0.378202 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20140880346298218
[5/23] Train loss=0.37091413140296936
[10/23] Train loss=0.20558388531208038
[15/23] Train loss=0.19374068081378937
[20/23] Train loss=0.17856022715568542
Test set avg_accuracy=83.70% avg_sensitivity=65.90%, avg_specificity=91.94% avg_auc=0.9145
Fold[3] Epoch: 26 [26/100 (26%)] Train loss=0.243812 Test loss=0.371144 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20289437472820282
[5/23] Train loss=0.3725392818450928
[10/23] Train loss=0.20647622644901276
[15/23] Train loss=0.19171889126300812
[20/23] Train loss=0.18358266353607178
Test set avg_accuracy=83.80% avg_sensitivity=64.91%, avg_specificity=92.55% avg_auc=0.9143
Fold[3] Epoch: 27 [27/100 (27%)] Train loss=0.243154 Test loss=0.373014 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20465919375419617
[5/23] Train loss=0.3579195737838745
[10/23] Train loss=0.19951385259628296
[15/23] Train loss=0.20166531205177307
[20/23] Train loss=0.17789825797080994
Test set avg_accuracy=83.72% avg_sensitivity=65.70%, avg_specificity=92.06% avg_auc=0.9145
Fold[3] Epoch: 28 [28/100 (28%)] Train loss=0.240563 Test loss=0.374997 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21056310832500458
[5/23] Train loss=0.3598325550556183
[10/23] Train loss=0.20188385248184204
[15/23] Train loss=0.20329999923706055
[20/23] Train loss=0.17359867691993713
Test set avg_accuracy=83.85% avg_sensitivity=64.84%, avg_specificity=92.66% avg_auc=0.9149
Fold[3] Epoch: 29 [29/100 (29%)] Train loss=0.240326 Test loss=0.374102 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2041640728712082
[5/23] Train loss=0.36109745502471924
[10/23] Train loss=0.19851720333099365
[15/23] Train loss=0.18197277188301086
[20/23] Train loss=0.17162184417247772
Test set avg_accuracy=84.18% avg_sensitivity=65.31%, avg_specificity=92.92% avg_auc=0.9154
Best model saved!! Metric=7.942524838062393!!
Fold[3] Epoch: 30 [30/100 (30%)] Train loss=0.235097 Test loss=0.370081 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1984879970550537
[5/23] Train loss=0.34167903661727905
[10/23] Train loss=0.19755782186985016
[15/23] Train loss=0.18779566884040833
[20/23] Train loss=0.1666654348373413
Test set avg_accuracy=84.04% avg_sensitivity=64.21%, avg_specificity=93.23% avg_auc=0.9164
Fold[3] Epoch: 31 [31/100 (31%)] Train loss=0.234273 Test loss=0.369174 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1951196789741516
[5/23] Train loss=0.3639112710952759
[10/23] Train loss=0.19399788975715637
[15/23] Train loss=0.1854233294725418
[20/23] Train loss=0.16944825649261475
Test set avg_accuracy=84.44% avg_sensitivity=66.04%, avg_specificity=92.96% avg_auc=0.9170
Best model saved!! Metric=9.141436280503454!!
Fold[3] Epoch: 32 [32/100 (32%)] Train loss=0.233276 Test loss=0.365969 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19782333076000214
[5/23] Train loss=0.3613487184047699
[10/23] Train loss=0.20247188210487366
[15/23] Train loss=0.18258744478225708
[20/23] Train loss=0.1672029048204422
Test set avg_accuracy=84.24% avg_sensitivity=65.64%, avg_specificity=92.86% avg_auc=0.9174
Fold[3] Epoch: 33 [33/100 (33%)] Train loss=0.231920 Test loss=0.364735 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20270565152168274
[5/23] Train loss=0.3502635061740875
[10/23] Train loss=0.191148042678833
[15/23] Train loss=0.18994496762752533
[20/23] Train loss=0.1734330654144287
Test set avg_accuracy=84.20% avg_sensitivity=63.65%, avg_specificity=93.72% avg_auc=0.9162
Fold[3] Epoch: 34 [34/100 (34%)] Train loss=0.229330 Test loss=0.370278 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20004215836524963
[5/23] Train loss=0.33444744348526
[10/23] Train loss=0.1996190845966339
[15/23] Train loss=0.18690623342990875
[20/23] Train loss=0.16339336335659027
Test set avg_accuracy=84.40% avg_sensitivity=64.61%, avg_specificity=93.56% avg_auc=0.9171
Fold[3] Epoch: 35 [35/100 (35%)] Train loss=0.228091 Test loss=0.370349 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19789661467075348
[5/23] Train loss=0.33809319138526917
[10/23] Train loss=0.19917675852775574
[15/23] Train loss=0.17792560160160065
[20/23] Train loss=0.16302774846553802
Test set avg_accuracy=84.35% avg_sensitivity=64.58%, avg_specificity=93.50% avg_auc=0.9159
Fold[3] Epoch: 36 [36/100 (36%)] Train loss=0.224544 Test loss=0.373702 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18857720494270325
[5/23] Train loss=0.34147366881370544
[10/23] Train loss=0.1930082142353058
[15/23] Train loss=0.1837894767522812
[20/23] Train loss=0.16342774033546448
Test set avg_accuracy=84.71% avg_sensitivity=65.64%, avg_specificity=93.55% avg_auc=0.9162
Best model saved!! Metric=9.524591102408142!!
Fold[3] Epoch: 37 [37/100 (37%)] Train loss=0.226449 Test loss=0.370658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1925523579120636
[5/23] Train loss=0.3485235869884491
[10/23] Train loss=0.1860036551952362
[15/23] Train loss=0.17725075781345367
[20/23] Train loss=0.17113818228244781
Test set avg_accuracy=84.45% avg_sensitivity=65.14%, avg_specificity=93.39% avg_auc=0.9172
Fold[3] Epoch: 38 [38/100 (38%)] Train loss=0.224544 Test loss=0.364876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19649937748908997
[5/23] Train loss=0.3213110566139221
[10/23] Train loss=0.19523663818836212
[15/23] Train loss=0.17747212946414948
[20/23] Train loss=0.1561347097158432
Test set avg_accuracy=84.35% avg_sensitivity=62.85%, avg_specificity=94.30% avg_auc=0.9156
Fold[3] Epoch: 39 [39/100 (39%)] Train loss=0.221022 Test loss=0.374598 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1881941258907318
[5/23] Train loss=0.3222857117652893
[10/23] Train loss=0.18792890012264252
[15/23] Train loss=0.17993448674678802
[20/23] Train loss=0.15085232257843018
Test set avg_accuracy=84.36% avg_sensitivity=64.28%, avg_specificity=93.66% avg_auc=0.9165
Fold[3] Epoch: 40 [40/100 (40%)] Train loss=0.218515 Test loss=0.370120 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18376290798187256
[5/23] Train loss=0.3143306076526642
[10/23] Train loss=0.18676145374774933
[15/23] Train loss=0.17229712009429932
[20/23] Train loss=0.15049079060554504
Test set avg_accuracy=84.61% avg_sensitivity=64.25%, avg_specificity=94.04% avg_auc=0.9167
Fold[3] Epoch: 41 [41/100 (41%)] Train loss=0.214924 Test loss=0.375457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1848175823688507
[5/23] Train loss=0.3101666569709778
[10/23] Train loss=0.187820702791214
[15/23] Train loss=0.16757020354270935
[20/23] Train loss=0.15436594188213348
Test set avg_accuracy=84.42% avg_sensitivity=63.32%, avg_specificity=94.19% avg_auc=0.9167
Fold[3] Epoch: 42 [42/100 (42%)] Train loss=0.213150 Test loss=0.379991 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1937023550271988
[5/23] Train loss=0.32588663697242737
[10/23] Train loss=0.18514412641525269
[15/23] Train loss=0.17238517105579376
[20/23] Train loss=0.15205052495002747
Test set avg_accuracy=84.41% avg_sensitivity=63.98%, avg_specificity=93.87% avg_auc=0.9164
Fold[3] Epoch: 43 [43/100 (43%)] Train loss=0.213319 Test loss=0.376078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1894998550415039
[5/23] Train loss=0.32082322239875793
[10/23] Train loss=0.18737755715847015
[15/23] Train loss=0.16810962557792664
[20/23] Train loss=0.15223929286003113
Test set avg_accuracy=84.45% avg_sensitivity=63.18%, avg_specificity=94.30% avg_auc=0.9157
Fold[3] Epoch: 44 [44/100 (44%)] Train loss=0.212741 Test loss=0.383462 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1829226166009903
[5/23] Train loss=0.31890133023262024
[10/23] Train loss=0.18343031406402588
[15/23] Train loss=0.17025290429592133
[20/23] Train loss=0.1542949229478836
Test set avg_accuracy=84.41% avg_sensitivity=63.08%, avg_specificity=94.29% avg_auc=0.9137
Fold[3] Epoch: 45 [45/100 (45%)] Train loss=0.210863 Test loss=0.388014 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18007947504520416
[5/23] Train loss=0.3173379898071289
[10/23] Train loss=0.18099196255207062
[15/23] Train loss=0.1689796894788742
[20/23] Train loss=0.1531413495540619
Test set avg_accuracy=84.37% avg_sensitivity=63.35%, avg_specificity=94.10% avg_auc=0.9152
Fold[3] Epoch: 46 [46/100 (46%)] Train loss=0.208307 Test loss=0.381688 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17628297209739685
[5/23] Train loss=0.3163996934890747
[10/23] Train loss=0.17759425938129425
[15/23] Train loss=0.1689974069595337
[20/23] Train loss=0.15211139619350433
Test set avg_accuracy=84.28% avg_sensitivity=62.52%, avg_specificity=94.36% avg_auc=0.9144
Fold[3] Epoch: 47 [47/100 (47%)] Train loss=0.207928 Test loss=0.388738 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18000094592571259
[5/23] Train loss=0.318204790353775
[10/23] Train loss=0.18386097252368927
[15/23] Train loss=0.16436581313610077
[20/23] Train loss=0.14295506477355957
Test set avg_accuracy=84.29% avg_sensitivity=62.16%, avg_specificity=94.55% avg_auc=0.9147
Fold[3] Epoch: 48 [48/100 (48%)] Train loss=0.204583 Test loss=0.385586 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17540793120861053
[5/23] Train loss=0.32978352904319763
[10/23] Train loss=0.18199951946735382
[15/23] Train loss=0.16691221296787262
[20/23] Train loss=0.15049754083156586
Test set avg_accuracy=83.97% avg_sensitivity=61.92%, avg_specificity=94.18% avg_auc=0.9145
Fold[3] Epoch: 49 [49/100 (49%)] Train loss=0.204150 Test loss=0.385988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1789173036813736
[5/23] Train loss=0.3145614266395569
[10/23] Train loss=0.18019209802150726
[15/23] Train loss=0.16477686166763306
[20/23] Train loss=0.14744432270526886
Test set avg_accuracy=84.29% avg_sensitivity=62.95%, avg_specificity=94.18% avg_auc=0.9139
Fold[3] Epoch: 50 [50/100 (50%)] Train loss=0.204785 Test loss=0.381299 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18240249156951904
[5/23] Train loss=0.30327165126800537
[10/23] Train loss=0.17871791124343872
[15/23] Train loss=0.16078759729862213
[20/23] Train loss=0.14382228255271912
Test set avg_accuracy=84.03% avg_sensitivity=61.92%, avg_specificity=94.27% avg_auc=0.9144
Fold[3] Epoch: 51 [51/100 (51%)] Train loss=0.201009 Test loss=0.391049 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18292084336280823
[5/23] Train loss=0.30293601751327515
[10/23] Train loss=0.17808088660240173
[15/23] Train loss=0.16151930391788483
[20/23] Train loss=0.14091505110263824
Test set avg_accuracy=83.85% avg_sensitivity=61.66%, avg_specificity=94.13% avg_auc=0.9151
Fold[3] Epoch: 52 [52/100 (52%)] Train loss=0.198796 Test loss=0.385870 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17199015617370605
[5/23] Train loss=0.29882895946502686
[10/23] Train loss=0.18567119538784027
[15/23] Train loss=0.15630045533180237
[20/23] Train loss=0.14045308530330658
Test set avg_accuracy=83.93% avg_sensitivity=61.39%, avg_specificity=94.36% avg_auc=0.9130
Fold[3] Epoch: 53 [53/100 (53%)] Train loss=0.196437 Test loss=0.395159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18067443370819092
[5/23] Train loss=0.2950403094291687
[10/23] Train loss=0.17481954395771027
[15/23] Train loss=0.15134508907794952
[20/23] Train loss=0.14373640716075897
Test set avg_accuracy=84.07% avg_sensitivity=62.49%, avg_specificity=94.07% avg_auc=0.9137
Fold[3] Epoch: 54 [54/100 (54%)] Train loss=0.196729 Test loss=0.394488 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17610394954681396
[5/23] Train loss=0.30532607436180115
[10/23] Train loss=0.1744660884141922
[15/23] Train loss=0.15187230706214905
[20/23] Train loss=0.14035101234912872
Test set avg_accuracy=84.00% avg_sensitivity=61.96%, avg_specificity=94.21% avg_auc=0.9140
Fold[3] Epoch: 55 [55/100 (55%)] Train loss=0.192378 Test loss=0.391679 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16927659511566162
[5/23] Train loss=0.2949245870113373
[10/23] Train loss=0.18252339959144592
[15/23] Train loss=0.16272816061973572
[20/23] Train loss=0.1341044157743454
Test set avg_accuracy=83.82% avg_sensitivity=62.16%, avg_specificity=93.86% avg_auc=0.9126
Fold[3] Epoch: 56 [56/100 (56%)] Train loss=0.194518 Test loss=0.395497 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17636515200138092
[5/23] Train loss=0.28482693433761597
[10/23] Train loss=0.16693463921546936
[15/23] Train loss=0.1559809148311615
[20/23] Train loss=0.1353546530008316
Test set avg_accuracy=84.05% avg_sensitivity=62.55%, avg_specificity=94.01% avg_auc=0.9141
Fold[3] Epoch: 57 [57/100 (57%)] Train loss=0.189696 Test loss=0.393136 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17196373641490936
[5/23] Train loss=0.2959035336971283
[10/23] Train loss=0.17344839870929718
[15/23] Train loss=0.15313337743282318
[20/23] Train loss=0.13352613151073456
Test set avg_accuracy=83.69% avg_sensitivity=60.36%, avg_specificity=94.49% avg_auc=0.9124
Fold[3] Epoch: 58 [58/100 (58%)] Train loss=0.190010 Test loss=0.401556 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16498424112796783
[5/23] Train loss=0.28723543882369995
[10/23] Train loss=0.1670236587524414
[15/23] Train loss=0.1576099544763565
[20/23] Train loss=0.1353117823600769
Test set avg_accuracy=83.48% avg_sensitivity=59.60%, avg_specificity=94.53% avg_auc=0.9110
Fold[3] Epoch: 59 [59/100 (59%)] Train loss=0.187610 Test loss=0.404499 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16141822934150696
[5/23] Train loss=0.2833716869354248
[10/23] Train loss=0.17116738855838776
[15/23] Train loss=0.13965925574302673
[20/23] Train loss=0.13651613891124725
Test set avg_accuracy=83.67% avg_sensitivity=60.43%, avg_specificity=94.44% avg_auc=0.9112
Fold[3] Epoch: 60 [60/100 (60%)] Train loss=0.185225 Test loss=0.405744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16355766355991364
[5/23] Train loss=0.2766887843608856
[10/23] Train loss=0.1673422008752823
[15/23] Train loss=0.145341694355011
[20/23] Train loss=0.13224384188652039
Test set avg_accuracy=83.75% avg_sensitivity=60.76%, avg_specificity=94.39% avg_auc=0.9116
Fold[3] Epoch: 61 [61/100 (61%)] Train loss=0.181169 Test loss=0.406858 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16127867996692657
[5/23] Train loss=0.29067474603652954
[10/23] Train loss=0.16563200950622559
[15/23] Train loss=0.1443149298429489
[20/23] Train loss=0.12716469168663025
Test set avg_accuracy=83.50% avg_sensitivity=60.07%, avg_specificity=94.35% avg_auc=0.9108
Fold[3] Epoch: 62 [62/100 (62%)] Train loss=0.182582 Test loss=0.407523 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17112942039966583
[5/23] Train loss=0.27693402767181396
[10/23] Train loss=0.16210158169269562
[15/23] Train loss=0.1457435041666031
[20/23] Train loss=0.12362435460090637
Test set avg_accuracy=83.73% avg_sensitivity=61.33%, avg_specificity=94.10% avg_auc=0.9106
Fold[3] Epoch: 63 [63/100 (63%)] Train loss=0.180224 Test loss=0.400579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1647166758775711
[5/23] Train loss=0.2607892155647278
[10/23] Train loss=0.1638154834508896
[15/23] Train loss=0.14482469856739044
[20/23] Train loss=0.1273563951253891
Test set avg_accuracy=83.57% avg_sensitivity=59.73%, avg_specificity=94.61% avg_auc=0.9102
Fold[3] Epoch: 64 [64/100 (64%)] Train loss=0.177273 Test loss=0.407482 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15712964534759521
[5/23] Train loss=0.26211467385292053
[10/23] Train loss=0.1633944809436798
[15/23] Train loss=0.1402626782655716
[20/23] Train loss=0.1239292249083519
Test set avg_accuracy=83.65% avg_sensitivity=60.73%, avg_specificity=94.27% avg_auc=0.9086
Fold[3] Epoch: 65 [65/100 (65%)] Train loss=0.174961 Test loss=0.419752 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1556263417005539
[5/23] Train loss=0.2697751224040985
[10/23] Train loss=0.16313257813453674
[15/23] Train loss=0.13455426692962646
[20/23] Train loss=0.126796156167984
Test set avg_accuracy=83.88% avg_sensitivity=61.99%, avg_specificity=94.02% avg_auc=0.9106
Fold[3] Epoch: 66 [66/100 (66%)] Train loss=0.172469 Test loss=0.410072 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16125735640525818
[5/23] Train loss=0.2624194622039795
[10/23] Train loss=0.15775816142559052
[15/23] Train loss=0.14174173772335052
[20/23] Train loss=0.1270224004983902
Test set avg_accuracy=83.63% avg_sensitivity=61.19%, avg_specificity=94.02% avg_auc=0.9110
Fold[3] Epoch: 67 [67/100 (67%)] Train loss=0.174012 Test loss=0.411134 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16538693010807037
[5/23] Train loss=0.2637326717376709
[10/23] Train loss=0.15734638273715973
[15/23] Train loss=0.13955093920230865
[20/23] Train loss=0.12292210012674332
Test set avg_accuracy=83.73% avg_sensitivity=60.63%, avg_specificity=94.42% avg_auc=0.9124
Fold[3] Epoch: 68 [68/100 (68%)] Train loss=0.171031 Test loss=0.416642 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15767692029476166
[5/23] Train loss=0.26645952463150024
[10/23] Train loss=0.15583939850330353
[15/23] Train loss=0.13519202172756195
[20/23] Train loss=0.11760667711496353
Test set avg_accuracy=83.41% avg_sensitivity=59.90%, avg_specificity=94.30% avg_auc=0.9115
Fold[3] Epoch: 69 [69/100 (69%)] Train loss=0.169317 Test loss=0.421588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15608318150043488
[5/23] Train loss=0.25457465648651123
[10/23] Train loss=0.14526663720607758
[15/23] Train loss=0.13855057954788208
[20/23] Train loss=0.12023711949586868
Test set avg_accuracy=83.85% avg_sensitivity=60.70%, avg_specificity=94.58% avg_auc=0.9112
Fold[3] Epoch: 70 [70/100 (70%)] Train loss=0.167637 Test loss=0.421211 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15323691070079803
[5/23] Train loss=0.2610463500022888
[10/23] Train loss=0.15816886723041534
[15/23] Train loss=0.12877187132835388
[20/23] Train loss=0.12181331217288971
Test set avg_accuracy=83.58% avg_sensitivity=60.36%, avg_specificity=94.33% avg_auc=0.9115
Fold[3] Epoch: 71 [71/100 (71%)] Train loss=0.165602 Test loss=0.412194 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1458524763584137
[5/23] Train loss=0.24759601056575775
[10/23] Train loss=0.15733855962753296
[15/23] Train loss=0.12808245420455933
[20/23] Train loss=0.11289892345666885
Test set avg_accuracy=83.61% avg_sensitivity=59.93%, avg_specificity=94.58% avg_auc=0.9108
Fold[3] Epoch: 72 [72/100 (72%)] Train loss=0.161414 Test loss=0.420295 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1500038504600525
[5/23] Train loss=0.24553991854190826
[10/23] Train loss=0.15243175625801086
[15/23] Train loss=0.12585780024528503
[20/23] Train loss=0.11798422038555145
Test set avg_accuracy=83.64% avg_sensitivity=60.40%, avg_specificity=94.41% avg_auc=0.9101
Fold[3] Epoch: 73 [73/100 (73%)] Train loss=0.163269 Test loss=0.420135 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14780430495738983
[5/23] Train loss=0.23784630000591278
[10/23] Train loss=0.1480785608291626
[15/23] Train loss=0.12704741954803467
[20/23] Train loss=0.11124369502067566
Test set avg_accuracy=83.44% avg_sensitivity=58.77%, avg_specificity=94.87% avg_auc=0.9083
Fold[3] Epoch: 74 [74/100 (74%)] Train loss=0.156801 Test loss=0.436737 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1487550437450409
[5/23] Train loss=0.2428417205810547
[10/23] Train loss=0.15060576796531677
[15/23] Train loss=0.1261747032403946
[20/23] Train loss=0.11372552812099457
Test set avg_accuracy=83.87% avg_sensitivity=60.33%, avg_specificity=94.78% avg_auc=0.9089
Fold[3] Epoch: 75 [75/100 (75%)] Train loss=0.156529 Test loss=0.432519 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14250333607196808
[5/23] Train loss=0.23484262824058533
[10/23] Train loss=0.14248697459697723
[15/23] Train loss=0.12690196931362152
[20/23] Train loss=0.11213336139917374
Test set avg_accuracy=83.63% avg_sensitivity=60.20%, avg_specificity=94.49% avg_auc=0.9096
Fold[3] Epoch: 76 [76/100 (76%)] Train loss=0.153237 Test loss=0.434786 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13492754101753235
[5/23] Train loss=0.23431691527366638
[10/23] Train loss=0.14397692680358887
[15/23] Train loss=0.12623970210552216
[20/23] Train loss=0.1089881882071495
Test set avg_accuracy=83.84% avg_sensitivity=61.13%, avg_specificity=94.36% avg_auc=0.9100
Fold[3] Epoch: 77 [77/100 (77%)] Train loss=0.152811 Test loss=0.427479 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14056368172168732
[5/23] Train loss=0.24361535906791687
[10/23] Train loss=0.13422001898288727
[15/23] Train loss=0.12883760035037994
[20/23] Train loss=0.10564396530389786
Test set avg_accuracy=83.60% avg_sensitivity=59.70%, avg_specificity=94.67% avg_auc=0.9080
Fold[3] Epoch: 78 [78/100 (78%)] Train loss=0.150241 Test loss=0.441209 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14651811122894287
[5/23] Train loss=0.2334894984960556
[10/23] Train loss=0.1428561508655548
[15/23] Train loss=0.12082946300506592
[20/23] Train loss=0.10202223807573318
Test set avg_accuracy=83.95% avg_sensitivity=60.30%, avg_specificity=94.90% avg_auc=0.9080
Fold[3] Epoch: 79 [79/100 (79%)] Train loss=0.149950 Test loss=0.440269 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14195534586906433
[5/23] Train loss=0.22498482465744019
[10/23] Train loss=0.13404220342636108
[15/23] Train loss=0.12235719710588455
[20/23] Train loss=0.10603859275579453
Test set avg_accuracy=83.86% avg_sensitivity=60.17%, avg_specificity=94.84% avg_auc=0.9079
Fold[3] Epoch: 80 [80/100 (80%)] Train loss=0.145130 Test loss=0.447302 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14012016355991364
[5/23] Train loss=0.2232070118188858
[10/23] Train loss=0.13367675244808197
[15/23] Train loss=0.12413888424634933
[20/23] Train loss=0.10683465749025345
Test set avg_accuracy=83.75% avg_sensitivity=60.50%, avg_specificity=94.52% avg_auc=0.9081
Fold[3] Epoch: 81 [81/100 (81%)] Train loss=0.143532 Test loss=0.444296 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13130119442939758
[5/23] Train loss=0.21605423092842102
[10/23] Train loss=0.1355152726173401
[15/23] Train loss=0.12134520709514618
[20/23] Train loss=0.10004260390996933
Test set avg_accuracy=83.52% avg_sensitivity=59.54%, avg_specificity=94.62% avg_auc=0.9066
Fold[3] Epoch: 82 [82/100 (82%)] Train loss=0.141169 Test loss=0.456426 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13255378603935242
[5/23] Train loss=0.2171773910522461
[10/23] Train loss=0.12805138528347015
[15/23] Train loss=0.11330760270357132
[20/23] Train loss=0.09729498624801636
Test set avg_accuracy=83.70% avg_sensitivity=59.64%, avg_specificity=94.84% avg_auc=0.9079
Fold[3] Epoch: 83 [83/100 (83%)] Train loss=0.139099 Test loss=0.456306 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13125872611999512
[5/23] Train loss=0.21810120344161987
[10/23] Train loss=0.13943813741207123
[15/23] Train loss=0.115774966776371
[20/23] Train loss=0.10226035863161087
Test set avg_accuracy=83.88% avg_sensitivity=60.83%, avg_specificity=94.56% avg_auc=0.9080
Fold[3] Epoch: 84 [84/100 (84%)] Train loss=0.136687 Test loss=0.453458 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13477611541748047
[5/23] Train loss=0.2006416618824005
[10/23] Train loss=0.13589172065258026
[15/23] Train loss=0.10916018486022949
[20/23] Train loss=0.09911055117845535
Test set avg_accuracy=83.88% avg_sensitivity=61.00%, avg_specificity=94.49% avg_auc=0.9081
Fold[3] Epoch: 85 [85/100 (85%)] Train loss=0.136698 Test loss=0.452075 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12748035788536072
[5/23] Train loss=0.20203574001789093
[10/23] Train loss=0.11986374855041504
[15/23] Train loss=0.1160934790968895
[20/23] Train loss=0.10301315784454346
Test set avg_accuracy=83.81% avg_sensitivity=60.53%, avg_specificity=94.59% avg_auc=0.9078
Fold[3] Epoch: 86 [86/100 (86%)] Train loss=0.134993 Test loss=0.454694 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12762807309627533
[5/23] Train loss=0.1978181004524231
[10/23] Train loss=0.13162247836589813
[15/23] Train loss=0.10145816951990128
[20/23] Train loss=0.09350451827049255
Test set avg_accuracy=83.70% avg_sensitivity=60.07%, avg_specificity=94.64% avg_auc=0.9074
Fold[3] Epoch: 87 [87/100 (87%)] Train loss=0.129989 Test loss=0.455271 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12611813843250275
[5/23] Train loss=0.21878188848495483
[10/23] Train loss=0.12437272816896439
[15/23] Train loss=0.1060439944267273
[20/23] Train loss=0.09227892011404037
Test set avg_accuracy=83.46% avg_sensitivity=59.07%, avg_specificity=94.76% avg_auc=0.9079
Fold[3] Epoch: 88 [88/100 (88%)] Train loss=0.131205 Test loss=0.463029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12620988488197327
[5/23] Train loss=0.20142430067062378
[10/23] Train loss=0.12517128884792328
[15/23] Train loss=0.10707974433898926
[20/23] Train loss=0.09207702428102493
Test set avg_accuracy=84.18% avg_sensitivity=62.29%, avg_specificity=94.32% avg_auc=0.9093
Fold[3] Epoch: 89 [89/100 (89%)] Train loss=0.128540 Test loss=0.451761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12333560734987259
[5/23] Train loss=0.18347887694835663
[10/23] Train loss=0.11942820996046066
[15/23] Train loss=0.10396749526262283
[20/23] Train loss=0.09283214062452316
Test set avg_accuracy=83.60% avg_sensitivity=59.30%, avg_specificity=94.85% avg_auc=0.9086
Fold[3] Epoch: 90 [90/100 (90%)] Train loss=0.124608 Test loss=0.471624 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12205497920513153
[5/23] Train loss=0.18300817906856537
[10/23] Train loss=0.11581572890281677
[15/23] Train loss=0.10259722918272018
[20/23] Train loss=0.08664216101169586
Test set avg_accuracy=83.61% avg_sensitivity=59.64%, avg_specificity=94.72% avg_auc=0.9077
Fold[3] Epoch: 91 [91/100 (91%)] Train loss=0.123880 Test loss=0.480660 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11618082225322723
[5/23] Train loss=0.17504481971263885
[10/23] Train loss=0.11675827950239182
[15/23] Train loss=0.10130039602518082
[20/23] Train loss=0.08432001620531082
Test set avg_accuracy=83.73% avg_sensitivity=60.07%, avg_specificity=94.69% avg_auc=0.9089
Fold[3] Epoch: 92 [92/100 (92%)] Train loss=0.121228 Test loss=0.471986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11722368001937866
[5/23] Train loss=0.17845986783504486
[10/23] Train loss=0.10880766063928604
[15/23] Train loss=0.09734305739402771
[20/23] Train loss=0.08122093975543976
Test set avg_accuracy=84.06% avg_sensitivity=60.27%, avg_specificity=95.08% avg_auc=0.9084
Fold[3] Epoch: 93 [93/100 (93%)] Train loss=0.117952 Test loss=0.481484 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11519401520490646
[5/23] Train loss=0.17288675904273987
[10/23] Train loss=0.11968454718589783
[15/23] Train loss=0.09537693858146667
[20/23] Train loss=0.08659587800502777
Test set avg_accuracy=83.80% avg_sensitivity=59.00%, avg_specificity=95.28% avg_auc=0.9078
Fold[3] Epoch: 94 [94/100 (94%)] Train loss=0.116758 Test loss=0.489606 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11663137376308441
[5/23] Train loss=0.17253006994724274
[10/23] Train loss=0.11887429654598236
[15/23] Train loss=0.10286486148834229
[20/23] Train loss=0.08083124458789825
Test set avg_accuracy=83.96% avg_sensitivity=60.07%, avg_specificity=95.02% avg_auc=0.9085
Fold[3] Epoch: 95 [95/100 (95%)] Train loss=0.116614 Test loss=0.487500 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10840562731027603
[5/23] Train loss=0.16416527330875397
[10/23] Train loss=0.1076321080327034
[15/23] Train loss=0.09585181623697281
[20/23] Train loss=0.08437050133943558
Test set avg_accuracy=83.80% avg_sensitivity=60.03%, avg_specificity=94.81% avg_auc=0.9080
Fold[3] Epoch: 96 [96/100 (96%)] Train loss=0.111505 Test loss=0.494562 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11273494362831116
[5/23] Train loss=0.16986273229122162
[10/23] Train loss=0.11209310591220856
[15/23] Train loss=0.09454458206892014
[20/23] Train loss=0.08494246751070023
Test set avg_accuracy=83.59% avg_sensitivity=59.30%, avg_specificity=94.84% avg_auc=0.9072
Fold[3] Epoch: 97 [97/100 (97%)] Train loss=0.113080 Test loss=0.499875 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11018167436122894
[5/23] Train loss=0.1721385419368744
[10/23] Train loss=0.10318491607904434
[15/23] Train loss=0.08841279149055481
[20/23] Train loss=0.0753265991806984
Test set avg_accuracy=83.71% avg_sensitivity=60.70%, avg_specificity=94.36% avg_auc=0.9085
Fold[3] Epoch: 98 [98/100 (98%)] Train loss=0.109324 Test loss=0.491555 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10411468148231506
[5/23] Train loss=0.1581275463104248
[10/23] Train loss=0.11225493997335434
[15/23] Train loss=0.08899617940187454
[20/23] Train loss=0.07655088603496552
Test set avg_accuracy=83.62% avg_sensitivity=59.67%, avg_specificity=94.72% avg_auc=0.9072
Fold[3] Epoch: 99 [99/100 (99%)] Train loss=0.107601 Test loss=0.508379 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10327035188674927
[5/23] Train loss=0.1571037471294403
[10/23] Train loss=0.10135065019130707
[15/23] Train loss=0.08888793736696243
[20/23] Train loss=0.07953615486621857
Test set avg_accuracy=83.81% avg_sensitivity=59.70%, avg_specificity=94.98% avg_auc=0.9067
Fold[3] Epoch: 100 [100/100 (100%)] Train loss=0.104619 Test loss=0.504432 Current lr=[3.9999999999999996e-05]

Fold[3] Best Result: acc=84.71391076115485 sen=65.63847429519072, spe=93.54838709677419, auc=0.9162381894928838!
[0/23] Train loss=0.6997694373130798
[5/23] Train loss=0.6473429203033447
[10/23] Train loss=0.5933922529220581
[15/23] Train loss=0.5329016447067261
[20/23] Train loss=0.5304366946220398
Test set avg_accuracy=75.73% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6547
Best model saved!! Metric=-84.79963688974217!!
Fold[4] Epoch: 1 [1/100 (1%)] Train loss=0.574988 Test loss=0.542417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5377384424209595
[5/23] Train loss=0.5618934631347656
[10/23] Train loss=0.4944199025630951
[15/23] Train loss=0.47680580615997314
[20/23] Train loss=0.42974403500556946
Test set avg_accuracy=75.54% avg_sensitivity=7.63%, avg_specificity=97.31% avg_auc=0.7870
Best model saved!! Metric=-66.82177197426812!!
Fold[4] Epoch: 2 [2/100 (2%)] Train loss=0.490978 Test loss=0.463845 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42935189604759216
[5/23] Train loss=0.4760468900203705
[10/23] Train loss=0.42747437953948975
[15/23] Train loss=0.40798649191856384
[20/23] Train loss=0.35606735944747925
Test set avg_accuracy=80.54% avg_sensitivity=40.58%, avg_specificity=93.35% avg_auc=0.8431
Best model saved!! Metric=-27.214619052517893!!
Fold[4] Epoch: 3 [3/100 (3%)] Train loss=0.422936 Test loss=0.421664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36699506640434265
[5/23] Train loss=0.41720423102378845
[10/23] Train loss=0.3606460392475128
[15/23] Train loss=0.381985604763031
[20/23] Train loss=0.3243735432624817
Test set avg_accuracy=82.94% avg_sensitivity=53.90%, avg_specificity=92.25% avg_auc=0.8726
Best model saved!! Metric=-9.644535978044932!!
Fold[4] Epoch: 4 [4/100 (4%)] Train loss=0.385463 Test loss=0.380189 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3394942879676819
[5/23] Train loss=0.40856191515922546
[10/23] Train loss=0.33208638429641724
[15/23] Train loss=0.3379427492618561
[20/23] Train loss=0.29720550775527954
Test set avg_accuracy=83.63% avg_sensitivity=56.62%, avg_specificity=92.29% avg_auc=0.8842
Best model saved!! Metric=-5.040902510502415!!
Fold[4] Epoch: 5 [5/100 (5%)] Train loss=0.363558 Test loss=0.363334 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31824570894241333
[5/23] Train loss=0.3969119191169739
[10/23] Train loss=0.31641629338264465
[15/23] Train loss=0.321087509393692
[20/23] Train loss=0.2783558666706085
Test set avg_accuracy=84.30% avg_sensitivity=65.59%, avg_specificity=90.30% avg_auc=0.8927
Best model saved!! Metric=3.455371530513732!!
Fold[4] Epoch: 6 [6/100 (6%)] Train loss=0.350380 Test loss=0.351172 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30079951882362366
[5/23] Train loss=0.38446375727653503
[10/23] Train loss=0.3067984879016876
[15/23] Train loss=0.30878645181655884
[20/23] Train loss=0.26600098609924316
Test set avg_accuracy=84.41% avg_sensitivity=70.55%, avg_specificity=88.85% avg_auc=0.8991
Best model saved!! Metric=7.709157004940142!!
Fold[4] Epoch: 7 [7/100 (7%)] Train loss=0.335650 Test loss=0.345609 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2822837233543396
[5/23] Train loss=0.3750312924385071
[10/23] Train loss=0.28464066982269287
[15/23] Train loss=0.2879296541213989
[20/23] Train loss=0.23616911470890045
Test set avg_accuracy=85.07% avg_sensitivity=71.32%, avg_specificity=89.47% avg_auc=0.9031
Best model saved!! Metric=10.165535187602828!!
Fold[4] Epoch: 8 [8/100 (8%)] Train loss=0.323032 Test loss=0.342486 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26332294940948486
[5/23] Train loss=0.36437851190567017
[10/23] Train loss=0.27843689918518066
[15/23] Train loss=0.2744092345237732
[20/23] Train loss=0.2294570505619049
Test set avg_accuracy=85.24% avg_sensitivity=74.43%, avg_specificity=88.71% avg_auc=0.9053
Best model saved!! Metric=12.90672557336237!!
Fold[4] Epoch: 9 [9/100 (9%)] Train loss=0.314502 Test loss=0.346161 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2739378809928894
[5/23] Train loss=0.3615216910839081
[10/23] Train loss=0.2504860758781433
[15/23] Train loss=0.27057385444641113
[20/23] Train loss=0.22890867292881012
Test set avg_accuracy=85.84% avg_sensitivity=73.70%, avg_specificity=89.73% avg_auc=0.9089
Best model saved!! Metric=14.162211863994496!!
Fold[4] Epoch: 10 [10/100 (10%)] Train loss=0.305740 Test loss=0.337482 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24711883068084717
[5/23] Train loss=0.36624690890312195
[10/23] Train loss=0.25478535890579224
[15/23] Train loss=0.25976166129112244
[20/23] Train loss=0.2210104912519455
Test set avg_accuracy=86.31% avg_sensitivity=72.19%, avg_specificity=90.84% avg_auc=0.9097
Best model saved!! Metric=14.30864874860106!!
Fold[4] Epoch: 11 [11/100 (11%)] Train loss=0.301272 Test loss=0.334105 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24912968277931213
[5/23] Train loss=0.3492773175239563
[10/23] Train loss=0.2546384930610657
[15/23] Train loss=0.25907763838768005
[20/23] Train loss=0.2139643132686615
Test set avg_accuracy=86.23% avg_sensitivity=73.82%, avg_specificity=90.20% avg_auc=0.9101
Best model saved!! Metric=15.260727827312753!!
Fold[4] Epoch: 12 [12/100 (12%)] Train loss=0.293244 Test loss=0.338096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23621894419193268
[5/23] Train loss=0.3496290445327759
[10/23] Train loss=0.24640849232673645
[15/23] Train loss=0.24767319858074188
[20/23] Train loss=0.21567095816135406
Test set avg_accuracy=86.35% avg_sensitivity=73.61%, avg_specificity=90.44% avg_auc=0.9111
Best model saved!! Metric=15.507783479239714!!
Fold[4] Epoch: 13 [13/100 (13%)] Train loss=0.289226 Test loss=0.336963 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23546360433101654
[5/23] Train loss=0.348559707403183
[10/23] Train loss=0.24132701754570007
[15/23] Train loss=0.2425498515367508
[20/23] Train loss=0.19783960282802582
Test set avg_accuracy=86.49% avg_sensitivity=74.30%, avg_specificity=90.40% avg_auc=0.9117
Best model saved!! Metric=16.3521066049231!!
Fold[4] Epoch: 14 [14/100 (14%)] Train loss=0.282945 Test loss=0.335906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24118605256080627
[5/23] Train loss=0.3350473940372467
[10/23] Train loss=0.2413274347782135
[15/23] Train loss=0.2369527816772461
[20/23] Train loss=0.2054503858089447
Test set avg_accuracy=86.59% avg_sensitivity=73.61%, avg_specificity=90.75% avg_auc=0.9122
Fold[4] Epoch: 15 [15/100 (15%)] Train loss=0.282518 Test loss=0.333364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2312244027853012
[5/23] Train loss=0.34035322070121765
[10/23] Train loss=0.22605569660663605
[15/23] Train loss=0.2317768633365631
[20/23] Train loss=0.1974504142999649
Test set avg_accuracy=86.37% avg_sensitivity=72.70%, avg_specificity=90.75% avg_auc=0.9119
Fold[4] Epoch: 16 [16/100 (16%)] Train loss=0.274732 Test loss=0.335187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21718093752861023
[5/23] Train loss=0.3431307077407837
[10/23] Train loss=0.23536868393421173
[15/23] Train loss=0.22892557084560394
[20/23] Train loss=0.19678835570812225
Test set avg_accuracy=86.35% avg_sensitivity=72.06%, avg_specificity=90.93% avg_auc=0.9121
Fold[4] Epoch: 17 [17/100 (17%)] Train loss=0.274399 Test loss=0.333069 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2230069637298584
[5/23] Train loss=0.340126633644104
[10/23] Train loss=0.23368023335933685
[15/23] Train loss=0.2273118644952774
[20/23] Train loss=0.19572396576404572
Test set avg_accuracy=86.65% avg_sensitivity=71.63%, avg_specificity=91.46% avg_auc=0.9128
Fold[4] Epoch: 18 [18/100 (18%)] Train loss=0.269885 Test loss=0.333084 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21770863234996796
[5/23] Train loss=0.3289632797241211
[10/23] Train loss=0.2292535901069641
[15/23] Train loss=0.2167481929063797
[20/23] Train loss=0.19058942794799805
Test set avg_accuracy=86.73% avg_sensitivity=70.20%, avg_specificity=92.03% avg_auc=0.9132
Fold[4] Epoch: 19 [19/100 (19%)] Train loss=0.268577 Test loss=0.326393 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21927757561206818
[5/23] Train loss=0.3326220214366913
[10/23] Train loss=0.22759097814559937
[15/23] Train loss=0.21355317533016205
[20/23] Train loss=0.18805822730064392
Test set avg_accuracy=86.74% avg_sensitivity=71.11%, avg_specificity=91.75% avg_auc=0.9134
Fold[4] Epoch: 20 [20/100 (20%)] Train loss=0.264749 Test loss=0.332218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21319320797920227
[5/23] Train loss=0.334721177816391
[10/23] Train loss=0.2243320494890213
[15/23] Train loss=0.21837368607521057
[20/23] Train loss=0.19002194702625275
Test set avg_accuracy=86.81% avg_sensitivity=71.15%, avg_specificity=91.83% avg_auc=0.9147
Fold[4] Epoch: 21 [21/100 (21%)] Train loss=0.265467 Test loss=0.323521 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22413431107997894
[5/23] Train loss=0.319631427526474
[10/23] Train loss=0.21656125783920288
[15/23] Train loss=0.2109893411397934
[20/23] Train loss=0.18231871724128723
Test set avg_accuracy=87.03% avg_sensitivity=69.60%, avg_specificity=92.62% avg_auc=0.9149
Fold[4] Epoch: 22 [22/100 (22%)] Train loss=0.260970 Test loss=0.321804 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20766136050224304
[5/23] Train loss=0.3384818136692047
[10/23] Train loss=0.21544593572616577
[15/23] Train loss=0.21487188339233398
[20/23] Train loss=0.18263407051563263
Test set avg_accuracy=87.02% avg_sensitivity=70.16%, avg_specificity=92.43% avg_auc=0.9143
Fold[4] Epoch: 23 [23/100 (23%)] Train loss=0.259174 Test loss=0.324928 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2130434662103653
[5/23] Train loss=0.3125112056732178
[10/23] Train loss=0.21887777745723724
[15/23] Train loss=0.21265415847301483
[20/23] Train loss=0.18288026750087738
Test set avg_accuracy=86.98% avg_sensitivity=69.21%, avg_specificity=92.68% avg_auc=0.9159
Fold[4] Epoch: 24 [24/100 (24%)] Train loss=0.258988 Test loss=0.318674 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21441718935966492
[5/23] Train loss=0.31187981367111206
[10/23] Train loss=0.22305934131145477
[15/23] Train loss=0.20805098116397858
[20/23] Train loss=0.17627952992916107
Test set avg_accuracy=87.12% avg_sensitivity=69.00%, avg_specificity=92.92% avg_auc=0.9167
Fold[4] Epoch: 25 [25/100 (25%)] Train loss=0.257272 Test loss=0.320456 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2084467113018036
[5/23] Train loss=0.32695913314819336
[10/23] Train loss=0.22428058087825775
[15/23] Train loss=0.20652911067008972
[20/23] Train loss=0.16817910969257355
Test set avg_accuracy=87.15% avg_sensitivity=68.26%, avg_specificity=93.20% avg_auc=0.9161
Fold[4] Epoch: 26 [26/100 (26%)] Train loss=0.252772 Test loss=0.321291 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2063586413860321
[5/23] Train loss=0.3130795359611511
[10/23] Train loss=0.22106947004795074
[15/23] Train loss=0.1983790099620819
[20/23] Train loss=0.17602837085723877
Test set avg_accuracy=87.01% avg_sensitivity=67.79%, avg_specificity=93.17% avg_auc=0.9161
Fold[4] Epoch: 27 [27/100 (27%)] Train loss=0.253023 Test loss=0.320287 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20751626789569855
[5/23] Train loss=0.32440808415412903
[10/23] Train loss=0.2142876833677292
[15/23] Train loss=0.1919003576040268
[20/23] Train loss=0.18126672506332397
Test set avg_accuracy=87.40% avg_sensitivity=66.19%, avg_specificity=94.20% avg_auc=0.9185
Fold[4] Epoch: 28 [28/100 (28%)] Train loss=0.251694 Test loss=0.317603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2061389535665512
[5/23] Train loss=0.3312382400035858
[10/23] Train loss=0.21907415986061096
[15/23] Train loss=0.19821061193943024
[20/23] Train loss=0.17866316437721252
Test set avg_accuracy=87.48% avg_sensitivity=65.07%, avg_specificity=94.67% avg_auc=0.9176
Fold[4] Epoch: 29 [29/100 (29%)] Train loss=0.252150 Test loss=0.320531 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21313098073005676
[5/23] Train loss=0.324149489402771
[10/23] Train loss=0.21478985249996185
[15/23] Train loss=0.20176510512828827
[20/23] Train loss=0.16911619901657104
Test set avg_accuracy=87.52% avg_sensitivity=64.86%, avg_specificity=94.79% avg_auc=0.9178
Fold[4] Epoch: 30 [30/100 (30%)] Train loss=0.252443 Test loss=0.322872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21115297079086304
[5/23] Train loss=0.33380594849586487
[10/23] Train loss=0.21167071163654327
[15/23] Train loss=0.20099574327468872
[20/23] Train loss=0.17192313075065613
Test set avg_accuracy=87.46% avg_sensitivity=63.43%, avg_specificity=95.16% avg_auc=0.9180
Fold[4] Epoch: 31 [31/100 (31%)] Train loss=0.250401 Test loss=0.322857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2107480764389038
[5/23] Train loss=0.33603858947753906
[10/23] Train loss=0.21288429200649261
[15/23] Train loss=0.2009943425655365
[20/23] Train loss=0.17246058583259583
Test set avg_accuracy=87.35% avg_sensitivity=63.95%, avg_specificity=94.85% avg_auc=0.9168
Fold[4] Epoch: 32 [32/100 (32%)] Train loss=0.251090 Test loss=0.326302 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20157143473625183
[5/23] Train loss=0.3478003144264221
[10/23] Train loss=0.19893737137317657
[15/23] Train loss=0.20136089622974396
[20/23] Train loss=0.17514550685882568
Test set avg_accuracy=87.71% avg_sensitivity=66.58%, avg_specificity=94.49% avg_auc=0.9206
Fold[4] Epoch: 33 [33/100 (33%)] Train loss=0.249550 Test loss=0.314496 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20363929867744446
[5/23] Train loss=0.3457154333591461
[10/23] Train loss=0.19112376868724823
[15/23] Train loss=0.19931000471115112
[20/23] Train loss=0.17024683952331543
Test set avg_accuracy=87.56% avg_sensitivity=65.16%, avg_specificity=94.73% avg_auc=0.9200
Fold[4] Epoch: 34 [34/100 (34%)] Train loss=0.248606 Test loss=0.316438 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20377716422080994
[5/23] Train loss=0.3414011597633362
[10/23] Train loss=0.19651618599891663
[15/23] Train loss=0.1897292137145996
[20/23] Train loss=0.17398221790790558
Test set avg_accuracy=87.05% avg_sensitivity=67.40%, avg_specificity=93.35% avg_auc=0.9209
Fold[4] Epoch: 35 [35/100 (35%)] Train loss=0.246669 Test loss=0.311729 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20016150176525116
[5/23] Train loss=0.33456769585609436
[10/23] Train loss=0.1952960193157196
[15/23] Train loss=0.18868018686771393
[20/23] Train loss=0.17388242483139038
Test set avg_accuracy=87.27% avg_sensitivity=69.34%, avg_specificity=93.02% avg_auc=0.9229
Fold[4] Epoch: 36 [36/100 (36%)] Train loss=0.242213 Test loss=0.308637 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20228850841522217
[5/23] Train loss=0.3255004584789276
[10/23] Train loss=0.1939007192850113
[15/23] Train loss=0.18859033286571503
[20/23] Train loss=0.1717251092195511
Test set avg_accuracy=87.39% avg_sensitivity=68.18%, avg_specificity=93.55% avg_auc=0.9209
Fold[4] Epoch: 37 [37/100 (37%)] Train loss=0.238919 Test loss=0.312098 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1953258365392685
[5/23] Train loss=0.3192700147628784
[10/23] Train loss=0.1919446587562561
[15/23] Train loss=0.18688887357711792
[20/23] Train loss=0.16015416383743286
Test set avg_accuracy=87.36% avg_sensitivity=70.03%, avg_specificity=92.91% avg_auc=0.9218
Best model saved!! Metric=16.474686782254!!
Fold[4] Epoch: 38 [38/100 (38%)] Train loss=0.236632 Test loss=0.310331 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19365377724170685
[5/23] Train loss=0.32285556197166443
[10/23] Train loss=0.19278796017169952
[15/23] Train loss=0.18450549244880676
[20/23] Train loss=0.1659277230501175
Test set avg_accuracy=87.19% avg_sensitivity=68.61%, avg_specificity=93.15% avg_auc=0.9207
Fold[4] Epoch: 39 [39/100 (39%)] Train loss=0.233570 Test loss=0.312283 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19535942375659943
[5/23] Train loss=0.3139423429965973
[10/23] Train loss=0.18921245634555817
[15/23] Train loss=0.17891018092632294
[20/23] Train loss=0.1612057387828827
Test set avg_accuracy=87.38% avg_sensitivity=69.12%, avg_specificity=93.23% avg_auc=0.9209
Fold[4] Epoch: 40 [40/100 (40%)] Train loss=0.231945 Test loss=0.313142 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19240279495716095
[5/23] Train loss=0.3212200403213501
[10/23] Train loss=0.1921049803495407
[15/23] Train loss=0.18665683269500732
[20/23] Train loss=0.15165434777736664
Test set avg_accuracy=87.33% avg_sensitivity=68.91%, avg_specificity=93.23% avg_auc=0.9212
Fold[4] Epoch: 41 [41/100 (41%)] Train loss=0.231629 Test loss=0.311526 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1922834813594818
[5/23] Train loss=0.3096780776977539
[10/23] Train loss=0.19043304026126862
[15/23] Train loss=0.17506831884384155
[20/23] Train loss=0.1589144617319107
Test set avg_accuracy=87.25% avg_sensitivity=68.78%, avg_specificity=93.17% avg_auc=0.9208
Fold[4] Epoch: 42 [42/100 (42%)] Train loss=0.227405 Test loss=0.313295 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19792774319648743
[5/23] Train loss=0.3056187927722931
[10/23] Train loss=0.18540982902050018
[15/23] Train loss=0.17710977792739868
[20/23] Train loss=0.15909221768379211
Test set avg_accuracy=87.69% avg_sensitivity=67.87%, avg_specificity=94.04% avg_auc=0.9223
Fold[4] Epoch: 43 [43/100 (43%)] Train loss=0.228999 Test loss=0.308304 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1931513547897339
[5/23] Train loss=0.29744255542755127
[10/23] Train loss=0.18264168500900269
[15/23] Train loss=0.18158818781375885
[20/23] Train loss=0.1622728407382965
Test set avg_accuracy=87.59% avg_sensitivity=68.52%, avg_specificity=93.70% avg_auc=0.9224
Fold[4] Epoch: 44 [44/100 (44%)] Train loss=0.225660 Test loss=0.308596 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18261440098285675
[5/23] Train loss=0.2940467298030853
[10/23] Train loss=0.1867348849773407
[15/23] Train loss=0.1828293651342392
[20/23] Train loss=0.15002182126045227
Test set avg_accuracy=87.72% avg_sensitivity=68.48%, avg_specificity=93.89% avg_auc=0.9227
Fold[4] Epoch: 45 [45/100 (45%)] Train loss=0.223334 Test loss=0.308137 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19091518223285675
[5/23] Train loss=0.3015616238117218
[10/23] Train loss=0.1788947433233261
[15/23] Train loss=0.1783452033996582
[20/23] Train loss=0.14910495281219482
Test set avg_accuracy=87.72% avg_sensitivity=68.56%, avg_specificity=93.86% avg_auc=0.9232
Fold[4] Epoch: 46 [46/100 (46%)] Train loss=0.222430 Test loss=0.307362 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18407553434371948
[5/23] Train loss=0.28582966327667236
[10/23] Train loss=0.18103986978530884
[15/23] Train loss=0.16502825915813446
[20/23] Train loss=0.14583104848861694
Test set avg_accuracy=87.54% avg_sensitivity=68.91%, avg_specificity=93.50% avg_auc=0.9236
Fold[4] Epoch: 47 [47/100 (47%)] Train loss=0.218519 Test loss=0.307173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18354524672031403
[5/23] Train loss=0.2938012182712555
[10/23] Train loss=0.18127186596393585
[15/23] Train loss=0.17721746861934662
[20/23] Train loss=0.1506194770336151
Test set avg_accuracy=87.89% avg_sensitivity=67.74%, avg_specificity=94.35% avg_auc=0.9241
Fold[4] Epoch: 48 [48/100 (48%)] Train loss=0.218272 Test loss=0.307365 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18248559534549713
[5/23] Train loss=0.30561932921409607
[10/23] Train loss=0.1784791499376297
[15/23] Train loss=0.17088952660560608
[20/23] Train loss=0.14733771979808807
Test set avg_accuracy=87.74% avg_sensitivity=67.57%, avg_specificity=94.21% avg_auc=0.9235
Fold[4] Epoch: 49 [49/100 (49%)] Train loss=0.219573 Test loss=0.309855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18331055343151093
[5/23] Train loss=0.3034457862377167
[10/23] Train loss=0.1774374544620514
[15/23] Train loss=0.16917935013771057
[20/23] Train loss=0.14397992193698883
Test set avg_accuracy=87.99% avg_sensitivity=68.87%, avg_specificity=94.11% avg_auc=0.9260
Best model saved!! Metric=17.559514668104974!!
Fold[4] Epoch: 50 [50/100 (50%)] Train loss=0.218307 Test loss=0.303336 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18131892383098602
[5/23] Train loss=0.28877976536750793
[10/23] Train loss=0.1756843477487564
[15/23] Train loss=0.1694452315568924
[20/23] Train loss=0.14993268251419067
Test set avg_accuracy=87.79% avg_sensitivity=67.70%, avg_specificity=94.22% avg_auc=0.9246
Fold[4] Epoch: 51 [51/100 (51%)] Train loss=0.215415 Test loss=0.306343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1827714443206787
[5/23] Train loss=0.2999895215034485
[10/23] Train loss=0.17422190308570862
[15/23] Train loss=0.15876995027065277
[20/23] Train loss=0.13804695010185242
Test set avg_accuracy=88.08% avg_sensitivity=67.70%, avg_specificity=94.61% avg_auc=0.9241
Fold[4] Epoch: 52 [52/100 (52%)] Train loss=0.214687 Test loss=0.308250 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1825505644083023
[5/23] Train loss=0.28297489881515503
[10/23] Train loss=0.1723935753107071
[15/23] Train loss=0.16704869270324707
[20/23] Train loss=0.14481860399246216
Test set avg_accuracy=88.11% avg_sensitivity=69.47%, avg_specificity=94.09% avg_auc=0.9248
Best model saved!! Metric=18.14605801880986!!
Fold[4] Epoch: 53 [53/100 (53%)] Train loss=0.213151 Test loss=0.307814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17749185860157013
[5/23] Train loss=0.2831084430217743
[10/23] Train loss=0.1702808290719986
[15/23] Train loss=0.15368078649044037
[20/23] Train loss=0.14416387677192688
Test set avg_accuracy=88.08% avg_sensitivity=69.94%, avg_specificity=93.89% avg_auc=0.9263
Best model saved!! Metric=18.545857360657415!!
Fold[4] Epoch: 54 [54/100 (54%)] Train loss=0.207889 Test loss=0.306175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1816234439611435
[5/23] Train loss=0.28949612379074097
[10/23] Train loss=0.17705166339874268
[15/23] Train loss=0.1558229923248291
[20/23] Train loss=0.1475101113319397
Test set avg_accuracy=88.33% avg_sensitivity=68.39%, avg_specificity=94.72% avg_auc=0.9260
Fold[4] Epoch: 55 [55/100 (55%)] Train loss=0.208212 Test loss=0.305882 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1774466633796692
[5/23] Train loss=0.2782144248485565
[10/23] Train loss=0.16726522147655487
[15/23] Train loss=0.16046345233917236
[20/23] Train loss=0.13410533964633942
Test set avg_accuracy=88.17% avg_sensitivity=70.46%, avg_specificity=93.85% avg_auc=0.9271
Best model saved!! Metric=19.195346398051242!!
Fold[4] Epoch: 56 [56/100 (56%)] Train loss=0.205991 Test loss=0.304646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17766180634498596
[5/23] Train loss=0.2754077613353729
[10/23] Train loss=0.17549961805343628
[15/23] Train loss=0.15728075802326202
[20/23] Train loss=0.14058919250965118
Test set avg_accuracy=87.92% avg_sensitivity=69.51%, avg_specificity=93.82% avg_auc=0.9261
Fold[4] Epoch: 57 [57/100 (57%)] Train loss=0.204636 Test loss=0.308367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1750255972146988
[5/23] Train loss=0.2770223319530487
[10/23] Train loss=0.17231351137161255
[15/23] Train loss=0.1593100130558014
[20/23] Train loss=0.13910508155822754
Test set avg_accuracy=87.93% avg_sensitivity=69.34%, avg_specificity=93.89% avg_auc=0.9251
Fold[4] Epoch: 58 [58/100 (58%)] Train loss=0.204231 Test loss=0.308550 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17702986299991608
[5/23] Train loss=0.26315996050834656
[10/23] Train loss=0.1786433905363083
[15/23] Train loss=0.15759138762950897
[20/23] Train loss=0.13438376784324646
Test set avg_accuracy=88.28% avg_sensitivity=69.90%, avg_specificity=94.17% avg_auc=0.9264
Fold[4] Epoch: 59 [59/100 (59%)] Train loss=0.202084 Test loss=0.308021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16929234564304352
[5/23] Train loss=0.2764819860458374
[10/23] Train loss=0.16892512142658234
[15/23] Train loss=0.15779440104961395
[20/23] Train loss=0.1375562697649002
Test set avg_accuracy=88.32% avg_sensitivity=68.78%, avg_specificity=94.58% avg_auc=0.9270
Fold[4] Epoch: 60 [60/100 (60%)] Train loss=0.202222 Test loss=0.302715 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17309008538722992
[5/23] Train loss=0.2635699510574341
[10/23] Train loss=0.16673240065574646
[15/23] Train loss=0.15442036092281342
[20/23] Train loss=0.12986746430397034
Test set avg_accuracy=88.27% avg_sensitivity=68.69%, avg_specificity=94.54% avg_auc=0.9277
Fold[4] Epoch: 61 [61/100 (61%)] Train loss=0.198428 Test loss=0.303383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1722114086151123
[5/23] Train loss=0.26738667488098145
[10/23] Train loss=0.16718712449073792
[15/23] Train loss=0.1535186469554901
[20/23] Train loss=0.12828132510185242
Test set avg_accuracy=88.27% avg_sensitivity=69.30%, avg_specificity=94.35% avg_auc=0.9278
Fold[4] Epoch: 62 [62/100 (62%)] Train loss=0.197195 Test loss=0.303898 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.172729030251503
[5/23] Train loss=0.2659797966480255
[10/23] Train loss=0.16507302224636078
[15/23] Train loss=0.1500483751296997
[20/23] Train loss=0.12781532108783722
Test set avg_accuracy=88.10% avg_sensitivity=68.82%, avg_specificity=94.28% avg_auc=0.9270
Fold[4] Epoch: 63 [63/100 (63%)] Train loss=0.194524 Test loss=0.306988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17906063795089722
[5/23] Train loss=0.2603784501552582
[10/23] Train loss=0.16199259459972382
[15/23] Train loss=0.14552000164985657
[20/23] Train loss=0.12828156352043152
Test set avg_accuracy=88.46% avg_sensitivity=70.29%, avg_specificity=94.28% avg_auc=0.9275
Best model saved!! Metric=19.778458192050913!!
Fold[4] Epoch: 64 [64/100 (64%)] Train loss=0.193761 Test loss=0.307922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17566561698913574
[5/23] Train loss=0.2501043379306793
[10/23] Train loss=0.16573384404182434
[15/23] Train loss=0.1483059525489807
[20/23] Train loss=0.13113777339458466
Test set avg_accuracy=88.39% avg_sensitivity=70.38%, avg_specificity=94.17% avg_auc=0.9266
Fold[4] Epoch: 65 [65/100 (65%)] Train loss=0.190988 Test loss=0.307852 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17370089888572693
[5/23] Train loss=0.24701040983200073
[10/23] Train loss=0.1576736569404602
[15/23] Train loss=0.14792127907276154
[20/23] Train loss=0.12662890553474426
Test set avg_accuracy=88.26% avg_sensitivity=70.07%, avg_specificity=94.09% avg_auc=0.9255
Fold[4] Epoch: 66 [66/100 (66%)] Train loss=0.190865 Test loss=0.310990 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17182506620883942
[5/23] Train loss=0.24825519323349
[10/23] Train loss=0.15934735536575317
[15/23] Train loss=0.14379386603832245
[20/23] Train loss=0.12684175372123718
Test set avg_accuracy=88.27% avg_sensitivity=70.46%, avg_specificity=93.97% avg_auc=0.9263
Fold[4] Epoch: 67 [67/100 (67%)] Train loss=0.188623 Test loss=0.310720 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1735588163137436
[5/23] Train loss=0.2534636855125427
[10/23] Train loss=0.15731516480445862
[15/23] Train loss=0.13980337977409363
[20/23] Train loss=0.12282493710517883
Test set avg_accuracy=88.40% avg_sensitivity=70.29%, avg_specificity=94.21% avg_auc=0.9258
Fold[4] Epoch: 68 [68/100 (68%)] Train loss=0.185689 Test loss=0.309936 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1720695197582245
[5/23] Train loss=0.2342814952135086
[10/23] Train loss=0.15669645369052887
[15/23] Train loss=0.1331733614206314
[20/23] Train loss=0.11918070167303085
Test set avg_accuracy=88.57% avg_sensitivity=70.29%, avg_specificity=94.43% avg_auc=0.9278
Best model saved!! Metric=20.069516804023426!!
Fold[4] Epoch: 69 [69/100 (69%)] Train loss=0.183207 Test loss=0.306773 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16473320126533508
[5/23] Train loss=0.24073097109794617
[10/23] Train loss=0.16534055769443512
[15/23] Train loss=0.14042285084724426
[20/23] Train loss=0.12319617718458176
Test set avg_accuracy=88.37% avg_sensitivity=70.94%, avg_specificity=93.96% avg_auc=0.9274
Fold[4] Epoch: 70 [70/100 (70%)] Train loss=0.182033 Test loss=0.309876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16231007874011993
[5/23] Train loss=0.2423134297132492
[10/23] Train loss=0.15749084949493408
[15/23] Train loss=0.1410742551088333
[20/23] Train loss=0.11590605974197388
Test set avg_accuracy=88.39% avg_sensitivity=70.16%, avg_specificity=94.24% avg_auc=0.9271
Fold[4] Epoch: 71 [71/100 (71%)] Train loss=0.181085 Test loss=0.311094 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1580522656440735
[5/23] Train loss=0.2298329472541809
[10/23] Train loss=0.15966063737869263
[15/23] Train loss=0.14189296960830688
[20/23] Train loss=0.11720612645149231
Test set avg_accuracy=88.26% avg_sensitivity=70.33%, avg_specificity=94.00% avg_auc=0.9264
Fold[4] Epoch: 72 [72/100 (72%)] Train loss=0.177961 Test loss=0.312790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15711456537246704
[5/23] Train loss=0.2568024694919586
[10/23] Train loss=0.14942926168441772
[15/23] Train loss=0.13208813965320587
[20/23] Train loss=0.11185485124588013
Test set avg_accuracy=88.32% avg_sensitivity=71.28%, avg_specificity=93.78% avg_auc=0.9280
Best model saved!! Metric=20.178896478033742!!
Fold[4] Epoch: 73 [73/100 (73%)] Train loss=0.177533 Test loss=0.310583 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15981417894363403
[5/23] Train loss=0.2318326085805893
[10/23] Train loss=0.1513766348361969
[15/23] Train loss=0.1278119683265686
[20/23] Train loss=0.11817368865013123
Test set avg_accuracy=88.48% avg_sensitivity=69.56%, avg_specificity=94.54% avg_auc=0.9277
Fold[4] Epoch: 74 [74/100 (74%)] Train loss=0.175312 Test loss=0.313470 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15314564108848572
[5/23] Train loss=0.22890450060367584
[10/23] Train loss=0.15704292058944702
[15/23] Train loss=0.1328100562095642
[20/23] Train loss=0.11904896795749664
Test set avg_accuracy=88.44% avg_sensitivity=70.89%, avg_specificity=94.06% avg_auc=0.9268
Fold[4] Epoch: 75 [75/100 (75%)] Train loss=0.173274 Test loss=0.313094 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1579192727804184
[5/23] Train loss=0.21575407683849335
[10/23] Train loss=0.14848829805850983
[15/23] Train loss=0.12715086340904236
[20/23] Train loss=0.11085660010576248
Test set avg_accuracy=88.62% avg_sensitivity=71.32%, avg_specificity=94.17% avg_auc=0.9287
Best model saved!! Metric=20.985188980249738!!
Fold[4] Epoch: 76 [76/100 (76%)] Train loss=0.170182 Test loss=0.315345 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15370970964431763
[5/23] Train loss=0.2275802195072174
[10/23] Train loss=0.153340682387352
[15/23] Train loss=0.1309480518102646
[20/23] Train loss=0.10937833040952682
Test set avg_accuracy=88.53% avg_sensitivity=71.50%, avg_specificity=93.99% avg_auc=0.9281
Fold[4] Epoch: 77 [77/100 (77%)] Train loss=0.169455 Test loss=0.314065 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15628579258918762
[5/23] Train loss=0.22474826872348785
[10/23] Train loss=0.15154843032360077
[15/23] Train loss=0.13204526901245117
[20/23] Train loss=0.11835942417383194
Test set avg_accuracy=88.66% avg_sensitivity=71.28%, avg_specificity=94.22% avg_auc=0.9276
Fold[4] Epoch: 78 [78/100 (78%)] Train loss=0.168328 Test loss=0.317190 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14894691109657288
[5/23] Train loss=0.22779639065265656
[10/23] Train loss=0.152724951505661
[15/23] Train loss=0.12443048506975174
[20/23] Train loss=0.11275817453861237
Test set avg_accuracy=88.75% avg_sensitivity=71.63%, avg_specificity=94.24% avg_auc=0.9274
Best model saved!! Metric=21.35695944630023!!
Fold[4] Epoch: 79 [79/100 (79%)] Train loss=0.166754 Test loss=0.315808 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14785723388195038
[5/23] Train loss=0.21400727331638336
[10/23] Train loss=0.1432613730430603
[15/23] Train loss=0.12539850175380707
[20/23] Train loss=0.10713230818510056
Test set avg_accuracy=88.47% avg_sensitivity=70.72%, avg_specificity=94.15% avg_auc=0.9281
Fold[4] Epoch: 80 [80/100 (80%)] Train loss=0.163094 Test loss=0.319737 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14609916508197784
[5/23] Train loss=0.2084195464849472
[10/23] Train loss=0.14590078592300415
[15/23] Train loss=0.12424451112747192
[20/23] Train loss=0.10978744179010391
Test set avg_accuracy=88.39% avg_sensitivity=70.50%, avg_specificity=94.13% avg_auc=0.9279
Fold[4] Epoch: 81 [81/100 (81%)] Train loss=0.161777 Test loss=0.320196 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15984033048152924
[5/23] Train loss=0.21685615181922913
[10/23] Train loss=0.13938939571380615
[15/23] Train loss=0.1269294172525406
[20/23] Train loss=0.10361381620168686
Test set avg_accuracy=88.42% avg_sensitivity=70.55%, avg_specificity=94.15% avg_auc=0.9289
Fold[4] Epoch: 82 [82/100 (82%)] Train loss=0.158973 Test loss=0.316691 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.151491180062294
[5/23] Train loss=0.21127526462078094
[10/23] Train loss=0.14233988523483276
[15/23] Train loss=0.11789673566818237
[20/23] Train loss=0.10391224920749664
Test set avg_accuracy=88.45% avg_sensitivity=70.76%, avg_specificity=94.11% avg_auc=0.9270
Fold[4] Epoch: 83 [83/100 (83%)] Train loss=0.157871 Test loss=0.321834 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1478835642337799
[5/23] Train loss=0.21025556325912476
[10/23] Train loss=0.1379852294921875
[15/23] Train loss=0.1168021559715271
[20/23] Train loss=0.10967417806386948
Test set avg_accuracy=88.35% avg_sensitivity=69.47%, avg_specificity=94.40% avg_auc=0.9264
Fold[4] Epoch: 84 [84/100 (84%)] Train loss=0.157876 Test loss=0.324751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14865081012248993
[5/23] Train loss=0.20372195541858673
[10/23] Train loss=0.13963881134986877
[15/23] Train loss=0.11972878873348236
[20/23] Train loss=0.10280650109052658
Test set avg_accuracy=88.22% avg_sensitivity=68.13%, avg_specificity=94.65% avg_auc=0.9274
Fold[4] Epoch: 85 [85/100 (85%)] Train loss=0.154167 Test loss=0.324166 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14486542344093323
[5/23] Train loss=0.19923754036426544
[10/23] Train loss=0.14000467956066132
[15/23] Train loss=0.11622380465269089
[20/23] Train loss=0.10489535331726074
Test set avg_accuracy=88.38% avg_sensitivity=70.29%, avg_specificity=94.18% avg_auc=0.9275
Fold[4] Epoch: 86 [86/100 (86%)] Train loss=0.150929 Test loss=0.324578 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14741824567317963
[5/23] Train loss=0.20035474002361298
[10/23] Train loss=0.1361456662416458
[15/23] Train loss=0.11317317187786102
[20/23] Train loss=0.11169715970754623
Test set avg_accuracy=88.49% avg_sensitivity=70.94%, avg_specificity=94.11% avg_auc=0.9278
Fold[4] Epoch: 87 [87/100 (87%)] Train loss=0.150643 Test loss=0.321233 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14750677347183228
[5/23] Train loss=0.19541554152965546
[10/23] Train loss=0.13174022734165192
[15/23] Train loss=0.12296304106712341
[20/23] Train loss=0.10277993977069855
Test set avg_accuracy=88.46% avg_sensitivity=70.29%, avg_specificity=94.28% avg_auc=0.9268
Fold[4] Epoch: 88 [88/100 (88%)] Train loss=0.146187 Test loss=0.327894 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1368001103401184
[5/23] Train loss=0.19192397594451904
[10/23] Train loss=0.12790203094482422
[15/23] Train loss=0.11603090912103653
[20/23] Train loss=0.09698875993490219
Test set avg_accuracy=88.94% avg_sensitivity=72.75%, avg_specificity=94.13% avg_auc=0.9292
Best model saved!! Metric=22.726663380078065!!
Fold[4] Epoch: 89 [89/100 (89%)] Train loss=0.144227 Test loss=0.322546 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1402522474527359
[5/23] Train loss=0.19227707386016846
[10/23] Train loss=0.1335415095090866
[15/23] Train loss=0.10655602067708969
[20/23] Train loss=0.0924830287694931
Test set avg_accuracy=88.56% avg_sensitivity=71.11%, avg_specificity=94.15% avg_auc=0.9297
Fold[4] Epoch: 90 [90/100 (90%)] Train loss=0.142328 Test loss=0.327633 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14287883043289185
[5/23] Train loss=0.19333294034004211
[10/23] Train loss=0.12745878100395203
[15/23] Train loss=0.10998140275478363
[20/23] Train loss=0.09545354545116425
Test set avg_accuracy=88.84% avg_sensitivity=72.32%, avg_specificity=94.14% avg_auc=0.9286
Fold[4] Epoch: 91 [91/100 (91%)] Train loss=0.141888 Test loss=0.327938 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1273556649684906
[5/23] Train loss=0.1889898180961609
[10/23] Train loss=0.12632249295711517
[15/23] Train loss=0.1086641326546669
[20/23] Train loss=0.09854434430599213
Test set avg_accuracy=88.59% avg_sensitivity=71.32%, avg_specificity=94.13% avg_auc=0.9295
Fold[4] Epoch: 92 [92/100 (92%)] Train loss=0.141012 Test loss=0.328980 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1284768432378769
[5/23] Train loss=0.19041107594966888
[10/23] Train loss=0.12554588913917542
[15/23] Train loss=0.11076023429632187
[20/23] Train loss=0.09158129245042801
Test set avg_accuracy=88.31% avg_sensitivity=68.00%, avg_specificity=94.82% avg_auc=0.9274
Fold[4] Epoch: 93 [93/100 (93%)] Train loss=0.139881 Test loss=0.334857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12575967609882355
[5/23] Train loss=0.18388241529464722
[10/23] Train loss=0.12177413702011108
[15/23] Train loss=0.11018484830856323
[20/23] Train loss=0.08779291808605194
Test set avg_accuracy=88.15% avg_sensitivity=69.56%, avg_specificity=94.11% avg_auc=0.9282
Fold[4] Epoch: 94 [94/100 (94%)] Train loss=0.135723 Test loss=0.336313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12695179879665375
[5/23] Train loss=0.18701548874378204
[10/23] Train loss=0.12049826234579086
[15/23] Train loss=0.10053016990423203
[20/23] Train loss=0.08795604109764099
Test set avg_accuracy=88.54% avg_sensitivity=70.85%, avg_specificity=94.21% avg_auc=0.9256
Fold[4] Epoch: 95 [95/100 (95%)] Train loss=0.133154 Test loss=0.339347 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13565203547477722
[5/23] Train loss=0.17340287566184998
[10/23] Train loss=0.1246110200881958
[15/23] Train loss=0.10658912360668182
[20/23] Train loss=0.09298374503850937
Test set avg_accuracy=88.82% avg_sensitivity=72.88%, avg_specificity=93.93% avg_auc=0.9286
Fold[4] Epoch: 96 [96/100 (96%)] Train loss=0.134333 Test loss=0.335906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1300041377544403
[5/23] Train loss=0.17123626172542572
[10/23] Train loss=0.12042909860610962
[15/23] Train loss=0.10610397160053253
[20/23] Train loss=0.09121356904506683
Test set avg_accuracy=88.71% avg_sensitivity=71.28%, avg_specificity=94.29% avg_auc=0.9280
Fold[4] Epoch: 97 [97/100 (97%)] Train loss=0.132155 Test loss=0.335725 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1243339255452156
[5/23] Train loss=0.16239705681800842
[10/23] Train loss=0.1214715763926506
[15/23] Train loss=0.10717985033988953
[20/23] Train loss=0.08919389545917511
Test set avg_accuracy=88.51% avg_sensitivity=68.95%, avg_specificity=94.78% avg_auc=0.9275
Fold[4] Epoch: 98 [98/100 (98%)] Train loss=0.128077 Test loss=0.348075 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11333686113357544
[5/23] Train loss=0.16397954523563385
[10/23] Train loss=0.11433522403240204
[15/23] Train loss=0.10159821063280106
[20/23] Train loss=0.08405699580907822
Test set avg_accuracy=88.34% avg_sensitivity=70.07%, avg_specificity=94.20% avg_auc=0.9282
Fold[4] Epoch: 99 [99/100 (99%)] Train loss=0.125466 Test loss=0.344685 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11692241579294205
[5/23] Train loss=0.16863813996315002
[10/23] Train loss=0.11532145738601685
[15/23] Train loss=0.09272289276123047
[20/23] Train loss=0.09205801784992218
Test set avg_accuracy=88.35% avg_sensitivity=69.43%, avg_specificity=94.42% avg_auc=0.9271
Fold[4] Epoch: 100 [100/100 (100%)] Train loss=0.125198 Test loss=0.347899 Current lr=[3.9999999999999996e-05]

Fold[4] Best Result: acc=88.93772893772893 sen=72.74687365243639, spe=94.126589275843, auc=0.9291547151406974!
[0/23] Train loss=0.7202162146568298
[5/23] Train loss=0.6412521600723267
[10/23] Train loss=0.5829290151596069
[15/23] Train loss=0.5235992074012756
[20/23] Train loss=0.5077996253967285
Test set avg_accuracy=74.71% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7137
Best model saved!! Metric=-79.91489524506734!!
Fold[5] Epoch: 1 [1/100 (1%)] Train loss=0.567664 Test loss=0.561200 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5141817927360535
[5/23] Train loss=0.5441053509712219
[10/23] Train loss=0.464962363243103
[15/23] Train loss=0.4515138864517212
[20/23] Train loss=0.381094753742218
Test set avg_accuracy=77.50% avg_sensitivity=23.97%, avg_specificity=95.62% avg_auc=0.8333
Best model saved!! Metric=-45.589839499308326!!
Fold[5] Epoch: 2 [2/100 (2%)] Train loss=0.467586 Test loss=0.446319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3870737850666046
[5/23] Train loss=0.4461030960083008
[10/23] Train loss=0.40306976437568665
[15/23] Train loss=0.3935416340827942
[20/23] Train loss=0.3427199423313141
Test set avg_accuracy=81.61% avg_sensitivity=48.43%, avg_specificity=92.84% avg_auc=0.8569
Best model saved!! Metric=-17.430492293058496!!
Fold[5] Epoch: 3 [3/100 (3%)] Train loss=0.408076 Test loss=0.415413 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3626434803009033
[5/23] Train loss=0.4166627526283264
[10/23] Train loss=0.3846732974052429
[15/23] Train loss=0.35555610060691833
[20/23] Train loss=0.3208942413330078
Test set avg_accuracy=83.00% avg_sensitivity=50.58%, avg_specificity=93.98% avg_auc=0.8706
Best model saved!! Metric=-11.383813004904795!!
Fold[5] Epoch: 4 [4/100 (4%)] Train loss=0.385856 Test loss=0.395624 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3417540490627289
[5/23] Train loss=0.4305700659751892
[10/23] Train loss=0.3782190680503845
[15/23] Train loss=0.3431232273578644
[20/23] Train loss=0.3089302182197571
Test set avg_accuracy=84.14% avg_sensitivity=52.11%, avg_specificity=94.99% avg_auc=0.8814
Best model saved!! Metric=-6.616524872707171!!
Fold[5] Epoch: 5 [5/100 (5%)] Train loss=0.378474 Test loss=0.384262 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3370380699634552
[5/23] Train loss=0.4237046241760254
[10/23] Train loss=0.3608499765396118
[15/23] Train loss=0.3405548334121704
[20/23] Train loss=0.3000204265117645
Test set avg_accuracy=84.68% avg_sensitivity=51.32%, avg_specificity=95.97% avg_auc=0.8928
Best model saved!! Metric=-4.753057347423475!!
Fold[5] Epoch: 6 [6/100 (6%)] Train loss=0.372690 Test loss=0.373335 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32002946734428406
[5/23] Train loss=0.43888893723487854
[10/23] Train loss=0.3382939100265503
[15/23] Train loss=0.35170188546180725
[20/23] Train loss=0.30917057394981384
Test set avg_accuracy=85.45% avg_sensitivity=58.86%, avg_specificity=94.45% avg_auc=0.9026
Best model saved!! Metric=3.0200282552791955!!
Fold[5] Epoch: 7 [7/100 (7%)] Train loss=0.372243 Test loss=0.343270 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3186347484588623
[5/23] Train loss=0.4691735804080963
[10/23] Train loss=0.31069737672805786
[15/23] Train loss=0.33839061856269836
[20/23] Train loss=0.3071269392967224
Test set avg_accuracy=85.88% avg_sensitivity=67.43%, avg_specificity=92.13% avg_auc=0.9070
Best model saved!! Metric=10.138076892623603!!
Fold[5] Epoch: 8 [8/100 (8%)] Train loss=0.369004 Test loss=0.329042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3099486529827118
[5/23] Train loss=0.4278978109359741
[10/23] Train loss=0.284964382648468
[15/23] Train loss=0.3116667568683624
[20/23] Train loss=0.2945149838924408
Test set avg_accuracy=85.82% avg_sensitivity=73.55%, avg_specificity=89.97% avg_auc=0.9097
Best model saved!! Metric=14.307126514693486!!
Fold[5] Epoch: 9 [9/100 (9%)] Train loss=0.348084 Test loss=0.327409 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30436161160469055
[5/23] Train loss=0.3903673589229584
[10/23] Train loss=0.27583175897598267
[15/23] Train loss=0.29715266823768616
[20/23] Train loss=0.27004989981651306
Test set avg_accuracy=86.80% avg_sensitivity=75.12%, avg_specificity=90.76% avg_auc=0.9177
Best model saved!! Metric=18.452949894109654!!
Fold[5] Epoch: 10 [10/100 (10%)] Train loss=0.334331 Test loss=0.313768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27562132477760315
[5/23] Train loss=0.3815615773200989
[10/23] Train loss=0.26105886697769165
[15/23] Train loss=0.2895749807357788
[20/23] Train loss=0.2553587853908539
Test set avg_accuracy=87.31% avg_sensitivity=76.66%, avg_specificity=90.91% avg_auc=0.9233
Best model saved!! Metric=21.196857007851776!!
Fold[5] Epoch: 11 [11/100 (11%)] Train loss=0.321541 Test loss=0.304061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26389822363853455
[5/23] Train loss=0.39081820845603943
[10/23] Train loss=0.24957890808582306
[15/23] Train loss=0.276010662317276
[20/23] Train loss=0.23679563403129578
Test set avg_accuracy=88.12% avg_sensitivity=74.59%, avg_specificity=92.70% avg_auc=0.9275
Best model saved!! Metric=22.154870976833084!!
Fold[5] Epoch: 12 [12/100 (12%)] Train loss=0.316995 Test loss=0.293314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2598305940628052
[5/23] Train loss=0.3969518542289734
[10/23] Train loss=0.2589954137802124
[15/23] Train loss=0.2607439458370209
[20/23] Train loss=0.23764100670814514
Test set avg_accuracy=88.07% avg_sensitivity=74.30%, avg_specificity=92.73% avg_auc=0.9290
Fold[5] Epoch: 13 [13/100 (13%)] Train loss=0.311855 Test loss=0.289110 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24205805361270905
[5/23] Train loss=0.39936184883117676
[10/23] Train loss=0.24855607748031616
[15/23] Train loss=0.2597561180591583
[20/23] Train loss=0.22838710248470306
Test set avg_accuracy=88.08% avg_sensitivity=75.12%, avg_specificity=92.46% avg_auc=0.9296
Best model saved!! Metric=22.62888184833892!!
Fold[5] Epoch: 14 [14/100 (14%)] Train loss=0.308676 Test loss=0.288986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24799352884292603
[5/23] Train loss=0.3869047462940216
[10/23] Train loss=0.23525752127170563
[15/23] Train loss=0.25443321466445923
[20/23] Train loss=0.225611612200737
Test set avg_accuracy=88.40% avg_sensitivity=76.28%, avg_specificity=92.51% avg_auc=0.9309
Best model saved!! Metric=24.28269280645763!!
Fold[5] Epoch: 15 [15/100 (15%)] Train loss=0.300118 Test loss=0.286921 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23707333207130432
[5/23] Train loss=0.3811854422092438
[10/23] Train loss=0.23528507351875305
[15/23] Train loss=0.24912814795970917
[20/23] Train loss=0.21411806344985962
Test set avg_accuracy=88.31% avg_sensitivity=78.06%, avg_specificity=91.78% avg_auc=0.9319
Best model saved!! Metric=25.341403238167306!!
Fold[5] Epoch: 16 [16/100 (16%)] Train loss=0.295578 Test loss=0.286874 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24968597292900085
[5/23] Train loss=0.3613813519477844
[10/23] Train loss=0.2352132499217987
[15/23] Train loss=0.2280668467283249
[20/23] Train loss=0.21820147335529327
Test set avg_accuracy=88.44% avg_sensitivity=76.45%, avg_specificity=92.49% avg_auc=0.9322
Fold[5] Epoch: 17 [17/100 (17%)] Train loss=0.291142 Test loss=0.285048 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23003646731376648
[5/23] Train loss=0.3524934947490692
[10/23] Train loss=0.22652870416641235
[15/23] Train loss=0.2329065054655075
[20/23] Train loss=0.21038872003555298
Test set avg_accuracy=88.61% avg_sensitivity=76.24%, avg_specificity=92.80% avg_auc=0.9324
Fold[5] Epoch: 18 [18/100 (18%)] Train loss=0.286302 Test loss=0.282709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24186767637729645
[5/23] Train loss=0.3604045808315277
[10/23] Train loss=0.22127695381641388
[15/23] Train loss=0.22269710898399353
[20/23] Train loss=0.20375320315361023
Test set avg_accuracy=88.47% avg_sensitivity=78.02%, avg_specificity=92.00% avg_auc=0.9336
Best model saved!! Metric=25.851230720067576!!
Fold[5] Epoch: 19 [19/100 (19%)] Train loss=0.281516 Test loss=0.283318 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2292584329843521
[5/23] Train loss=0.3460470139980316
[10/23] Train loss=0.22153210639953613
[15/23] Train loss=0.22491170465946198
[20/23] Train loss=0.2091074436903
Test set avg_accuracy=88.75% avg_sensitivity=77.36%, avg_specificity=92.60% avg_auc=0.9340
Best model saved!! Metric=26.108518040527354!!
Fold[5] Epoch: 20 [20/100 (20%)] Train loss=0.279913 Test loss=0.280826 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2270974963903427
[5/23] Train loss=0.34434765577316284
[10/23] Train loss=0.21735507249832153
[15/23] Train loss=0.21935400366783142
[20/23] Train loss=0.20336458086967468
Test set avg_accuracy=89.03% avg_sensitivity=76.78%, avg_specificity=93.18% avg_auc=0.9352
Best model saved!! Metric=26.513510949819697!!
Fold[5] Epoch: 21 [21/100 (21%)] Train loss=0.274509 Test loss=0.277021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22132910788059235
[5/23] Train loss=0.34291934967041016
[10/23] Train loss=0.21755707263946533
[15/23] Train loss=0.21728824079036713
[20/23] Train loss=0.19202129542827606
Test set avg_accuracy=89.37% avg_sensitivity=76.95%, avg_specificity=93.57% avg_auc=0.9346
Best model saved!! Metric=27.34726547522815!!
Fold[5] Epoch: 22 [22/100 (22%)] Train loss=0.269822 Test loss=0.278171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22524148225784302
[5/23] Train loss=0.34766003489494324
[10/23] Train loss=0.21743416786193848
[15/23] Train loss=0.21445894241333008
[20/23] Train loss=0.1945001482963562
Test set avg_accuracy=88.98% avg_sensitivity=76.45%, avg_specificity=93.22% avg_auc=0.9349
Fold[5] Epoch: 23 [23/100 (23%)] Train loss=0.271439 Test loss=0.277151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21901275217533112
[5/23] Train loss=0.33734753727912903
[10/23] Train loss=0.21338242292404175
[15/23] Train loss=0.2135474532842636
[20/23] Train loss=0.1885949820280075
Test set avg_accuracy=89.46% avg_sensitivity=76.53%, avg_specificity=93.84% avg_auc=0.9355
Best model saved!! Metric=27.380284063944476!!
Fold[5] Epoch: 24 [24/100 (24%)] Train loss=0.265344 Test loss=0.275151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21887671947479248
[5/23] Train loss=0.33553120493888855
[10/23] Train loss=0.2210605889558792
[15/23] Train loss=0.21157002449035645
[20/23] Train loss=0.1873188018798828
Test set avg_accuracy=89.61% avg_sensitivity=75.62%, avg_specificity=94.34% avg_auc=0.9359
Fold[5] Epoch: 25 [25/100 (25%)] Train loss=0.265819 Test loss=0.274144 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21235869824886322
[5/23] Train loss=0.3368481993675232
[10/23] Train loss=0.21099033951759338
[15/23] Train loss=0.2034764140844345
[20/23] Train loss=0.18282218277454376
Test set avg_accuracy=89.08% avg_sensitivity=76.20%, avg_specificity=93.44% avg_auc=0.9351
Fold[5] Epoch: 26 [26/100 (26%)] Train loss=0.263372 Test loss=0.276786 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2190561443567276
[5/23] Train loss=0.33830782771110535
[10/23] Train loss=0.20293354988098145
[15/23] Train loss=0.20348337292671204
[20/23] Train loss=0.18581555783748627
Test set avg_accuracy=89.20% avg_sensitivity=77.32%, avg_specificity=93.22% avg_auc=0.9356
Fold[5] Epoch: 27 [27/100 (27%)] Train loss=0.260606 Test loss=0.277338 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2141406238079071
[5/23] Train loss=0.332325279712677
[10/23] Train loss=0.2054757922887802
[15/23] Train loss=0.2061755657196045
[20/23] Train loss=0.1794384866952896
Test set avg_accuracy=89.20% avg_sensitivity=76.78%, avg_specificity=93.40% avg_auc=0.9355
Fold[5] Epoch: 28 [28/100 (28%)] Train loss=0.256581 Test loss=0.276598 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2229500561952591
[5/23] Train loss=0.3372265100479126
[10/23] Train loss=0.2040259689092636
[15/23] Train loss=0.20397819578647614
[20/23] Train loss=0.1807795614004135
Test set avg_accuracy=89.38% avg_sensitivity=75.91%, avg_specificity=93.93% avg_auc=0.9356
Fold[5] Epoch: 29 [29/100 (29%)] Train loss=0.256565 Test loss=0.275404 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22063274681568146
[5/23] Train loss=0.32027533650398254
[10/23] Train loss=0.21382035315036774
[15/23] Train loss=0.20066344738006592
[20/23] Train loss=0.17333626747131348
Test set avg_accuracy=89.47% avg_sensitivity=75.87%, avg_specificity=94.07% avg_auc=0.9358
Fold[5] Epoch: 30 [30/100 (30%)] Train loss=0.255402 Test loss=0.274572 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20148733258247375
[5/23] Train loss=0.33440202474594116
[10/23] Train loss=0.2034052014350891
[15/23] Train loss=0.20270845293998718
[20/23] Train loss=0.17372551560401917
Test set avg_accuracy=89.60% avg_sensitivity=75.95%, avg_specificity=94.21% avg_auc=0.9353
Fold[5] Epoch: 31 [31/100 (31%)] Train loss=0.253753 Test loss=0.275321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2044755518436432
[5/23] Train loss=0.31300103664398193
[10/23] Train loss=0.19724836945533752
[15/23] Train loss=0.1996089220046997
[20/23] Train loss=0.17658154666423798
Test set avg_accuracy=89.05% avg_sensitivity=76.70%, avg_specificity=93.23% avg_auc=0.9361
Fold[5] Epoch: 32 [32/100 (32%)] Train loss=0.251009 Test loss=0.275698 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20542775094509125
[5/23] Train loss=0.3269830644130707
[10/23] Train loss=0.19616836309432983
[15/23] Train loss=0.19823545217514038
[20/23] Train loss=0.17561516165733337
Test set avg_accuracy=89.18% avg_sensitivity=77.19%, avg_specificity=93.23% avg_auc=0.9358
Fold[5] Epoch: 33 [33/100 (33%)] Train loss=0.247547 Test loss=0.276914 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20829153060913086
[5/23] Train loss=0.3213209807872772
[10/23] Train loss=0.19347448647022247
[15/23] Train loss=0.19900856912136078
[20/23] Train loss=0.1726420819759369
Test set avg_accuracy=89.26% avg_sensitivity=77.28%, avg_specificity=93.32% avg_auc=0.9369
Best model saved!! Metric=27.542457646399846!!
Fold[5] Epoch: 34 [34/100 (34%)] Train loss=0.245882 Test loss=0.273802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20511466264724731
[5/23] Train loss=0.30326783657073975
[10/23] Train loss=0.20017653703689575
[15/23] Train loss=0.1939355432987213
[20/23] Train loss=0.17083343863487244
Test set avg_accuracy=89.85% avg_sensitivity=75.08%, avg_specificity=94.85% avg_auc=0.9362
Fold[5] Epoch: 35 [35/100 (35%)] Train loss=0.243504 Test loss=0.273097 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20472458004951477
[5/23] Train loss=0.31342142820358276
[10/23] Train loss=0.1967179924249649
[15/23] Train loss=0.19360880553722382
[20/23] Train loss=0.17151881754398346
Test set avg_accuracy=89.48% avg_sensitivity=76.66%, avg_specificity=93.82% avg_auc=0.9370
Best model saved!! Metric=27.656902839570336!!
Fold[5] Epoch: 36 [36/100 (36%)] Train loss=0.243645 Test loss=0.273005 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20438602566719055
[5/23] Train loss=0.3046909272670746
[10/23] Train loss=0.19224122166633606
[15/23] Train loss=0.18756531178951263
[20/23] Train loss=0.17069701850414276
Test set avg_accuracy=89.51% avg_sensitivity=75.83%, avg_specificity=94.14% avg_auc=0.9356
Fold[5] Epoch: 37 [37/100 (37%)] Train loss=0.242453 Test loss=0.275008 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19913804531097412
[5/23] Train loss=0.31449779868125916
[10/23] Train loss=0.20238998532295227
[15/23] Train loss=0.1858738660812378
[20/23] Train loss=0.16491825878620148
Test set avg_accuracy=89.28% avg_sensitivity=75.37%, avg_specificity=93.99% avg_auc=0.9353
Fold[5] Epoch: 38 [38/100 (38%)] Train loss=0.240041 Test loss=0.275767 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19349680840969086
[5/23] Train loss=0.30741459131240845
[10/23] Train loss=0.1929340958595276
[15/23] Train loss=0.1874476671218872
[20/23] Train loss=0.16591666638851166
Test set avg_accuracy=89.47% avg_sensitivity=75.95%, avg_specificity=94.05% avg_auc=0.9367
Fold[5] Epoch: 39 [39/100 (39%)] Train loss=0.238520 Test loss=0.273787 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19895237684249878
[5/23] Train loss=0.3121837079524994
[10/23] Train loss=0.1881844401359558
[15/23] Train loss=0.18661795556545258
[20/23] Train loss=0.16509753465652466
Test set avg_accuracy=89.52% avg_sensitivity=75.75%, avg_specificity=94.19% avg_auc=0.9373
Fold[5] Epoch: 40 [40/100 (40%)] Train loss=0.237117 Test loss=0.271729 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20039525628089905
[5/23] Train loss=0.31485605239868164
[10/23] Train loss=0.1896381676197052
[15/23] Train loss=0.17923475801944733
[20/23] Train loss=0.16886968910694122
Test set avg_accuracy=89.53% avg_sensitivity=76.20%, avg_specificity=94.05% avg_auc=0.9376
Fold[5] Epoch: 41 [41/100 (41%)] Train loss=0.235770 Test loss=0.272332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19759038090705872
[5/23] Train loss=0.30942416191101074
[10/23] Train loss=0.1868651956319809
[15/23] Train loss=0.18534766137599945
[20/23] Train loss=0.16611072421073914
Test set avg_accuracy=89.38% avg_sensitivity=73.88%, avg_specificity=94.62% avg_auc=0.9349
Fold[5] Epoch: 42 [42/100 (42%)] Train loss=0.235666 Test loss=0.276051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21159440279006958
[5/23] Train loss=0.3091907799243927
[10/23] Train loss=0.1818312108516693
[15/23] Train loss=0.17776185274124146
[20/23] Train loss=0.16596442461013794
Test set avg_accuracy=89.40% avg_sensitivity=75.75%, avg_specificity=94.02% avg_auc=0.9365
Fold[5] Epoch: 43 [43/100 (43%)] Train loss=0.233709 Test loss=0.274429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19489170610904694
[5/23] Train loss=0.29548364877700806
[10/23] Train loss=0.18977102637290955
[15/23] Train loss=0.18216943740844727
[20/23] Train loss=0.15809568762779236
Test set avg_accuracy=89.80% avg_sensitivity=75.83%, avg_specificity=94.52% avg_auc=0.9351
Fold[5] Epoch: 44 [44/100 (44%)] Train loss=0.228254 Test loss=0.276953 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19469578564167023
[5/23] Train loss=0.3000391721725464
[10/23] Train loss=0.1805506944656372
[15/23] Train loss=0.17905031144618988
[20/23] Train loss=0.15732111036777496
Test set avg_accuracy=89.59% avg_sensitivity=75.66%, avg_specificity=94.30% avg_auc=0.9362
Fold[5] Epoch: 45 [45/100 (45%)] Train loss=0.229041 Test loss=0.275130 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19981032609939575
[5/23] Train loss=0.298520028591156
[10/23] Train loss=0.18680326640605927
[15/23] Train loss=0.1699695736169815
[20/23] Train loss=0.15814994275569916
Test set avg_accuracy=89.72% avg_sensitivity=75.04%, avg_specificity=94.69% avg_auc=0.9363
Fold[5] Epoch: 46 [46/100 (46%)] Train loss=0.228282 Test loss=0.273750 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19125542044639587
[5/23] Train loss=0.2972141206264496
[10/23] Train loss=0.1832110732793808
[15/23] Train loss=0.17199744284152985
[20/23] Train loss=0.15486204624176025
Test set avg_accuracy=89.71% avg_sensitivity=75.58%, avg_specificity=94.50% avg_auc=0.9366
Fold[5] Epoch: 47 [47/100 (47%)] Train loss=0.225680 Test loss=0.274236 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1934325248003006
[5/23] Train loss=0.2879306972026825
[10/23] Train loss=0.18406939506530762
[15/23] Train loss=0.1739407479763031
[20/23] Train loss=0.15176142752170563
Test set avg_accuracy=89.57% avg_sensitivity=75.29%, avg_specificity=94.40% avg_auc=0.9358
Fold[5] Epoch: 48 [48/100 (48%)] Train loss=0.224330 Test loss=0.275889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1922527700662613
[5/23] Train loss=0.2827887535095215
[10/23] Train loss=0.1883525252342224
[15/23] Train loss=0.1747426986694336
[20/23] Train loss=0.14986422657966614
Test set avg_accuracy=89.36% avg_sensitivity=75.99%, avg_specificity=93.88% avg_auc=0.9358
Fold[5] Epoch: 49 [49/100 (49%)] Train loss=0.222321 Test loss=0.276427 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1950947642326355
[5/23] Train loss=0.29494354128837585
[10/23] Train loss=0.1797235757112503
[15/23] Train loss=0.17574985325336456
[20/23] Train loss=0.1491541564464569
Test set avg_accuracy=89.41% avg_sensitivity=76.49%, avg_specificity=93.78% avg_auc=0.9356
Fold[5] Epoch: 50 [50/100 (50%)] Train loss=0.221361 Test loss=0.279120 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18747228384017944
[5/23] Train loss=0.2796361446380615
[10/23] Train loss=0.18034912645816803
[15/23] Train loss=0.17281988263130188
[20/23] Train loss=0.14832471311092377
Test set avg_accuracy=89.23% avg_sensitivity=75.95%, avg_specificity=93.72% avg_auc=0.9360
Fold[5] Epoch: 51 [51/100 (51%)] Train loss=0.217304 Test loss=0.277158 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18843874335289001
[5/23] Train loss=0.28911513090133667
[10/23] Train loss=0.1805243343114853
[15/23] Train loss=0.16462261974811554
[20/23] Train loss=0.14349524676799774
Test set avg_accuracy=89.39% avg_sensitivity=75.08%, avg_specificity=94.23% avg_auc=0.9351
Fold[5] Epoch: 52 [52/100 (52%)] Train loss=0.218625 Test loss=0.278873 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18466301262378693
[5/23] Train loss=0.28439393639564514
[10/23] Train loss=0.17725048959255219
[15/23] Train loss=0.1691988855600357
[20/23] Train loss=0.14985224604606628
Test set avg_accuracy=89.36% avg_sensitivity=77.11%, avg_specificity=93.50% avg_auc=0.9353
Fold[5] Epoch: 53 [53/100 (53%)] Train loss=0.215172 Test loss=0.280051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17653489112854004
[5/23] Train loss=0.26964303851127625
[10/23] Train loss=0.18025177717208862
[15/23] Train loss=0.16572993993759155
[20/23] Train loss=0.14244289696216583
Test set avg_accuracy=89.20% avg_sensitivity=76.95%, avg_specificity=93.35% avg_auc=0.9354
Fold[5] Epoch: 54 [54/100 (54%)] Train loss=0.212417 Test loss=0.282093 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17906363308429718
[5/23] Train loss=0.2770955264568329
[10/23] Train loss=0.17772121727466583
[15/23] Train loss=0.1650814712047577
[20/23] Train loss=0.14795120060443878
Test set avg_accuracy=89.46% avg_sensitivity=75.66%, avg_specificity=94.13% avg_auc=0.9351
Fold[5] Epoch: 55 [55/100 (55%)] Train loss=0.211566 Test loss=0.278430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18231825530529022
[5/23] Train loss=0.2703140079975128
[10/23] Train loss=0.170039564371109
[15/23] Train loss=0.15785299241542816
[20/23] Train loss=0.1503497213125229
Test set avg_accuracy=89.45% avg_sensitivity=74.83%, avg_specificity=94.40% avg_auc=0.9340
Fold[5] Epoch: 56 [56/100 (56%)] Train loss=0.210193 Test loss=0.281418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18165209889411926
[5/23] Train loss=0.27315500378608704
[10/23] Train loss=0.16866451501846313
[15/23] Train loss=0.15735240280628204
[20/23] Train loss=0.1372421234846115
Test set avg_accuracy=89.34% avg_sensitivity=75.58%, avg_specificity=93.99% avg_auc=0.9357
Fold[5] Epoch: 57 [57/100 (57%)] Train loss=0.207192 Test loss=0.278115 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18411101400852203
[5/23] Train loss=0.2712010443210602
[10/23] Train loss=0.16880963742733002
[15/23] Train loss=0.15958386659622192
[20/23] Train loss=0.1360856294631958
Test set avg_accuracy=89.44% avg_sensitivity=74.67%, avg_specificity=94.44% avg_auc=0.9336
Fold[5] Epoch: 58 [58/100 (58%)] Train loss=0.206274 Test loss=0.282433 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18075302243232727
[5/23] Train loss=0.27698394656181335
[10/23] Train loss=0.17362526059150696
[15/23] Train loss=0.1548875868320465
[20/23] Train loss=0.14274069666862488
Test set avg_accuracy=89.44% avg_sensitivity=74.75%, avg_specificity=94.41% avg_auc=0.9350
Fold[5] Epoch: 59 [59/100 (59%)] Train loss=0.205851 Test loss=0.279895 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17568975687026978
[5/23] Train loss=0.2727476954460144
[10/23] Train loss=0.17053817212581635
[15/23] Train loss=0.14918774366378784
[20/23] Train loss=0.1379537284374237
Test set avg_accuracy=89.48% avg_sensitivity=75.21%, avg_specificity=94.31% avg_auc=0.9350
Fold[5] Epoch: 60 [60/100 (60%)] Train loss=0.203698 Test loss=0.280327 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18167878687381744
[5/23] Train loss=0.27019262313842773
[10/23] Train loss=0.17356528341770172
[15/23] Train loss=0.15469016134738922
[20/23] Train loss=0.13530343770980835
Test set avg_accuracy=89.50% avg_sensitivity=74.17%, avg_specificity=94.69% avg_auc=0.9323
Fold[5] Epoch: 61 [61/100 (61%)] Train loss=0.202438 Test loss=0.286046 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1778499037027359
[5/23] Train loss=0.2616860270500183
[10/23] Train loss=0.17039600014686584
[15/23] Train loss=0.15040330588817596
[20/23] Train loss=0.1422538459300995
Test set avg_accuracy=89.72% avg_sensitivity=74.75%, avg_specificity=94.79% avg_auc=0.9333
Fold[5] Epoch: 62 [62/100 (62%)] Train loss=0.200194 Test loss=0.284251 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17652396857738495
[5/23] Train loss=0.2695675790309906
[10/23] Train loss=0.17549172043800354
[15/23] Train loss=0.14916718006134033
[20/23] Train loss=0.13261063396930695
Test set avg_accuracy=89.50% avg_sensitivity=74.30%, avg_specificity=94.65% avg_auc=0.9344
Fold[5] Epoch: 63 [63/100 (63%)] Train loss=0.199016 Test loss=0.282855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18382461369037628
[5/23] Train loss=0.25788235664367676
[10/23] Train loss=0.17169417440891266
[15/23] Train loss=0.14727436006069183
[20/23] Train loss=0.13206134736537933
Test set avg_accuracy=89.31% avg_sensitivity=73.47%, avg_specificity=94.68% avg_auc=0.9333
Fold[5] Epoch: 64 [64/100 (64%)] Train loss=0.196924 Test loss=0.284719 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1712082475423813
[5/23] Train loss=0.2622751295566559
[10/23] Train loss=0.1653996706008911
[15/23] Train loss=0.14491140842437744
[20/23] Train loss=0.125466987490654
Test set avg_accuracy=89.17% avg_sensitivity=74.42%, avg_specificity=94.16% avg_auc=0.9345
Fold[5] Epoch: 65 [65/100 (65%)] Train loss=0.193622 Test loss=0.283212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17199330031871796
[5/23] Train loss=0.26156067848205566
[10/23] Train loss=0.16062787175178528
[15/23] Train loss=0.146864652633667
[20/23] Train loss=0.13351720571517944
Test set avg_accuracy=89.48% avg_sensitivity=73.97%, avg_specificity=94.73% avg_auc=0.9336
Fold[5] Epoch: 66 [66/100 (66%)] Train loss=0.193494 Test loss=0.285224 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1736036092042923
[5/23] Train loss=0.2617233395576477
[10/23] Train loss=0.16518348455429077
[15/23] Train loss=0.1455734223127365
[20/23] Train loss=0.12749573588371277
Test set avg_accuracy=89.09% avg_sensitivity=73.26%, avg_specificity=94.45% avg_auc=0.9314
Fold[5] Epoch: 67 [67/100 (67%)] Train loss=0.191962 Test loss=0.292113 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17340409755706787
[5/23] Train loss=0.2581017017364502
[10/23] Train loss=0.1622147560119629
[15/23] Train loss=0.14229567348957062
[20/23] Train loss=0.12977391481399536
Test set avg_accuracy=89.21% avg_sensitivity=73.92%, avg_specificity=94.38% avg_auc=0.9323
Fold[5] Epoch: 68 [68/100 (68%)] Train loss=0.190290 Test loss=0.288457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1726025938987732
[5/23] Train loss=0.2528821527957916
[10/23] Train loss=0.15560345351696014
[15/23] Train loss=0.15118032693862915
[20/23] Train loss=0.1307692527770996
Test set avg_accuracy=89.14% avg_sensitivity=74.83%, avg_specificity=93.98% avg_auc=0.9305
Fold[5] Epoch: 69 [69/100 (69%)] Train loss=0.190013 Test loss=0.292706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16321153938770294
[5/23] Train loss=0.2539137005805969
[10/23] Train loss=0.1573013961315155
[15/23] Train loss=0.14394214749336243
[20/23] Train loss=0.1247546523809433
Test set avg_accuracy=88.93% avg_sensitivity=75.54%, avg_specificity=93.46% avg_auc=0.9313
Fold[5] Epoch: 70 [70/100 (70%)] Train loss=0.187376 Test loss=0.292232 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16677559912204742
[5/23] Train loss=0.2506132423877716
[10/23] Train loss=0.1614135503768921
[15/23] Train loss=0.1385468691587448
[20/23] Train loss=0.1209942176938057
Test set avg_accuracy=88.80% avg_sensitivity=77.24%, avg_specificity=92.72% avg_auc=0.9337
Fold[5] Epoch: 71 [71/100 (71%)] Train loss=0.184410 Test loss=0.291972 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16403613984584808
[5/23] Train loss=0.24843433499336243
[10/23] Train loss=0.1555461436510086
[15/23] Train loss=0.13848334550857544
[20/23] Train loss=0.12338478118181229
Test set avg_accuracy=89.13% avg_sensitivity=74.34%, avg_specificity=94.13% avg_auc=0.9326
Fold[5] Epoch: 72 [72/100 (72%)] Train loss=0.181639 Test loss=0.290594 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16844207048416138
[5/23] Train loss=0.24516268074512482
[10/23] Train loss=0.1575922966003418
[15/23] Train loss=0.13643553853034973
[20/23] Train loss=0.12822821736335754
Test set avg_accuracy=88.86% avg_sensitivity=74.79%, avg_specificity=93.63% avg_auc=0.9330
Fold[5] Epoch: 73 [73/100 (73%)] Train loss=0.181349 Test loss=0.288889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1552049070596695
[5/23] Train loss=0.24028809368610382
[10/23] Train loss=0.15475352108478546
[15/23] Train loss=0.13809631764888763
[20/23] Train loss=0.12462184578180313
Test set avg_accuracy=88.84% avg_sensitivity=73.84%, avg_specificity=93.92% avg_auc=0.9318
Fold[5] Epoch: 74 [74/100 (74%)] Train loss=0.180121 Test loss=0.293255 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16171808540821075
[5/23] Train loss=0.2407081574201584
[10/23] Train loss=0.1450844556093216
[15/23] Train loss=0.13851845264434814
[20/23] Train loss=0.12483885139226913
Test set avg_accuracy=88.86% avg_sensitivity=74.79%, avg_specificity=93.63% avg_auc=0.9308
Fold[5] Epoch: 75 [75/100 (75%)] Train loss=0.177303 Test loss=0.296215 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16176943480968475
[5/23] Train loss=0.23844733834266663
[10/23] Train loss=0.1488763391971588
[15/23] Train loss=0.13173583149909973
[20/23] Train loss=0.11901574581861496
Test set avg_accuracy=88.95% avg_sensitivity=76.24%, avg_specificity=93.25% avg_auc=0.9319
Fold[5] Epoch: 76 [76/100 (76%)] Train loss=0.174547 Test loss=0.295353 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16076114773750305
[5/23] Train loss=0.22417564690113068
[10/23] Train loss=0.14837926626205444
[15/23] Train loss=0.13796111941337585
[20/23] Train loss=0.11918062716722488
Test set avg_accuracy=88.82% avg_sensitivity=74.83%, avg_specificity=93.56% avg_auc=0.9294
Fold[5] Epoch: 77 [77/100 (77%)] Train loss=0.170846 Test loss=0.300543 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16512829065322876
[5/23] Train loss=0.2321147322654724
[10/23] Train loss=0.15588246285915375
[15/23] Train loss=0.137101411819458
[20/23] Train loss=0.11936042457818985
Test set avg_accuracy=89.02% avg_sensitivity=76.70%, avg_specificity=93.19% avg_auc=0.9301
Fold[5] Epoch: 78 [78/100 (78%)] Train loss=0.171220 Test loss=0.300249 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15537746250629425
[5/23] Train loss=0.22202923893928528
[10/23] Train loss=0.14600582420825958
[15/23] Train loss=0.12527355551719666
[20/23] Train loss=0.1138928085565567
Test set avg_accuracy=88.83% avg_sensitivity=76.24%, avg_specificity=93.09% avg_auc=0.9305
Fold[5] Epoch: 79 [79/100 (79%)] Train loss=0.167538 Test loss=0.299830 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1498369574546814
[5/23] Train loss=0.2240866720676422
[10/23] Train loss=0.14788788557052612
[15/23] Train loss=0.13247530162334442
[20/23] Train loss=0.11095769703388214
Test set avg_accuracy=88.73% avg_sensitivity=76.03%, avg_specificity=93.02% avg_auc=0.9298
Fold[5] Epoch: 80 [80/100 (80%)] Train loss=0.165364 Test loss=0.302445 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16079790890216827
[5/23] Train loss=0.22638431191444397
[10/23] Train loss=0.14819923043251038
[15/23] Train loss=0.12777191400527954
[20/23] Train loss=0.11421588808298111
Test set avg_accuracy=88.71% avg_sensitivity=77.24%, avg_specificity=92.59% avg_auc=0.9295
Fold[5] Epoch: 81 [81/100 (81%)] Train loss=0.164927 Test loss=0.305050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15020689368247986
[5/23] Train loss=0.21477702260017395
[10/23] Train loss=0.14159920811653137
[15/23] Train loss=0.13053791224956512
[20/23] Train loss=0.10684442520141602
Test set avg_accuracy=88.94% avg_sensitivity=74.92%, avg_specificity=93.68% avg_auc=0.9293
Fold[5] Epoch: 82 [82/100 (82%)] Train loss=0.163485 Test loss=0.303227 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15014731884002686
[5/23] Train loss=0.22053179144859314
[10/23] Train loss=0.14021927118301392
[15/23] Train loss=0.12631045281887054
[20/23] Train loss=0.11007150262594223
Test set avg_accuracy=88.86% avg_sensitivity=74.54%, avg_specificity=93.71% avg_auc=0.9284
Fold[5] Epoch: 83 [83/100 (83%)] Train loss=0.160271 Test loss=0.302991 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14504322409629822
[5/23] Train loss=0.20911253988742828
[10/23] Train loss=0.13942639529705048
[15/23] Train loss=0.1278630644083023
[20/23] Train loss=0.10969596356153488
Test set avg_accuracy=88.58% avg_sensitivity=74.17%, avg_specificity=93.46% avg_auc=0.9266
Fold[5] Epoch: 84 [84/100 (84%)] Train loss=0.158917 Test loss=0.309582 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14529336988925934
[5/23] Train loss=0.2099204808473587
[10/23] Train loss=0.13898372650146484
[15/23] Train loss=0.12421184033155441
[20/23] Train loss=0.09838976711034775
Test set avg_accuracy=88.41% avg_sensitivity=74.17%, avg_specificity=93.23% avg_auc=0.9283
Fold[5] Epoch: 85 [85/100 (85%)] Train loss=0.156993 Test loss=0.307693 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15163090825080872
[5/23] Train loss=0.2060927003622055
[10/23] Train loss=0.14083100855350494
[15/23] Train loss=0.12377246469259262
[20/23] Train loss=0.10459775477647781
Test set avg_accuracy=88.55% avg_sensitivity=76.70%, avg_specificity=92.56% avg_auc=0.9270
Fold[5] Epoch: 86 [86/100 (86%)] Train loss=0.155222 Test loss=0.316323 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14708176255226135
[5/23] Train loss=0.20762217044830322
[10/23] Train loss=0.13550516963005066
[15/23] Train loss=0.12654942274093628
[20/23] Train loss=0.10891566425561905
Test set avg_accuracy=88.49% avg_sensitivity=76.37%, avg_specificity=92.59% avg_auc=0.9273
Fold[5] Epoch: 87 [87/100 (87%)] Train loss=0.152310 Test loss=0.312636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13966576755046844
[5/23] Train loss=0.19697733223438263
[10/23] Train loss=0.13564592599868774
[15/23] Train loss=0.12410362809896469
[20/23] Train loss=0.10411906242370605
Test set avg_accuracy=88.62% avg_sensitivity=76.28%, avg_specificity=92.80% avg_auc=0.9285
Fold[5] Epoch: 88 [88/100 (88%)] Train loss=0.151095 Test loss=0.312076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1411343365907669
[5/23] Train loss=0.19777150452136993
[10/23] Train loss=0.1341117024421692
[15/23] Train loss=0.11950387805700302
[20/23] Train loss=0.09948577731847763
Test set avg_accuracy=88.56% avg_sensitivity=75.66%, avg_specificity=92.93% avg_auc=0.9268
Fold[5] Epoch: 89 [89/100 (89%)] Train loss=0.147331 Test loss=0.314755 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14051508903503418
[5/23] Train loss=0.1913682520389557
[10/23] Train loss=0.12865251302719116
[15/23] Train loss=0.1175430491566658
[20/23] Train loss=0.0978999137878418
Test set avg_accuracy=88.91% avg_sensitivity=75.08%, avg_specificity=93.58% avg_auc=0.9292
Fold[5] Epoch: 90 [90/100 (90%)] Train loss=0.145122 Test loss=0.310472 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13214221596717834
[5/23] Train loss=0.19635207951068878
[10/23] Train loss=0.13375040888786316
[15/23] Train loss=0.12115392833948135
[20/23] Train loss=0.09564822912216187
Test set avg_accuracy=88.45% avg_sensitivity=75.33%, avg_specificity=92.88% avg_auc=0.9268
Fold[5] Epoch: 91 [91/100 (91%)] Train loss=0.145916 Test loss=0.315149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12657462060451508
[5/23] Train loss=0.18894171714782715
[10/23] Train loss=0.1327614039182663
[15/23] Train loss=0.11463824659585953
[20/23] Train loss=0.10126843303442001
Test set avg_accuracy=88.80% avg_sensitivity=76.74%, avg_specificity=92.88% avg_auc=0.9308
Fold[5] Epoch: 92 [92/100 (92%)] Train loss=0.143727 Test loss=0.310081 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13866263628005981
[5/23] Train loss=0.18622399866580963
[10/23] Train loss=0.12584459781646729
[15/23] Train loss=0.11437701433897018
[20/23] Train loss=0.09565369784832001
Test set avg_accuracy=88.69% avg_sensitivity=76.82%, avg_specificity=92.70% avg_auc=0.9294
Fold[5] Epoch: 93 [93/100 (93%)] Train loss=0.141558 Test loss=0.315796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13335606455802917
[5/23] Train loss=0.18950650095939636
[10/23] Train loss=0.12662403285503387
[15/23] Train loss=0.11258435994386673
[20/23] Train loss=0.09388647228479385
Test set avg_accuracy=88.68% avg_sensitivity=74.13%, avg_specificity=93.60% avg_auc=0.9262
Fold[5] Epoch: 94 [94/100 (94%)] Train loss=0.138416 Test loss=0.320344 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12411532551050186
[5/23] Train loss=0.18788683414459229
[10/23] Train loss=0.12468139082193375
[15/23] Train loss=0.10854125767946243
[20/23] Train loss=0.09504719078540802
Test set avg_accuracy=88.91% avg_sensitivity=76.08%, avg_specificity=93.25% avg_auc=0.9275
Fold[5] Epoch: 95 [95/100 (95%)] Train loss=0.136009 Test loss=0.321784 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13139067590236664
[5/23] Train loss=0.17651741206645966
[10/23] Train loss=0.13143840432167053
[15/23] Train loss=0.11123527586460114
[20/23] Train loss=0.0943160280585289
Test set avg_accuracy=88.79% avg_sensitivity=76.12%, avg_specificity=93.08% avg_auc=0.9267
Fold[5] Epoch: 96 [96/100 (96%)] Train loss=0.134897 Test loss=0.323438 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12559077143669128
[5/23] Train loss=0.1836000680923462
[10/23] Train loss=0.12200942635536194
[15/23] Train loss=0.11569596827030182
[20/23] Train loss=0.09197476506233215
Test set avg_accuracy=88.46% avg_sensitivity=74.25%, avg_specificity=93.26% avg_auc=0.9233
Fold[5] Epoch: 97 [97/100 (97%)] Train loss=0.132265 Test loss=0.326645 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12898460030555725
[5/23] Train loss=0.1757277250289917
[10/23] Train loss=0.11693934351205826
[15/23] Train loss=0.11133983731269836
[20/23] Train loss=0.09109067171812057
Test set avg_accuracy=88.33% avg_sensitivity=72.76%, avg_specificity=93.60% avg_auc=0.9250
Fold[5] Epoch: 98 [98/100 (98%)] Train loss=0.131495 Test loss=0.324927 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11998249590396881
[5/23] Train loss=0.1762721836566925
[10/23] Train loss=0.12314842641353607
[15/23] Train loss=0.10874643921852112
[20/23] Train loss=0.09252088516950607
Test set avg_accuracy=88.67% avg_sensitivity=74.75%, avg_specificity=93.37% avg_auc=0.9267
Fold[5] Epoch: 99 [99/100 (99%)] Train loss=0.130153 Test loss=0.324022 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12344446778297424
[5/23] Train loss=0.16829636693000793
[10/23] Train loss=0.11383083462715149
[15/23] Train loss=0.10613232851028442
[20/23] Train loss=0.0881255567073822
Test set avg_accuracy=88.69% avg_sensitivity=74.50%, avg_specificity=93.49% avg_auc=0.9262
Fold[5] Epoch: 100 [100/100 (100%)] Train loss=0.128112 Test loss=0.323093 Current lr=[3.9999999999999996e-05]

Fold[5] Best Result: acc=89.48194662480377 sen=76.65562913907284, spe=93.82266423868889, auc=0.9369666283700484!
[0/23] Train loss=0.6958164572715759
[5/23] Train loss=0.6532502174377441
[10/23] Train loss=0.5667195916175842
[15/23] Train loss=0.5161377191543579
[20/23] Train loss=0.4981219172477722
Test set avg_accuracy=76.88% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.7748
Best model saved!! Metric=-71.64222728986383!!
Fold[6] Epoch: 1 [1/100 (1%)] Train loss=0.562478 Test loss=0.516436 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5045832395553589
[5/23] Train loss=0.5351910591125488
[10/23] Train loss=0.4666885733604431
[15/23] Train loss=0.4285415709018707
[20/23] Train loss=0.3697519600391388
Test set avg_accuracy=81.65% avg_sensitivity=33.44%, avg_specificity=96.14% avg_auc=0.8686
Best model saved!! Metric=-27.906203066775603!!
Fold[6] Epoch: 2 [2/100 (2%)] Train loss=0.456174 Test loss=0.379140 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3760411739349365
[5/23] Train loss=0.4404512047767639
[10/23] Train loss=0.42376601696014404
[15/23] Train loss=0.3743290901184082
[20/23] Train loss=0.3227493464946747
Test set avg_accuracy=84.34% avg_sensitivity=49.41%, avg_specificity=94.84% avg_auc=0.8887
Best model saved!! Metric=-8.546278590219252!!
Fold[6] Epoch: 3 [3/100 (3%)] Train loss=0.393098 Test loss=0.354447 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3551895320415497
[5/23] Train loss=0.42311301827430725
[10/23] Train loss=0.4318983852863312
[15/23] Train loss=0.348268985748291
[20/23] Train loss=0.3144262433052063
Test set avg_accuracy=85.49% avg_sensitivity=50.91%, avg_specificity=95.88% avg_auc=0.9003
Best model saved!! Metric=-3.688721016050483!!
Fold[6] Epoch: 4 [4/100 (4%)] Train loss=0.379962 Test loss=0.340091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3414599895477295
[5/23] Train loss=0.4171815514564514
[10/23] Train loss=0.4149080812931061
[15/23] Train loss=0.3432667553424835
[20/23] Train loss=0.29530224204063416
Test set avg_accuracy=85.60% avg_sensitivity=50.91%, avg_specificity=96.03% avg_auc=0.9109
Best model saved!! Metric=-2.3567692583805275!!
Fold[6] Epoch: 5 [5/100 (5%)] Train loss=0.371371 Test loss=0.330407 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32675135135650635
[5/23] Train loss=0.4257129430770874
[10/23] Train loss=0.4079848825931549
[15/23] Train loss=0.33004382252693176
[20/23] Train loss=0.29582270979881287
Test set avg_accuracy=86.75% avg_sensitivity=55.38%, avg_specificity=96.19% avg_auc=0.9194
Best model saved!! Metric=4.263844850077192!!
Fold[6] Epoch: 6 [6/100 (6%)] Train loss=0.367775 Test loss=0.307252 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31450316309928894
[5/23] Train loss=0.44125819206237793
[10/23] Train loss=0.37464669346809387
[15/23] Train loss=0.32213258743286133
[20/23] Train loss=0.2889675498008728
Test set avg_accuracy=87.59% avg_sensitivity=60.95%, avg_specificity=95.61% avg_auc=0.9251
Best model saved!! Metric=10.664074457544725!!
Fold[6] Epoch: 7 [7/100 (7%)] Train loss=0.359158 Test loss=0.290588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2897452116012573
[5/23] Train loss=0.42632266879081726
[10/23] Train loss=0.34514498710632324
[15/23] Train loss=0.3100951015949249
[20/23] Train loss=0.2743079662322998
Test set avg_accuracy=88.81% avg_sensitivity=71.85%, avg_specificity=93.91% avg_auc=0.9299
Best model saved!! Metric=21.558033152765937!!
Fold[6] Epoch: 8 [8/100 (8%)] Train loss=0.343997 Test loss=0.277545 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2906128168106079
[5/23] Train loss=0.4186314046382904
[10/23] Train loss=0.34060415625572205
[15/23] Train loss=0.2759634554386139
[20/23] Train loss=0.2494703233242035
Test set avg_accuracy=89.21% avg_sensitivity=71.81%, avg_specificity=94.44% avg_auc=0.9350
Best model saved!! Metric=22.954658270851198!!
Fold[6] Epoch: 9 [9/100 (9%)] Train loss=0.329893 Test loss=0.269163 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2631892263889313
[5/23] Train loss=0.3945205807685852
[10/23] Train loss=0.3166963756084442
[15/23] Train loss=0.2619750201702118
[20/23] Train loss=0.24268381297588348
Test set avg_accuracy=89.66% avg_sensitivity=75.82%, avg_specificity=93.83% avg_auc=0.9396
Best model saved!! Metric=27.27189774894294!!
Fold[6] Epoch: 10 [10/100 (10%)] Train loss=0.318553 Test loss=0.260212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2565603256225586
[5/23] Train loss=0.3759646713733673
[10/23] Train loss=0.3121192157268524
[15/23] Train loss=0.25784924626350403
[20/23] Train loss=0.23673664033412933
Test set avg_accuracy=90.51% avg_sensitivity=78.10%, avg_specificity=94.24% avg_auc=0.9422
Best model saved!! Metric=31.070529238917043!!
Fold[6] Epoch: 11 [11/100 (11%)] Train loss=0.307757 Test loss=0.255219 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2567630410194397
[5/23] Train loss=0.3617781400680542
[10/23] Train loss=0.3096470534801483
[15/23] Train loss=0.245703786611557
[20/23] Train loss=0.22359861433506012
Test set avg_accuracy=90.40% avg_sensitivity=76.37%, avg_specificity=94.62% avg_auc=0.9431
Fold[6] Epoch: 12 [12/100 (12%)] Train loss=0.299464 Test loss=0.253217 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24684320390224457
[5/23] Train loss=0.36511921882629395
[10/23] Train loss=0.3057097792625427
[15/23] Train loss=0.2410949021577835
[20/23] Train loss=0.21797870099544525
Test set avg_accuracy=90.63% avg_sensitivity=76.23%, avg_specificity=94.96% avg_auc=0.9438
Fold[6] Epoch: 13 [13/100 (13%)] Train loss=0.295656 Test loss=0.251506 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25050652027130127
[5/23] Train loss=0.3634370267391205
[10/23] Train loss=0.3021021783351898
[15/23] Train loss=0.23862330615520477
[20/23] Train loss=0.2059578001499176
Test set avg_accuracy=90.27% avg_sensitivity=72.72%, avg_specificity=95.55% avg_auc=0.9442
Fold[6] Epoch: 14 [14/100 (14%)] Train loss=0.291138 Test loss=0.249792 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23484116792678833
[5/23] Train loss=0.3434807360172272
[10/23] Train loss=0.30787280201911926
[15/23] Train loss=0.23475678265094757
[20/23] Train loss=0.20889240503311157
Test set avg_accuracy=89.99% avg_sensitivity=71.08%, avg_specificity=95.68% avg_auc=0.9453
Fold[6] Epoch: 15 [15/100 (15%)] Train loss=0.285947 Test loss=0.247780 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24152928590774536
[5/23] Train loss=0.3513233959674835
[10/23] Train loss=0.29972293972969055
[15/23] Train loss=0.2334551215171814
[20/23] Train loss=0.19996850192546844
Test set avg_accuracy=89.93% avg_sensitivity=68.52%, avg_specificity=96.36% avg_auc=0.9455
Fold[6] Epoch: 16 [16/100 (16%)] Train loss=0.284296 Test loss=0.248988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23345062136650085
[5/23] Train loss=0.3498230278491974
[10/23] Train loss=0.30372753739356995
[15/23] Train loss=0.21751463413238525
[20/23] Train loss=0.1896865963935852
Test set avg_accuracy=90.25% avg_sensitivity=70.76%, avg_specificity=96.12% avg_auc=0.9461
Fold[6] Epoch: 17 [17/100 (17%)] Train loss=0.282170 Test loss=0.245703 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23246203362941742
[5/23] Train loss=0.34364354610443115
[10/23] Train loss=0.2885104715824127
[15/23] Train loss=0.21937690675258636
[20/23] Train loss=0.19559581577777863
Test set avg_accuracy=90.24% avg_sensitivity=70.99%, avg_specificity=96.03% avg_auc=0.9467
Fold[6] Epoch: 18 [18/100 (18%)] Train loss=0.278462 Test loss=0.245672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22302290797233582
[5/23] Train loss=0.3632262945175171
[10/23] Train loss=0.27938154339790344
[15/23] Train loss=0.22509180009365082
[20/23] Train loss=0.19983980059623718
Test set avg_accuracy=90.21% avg_sensitivity=71.35%, avg_specificity=95.88% avg_auc=0.9471
Fold[6] Epoch: 19 [19/100 (19%)] Train loss=0.277895 Test loss=0.243691 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22456462681293488
[5/23] Train loss=0.35113030672073364
[10/23] Train loss=0.2804596424102783
[15/23] Train loss=0.22261959314346313
[20/23] Train loss=0.1947302520275116
Test set avg_accuracy=90.08% avg_sensitivity=70.30%, avg_specificity=96.03% avg_auc=0.9465
Fold[6] Epoch: 20 [20/100 (20%)] Train loss=0.274868 Test loss=0.245889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2267930805683136
[5/23] Train loss=0.34790271520614624
[10/23] Train loss=0.2738374173641205
[15/23] Train loss=0.21330522000789642
[20/23] Train loss=0.19613467156887054
Test set avg_accuracy=90.85% avg_sensitivity=77.05%, avg_specificity=95.01% avg_auc=0.9471
Best model saved!! Metric=31.626144656590256!!
Fold[6] Epoch: 21 [21/100 (21%)] Train loss=0.271452 Test loss=0.245314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22186575829982758
[5/23] Train loss=0.33814188838005066
[10/23] Train loss=0.27226120233535767
[15/23] Train loss=0.2072650045156479
[20/23] Train loss=0.18977895379066467
Test set avg_accuracy=90.55% avg_sensitivity=74.45%, avg_specificity=95.39% avg_auc=0.9474
Fold[6] Epoch: 22 [22/100 (22%)] Train loss=0.268223 Test loss=0.243171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22520801424980164
[5/23] Train loss=0.3363715410232544
[10/23] Train loss=0.26519715785980225
[15/23] Train loss=0.2016385793685913
[20/23] Train loss=0.18498335778713226
Test set avg_accuracy=91.03% avg_sensitivity=77.83%, avg_specificity=95.01% avg_auc=0.9468
Best model saved!! Metric=32.55212238307761!!
Fold[6] Epoch: 23 [23/100 (23%)] Train loss=0.265165 Test loss=0.245575 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21168963611125946
[5/23] Train loss=0.32607588171958923
[10/23] Train loss=0.27885693311691284
[15/23] Train loss=0.200199693441391
[20/23] Train loss=0.17869259417057037
Test set avg_accuracy=90.63% avg_sensitivity=74.50%, avg_specificity=95.49% avg_auc=0.9471
Fold[6] Epoch: 24 [24/100 (24%)] Train loss=0.261895 Test loss=0.244255 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22322978079319
[5/23] Train loss=0.3266230821609497
[10/23] Train loss=0.26994895935058594
[15/23] Train loss=0.2131371647119522
[20/23] Train loss=0.17021292448043823
Test set avg_accuracy=91.01% avg_sensitivity=76.73%, avg_specificity=95.31% avg_auc=0.9471
Fold[6] Epoch: 25 [25/100 (25%)] Train loss=0.258712 Test loss=0.244435 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22068670392036438
[5/23] Train loss=0.3238806128501892
[10/23] Train loss=0.2591596841812134
[15/23] Train loss=0.20235560834407806
[20/23] Train loss=0.17507106065750122
Test set avg_accuracy=90.80% avg_sensitivity=75.41%, avg_specificity=95.43% avg_auc=0.9469
Fold[6] Epoch: 26 [26/100 (26%)] Train loss=0.256016 Test loss=0.245204 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20792819559574127
[5/23] Train loss=0.3221850097179413
[10/23] Train loss=0.2762279212474823
[15/23] Train loss=0.19493408501148224
[20/23] Train loss=0.17934934794902802
Test set avg_accuracy=90.83% avg_sensitivity=75.55%, avg_specificity=95.43% avg_auc=0.9466
Fold[6] Epoch: 27 [27/100 (27%)] Train loss=0.253168 Test loss=0.245893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20963238179683685
[5/23] Train loss=0.32599109411239624
[10/23] Train loss=0.2579496204853058
[15/23] Train loss=0.1951405107975006
[20/23] Train loss=0.1726864129304886
Test set avg_accuracy=90.78% avg_sensitivity=74.77%, avg_specificity=95.60% avg_auc=0.9470
Fold[6] Epoch: 28 [28/100 (28%)] Train loss=0.251448 Test loss=0.244468 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21009354293346405
[5/23] Train loss=0.3093215525150299
[10/23] Train loss=0.26673999428749084
[15/23] Train loss=0.20172341167926788
[20/23] Train loss=0.16997620463371277
Test set avg_accuracy=90.96% avg_sensitivity=74.54%, avg_specificity=95.90% avg_auc=0.9472
Fold[6] Epoch: 29 [29/100 (29%)] Train loss=0.251315 Test loss=0.244451 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20458845794200897
[5/23] Train loss=0.31988513469696045
[10/23] Train loss=0.26747453212738037
[15/23] Train loss=0.1867479532957077
[20/23] Train loss=0.16918569803237915
Test set avg_accuracy=90.79% avg_sensitivity=75.82%, avg_specificity=95.29% avg_auc=0.9472
Fold[6] Epoch: 30 [30/100 (30%)] Train loss=0.249066 Test loss=0.245518 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2041110396385193
[5/23] Train loss=0.31501129269599915
[10/23] Train loss=0.2598456144332886
[15/23] Train loss=0.19439946115016937
[20/23] Train loss=0.17736363410949707
Test set avg_accuracy=90.79% avg_sensitivity=76.19%, avg_specificity=95.18% avg_auc=0.9475
Fold[6] Epoch: 31 [31/100 (31%)] Train loss=0.247154 Test loss=0.246457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20460470020771027
[5/23] Train loss=0.302639901638031
[10/23] Train loss=0.25259917974472046
[15/23] Train loss=0.19015543162822723
[20/23] Train loss=0.16706052422523499
Test set avg_accuracy=90.63% avg_sensitivity=75.59%, avg_specificity=95.16% avg_auc=0.9466
Fold[6] Epoch: 32 [32/100 (32%)] Train loss=0.242597 Test loss=0.248548 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2079346477985382
[5/23] Train loss=0.30408164858818054
[10/23] Train loss=0.25553107261657715
[15/23] Train loss=0.1828022003173828
[20/23] Train loss=0.16594365239143372
Test set avg_accuracy=90.68% avg_sensitivity=76.09%, avg_specificity=95.06% avg_auc=0.9467
Fold[6] Epoch: 33 [33/100 (33%)] Train loss=0.241739 Test loss=0.248141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21225810050964355
[5/23] Train loss=0.3046250641345978
[10/23] Train loss=0.2530231177806854
[15/23] Train loss=0.18518918752670288
[20/23] Train loss=0.1621134728193283
Test set avg_accuracy=90.78% avg_sensitivity=75.23%, avg_specificity=95.46% avg_auc=0.9472
Fold[6] Epoch: 34 [34/100 (34%)] Train loss=0.241986 Test loss=0.246946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1997423619031906
[5/23] Train loss=0.3021922707557678
[10/23] Train loss=0.24580441415309906
[15/23] Train loss=0.17776602506637573
[20/23] Train loss=0.16158679127693176
Test set avg_accuracy=91.04% avg_sensitivity=76.46%, avg_specificity=95.43% avg_auc=0.9475
Fold[6] Epoch: 35 [35/100 (35%)] Train loss=0.238595 Test loss=0.247597 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1952115297317505
[5/23] Train loss=0.2986345589160919
[10/23] Train loss=0.2503010034561157
[15/23] Train loss=0.17566533386707306
[20/23] Train loss=0.16159938275814056
Test set avg_accuracy=91.01% avg_sensitivity=75.82%, avg_specificity=95.58% avg_auc=0.9476
Fold[6] Epoch: 36 [36/100 (36%)] Train loss=0.234294 Test loss=0.246653 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19506268203258514
[5/23] Train loss=0.29039040207862854
[10/23] Train loss=0.24499954283237457
[15/23] Train loss=0.17317511141300201
[20/23] Train loss=0.16346579790115356
Test set avg_accuracy=91.16% avg_sensitivity=75.64%, avg_specificity=95.83% avg_auc=0.9463
Fold[6] Epoch: 37 [37/100 (37%)] Train loss=0.233236 Test loss=0.248992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.199310302734375
[5/23] Train loss=0.29122596979141235
[10/23] Train loss=0.242206409573555
[15/23] Train loss=0.17223310470581055
[20/23] Train loss=0.15453693270683289
Test set avg_accuracy=90.95% avg_sensitivity=76.28%, avg_specificity=95.36% avg_auc=0.9469
Fold[6] Epoch: 38 [38/100 (38%)] Train loss=0.231592 Test loss=0.249721 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2038809359073639
[5/23] Train loss=0.2920125126838684
[10/23] Train loss=0.250362753868103
[15/23] Train loss=0.17634007334709167
[20/23] Train loss=0.15285763144493103
Test set avg_accuracy=90.84% avg_sensitivity=75.87%, avg_specificity=95.35% avg_auc=0.9465
Fold[6] Epoch: 39 [39/100 (39%)] Train loss=0.232617 Test loss=0.250187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19217848777770996
[5/23] Train loss=0.29097381234169006
[10/23] Train loss=0.2520813047885895
[15/23] Train loss=0.16943827271461487
[20/23] Train loss=0.16201864182949066
Test set avg_accuracy=90.83% avg_sensitivity=76.60%, avg_specificity=95.12% avg_auc=0.9449
Fold[6] Epoch: 40 [40/100 (40%)] Train loss=0.230943 Test loss=0.254020 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19627486169338226
[5/23] Train loss=0.2901930809020996
[10/23] Train loss=0.24681057035923004
[15/23] Train loss=0.16847720742225647
[20/23] Train loss=0.14875316619873047
Test set avg_accuracy=91.15% avg_sensitivity=77.55%, avg_specificity=95.24% avg_auc=0.9469
Best model saved!! Metric=32.63430074061778!!
Fold[6] Epoch: 41 [41/100 (41%)] Train loss=0.225661 Test loss=0.251529 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19183245301246643
[5/23] Train loss=0.28620031476020813
[10/23] Train loss=0.24332907795906067
[15/23] Train loss=0.17118260264396667
[20/23] Train loss=0.1504450887441635
Test set avg_accuracy=90.80% avg_sensitivity=75.50%, avg_specificity=95.40% avg_auc=0.9463
Fold[6] Epoch: 42 [42/100 (42%)] Train loss=0.225080 Test loss=0.250049 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1872549057006836
[5/23] Train loss=0.2912522256374359
[10/23] Train loss=0.24101519584655762
[15/23] Train loss=0.16905714571475983
[20/23] Train loss=0.15241751074790955
Test set avg_accuracy=91.14% avg_sensitivity=77.46%, avg_specificity=95.25% avg_auc=0.9473
Fold[6] Epoch: 43 [43/100 (43%)] Train loss=0.222129 Test loss=0.250856 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18868373334407806
[5/23] Train loss=0.2858818769454956
[10/23] Train loss=0.2393280267715454
[15/23] Train loss=0.16449764370918274
[20/23] Train loss=0.14405590295791626
Test set avg_accuracy=91.03% avg_sensitivity=76.78%, avg_specificity=95.32% avg_auc=0.9457
Fold[6] Epoch: 44 [44/100 (44%)] Train loss=0.220707 Test loss=0.253325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18909503519535065
[5/23] Train loss=0.28021004796028137
[10/23] Train loss=0.24006043374538422
[15/23] Train loss=0.15320754051208496
[20/23] Train loss=0.1405842900276184
Test set avg_accuracy=91.27% avg_sensitivity=78.24%, avg_specificity=95.18% avg_auc=0.9469
Best model saved!! Metric=33.382635769057806!!
Fold[6] Epoch: 45 [45/100 (45%)] Train loss=0.217669 Test loss=0.252078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18599456548690796
[5/23] Train loss=0.28630250692367554
[10/23] Train loss=0.2232140600681305
[15/23] Train loss=0.1579061597585678
[20/23] Train loss=0.15085449814796448
Test set avg_accuracy=91.03% avg_sensitivity=77.69%, avg_specificity=95.05% avg_auc=0.9456
Fold[6] Epoch: 46 [46/100 (46%)] Train loss=0.215563 Test loss=0.255871 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18084129691123962
[5/23] Train loss=0.2657911777496338
[10/23] Train loss=0.22585001587867737
[15/23] Train loss=0.15682530403137207
[20/23] Train loss=0.1476675122976303
Test set avg_accuracy=91.00% avg_sensitivity=76.19%, avg_specificity=95.46% avg_auc=0.9454
Fold[6] Epoch: 47 [47/100 (47%)] Train loss=0.215025 Test loss=0.255059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1861184537410736
[5/23] Train loss=0.27385568618774414
[10/23] Train loss=0.22650909423828125
[15/23] Train loss=0.15683728456497192
[20/23] Train loss=0.14552968740463257
Test set avg_accuracy=90.92% avg_sensitivity=77.01%, avg_specificity=95.10% avg_auc=0.9454
Fold[6] Epoch: 48 [48/100 (48%)] Train loss=0.216118 Test loss=0.255890 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1888481229543686
[5/23] Train loss=0.28294286131858826
[10/23] Train loss=0.22475647926330566
[15/23] Train loss=0.16636931896209717
[20/23] Train loss=0.13982520997524261
Test set avg_accuracy=90.95% avg_sensitivity=76.60%, avg_specificity=95.27% avg_auc=0.9446
Fold[6] Epoch: 49 [49/100 (49%)] Train loss=0.211952 Test loss=0.257426 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1881898045539856
[5/23] Train loss=0.2729634940624237
[10/23] Train loss=0.2198917418718338
[15/23] Train loss=0.15723982453346252
[20/23] Train loss=0.1448841691017151
Test set avg_accuracy=91.11% avg_sensitivity=75.91%, avg_specificity=95.68% avg_auc=0.9462
Fold[6] Epoch: 50 [50/100 (50%)] Train loss=0.211212 Test loss=0.254407 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18386688828468323
[5/23] Train loss=0.272985577583313
[10/23] Train loss=0.20956028997898102
[15/23] Train loss=0.16427376866340637
[20/23] Train loss=0.13834677636623383
Test set avg_accuracy=91.08% avg_sensitivity=76.60%, avg_specificity=95.43% avg_auc=0.9453
Fold[6] Epoch: 51 [51/100 (51%)] Train loss=0.209133 Test loss=0.257180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1905232071876526
[5/23] Train loss=0.2852666676044464
[10/23] Train loss=0.22524866461753845
[15/23] Train loss=0.1552605926990509
[20/23] Train loss=0.13284021615982056
Test set avg_accuracy=91.18% avg_sensitivity=77.74%, avg_specificity=95.23% avg_auc=0.9471
Fold[6] Epoch: 52 [52/100 (52%)] Train loss=0.207789 Test loss=0.254774 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17846563458442688
[5/23] Train loss=0.26508140563964844
[10/23] Train loss=0.22179560363292694
[15/23] Train loss=0.1567913293838501
[20/23] Train loss=0.13877809047698975
Test set avg_accuracy=91.26% avg_sensitivity=77.74%, avg_specificity=95.32% avg_auc=0.9464
Fold[6] Epoch: 53 [53/100 (53%)] Train loss=0.204929 Test loss=0.256382 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1759999692440033
[5/23] Train loss=0.2661585509777069
[10/23] Train loss=0.21465541422367096
[15/23] Train loss=0.1519162952899933
[20/23] Train loss=0.13230490684509277
Test set avg_accuracy=91.14% avg_sensitivity=77.10%, avg_specificity=95.36% avg_auc=0.9461
Fold[6] Epoch: 54 [54/100 (54%)] Train loss=0.201297 Test loss=0.257918 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1843871921300888
[5/23] Train loss=0.26226121187210083
[10/23] Train loss=0.2124096304178238
[15/23] Train loss=0.15299871563911438
[20/23] Train loss=0.1303001046180725
Test set avg_accuracy=91.16% avg_sensitivity=76.28%, avg_specificity=95.64% avg_auc=0.9464
Fold[6] Epoch: 55 [55/100 (55%)] Train loss=0.201096 Test loss=0.255902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17585140466690063
[5/23] Train loss=0.26233720779418945
[10/23] Train loss=0.21584142744541168
[15/23] Train loss=0.14792324602603912
[20/23] Train loss=0.13474911451339722
Test set avg_accuracy=91.21% avg_sensitivity=77.42%, avg_specificity=95.36% avg_auc=0.9466
Fold[6] Epoch: 56 [56/100 (56%)] Train loss=0.199344 Test loss=0.257082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17081408202648163
[5/23] Train loss=0.254958838224411
[10/23] Train loss=0.2057940661907196
[15/23] Train loss=0.14467231929302216
[20/23] Train loss=0.13769493997097015
Test set avg_accuracy=91.09% avg_sensitivity=77.78%, avg_specificity=95.09% avg_auc=0.9468
Fold[6] Epoch: 57 [57/100 (57%)] Train loss=0.197118 Test loss=0.259373 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17541494965553284
[5/23] Train loss=0.2657560408115387
[10/23] Train loss=0.20073284208774567
[15/23] Train loss=0.14253711700439453
[20/23] Train loss=0.12746255099773407
Test set avg_accuracy=91.03% avg_sensitivity=77.83%, avg_specificity=95.01% avg_auc=0.9472
Fold[6] Epoch: 58 [58/100 (58%)] Train loss=0.195703 Test loss=0.259487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17425741255283356
[5/23] Train loss=0.25752633810043335
[10/23] Train loss=0.19693602621555328
[15/23] Train loss=0.14785850048065186
[20/23] Train loss=0.13155433535575867
Test set avg_accuracy=91.24% avg_sensitivity=78.83%, avg_specificity=94.98% avg_auc=0.9468
Best model saved!! Metric=33.73853643210772!!
Fold[6] Epoch: 59 [59/100 (59%)] Train loss=0.193737 Test loss=0.261138 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1703430861234665
[5/23] Train loss=0.24266120791435242
[10/23] Train loss=0.20430442690849304
[15/23] Train loss=0.14508436620235443
[20/23] Train loss=0.12574176490306854
Test set avg_accuracy=91.13% avg_sensitivity=77.37%, avg_specificity=95.27% avg_auc=0.9458
Fold[6] Epoch: 60 [60/100 (60%)] Train loss=0.190568 Test loss=0.262146 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16038963198661804
[5/23] Train loss=0.24909847974777222
[10/23] Train loss=0.20032116770744324
[15/23] Train loss=0.13725776970386505
[20/23] Train loss=0.12951378524303436
Test set avg_accuracy=90.75% avg_sensitivity=76.92%, avg_specificity=94.91% avg_auc=0.9455
Fold[6] Epoch: 61 [61/100 (61%)] Train loss=0.188382 Test loss=0.265253 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1647450178861618
[5/23] Train loss=0.25050824880599976
[10/23] Train loss=0.1979285180568695
[15/23] Train loss=0.13518883287906647
[20/23] Train loss=0.1297740787267685
Test set avg_accuracy=91.07% avg_sensitivity=78.38%, avg_specificity=94.88% avg_auc=0.9453
Fold[6] Epoch: 62 [62/100 (62%)] Train loss=0.187839 Test loss=0.268214 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17210957407951355
[5/23] Train loss=0.2430821806192398
[10/23] Train loss=0.2021862417459488
[15/23] Train loss=0.13968676328659058
[20/23] Train loss=0.1270637959241867
Test set avg_accuracy=90.97% avg_sensitivity=78.10%, avg_specificity=94.84% avg_auc=0.9455
Fold[6] Epoch: 63 [63/100 (63%)] Train loss=0.186838 Test loss=0.267889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16409750282764435
[5/23] Train loss=0.2434360682964325
[10/23] Train loss=0.20258544385433197
[15/23] Train loss=0.14011693000793457
[20/23] Train loss=0.1202624961733818
Test set avg_accuracy=91.05% avg_sensitivity=77.83%, avg_specificity=95.03% avg_auc=0.9451
Fold[6] Epoch: 64 [64/100 (64%)] Train loss=0.185432 Test loss=0.269988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1584601104259491
[5/23] Train loss=0.23408885300159454
[10/23] Train loss=0.19415082037448883
[15/23] Train loss=0.12879277765750885
[20/23] Train loss=0.12875902652740479
Test set avg_accuracy=90.71% avg_sensitivity=77.55%, avg_specificity=94.66% avg_auc=0.9449
Fold[6] Epoch: 65 [65/100 (65%)] Train loss=0.181347 Test loss=0.270233 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16680878400802612
[5/23] Train loss=0.2320089340209961
[10/23] Train loss=0.18136608600616455
[15/23] Train loss=0.14373679459095
[20/23] Train loss=0.1226322203874588
Test set avg_accuracy=90.93% avg_sensitivity=78.19%, avg_specificity=94.76% avg_auc=0.9463
Fold[6] Epoch: 66 [66/100 (66%)] Train loss=0.178678 Test loss=0.269888 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16052749752998352
[5/23] Train loss=0.23625558614730835
[10/23] Train loss=0.18183612823486328
[15/23] Train loss=0.13388210535049438
[20/23] Train loss=0.11948457360267639
Test set avg_accuracy=90.92% avg_sensitivity=80.38%, avg_specificity=94.09% avg_auc=0.9449
Best model saved!! Metric=33.87898521012643!!
Fold[6] Epoch: 67 [67/100 (67%)] Train loss=0.178916 Test loss=0.276241 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15598733723163605
[5/23] Train loss=0.23279675841331482
[10/23] Train loss=0.18121959269046783
[15/23] Train loss=0.13446158170700073
[20/23] Train loss=0.12664496898651123
Test set avg_accuracy=90.90% avg_sensitivity=77.87%, avg_specificity=94.81% avg_auc=0.9442
Fold[6] Epoch: 68 [68/100 (68%)] Train loss=0.175847 Test loss=0.276207 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15959210693836212
[5/23] Train loss=0.23901614546775818
[10/23] Train loss=0.1823534220457077
[15/23] Train loss=0.1275453269481659
[20/23] Train loss=0.1150597408413887
Test set avg_accuracy=90.44% avg_sensitivity=79.11%, avg_specificity=93.85% avg_auc=0.9444
Fold[6] Epoch: 69 [69/100 (69%)] Train loss=0.175928 Test loss=0.279401 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15828044712543488
[5/23] Train loss=0.22530966997146606
[10/23] Train loss=0.17852827906608582
[15/23] Train loss=0.13253414630889893
[20/23] Train loss=0.11658874899148941
Test set avg_accuracy=90.58% avg_sensitivity=80.43%, avg_specificity=93.63% avg_auc=0.9445
Fold[6] Epoch: 70 [70/100 (70%)] Train loss=0.171323 Test loss=0.283754 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16004708409309387
[5/23] Train loss=0.22350747883319855
[10/23] Train loss=0.16986116766929626
[15/23] Train loss=0.13109572231769562
[20/23] Train loss=0.11966017633676529
Test set avg_accuracy=90.51% avg_sensitivity=80.61%, avg_specificity=93.48% avg_auc=0.9441
Fold[6] Epoch: 71 [71/100 (71%)] Train loss=0.171735 Test loss=0.285427 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1472369134426117
[5/23] Train loss=0.221770778298378
[10/23] Train loss=0.18210791051387787
[15/23] Train loss=0.13216818869113922
[20/23] Train loss=0.11437177658081055
Test set avg_accuracy=90.49% avg_sensitivity=81.39%, avg_specificity=93.22% avg_auc=0.9428
Fold[6] Epoch: 72 [72/100 (72%)] Train loss=0.171750 Test loss=0.289802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15533298254013062
[5/23] Train loss=0.21246632933616638
[10/23] Train loss=0.17908361554145813
[15/23] Train loss=0.12943801283836365
[20/23] Train loss=0.11305287480354309
Test set avg_accuracy=90.16% avg_sensitivity=81.25%, avg_specificity=92.84% avg_auc=0.9438
Fold[6] Epoch: 73 [73/100 (73%)] Train loss=0.166668 Test loss=0.293088 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1461115926504135
[5/23] Train loss=0.2167477011680603
[10/23] Train loss=0.16741521656513214
[15/23] Train loss=0.1290167272090912
[20/23] Train loss=0.11149484664201736
Test set avg_accuracy=90.15% avg_sensitivity=82.25%, avg_specificity=92.52% avg_auc=0.9432
Fold[6] Epoch: 74 [74/100 (74%)] Train loss=0.165486 Test loss=0.299482 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14881806075572968
[5/23] Train loss=0.20922288298606873
[10/23] Train loss=0.16302955150604248
[15/23] Train loss=0.13156233727931976
[20/23] Train loss=0.11533218622207642
Test set avg_accuracy=90.25% avg_sensitivity=81.34%, avg_specificity=92.93% avg_auc=0.9439
Fold[6] Epoch: 75 [75/100 (75%)] Train loss=0.163339 Test loss=0.291640 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15324151515960693
[5/23] Train loss=0.21054621040821075
[10/23] Train loss=0.1687985509634018
[15/23] Train loss=0.12009628117084503
[20/23] Train loss=0.10319680720567703
Test set avg_accuracy=90.19% avg_sensitivity=82.57%, avg_specificity=92.48% avg_auc=0.9437
Fold[6] Epoch: 76 [76/100 (76%)] Train loss=0.159484 Test loss=0.301940 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1461760550737381
[5/23] Train loss=0.21191532909870148
[10/23] Train loss=0.16571106016635895
[15/23] Train loss=0.1294965147972107
[20/23] Train loss=0.10967491567134857
Test set avg_accuracy=90.25% avg_sensitivity=80.16%, avg_specificity=93.29% avg_auc=0.9425
Fold[6] Epoch: 77 [77/100 (77%)] Train loss=0.161136 Test loss=0.295611 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1447782963514328
[5/23] Train loss=0.2065144032239914
[10/23] Train loss=0.16523434221744537
[15/23] Train loss=0.11684570461511612
[20/23] Train loss=0.10265564173460007
Test set avg_accuracy=90.32% avg_sensitivity=79.93%, avg_specificity=93.44% avg_auc=0.9423
Fold[6] Epoch: 78 [78/100 (78%)] Train loss=0.157872 Test loss=0.294853 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1407848447561264
[5/23] Train loss=0.19246995449066162
[10/23] Train loss=0.1586088240146637
[15/23] Train loss=0.11811911314725876
[20/23] Train loss=0.10708146542310715
Test set avg_accuracy=90.53% avg_sensitivity=79.88%, avg_specificity=93.73% avg_auc=0.9422
Fold[6] Epoch: 79 [79/100 (79%)] Train loss=0.154732 Test loss=0.296774 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1430155634880066
[5/23] Train loss=0.19748535752296448
[10/23] Train loss=0.16091054677963257
[15/23] Train loss=0.12206199765205383
[20/23] Train loss=0.1082289069890976
Test set avg_accuracy=90.62% avg_sensitivity=78.51%, avg_specificity=94.26% avg_auc=0.9410
Fold[6] Epoch: 80 [80/100 (80%)] Train loss=0.152606 Test loss=0.293855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13959500193595886
[5/23] Train loss=0.19324210286140442
[10/23] Train loss=0.15837205946445465
[15/23] Train loss=0.12332744896411896
[20/23] Train loss=0.10137176513671875
Test set avg_accuracy=90.71% avg_sensitivity=77.60%, avg_specificity=94.65% avg_auc=0.9413
Fold[6] Epoch: 81 [81/100 (81%)] Train loss=0.151972 Test loss=0.289883 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13298654556274414
[5/23] Train loss=0.19489306211471558
[10/23] Train loss=0.15422077476978302
[15/23] Train loss=0.11340740323066711
[20/23] Train loss=0.10056185722351074
Test set avg_accuracy=90.68% avg_sensitivity=76.96%, avg_specificity=94.80% avg_auc=0.9427
Fold[6] Epoch: 82 [82/100 (82%)] Train loss=0.145818 Test loss=0.292155 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13160648941993713
[5/23] Train loss=0.19157008826732635
[10/23] Train loss=0.16582432389259338
[15/23] Train loss=0.10854726284742355
[20/23] Train loss=0.09697645902633667
Test set avg_accuracy=90.74% avg_sensitivity=75.23%, avg_specificity=95.40% avg_auc=0.9438
Fold[6] Epoch: 83 [83/100 (83%)] Train loss=0.144862 Test loss=0.284223 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13359525799751282
[5/23] Train loss=0.19216808676719666
[10/23] Train loss=0.1610771268606186
[15/23] Train loss=0.10552985221147537
[20/23] Train loss=0.10421914607286453
Test set avg_accuracy=90.37% avg_sensitivity=73.49%, avg_specificity=95.44% avg_auc=0.9405
Fold[6] Epoch: 84 [84/100 (84%)] Train loss=0.141870 Test loss=0.292002 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13444150984287262
[5/23] Train loss=0.18820422887802124
[10/23] Train loss=0.15669408440589905
[15/23] Train loss=0.10716226696968079
[20/23] Train loss=0.09957894682884216
Test set avg_accuracy=90.47% avg_sensitivity=72.99%, avg_specificity=95.73% avg_auc=0.9410
Fold[6] Epoch: 85 [85/100 (85%)] Train loss=0.140577 Test loss=0.293286 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1364886313676834
[5/23] Train loss=0.17723651230335236
[10/23] Train loss=0.1544777899980545
[15/23] Train loss=0.10755976289510727
[20/23] Train loss=0.09844540804624557
Test set avg_accuracy=90.26% avg_sensitivity=70.99%, avg_specificity=96.06% avg_auc=0.9402
Fold[6] Epoch: 86 [86/100 (86%)] Train loss=0.138870 Test loss=0.297353 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12480444461107254
[5/23] Train loss=0.17822842299938202
[10/23] Train loss=0.13932693004608154
[15/23] Train loss=0.11129774153232574
[20/23] Train loss=0.09125420451164246
Test set avg_accuracy=90.56% avg_sensitivity=72.03%, avg_specificity=96.13% avg_auc=0.9408
Fold[6] Epoch: 87 [87/100 (87%)] Train loss=0.136691 Test loss=0.297182 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.131109818816185
[5/23] Train loss=0.17987386882305145
[10/23] Train loss=0.14797532558441162
[15/23] Train loss=0.10985356569290161
[20/23] Train loss=0.09455706924200058
Test set avg_accuracy=90.23% avg_sensitivity=70.76%, avg_specificity=96.09% avg_auc=0.9409
Fold[6] Epoch: 88 [88/100 (88%)] Train loss=0.136776 Test loss=0.296491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13521020114421844
[5/23] Train loss=0.2019554078578949
[10/23] Train loss=0.1437796801328659
[15/23] Train loss=0.10508318990468979
[20/23] Train loss=0.09177964180707932
Test set avg_accuracy=90.37% avg_sensitivity=71.81%, avg_specificity=95.95% avg_auc=0.9419
Fold[6] Epoch: 89 [89/100 (89%)] Train loss=0.135346 Test loss=0.296412 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12963637709617615
[5/23] Train loss=0.18338657915592194
[10/23] Train loss=0.14069175720214844
[15/23] Train loss=0.10444840043783188
[20/23] Train loss=0.08601520210504532
Test set avg_accuracy=90.19% avg_sensitivity=71.85%, avg_specificity=95.71% avg_auc=0.9424
Fold[6] Epoch: 90 [90/100 (90%)] Train loss=0.131752 Test loss=0.300723 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11772233992815018
[5/23] Train loss=0.1816156953573227
[10/23] Train loss=0.13423791527748108
[15/23] Train loss=0.10319247096776962
[20/23] Train loss=0.08530064672231674
Test set avg_accuracy=90.32% avg_sensitivity=72.35%, avg_specificity=95.72% avg_auc=0.9434
Fold[6] Epoch: 91 [91/100 (91%)] Train loss=0.131410 Test loss=0.298472 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11848344653844833
[5/23] Train loss=0.17984610795974731
[10/23] Train loss=0.14625979959964752
[15/23] Train loss=0.0968434289097786
[20/23] Train loss=0.0952715128660202
Test set avg_accuracy=90.74% avg_sensitivity=75.59%, avg_specificity=95.29% avg_auc=0.9418
Fold[6] Epoch: 92 [92/100 (92%)] Train loss=0.130754 Test loss=0.299765 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11549587547779083
[5/23] Train loss=0.17902539670467377
[10/23] Train loss=0.12856721878051758
[15/23] Train loss=0.09631139039993286
[20/23] Train loss=0.08944037556648254
Test set avg_accuracy=90.28% avg_sensitivity=76.00%, avg_specificity=94.58% avg_auc=0.9406
Fold[6] Epoch: 93 [93/100 (93%)] Train loss=0.126229 Test loss=0.304520 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11900819838047028
[5/23] Train loss=0.16378411650657654
[10/23] Train loss=0.12331093847751617
[15/23] Train loss=0.10098394751548767
[20/23] Train loss=0.09309535473585129
Test set avg_accuracy=90.32% avg_sensitivity=77.28%, avg_specificity=94.24% avg_auc=0.9401
Fold[6] Epoch: 94 [94/100 (94%)] Train loss=0.123488 Test loss=0.309303 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12059216946363449
[5/23] Train loss=0.16413408517837524
[10/23] Train loss=0.12558674812316895
[15/23] Train loss=0.10525521636009216
[20/23] Train loss=0.07855382561683655
Test set avg_accuracy=90.07% avg_sensitivity=76.64%, avg_specificity=94.11% avg_auc=0.9390
Fold[6] Epoch: 95 [95/100 (95%)] Train loss=0.122703 Test loss=0.312055 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10998060554265976
[5/23] Train loss=0.16364693641662598
[10/23] Train loss=0.12110807746648788
[15/23] Train loss=0.1008123978972435
[20/23] Train loss=0.08546684682369232
Test set avg_accuracy=89.86% avg_sensitivity=77.60%, avg_specificity=93.55% avg_auc=0.9412
Fold[6] Epoch: 96 [96/100 (96%)] Train loss=0.119762 Test loss=0.313534 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11290188133716583
[5/23] Train loss=0.15897919237613678
[10/23] Train loss=0.12299487739801407
[15/23] Train loss=0.09556812793016434
[20/23] Train loss=0.0813811868429184
Test set avg_accuracy=90.16% avg_sensitivity=77.55%, avg_specificity=93.95% avg_auc=0.9395
Fold[6] Epoch: 97 [97/100 (97%)] Train loss=0.116931 Test loss=0.318437 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11299251019954681
[5/23] Train loss=0.1479828655719757
[10/23] Train loss=0.11941200494766235
[15/23] Train loss=0.09037938714027405
[20/23] Train loss=0.0771297961473465
Test set avg_accuracy=90.11% avg_sensitivity=78.60%, avg_specificity=93.56% avg_auc=0.9403
Fold[6] Epoch: 98 [98/100 (98%)] Train loss=0.114099 Test loss=0.321858 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11278045177459717
[5/23] Train loss=0.14481891691684723
[10/23] Train loss=0.1193370372056961
[15/23] Train loss=0.09194985032081604
[20/23] Train loss=0.08313538879156113
Test set avg_accuracy=90.02% avg_sensitivity=79.38%, avg_specificity=93.22% avg_auc=0.9407
Fold[6] Epoch: 99 [99/100 (99%)] Train loss=0.114807 Test loss=0.327132 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1067376658320427
[5/23] Train loss=0.1539713591337204
[10/23] Train loss=0.11384948343038559
[15/23] Train loss=0.09268490970134735
[20/23] Train loss=0.07863231003284454
Test set avg_accuracy=89.83% avg_sensitivity=79.24%, avg_specificity=93.02% avg_auc=0.9383
Fold[6] Epoch: 100 [100/100 (100%)] Train loss=0.112353 Test loss=0.334892 Current lr=[3.9999999999999996e-05]

Fold[6] Best Result: acc=90.91772151898734 sen=80.38321167883211, spe=94.08616904500549, auc=0.944918829673015!
[0/23] Train loss=0.7023059725761414
[5/23] Train loss=0.6887195110321045
[10/23] Train loss=0.5596028566360474
[15/23] Train loss=0.5220019817352295
[20/23] Train loss=0.5161948204040527
Test set avg_accuracy=75.58% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6950
Best model saved!! Metric=-80.91932117220003!!
Fold[7] Epoch: 1 [1/100 (1%)] Train loss=0.573584 Test loss=0.579433 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5320590138435364
[5/23] Train loss=0.5853852033615112
[10/23] Train loss=0.4973730146884918
[15/23] Train loss=0.4391249418258667
[20/23] Train loss=0.4224590063095093
Test set avg_accuracy=76.47% avg_sensitivity=6.27%, avg_specificity=99.15% avg_auc=0.8037
Best model saved!! Metric=-63.74054801298959!!
Fold[7] Epoch: 2 [2/100 (2%)] Train loss=0.494889 Test loss=0.477779 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4296116232872009
[5/23] Train loss=0.49032890796661377
[10/23] Train loss=0.4525746703147888
[15/23] Train loss=0.37142977118492126
[20/23] Train loss=0.3531286418437958
Test set avg_accuracy=80.67% avg_sensitivity=36.95%, avg_specificity=94.79% avg_auc=0.8550
Best model saved!! Metric=-28.098308817903494!!
Fold[7] Epoch: 3 [3/100 (3%)] Train loss=0.426830 Test loss=0.419496 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37097957730293274
[5/23] Train loss=0.4322417676448822
[10/23] Train loss=0.4252835810184479
[15/23] Train loss=0.33995509147644043
[20/23] Train loss=0.3234228789806366
Test set avg_accuracy=82.27% avg_sensitivity=45.22%, avg_specificity=94.24% avg_auc=0.8758
Best model saved!! Metric=-16.688881540740503!!
Fold[7] Epoch: 4 [4/100 (4%)] Train loss=0.391096 Test loss=0.403182 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34228357672691345
[5/23] Train loss=0.4025656282901764
[10/23] Train loss=0.42752841114997864
[15/23] Train loss=0.3315421938896179
[20/23] Train loss=0.30437415838241577
Test set avg_accuracy=83.88% avg_sensitivity=50.34%, avg_specificity=94.71% avg_auc=0.8884
Best model saved!! Metric=-8.240423248642523!!
Fold[7] Epoch: 5 [5/100 (5%)] Train loss=0.375943 Test loss=0.385678 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33335599303245544
[5/23] Train loss=0.39637959003448486
[10/23] Train loss=0.421436607837677
[15/23] Train loss=0.31428709626197815
[20/23] Train loss=0.3011910617351532
Test set avg_accuracy=84.36% avg_sensitivity=47.95%, avg_specificity=96.13% avg_auc=0.8949
Best model saved!! Metric=-8.068580370660262!!
Fold[7] Epoch: 6 [6/100 (6%)] Train loss=0.366252 Test loss=0.382934 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3108943700790405
[5/23] Train loss=0.402120977640152
[10/23] Train loss=0.42022547125816345
[15/23] Train loss=0.315448522567749
[20/23] Train loss=0.29616817831993103
Test set avg_accuracy=84.83% avg_sensitivity=45.18%, avg_specificity=97.64% avg_auc=0.9028
Best model saved!! Metric=-8.067534984189423!!
Fold[7] Epoch: 7 [7/100 (7%)] Train loss=0.360716 Test loss=0.381429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.320521742105484
[5/23] Train loss=0.4137548804283142
[10/23] Train loss=0.40200290083885193
[15/23] Train loss=0.32691097259521484
[20/23] Train loss=0.28685319423675537
Test set avg_accuracy=85.65% avg_sensitivity=46.63%, avg_specificity=98.25% avg_auc=0.9084
Best model saved!! Metric=-4.6299360899237705!!
Fold[7] Epoch: 8 [8/100 (8%)] Train loss=0.358311 Test loss=0.368657 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.313105970621109
[5/23] Train loss=0.4375036358833313
[10/23] Train loss=0.3844279944896698
[15/23] Train loss=0.3114762306213379
[20/23] Train loss=0.2781761884689331
Test set avg_accuracy=87.15% avg_sensitivity=54.14%, avg_specificity=97.81% avg_auc=0.9126
Best model saved!! Metric=4.354942847502604!!
Fold[7] Epoch: 9 [9/100 (9%)] Train loss=0.355074 Test loss=0.339331 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2960003614425659
[5/23] Train loss=0.4318843483924866
[10/23] Train loss=0.34914496541023254
[15/23] Train loss=0.2914532721042633
[20/23] Train loss=0.27022963762283325
Test set avg_accuracy=88.25% avg_sensitivity=65.23%, avg_specificity=95.69% avg_auc=0.9187
Best model saved!! Metric=15.035543375189553!!
Fold[7] Epoch: 10 [10/100 (10%)] Train loss=0.342752 Test loss=0.311256 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2811777889728546
[5/23] Train loss=0.41373172402381897
[10/23] Train loss=0.3424696922302246
[15/23] Train loss=0.27077221870422363
[20/23] Train loss=0.2635924816131592
Test set avg_accuracy=88.38% avg_sensitivity=65.27%, avg_specificity=95.84% avg_auc=0.9224
Best model saved!! Metric=15.72191532204958!!
Fold[7] Epoch: 11 [11/100 (11%)] Train loss=0.327987 Test loss=0.301616 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2766064405441284
[5/23] Train loss=0.39083021879196167
[10/23] Train loss=0.33751681447029114
[15/23] Train loss=0.2549096345901489
[20/23] Train loss=0.24206162989139557
Test set avg_accuracy=88.74% avg_sensitivity=65.02%, avg_specificity=96.40% avg_auc=0.9240
Best model saved!! Metric=16.563278375873175!!
Fold[7] Epoch: 12 [12/100 (12%)] Train loss=0.316859 Test loss=0.305115 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2618281841278076
[5/23] Train loss=0.38099393248558044
[10/23] Train loss=0.3292437791824341
[15/23] Train loss=0.2532676160335541
[20/23] Train loss=0.23005010187625885
Test set avg_accuracy=89.22% avg_sensitivity=66.04%, avg_specificity=96.71% avg_auc=0.9270
Best model saved!! Metric=18.661568183186517!!
Fold[7] Epoch: 13 [13/100 (13%)] Train loss=0.310439 Test loss=0.296640 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2546547055244446
[5/23] Train loss=0.37563344836235046
[10/23] Train loss=0.3245146572589874
[15/23] Train loss=0.24264568090438843
[20/23] Train loss=0.22915762662887573
Test set avg_accuracy=89.25% avg_sensitivity=65.10%, avg_specificity=97.05% avg_auc=0.9292
Fold[7] Epoch: 14 [14/100 (14%)] Train loss=0.305378 Test loss=0.295134 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2376476675271988
[5/23] Train loss=0.3686040937900543
[10/23] Train loss=0.3176928162574768
[15/23] Train loss=0.2341069132089615
[20/23] Train loss=0.21077533066272736
Test set avg_accuracy=89.38% avg_sensitivity=65.19%, avg_specificity=97.19% avg_auc=0.9308
Best model saved!! Metric=18.829324489842!!
Fold[7] Epoch: 15 [15/100 (15%)] Train loss=0.298151 Test loss=0.290195 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24327203631401062
[5/23] Train loss=0.3590048551559448
[10/23] Train loss=0.3010959029197693
[15/23] Train loss=0.24058915674686432
[20/23] Train loss=0.20954586565494537
Test set avg_accuracy=89.33% avg_sensitivity=64.72%, avg_specificity=97.29% avg_auc=0.9314
Fold[7] Epoch: 16 [16/100 (16%)] Train loss=0.292650 Test loss=0.293277 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2368459850549698
[5/23] Train loss=0.3652706742286682
[10/23] Train loss=0.30836620926856995
[15/23] Train loss=0.23478691279888153
[20/23] Train loss=0.21084022521972656
Test set avg_accuracy=89.90% avg_sensitivity=67.11%, avg_specificity=97.26% avg_auc=0.9334
Best model saved!! Metric=21.60355656391384!!
Fold[7] Epoch: 17 [17/100 (17%)] Train loss=0.291359 Test loss=0.287586 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23023119568824768
[5/23] Train loss=0.3610939085483551
[10/23] Train loss=0.30020835995674133
[15/23] Train loss=0.2318723052740097
[20/23] Train loss=0.20805633068084717
Test set avg_accuracy=90.11% avg_sensitivity=68.00%, avg_specificity=97.26% avg_auc=0.9342
Best model saved!! Metric=22.793760457784423!!
Fold[7] Epoch: 18 [18/100 (18%)] Train loss=0.286387 Test loss=0.283064 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24382038414478302
[5/23] Train loss=0.3503582775592804
[10/23] Train loss=0.2952999174594879
[15/23] Train loss=0.2208475023508072
[20/23] Train loss=0.20034277439117432
Test set avg_accuracy=90.10% avg_sensitivity=68.64%, avg_specificity=97.04% avg_auc=0.9350
Best model saved!! Metric=23.283879889758957!!
Fold[7] Epoch: 19 [19/100 (19%)] Train loss=0.282294 Test loss=0.283826 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22543053328990936
[5/23] Train loss=0.34577012062072754
[10/23] Train loss=0.2908877432346344
[15/23] Train loss=0.2191694974899292
[20/23] Train loss=0.1931452453136444
Test set avg_accuracy=90.26% avg_sensitivity=68.73%, avg_specificity=97.22% avg_auc=0.9351
Best model saved!! Metric=23.714781960682494!!
Fold[7] Epoch: 20 [20/100 (20%)] Train loss=0.278224 Test loss=0.283260 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22876609861850739
[5/23] Train loss=0.33683887124061584
[10/23] Train loss=0.2964531183242798
[15/23] Train loss=0.22736254334449768
[20/23] Train loss=0.19385269284248352
Test set avg_accuracy=90.26% avg_sensitivity=68.09%, avg_specificity=97.42% avg_auc=0.9354
Fold[7] Epoch: 21 [21/100 (21%)] Train loss=0.276470 Test loss=0.287012 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23148085176944733
[5/23] Train loss=0.34802907705307007
[10/23] Train loss=0.30062901973724365
[15/23] Train loss=0.21247394382953644
[20/23] Train loss=0.19333282113075256
Test set avg_accuracy=90.10% avg_sensitivity=67.70%, avg_specificity=97.34% avg_auc=0.9349
Fold[7] Epoch: 22 [22/100 (22%)] Train loss=0.273504 Test loss=0.286752 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22529490292072296
[5/23] Train loss=0.35173606872558594
[10/23] Train loss=0.2918301224708557
[15/23] Train loss=0.2158227264881134
[20/23] Train loss=0.18831899762153625
Test set avg_accuracy=90.51% avg_sensitivity=69.24%, avg_specificity=97.38% avg_auc=0.9364
Best model saved!! Metric=24.774089239864896!!
Fold[7] Epoch: 23 [23/100 (23%)] Train loss=0.274009 Test loss=0.279820 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22996416687965393
[5/23] Train loss=0.3394506275653839
[10/23] Train loss=0.2822086811065674
[15/23] Train loss=0.21769902110099792
[20/23] Train loss=0.18777740001678467
Test set avg_accuracy=90.45% avg_sensitivity=70.05%, avg_specificity=97.04% avg_auc=0.9378
Best model saved!! Metric=25.315032406588614!!
Fold[7] Epoch: 24 [24/100 (24%)] Train loss=0.271738 Test loss=0.276050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22152090072631836
[5/23] Train loss=0.3516082167625427
[10/23] Train loss=0.2778906226158142
[15/23] Train loss=0.21217355132102966
[20/23] Train loss=0.18515467643737793
Test set avg_accuracy=90.94% avg_sensitivity=72.40%, avg_specificity=96.93% avg_auc=0.9395
Best model saved!! Metric=28.214701920218545!!
Fold[7] Epoch: 25 [25/100 (25%)] Train loss=0.267262 Test loss=0.266038 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21528276801109314
[5/23] Train loss=0.33066630363464355
[10/23] Train loss=0.2676324248313904
[15/23] Train loss=0.20797047019004822
[20/23] Train loss=0.17718926072120667
Test set avg_accuracy=91.03% avg_sensitivity=72.78%, avg_specificity=96.93% avg_auc=0.9410
Best model saved!! Metric=28.83500802913251!!
Fold[7] Epoch: 26 [26/100 (26%)] Train loss=0.260422 Test loss=0.264647 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21566206216812134
[5/23] Train loss=0.3281177580356598
[10/23] Train loss=0.25953808426856995
[15/23] Train loss=0.20474807918071747
[20/23] Train loss=0.18611101806163788
Test set avg_accuracy=90.96% avg_sensitivity=71.84%, avg_specificity=97.13% avg_auc=0.9408
Fold[7] Epoch: 27 [27/100 (27%)] Train loss=0.260060 Test loss=0.263748 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21396031975746155
[5/23] Train loss=0.3315574824810028
[10/23] Train loss=0.26696231961250305
[15/23] Train loss=0.20678837597370148
[20/23] Train loss=0.17483937740325928
Test set avg_accuracy=90.84% avg_sensitivity=71.20%, avg_specificity=97.19% avg_auc=0.9410
Fold[7] Epoch: 28 [28/100 (28%)] Train loss=0.255577 Test loss=0.265107 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21093663573265076
[5/23] Train loss=0.3261241018772125
[10/23] Train loss=0.2633633613586426
[15/23] Train loss=0.19495642185211182
[20/23] Train loss=0.17560765147209167
Test set avg_accuracy=91.08% avg_sensitivity=71.72%, avg_specificity=97.34% avg_auc=0.9421
Fold[7] Epoch: 29 [29/100 (29%)] Train loss=0.254605 Test loss=0.262245 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20945072174072266
[5/23] Train loss=0.32478782534599304
[10/23] Train loss=0.26704490184783936
[15/23] Train loss=0.20249462127685547
[20/23] Train loss=0.1781969964504242
Test set avg_accuracy=90.61% avg_sensitivity=69.67%, avg_specificity=97.38% avg_auc=0.9416
Fold[7] Epoch: 30 [30/100 (30%)] Train loss=0.253033 Test loss=0.266648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22034962475299835
[5/23] Train loss=0.317612886428833
[10/23] Train loss=0.2629825472831726
[15/23] Train loss=0.20174048840999603
[20/23] Train loss=0.17461363971233368
Test set avg_accuracy=90.96% avg_sensitivity=71.08%, avg_specificity=97.38% avg_auc=0.9432
Fold[7] Epoch: 31 [31/100 (31%)] Train loss=0.250261 Test loss=0.261655 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20577186346054077
[5/23] Train loss=0.3260685205459595
[10/23] Train loss=0.262921541929245
[15/23] Train loss=0.19522878527641296
[20/23] Train loss=0.17148564755916595
Test set avg_accuracy=91.06% avg_sensitivity=70.99%, avg_specificity=97.55% avg_auc=0.9442
Fold[7] Epoch: 32 [32/100 (32%)] Train loss=0.251742 Test loss=0.257688 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21160542964935303
[5/23] Train loss=0.326189786195755
[10/23] Train loss=0.24783383309841156
[15/23] Train loss=0.19753442704677582
[20/23] Train loss=0.16431142389774323
Test set avg_accuracy=91.20% avg_sensitivity=72.40%, avg_specificity=97.27% avg_auc=0.9445
Best model saved!! Metric=29.31528475747348!!
Fold[7] Epoch: 33 [33/100 (33%)] Train loss=0.247653 Test loss=0.253988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2075764387845993
[5/23] Train loss=0.3161289393901825
[10/23] Train loss=0.2532655894756317
[15/23] Train loss=0.1863718330860138
[20/23] Train loss=0.1704280525445938
Test set avg_accuracy=91.23% avg_sensitivity=72.82%, avg_specificity=97.17% avg_auc=0.9436
Best model saved!! Metric=29.588631682790776!!
Fold[7] Epoch: 34 [34/100 (34%)] Train loss=0.244910 Test loss=0.254061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20899054408073425
[5/23] Train loss=0.3140295743942261
[10/23] Train loss=0.2531090974807739
[15/23] Train loss=0.17957167327404022
[20/23] Train loss=0.15969280898571014
Test set avg_accuracy=91.19% avg_sensitivity=73.04%, avg_specificity=97.05% avg_auc=0.9452
Best model saved!! Metric=29.79092576321444!!
Fold[7] Epoch: 35 [35/100 (35%)] Train loss=0.239553 Test loss=0.251258 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19511912763118744
[5/23] Train loss=0.3143309950828552
[10/23] Train loss=0.2538386583328247
[15/23] Train loss=0.18607595562934875
[20/23] Train loss=0.16173477470874786
Test set avg_accuracy=91.06% avg_sensitivity=71.84%, avg_specificity=97.27% avg_auc=0.9445
Fold[7] Epoch: 36 [36/100 (36%)] Train loss=0.238686 Test loss=0.253122 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19902224838733673
[5/23] Train loss=0.3029381036758423
[10/23] Train loss=0.25122150778770447
[15/23] Train loss=0.18604199588298798
[20/23] Train loss=0.16168369352817535
Test set avg_accuracy=90.91% avg_sensitivity=71.46%, avg_specificity=97.19% avg_auc=0.9451
Fold[7] Epoch: 37 [37/100 (37%)] Train loss=0.237572 Test loss=0.253019 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19212059676647186
[5/23] Train loss=0.3074321448802948
[10/23] Train loss=0.24990133941173553
[15/23] Train loss=0.1837889850139618
[20/23] Train loss=0.15881069004535675
Test set avg_accuracy=91.03% avg_sensitivity=72.18%, avg_specificity=97.12% avg_auc=0.9451
Fold[7] Epoch: 38 [38/100 (38%)] Train loss=0.233435 Test loss=0.251515 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19074100255966187
[5/23] Train loss=0.3156583607196808
[10/23] Train loss=0.24743789434432983
[15/23] Train loss=0.18189193308353424
[20/23] Train loss=0.15443669259548187
Test set avg_accuracy=91.04% avg_sensitivity=72.18%, avg_specificity=97.13% avg_auc=0.9455
Fold[7] Epoch: 39 [39/100 (39%)] Train loss=0.233274 Test loss=0.250849 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1903044432401657
[5/23] Train loss=0.3045557737350464
[10/23] Train loss=0.24313606321811676
[15/23] Train loss=0.18136316537857056
[20/23] Train loss=0.1531643569469452
Test set avg_accuracy=90.75% avg_sensitivity=71.12%, avg_specificity=97.09% avg_auc=0.9438
Fold[7] Epoch: 40 [40/100 (40%)] Train loss=0.230687 Test loss=0.255491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1949467808008194
[5/23] Train loss=0.3125373423099518
[10/23] Train loss=0.23907920718193054
[15/23] Train loss=0.17099051177501678
[20/23] Train loss=0.15621830523014069
Test set avg_accuracy=91.03% avg_sensitivity=72.57%, avg_specificity=97.00% avg_auc=0.9460
Fold[7] Epoch: 41 [41/100 (41%)] Train loss=0.230195 Test loss=0.249882 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18978817760944366
[5/23] Train loss=0.2983669340610504
[10/23] Train loss=0.23458850383758545
[15/23] Train loss=0.17994529008865356
[20/23] Train loss=0.15742415189743042
Test set avg_accuracy=90.99% avg_sensitivity=71.63%, avg_specificity=97.24% avg_auc=0.9442
Fold[7] Epoch: 42 [42/100 (42%)] Train loss=0.227362 Test loss=0.253415 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1923546940088272
[5/23] Train loss=0.30082395672798157
[10/23] Train loss=0.24468742311000824
[15/23] Train loss=0.17997920513153076
[20/23] Train loss=0.1496201455593109
Test set avg_accuracy=90.89% avg_sensitivity=71.08%, avg_specificity=97.29% avg_auc=0.9457
Fold[7] Epoch: 43 [43/100 (43%)] Train loss=0.224986 Test loss=0.253119 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1875171810388565
[5/23] Train loss=0.2992192804813385
[10/23] Train loss=0.235060915350914
[15/23] Train loss=0.1798723191022873
[20/23] Train loss=0.15682025253772736
Test set avg_accuracy=90.72% avg_sensitivity=70.05%, avg_specificity=97.40% avg_auc=0.9453
Fold[7] Epoch: 44 [44/100 (44%)] Train loss=0.225471 Test loss=0.253803 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18831346929073334
[5/23] Train loss=0.28854185342788696
[10/23] Train loss=0.24140289425849915
[15/23] Train loss=0.17547990381717682
[20/23] Train loss=0.15179212391376495
Test set avg_accuracy=90.81% avg_sensitivity=70.95%, avg_specificity=97.23% avg_auc=0.9462
Fold[7] Epoch: 45 [45/100 (45%)] Train loss=0.223327 Test loss=0.250811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19045844674110413
[5/23] Train loss=0.3029922544956207
[10/23] Train loss=0.2273935228586197
[15/23] Train loss=0.1778944730758667
[20/23] Train loss=0.14334264397621155
Test set avg_accuracy=91.05% avg_sensitivity=71.97%, avg_specificity=97.22% avg_auc=0.9458
Fold[7] Epoch: 46 [46/100 (46%)] Train loss=0.219351 Test loss=0.250671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18516945838928223
[5/23] Train loss=0.2930516302585602
[10/23] Train loss=0.21394884586334229
[15/23] Train loss=0.17265982925891876
[20/23] Train loss=0.14595742523670197
Test set avg_accuracy=90.95% avg_sensitivity=72.48%, avg_specificity=96.91% avg_auc=0.9458
Fold[7] Epoch: 47 [47/100 (47%)] Train loss=0.218715 Test loss=0.251148 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17729200422763824
[5/23] Train loss=0.29099562764167786
[10/23] Train loss=0.23264816403388977
[15/23] Train loss=0.17050570249557495
[20/23] Train loss=0.1470523476600647
Test set avg_accuracy=91.12% avg_sensitivity=72.44%, avg_specificity=97.16% avg_auc=0.9471
Fold[7] Epoch: 48 [48/100 (48%)] Train loss=0.216686 Test loss=0.247006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18289299309253693
[5/23] Train loss=0.2936883866786957
[10/23] Train loss=0.22189532220363617
[15/23] Train loss=0.16691002249717712
[20/23] Train loss=0.14427141845226288
Test set avg_accuracy=91.10% avg_sensitivity=73.29%, avg_specificity=96.86% avg_auc=0.9471
Best model saved!! Metric=29.966651897202002!!
Fold[7] Epoch: 49 [49/100 (49%)] Train loss=0.213762 Test loss=0.244738 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18522202968597412
[5/23] Train loss=0.2915934920310974
[10/23] Train loss=0.21571634709835052
[15/23] Train loss=0.16193389892578125
[20/23] Train loss=0.1502690613269806
Test set avg_accuracy=91.12% avg_sensitivity=73.63%, avg_specificity=96.78% avg_auc=0.9470
Best model saved!! Metric=30.237531326316738!!
Fold[7] Epoch: 50 [50/100 (50%)] Train loss=0.212521 Test loss=0.245314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17751818895339966
[5/23] Train loss=0.29137295484542847
[10/23] Train loss=0.22057370841503143
[15/23] Train loss=0.1653999537229538
[20/23] Train loss=0.14635471999645233
Test set avg_accuracy=91.12% avg_sensitivity=73.17%, avg_specificity=96.93% avg_auc=0.9474
Fold[7] Epoch: 51 [51/100 (51%)] Train loss=0.210912 Test loss=0.243366 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17359629273414612
[5/23] Train loss=0.28394263982772827
[10/23] Train loss=0.21877217292785645
[15/23] Train loss=0.15565739572048187
[20/23] Train loss=0.13712966442108154
Test set avg_accuracy=91.04% avg_sensitivity=73.21%, avg_specificity=96.80% avg_auc=0.9470
Fold[7] Epoch: 52 [52/100 (52%)] Train loss=0.205932 Test loss=0.245160 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17126144468784332
[5/23] Train loss=0.2909407615661621
[10/23] Train loss=0.20129455626010895
[15/23] Train loss=0.16344822943210602
[20/23] Train loss=0.1434081494808197
Test set avg_accuracy=90.81% avg_sensitivity=72.18%, avg_specificity=96.83% avg_auc=0.9452
Fold[7] Epoch: 53 [53/100 (53%)] Train loss=0.205282 Test loss=0.250090 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.175209179520607
[5/23] Train loss=0.2725088894367218
[10/23] Train loss=0.21499209105968475
[15/23] Train loss=0.15275640785694122
[20/23] Train loss=0.13839036226272583
Test set avg_accuracy=90.88% avg_sensitivity=72.70%, avg_specificity=96.75% avg_auc=0.9470
Fold[7] Epoch: 54 [54/100 (54%)] Train loss=0.200705 Test loss=0.246459 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1678425520658493
[5/23] Train loss=0.26389044523239136
[10/23] Train loss=0.2117021083831787
[15/23] Train loss=0.1544729620218277
[20/23] Train loss=0.13361123204231262
Test set avg_accuracy=90.70% avg_sensitivity=71.97%, avg_specificity=96.75% avg_auc=0.9459
Fold[7] Epoch: 55 [55/100 (55%)] Train loss=0.200711 Test loss=0.248234 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17384104430675507
[5/23] Train loss=0.27048635482788086
[10/23] Train loss=0.2063751071691513
[15/23] Train loss=0.15648898482322693
[20/23] Train loss=0.13144071400165558
Test set avg_accuracy=90.48% avg_sensitivity=71.50%, avg_specificity=96.61% avg_auc=0.9459
Fold[7] Epoch: 56 [56/100 (56%)] Train loss=0.198745 Test loss=0.248644 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16143539547920227
[5/23] Train loss=0.2686780095100403
[10/23] Train loss=0.20685632526874542
[15/23] Train loss=0.1491474211215973
[20/23] Train loss=0.13427503407001495
Test set avg_accuracy=90.71% avg_sensitivity=72.06%, avg_specificity=96.73% avg_auc=0.9459
Fold[7] Epoch: 57 [57/100 (57%)] Train loss=0.195762 Test loss=0.249665 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17195016145706177
[5/23] Train loss=0.2533814609050751
[10/23] Train loss=0.2065725177526474
[15/23] Train loss=0.15660391747951508
[20/23] Train loss=0.13038761913776398
Test set avg_accuracy=90.83% avg_sensitivity=71.80%, avg_specificity=96.98% avg_auc=0.9464
Fold[7] Epoch: 58 [58/100 (58%)] Train loss=0.194312 Test loss=0.248517 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16474486887454987
[5/23] Train loss=0.2678723633289337
[10/23] Train loss=0.1874535232782364
[15/23] Train loss=0.14922305941581726
[20/23] Train loss=0.12188175320625305
Test set avg_accuracy=90.66% avg_sensitivity=71.37%, avg_specificity=96.89% avg_auc=0.9455
Fold[7] Epoch: 59 [59/100 (59%)] Train loss=0.191503 Test loss=0.249421 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16368648409843445
[5/23] Train loss=0.2610544264316559
[10/23] Train loss=0.20206773281097412
[15/23] Train loss=0.15337161719799042
[20/23] Train loss=0.12823931872844696
Test set avg_accuracy=90.66% avg_sensitivity=71.97%, avg_specificity=96.69% avg_auc=0.9457
Fold[7] Epoch: 60 [60/100 (60%)] Train loss=0.189330 Test loss=0.249156 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1659499555826187
[5/23] Train loss=0.26349377632141113
[10/23] Train loss=0.19529075920581818
[15/23] Train loss=0.1443958431482315
[20/23] Train loss=0.135313481092453
Test set avg_accuracy=90.79% avg_sensitivity=72.18%, avg_specificity=96.80% avg_auc=0.9457
Fold[7] Epoch: 61 [61/100 (61%)] Train loss=0.188610 Test loss=0.250504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15947094559669495
[5/23] Train loss=0.25085505843162537
[10/23] Train loss=0.1886015087366104
[15/23] Train loss=0.14701080322265625
[20/23] Train loss=0.1229066550731659
Test set avg_accuracy=90.83% avg_sensitivity=72.57%, avg_specificity=96.73% avg_auc=0.9455
Fold[7] Epoch: 62 [62/100 (62%)] Train loss=0.182490 Test loss=0.251818 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15707623958587646
[5/23] Train loss=0.2549728453159332
[10/23] Train loss=0.1880706548690796
[15/23] Train loss=0.1450735479593277
[20/23] Train loss=0.11837807297706604
Test set avg_accuracy=91.01% avg_sensitivity=72.87%, avg_specificity=96.87% avg_auc=0.9459
Fold[7] Epoch: 63 [63/100 (63%)] Train loss=0.182568 Test loss=0.249034 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1579573005437851
[5/23] Train loss=0.2519204616546631
[10/23] Train loss=0.19049006700515747
[15/23] Train loss=0.14409245550632477
[20/23] Train loss=0.12630929052829742
Test set avg_accuracy=90.81% avg_sensitivity=73.21%, avg_specificity=96.50% avg_auc=0.9456
Fold[7] Epoch: 64 [64/100 (64%)] Train loss=0.179755 Test loss=0.249032 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1495276838541031
[5/23] Train loss=0.23929300904273987
[10/23] Train loss=0.17917710542678833
[15/23] Train loss=0.134685680270195
[20/23] Train loss=0.11845800280570984
Test set avg_accuracy=90.91% avg_sensitivity=73.63%, avg_specificity=96.49% avg_auc=0.9462
Fold[7] Epoch: 65 [65/100 (65%)] Train loss=0.175476 Test loss=0.249481 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1585913449525833
[5/23] Train loss=0.23753677308559418
[10/23] Train loss=0.18441039323806763
[15/23] Train loss=0.14612853527069092
[20/23] Train loss=0.11489204317331314
Test set avg_accuracy=90.79% avg_sensitivity=72.44%, avg_specificity=96.72% avg_auc=0.9454
Fold[7] Epoch: 66 [66/100 (66%)] Train loss=0.175403 Test loss=0.251779 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.155010387301445
[5/23] Train loss=0.2385416328907013
[10/23] Train loss=0.18698659539222717
[15/23] Train loss=0.13250888884067535
[20/23] Train loss=0.11399874836206436
Test set avg_accuracy=90.95% avg_sensitivity=72.78%, avg_specificity=96.82% avg_auc=0.9450
Fold[7] Epoch: 67 [67/100 (67%)] Train loss=0.174192 Test loss=0.253159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15034012496471405
[5/23] Train loss=0.2312973141670227
[10/23] Train loss=0.18011292815208435
[15/23] Train loss=0.12874248623847961
[20/23] Train loss=0.11358928680419922
Test set avg_accuracy=91.02% avg_sensitivity=73.25%, avg_specificity=96.76% avg_auc=0.9465
Fold[7] Epoch: 68 [68/100 (68%)] Train loss=0.169447 Test loss=0.250218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15981611609458923
[5/23] Train loss=0.23853722214698792
[10/23] Train loss=0.16889549791812897
[15/23] Train loss=0.1336948424577713
[20/23] Train loss=0.11437883228063583
Test set avg_accuracy=90.68% avg_sensitivity=71.80%, avg_specificity=96.78% avg_auc=0.9456
Fold[7] Epoch: 69 [69/100 (69%)] Train loss=0.168738 Test loss=0.252877 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1536598950624466
[5/23] Train loss=0.24087059497833252
[10/23] Train loss=0.17167264223098755
[15/23] Train loss=0.1288059651851654
[20/23] Train loss=0.10448028892278671
Test set avg_accuracy=90.76% avg_sensitivity=72.48%, avg_specificity=96.66% avg_auc=0.9448
Fold[7] Epoch: 70 [70/100 (70%)] Train loss=0.166359 Test loss=0.255556 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14919373393058777
[5/23] Train loss=0.22732530534267426
[10/23] Train loss=0.17007498443126678
[15/23] Train loss=0.12828245759010315
[20/23] Train loss=0.09670871496200562
Test set avg_accuracy=90.60% avg_sensitivity=71.80%, avg_specificity=96.68% avg_auc=0.9441
Fold[7] Epoch: 71 [71/100 (71%)] Train loss=0.163044 Test loss=0.259370 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14493384957313538
[5/23] Train loss=0.23403573036193848
[10/23] Train loss=0.1770126074552536
[15/23] Train loss=0.1284882128238678
[20/23] Train loss=0.11104265600442886
Test set avg_accuracy=90.81% avg_sensitivity=73.12%, avg_specificity=96.53% avg_auc=0.9444
Fold[7] Epoch: 72 [72/100 (72%)] Train loss=0.162524 Test loss=0.254901 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14263436198234558
[5/23] Train loss=0.22919802367687225
[10/23] Train loss=0.16459114849567413
[15/23] Train loss=0.13375872373580933
[20/23] Train loss=0.10346856713294983
Test set avg_accuracy=90.95% avg_sensitivity=73.42%, avg_specificity=96.61% avg_auc=0.9448
Fold[7] Epoch: 73 [73/100 (73%)] Train loss=0.159551 Test loss=0.256327 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13760678470134735
[5/23] Train loss=0.2234862744808197
[10/23] Train loss=0.16711106896400452
[15/23] Train loss=0.12085666507482529
[20/23] Train loss=0.1044406145811081
Test set avg_accuracy=90.69% avg_sensitivity=73.29%, avg_specificity=96.31% avg_auc=0.9434
Fold[7] Epoch: 74 [74/100 (74%)] Train loss=0.158014 Test loss=0.258891 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14069771766662598
[5/23] Train loss=0.2216029167175293
[10/23] Train loss=0.16249439120292664
[15/23] Train loss=0.11246724426746368
[20/23] Train loss=0.09534814208745956
Test set avg_accuracy=90.68% avg_sensitivity=72.91%, avg_specificity=96.42% avg_auc=0.9441
Fold[7] Epoch: 75 [75/100 (75%)] Train loss=0.154123 Test loss=0.256049 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1394733488559723
[5/23] Train loss=0.21123334765434265
[10/23] Train loss=0.15987583994865417
[15/23] Train loss=0.11741559952497482
[20/23] Train loss=0.09790349751710892
Test set avg_accuracy=90.89% avg_sensitivity=73.89%, avg_specificity=96.38% avg_auc=0.9442
Fold[7] Epoch: 76 [76/100 (76%)] Train loss=0.151806 Test loss=0.258108 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1357201635837555
[5/23] Train loss=0.21296480298042297
[10/23] Train loss=0.16005797684192657
[15/23] Train loss=0.11836902797222137
[20/23] Train loss=0.0983109325170517
Test set avg_accuracy=90.77% avg_sensitivity=73.38%, avg_specificity=96.39% avg_auc=0.9423
Fold[7] Epoch: 77 [77/100 (77%)] Train loss=0.150329 Test loss=0.260304 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.136621356010437
[5/23] Train loss=0.2081119567155838
[10/23] Train loss=0.16583092510700226
[15/23] Train loss=0.11909355968236923
[20/23] Train loss=0.10356032103300095
Test set avg_accuracy=90.68% avg_sensitivity=73.42%, avg_specificity=96.25% avg_auc=0.9424
Fold[7] Epoch: 78 [78/100 (78%)] Train loss=0.148187 Test loss=0.261724 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1334877759218216
[5/23] Train loss=0.2018432468175888
[10/23] Train loss=0.15157897770404816
[15/23] Train loss=0.11522649973630905
[20/23] Train loss=0.10189790278673172
Test set avg_accuracy=90.57% avg_sensitivity=72.57%, avg_specificity=96.39% avg_auc=0.9428
Fold[7] Epoch: 79 [79/100 (79%)] Train loss=0.143457 Test loss=0.263770 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1380302757024765
[5/23] Train loss=0.20467165112495422
[10/23] Train loss=0.14745308458805084
[15/23] Train loss=0.11173611134290695
[20/23] Train loss=0.09881410002708435
Test set avg_accuracy=90.74% avg_sensitivity=73.59%, avg_specificity=96.28% avg_auc=0.9429
Fold[7] Epoch: 80 [80/100 (80%)] Train loss=0.142861 Test loss=0.264023 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12752214074134827
[5/23] Train loss=0.19328366219997406
[10/23] Train loss=0.15311776101589203
[15/23] Train loss=0.1122279018163681
[20/23] Train loss=0.0984155461192131
Test set avg_accuracy=90.74% avg_sensitivity=73.89%, avg_specificity=96.18% avg_auc=0.9440
Fold[7] Epoch: 81 [81/100 (81%)] Train loss=0.141147 Test loss=0.260159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12277275323867798
[5/23] Train loss=0.1878456473350525
[10/23] Train loss=0.1467873901128769
[15/23] Train loss=0.11163206398487091
[20/23] Train loss=0.0891680121421814
Test set avg_accuracy=90.73% avg_sensitivity=73.46%, avg_specificity=96.31% avg_auc=0.9412
Fold[7] Epoch: 82 [82/100 (82%)] Train loss=0.135732 Test loss=0.268316 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12982416152954102
[5/23] Train loss=0.1976698935031891
[10/23] Train loss=0.1479850858449936
[15/23] Train loss=0.10813857614994049
[20/23] Train loss=0.08667232096195221
Test set avg_accuracy=90.68% avg_sensitivity=73.25%, avg_specificity=96.31% avg_auc=0.9432
Fold[7] Epoch: 83 [83/100 (83%)] Train loss=0.134664 Test loss=0.266760 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1293717324733734
[5/23] Train loss=0.18722625076770782
[10/23] Train loss=0.14995327591896057
[15/23] Train loss=0.11406172811985016
[20/23] Train loss=0.08842983096837997
Test set avg_accuracy=90.52% avg_sensitivity=72.70%, avg_specificity=96.28% avg_auc=0.9422
Fold[7] Epoch: 84 [84/100 (84%)] Train loss=0.133302 Test loss=0.269993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12304828315973282
[5/23] Train loss=0.19328173995018005
[10/23] Train loss=0.14637146890163422
[15/23] Train loss=0.10925902426242828
[20/23] Train loss=0.08884064108133316
Test set avg_accuracy=90.78% avg_sensitivity=72.57%, avg_specificity=96.66% avg_auc=0.9423
Fold[7] Epoch: 85 [85/100 (85%)] Train loss=0.131662 Test loss=0.269662 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11983166635036469
[5/23] Train loss=0.18333563208580017
[10/23] Train loss=0.1430041491985321
[15/23] Train loss=0.105443574488163
[20/23] Train loss=0.08684120327234268
Test set avg_accuracy=90.73% avg_sensitivity=72.95%, avg_specificity=96.47% avg_auc=0.9415
Fold[7] Epoch: 86 [86/100 (86%)] Train loss=0.129751 Test loss=0.272101 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12317266315221786
[5/23] Train loss=0.18284274637699127
[10/23] Train loss=0.14241020381450653
[15/23] Train loss=0.10702032595872879
[20/23] Train loss=0.08626807481050491
Test set avg_accuracy=91.10% avg_sensitivity=74.10%, avg_specificity=96.60% avg_auc=0.9426
Fold[7] Epoch: 87 [87/100 (87%)] Train loss=0.127105 Test loss=0.267352 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11383874714374542
[5/23] Train loss=0.17652972042560577
[10/23] Train loss=0.13382422924041748
[15/23] Train loss=0.09721199423074722
[20/23] Train loss=0.08430017530918121
Test set avg_accuracy=90.85% avg_sensitivity=73.46%, avg_specificity=96.47% avg_auc=0.9412
Fold[7] Epoch: 88 [88/100 (88%)] Train loss=0.123126 Test loss=0.272502 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11510617285966873
[5/23] Train loss=0.16971151530742645
[10/23] Train loss=0.1336396038532257
[15/23] Train loss=0.09705192595720291
[20/23] Train loss=0.08211974799633026
Test set avg_accuracy=90.71% avg_sensitivity=73.63%, avg_specificity=96.22% avg_auc=0.9417
Fold[7] Epoch: 89 [89/100 (89%)] Train loss=0.120816 Test loss=0.271140 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1110818162560463
[5/23] Train loss=0.1748017817735672
[10/23] Train loss=0.1286773532629013
[15/23] Train loss=0.09880607575178146
[20/23] Train loss=0.08648177236318588
Test set avg_accuracy=90.73% avg_sensitivity=74.36%, avg_specificity=96.02% avg_auc=0.9419
Fold[7] Epoch: 90 [90/100 (90%)] Train loss=0.120184 Test loss=0.269820 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1092277392745018
[5/23] Train loss=0.16368192434310913
[10/23] Train loss=0.1320916712284088
[15/23] Train loss=0.09462960809469223
[20/23] Train loss=0.07946725934743881
Test set avg_accuracy=90.81% avg_sensitivity=74.36%, avg_specificity=96.13% avg_auc=0.9414
Fold[7] Epoch: 91 [91/100 (91%)] Train loss=0.117800 Test loss=0.272642 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10078693926334381
[5/23] Train loss=0.1642160564661026
[10/23] Train loss=0.1252429485321045
[15/23] Train loss=0.09706524014472961
[20/23] Train loss=0.08289957791566849
Test set avg_accuracy=90.96% avg_sensitivity=75.55%, avg_specificity=95.93% avg_auc=0.9411
Best model saved!! Metric=30.557245708075115!!
Fold[7] Epoch: 92 [92/100 (92%)] Train loss=0.114440 Test loss=0.273645 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1074957475066185
[5/23] Train loss=0.1596936732530594
[10/23] Train loss=0.12987981736660004
[15/23] Train loss=0.10063330829143524
[20/23] Train loss=0.0815497562289238
Test set avg_accuracy=90.95% avg_sensitivity=75.09%, avg_specificity=96.07% avg_auc=0.9406
Fold[7] Epoch: 93 [93/100 (93%)] Train loss=0.113997 Test loss=0.276090 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10717795789241791
[5/23] Train loss=0.1697535216808319
[10/23] Train loss=0.11869917064905167
[15/23] Train loss=0.09169695526361465
[20/23] Train loss=0.07851005345582962
Test set avg_accuracy=91.04% avg_sensitivity=74.66%, avg_specificity=96.33% avg_auc=0.9411
Fold[7] Epoch: 94 [94/100 (94%)] Train loss=0.111689 Test loss=0.276249 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10262431204319
[5/23] Train loss=0.15471501648426056
[10/23] Train loss=0.12571196258068085
[15/23] Train loss=0.09244981408119202
[20/23] Train loss=0.07697988301515579
Test set avg_accuracy=90.89% avg_sensitivity=74.02%, avg_specificity=96.33% avg_auc=0.9392
Fold[7] Epoch: 95 [95/100 (95%)] Train loss=0.108969 Test loss=0.279724 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1015133410692215
[5/23] Train loss=0.15913178026676178
[10/23] Train loss=0.12558354437351227
[15/23] Train loss=0.0968487411737442
[20/23] Train loss=0.07134652882814407
Test set avg_accuracy=90.99% avg_sensitivity=74.96%, avg_specificity=96.17% avg_auc=0.9395
Fold[7] Epoch: 96 [96/100 (96%)] Train loss=0.110139 Test loss=0.279973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09804873913526535
[5/23] Train loss=0.1577475368976593
[10/23] Train loss=0.12754607200622559
[15/23] Train loss=0.08645555377006531
[20/23] Train loss=0.07132791727781296
Test set avg_accuracy=90.97% avg_sensitivity=74.57%, avg_specificity=96.27% avg_auc=0.9401
Fold[7] Epoch: 97 [97/100 (97%)] Train loss=0.104756 Test loss=0.279104 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1062641367316246
[5/23] Train loss=0.13998712599277496
[10/23] Train loss=0.1223476380109787
[15/23] Train loss=0.09029204398393631
[20/23] Train loss=0.07705411314964294
Test set avg_accuracy=90.94% avg_sensitivity=74.70%, avg_specificity=96.18% avg_auc=0.9382
Fold[7] Epoch: 98 [98/100 (98%)] Train loss=0.103670 Test loss=0.284212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09632828086614609
[5/23] Train loss=0.15370291471481323
[10/23] Train loss=0.11920902878046036
[15/23] Train loss=0.07914184778928757
[20/23] Train loss=0.06937119364738464
Test set avg_accuracy=90.91% avg_sensitivity=75.64%, avg_specificity=95.84% avg_auc=0.9390
Fold[7] Epoch: 99 [99/100 (99%)] Train loss=0.101585 Test loss=0.283086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.09330059587955475
[5/23] Train loss=0.13402001559734344
[10/23] Train loss=0.1162509173154831
[15/23] Train loss=0.08754415065050125
[20/23] Train loss=0.06793080270290375
Test set avg_accuracy=90.75% avg_sensitivity=75.00%, avg_specificity=95.84% avg_auc=0.9391
Fold[7] Epoch: 100 [100/100 (100%)] Train loss=0.099565 Test loss=0.286316 Current lr=[3.9999999999999996e-05]

Fold[7] Best Result: acc=90.95833333333333 sen=75.55460750853243, spe=95.93439911797134, auc=0.9410990574823802!
[0/23] Train loss=0.6983175277709961
[5/23] Train loss=0.67249995470047
[10/23] Train loss=0.5754340291023254
[15/23] Train loss=0.5491556525230408
[20/23] Train loss=0.5193130373954773
Test set avg_accuracy=76.87% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6548
Best model saved!! Metric=-83.64852782921363!!
Fold[8] Epoch: 1 [1/100 (1%)] Train loss=0.574843 Test loss=0.534854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.526065468788147
[5/23] Train loss=0.5533990859985352
[10/23] Train loss=0.4936876595020294
[15/23] Train loss=0.47621381282806396
[20/23] Train loss=0.43449386954307556
Test set avg_accuracy=77.31% avg_sensitivity=9.33%, avg_specificity=97.78% avg_auc=0.8111
Best model saved!! Metric=-60.47540201679912!!
Fold[8] Epoch: 2 [2/100 (2%)] Train loss=0.492209 Test loss=0.428554 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4362974762916565
[5/23] Train loss=0.4718265235424042
[10/23] Train loss=0.4702052175998688
[15/23] Train loss=0.39779043197631836
[20/23] Train loss=0.3604796230792999
Test set avg_accuracy=81.04% avg_sensitivity=37.30%, avg_specificity=94.21% avg_auc=0.8527
Best model saved!! Metric=-28.176355497695035!!
Fold[8] Epoch: 3 [3/100 (3%)] Train loss=0.431000 Test loss=0.393128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36939674615859985
[5/23] Train loss=0.43083882331848145
[10/23] Train loss=0.42108678817749023
[15/23] Train loss=0.36558228731155396
[20/23] Train loss=0.3325969874858856
Test set avg_accuracy=83.76% avg_sensitivity=51.59%, avg_specificity=93.45% avg_auc=0.8722
Best model saved!! Metric=-9.986632042711053!!
Fold[8] Epoch: 4 [4/100 (4%)] Train loss=0.392664 Test loss=0.373833 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34185969829559326
[5/23] Train loss=0.41236987709999084
[10/23] Train loss=0.41177621483802795
[15/23] Train loss=0.35334932804107666
[20/23] Train loss=0.3111398220062256
Test set avg_accuracy=85.58% avg_sensitivity=61.26%, avg_specificity=92.89% avg_auc=0.8870
Best model saved!! Metric=2.4313950975177128!!
Fold[8] Epoch: 5 [5/100 (5%)] Train loss=0.377300 Test loss=0.350575 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32530611753463745
[5/23] Train loss=0.4062846899032593
[10/23] Train loss=0.3994956612586975
[15/23] Train loss=0.3492605984210968
[20/23] Train loss=0.29279860854148865
Test set avg_accuracy=86.47% avg_sensitivity=66.37%, avg_specificity=92.52% avg_auc=0.8979
Best model saved!! Metric=9.1480718864911!!
Fold[8] Epoch: 6 [6/100 (6%)] Train loss=0.363180 Test loss=0.333403 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31734079122543335
[5/23] Train loss=0.39453351497650146
[10/23] Train loss=0.3910885751247406
[15/23] Train loss=0.33932411670684814
[20/23] Train loss=0.2771947681903839
Test set avg_accuracy=87.99% avg_sensitivity=69.30%, avg_specificity=93.61% avg_auc=0.9130
Best model saved!! Metric=16.192715346704478!!
Fold[8] Epoch: 7 [7/100 (7%)] Train loss=0.351869 Test loss=0.306448 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2950659692287445
[5/23] Train loss=0.39152613282203674
[10/23] Train loss=0.38613346219062805
[15/23] Train loss=0.32854264974594116
[20/23] Train loss=0.27146223187446594
Test set avg_accuracy=88.78% avg_sensitivity=73.31%, avg_specificity=93.43% avg_auc=0.9239
Best model saved!! Metric=21.916208083280324!!
Fold[8] Epoch: 8 [8/100 (8%)] Train loss=0.341710 Test loss=0.287336 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2813466489315033
[5/23] Train loss=0.37290066480636597
[10/23] Train loss=0.37179046869277954
[15/23] Train loss=0.3070806562900543
[20/23] Train loss=0.27042508125305176
Test set avg_accuracy=88.87% avg_sensitivity=74.11%, avg_specificity=93.31% avg_auc=0.9293
Best model saved!! Metric=23.2222486788188!!
Fold[8] Epoch: 9 [9/100 (9%)] Train loss=0.331344 Test loss=0.277859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26801133155822754
[5/23] Train loss=0.3718109428882599
[10/23] Train loss=0.3702026903629303
[15/23] Train loss=0.31560683250427246
[20/23] Train loss=0.24518004059791565
Test set avg_accuracy=89.55% avg_sensitivity=73.91%, avg_specificity=94.25% avg_auc=0.9328
Best model saved!! Metric=24.99138224540696!!
Fold[8] Epoch: 10 [10/100 (10%)] Train loss=0.326939 Test loss=0.269917 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2753787040710449
[5/23] Train loss=0.3695913553237915
[10/23] Train loss=0.3673059940338135
[15/23] Train loss=0.2863881289958954
[20/23] Train loss=0.2375473827123642
Test set avg_accuracy=89.42% avg_sensitivity=72.32%, avg_specificity=94.57% avg_auc=0.9369
Fold[8] Epoch: 11 [11/100 (11%)] Train loss=0.318277 Test loss=0.261311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2628873586654663
[5/23] Train loss=0.348645955324173
[10/23] Train loss=0.3618008494377136
[15/23] Train loss=0.2858012020587921
[20/23] Train loss=0.24145564436912537
Test set avg_accuracy=89.90% avg_sensitivity=73.76%, avg_specificity=94.76% avg_auc=0.9391
Best model saved!! Metric=26.33049464828801!!
Fold[8] Epoch: 12 [12/100 (12%)] Train loss=0.314258 Test loss=0.256532 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2546703517436981
[5/23] Train loss=0.35863354802131653
[10/23] Train loss=0.3564830422401428
[15/23] Train loss=0.28587546944618225
[20/23] Train loss=0.23339176177978516
Test set avg_accuracy=89.63% avg_sensitivity=67.36%, avg_specificity=96.33% avg_auc=0.9408
Fold[8] Epoch: 13 [13/100 (13%)] Train loss=0.311942 Test loss=0.257741 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2733737826347351
[5/23] Train loss=0.3532309830188751
[10/23] Train loss=0.3465668261051178
[15/23] Train loss=0.28594475984573364
[20/23] Train loss=0.23711547255516052
Test set avg_accuracy=90.10% avg_sensitivity=70.49%, avg_specificity=96.00% avg_auc=0.9448
Fold[8] Epoch: 14 [14/100 (14%)] Train loss=0.309442 Test loss=0.246821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2560315430164337
[5/23] Train loss=0.3728180229663849
[10/23] Train loss=0.34949687123298645
[15/23] Train loss=0.29054147005081177
[20/23] Train loss=0.2248995006084442
Test set avg_accuracy=90.22% avg_sensitivity=68.90%, avg_specificity=96.64% avg_auc=0.9443
Fold[8] Epoch: 15 [15/100 (15%)] Train loss=0.309370 Test loss=0.249959 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25266721844673157
[5/23] Train loss=0.3815343677997589
[10/23] Train loss=0.31217584013938904
[15/23] Train loss=0.2848694622516632
[20/23] Train loss=0.22696343064308167
Test set avg_accuracy=90.52% avg_sensitivity=75.00%, avg_specificity=95.19% avg_auc=0.9466
Best model saved!! Metric=29.38000513559152!!
Fold[8] Epoch: 16 [16/100 (16%)] Train loss=0.303314 Test loss=0.241146 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23810690641403198
[5/23] Train loss=0.3738565444946289
[10/23] Train loss=0.31423285603523254
[15/23] Train loss=0.27147015929222107
[20/23] Train loss=0.21881744265556335
Test set avg_accuracy=90.61% avg_sensitivity=75.15%, avg_specificity=95.27% avg_auc=0.9477
Best model saved!! Metric=29.800667197968217!!
Fold[8] Epoch: 17 [17/100 (17%)] Train loss=0.297978 Test loss=0.237702 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23846684396266937
[5/23] Train loss=0.36436235904693604
[10/23] Train loss=0.3024440407752991
[15/23] Train loss=0.2632042467594147
[20/23] Train loss=0.21792778372764587
Test set avg_accuracy=90.56% avg_sensitivity=76.59%, avg_specificity=94.76% avg_auc=0.9472
Best model saved!! Metric=30.621387293571118!!
Fold[8] Epoch: 18 [18/100 (18%)] Train loss=0.291365 Test loss=0.239642 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2322559803724289
[5/23] Train loss=0.3489874005317688
[10/23] Train loss=0.30215105414390564
[15/23] Train loss=0.2628442347049713
[20/23] Train loss=0.21067248284816742
Test set avg_accuracy=90.88% avg_sensitivity=77.88%, avg_specificity=94.79% avg_auc=0.9483
Best model saved!! Metric=32.372623332988205!!
Fold[8] Epoch: 19 [19/100 (19%)] Train loss=0.287979 Test loss=0.237610 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2242790013551712
[5/23] Train loss=0.3491079807281494
[10/23] Train loss=0.3002516031265259
[15/23] Train loss=0.2531052231788635
[20/23] Train loss=0.2058221697807312
Test set avg_accuracy=90.64% avg_sensitivity=76.49%, avg_specificity=94.89% avg_auc=0.9476
Fold[8] Epoch: 20 [20/100 (20%)] Train loss=0.280787 Test loss=0.238388 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22349117696285248
[5/23] Train loss=0.34764835238456726
[10/23] Train loss=0.2944284677505493
[15/23] Train loss=0.25663089752197266
[20/23] Train loss=0.20094682276248932
Test set avg_accuracy=90.97% avg_sensitivity=75.50%, avg_specificity=95.63% avg_auc=0.9484
Fold[8] Epoch: 21 [21/100 (21%)] Train loss=0.281061 Test loss=0.235549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22438384592533112
[5/23] Train loss=0.34300723671913147
[10/23] Train loss=0.3060224652290344
[15/23] Train loss=0.25721824169158936
[20/23] Train loss=0.19979335367679596
Test set avg_accuracy=91.06% avg_sensitivity=75.69%, avg_specificity=95.69% avg_auc=0.9488
Fold[8] Epoch: 22 [22/100 (22%)] Train loss=0.279183 Test loss=0.234515 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22730059921741486
[5/23] Train loss=0.3438354432582855
[10/23] Train loss=0.2830023467540741
[15/23] Train loss=0.25012460350990295
[20/23] Train loss=0.19719065725803375
Test set avg_accuracy=90.89% avg_sensitivity=74.90%, avg_specificity=95.70% avg_auc=0.9489
Fold[8] Epoch: 23 [23/100 (23%)] Train loss=0.276777 Test loss=0.235060 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2194642573595047
[5/23] Train loss=0.3395979404449463
[10/23] Train loss=0.2792685925960541
[15/23] Train loss=0.24955134093761444
[20/23] Train loss=0.19575241208076477
Test set avg_accuracy=90.75% avg_sensitivity=75.20%, avg_specificity=95.43% avg_auc=0.9482
Fold[8] Epoch: 24 [24/100 (24%)] Train loss=0.274660 Test loss=0.236643 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22202655673027039
[5/23] Train loss=0.34399205446243286
[10/23] Train loss=0.2841169536113739
[15/23] Train loss=0.2479836344718933
[20/23] Train loss=0.1951310932636261
Test set avg_accuracy=90.94% avg_sensitivity=75.00%, avg_specificity=95.73% avg_auc=0.9479
Fold[8] Epoch: 25 [25/100 (25%)] Train loss=0.273251 Test loss=0.236108 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22063902020454407
[5/23] Train loss=0.33666643500328064
[10/23] Train loss=0.2767307460308075
[15/23] Train loss=0.24586525559425354
[20/23] Train loss=0.18359237909317017
Test set avg_accuracy=91.08% avg_sensitivity=76.14%, avg_specificity=95.58% avg_auc=0.9490
Fold[8] Epoch: 26 [26/100 (26%)] Train loss=0.268046 Test loss=0.233864 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21506370604038239
[5/23] Train loss=0.3314753472805023
[10/23] Train loss=0.2831403911113739
[15/23] Train loss=0.2545173168182373
[20/23] Train loss=0.18658457696437836
Test set avg_accuracy=90.98% avg_sensitivity=75.40%, avg_specificity=95.67% avg_auc=0.9485
Fold[8] Epoch: 27 [27/100 (27%)] Train loss=0.266727 Test loss=0.234802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22600002586841583
[5/23] Train loss=0.3347095847129822
[10/23] Train loss=0.2642172574996948
[15/23] Train loss=0.247239887714386
[20/23] Train loss=0.18059846758842468
Test set avg_accuracy=91.06% avg_sensitivity=76.49%, avg_specificity=95.45% avg_auc=0.9488
Fold[8] Epoch: 28 [28/100 (28%)] Train loss=0.264704 Test loss=0.235091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21001553535461426
[5/23] Train loss=0.3271307647228241
[10/23] Train loss=0.2724737524986267
[15/23] Train loss=0.24815338850021362
[20/23] Train loss=0.183475062251091
Test set avg_accuracy=91.19% avg_sensitivity=76.49%, avg_specificity=95.61% avg_auc=0.9482
Fold[8] Epoch: 29 [29/100 (29%)] Train loss=0.263765 Test loss=0.235421 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21072852611541748
[5/23] Train loss=0.32303646206855774
[10/23] Train loss=0.2722078859806061
[15/23] Train loss=0.2408670336008072
[20/23] Train loss=0.18344150483608246
Test set avg_accuracy=91.04% avg_sensitivity=76.93%, avg_specificity=95.28% avg_auc=0.9495
Fold[8] Epoch: 30 [30/100 (30%)] Train loss=0.261934 Test loss=0.233150 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20624549686908722
[5/23] Train loss=0.3332836925983429
[10/23] Train loss=0.2643442451953888
[15/23] Train loss=0.2414071261882782
[20/23] Train loss=0.1728638857603073
Test set avg_accuracy=90.96% avg_sensitivity=75.79%, avg_specificity=95.52% avg_auc=0.9473
Fold[8] Epoch: 31 [31/100 (31%)] Train loss=0.259622 Test loss=0.237443 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20002096891403198
[5/23] Train loss=0.3309250771999359
[10/23] Train loss=0.26345333456993103
[15/23] Train loss=0.2426064908504486
[20/23] Train loss=0.17542457580566406
Test set avg_accuracy=90.99% avg_sensitivity=76.79%, avg_specificity=95.27% avg_auc=0.9490
Fold[8] Epoch: 32 [32/100 (32%)] Train loss=0.257724 Test loss=0.234226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20532077550888062
[5/23] Train loss=0.32961395382881165
[10/23] Train loss=0.26416265964508057
[15/23] Train loss=0.23556719720363617
[20/23] Train loss=0.175650954246521
Test set avg_accuracy=91.12% avg_sensitivity=76.54%, avg_specificity=95.51% avg_auc=0.9488
Fold[8] Epoch: 33 [33/100 (33%)] Train loss=0.256724 Test loss=0.234302 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20562700927257538
[5/23] Train loss=0.32760417461395264
[10/23] Train loss=0.26613736152648926
[15/23] Train loss=0.23829899728298187
[20/23] Train loss=0.17188875377178192
Test set avg_accuracy=91.00% avg_sensitivity=76.54%, avg_specificity=95.36% avg_auc=0.9489
Fold[8] Epoch: 34 [34/100 (34%)] Train loss=0.255698 Test loss=0.233690 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2006588727235794
[5/23] Train loss=0.32932037115097046
[10/23] Train loss=0.2545311152935028
[15/23] Train loss=0.23039039969444275
[20/23] Train loss=0.17543548345565796
Test set avg_accuracy=91.00% avg_sensitivity=76.69%, avg_specificity=95.31% avg_auc=0.9485
Fold[8] Epoch: 35 [35/100 (35%)] Train loss=0.251961 Test loss=0.235226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2014055997133255
[5/23] Train loss=0.32132530212402344
[10/23] Train loss=0.2541460394859314
[15/23] Train loss=0.22824779152870178
[20/23] Train loss=0.17612168192863464
Test set avg_accuracy=90.90% avg_sensitivity=76.69%, avg_specificity=95.18% avg_auc=0.9483
Fold[8] Epoch: 36 [36/100 (36%)] Train loss=0.247286 Test loss=0.236698 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20062896609306335
[5/23] Train loss=0.3212999105453491
[10/23] Train loss=0.2522561252117157
[15/23] Train loss=0.23896008729934692
[20/23] Train loss=0.17280516028404236
Test set avg_accuracy=91.14% avg_sensitivity=76.88%, avg_specificity=95.43% avg_auc=0.9490
Fold[8] Epoch: 37 [37/100 (37%)] Train loss=0.246891 Test loss=0.233780 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20618058741092682
[5/23] Train loss=0.30358242988586426
[10/23] Train loss=0.2611391842365265
[15/23] Train loss=0.23333154618740082
[20/23] Train loss=0.15985527634620667
Test set avg_accuracy=91.04% avg_sensitivity=76.74%, avg_specificity=95.34% avg_auc=0.9487
Fold[8] Epoch: 38 [38/100 (38%)] Train loss=0.244230 Test loss=0.235432 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19901753962039948
[5/23] Train loss=0.30685120820999146
[10/23] Train loss=0.24858663976192474
[15/23] Train loss=0.2251856029033661
[20/23] Train loss=0.1687735766172409
Test set avg_accuracy=90.91% avg_sensitivity=76.14%, avg_specificity=95.36% avg_auc=0.9479
Fold[8] Epoch: 39 [39/100 (39%)] Train loss=0.241958 Test loss=0.236720 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19186492264270782
[5/23] Train loss=0.29754355549812317
[10/23] Train loss=0.26106470823287964
[15/23] Train loss=0.23033639788627625
[20/23] Train loss=0.16514801979064941
Test set avg_accuracy=90.85% avg_sensitivity=75.74%, avg_specificity=95.40% avg_auc=0.9473
Fold[8] Epoch: 40 [40/100 (40%)] Train loss=0.241663 Test loss=0.238673 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2020038664340973
[5/23] Train loss=0.29779690504074097
[10/23] Train loss=0.2448064386844635
[15/23] Train loss=0.234288290143013
[20/23] Train loss=0.15698400139808655
Test set avg_accuracy=90.76% avg_sensitivity=75.50%, avg_specificity=95.36% avg_auc=0.9475
Fold[8] Epoch: 41 [41/100 (41%)] Train loss=0.238916 Test loss=0.238212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19669567048549652
[5/23] Train loss=0.3016464412212372
[10/23] Train loss=0.2522812783718109
[15/23] Train loss=0.22081704437732697
[20/23] Train loss=0.16288290917873383
Test set avg_accuracy=90.80% avg_sensitivity=75.10%, avg_specificity=95.52% avg_auc=0.9478
Fold[8] Epoch: 42 [42/100 (42%)] Train loss=0.238275 Test loss=0.237446 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18867827951908112
[5/23] Train loss=0.29987895488739014
[10/23] Train loss=0.24543960392475128
[15/23] Train loss=0.23335273563861847
[20/23] Train loss=0.1619214564561844
Test set avg_accuracy=90.66% avg_sensitivity=73.66%, avg_specificity=95.78% avg_auc=0.9476
Fold[8] Epoch: 43 [43/100 (43%)] Train loss=0.235269 Test loss=0.237672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19025389850139618
[5/23] Train loss=0.30266544222831726
[10/23] Train loss=0.24426208436489105
[15/23] Train loss=0.2248982936143875
[20/23] Train loss=0.15723277628421783
Test set avg_accuracy=90.72% avg_sensitivity=74.01%, avg_specificity=95.75% avg_auc=0.9467
Fold[8] Epoch: 44 [44/100 (44%)] Train loss=0.233504 Test loss=0.241356 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19242748618125916
[5/23] Train loss=0.30293670296669006
[10/23] Train loss=0.24500922858715057
[15/23] Train loss=0.22614598274230957
[20/23] Train loss=0.1477051079273224
Test set avg_accuracy=90.49% avg_sensitivity=74.80%, avg_specificity=95.21% avg_auc=0.9471
Fold[8] Epoch: 45 [45/100 (45%)] Train loss=0.232265 Test loss=0.240813 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18590624630451202
[5/23] Train loss=0.3057076334953308
[10/23] Train loss=0.24054324626922607
[15/23] Train loss=0.21494945883750916
[20/23] Train loss=0.1589459627866745
Test set avg_accuracy=90.72% avg_sensitivity=75.55%, avg_specificity=95.28% avg_auc=0.9483
Fold[8] Epoch: 46 [46/100 (46%)] Train loss=0.233016 Test loss=0.237848 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1904103308916092
[5/23] Train loss=0.2975728213787079
[10/23] Train loss=0.23292133212089539
[15/23] Train loss=0.22071850299835205
[20/23] Train loss=0.159348726272583
Test set avg_accuracy=90.80% avg_sensitivity=75.45%, avg_specificity=95.42% avg_auc=0.9486
Fold[8] Epoch: 47 [47/100 (47%)] Train loss=0.230483 Test loss=0.238004 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18584509193897247
[5/23] Train loss=0.2955392301082611
[10/23] Train loss=0.23412296175956726
[15/23] Train loss=0.21853917837142944
[20/23] Train loss=0.14946794509887695
Test set avg_accuracy=90.60% avg_sensitivity=77.13%, avg_specificity=94.66% avg_auc=0.9483
Fold[8] Epoch: 48 [48/100 (48%)] Train loss=0.226434 Test loss=0.240592 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18358956277370453
[5/23] Train loss=0.2945157587528229
[10/23] Train loss=0.2278110235929489
[15/23] Train loss=0.20759651064872742
[20/23] Train loss=0.1552794724702835
Test set avg_accuracy=90.68% avg_sensitivity=76.93%, avg_specificity=94.82% avg_auc=0.9480
Fold[8] Epoch: 49 [49/100 (49%)] Train loss=0.224491 Test loss=0.241972 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17968161404132843
[5/23] Train loss=0.2795425355434418
[10/23] Train loss=0.22475889325141907
[15/23] Train loss=0.20528756082057953
[20/23] Train loss=0.1505853533744812
Test set avg_accuracy=90.36% avg_sensitivity=77.38%, avg_specificity=94.27% avg_auc=0.9471
Fold[8] Epoch: 50 [50/100 (50%)] Train loss=0.222138 Test loss=0.244433 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1828637421131134
[5/23] Train loss=0.29360252618789673
[10/23] Train loss=0.2254561334848404
[15/23] Train loss=0.2155500054359436
[20/23] Train loss=0.15099184215068817
Test set avg_accuracy=90.19% avg_sensitivity=76.93%, avg_specificity=94.18% avg_auc=0.9482
Fold[8] Epoch: 51 [51/100 (51%)] Train loss=0.222113 Test loss=0.241303 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17262370884418488
[5/23] Train loss=0.2930457592010498
[10/23] Train loss=0.2186248004436493
[15/23] Train loss=0.20991793274879456
[20/23] Train loss=0.14194488525390625
Test set avg_accuracy=90.75% avg_sensitivity=76.74%, avg_specificity=94.97% avg_auc=0.9487
Fold[8] Epoch: 52 [52/100 (52%)] Train loss=0.217714 Test loss=0.240245 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18228335678577423
[5/23] Train loss=0.2842777371406555
[10/23] Train loss=0.22705470025539398
[15/23] Train loss=0.21439006924629211
[20/23] Train loss=0.14594273269176483
Test set avg_accuracy=90.24% avg_sensitivity=76.29%, avg_specificity=94.43% avg_auc=0.9477
Fold[8] Epoch: 53 [53/100 (53%)] Train loss=0.215747 Test loss=0.242940 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1789400726556778
[5/23] Train loss=0.2828475534915924
[10/23] Train loss=0.2243259847164154
[15/23] Train loss=0.20185120403766632
[20/23] Train loss=0.1376093327999115
Test set avg_accuracy=90.35% avg_sensitivity=76.98%, avg_specificity=94.37% avg_auc=0.9490
Fold[8] Epoch: 54 [54/100 (54%)] Train loss=0.214115 Test loss=0.240557 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17762112617492676
[5/23] Train loss=0.2859054505825043
[10/23] Train loss=0.22306177020072937
[15/23] Train loss=0.21036987006664276
[20/23] Train loss=0.14132970571517944
Test set avg_accuracy=90.40% avg_sensitivity=76.39%, avg_specificity=94.61% avg_auc=0.9473
Fold[8] Epoch: 55 [55/100 (55%)] Train loss=0.214683 Test loss=0.244994 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17526881396770477
[5/23] Train loss=0.2785067558288574
[10/23] Train loss=0.223237082362175
[15/23] Train loss=0.1979852020740509
[20/23] Train loss=0.14089350402355194
Test set avg_accuracy=90.64% avg_sensitivity=77.28%, avg_specificity=94.66% avg_auc=0.9488
Fold[8] Epoch: 56 [56/100 (56%)] Train loss=0.211510 Test loss=0.241985 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17258912324905396
[5/23] Train loss=0.27263885736465454
[10/23] Train loss=0.2167307436466217
[15/23] Train loss=0.20529474318027496
[20/23] Train loss=0.1390789896249771
Test set avg_accuracy=90.36% avg_sensitivity=75.79%, avg_specificity=94.75% avg_auc=0.9477
Fold[8] Epoch: 57 [57/100 (57%)] Train loss=0.208851 Test loss=0.243992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17575255036354065
[5/23] Train loss=0.2676544487476349
[10/23] Train loss=0.21992303431034088
[15/23] Train loss=0.20029258728027344
[20/23] Train loss=0.14616288244724274
Test set avg_accuracy=90.82% avg_sensitivity=76.93%, avg_specificity=95.00% avg_auc=0.9496
Fold[8] Epoch: 58 [58/100 (58%)] Train loss=0.208104 Test loss=0.239622 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1803533285856247
[5/23] Train loss=0.27111461758613586
[10/23] Train loss=0.2101302295923233
[15/23] Train loss=0.20866060256958008
[20/23] Train loss=0.14133669435977936
Test set avg_accuracy=90.38% avg_sensitivity=75.99%, avg_specificity=94.72% avg_auc=0.9477
Fold[8] Epoch: 59 [59/100 (59%)] Train loss=0.208314 Test loss=0.244547 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1751326024532318
[5/23] Train loss=0.27220386266708374
[10/23] Train loss=0.20595821738243103
[15/23] Train loss=0.19571813941001892
[20/23] Train loss=0.1359248161315918
Test set avg_accuracy=90.51% avg_sensitivity=77.58%, avg_specificity=94.40% avg_auc=0.9499
Fold[8] Epoch: 60 [60/100 (60%)] Train loss=0.205074 Test loss=0.239817 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16795869171619415
[5/23] Train loss=0.2793453335762024
[10/23] Train loss=0.21190284192562103
[15/23] Train loss=0.20414999127388
[20/23] Train loss=0.1309623420238495
Test set avg_accuracy=90.22% avg_sensitivity=75.30%, avg_specificity=94.72% avg_auc=0.9478
Fold[8] Epoch: 61 [61/100 (61%)] Train loss=0.205929 Test loss=0.246049 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16505582630634308
[5/23] Train loss=0.2770003378391266
[10/23] Train loss=0.2060910314321518
[15/23] Train loss=0.20075610280036926
[20/23] Train loss=0.13558778166770935
Test set avg_accuracy=90.73% avg_sensitivity=77.28%, avg_specificity=94.78% avg_auc=0.9492
Fold[8] Epoch: 62 [62/100 (62%)] Train loss=0.201796 Test loss=0.241504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16853313148021698
[5/23] Train loss=0.2616821527481079
[10/23] Train loss=0.19883312284946442
[15/23] Train loss=0.19290445744991302
[20/23] Train loss=0.1246551126241684
Test set avg_accuracy=91.00% avg_sensitivity=77.38%, avg_specificity=95.10% avg_auc=0.9493
Best model saved!! Metric=32.41537454704408!!
Fold[8] Epoch: 63 [63/100 (63%)] Train loss=0.198816 Test loss=0.242364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16595259308815002
[5/23] Train loss=0.26299428939819336
[10/23] Train loss=0.2085781991481781
[15/23] Train loss=0.18892480432987213
[20/23] Train loss=0.13159802556037903
Test set avg_accuracy=90.67% avg_sensitivity=77.38%, avg_specificity=94.67% avg_auc=0.9487
Fold[8] Epoch: 64 [64/100 (64%)] Train loss=0.196848 Test loss=0.244927 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17050403356552124
[5/23] Train loss=0.2661929130554199
[10/23] Train loss=0.20518076419830322
[15/23] Train loss=0.19350717961788177
[20/23] Train loss=0.12748461961746216
Test set avg_accuracy=90.41% avg_sensitivity=75.64%, avg_specificity=94.85% avg_auc=0.9475
Fold[8] Epoch: 65 [65/100 (65%)] Train loss=0.195491 Test loss=0.248128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16409769654273987
[5/23] Train loss=0.2583051323890686
[10/23] Train loss=0.19861328601837158
[15/23] Train loss=0.18719057738780975
[20/23] Train loss=0.1281980276107788
Test set avg_accuracy=90.53% avg_sensitivity=76.64%, avg_specificity=94.72% avg_auc=0.9483
Fold[8] Epoch: 66 [66/100 (66%)] Train loss=0.193593 Test loss=0.246868 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1649000197649002
[5/23] Train loss=0.26604604721069336
[10/23] Train loss=0.18576207756996155
[15/23] Train loss=0.19570791721343994
[20/23] Train loss=0.12643560767173767
Test set avg_accuracy=90.72% avg_sensitivity=77.88%, avg_specificity=94.58% avg_auc=0.9488
Fold[8] Epoch: 67 [67/100 (67%)] Train loss=0.190376 Test loss=0.246029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16516457498073578
[5/23] Train loss=0.2523820996284485
[10/23] Train loss=0.18959224224090576
[15/23] Train loss=0.18841509521007538
[20/23] Train loss=0.12462015450000763
Test set avg_accuracy=90.56% avg_sensitivity=77.83%, avg_specificity=94.39% avg_auc=0.9479
Fold[8] Epoch: 68 [68/100 (68%)] Train loss=0.191508 Test loss=0.249246 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16368240118026733
[5/23] Train loss=0.2416856735944748
[10/23] Train loss=0.18391697108745575
[15/23] Train loss=0.18247413635253906
[20/23] Train loss=0.12442930042743683
Test set avg_accuracy=90.46% avg_sensitivity=77.48%, avg_specificity=94.37% avg_auc=0.9474
Fold[8] Epoch: 69 [69/100 (69%)] Train loss=0.186542 Test loss=0.250866 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15341365337371826
[5/23] Train loss=0.24901103973388672
[10/23] Train loss=0.19404879212379456
[15/23] Train loss=0.1851799339056015
[20/23] Train loss=0.11468447744846344
Test set avg_accuracy=90.44% avg_sensitivity=79.07%, avg_specificity=93.86% avg_auc=0.9492
Fold[8] Epoch: 70 [70/100 (70%)] Train loss=0.184809 Test loss=0.249677 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15794150531291962
[5/23] Train loss=0.24877852201461792
[10/23] Train loss=0.18390357494354248
[15/23] Train loss=0.19038252532482147
[20/23] Train loss=0.1274411678314209
Test set avg_accuracy=90.44% avg_sensitivity=78.47%, avg_specificity=94.04% avg_auc=0.9495
Fold[8] Epoch: 71 [71/100 (71%)] Train loss=0.184079 Test loss=0.249769 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15404745936393738
[5/23] Train loss=0.24916771054267883
[10/23] Train loss=0.18692126870155334
[15/23] Train loss=0.18245749175548553
[20/23] Train loss=0.1167990118265152
Test set avg_accuracy=90.32% avg_sensitivity=77.83%, avg_specificity=94.07% avg_auc=0.9482
Fold[8] Epoch: 72 [72/100 (72%)] Train loss=0.180851 Test loss=0.251168 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1501438468694687
[5/23] Train loss=0.23725715279579163
[10/23] Train loss=0.1846151202917099
[15/23] Train loss=0.18005013465881348
[20/23] Train loss=0.11952265352010727
Test set avg_accuracy=90.11% avg_sensitivity=77.78%, avg_specificity=93.82% avg_auc=0.9474
Fold[8] Epoch: 73 [73/100 (73%)] Train loss=0.179772 Test loss=0.254383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15020038187503815
[5/23] Train loss=0.22741945087909698
[10/23] Train loss=0.1798112392425537
[15/23] Train loss=0.179536834359169
[20/23] Train loss=0.12217958271503448
Test set avg_accuracy=90.38% avg_sensitivity=77.73%, avg_specificity=94.19% avg_auc=0.9488
Fold[8] Epoch: 74 [74/100 (74%)] Train loss=0.174707 Test loss=0.250567 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1419169157743454
[5/23] Train loss=0.21870578825473785
[10/23] Train loss=0.17630654573440552
[15/23] Train loss=0.17825175821781158
[20/23] Train loss=0.11296790838241577
Test set avg_accuracy=90.30% avg_sensitivity=78.17%, avg_specificity=93.95% avg_auc=0.9477
Fold[8] Epoch: 75 [75/100 (75%)] Train loss=0.172886 Test loss=0.255013 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15698429942131042
[5/23] Train loss=0.23278528451919556
[10/23] Train loss=0.18495285511016846
[15/23] Train loss=0.18004466593265533
[20/23] Train loss=0.10560490936040878
Test set avg_accuracy=90.49% avg_sensitivity=78.42%, avg_specificity=94.12% avg_auc=0.9489
Fold[8] Epoch: 76 [76/100 (76%)] Train loss=0.172450 Test loss=0.252545 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15123668313026428
[5/23] Train loss=0.23474274575710297
[10/23] Train loss=0.17133627831935883
[15/23] Train loss=0.17565780878067017
[20/23] Train loss=0.1121693029999733
Test set avg_accuracy=90.33% avg_sensitivity=78.17%, avg_specificity=93.98% avg_auc=0.9476
Fold[8] Epoch: 77 [77/100 (77%)] Train loss=0.169906 Test loss=0.256434 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15388783812522888
[5/23] Train loss=0.22700534760951996
[10/23] Train loss=0.1684369444847107
[15/23] Train loss=0.1681935042142868
[20/23] Train loss=0.11321958899497986
Test set avg_accuracy=90.61% avg_sensitivity=79.66%, avg_specificity=93.91% avg_auc=0.9491
Best model saved!! Metric=33.09482446380037!!
Fold[8] Epoch: 78 [78/100 (78%)] Train loss=0.167910 Test loss=0.253928 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1442287564277649
[5/23] Train loss=0.22389307618141174
[10/23] Train loss=0.17195406556129456
[15/23] Train loss=0.17168185114860535
[20/23] Train loss=0.09952804446220398
Test set avg_accuracy=90.44% avg_sensitivity=79.91%, avg_specificity=93.61% avg_auc=0.9484
Fold[8] Epoch: 79 [79/100 (79%)] Train loss=0.163552 Test loss=0.257325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13950331509113312
[5/23] Train loss=0.20333948731422424
[10/23] Train loss=0.17261475324630737
[15/23] Train loss=0.1649048924446106
[20/23] Train loss=0.10585352778434753
Test set avg_accuracy=90.68% avg_sensitivity=79.12%, avg_specificity=94.16% avg_auc=0.9486
Fold[8] Epoch: 80 [80/100 (80%)] Train loss=0.164429 Test loss=0.255857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14409774541854858
[5/23] Train loss=0.20522837340831757
[10/23] Train loss=0.1697581559419632
[15/23] Train loss=0.1602102369070053
[20/23] Train loss=0.10229919850826263
Test set avg_accuracy=90.58% avg_sensitivity=78.97%, avg_specificity=94.07% avg_auc=0.9491
Fold[8] Epoch: 81 [81/100 (81%)] Train loss=0.159570 Test loss=0.255022 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14016126096248627
[5/23] Train loss=0.20803998410701752
[10/23] Train loss=0.16054555773735046
[15/23] Train loss=0.16142623126506805
[20/23] Train loss=0.10084117949008942
Test set avg_accuracy=90.83% avg_sensitivity=80.61%, avg_specificity=93.91% avg_auc=0.9502
Best model saved!! Metric=34.36929296169458!!
Fold[8] Epoch: 82 [82/100 (82%)] Train loss=0.158432 Test loss=0.251604 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13952942192554474
[5/23] Train loss=0.21516995131969452
[10/23] Train loss=0.148856520652771
[15/23] Train loss=0.1634587049484253
[20/23] Train loss=0.10178127884864807
Test set avg_accuracy=90.73% avg_sensitivity=78.77%, avg_specificity=94.33% avg_auc=0.9493
Fold[8] Epoch: 83 [83/100 (83%)] Train loss=0.156349 Test loss=0.255529 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14481832087039948
[5/23] Train loss=0.20793844759464264
[10/23] Train loss=0.16342532634735107
[15/23] Train loss=0.15522444248199463
[20/23] Train loss=0.09612017124891281
Test set avg_accuracy=90.46% avg_sensitivity=78.17%, avg_specificity=94.16% avg_auc=0.9491
Fold[8] Epoch: 84 [84/100 (84%)] Train loss=0.154151 Test loss=0.253993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13636289536952972
[5/23] Train loss=0.21009878814220428
[10/23] Train loss=0.15061523020267487
[15/23] Train loss=0.16188065707683563
[20/23] Train loss=0.09881065040826797
Test set avg_accuracy=90.46% avg_sensitivity=77.88%, avg_specificity=94.25% avg_auc=0.9488
Fold[8] Epoch: 85 [85/100 (85%)] Train loss=0.151421 Test loss=0.257986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13732284307479858
[5/23] Train loss=0.20731516182422638
[10/23] Train loss=0.15583713352680206
[15/23] Train loss=0.15908320248126984
[20/23] Train loss=0.09846081584692001
Test set avg_accuracy=90.80% avg_sensitivity=78.03%, avg_specificity=94.64% avg_auc=0.9499
Fold[8] Epoch: 86 [86/100 (86%)] Train loss=0.152826 Test loss=0.253206 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14099004864692688
[5/23] Train loss=0.20198844373226166
[10/23] Train loss=0.15473195910453796
[15/23] Train loss=0.1479090452194214
[20/23] Train loss=0.09283122420310974
Test set avg_accuracy=90.51% avg_sensitivity=77.08%, avg_specificity=94.55% avg_auc=0.9474
Fold[8] Epoch: 87 [87/100 (87%)] Train loss=0.148730 Test loss=0.260327 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13409985601902008
[5/23] Train loss=0.20135760307312012
[10/23] Train loss=0.1465645283460617
[15/23] Train loss=0.15143124759197235
[20/23] Train loss=0.10114005953073502
Test set avg_accuracy=91.14% avg_sensitivity=78.72%, avg_specificity=94.88% avg_auc=0.9498
Fold[8] Epoch: 88 [88/100 (88%)] Train loss=0.147589 Test loss=0.254748 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12636911869049072
[5/23] Train loss=0.18984024226665497
[10/23] Train loss=0.15754954516887665
[15/23] Train loss=0.1634102612733841
[20/23] Train loss=0.08937502652406693
Test set avg_accuracy=90.84% avg_sensitivity=76.98%, avg_specificity=95.01% avg_auc=0.9487
Fold[8] Epoch: 89 [89/100 (89%)] Train loss=0.144997 Test loss=0.259517 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13675124943256378
[5/23] Train loss=0.19523608684539795
[10/23] Train loss=0.14598247408866882
[15/23] Train loss=0.14705342054367065
[20/23] Train loss=0.0911327674984932
Test set avg_accuracy=90.90% avg_sensitivity=78.22%, avg_specificity=94.72% avg_auc=0.9486
Fold[8] Epoch: 90 [90/100 (90%)] Train loss=0.142083 Test loss=0.262757 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12350670248270035
[5/23] Train loss=0.18684722483158112
[10/23] Train loss=0.14726576209068298
[15/23] Train loss=0.15122796595096588
[20/23] Train loss=0.09103263914585114
Test set avg_accuracy=90.67% avg_sensitivity=79.71%, avg_specificity=93.97% avg_auc=0.9489
Fold[8] Epoch: 91 [91/100 (91%)] Train loss=0.140904 Test loss=0.263298 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1260051280260086
[5/23] Train loss=0.20173293352127075
[10/23] Train loss=0.14875589311122894
[15/23] Train loss=0.13537974655628204
[20/23] Train loss=0.08812327682971954
Test set avg_accuracy=90.90% avg_sensitivity=81.65%, avg_specificity=93.69% avg_auc=0.9504
Best model saved!! Metric=35.26955384785966!!
Fold[8] Epoch: 92 [92/100 (92%)] Train loss=0.139541 Test loss=0.262720 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12638957798480988
[5/23] Train loss=0.17733560502529144
[10/23] Train loss=0.1333620399236679
[15/23] Train loss=0.1512003093957901
[20/23] Train loss=0.0832364484667778
Test set avg_accuracy=90.66% avg_sensitivity=80.75%, avg_specificity=93.64% avg_auc=0.9497
Fold[8] Epoch: 93 [93/100 (93%)] Train loss=0.135351 Test loss=0.265566 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12407702207565308
[5/23] Train loss=0.18243958055973053
[10/23] Train loss=0.1403166949748993
[15/23] Train loss=0.1405010223388672
[20/23] Train loss=0.0832129493355751
Test set avg_accuracy=90.68% avg_sensitivity=81.70%, avg_specificity=93.39% avg_auc=0.9494
Fold[8] Epoch: 94 [94/100 (94%)] Train loss=0.134381 Test loss=0.268330 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12050054222345352
[5/23] Train loss=0.17777736485004425
[10/23] Train loss=0.14097264409065247
[15/23] Train loss=0.15052054822444916
[20/23] Train loss=0.09114927053451538
Test set avg_accuracy=90.53% avg_sensitivity=81.89%, avg_specificity=93.13% avg_auc=0.9486
Fold[8] Epoch: 95 [95/100 (95%)] Train loss=0.134197 Test loss=0.271231 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12332597374916077
[5/23] Train loss=0.17954343557357788
[10/23] Train loss=0.13276304304599762
[15/23] Train loss=0.14150631427764893
[20/23] Train loss=0.08485667407512665
Test set avg_accuracy=90.51% avg_sensitivity=80.31%, avg_specificity=93.58% avg_auc=0.9491
Fold[8] Epoch: 96 [96/100 (96%)] Train loss=0.130967 Test loss=0.271274 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12220761179924011
[5/23] Train loss=0.17445340752601624
[10/23] Train loss=0.13459479808807373
[15/23] Train loss=0.1356755942106247
[20/23] Train loss=0.08122166246175766
Test set avg_accuracy=90.76% avg_sensitivity=82.09%, avg_specificity=93.37% avg_auc=0.9491
Fold[8] Epoch: 97 [97/100 (97%)] Train loss=0.130073 Test loss=0.271455 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11803815513849258
[5/23] Train loss=0.17304329574108124
[10/23] Train loss=0.1282462328672409
[15/23] Train loss=0.1362362653017044
[20/23] Train loss=0.07803723216056824
Test set avg_accuracy=90.30% avg_sensitivity=82.54%, avg_specificity=92.64% avg_auc=0.9488
Fold[8] Epoch: 98 [98/100 (98%)] Train loss=0.125503 Test loss=0.278927 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12166354805231094
[5/23] Train loss=0.16938111186027527
[10/23] Train loss=0.125523179769516
[15/23] Train loss=0.12475793808698654
[20/23] Train loss=0.07766135782003403
Test set avg_accuracy=90.71% avg_sensitivity=83.04%, avg_specificity=93.01% avg_auc=0.9497
Best model saved!! Metric=35.72154310415483!!
Fold[8] Epoch: 99 [99/100 (99%)] Train loss=0.124286 Test loss=0.276748 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11930175125598907
[5/23] Train loss=0.1721014529466629
[10/23] Train loss=0.1265203356742859
[15/23] Train loss=0.12707602977752686
[20/23] Train loss=0.08372820168733597
Test set avg_accuracy=90.55% avg_sensitivity=83.23%, avg_specificity=92.75% avg_auc=0.9478
Fold[8] Epoch: 100 [100/100 (100%)] Train loss=0.124161 Test loss=0.282659 Current lr=[3.9999999999999996e-05]

Fold[8] Best Result: acc=90.70567986230637 sen=83.03571428571429, spe=93.01388266905508, auc=0.9496626628707909!
[0/23] Train loss=0.6994712948799133
[5/23] Train loss=0.6640993356704712
[10/23] Train loss=0.5838943719863892
[15/23] Train loss=0.5451682209968567
[20/23] Train loss=0.5628259778022766
Test set avg_accuracy=74.62% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6531
Best model saved!! Metric=-86.07252440074681!!
Fold[9] Epoch: 1 [1/100 (1%)] Train loss=0.571620 Test loss=0.578409 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5321177244186401
[5/23] Train loss=0.5594001412391663
[10/23] Train loss=0.49642083048820496
[15/23] Train loss=0.46097829937934875
[20/23] Train loss=0.45448067784309387
Test set avg_accuracy=76.63% avg_sensitivity=18.92%, avg_specificity=96.25% avg_auc=0.8262
Best model saved!! Metric=-51.57995124228926!!
Fold[9] Epoch: 2 [2/100 (2%)] Train loss=0.488949 Test loss=0.436230 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4263763725757599
[5/23] Train loss=0.45984947681427
[10/23] Train loss=0.46687051653862
[15/23] Train loss=0.3978300988674164
[20/23] Train loss=0.3884159326553345
Test set avg_accuracy=81.75% avg_sensitivity=53.37%, avg_specificity=91.40% avg_auc=0.8653
Best model saved!! Metric=-12.959176664835889!!
Fold[9] Epoch: 3 [3/100 (3%)] Train loss=0.424355 Test loss=0.389216 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3770858645439148
[5/23] Train loss=0.4217512607574463
[10/23] Train loss=0.41429951786994934
[15/23] Train loss=0.3679896295070648
[20/23] Train loss=0.36761173605918884
Test set avg_accuracy=82.48% avg_sensitivity=55.83%, avg_specificity=91.54% avg_auc=0.8781
Best model saved!! Metric=-8.332608757206721!!
Fold[9] Epoch: 4 [4/100 (4%)] Train loss=0.391527 Test loss=0.378320 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35382750630378723
[5/23] Train loss=0.4056799113750458
[10/23] Train loss=0.4310630261898041
[15/23] Train loss=0.35875529050827026
[20/23] Train loss=0.3615339696407318
Test set avg_accuracy=83.23% avg_sensitivity=55.14%, avg_specificity=92.79% avg_auc=0.8832
Best model saved!! Metric=-6.5172038792502995!!
Fold[9] Epoch: 5 [5/100 (5%)] Train loss=0.380832 Test loss=0.370042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33908677101135254
[5/23] Train loss=0.4040273427963257
[10/23] Train loss=0.4300050139427185
[15/23] Train loss=0.3454628884792328
[20/23] Train loss=0.36398568749427795
Test set avg_accuracy=83.00% avg_sensitivity=52.86%, avg_specificity=93.25% avg_auc=0.8878
Fold[9] Epoch: 6 [6/100 (6%)] Train loss=0.374504 Test loss=0.369149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.342308908700943
[5/23] Train loss=0.40146172046661377
[10/23] Train loss=0.42827513813972473
[15/23] Train loss=0.35526028275489807
[20/23] Train loss=0.34192532300949097
Test set avg_accuracy=83.23% avg_sensitivity=53.46%, avg_specificity=93.36% avg_auc=0.8903
Fold[9] Epoch: 7 [7/100 (7%)] Train loss=0.367525 Test loss=0.367607 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3415144085884094
[5/23] Train loss=0.41598403453826904
[10/23] Train loss=0.4168340861797333
[15/23] Train loss=0.36701980233192444
[20/23] Train loss=0.32578033208847046
Test set avg_accuracy=83.76% avg_sensitivity=56.02%, avg_specificity=93.20% avg_auc=0.8960
Best model saved!! Metric=-3.415775722743313!!
Fold[9] Epoch: 8 [8/100 (8%)] Train loss=0.366476 Test loss=0.355392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.335992693901062
[5/23] Train loss=0.4370327889919281
[10/23] Train loss=0.3916965425014496
[15/23] Train loss=0.34969446063041687
[20/23] Train loss=0.33613672852516174
Test set avg_accuracy=84.34% avg_sensitivity=60.53%, avg_specificity=92.44% avg_auc=0.9017
Best model saved!! Metric=1.4853335840446507!!
Fold[9] Epoch: 9 [9/100 (9%)] Train loss=0.364508 Test loss=0.339336 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31228265166282654
[5/23] Train loss=0.42425447702407837
[10/23] Train loss=0.37266045808792114
[15/23] Train loss=0.32870593667030334
[20/23] Train loss=0.3246592879295349
Test set avg_accuracy=84.60% avg_sensitivity=64.62%, avg_specificity=91.40% avg_auc=0.9046
Best model saved!! Metric=5.082467737942327!!
Fold[9] Epoch: 10 [10/100 (10%)] Train loss=0.350576 Test loss=0.333879 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30079391598701477
[5/23] Train loss=0.40763044357299805
[10/23] Train loss=0.35264095664024353
[15/23] Train loss=0.31780141592025757
[20/23] Train loss=0.30823442339897156
Test set avg_accuracy=84.84% avg_sensitivity=68.57%, avg_specificity=90.37% avg_auc=0.9091
Best model saved!! Metric=8.691304305545161!!
Fold[9] Epoch: 11 [11/100 (11%)] Train loss=0.337308 Test loss=0.327759 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2859759032726288
[5/23] Train loss=0.38317328691482544
[10/23] Train loss=0.3485758304595947
[15/23] Train loss=0.30367687344551086
[20/23] Train loss=0.28901177644729614
Test set avg_accuracy=85.32% avg_sensitivity=71.46%, avg_specificity=90.04% avg_auc=0.9130
Best model saved!! Metric=12.119432375136697!!
Fold[9] Epoch: 12 [12/100 (12%)] Train loss=0.324524 Test loss=0.323748 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28739455342292786
[5/23] Train loss=0.38646355271339417
[10/23] Train loss=0.3412964642047882
[15/23] Train loss=0.29379916191101074
[20/23] Train loss=0.26420578360557556
Test set avg_accuracy=86.17% avg_sensitivity=72.01%, avg_specificity=90.99% avg_auc=0.9180
Best model saved!! Metric=14.97158875027188!!
Fold[9] Epoch: 13 [13/100 (13%)] Train loss=0.313591 Test loss=0.314930 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2634660005569458
[5/23] Train loss=0.3557277023792267
[10/23] Train loss=0.3444472849369049
[15/23] Train loss=0.2875562012195587
[20/23] Train loss=0.25258052349090576
Test set avg_accuracy=86.40% avg_sensitivity=71.97%, avg_specificity=91.30% avg_auc=0.9223
Best model saved!! Metric=15.897832481373108!!
Fold[9] Epoch: 14 [14/100 (14%)] Train loss=0.306460 Test loss=0.306786 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2635916471481323
[5/23] Train loss=0.3671441376209259
[10/23] Train loss=0.33351027965545654
[15/23] Train loss=0.28802549839019775
[20/23] Train loss=0.25416749715805054
Test set avg_accuracy=86.42% avg_sensitivity=71.59%, avg_specificity=91.46% avg_auc=0.9238
Fold[9] Epoch: 15 [15/100 (15%)] Train loss=0.302663 Test loss=0.304859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2579987645149231
[5/23] Train loss=0.36110153794288635
[10/23] Train loss=0.3363039195537567
[15/23] Train loss=0.29007360339164734
[20/23] Train loss=0.2465958446264267
Test set avg_accuracy=86.68% avg_sensitivity=71.87%, avg_specificity=91.71% avg_auc=0.9257
Best model saved!! Metric=16.839979586585656!!
Fold[9] Epoch: 16 [16/100 (16%)] Train loss=0.302897 Test loss=0.299802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2552155554294586
[5/23] Train loss=0.36464834213256836
[10/23] Train loss=0.3331860303878784
[15/23] Train loss=0.2799646854400635
[20/23] Train loss=0.24399617314338684
Test set avg_accuracy=87.06% avg_sensitivity=73.31%, avg_specificity=91.73% avg_auc=0.9271
Best model saved!! Metric=18.810615259624434!!
Fold[9] Epoch: 17 [17/100 (17%)] Train loss=0.297821 Test loss=0.297534 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2427237331867218
[5/23] Train loss=0.36502569913864136
[10/23] Train loss=0.3226954936981201
[15/23] Train loss=0.28268030285835266
[20/23] Train loss=0.23914089798927307
Test set avg_accuracy=87.17% avg_sensitivity=73.22%, avg_specificity=91.92% avg_auc=0.9275
Best model saved!! Metric=19.064326504262805!!
Fold[9] Epoch: 18 [18/100 (18%)] Train loss=0.292492 Test loss=0.295707 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23794350028038025
[5/23] Train loss=0.36353570222854614
[10/23] Train loss=0.3036958575248718
[15/23] Train loss=0.26673179864883423
[20/23] Train loss=0.2417130023241043
Test set avg_accuracy=87.33% avg_sensitivity=76.48%, avg_specificity=91.02% avg_auc=0.9294
Best model saved!! Metric=21.764417617937298!!
Fold[9] Epoch: 19 [19/100 (19%)] Train loss=0.288141 Test loss=0.296524 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24187394976615906
[5/23] Train loss=0.34646913409233093
[10/23] Train loss=0.31476226449012756
[15/23] Train loss=0.25870659947395325
[20/23] Train loss=0.23352444171905518
Test set avg_accuracy=87.72% avg_sensitivity=77.03%, avg_specificity=91.35% avg_auc=0.9302
Best model saved!! Metric=23.11624563446604!!
Fold[9] Epoch: 20 [20/100 (20%)] Train loss=0.284121 Test loss=0.292672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2317543625831604
[5/23] Train loss=0.3456343710422516
[10/23] Train loss=0.29653894901275635
[15/23] Train loss=0.25896480679512024
[20/23] Train loss=0.23139838874340057
Test set avg_accuracy=88.07% avg_sensitivity=77.78%, avg_specificity=91.57% avg_auc=0.9312
Best model saved!! Metric=24.541497612370463!!
Fold[9] Epoch: 21 [21/100 (21%)] Train loss=0.277587 Test loss=0.291134 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21890899538993835
[5/23] Train loss=0.3402210772037506
[10/23] Train loss=0.29374250769615173
[15/23] Train loss=0.2544029653072357
[20/23] Train loss=0.23079223930835724
Test set avg_accuracy=87.94% avg_sensitivity=77.73%, avg_specificity=91.41% avg_auc=0.9325
Fold[9] Epoch: 22 [22/100 (22%)] Train loss=0.274744 Test loss=0.288027 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22257962822914124
[5/23] Train loss=0.332736611366272
[10/23] Train loss=0.29791706800460815
[15/23] Train loss=0.2610946595668793
[20/23] Train loss=0.21587660908699036
Test set avg_accuracy=87.86% avg_sensitivity=76.62%, avg_specificity=91.68% avg_auc=0.9333
Fold[9] Epoch: 23 [23/100 (23%)] Train loss=0.272365 Test loss=0.284666 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22894133627414703
[5/23] Train loss=0.3381875455379486
[10/23] Train loss=0.2869790196418762
[15/23] Train loss=0.26524266600608826
[20/23] Train loss=0.21884451806545258
Test set avg_accuracy=87.78% avg_sensitivity=75.22%, avg_specificity=92.05% avg_auc=0.9335
Fold[9] Epoch: 24 [24/100 (24%)] Train loss=0.272593 Test loss=0.283476 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22482745349407196
[5/23] Train loss=0.340425580739975
[10/23] Train loss=0.30004748702049255
[15/23] Train loss=0.25793546438217163
[20/23] Train loss=0.22591948509216309
Test set avg_accuracy=88.01% avg_sensitivity=75.92%, avg_specificity=92.13% avg_auc=0.9337
Fold[9] Epoch: 25 [25/100 (25%)] Train loss=0.272570 Test loss=0.283373 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21797187626361847
[5/23] Train loss=0.34709909558296204
[10/23] Train loss=0.29139629006385803
[15/23] Train loss=0.2623738944530487
[20/23] Train loss=0.22400973737239838
Test set avg_accuracy=88.39% avg_sensitivity=74.66%, avg_specificity=93.06% avg_auc=0.9347
Fold[9] Epoch: 26 [26/100 (26%)] Train loss=0.271717 Test loss=0.279267 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22030554711818695
[5/23] Train loss=0.3349558115005493
[10/23] Train loss=0.2908962368965149
[15/23] Train loss=0.2536877989768982
[20/23] Train loss=0.2233828455209732
Test set avg_accuracy=88.24% avg_sensitivity=76.75%, avg_specificity=92.14% avg_auc=0.9353
Best model saved!! Metric=24.663250162797503!!
Fold[9] Epoch: 27 [27/100 (27%)] Train loss=0.267826 Test loss=0.280888 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2159317433834076
[5/23] Train loss=0.33277860283851624
[10/23] Train loss=0.2861890494823456
[15/23] Train loss=0.24535635113716125
[20/23] Train loss=0.2136920988559723
Test set avg_accuracy=88.34% avg_sensitivity=77.08%, avg_specificity=92.17% avg_auc=0.9362
Best model saved!! Metric=25.21255546663403!!
Fold[9] Epoch: 28 [28/100 (28%)] Train loss=0.261208 Test loss=0.279962 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2149631232023239
[5/23] Train loss=0.3173677623271942
[10/23] Train loss=0.2754945755004883
[15/23] Train loss=0.24199824035167694
[20/23] Train loss=0.20549127459526062
Test set avg_accuracy=88.29% avg_sensitivity=76.71%, avg_specificity=92.24% avg_auc=0.9358
Fold[9] Epoch: 29 [29/100 (29%)] Train loss=0.259459 Test loss=0.280307 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21647655963897705
[5/23] Train loss=0.3300178050994873
[10/23] Train loss=0.28587210178375244
[15/23] Train loss=0.24862827360630035
[20/23] Train loss=0.2152826339006424
Test set avg_accuracy=88.54% avg_sensitivity=75.96%, avg_specificity=92.82% avg_auc=0.9366
Fold[9] Epoch: 30 [30/100 (30%)] Train loss=0.259781 Test loss=0.277006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2137940227985382
[5/23] Train loss=0.32297661900520325
[10/23] Train loss=0.276792973279953
[15/23] Train loss=0.24053898453712463
[20/23] Train loss=0.20935983955860138
Test set avg_accuracy=88.24% avg_sensitivity=74.48%, avg_specificity=92.92% avg_auc=0.9362
Fold[9] Epoch: 31 [31/100 (31%)] Train loss=0.254230 Test loss=0.278764 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2096782773733139
[5/23] Train loss=0.31859156489372253
[10/23] Train loss=0.2847939431667328
[15/23] Train loss=0.24608176946640015
[20/23] Train loss=0.20959395170211792
Test set avg_accuracy=88.21% avg_sensitivity=73.78%, avg_specificity=93.12% avg_auc=0.9361
Fold[9] Epoch: 32 [32/100 (32%)] Train loss=0.256763 Test loss=0.277664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21174772083759308
[5/23] Train loss=0.32405170798301697
[10/23] Train loss=0.2731044292449951
[15/23] Train loss=0.23971453309059143
[20/23] Train loss=0.21069984138011932
Test set avg_accuracy=88.57% avg_sensitivity=74.11%, avg_specificity=93.49% avg_auc=0.9368
Fold[9] Epoch: 33 [33/100 (33%)] Train loss=0.253298 Test loss=0.276301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2156360000371933
[5/23] Train loss=0.3211213946342468
[10/23] Train loss=0.28475943207740784
[15/23] Train loss=0.24656938016414642
[20/23] Train loss=0.20281550288200378
Test set avg_accuracy=88.51% avg_sensitivity=74.06%, avg_specificity=93.42% avg_auc=0.9368
Fold[9] Epoch: 34 [34/100 (34%)] Train loss=0.252926 Test loss=0.276487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2000901997089386
[5/23] Train loss=0.312970370054245
[10/23] Train loss=0.2753579020500183
[15/23] Train loss=0.23258358240127563
[20/23] Train loss=0.2050410509109497
Test set avg_accuracy=88.68% avg_sensitivity=75.03%, avg_specificity=93.33% avg_auc=0.9382
Fold[9] Epoch: 35 [35/100 (35%)] Train loss=0.250259 Test loss=0.273751 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21138910949230194
[5/23] Train loss=0.32069113850593567
[10/23] Train loss=0.2640847861766815
[15/23] Train loss=0.23889759182929993
[20/23] Train loss=0.20282024145126343
Test set avg_accuracy=88.61% avg_sensitivity=76.29%, avg_specificity=92.81% avg_auc=0.9386
Best model saved!! Metric=25.5695999514191!!
Fold[9] Epoch: 36 [36/100 (36%)] Train loss=0.249195 Test loss=0.275040 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21119119226932526
[5/23] Train loss=0.31480416655540466
[10/23] Train loss=0.27959978580474854
[15/23] Train loss=0.24431335926055908
[20/23] Train loss=0.2112342268228531
Test set avg_accuracy=88.39% avg_sensitivity=73.69%, avg_specificity=93.39% avg_auc=0.9369
Fold[9] Epoch: 37 [37/100 (37%)] Train loss=0.247091 Test loss=0.276841 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20584805309772491
[5/23] Train loss=0.3142325282096863
[10/23] Train loss=0.26928049325942993
[15/23] Train loss=0.2399982511997223
[20/23] Train loss=0.19937793910503387
Test set avg_accuracy=88.19% avg_sensitivity=71.92%, avg_specificity=93.72% avg_auc=0.9370
Fold[9] Epoch: 38 [38/100 (38%)] Train loss=0.245461 Test loss=0.275844 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20008040964603424
[5/23] Train loss=0.3111210763454437
[10/23] Train loss=0.259335458278656
[15/23] Train loss=0.23523487150669098
[20/23] Train loss=0.20413853228092194
Test set avg_accuracy=88.53% avg_sensitivity=73.64%, avg_specificity=93.60% avg_auc=0.9377
Fold[9] Epoch: 39 [39/100 (39%)] Train loss=0.243404 Test loss=0.274332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19991493225097656
[5/23] Train loss=0.3124499022960663
[10/23] Train loss=0.25590986013412476
[15/23] Train loss=0.2392156422138214
[20/23] Train loss=0.19309955835342407
Test set avg_accuracy=88.48% avg_sensitivity=72.80%, avg_specificity=93.82% avg_auc=0.9388
Fold[9] Epoch: 40 [40/100 (40%)] Train loss=0.241106 Test loss=0.271798 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19936788082122803
[5/23] Train loss=0.3189450204372406
[10/23] Train loss=0.2498088777065277
[15/23] Train loss=0.23879790306091309
[20/23] Train loss=0.19809465110301971
Test set avg_accuracy=88.59% avg_sensitivity=73.08%, avg_specificity=93.86% avg_auc=0.9389
Fold[9] Epoch: 41 [41/100 (41%)] Train loss=0.242228 Test loss=0.271719 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19429193437099457
[5/23] Train loss=0.3093909025192261
[10/23] Train loss=0.2625828683376312
[15/23] Train loss=0.24310672283172607
[20/23] Train loss=0.19656145572662354
Test set avg_accuracy=88.31% avg_sensitivity=73.13%, avg_specificity=93.47% avg_auc=0.9377
Fold[9] Epoch: 42 [42/100 (42%)] Train loss=0.238273 Test loss=0.274488 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19994476437568665
[5/23] Train loss=0.30702999234199524
[10/23] Train loss=0.253592848777771
[15/23] Train loss=0.22500286996364594
[20/23] Train loss=0.18568529188632965
Test set avg_accuracy=88.07% avg_sensitivity=73.41%, avg_specificity=93.06% avg_auc=0.9373
Fold[9] Epoch: 43 [43/100 (43%)] Train loss=0.235260 Test loss=0.277317 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20399467647075653
[5/23] Train loss=0.31794115900993347
[10/23] Train loss=0.25401610136032104
[15/23] Train loss=0.23251235485076904
[20/23] Train loss=0.1895986944437027
Test set avg_accuracy=88.65% avg_sensitivity=74.76%, avg_specificity=93.37% avg_auc=0.9381
Fold[9] Epoch: 44 [44/100 (44%)] Train loss=0.236234 Test loss=0.274360 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20031507313251495
[5/23] Train loss=0.3043293058872223
[10/23] Train loss=0.2514553666114807
[15/23] Train loss=0.22290386259555817
[20/23] Train loss=0.18680645525455475
Test set avg_accuracy=88.44% avg_sensitivity=74.43%, avg_specificity=93.20% avg_auc=0.9378
Fold[9] Epoch: 45 [45/100 (45%)] Train loss=0.233837 Test loss=0.275288 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1957653909921646
[5/23] Train loss=0.30483630299568176
[10/23] Train loss=0.2519989013671875
[15/23] Train loss=0.227539524435997
[20/23] Train loss=0.18889351189136505
Test set avg_accuracy=88.54% avg_sensitivity=73.83%, avg_specificity=93.55% avg_auc=0.9380
Fold[9] Epoch: 46 [46/100 (46%)] Train loss=0.232751 Test loss=0.274242 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19382448494434357
[5/23] Train loss=0.30089330673217773
[10/23] Train loss=0.24906668066978455
[15/23] Train loss=0.22477233409881592
[20/23] Train loss=0.18293368816375732
Test set avg_accuracy=88.54% avg_sensitivity=72.76%, avg_specificity=93.91% avg_auc=0.9363
Fold[9] Epoch: 47 [47/100 (47%)] Train loss=0.231311 Test loss=0.277061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19673021137714386
[5/23] Train loss=0.30305978655815125
[10/23] Train loss=0.2482580691576004
[15/23] Train loss=0.22831781208515167
[20/23] Train loss=0.1742994338274002
Test set avg_accuracy=88.55% avg_sensitivity=73.50%, avg_specificity=93.67% avg_auc=0.9374
Fold[9] Epoch: 48 [48/100 (48%)] Train loss=0.229015 Test loss=0.274571 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18619678914546967
[5/23] Train loss=0.2945988178253174
[10/23] Train loss=0.24156485497951508
[15/23] Train loss=0.219741553068161
[20/23] Train loss=0.1763572096824646
Test set avg_accuracy=88.87% avg_sensitivity=74.66%, avg_specificity=93.71% avg_auc=0.9380
Fold[9] Epoch: 49 [49/100 (49%)] Train loss=0.226473 Test loss=0.275108 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19025695323944092
[5/23] Train loss=0.303533673286438
[10/23] Train loss=0.24333447217941284
[15/23] Train loss=0.22652742266654968
[20/23] Train loss=0.17461270093917847
Test set avg_accuracy=88.31% avg_sensitivity=74.24%, avg_specificity=93.09% avg_auc=0.9359
Fold[9] Epoch: 50 [50/100 (50%)] Train loss=0.226856 Test loss=0.280112 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19285660982131958
[5/23] Train loss=0.308258593082428
[10/23] Train loss=0.2459286004304886
[15/23] Train loss=0.21941635012626648
[20/23] Train loss=0.1873176246881485
Test set avg_accuracy=88.44% avg_sensitivity=73.50%, avg_specificity=93.52% avg_auc=0.9373
Fold[9] Epoch: 51 [51/100 (51%)] Train loss=0.227215 Test loss=0.275917 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1889895796775818
[5/23] Train loss=0.2969188392162323
[10/23] Train loss=0.24620234966278076
[15/23] Train loss=0.2272728532552719
[20/23] Train loss=0.17787420749664307
Test set avg_accuracy=88.50% avg_sensitivity=73.92%, avg_specificity=93.45% avg_auc=0.9365
Fold[9] Epoch: 52 [52/100 (52%)] Train loss=0.225168 Test loss=0.276857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19092564284801483
[5/23] Train loss=0.29295146465301514
[10/23] Train loss=0.24209748208522797
[15/23] Train loss=0.21780814230442047
[20/23] Train loss=0.1744094341993332
Test set avg_accuracy=88.53% avg_sensitivity=73.87%, avg_specificity=93.52% avg_auc=0.9359
Fold[9] Epoch: 53 [53/100 (53%)] Train loss=0.220587 Test loss=0.279006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18811339139938354
[5/23] Train loss=0.2887624204158783
[10/23] Train loss=0.22598569095134735
[15/23] Train loss=0.2212096005678177
[20/23] Train loss=0.17889109253883362
Test set avg_accuracy=88.61% avg_sensitivity=73.50%, avg_specificity=93.75% avg_auc=0.9342
Fold[9] Epoch: 54 [54/100 (54%)] Train loss=0.219127 Test loss=0.282186 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1774357557296753
[5/23] Train loss=0.2892597019672394
[10/23] Train loss=0.24109596014022827
[15/23] Train loss=0.21765026450157166
[20/23] Train loss=0.17070522904396057
Test set avg_accuracy=88.41% avg_sensitivity=72.11%, avg_specificity=93.96% avg_auc=0.9363
Fold[9] Epoch: 55 [55/100 (55%)] Train loss=0.217177 Test loss=0.278543 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18186816573143005
[5/23] Train loss=0.2958056628704071
[10/23] Train loss=0.23607711493968964
[15/23] Train loss=0.2205447256565094
[20/23] Train loss=0.16584935784339905
Test set avg_accuracy=88.27% avg_sensitivity=72.76%, avg_specificity=93.55% avg_auc=0.9347
Fold[9] Epoch: 56 [56/100 (56%)] Train loss=0.217203 Test loss=0.281687 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1788618117570877
[5/23] Train loss=0.29272857308387756
[10/23] Train loss=0.23900459706783295
[15/23] Train loss=0.2170482873916626
[20/23] Train loss=0.17216520011425018
Test set avg_accuracy=88.09% avg_sensitivity=70.53%, avg_specificity=94.07% avg_auc=0.9345
Fold[9] Epoch: 57 [57/100 (57%)] Train loss=0.216502 Test loss=0.281584 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17921917140483856
[5/23] Train loss=0.2988656461238861
[10/23] Train loss=0.23292647302150726
[15/23] Train loss=0.2178572416305542
[20/23] Train loss=0.16292552649974823
Test set avg_accuracy=88.14% avg_sensitivity=72.25%, avg_specificity=93.55% avg_auc=0.9348
Fold[9] Epoch: 58 [58/100 (58%)] Train loss=0.215839 Test loss=0.282990 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18329115211963654
[5/23] Train loss=0.2886439561843872
[10/23] Train loss=0.22678883373737335
[15/23] Train loss=0.21727603673934937
[20/23] Train loss=0.1659720242023468
Test set avg_accuracy=88.32% avg_sensitivity=73.18%, avg_specificity=93.47% avg_auc=0.9348
Fold[9] Epoch: 59 [59/100 (59%)] Train loss=0.214403 Test loss=0.283646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17651276290416718
[5/23] Train loss=0.27602526545524597
[10/23] Train loss=0.22723078727722168
[15/23] Train loss=0.21613840758800507
[20/23] Train loss=0.17231157422065735
Test set avg_accuracy=87.94% avg_sensitivity=72.48%, avg_specificity=93.20% avg_auc=0.9341
Fold[9] Epoch: 60 [60/100 (60%)] Train loss=0.207979 Test loss=0.285403 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1829371601343155
[5/23] Train loss=0.28197169303894043
[10/23] Train loss=0.22451382875442505
[15/23] Train loss=0.2136743664741516
[20/23] Train loss=0.16032332181930542
Test set avg_accuracy=88.29% avg_sensitivity=73.13%, avg_specificity=93.45% avg_auc=0.9340
Fold[9] Epoch: 61 [61/100 (61%)] Train loss=0.208354 Test loss=0.285619 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17254357039928436
[5/23] Train loss=0.2819620370864868
[10/23] Train loss=0.21821124851703644
[15/23] Train loss=0.22180266678333282
[20/23] Train loss=0.1692734658718109
Test set avg_accuracy=88.20% avg_sensitivity=72.80%, avg_specificity=93.44% avg_auc=0.9336
Fold[9] Epoch: 62 [62/100 (62%)] Train loss=0.207286 Test loss=0.285927 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1736268550157547
[5/23] Train loss=0.2809174954891205
[10/23] Train loss=0.2180679738521576
[15/23] Train loss=0.2117319256067276
[20/23] Train loss=0.16482698917388916
Test set avg_accuracy=88.48% avg_sensitivity=72.99%, avg_specificity=93.75% avg_auc=0.9334
Fold[9] Epoch: 63 [63/100 (63%)] Train loss=0.203459 Test loss=0.286574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17839159071445465
[5/23] Train loss=0.2751650810241699
[10/23] Train loss=0.21564678847789764
[15/23] Train loss=0.20903581380844116
[20/23] Train loss=0.15504781901836395
Test set avg_accuracy=88.15% avg_sensitivity=72.76%, avg_specificity=93.39% avg_auc=0.9316
Fold[9] Epoch: 64 [64/100 (64%)] Train loss=0.204253 Test loss=0.291776 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17142067849636078
[5/23] Train loss=0.2739061117172241
[10/23] Train loss=0.2215515822172165
[15/23] Train loss=0.2054489552974701
[20/23] Train loss=0.15355284512043
Test set avg_accuracy=88.48% avg_sensitivity=73.73%, avg_specificity=93.50% avg_auc=0.9353
Fold[9] Epoch: 65 [65/100 (65%)] Train loss=0.201957 Test loss=0.283663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17089863121509552
[5/23] Train loss=0.281072199344635
[10/23] Train loss=0.21861772239208221
[15/23] Train loss=0.19811657071113586
[20/23] Train loss=0.16286511719226837
Test set avg_accuracy=88.31% avg_sensitivity=72.71%, avg_specificity=93.61% avg_auc=0.9336
Fold[9] Epoch: 66 [66/100 (66%)] Train loss=0.200743 Test loss=0.287350 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16679222881793976
[5/23] Train loss=0.2661100924015045
[10/23] Train loss=0.20989887416362762
[15/23] Train loss=0.1936180591583252
[20/23] Train loss=0.15537913143634796
Test set avg_accuracy=88.15% avg_sensitivity=71.92%, avg_specificity=93.67% avg_auc=0.9324
Fold[9] Epoch: 67 [67/100 (67%)] Train loss=0.198448 Test loss=0.289765 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17857934534549713
[5/23] Train loss=0.2599358558654785
[10/23] Train loss=0.20174749195575714
[15/23] Train loss=0.19916684925556183
[20/23] Train loss=0.15672890841960907
Test set avg_accuracy=88.39% avg_sensitivity=71.64%, avg_specificity=94.09% avg_auc=0.9326
Fold[9] Epoch: 68 [68/100 (68%)] Train loss=0.195238 Test loss=0.290673 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17594552040100098
[5/23] Train loss=0.26219111680984497
[10/23] Train loss=0.20857849717140198
[15/23] Train loss=0.20149467885494232
[20/23] Train loss=0.14873507618904114
Test set avg_accuracy=88.58% avg_sensitivity=72.66%, avg_specificity=93.99% avg_auc=0.9328
Fold[9] Epoch: 69 [69/100 (69%)] Train loss=0.195189 Test loss=0.288815 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16474387049674988
[5/23] Train loss=0.2601298689842224
[10/23] Train loss=0.20698831975460052
[15/23] Train loss=0.20259203016757965
[20/23] Train loss=0.1456020623445511
Test set avg_accuracy=88.48% avg_sensitivity=71.97%, avg_specificity=94.10% avg_auc=0.9342
Fold[9] Epoch: 70 [70/100 (70%)] Train loss=0.192490 Test loss=0.287378 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1655825972557068
[5/23] Train loss=0.2603070139884949
[10/23] Train loss=0.20403951406478882
[15/23] Train loss=0.19956102967262268
[20/23] Train loss=0.15042997896671295
Test set avg_accuracy=88.61% avg_sensitivity=72.90%, avg_specificity=93.96% avg_auc=0.9340
Fold[9] Epoch: 71 [71/100 (71%)] Train loss=0.191646 Test loss=0.287186 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16324645280838013
[5/23] Train loss=0.2678855061531067
[10/23] Train loss=0.1947784423828125
[15/23] Train loss=0.1936921328306198
[20/23] Train loss=0.14446179568767548
Test set avg_accuracy=88.46% avg_sensitivity=72.29%, avg_specificity=93.96% avg_auc=0.9333
Fold[9] Epoch: 72 [72/100 (72%)] Train loss=0.189791 Test loss=0.289078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16662634909152985
[5/23] Train loss=0.2650427222251892
[10/23] Train loss=0.20534802973270416
[15/23] Train loss=0.19252246618270874
[20/23] Train loss=0.14547717571258545
Test set avg_accuracy=88.07% avg_sensitivity=71.59%, avg_specificity=93.67% avg_auc=0.9323
Fold[9] Epoch: 73 [73/100 (73%)] Train loss=0.191024 Test loss=0.291056 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16793376207351685
[5/23] Train loss=0.2560880780220032
[10/23] Train loss=0.19811774790287018
[15/23] Train loss=0.1910502165555954
[20/23] Train loss=0.14512693881988525
Test set avg_accuracy=88.05% avg_sensitivity=71.92%, avg_specificity=93.53% avg_auc=0.9323
Fold[9] Epoch: 74 [74/100 (74%)] Train loss=0.183693 Test loss=0.292819 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15479296445846558
[5/23] Train loss=0.23519660532474518
[10/23] Train loss=0.1827496737241745
[15/23] Train loss=0.19267109036445618
[20/23] Train loss=0.14879110455513
Test set avg_accuracy=88.04% avg_sensitivity=72.76%, avg_specificity=93.23% avg_auc=0.9321
Fold[9] Epoch: 75 [75/100 (75%)] Train loss=0.183634 Test loss=0.295414 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1649412214756012
[5/23] Train loss=0.25352752208709717
[10/23] Train loss=0.20526520907878876
[15/23] Train loss=0.1931486427783966
[20/23] Train loss=0.14715246856212616
Test set avg_accuracy=87.76% avg_sensitivity=72.90%, avg_specificity=92.82% avg_auc=0.9311
Fold[9] Epoch: 76 [76/100 (76%)] Train loss=0.183332 Test loss=0.295797 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1588912159204483
[5/23] Train loss=0.2484189122915268
[10/23] Train loss=0.19323667883872986
[15/23] Train loss=0.1987239122390747
[20/23] Train loss=0.13409626483917236
Test set avg_accuracy=88.31% avg_sensitivity=72.52%, avg_specificity=93.67% avg_auc=0.9331
Fold[9] Epoch: 77 [77/100 (77%)] Train loss=0.180356 Test loss=0.293094 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1594877690076828
[5/23] Train loss=0.2513425052165985
[10/23] Train loss=0.18997041881084442
[15/23] Train loss=0.1870572715997696
[20/23] Train loss=0.13799138367176056
Test set avg_accuracy=87.87% avg_sensitivity=71.22%, avg_specificity=93.53% avg_auc=0.9302
Fold[9] Epoch: 78 [78/100 (78%)] Train loss=0.178203 Test loss=0.298770 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16024695336818695
[5/23] Train loss=0.2420981526374817
[10/23] Train loss=0.19109860062599182
[15/23] Train loss=0.18754175305366516
[20/23] Train loss=0.13287046551704407
Test set avg_accuracy=87.75% avg_sensitivity=71.08%, avg_specificity=93.42% avg_auc=0.9281
Fold[9] Epoch: 79 [79/100 (79%)] Train loss=0.176408 Test loss=0.303575 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15589135885238647
[5/23] Train loss=0.23781485855579376
[10/23] Train loss=0.18100404739379883
[15/23] Train loss=0.18669965863227844
[20/23] Train loss=0.14078740775585175
Test set avg_accuracy=88.09% avg_sensitivity=72.34%, avg_specificity=93.45% avg_auc=0.9307
Fold[9] Epoch: 80 [80/100 (80%)] Train loss=0.174019 Test loss=0.301250 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16432377696037292
[5/23] Train loss=0.23508433997631073
[10/23] Train loss=0.18653936684131622
[15/23] Train loss=0.17884093523025513
[20/23] Train loss=0.1318744719028473
Test set avg_accuracy=88.18% avg_sensitivity=72.76%, avg_specificity=93.42% avg_auc=0.9302
Fold[9] Epoch: 81 [81/100 (81%)] Train loss=0.172475 Test loss=0.302307 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1519891619682312
[5/23] Train loss=0.22604183852672577
[10/23] Train loss=0.1804921180009842
[15/23] Train loss=0.18449930846691132
[20/23] Train loss=0.13483723998069763
Test set avg_accuracy=87.88% avg_sensitivity=72.85%, avg_specificity=92.99% avg_auc=0.9319
Fold[9] Epoch: 82 [82/100 (82%)] Train loss=0.170419 Test loss=0.300533 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15227799117565155
[5/23] Train loss=0.2425202876329422
[10/23] Train loss=0.17462016642093658
[15/23] Train loss=0.17470213770866394
[20/23] Train loss=0.13600175082683563
Test set avg_accuracy=87.96% avg_sensitivity=71.55%, avg_specificity=93.55% avg_auc=0.9285
Fold[9] Epoch: 83 [83/100 (83%)] Train loss=0.169375 Test loss=0.307058 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15421117842197418
[5/23] Train loss=0.21990592777729034
[10/23] Train loss=0.16881173849105835
[15/23] Train loss=0.1781422644853592
[20/23] Train loss=0.13562491536140442
Test set avg_accuracy=88.06% avg_sensitivity=71.32%, avg_specificity=93.75% avg_auc=0.9276
Fold[9] Epoch: 84 [84/100 (84%)] Train loss=0.166511 Test loss=0.309582 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15249966084957123
[5/23] Train loss=0.22337010502815247
[10/23] Train loss=0.17684142291545868
[15/23] Train loss=0.1744503378868103
[20/23] Train loss=0.13040359318256378
Test set avg_accuracy=88.17% avg_sensitivity=73.50%, avg_specificity=93.15% avg_auc=0.9295
Fold[9] Epoch: 85 [85/100 (85%)] Train loss=0.165345 Test loss=0.305793 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14519482851028442
[5/23] Train loss=0.2138197273015976
[10/23] Train loss=0.17352096736431122
[15/23] Train loss=0.17570914328098297
[20/23] Train loss=0.1260489672422409
Test set avg_accuracy=88.17% avg_sensitivity=73.22%, avg_specificity=93.25% avg_auc=0.9307
Fold[9] Epoch: 86 [86/100 (86%)] Train loss=0.161096 Test loss=0.304443 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1455167531967163
[5/23] Train loss=0.21411243081092834
[10/23] Train loss=0.16504867374897003
[15/23] Train loss=0.17435172200202942
[20/23] Train loss=0.12522321939468384
Test set avg_accuracy=88.15% avg_sensitivity=74.06%, avg_specificity=92.95% avg_auc=0.9301
Fold[9] Epoch: 87 [87/100 (87%)] Train loss=0.160699 Test loss=0.306543 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14716725051403046
[5/23] Train loss=0.21401722729206085
[10/23] Train loss=0.1620238870382309
[15/23] Train loss=0.17272788286209106
[20/23] Train loss=0.13160113990306854
Test set avg_accuracy=87.63% avg_sensitivity=73.04%, avg_specificity=92.60% avg_auc=0.9302
Fold[9] Epoch: 88 [88/100 (88%)] Train loss=0.158288 Test loss=0.309777 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1451684981584549
[5/23] Train loss=0.21722108125686646
[10/23] Train loss=0.16542215645313263
[15/23] Train loss=0.15991836786270142
[20/23] Train loss=0.11797457933425903
Test set avg_accuracy=87.72% avg_sensitivity=71.59%, avg_specificity=93.20% avg_auc=0.9261
Fold[9] Epoch: 89 [89/100 (89%)] Train loss=0.154497 Test loss=0.316400 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14763984084129333
[5/23] Train loss=0.2126626819372177
[10/23] Train loss=0.15815110504627228
[15/23] Train loss=0.16282925009727478
[20/23] Train loss=0.12529854476451874
Test set avg_accuracy=87.71% avg_sensitivity=71.55%, avg_specificity=93.20% avg_auc=0.9262
Fold[9] Epoch: 90 [90/100 (90%)] Train loss=0.153973 Test loss=0.315854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14158228039741516
[5/23] Train loss=0.20521500706672668
[10/23] Train loss=0.1658526211977005
[15/23] Train loss=0.17161825299263
[20/23] Train loss=0.12867306172847748
Test set avg_accuracy=87.36% avg_sensitivity=70.66%, avg_specificity=93.04% avg_auc=0.9248
Fold[9] Epoch: 91 [91/100 (91%)] Train loss=0.151741 Test loss=0.323237 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14052779972553253
[5/23] Train loss=0.19961805641651154
[10/23] Train loss=0.1541236788034439
[15/23] Train loss=0.16293005645275116
[20/23] Train loss=0.11975663155317307
Test set avg_accuracy=87.66% avg_sensitivity=71.55%, avg_specificity=93.14% avg_auc=0.9263
Fold[9] Epoch: 92 [92/100 (92%)] Train loss=0.150608 Test loss=0.321855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14147132635116577
[5/23] Train loss=0.20538705587387085
[10/23] Train loss=0.15728601813316345
[15/23] Train loss=0.15964500606060028
[20/23] Train loss=0.11881258338689804
Test set avg_accuracy=87.69% avg_sensitivity=71.08%, avg_specificity=93.34% avg_auc=0.9258
Fold[9] Epoch: 93 [93/100 (93%)] Train loss=0.147961 Test loss=0.322789 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13375549018383026
[5/23] Train loss=0.20655937492847443
[10/23] Train loss=0.1612733006477356
[15/23] Train loss=0.15738345682621002
[20/23] Train loss=0.11134877800941467
Test set avg_accuracy=87.86% avg_sensitivity=71.73%, avg_specificity=93.34% avg_auc=0.9255
Fold[9] Epoch: 94 [94/100 (94%)] Train loss=0.146748 Test loss=0.321787 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.139178067445755
[5/23] Train loss=0.2015382945537567
[10/23] Train loss=0.1497100293636322
[15/23] Train loss=0.1520901769399643
[20/23] Train loss=0.10787800699472427
Test set avg_accuracy=87.71% avg_sensitivity=70.80%, avg_specificity=93.45% avg_auc=0.9254
Fold[9] Epoch: 95 [95/100 (95%)] Train loss=0.144068 Test loss=0.323491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1344401091337204
[5/23] Train loss=0.19777125120162964
[10/23] Train loss=0.1567094922065735
[15/23] Train loss=0.1561904102563858
[20/23] Train loss=0.11487322300672531
Test set avg_accuracy=87.78% avg_sensitivity=71.36%, avg_specificity=93.36% avg_auc=0.9245
Fold[9] Epoch: 96 [96/100 (96%)] Train loss=0.142984 Test loss=0.328823 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1340087205171585
[5/23] Train loss=0.19886179268360138
[10/23] Train loss=0.15565194189548492
[15/23] Train loss=0.14931471645832062
[20/23] Train loss=0.1097978726029396
Test set avg_accuracy=87.40% avg_sensitivity=70.29%, avg_specificity=93.22% avg_auc=0.9259
Fold[9] Epoch: 97 [97/100 (97%)] Train loss=0.140613 Test loss=0.323094 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13152915239334106
[5/23] Train loss=0.18120530247688293
[10/23] Train loss=0.14671590924263
[15/23] Train loss=0.14957201480865479
[20/23] Train loss=0.10882196575403214
Test set avg_accuracy=87.40% avg_sensitivity=72.57%, avg_specificity=92.44% avg_auc=0.9279
Fold[9] Epoch: 98 [98/100 (98%)] Train loss=0.136922 Test loss=0.322276 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13049371540546417
[5/23] Train loss=0.19272097945213318
[10/23] Train loss=0.14077261090278625
[15/23] Train loss=0.14308176934719086
[20/23] Train loss=0.10815013200044632
Test set avg_accuracy=87.93% avg_sensitivity=72.34%, avg_specificity=93.23% avg_auc=0.9274
Fold[9] Epoch: 99 [99/100 (99%)] Train loss=0.136864 Test loss=0.323536 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12310682237148285
[5/23] Train loss=0.18382330238819122
[10/23] Train loss=0.13718385994434357
[15/23] Train loss=0.1523778885602951
[20/23] Train loss=0.10872265696525574
Test set avg_accuracy=87.88% avg_sensitivity=72.34%, avg_specificity=93.17% avg_auc=0.9257
Fold[9] Epoch: 100 [100/100 (100%)] Train loss=0.133597 Test loss=0.330583 Current lr=[3.9999999999999996e-05]

Fold[9] Best Result: acc=88.61356932153393 sen=76.29009762900976, spe=92.80518659076535, auc=0.9386074641011006!
[0/23] Train loss=0.708408534526825
[5/23] Train loss=0.6735761165618896
[10/23] Train loss=0.5800305604934692
[15/23] Train loss=0.5515527725219727
[20/23] Train loss=0.6073296070098877
Test set avg_accuracy=77.55% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6874
Best model saved!! Metric=-79.70726543579327!!
Fold[10] Epoch: 1 [1/100 (1%)] Train loss=0.576451 Test loss=0.549279 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5304259657859802
[5/23] Train loss=0.5678222179412842
[10/23] Train loss=0.5024245977401733
[15/23] Train loss=0.4749353528022766
[20/23] Train loss=0.5003911256790161
Test set avg_accuracy=77.42% avg_sensitivity=6.32%, avg_specificity=97.99% avg_auc=0.7948
Best model saved!! Metric=-64.79210131820882!!
Fold[10] Epoch: 2 [2/100 (2%)] Train loss=0.492076 Test loss=0.464257 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42480334639549255
[5/23] Train loss=0.4730026125907898
[10/23] Train loss=0.4409257769584656
[15/23] Train loss=0.3883126378059387
[20/23] Train loss=0.4753866493701935
Test set avg_accuracy=79.71% avg_sensitivity=27.70%, avg_specificity=94.77% avg_auc=0.8337
Best model saved!! Metric=-40.46043626832028!!
Fold[10] Epoch: 3 [3/100 (3%)] Train loss=0.426170 Test loss=0.442749 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3786585032939911
[5/23] Train loss=0.42834872007369995
[10/23] Train loss=0.42451903223991394
[15/23] Train loss=0.36699631810188293
[20/23] Train loss=0.47513777017593384
Test set avg_accuracy=81.79% avg_sensitivity=39.62%, avg_specificity=93.99% avg_auc=0.8573
Best model saved!! Metric=-24.87134286286315!!
Fold[10] Epoch: 4 [4/100 (4%)] Train loss=0.399143 Test loss=0.403598 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3544897139072418
[5/23] Train loss=0.40617573261260986
[10/23] Train loss=0.4238050580024719
[15/23] Train loss=0.3571580946445465
[20/23] Train loss=0.46855828166007996
Test set avg_accuracy=83.52% avg_sensitivity=46.56%, avg_specificity=94.21% avg_auc=0.8715
Best model saved!! Metric=-14.563147845572011!!
Fold[10] Epoch: 5 [5/100 (5%)] Train loss=0.383652 Test loss=0.381337 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3428303003311157
[5/23] Train loss=0.40742063522338867
[10/23] Train loss=0.42773404717445374
[15/23] Train loss=0.3520983159542084
[20/23] Train loss=0.45623308420181274
Test set avg_accuracy=84.72% avg_sensitivity=51.03%, avg_specificity=94.47% avg_auc=0.8820
Best model saved!! Metric=-7.5858289492767454!!
Fold[10] Epoch: 6 [6/100 (6%)] Train loss=0.374518 Test loss=0.365965 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3403674066066742
[5/23] Train loss=0.4036702811717987
[10/23] Train loss=0.43365657329559326
[15/23] Train loss=0.3543233871459961
[20/23] Train loss=0.4435179531574249
Test set avg_accuracy=84.89% avg_sensitivity=51.18%, avg_specificity=94.65% avg_auc=0.8938
Best model saved!! Metric=-5.901275190116326!!
Fold[10] Epoch: 7 [7/100 (7%)] Train loss=0.368284 Test loss=0.351482 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3348739445209503
[5/23] Train loss=0.41634950041770935
[10/23] Train loss=0.4178006052970886
[15/23] Train loss=0.3575113117694855
[20/23] Train loss=0.4306565523147583
Test set avg_accuracy=85.63% avg_sensitivity=53.55%, avg_specificity=94.91% avg_auc=0.9013
Best model saved!! Metric=-1.7785713976492712!!
Fold[10] Epoch: 8 [8/100 (8%)] Train loss=0.365119 Test loss=0.335750 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3216778337955475
[5/23] Train loss=0.42879974842071533
[10/23] Train loss=0.3910055458545685
[15/23] Train loss=0.3514610826969147
[20/23] Train loss=0.4061613380908966
Test set avg_accuracy=86.57% avg_sensitivity=61.46%, avg_specificity=93.84% avg_auc=0.9112
Best model saved!! Metric=7.001559691628243!!
Fold[10] Epoch: 9 [9/100 (9%)] Train loss=0.358580 Test loss=0.310178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31179291009902954
[5/23] Train loss=0.4383090138435364
[10/23] Train loss=0.35734349489212036
[15/23] Train loss=0.3273163437843323
[20/23] Train loss=0.4006086587905884
Test set avg_accuracy=87.37% avg_sensitivity=69.53%, avg_specificity=92.53% avg_auc=0.9186
Best model saved!! Metric=15.295689432181533!!
Fold[10] Epoch: 10 [10/100 (10%)] Train loss=0.346521 Test loss=0.296316 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29241088032722473
[5/23] Train loss=0.40785056352615356
[10/23] Train loss=0.3452984094619751
[15/23] Train loss=0.3171842098236084
[20/23] Train loss=0.3882438540458679
Test set avg_accuracy=88.28% avg_sensitivity=73.12%, avg_specificity=92.67% avg_auc=0.9269
Best model saved!! Metric=20.767239515110745!!
Fold[10] Epoch: 11 [11/100 (11%)] Train loss=0.331531 Test loss=0.283129 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.277382493019104
[5/23] Train loss=0.3983222246170044
[10/23] Train loss=0.3359571695327759
[15/23] Train loss=0.30024391412734985
[20/23] Train loss=0.38515785336494446
Test set avg_accuracy=88.97% avg_sensitivity=75.95%, avg_specificity=92.74% avg_auc=0.9331
Best model saved!! Metric=24.980109314217646!!
Fold[10] Epoch: 12 [12/100 (12%)] Train loss=0.321758 Test loss=0.272025 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27017897367477417
[5/23] Train loss=0.3805255889892578
[10/23] Train loss=0.34518736600875854
[15/23] Train loss=0.29252371191978455
[20/23] Train loss=0.3728138506412506
Test set avg_accuracy=89.75% avg_sensitivity=75.80%, avg_specificity=93.78% avg_auc=0.9390
Best model saved!! Metric=27.228551350105583!!
Fold[10] Epoch: 13 [13/100 (13%)] Train loss=0.313833 Test loss=0.258947 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25158610939979553
[5/23] Train loss=0.36532166600227356
[10/23] Train loss=0.3397581875324249
[15/23] Train loss=0.28634607791900635
[20/23] Train loss=0.382644921541214
Test set avg_accuracy=90.07% avg_sensitivity=72.82%, avg_specificity=95.06% avg_auc=0.9419
Fold[10] Epoch: 14 [14/100 (14%)] Train loss=0.308413 Test loss=0.251337 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25535574555397034
[5/23] Train loss=0.36403438448905945
[10/23] Train loss=0.3347781002521515
[15/23] Train loss=0.2889431416988373
[20/23] Train loss=0.372800350189209
Test set avg_accuracy=89.95% avg_sensitivity=71.58%, avg_specificity=95.27% avg_auc=0.9431
Fold[10] Epoch: 15 [15/100 (15%)] Train loss=0.306749 Test loss=0.249734 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25367823243141174
[5/23] Train loss=0.37000173330307007
[10/23] Train loss=0.32243651151657104
[15/23] Train loss=0.2867374122142792
[20/23] Train loss=0.3717612028121948
Test set avg_accuracy=90.30% avg_sensitivity=74.87%, avg_specificity=94.77% avg_auc=0.9437
Best model saved!! Metric=28.308615637061795!!
Fold[10] Epoch: 16 [16/100 (16%)] Train loss=0.304148 Test loss=0.247359 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2576504647731781
[5/23] Train loss=0.37447744607925415
[10/23] Train loss=0.3106445372104645
[15/23] Train loss=0.2787807583808899
[20/23] Train loss=0.377534955739975
Test set avg_accuracy=90.69% avg_sensitivity=77.03%, avg_specificity=94.65% avg_auc=0.9447
Best model saved!! Metric=30.834017038704523!!
Fold[10] Epoch: 17 [17/100 (17%)] Train loss=0.299015 Test loss=0.245658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2445911318063736
[5/23] Train loss=0.35901182889938354
[10/23] Train loss=0.30451077222824097
[15/23] Train loss=0.2763863801956177
[20/23] Train loss=0.36198562383651733
Test set avg_accuracy=90.58% avg_sensitivity=77.70%, avg_specificity=94.30% avg_auc=0.9451
Best model saved!! Metric=31.090616846572022!!
Fold[10] Epoch: 18 [18/100 (18%)] Train loss=0.290320 Test loss=0.244973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2341252714395523
[5/23] Train loss=0.35604095458984375
[10/23] Train loss=0.29162096977233887
[15/23] Train loss=0.2680562436580658
[20/23] Train loss=0.3700820207595825
Test set avg_accuracy=90.47% avg_sensitivity=79.65%, avg_specificity=93.60% avg_auc=0.9456
Best model saved!! Metric=32.289151086267466!!
Fold[10] Epoch: 19 [19/100 (19%)] Train loss=0.285985 Test loss=0.246012 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2329953908920288
[5/23] Train loss=0.3421887159347534
[10/23] Train loss=0.29698315262794495
[15/23] Train loss=0.2591744065284729
[20/23] Train loss=0.360146164894104
Test set avg_accuracy=90.68% avg_sensitivity=77.70%, avg_specificity=94.44% avg_auc=0.9451
Fold[10] Epoch: 20 [20/100 (20%)] Train loss=0.280487 Test loss=0.243131 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23513250052928925
[5/23] Train loss=0.33130693435668945
[10/23] Train loss=0.29651349782943726
[15/23] Train loss=0.2641536593437195
[20/23] Train loss=0.3679434359073639
Test set avg_accuracy=90.78% avg_sensitivity=77.85%, avg_specificity=94.53% avg_auc=0.9467
Fold[10] Epoch: 21 [21/100 (21%)] Train loss=0.278119 Test loss=0.239813 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22914360463619232
[5/23] Train loss=0.33601629734039307
[10/23] Train loss=0.3062516748905182
[15/23] Train loss=0.26473137736320496
[20/23] Train loss=0.359749972820282
Test set avg_accuracy=91.03% avg_sensitivity=75.90%, avg_specificity=95.40% avg_auc=0.9464
Fold[10] Epoch: 22 [22/100 (22%)] Train loss=0.276838 Test loss=0.238452 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22396859526634216
[5/23] Train loss=0.349409282207489
[10/23] Train loss=0.283237099647522
[15/23] Train loss=0.2534264028072357
[20/23] Train loss=0.37108859419822693
Test set avg_accuracy=91.18% avg_sensitivity=76.46%, avg_specificity=95.43% avg_auc=0.9474
Fold[10] Epoch: 23 [23/100 (23%)] Train loss=0.275252 Test loss=0.235559 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2218603789806366
[5/23] Train loss=0.34930673241615295
[10/23] Train loss=0.30266425013542175
[15/23] Train loss=0.2692757546901703
[20/23] Train loss=0.35094156861305237
Test set avg_accuracy=90.84% avg_sensitivity=73.18%, avg_specificity=95.95% avg_auc=0.9467
Fold[10] Epoch: 24 [24/100 (24%)] Train loss=0.275654 Test loss=0.236671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22551830112934113
[5/23] Train loss=0.34647250175476074
[10/23] Train loss=0.2921677529811859
[15/23] Train loss=0.2622286081314087
[20/23] Train loss=0.34278199076652527
Test set avg_accuracy=90.90% avg_sensitivity=73.33%, avg_specificity=95.98% avg_auc=0.9460
Fold[10] Epoch: 25 [25/100 (25%)] Train loss=0.271136 Test loss=0.238167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21438586711883545
[5/23] Train loss=0.33443349599838257
[10/23] Train loss=0.2923094928264618
[15/23] Train loss=0.260378897190094
[20/23] Train loss=0.34483999013900757
Test set avg_accuracy=90.95% avg_sensitivity=73.79%, avg_specificity=95.91% avg_auc=0.9465
Fold[10] Epoch: 26 [26/100 (26%)] Train loss=0.272972 Test loss=0.236516 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21970954537391663
[5/23] Train loss=0.3395152986049652
[10/23] Train loss=0.2873021364212036
[15/23] Train loss=0.256818950176239
[20/23] Train loss=0.3423115015029907
Test set avg_accuracy=90.93% avg_sensitivity=73.54%, avg_specificity=95.97% avg_auc=0.9468
Fold[10] Epoch: 27 [27/100 (27%)] Train loss=0.267579 Test loss=0.236486 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21915403008460999
[5/23] Train loss=0.3411269187927246
[10/23] Train loss=0.28734108805656433
[15/23] Train loss=0.2622825503349304
[20/23] Train loss=0.3435170352458954
Test set avg_accuracy=91.15% avg_sensitivity=75.23%, avg_specificity=95.76% avg_auc=0.9469
Fold[10] Epoch: 28 [28/100 (28%)] Train loss=0.266814 Test loss=0.235467 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21159100532531738
[5/23] Train loss=0.3517015278339386
[10/23] Train loss=0.2752174735069275
[15/23] Train loss=0.25265952944755554
[20/23] Train loss=0.3438180088996887
Test set avg_accuracy=91.21% avg_sensitivity=76.36%, avg_specificity=95.51% avg_auc=0.9461
Fold[10] Epoch: 29 [29/100 (29%)] Train loss=0.264094 Test loss=0.236674 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21486181020736694
[5/23] Train loss=0.3223062753677368
[10/23] Train loss=0.2725311517715454
[15/23] Train loss=0.2545669376850128
[20/23] Train loss=0.33997902274131775
Test set avg_accuracy=91.48% avg_sensitivity=76.31%, avg_specificity=95.87% avg_auc=0.9465
Best model saved!! Metric=32.30000943757284!!
Fold[10] Epoch: 30 [30/100 (30%)] Train loss=0.263519 Test loss=0.235558 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21215461194515228
[5/23] Train loss=0.3310908377170563
[10/23] Train loss=0.27855682373046875
[15/23] Train loss=0.2545735239982605
[20/23] Train loss=0.33645835518836975
Test set avg_accuracy=91.33% avg_sensitivity=75.44%, avg_specificity=95.93% avg_auc=0.9450
Fold[10] Epoch: 31 [31/100 (31%)] Train loss=0.258960 Test loss=0.238848 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20608359575271606
[5/23] Train loss=0.323497474193573
[10/23] Train loss=0.2835312783718109
[15/23] Train loss=0.24119076132774353
[20/23] Train loss=0.3355191946029663
Test set avg_accuracy=91.37% avg_sensitivity=75.33%, avg_specificity=96.01% avg_auc=0.9457
Fold[10] Epoch: 32 [32/100 (32%)] Train loss=0.257745 Test loss=0.237934 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20659218728542328
[5/23] Train loss=0.31781601905822754
[10/23] Train loss=0.2754725515842438
[15/23] Train loss=0.2546805739402771
[20/23] Train loss=0.32531946897506714
Test set avg_accuracy=91.70% avg_sensitivity=76.72%, avg_specificity=96.03% avg_auc=0.9466
Best model saved!! Metric=33.10819348542733!!
Fold[10] Epoch: 33 [33/100 (33%)] Train loss=0.255672 Test loss=0.235667 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20790570974349976
[5/23] Train loss=0.3241267800331116
[10/23] Train loss=0.281328022480011
[15/23] Train loss=0.2515893876552582
[20/23] Train loss=0.3238300085067749
Test set avg_accuracy=91.43% avg_sensitivity=75.18%, avg_specificity=96.13% avg_auc=0.9453
Fold[10] Epoch: 34 [34/100 (34%)] Train loss=0.255082 Test loss=0.237433 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21089640259742737
[5/23] Train loss=0.31310558319091797
[10/23] Train loss=0.26870450377464294
[15/23] Train loss=0.24626153707504272
[20/23] Train loss=0.32898831367492676
Test set avg_accuracy=91.22% avg_sensitivity=75.23%, avg_specificity=95.85% avg_auc=0.9452
Fold[10] Epoch: 35 [35/100 (35%)] Train loss=0.251516 Test loss=0.237255 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20599083602428436
[5/23] Train loss=0.31557825207710266
[10/23] Train loss=0.272673100233078
[15/23] Train loss=0.23979884386062622
[20/23] Train loss=0.3208011984825134
Test set avg_accuracy=91.22% avg_sensitivity=73.79%, avg_specificity=96.27% avg_auc=0.9446
Fold[10] Epoch: 36 [36/100 (36%)] Train loss=0.248460 Test loss=0.239641 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20335273444652557
[5/23] Train loss=0.3238959312438965
[10/23] Train loss=0.26130902767181396
[15/23] Train loss=0.24283817410469055
[20/23] Train loss=0.3215901851654053
Test set avg_accuracy=91.27% avg_sensitivity=74.05%, avg_specificity=96.25% avg_auc=0.9453
Fold[10] Epoch: 37 [37/100 (37%)] Train loss=0.249971 Test loss=0.237169 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19797472655773163
[5/23] Train loss=0.31155213713645935
[10/23] Train loss=0.25541162490844727
[15/23] Train loss=0.24280762672424316
[20/23] Train loss=0.3247980773448944
Test set avg_accuracy=91.30% avg_sensitivity=75.13%, avg_specificity=95.98% avg_auc=0.9460
Fold[10] Epoch: 38 [38/100 (38%)] Train loss=0.245510 Test loss=0.237636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20841285586357117
[5/23] Train loss=0.312660276889801
[10/23] Train loss=0.26298439502716064
[15/23] Train loss=0.24613523483276367
[20/23] Train loss=0.3195286691188812
Test set avg_accuracy=90.99% avg_sensitivity=72.20%, avg_specificity=96.43% avg_auc=0.9437
Fold[10] Epoch: 39 [39/100 (39%)] Train loss=0.245269 Test loss=0.243098 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20282724499702454
[5/23] Train loss=0.30628418922424316
[10/23] Train loss=0.2649633288383484
[15/23] Train loss=0.23163297772407532
[20/23] Train loss=0.3141557574272156
Test set avg_accuracy=91.43% avg_sensitivity=76.21%, avg_specificity=95.84% avg_auc=0.9475
Fold[10] Epoch: 40 [40/100 (40%)] Train loss=0.241612 Test loss=0.234291 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19432832300662994
[5/23] Train loss=0.3040158152580261
[10/23] Train loss=0.2522423267364502
[15/23] Train loss=0.24043309688568115
[20/23] Train loss=0.31161606311798096
Test set avg_accuracy=91.06% avg_sensitivity=72.30%, avg_specificity=96.49% avg_auc=0.9448
Fold[10] Epoch: 41 [41/100 (41%)] Train loss=0.241755 Test loss=0.240326 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2023897022008896
[5/23] Train loss=0.3068679869174957
[10/23] Train loss=0.24613678455352783
[15/23] Train loss=0.23457786440849304
[20/23] Train loss=0.31742140650749207
Test set avg_accuracy=91.34% avg_sensitivity=74.87%, avg_specificity=96.10% avg_auc=0.9455
Fold[10] Epoch: 42 [42/100 (42%)] Train loss=0.238894 Test loss=0.236405 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1928243488073349
[5/23] Train loss=0.30260008573532104
[10/23] Train loss=0.24862614274024963
[15/23] Train loss=0.23424752056598663
[20/23] Train loss=0.312691330909729
Test set avg_accuracy=91.23% avg_sensitivity=74.46%, avg_specificity=96.09% avg_auc=0.9447
Fold[10] Epoch: 43 [43/100 (43%)] Train loss=0.238276 Test loss=0.239460 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18632183969020844
[5/23] Train loss=0.31065458059310913
[10/23] Train loss=0.2448531985282898
[15/23] Train loss=0.2375107854604721
[20/23] Train loss=0.3179413676261902
Test set avg_accuracy=91.22% avg_sensitivity=73.74%, avg_specificity=96.28% avg_auc=0.9437
Fold[10] Epoch: 44 [44/100 (44%)] Train loss=0.236613 Test loss=0.240588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18849961459636688
[5/23] Train loss=0.30112603306770325
[10/23] Train loss=0.2591724991798401
[15/23] Train loss=0.2298523336648941
[20/23] Train loss=0.3074311316013336
Test set avg_accuracy=90.82% avg_sensitivity=74.72%, avg_specificity=95.48% avg_auc=0.9446
Fold[10] Epoch: 45 [45/100 (45%)] Train loss=0.233760 Test loss=0.239832 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1863327920436859
[5/23] Train loss=0.2849971354007721
[10/23] Train loss=0.24128848314285278
[15/23] Train loss=0.23015138506889343
[20/23] Train loss=0.30606651306152344
Test set avg_accuracy=91.12% avg_sensitivity=75.23%, avg_specificity=95.72% avg_auc=0.9434
Fold[10] Epoch: 46 [46/100 (46%)] Train loss=0.231226 Test loss=0.241954 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.189279243350029
[5/23] Train loss=0.2955177426338196
[10/23] Train loss=0.239018976688385
[15/23] Train loss=0.22489525377750397
[20/23] Train loss=0.3003326654434204
Test set avg_accuracy=91.14% avg_sensitivity=74.67%, avg_specificity=95.91% avg_auc=0.9444
Fold[10] Epoch: 47 [47/100 (47%)] Train loss=0.230638 Test loss=0.239623 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1906740665435791
[5/23] Train loss=0.30651211738586426
[10/23] Train loss=0.2321833372116089
[15/23] Train loss=0.23245391249656677
[20/23] Train loss=0.3027274012565613
Test set avg_accuracy=91.12% avg_sensitivity=73.54%, avg_specificity=96.21% avg_auc=0.9438
Fold[10] Epoch: 48 [48/100 (48%)] Train loss=0.229055 Test loss=0.242051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18969622254371643
[5/23] Train loss=0.2950560450553894
[10/23] Train loss=0.24609331786632538
[15/23] Train loss=0.22518078982830048
[20/23] Train loss=0.29955539107322693
Test set avg_accuracy=91.48% avg_sensitivity=75.64%, avg_specificity=96.06% avg_auc=0.9448
Fold[10] Epoch: 49 [49/100 (49%)] Train loss=0.227881 Test loss=0.239893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1835690587759018
[5/23] Train loss=0.2982797920703888
[10/23] Train loss=0.2518012225627899
[15/23] Train loss=0.22997401654720306
[20/23] Train loss=0.29795852303504944
Test set avg_accuracy=91.36% avg_sensitivity=74.56%, avg_specificity=96.22% avg_auc=0.9441
Fold[10] Epoch: 50 [50/100 (50%)] Train loss=0.227213 Test loss=0.240357 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18876789510250092
[5/23] Train loss=0.2880787253379822
[10/23] Train loss=0.2419847548007965
[15/23] Train loss=0.22394417226314545
[20/23] Train loss=0.2925724387168884
Test set avg_accuracy=91.19% avg_sensitivity=74.72%, avg_specificity=95.95% avg_auc=0.9446
Fold[10] Epoch: 51 [51/100 (51%)] Train loss=0.225413 Test loss=0.240930 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17940977215766907
[5/23] Train loss=0.2959206998348236
[10/23] Train loss=0.237849161028862
[15/23] Train loss=0.21437296271324158
[20/23] Train loss=0.2874636948108673
Test set avg_accuracy=91.41% avg_sensitivity=76.93%, avg_specificity=95.60% avg_auc=0.9454
Fold[10] Epoch: 52 [52/100 (52%)] Train loss=0.221876 Test loss=0.238647 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18759092688560486
[5/23] Train loss=0.29451000690460205
[10/23] Train loss=0.24145099520683289
[15/23] Train loss=0.22507189214229584
[20/23] Train loss=0.2816116511821747
Test set avg_accuracy=91.29% avg_sensitivity=75.44%, avg_specificity=95.88% avg_auc=0.9427
Fold[10] Epoch: 53 [53/100 (53%)] Train loss=0.221457 Test loss=0.243830 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1843065619468689
[5/23] Train loss=0.27376413345336914
[10/23] Train loss=0.23636513948440552
[15/23] Train loss=0.21631285548210144
[20/23] Train loss=0.28586500883102417
Test set avg_accuracy=91.14% avg_sensitivity=75.59%, avg_specificity=95.64% avg_auc=0.9432
Fold[10] Epoch: 54 [54/100 (54%)] Train loss=0.219468 Test loss=0.243440 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17887860536575317
[5/23] Train loss=0.28270798921585083
[10/23] Train loss=0.23643441498279572
[15/23] Train loss=0.21736028790473938
[20/23] Train loss=0.2879139184951782
Test set avg_accuracy=91.15% avg_sensitivity=76.10%, avg_specificity=95.51% avg_auc=0.9428
Fold[10] Epoch: 55 [55/100 (55%)] Train loss=0.219964 Test loss=0.243574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.184064581990242
[5/23] Train loss=0.27512508630752563
[10/23] Train loss=0.23628893494606018
[15/23] Train loss=0.2246936559677124
[20/23] Train loss=0.2819352447986603
Test set avg_accuracy=91.00% avg_sensitivity=75.08%, avg_specificity=95.61% avg_auc=0.9437
Fold[10] Epoch: 56 [56/100 (56%)] Train loss=0.214726 Test loss=0.243655 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17935611307621002
[5/23] Train loss=0.26708248257637024
[10/23] Train loss=0.22444306313991547
[15/23] Train loss=0.2224501073360443
[20/23] Train loss=0.27639031410217285
Test set avg_accuracy=90.93% avg_sensitivity=74.87%, avg_specificity=95.58% avg_auc=0.9432
Fold[10] Epoch: 57 [57/100 (57%)] Train loss=0.212570 Test loss=0.243695 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1769462674856186
[5/23] Train loss=0.2884926497936249
[10/23] Train loss=0.2300451695919037
[15/23] Train loss=0.2230830192565918
[20/23] Train loss=0.27995556592941284
Test set avg_accuracy=91.06% avg_sensitivity=75.28%, avg_specificity=95.63% avg_auc=0.9434
Fold[10] Epoch: 58 [58/100 (58%)] Train loss=0.213927 Test loss=0.244325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17780174314975739
[5/23] Train loss=0.2789277136325836
[10/23] Train loss=0.2248290777206421
[15/23] Train loss=0.2206263244152069
[20/23] Train loss=0.28286945819854736
Test set avg_accuracy=91.27% avg_sensitivity=75.03%, avg_specificity=95.97% avg_auc=0.9437
Fold[10] Epoch: 59 [59/100 (59%)] Train loss=0.211901 Test loss=0.243332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1737116277217865
[5/23] Train loss=0.2666747272014618
[10/23] Train loss=0.23175865411758423
[15/23] Train loss=0.21309994161128998
[20/23] Train loss=0.28602758049964905
Test set avg_accuracy=90.78% avg_sensitivity=72.76%, avg_specificity=96.00% avg_auc=0.9410
Fold[10] Epoch: 60 [60/100 (60%)] Train loss=0.210708 Test loss=0.251077 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1715305745601654
[5/23] Train loss=0.2621084153652191
[10/23] Train loss=0.22847090661525726
[15/23] Train loss=0.2150961011648178
[20/23] Train loss=0.26296311616897583
Test set avg_accuracy=91.34% avg_sensitivity=75.75%, avg_specificity=95.85% avg_auc=0.9455
Fold[10] Epoch: 61 [61/100 (61%)] Train loss=0.207633 Test loss=0.239354 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17398186028003693
[5/23] Train loss=0.2731016278266907
[10/23] Train loss=0.22470854222774506
[15/23] Train loss=0.2155856192111969
[20/23] Train loss=0.26437002420425415
Test set avg_accuracy=91.06% avg_sensitivity=75.64%, avg_specificity=95.52% avg_auc=0.9423
Fold[10] Epoch: 62 [62/100 (62%)] Train loss=0.207944 Test loss=0.247378 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17114189267158508
[5/23] Train loss=0.2655092775821686
[10/23] Train loss=0.22933265566825867
[15/23] Train loss=0.21092188358306885
[20/23] Train loss=0.2586694359779358
Test set avg_accuracy=91.26% avg_sensitivity=76.46%, avg_specificity=95.54% avg_auc=0.9447
Fold[10] Epoch: 63 [63/100 (63%)] Train loss=0.205414 Test loss=0.243042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1751619279384613
[5/23] Train loss=0.25353768467903137
[10/23] Train loss=0.217515766620636
[15/23] Train loss=0.2141788750886917
[20/23] Train loss=0.26234331727027893
Test set avg_accuracy=91.48% avg_sensitivity=77.54%, avg_specificity=95.51% avg_auc=0.9439
Fold[10] Epoch: 64 [64/100 (64%)] Train loss=0.201064 Test loss=0.244626 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16767087578773499
[5/23] Train loss=0.2568564713001251
[10/23] Train loss=0.21216486394405365
[15/23] Train loss=0.20667599141597748
[20/23] Train loss=0.26412078738212585
Test set avg_accuracy=91.41% avg_sensitivity=76.82%, avg_specificity=95.63% avg_auc=0.9442
Fold[10] Epoch: 65 [65/100 (65%)] Train loss=0.200758 Test loss=0.243162 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16705568134784698
[5/23] Train loss=0.25267547369003296
[10/23] Train loss=0.21024812757968903
[15/23] Train loss=0.20241639018058777
[20/23] Train loss=0.2517467737197876
Test set avg_accuracy=91.11% avg_sensitivity=77.34%, avg_specificity=95.09% avg_auc=0.9440
Fold[10] Epoch: 66 [66/100 (66%)] Train loss=0.198584 Test loss=0.245557 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17024002969264984
[5/23] Train loss=0.2601183354854584
[10/23] Train loss=0.2106286734342575
[15/23] Train loss=0.20347847044467926
[20/23] Train loss=0.27048882842063904
Test set avg_accuracy=91.15% avg_sensitivity=77.34%, avg_specificity=95.15% avg_auc=0.9430
Fold[10] Epoch: 67 [67/100 (67%)] Train loss=0.196909 Test loss=0.247545 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16742035746574402
[5/23] Train loss=0.24874478578567505
[10/23] Train loss=0.20157071948051453
[15/23] Train loss=0.19762873649597168
[20/23] Train loss=0.25430262088775635
Test set avg_accuracy=91.19% avg_sensitivity=78.16%, avg_specificity=94.96% avg_auc=0.9414
Fold[10] Epoch: 68 [68/100 (68%)] Train loss=0.193906 Test loss=0.252624 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16676285862922668
[5/23] Train loss=0.24892115592956543
[10/23] Train loss=0.20139558613300323
[15/23] Train loss=0.19969625771045685
[20/23] Train loss=0.26209190487861633
Test set avg_accuracy=91.34% avg_sensitivity=77.18%, avg_specificity=95.43% avg_auc=0.9431
Fold[10] Epoch: 69 [69/100 (69%)] Train loss=0.194279 Test loss=0.246847 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16991741955280304
[5/23] Train loss=0.25574830174446106
[10/23] Train loss=0.20827838778495789
[15/23] Train loss=0.20302370190620422
[20/23] Train loss=0.2570074498653412
Test set avg_accuracy=91.05% avg_sensitivity=74.46%, avg_specificity=95.85% avg_auc=0.9397
Fold[10] Epoch: 70 [70/100 (70%)] Train loss=0.193068 Test loss=0.254467 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1616767793893814
[5/23] Train loss=0.24750913679599762
[10/23] Train loss=0.20549272000789642
[15/23] Train loss=0.1903020590543747
[20/23] Train loss=0.25099465250968933
Test set avg_accuracy=91.33% avg_sensitivity=75.28%, avg_specificity=95.97% avg_auc=0.9432
Fold[10] Epoch: 71 [71/100 (71%)] Train loss=0.188667 Test loss=0.247708 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15829138457775116
[5/23] Train loss=0.2415986806154251
[10/23] Train loss=0.19758282601833344
[15/23] Train loss=0.19189079105854034
[20/23] Train loss=0.24631690979003906
Test set avg_accuracy=90.95% avg_sensitivity=75.69%, avg_specificity=95.36% avg_auc=0.9412
Fold[10] Epoch: 72 [72/100 (72%)] Train loss=0.186856 Test loss=0.252821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15571144223213196
[5/23] Train loss=0.23910848796367645
[10/23] Train loss=0.20016071200370789
[15/23] Train loss=0.19017566740512848
[20/23] Train loss=0.24414169788360596
Test set avg_accuracy=90.85% avg_sensitivity=74.00%, avg_specificity=95.73% avg_auc=0.9406
Fold[10] Epoch: 73 [73/100 (73%)] Train loss=0.183815 Test loss=0.256226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16320160031318665
[5/23] Train loss=0.23691409826278687
[10/23] Train loss=0.19073592126369476
[15/23] Train loss=0.1860094964504242
[20/23] Train loss=0.2349870502948761
Test set avg_accuracy=91.16% avg_sensitivity=76.72%, avg_specificity=95.35% avg_auc=0.9410
Fold[10] Epoch: 74 [74/100 (74%)] Train loss=0.183186 Test loss=0.257071 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15482817590236664
[5/23] Train loss=0.2299041450023651
[10/23] Train loss=0.19432370364665985
[15/23] Train loss=0.18990686535835266
[20/23] Train loss=0.2428620159626007
Test set avg_accuracy=91.06% avg_sensitivity=74.05%, avg_specificity=95.98% avg_auc=0.9395
Fold[10] Epoch: 75 [75/100 (75%)] Train loss=0.180418 Test loss=0.259140 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1527792066335678
[5/23] Train loss=0.2394379824399948
[10/23] Train loss=0.1944931596517563
[15/23] Train loss=0.19106023013591766
[20/23] Train loss=0.23597212135791779
Test set avg_accuracy=91.00% avg_sensitivity=73.95%, avg_specificity=95.94% avg_auc=0.9395
Fold[10] Epoch: 76 [76/100 (76%)] Train loss=0.178228 Test loss=0.260315 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1575552076101303
[5/23] Train loss=0.22338877618312836
[10/23] Train loss=0.18429818749427795
[15/23] Train loss=0.18434500694274902
[20/23] Train loss=0.22598674893379211
Test set avg_accuracy=90.82% avg_sensitivity=75.08%, avg_specificity=95.37% avg_auc=0.9380
Fold[10] Epoch: 77 [77/100 (77%)] Train loss=0.174633 Test loss=0.262919 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15027043223381042
[5/23] Train loss=0.22859062254428864
[10/23] Train loss=0.1916833072900772
[15/23] Train loss=0.18701361119747162
[20/23] Train loss=0.22344741225242615
Test set avg_accuracy=90.85% avg_sensitivity=74.87%, avg_specificity=95.48% avg_auc=0.9401
Fold[10] Epoch: 78 [78/100 (78%)] Train loss=0.173881 Test loss=0.258639 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14834846556186676
[5/23] Train loss=0.23159271478652954
[10/23] Train loss=0.19146956503391266
[15/23] Train loss=0.18526004254817963
[20/23] Train loss=0.23126524686813354
Test set avg_accuracy=90.87% avg_sensitivity=75.28%, avg_specificity=95.37% avg_auc=0.9392
Fold[10] Epoch: 79 [79/100 (79%)] Train loss=0.174705 Test loss=0.260625 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1556757241487503
[5/23] Train loss=0.22276252508163452
[10/23] Train loss=0.180950328707695
[15/23] Train loss=0.18876220285892487
[20/23] Train loss=0.227886363863945
Test set avg_accuracy=90.96% avg_sensitivity=74.10%, avg_specificity=95.84% avg_auc=0.9375
Fold[10] Epoch: 80 [80/100 (80%)] Train loss=0.169778 Test loss=0.265623 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1426059752702713
[5/23] Train loss=0.22775042057037354
[10/23] Train loss=0.17842496931552887
[15/23] Train loss=0.17699891328811646
[20/23] Train loss=0.2216845452785492
Test set avg_accuracy=91.18% avg_sensitivity=75.95%, avg_specificity=95.58% avg_auc=0.9398
Fold[10] Epoch: 81 [81/100 (81%)] Train loss=0.167791 Test loss=0.262223 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1474963277578354
[5/23] Train loss=0.21741969883441925
[10/23] Train loss=0.17867791652679443
[15/23] Train loss=0.18383218348026276
[20/23] Train loss=0.21355463564395905
Test set avg_accuracy=90.99% avg_sensitivity=74.77%, avg_specificity=95.69% avg_auc=0.9394
Fold[10] Epoch: 82 [82/100 (82%)] Train loss=0.168189 Test loss=0.259625 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14848193526268005
[5/23] Train loss=0.22351592779159546
[10/23] Train loss=0.1887604147195816
[15/23] Train loss=0.17876136302947998
[20/23] Train loss=0.22184720635414124
Test set avg_accuracy=91.01% avg_sensitivity=74.41%, avg_specificity=95.82% avg_auc=0.9396
Fold[10] Epoch: 83 [83/100 (83%)] Train loss=0.165208 Test loss=0.259967 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14914926886558533
[5/23] Train loss=0.20597930252552032
[10/23] Train loss=0.17130590975284576
[15/23] Train loss=0.17706109583377838
[20/23] Train loss=0.22582252323627472
Test set avg_accuracy=90.92% avg_sensitivity=73.59%, avg_specificity=95.94% avg_auc=0.9377
Fold[10] Epoch: 84 [84/100 (84%)] Train loss=0.162945 Test loss=0.266689 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1513136476278305
[5/23] Train loss=0.21522535383701324
[10/23] Train loss=0.18377482891082764
[15/23] Train loss=0.17927831411361694
[20/23] Train loss=0.1982475072145462
Test set avg_accuracy=90.63% avg_sensitivity=72.40%, avg_specificity=95.91% avg_auc=0.9380
Fold[10] Epoch: 85 [85/100 (85%)] Train loss=0.163113 Test loss=0.264606 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14204588532447815
[5/23] Train loss=0.20983587205410004
[10/23] Train loss=0.180757537484169
[15/23] Train loss=0.18248794972896576
[20/23] Train loss=0.19974958896636963
Test set avg_accuracy=91.12% avg_sensitivity=76.88%, avg_specificity=95.24% avg_auc=0.9382
Fold[10] Epoch: 86 [86/100 (86%)] Train loss=0.158960 Test loss=0.267253 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14212380349636078
[5/23] Train loss=0.21219845116138458
[10/23] Train loss=0.16801710426807404
[15/23] Train loss=0.16411560773849487
[20/23] Train loss=0.20338384807109833
Test set avg_accuracy=90.54% avg_sensitivity=73.90%, avg_specificity=95.36% avg_auc=0.9377
Fold[10] Epoch: 87 [87/100 (87%)] Train loss=0.157648 Test loss=0.267380 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14615371823310852
[5/23] Train loss=0.2043878585100174
[10/23] Train loss=0.16569872200489044
[15/23] Train loss=0.16615642607212067
[20/23] Train loss=0.19663655757904053
Test set avg_accuracy=90.97% avg_sensitivity=74.77%, avg_specificity=95.66% avg_auc=0.9403
Fold[10] Epoch: 88 [88/100 (88%)] Train loss=0.153177 Test loss=0.265426 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1363757848739624
[5/23] Train loss=0.20254634320735931
[10/23] Train loss=0.16372795403003693
[15/23] Train loss=0.16339750587940216
[20/23] Train loss=0.19837255775928497
Test set avg_accuracy=90.89% avg_sensitivity=74.56%, avg_specificity=95.61% avg_auc=0.9396
Fold[10] Epoch: 89 [89/100 (89%)] Train loss=0.151807 Test loss=0.267646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1391628533601761
[5/23] Train loss=0.20066751539707184
[10/23] Train loss=0.1638333946466446
[15/23] Train loss=0.15597644448280334
[20/23] Train loss=0.19859333336353302
Test set avg_accuracy=90.63% avg_sensitivity=72.87%, avg_specificity=95.78% avg_auc=0.9388
Fold[10] Epoch: 90 [90/100 (90%)] Train loss=0.150103 Test loss=0.271477 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13686583936214447
[5/23] Train loss=0.19202981889247894
[10/23] Train loss=0.16195815801620483
[15/23] Train loss=0.16521084308624268
[20/23] Train loss=0.20451265573501587
Test set avg_accuracy=90.48% avg_sensitivity=71.58%, avg_specificity=95.95% avg_auc=0.9348
Fold[10] Epoch: 91 [91/100 (91%)] Train loss=0.149593 Test loss=0.278256 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14003457129001617
[5/23] Train loss=0.1867935210466385
[10/23] Train loss=0.1649858057498932
[15/23] Train loss=0.16360081732273102
[20/23] Train loss=0.18701989948749542
Test set avg_accuracy=90.93% avg_sensitivity=75.33%, avg_specificity=95.45% avg_auc=0.9347
Fold[10] Epoch: 92 [92/100 (92%)] Train loss=0.147401 Test loss=0.276759 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1284208446741104
[5/23] Train loss=0.18475309014320374
[10/23] Train loss=0.14943714439868927
[15/23] Train loss=0.1510581225156784
[20/23] Train loss=0.18209481239318848
Test set avg_accuracy=91.00% avg_sensitivity=76.41%, avg_specificity=95.23% avg_auc=0.9378
Fold[10] Epoch: 93 [93/100 (93%)] Train loss=0.143162 Test loss=0.275061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13244572281837463
[5/23] Train loss=0.18563267588615417
[10/23] Train loss=0.14948925375938416
[15/23] Train loss=0.1579420268535614
[20/23] Train loss=0.18299992382526398
Test set avg_accuracy=91.26% avg_sensitivity=77.80%, avg_specificity=95.15% avg_auc=0.9378
Fold[10] Epoch: 94 [94/100 (94%)] Train loss=0.141743 Test loss=0.277905 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12798257172107697
[5/23] Train loss=0.1864730715751648
[10/23] Train loss=0.14716559648513794
[15/23] Train loss=0.15383024513721466
[20/23] Train loss=0.1769844889640808
Test set avg_accuracy=91.30% avg_sensitivity=79.03%, avg_specificity=94.85% avg_auc=0.9371
Fold[10] Epoch: 95 [95/100 (95%)] Train loss=0.140284 Test loss=0.280949 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1268899142742157
[5/23] Train loss=0.17837567627429962
[10/23] Train loss=0.15021763741970062
[15/23] Train loss=0.15495578944683075
[20/23] Train loss=0.17361313104629517
Test set avg_accuracy=91.07% avg_sensitivity=77.29%, avg_specificity=95.06% avg_auc=0.9368
Fold[10] Epoch: 96 [96/100 (96%)] Train loss=0.138437 Test loss=0.280744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13041867315769196
[5/23] Train loss=0.17824840545654297
[10/23] Train loss=0.1417161524295807
[15/23] Train loss=0.14346489310264587
[20/23] Train loss=0.1768554300069809
Test set avg_accuracy=91.05% avg_sensitivity=77.18%, avg_specificity=95.06% avg_auc=0.9356
Fold[10] Epoch: 97 [97/100 (97%)] Train loss=0.133742 Test loss=0.284614 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12736694514751434
[5/23] Train loss=0.17230115830898285
[10/23] Train loss=0.14187656342983246
[15/23] Train loss=0.14635303616523743
[20/23] Train loss=0.17161543667316437
Test set avg_accuracy=90.75% avg_sensitivity=74.72%, avg_specificity=95.39% avg_auc=0.9366
Fold[10] Epoch: 98 [98/100 (98%)] Train loss=0.134058 Test loss=0.283669 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11884255707263947
[5/23] Train loss=0.17065736651420593
[10/23] Train loss=0.14068050682544708
[15/23] Train loss=0.1405995786190033
[20/23] Train loss=0.16921177506446838
Test set avg_accuracy=90.80% avg_sensitivity=74.41%, avg_specificity=95.54% avg_auc=0.9357
Fold[10] Epoch: 99 [99/100 (99%)] Train loss=0.131883 Test loss=0.284085 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12093796581029892
[5/23] Train loss=0.16881752014160156
[10/23] Train loss=0.1333368420600891
[15/23] Train loss=0.13686589896678925
[20/23] Train loss=0.15594837069511414
Test set avg_accuracy=91.00% avg_sensitivity=75.64%, avg_specificity=95.45% avg_auc=0.9345
Fold[10] Epoch: 100 [100/100 (100%)] Train loss=0.128523 Test loss=0.285953 Current lr=[3.9999999999999996e-05]

Fold[10] Best Result: acc=91.6955017301038 sen=76.72147995889003, spe=96.0291493158834, auc=0.946620624805501!
Final Avg Result: avg_acc=89.406343% avg_sen=75.440590% avg_spe=94.100161% avg_auc=0.936076
