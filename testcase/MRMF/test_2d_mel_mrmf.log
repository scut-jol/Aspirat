/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/23] Train loss=0.6814839839935303
[5/23] Train loss=0.6376789808273315
[10/23] Train loss=0.5688022971153259
[15/23] Train loss=0.5551079511642456
[20/23] Train loss=0.5485043525695801
Test set avg_accuracy=74.76% avg_sensitivity=0.37%, avg_specificity=99.94% avg_auc=0.5422
Best model saved!! Metric=-96.7096917268551!!
Fold[1] Epoch: 1 [1/100 (1%)] Train loss=0.578919 Test loss=0.617586 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42476797103881836
[5/23] Train loss=0.6200535297393799
[10/23] Train loss=0.5608410239219666
[15/23] Train loss=0.5468873381614685
[20/23] Train loss=0.5325697064399719
Test set avg_accuracy=74.76% avg_sensitivity=0.53%, avg_specificity=99.89% avg_auc=0.6019
Best model saved!! Metric=-90.63063994443455!!
Fold[1] Epoch: 2 [2/100 (2%)] Train loss=0.556676 Test loss=0.622887 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41609638929367065
[5/23] Train loss=0.6254871487617493
[10/23] Train loss=0.5473063588142395
[15/23] Train loss=0.5421212911605835
[20/23] Train loss=0.5155431032180786
Test set avg_accuracy=74.57% avg_sensitivity=3.46%, avg_specificity=98.64% avg_auc=0.6222
Best model saved!! Metric=-87.12154093673567!!
Fold[1] Epoch: 3 [3/100 (3%)] Train loss=0.547208 Test loss=0.602523 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4001232981681824
[5/23] Train loss=0.5943112373352051
[10/23] Train loss=0.5206640958786011
[15/23] Train loss=0.5179362297058105
[20/23] Train loss=0.48138442635536194
Test set avg_accuracy=75.27% avg_sensitivity=13.10%, avg_specificity=96.31% avg_auc=0.6738
Best model saved!! Metric=-73.94027179120566!!
Fold[1] Epoch: 4 [4/100 (4%)] Train loss=0.521705 Test loss=0.591768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38491031527519226
[5/23] Train loss=0.5475745797157288
[10/23] Train loss=0.48570123314857483
[15/23] Train loss=0.4951266646385193
[20/23] Train loss=0.441631019115448
Test set avg_accuracy=75.69% avg_sensitivity=18.92%, avg_specificity=94.90% avg_auc=0.7149
Best model saved!! Metric=-64.99579811735097!!
Fold[1] Epoch: 5 [5/100 (5%)] Train loss=0.494010 Test loss=0.612149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3785623610019684
[5/23] Train loss=0.5021260976791382
[10/23] Train loss=0.4578458070755005
[15/23] Train loss=0.4919520318508148
[20/23] Train loss=0.41252100467681885
Test set avg_accuracy=76.34% avg_sensitivity=24.78%, avg_specificity=93.79% avg_auc=0.7488
Best model saved!! Metric=-56.21498428121052!!
Fold[1] Epoch: 6 [6/100 (6%)] Train loss=0.473627 Test loss=0.594879 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3876994550228119
[5/23] Train loss=0.48176002502441406
[10/23] Train loss=0.43477413058280945
[15/23] Train loss=0.48574891686439514
[20/23] Train loss=0.3940538465976715
Test set avg_accuracy=76.95% avg_sensitivity=29.74%, avg_specificity=92.94% avg_auc=0.7599
Best model saved!! Metric=-50.38330140299685!!
Fold[1] Epoch: 7 [7/100 (7%)] Train loss=0.457700 Test loss=0.602564 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3784292936325073
[5/23] Train loss=0.470282644033432
[10/23] Train loss=0.41718077659606934
[15/23] Train loss=0.48634275794029236
[20/23] Train loss=0.3907764256000519
Test set avg_accuracy=77.57% avg_sensitivity=33.60%, avg_specificity=92.45% avg_auc=0.7780
Best model saved!! Metric=-44.57047567186601!!
Fold[1] Epoch: 8 [8/100 (8%)] Train loss=0.446340 Test loss=0.569672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38196423649787903
[5/23] Train loss=0.46953094005584717
[10/23] Train loss=0.41553911566734314
[15/23] Train loss=0.4488717317581177
[20/23] Train loss=0.3882107138633728
Test set avg_accuracy=77.73% avg_sensitivity=33.73%, avg_specificity=92.62% avg_auc=0.7751
Best model saved!! Metric=-44.421896982417245!!
Fold[1] Epoch: 9 [9/100 (9%)] Train loss=0.439678 Test loss=0.597508 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3699009418487549
[5/23] Train loss=0.455626517534256
[10/23] Train loss=0.4373440742492676
[15/23] Train loss=0.4346664845943451
[20/23] Train loss=0.38457322120666504
Test set avg_accuracy=77.48% avg_sensitivity=31.12%, avg_specificity=93.17% avg_auc=0.7755
Fold[1] Epoch: 10 [10/100 (10%)] Train loss=0.439837 Test loss=0.614359 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35836103558540344
[5/23] Train loss=0.4520932734012604
[10/23] Train loss=0.40058597922325134
[15/23] Train loss=0.4234859049320221
[20/23] Train loss=0.3781108260154724
Test set avg_accuracy=78.43% avg_sensitivity=38.32%, avg_specificity=92.00% avg_auc=0.7943
Best model saved!! Metric=-37.82528757574656!!
Fold[1] Epoch: 11 [11/100 (11%)] Train loss=0.433793 Test loss=0.543633 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3623320758342743
[5/23] Train loss=0.450730562210083
[10/23] Train loss=0.4009343385696411
[15/23] Train loss=0.4220559895038605
[20/23] Train loss=0.37899231910705566
Test set avg_accuracy=78.54% avg_sensitivity=38.69%, avg_specificity=92.03% avg_auc=0.8013
Best model saved!! Metric=-36.61623625294962!!
Fold[1] Epoch: 12 [12/100 (12%)] Train loss=0.428093 Test loss=0.549461 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3630179166793823
[5/23] Train loss=0.4489043056964874
[10/23] Train loss=0.3950328230857849
[15/23] Train loss=0.4163815677165985
[20/23] Train loss=0.37706488370895386
Test set avg_accuracy=79.00% avg_sensitivity=41.38%, avg_specificity=91.74% avg_auc=0.8090
Best model saved!! Metric=-32.98110171078856!!
Fold[1] Epoch: 13 [13/100 (13%)] Train loss=0.422142 Test loss=0.542656 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3657987117767334
[5/23] Train loss=0.44172218441963196
[10/23] Train loss=0.39514580368995667
[15/23] Train loss=0.39166000485420227
[20/23] Train loss=0.374259889125824
Test set avg_accuracy=78.72% avg_sensitivity=39.75%, avg_specificity=91.92% avg_auc=0.8128
Fold[1] Epoch: 14 [14/100 (14%)] Train loss=0.419715 Test loss=0.560059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3494705259799957
[5/23] Train loss=0.44774138927459717
[10/23] Train loss=0.38584965467453003
[15/23] Train loss=0.41089311242103577
[20/23] Train loss=0.36242473125457764
Test set avg_accuracy=79.12% avg_sensitivity=42.72%, avg_specificity=91.43% avg_auc=0.8245
Best model saved!! Metric=-30.28244781329074!!
Fold[1] Epoch: 15 [15/100 (15%)] Train loss=0.416960 Test loss=0.506463 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3559364378452301
[5/23] Train loss=0.43856099247932434
[10/23] Train loss=0.38087618350982666
[15/23] Train loss=0.3942885398864746
[20/23] Train loss=0.36227789521217346
Test set avg_accuracy=79.84% avg_sensitivity=48.33%, avg_specificity=90.50% avg_auc=0.8333
Best model saved!! Metric=-24.003990642154882!!
Fold[1] Epoch: 16 [16/100 (16%)] Train loss=0.409809 Test loss=0.469900 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36782005429267883
[5/23] Train loss=0.4311780035495758
[10/23] Train loss=0.3741176128387451
[15/23] Train loss=0.38628870248794556
[20/23] Train loss=0.3593405485153198
Test set avg_accuracy=79.79% avg_sensitivity=48.13%, avg_specificity=90.51% avg_auc=0.8352
Fold[1] Epoch: 17 [17/100 (17%)] Train loss=0.402964 Test loss=0.468475 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3459637463092804
[5/23] Train loss=0.42906323075294495
[10/23] Train loss=0.3723772466182709
[15/23] Train loss=0.3815866708755493
[20/23] Train loss=0.35575801134109497
Test set avg_accuracy=79.86% avg_sensitivity=45.65%, avg_specificity=91.43% avg_auc=0.8330
Fold[1] Epoch: 18 [18/100 (18%)] Train loss=0.403889 Test loss=0.489175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3385411500930786
[5/23] Train loss=0.4275806248188019
[10/23] Train loss=0.3729735314846039
[15/23] Train loss=0.38481223583221436
[20/23] Train loss=0.34493598341941833
Test set avg_accuracy=79.78% avg_sensitivity=45.36%, avg_specificity=91.43% avg_auc=0.8382
Fold[1] Epoch: 19 [19/100 (19%)] Train loss=0.402001 Test loss=0.473839 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3417649567127228
[5/23] Train loss=0.4236547648906708
[10/23] Train loss=0.3675006031990051
[15/23] Train loss=0.3806959092617035
[20/23] Train loss=0.34176716208457947
Test set avg_accuracy=80.14% avg_sensitivity=50.20%, avg_specificity=90.28% avg_auc=0.8448
Best model saved!! Metric=-20.894409663834708!!
Fold[1] Epoch: 20 [20/100 (20%)] Train loss=0.396601 Test loss=0.441664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3415277600288391
[5/23] Train loss=0.4295632839202881
[10/23] Train loss=0.35673725605010986
[15/23] Train loss=0.3662869930267334
[20/23] Train loss=0.339971125125885
Test set avg_accuracy=80.19% avg_sensitivity=50.65%, avg_specificity=90.18% avg_auc=0.8471
Best model saved!! Metric=-20.27201077160942!!
Fold[1] Epoch: 21 [21/100 (21%)] Train loss=0.393033 Test loss=0.444566 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33378344774246216
[5/23] Train loss=0.4210136830806732
[10/23] Train loss=0.354567289352417
[15/23] Train loss=0.3679645359516144
[20/23] Train loss=0.34091901779174805
Test set avg_accuracy=80.19% avg_sensitivity=47.93%, avg_specificity=91.10% avg_auc=0.8481
Fold[1] Epoch: 22 [22/100 (22%)] Train loss=0.393754 Test loss=0.447414 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32156115770339966
[5/23] Train loss=0.4240367114543915
[10/23] Train loss=0.36566823720932007
[15/23] Train loss=0.36832860112190247
[20/23] Train loss=0.33343830704689026
Test set avg_accuracy=80.30% avg_sensitivity=48.62%, avg_specificity=91.02% avg_auc=0.8471
Fold[1] Epoch: 23 [23/100 (23%)] Train loss=0.391777 Test loss=0.450769 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3283219337463379
[5/23] Train loss=0.4348783791065216
[10/23] Train loss=0.35544678568840027
[15/23] Train loss=0.3679954707622528
[20/23] Train loss=0.3368258476257324
Test set avg_accuracy=80.61% avg_sensitivity=52.36%, avg_specificity=90.17% avg_auc=0.8505
Best model saved!! Metric=-17.81484947586396!!
Fold[1] Epoch: 24 [24/100 (24%)] Train loss=0.390686 Test loss=0.435549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33445557951927185
[5/23] Train loss=0.41753479838371277
[10/23] Train loss=0.3463077247142792
[15/23] Train loss=0.36062005162239075
[20/23] Train loss=0.33317673206329346
Test set avg_accuracy=80.75% avg_sensitivity=54.64%, avg_specificity=89.59% avg_auc=0.8536
Best model saved!! Metric=-15.660757280090392!!
Fold[1] Epoch: 25 [25/100 (25%)] Train loss=0.382390 Test loss=0.428157 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3268413841724396
[5/23] Train loss=0.41315382719039917
[10/23] Train loss=0.350231796503067
[15/23] Train loss=0.3581577241420746
[20/23] Train loss=0.3283195495605469
Test set avg_accuracy=80.61% avg_sensitivity=51.26%, avg_specificity=90.54% avg_auc=0.8518
Fold[1] Epoch: 26 [26/100 (26%)] Train loss=0.383539 Test loss=0.435741 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3042813837528229
[5/23] Train loss=0.41840431094169617
[10/23] Train loss=0.34537503123283386
[15/23] Train loss=0.3530311584472656
[20/23] Train loss=0.324278861284256
Test set avg_accuracy=80.63% avg_sensitivity=50.41%, avg_specificity=90.86% avg_auc=0.8515
Fold[1] Epoch: 27 [27/100 (27%)] Train loss=0.382663 Test loss=0.442657 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30175116658210754
[5/23] Train loss=0.4094640910625458
[10/23] Train loss=0.34727922081947327
[15/23] Train loss=0.35763031244277954
[20/23] Train loss=0.3351469933986664
Test set avg_accuracy=80.93% avg_sensitivity=54.23%, avg_specificity=89.96% avg_auc=0.8540
Best model saved!! Metric=-15.477484808731948!!
Fold[1] Epoch: 28 [28/100 (28%)] Train loss=0.380405 Test loss=0.424612 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31860870122909546
[5/23] Train loss=0.41920986771583557
[10/23] Train loss=0.33859768509864807
[15/23] Train loss=0.34824255108833313
[20/23] Train loss=0.3321862816810608
Test set avg_accuracy=81.22% avg_sensitivity=59.44%, avg_specificity=88.60% avg_auc=0.8570
Best model saved!! Metric=-11.035320446872426!!
Fold[1] Epoch: 29 [29/100 (29%)] Train loss=0.377237 Test loss=0.416021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31426480412483215
[5/23] Train loss=0.4114867150783539
[10/23] Train loss=0.3403830826282501
[15/23] Train loss=0.34470200538635254
[20/23] Train loss=0.33013492822647095
Test set avg_accuracy=81.19% avg_sensitivity=58.91%, avg_specificity=88.74% avg_auc=0.8587
Fold[1] Epoch: 30 [30/100 (30%)] Train loss=0.374581 Test loss=0.414600 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30642396211624146
[5/23] Train loss=0.416960746049881
[10/23] Train loss=0.3410457372665405
[15/23] Train loss=0.34479933977127075
[20/23] Train loss=0.3216709792613983
Test set avg_accuracy=81.41% avg_sensitivity=56.39%, avg_specificity=89.88% avg_auc=0.8579
Fold[1] Epoch: 31 [31/100 (31%)] Train loss=0.372035 Test loss=0.418979 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29346027970314026
[5/23] Train loss=0.39933812618255615
[10/23] Train loss=0.3466578423976898
[15/23] Train loss=0.3422701358795166
[20/23] Train loss=0.32237163186073303
Test set avg_accuracy=80.95% avg_sensitivity=51.55%, avg_specificity=90.90% avg_auc=0.8545
Fold[1] Epoch: 32 [32/100 (32%)] Train loss=0.372713 Test loss=0.434725 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29438516497612
[5/23] Train loss=0.4115583002567291
[10/23] Train loss=0.3352774381637573
[15/23] Train loss=0.349907785654068
[20/23] Train loss=0.322072833776474
Test set avg_accuracy=81.23% avg_sensitivity=56.75%, avg_specificity=89.52% avg_auc=0.8554
Fold[1] Epoch: 33 [33/100 (33%)] Train loss=0.369869 Test loss=0.417535 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30547431111335754
[5/23] Train loss=0.40362122654914856
[10/23] Train loss=0.32986658811569214
[15/23] Train loss=0.3405739963054657
[20/23] Train loss=0.3149056136608124
Test set avg_accuracy=81.29% avg_sensitivity=58.95%, avg_specificity=88.85% avg_auc=0.8574
Fold[1] Epoch: 34 [34/100 (34%)] Train loss=0.365296 Test loss=0.413664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.299699991941452
[5/23] Train loss=0.4025273621082306
[10/23] Train loss=0.3270280957221985
[15/23] Train loss=0.34156227111816406
[20/23] Train loss=0.3185610771179199
Test set avg_accuracy=81.42% avg_sensitivity=58.30%, avg_specificity=89.25% avg_auc=0.8559
Fold[1] Epoch: 35 [35/100 (35%)] Train loss=0.363408 Test loss=0.412753 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2825249433517456
[5/23] Train loss=0.39285850524902344
[10/23] Train loss=0.33122238516807556
[15/23] Train loss=0.33512887358665466
[20/23] Train loss=0.3176690340042114
Test set avg_accuracy=81.36% avg_sensitivity=57.85%, avg_specificity=89.31% avg_auc=0.8568
Fold[1] Epoch: 36 [36/100 (36%)] Train loss=0.361495 Test loss=0.410464 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2850760817527771
[5/23] Train loss=0.3991662263870239
[10/23] Train loss=0.3310018479824066
[15/23] Train loss=0.3357561230659485
[20/23] Train loss=0.3194107115268707
Test set avg_accuracy=81.52% avg_sensitivity=56.88%, avg_specificity=89.87% avg_auc=0.8593
Fold[1] Epoch: 37 [37/100 (37%)] Train loss=0.362202 Test loss=0.411352 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2765132188796997
[5/23] Train loss=0.3957401514053345
[10/23] Train loss=0.3269343376159668
[15/23] Train loss=0.3307737112045288
[20/23] Train loss=0.3170805871486664
Test set avg_accuracy=81.38% avg_sensitivity=55.04%, avg_specificity=90.29% avg_auc=0.8583
Fold[1] Epoch: 38 [38/100 (38%)] Train loss=0.359583 Test loss=0.419295 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27115198969841003
[5/23] Train loss=0.38903066515922546
[10/23] Train loss=0.33458471298217773
[15/23] Train loss=0.3365970849990845
[20/23] Train loss=0.31341689825057983
Test set avg_accuracy=81.36% avg_sensitivity=54.31%, avg_specificity=90.51% avg_auc=0.8606
Fold[1] Epoch: 39 [39/100 (39%)] Train loss=0.359270 Test loss=0.418495 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2801898419857025
[5/23] Train loss=0.39995473623275757
[10/23] Train loss=0.32497116923332214
[15/23] Train loss=0.3376137912273407
[20/23] Train loss=0.3130472004413605
Test set avg_accuracy=81.45% avg_sensitivity=57.32%, avg_specificity=89.62% avg_auc=0.8598
Fold[1] Epoch: 40 [40/100 (40%)] Train loss=0.357731 Test loss=0.414994 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28527170419692993
[5/23] Train loss=0.39370229840278625
[10/23] Train loss=0.31994789838790894
[15/23] Train loss=0.32256603240966797
[20/23] Train loss=0.30340519547462463
Test set avg_accuracy=81.52% avg_sensitivity=58.18%, avg_specificity=89.42% avg_auc=0.8586
Best model saved!! Metric=-11.020033827730611!!
Fold[1] Epoch: 41 [41/100 (41%)] Train loss=0.353135 Test loss=0.416681 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2794058918952942
[5/23] Train loss=0.3872455656528473
[10/23] Train loss=0.3266618251800537
[15/23] Train loss=0.32976269721984863
[20/23] Train loss=0.30631959438323975
Test set avg_accuracy=81.78% avg_sensitivity=61.19%, avg_specificity=88.75% avg_auc=0.8608
Best model saved!! Metric=-8.203181748104951!!
Fold[1] Epoch: 42 [42/100 (42%)] Train loss=0.351593 Test loss=0.410960 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2719764709472656
[5/23] Train loss=0.3824848234653473
[10/23] Train loss=0.3199975788593292
[15/23] Train loss=0.30950120091438293
[20/23] Train loss=0.29978930950164795
Test set avg_accuracy=81.54% avg_sensitivity=59.52%, avg_specificity=89.00% avg_auc=0.8593
Fold[1] Epoch: 43 [43/100 (43%)] Train loss=0.347794 Test loss=0.416420 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26443415880203247
[5/23] Train loss=0.38382166624069214
[10/23] Train loss=0.3200880289077759
[15/23] Train loss=0.31598159670829773
[20/23] Train loss=0.30065757036209106
Test set avg_accuracy=81.26% avg_sensitivity=54.39%, avg_specificity=90.35% avg_auc=0.8586
Fold[1] Epoch: 44 [44/100 (44%)] Train loss=0.347529 Test loss=0.417615 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25942832231521606
[5/23] Train loss=0.39132237434387207
[10/23] Train loss=0.3168964982032776
[15/23] Train loss=0.3197568655014038
[20/23] Train loss=0.3007931113243103
Test set avg_accuracy=81.45% avg_sensitivity=53.54%, avg_specificity=90.90% avg_auc=0.8581
Fold[1] Epoch: 45 [45/100 (45%)] Train loss=0.345435 Test loss=0.416711 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2569975256919861
[5/23] Train loss=0.3859706521034241
[10/23] Train loss=0.32218465209007263
[15/23] Train loss=0.3137097656726837
[20/23] Train loss=0.2964532971382141
Test set avg_accuracy=81.38% avg_sensitivity=52.93%, avg_specificity=91.01% avg_auc=0.8592
Fold[1] Epoch: 46 [46/100 (46%)] Train loss=0.345911 Test loss=0.423397 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2519305646419525
[5/23] Train loss=0.3845789432525635
[10/23] Train loss=0.31390517950057983
[15/23] Train loss=0.3207852840423584
[20/23] Train loss=0.29149138927459717
Test set avg_accuracy=81.41% avg_sensitivity=55.17%, avg_specificity=90.29% avg_auc=0.8593
Fold[1] Epoch: 47 [47/100 (47%)] Train loss=0.343496 Test loss=0.415613 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24969448149204254
[5/23] Train loss=0.3880196213722229
[10/23] Train loss=0.3159111738204956
[15/23] Train loss=0.31221041083335876
[20/23] Train loss=0.3004654049873352
Test set avg_accuracy=81.19% avg_sensitivity=51.59%, avg_specificity=91.21% avg_auc=0.8534
Fold[1] Epoch: 48 [48/100 (48%)] Train loss=0.343909 Test loss=0.427189 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2572390139102936
[5/23] Train loss=0.3835735619068146
[10/23] Train loss=0.3069293200969696
[15/23] Train loss=0.32178014516830444
[20/23] Train loss=0.29750239849090576
Test set avg_accuracy=81.66% avg_sensitivity=57.69%, avg_specificity=89.77% avg_auc=0.8601
Fold[1] Epoch: 49 [49/100 (49%)] Train loss=0.339072 Test loss=0.416931 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2516408860683441
[5/23] Train loss=0.37774237990379333
[10/23] Train loss=0.29888370633125305
[15/23] Train loss=0.31000393629074097
[20/23] Train loss=0.28957194089889526
Test set avg_accuracy=81.78% avg_sensitivity=58.50%, avg_specificity=89.66% avg_auc=0.8625
Fold[1] Epoch: 50 [50/100 (50%)] Train loss=0.336774 Test loss=0.411499 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2449989765882492
[5/23] Train loss=0.3773258328437805
[10/23] Train loss=0.2976466119289398
[15/23] Train loss=0.3087053596973419
[20/23] Train loss=0.2884067893028259
Test set avg_accuracy=81.53% avg_sensitivity=56.92%, avg_specificity=89.87% avg_auc=0.8585
Fold[1] Epoch: 51 [51/100 (51%)] Train loss=0.331555 Test loss=0.414074 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2470771223306656
[5/23] Train loss=0.38065043091773987
[10/23] Train loss=0.29478657245635986
[15/23] Train loss=0.3080665171146393
[20/23] Train loss=0.288730263710022
Test set avg_accuracy=81.38% avg_sensitivity=57.04%, avg_specificity=89.62% avg_auc=0.8575
Fold[1] Epoch: 52 [52/100 (52%)] Train loss=0.332961 Test loss=0.414596 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24588939547538757
[5/23] Train loss=0.3706822991371155
[10/23] Train loss=0.30693671107292175
[15/23] Train loss=0.3030024468898773
[20/23] Train loss=0.2880557179450989
Test set avg_accuracy=81.24% avg_sensitivity=52.56%, avg_specificity=90.95% avg_auc=0.8594
Fold[1] Epoch: 53 [53/100 (53%)] Train loss=0.332499 Test loss=0.424397 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24823978543281555
[5/23] Train loss=0.3706892430782318
[10/23] Train loss=0.2992395758628845
[15/23] Train loss=0.2992936372756958
[20/23] Train loss=0.2846975028514862
Test set avg_accuracy=81.26% avg_sensitivity=51.18%, avg_specificity=91.43% avg_auc=0.8559
Fold[1] Epoch: 54 [54/100 (54%)] Train loss=0.329516 Test loss=0.427538 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24753451347351074
[5/23] Train loss=0.376016765832901
[10/23] Train loss=0.29316389560699463
[15/23] Train loss=0.2996726334095001
[20/23] Train loss=0.28089046478271484
Test set avg_accuracy=81.60% avg_sensitivity=56.51%, avg_specificity=90.10% avg_auc=0.8599
Fold[1] Epoch: 55 [55/100 (55%)] Train loss=0.329295 Test loss=0.420231 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24145075678825378
[5/23] Train loss=0.3716981112957001
[10/23] Train loss=0.2880822420120239
[15/23] Train loss=0.30130627751350403
[20/23] Train loss=0.28123241662979126
Test set avg_accuracy=81.43% avg_sensitivity=56.43%, avg_specificity=89.89% avg_auc=0.8528
Fold[1] Epoch: 56 [56/100 (56%)] Train loss=0.325805 Test loss=0.420221 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2402719259262085
[5/23] Train loss=0.3658417761325836
[10/23] Train loss=0.2835223972797394
[15/23] Train loss=0.29874783754348755
[20/23] Train loss=0.27684423327445984
Test set avg_accuracy=81.35% avg_sensitivity=57.69%, avg_specificity=89.36% avg_auc=0.8531
Fold[1] Epoch: 57 [57/100 (57%)] Train loss=0.319176 Test loss=0.425287 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24156561493873596
[5/23] Train loss=0.36175259947776794
[10/23] Train loss=0.28487226366996765
[15/23] Train loss=0.2972814738750458
[20/23] Train loss=0.27663758397102356
Test set avg_accuracy=81.20% avg_sensitivity=54.96%, avg_specificity=90.09% avg_auc=0.8552
Fold[1] Epoch: 58 [58/100 (58%)] Train loss=0.317018 Test loss=0.419208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2332485318183899
[5/23] Train loss=0.37377849221229553
[10/23] Train loss=0.28544241189956665
[15/23] Train loss=0.29413896799087524
[20/23] Train loss=0.2710716128349304
Test set avg_accuracy=81.46% avg_sensitivity=56.43%, avg_specificity=89.93% avg_auc=0.8537
Fold[1] Epoch: 59 [59/100 (59%)] Train loss=0.316963 Test loss=0.416177 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2285957783460617
[5/23] Train loss=0.3563721179962158
[10/23] Train loss=0.28609099984169006
[15/23] Train loss=0.29509544372558594
[20/23] Train loss=0.2755819857120514
Test set avg_accuracy=81.46% avg_sensitivity=55.86%, avg_specificity=90.13% avg_auc=0.8596
Fold[1] Epoch: 60 [60/100 (60%)] Train loss=0.314719 Test loss=0.416289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23134459555149078
[5/23] Train loss=0.35544148087501526
[10/23] Train loss=0.28666338324546814
[15/23] Train loss=0.2881285846233368
[20/23] Train loss=0.2763430178165436
Test set avg_accuracy=81.46% avg_sensitivity=58.14%, avg_specificity=89.36% avg_auc=0.8557
Fold[1] Epoch: 61 [61/100 (61%)] Train loss=0.314008 Test loss=0.425876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22524325549602509
[5/23] Train loss=0.358492374420166
[10/23] Train loss=0.28490039706230164
[15/23] Train loss=0.29228419065475464
[20/23] Train loss=0.27185624837875366
Test set avg_accuracy=80.95% avg_sensitivity=55.04%, avg_specificity=89.71% avg_auc=0.8532
Fold[1] Epoch: 62 [62/100 (62%)] Train loss=0.311737 Test loss=0.423505 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21446159482002258
[5/23] Train loss=0.36127662658691406
[10/23] Train loss=0.2836107611656189
[15/23] Train loss=0.29826095700263977
[20/23] Train loss=0.2601962089538574
Test set avg_accuracy=81.28% avg_sensitivity=53.58%, avg_specificity=90.65% avg_auc=0.8518
Fold[1] Epoch: 63 [63/100 (63%)] Train loss=0.311555 Test loss=0.428705 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22301223874092102
[5/23] Train loss=0.3415592312812805
[10/23] Train loss=0.2800484001636505
[15/23] Train loss=0.285888671875
[20/23] Train loss=0.2763984799385071
Test set avg_accuracy=80.48% avg_sensitivity=49.10%, avg_specificity=91.10% avg_auc=0.8394
Fold[1] Epoch: 64 [64/100 (64%)] Train loss=0.307997 Test loss=0.444607 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22192148864269257
[5/23] Train loss=0.3510071933269501
[10/23] Train loss=0.28611135482788086
[15/23] Train loss=0.2805175185203552
[20/23] Train loss=0.26340675354003906
Test set avg_accuracy=81.50% avg_sensitivity=53.38%, avg_specificity=91.02% avg_auc=0.8563
Fold[1] Epoch: 65 [65/100 (65%)] Train loss=0.309118 Test loss=0.430128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22035010159015656
[5/23] Train loss=0.3530951738357544
[10/23] Train loss=0.28743815422058105
[15/23] Train loss=0.2850049138069153
[20/23] Train loss=0.2677278220653534
Test set avg_accuracy=81.35% avg_sensitivity=53.01%, avg_specificity=90.94% avg_auc=0.8600
Fold[1] Epoch: 66 [66/100 (66%)] Train loss=0.308857 Test loss=0.429154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22423478960990906
[5/23] Train loss=0.34807687997817993
[10/23] Train loss=0.2690518796443939
[15/23] Train loss=0.2846047878265381
[20/23] Train loss=0.26969432830810547
Test set avg_accuracy=81.47% avg_sensitivity=54.39%, avg_specificity=90.64% avg_auc=0.8595
Fold[1] Epoch: 67 [67/100 (67%)] Train loss=0.305167 Test loss=0.436775 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21527954936027527
[5/23] Train loss=0.35139697790145874
[10/23] Train loss=0.28144803643226624
[15/23] Train loss=0.28116875886917114
[20/23] Train loss=0.26622486114501953
Test set avg_accuracy=81.10% avg_sensitivity=51.38%, avg_specificity=91.16% avg_auc=0.8564
Fold[1] Epoch: 68 [68/100 (68%)] Train loss=0.300337 Test loss=0.437905 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20863288640975952
[5/23] Train loss=0.34591639041900635
[10/23] Train loss=0.26786819100379944
[15/23] Train loss=0.2798626124858856
[20/23] Train loss=0.255634069442749
Test set avg_accuracy=81.31% avg_sensitivity=54.23%, avg_specificity=90.47% avg_auc=0.8549
Fold[1] Epoch: 69 [69/100 (69%)] Train loss=0.298481 Test loss=0.436364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20938530564308167
[5/23] Train loss=0.3514155149459839
[10/23] Train loss=0.25982239842414856
[15/23] Train loss=0.27211320400238037
[20/23] Train loss=0.2621833384037018
Test set avg_accuracy=81.09% avg_sensitivity=56.59%, avg_specificity=89.38% avg_auc=0.8509
Fold[1] Epoch: 70 [70/100 (70%)] Train loss=0.296635 Test loss=0.430545 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20254164934158325
[5/23] Train loss=0.3463577330112457
[10/23] Train loss=0.27496498823165894
[15/23] Train loss=0.27773338556289673
[20/23] Train loss=0.2577674388885498
Test set avg_accuracy=80.94% avg_sensitivity=54.15%, avg_specificity=90.00% avg_auc=0.8483
Fold[1] Epoch: 71 [71/100 (71%)] Train loss=0.294325 Test loss=0.430217 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20871123671531677
[5/23] Train loss=0.3453325927257538
[10/23] Train loss=0.2588869035243988
[15/23] Train loss=0.2686934471130371
[20/23] Train loss=0.2556869089603424
Test set avg_accuracy=81.20% avg_sensitivity=56.92%, avg_specificity=89.42% avg_auc=0.8465
Fold[1] Epoch: 72 [72/100 (72%)] Train loss=0.289501 Test loss=0.440198 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20664826035499573
[5/23] Train loss=0.3410542607307434
[10/23] Train loss=0.2705537676811218
[15/23] Train loss=0.26644495129585266
[20/23] Train loss=0.25067055225372314
Test set avg_accuracy=81.06% avg_sensitivity=58.10%, avg_specificity=88.83% avg_auc=0.8555
Fold[1] Epoch: 73 [73/100 (73%)] Train loss=0.287708 Test loss=0.433646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20765696465969086
[5/23] Train loss=0.32971078157424927
[10/23] Train loss=0.2652358412742615
[15/23] Train loss=0.2609332799911499
[20/23] Train loss=0.2481047809123993
Test set avg_accuracy=80.95% avg_sensitivity=56.18%, avg_specificity=89.33% avg_auc=0.8547
Fold[1] Epoch: 74 [74/100 (74%)] Train loss=0.286950 Test loss=0.440852 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20531341433525085
[5/23] Train loss=0.33809608221054077
[10/23] Train loss=0.26278892159461975
[15/23] Train loss=0.2643590569496155
[20/23] Train loss=0.24384140968322754
Test set avg_accuracy=80.80% avg_sensitivity=57.93%, avg_specificity=88.54% avg_auc=0.8473
Fold[1] Epoch: 75 [75/100 (75%)] Train loss=0.285787 Test loss=0.440501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19687041640281677
[5/23] Train loss=0.33378949761390686
[10/23] Train loss=0.2603180706501007
[15/23] Train loss=0.26495516300201416
[20/23] Train loss=0.23749856650829315
Test set avg_accuracy=81.39% avg_sensitivity=57.32%, avg_specificity=89.53% avg_auc=0.8558
Fold[1] Epoch: 76 [76/100 (76%)] Train loss=0.283021 Test loss=0.439316 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.196674644947052
[5/23] Train loss=0.32907989621162415
[10/23] Train loss=0.2600224018096924
[15/23] Train loss=0.2699732482433319
[20/23] Train loss=0.24831172823905945
Test set avg_accuracy=81.39% avg_sensitivity=57.97%, avg_specificity=89.31% avg_auc=0.8592
Fold[1] Epoch: 77 [77/100 (77%)] Train loss=0.282160 Test loss=0.440442 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1896193027496338
[5/23] Train loss=0.3224949836730957
[10/23] Train loss=0.2605442702770233
[15/23] Train loss=0.2563077509403229
[20/23] Train loss=0.2378750741481781
Test set avg_accuracy=81.68% avg_sensitivity=59.32%, avg_specificity=89.25% avg_auc=0.8583
Fold[1] Epoch: 78 [78/100 (78%)] Train loss=0.280892 Test loss=0.444708 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19406993687152863
[5/23] Train loss=0.3294045925140381
[10/23] Train loss=0.2720355689525604
[15/23] Train loss=0.2630312442779541
[20/23] Train loss=0.2410004884004593
Test set avg_accuracy=81.90% avg_sensitivity=56.14%, avg_specificity=90.62% avg_auc=0.8641
Fold[1] Epoch: 79 [79/100 (79%)] Train loss=0.283163 Test loss=0.437733 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18835186958312988
[5/23] Train loss=0.3254658579826355
[10/23] Train loss=0.2792411148548126
[15/23] Train loss=0.2538975179195404
[20/23] Train loss=0.23898589611053467
Test set avg_accuracy=81.38% avg_sensitivity=48.90%, avg_specificity=92.37% avg_auc=0.8581
Fold[1] Epoch: 80 [80/100 (80%)] Train loss=0.282452 Test loss=0.447487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19290108978748322
[5/23] Train loss=0.3304859399795532
[10/23] Train loss=0.2577722370624542
[15/23] Train loss=0.2703234851360321
[20/23] Train loss=0.2398572862148285
Test set avg_accuracy=81.47% avg_sensitivity=51.10%, avg_specificity=91.75% avg_auc=0.8609
Fold[1] Epoch: 81 [81/100 (81%)] Train loss=0.283160 Test loss=0.450977 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18661655485630035
[5/23] Train loss=0.3281887471675873
[10/23] Train loss=0.2514369785785675
[15/23] Train loss=0.2553357481956482
[20/23] Train loss=0.24161462485790253
Test set avg_accuracy=81.03% avg_sensitivity=54.56%, avg_specificity=89.99% avg_auc=0.8499
Fold[1] Epoch: 82 [82/100 (82%)] Train loss=0.280220 Test loss=0.450481 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18992184102535248
[5/23] Train loss=0.32018575072288513
[10/23] Train loss=0.2534398138523102
[15/23] Train loss=0.24471019208431244
[20/23] Train loss=0.23263798654079437
Test set avg_accuracy=81.07% avg_sensitivity=56.71%, avg_specificity=89.31% avg_auc=0.8501
Fold[1] Epoch: 83 [83/100 (83%)] Train loss=0.269005 Test loss=0.453749 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1908917874097824
[5/23] Train loss=0.30776408314704895
[10/23] Train loss=0.25945720076560974
[15/23] Train loss=0.2524188458919525
[20/23] Train loss=0.23853816092014313
Test set avg_accuracy=81.05% avg_sensitivity=53.13%, avg_specificity=90.50% avg_auc=0.8523
Fold[1] Epoch: 84 [84/100 (84%)] Train loss=0.269808 Test loss=0.453570 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1694018393754959
[5/23] Train loss=0.3107326924800873
[10/23] Train loss=0.24660617113113403
[15/23] Train loss=0.2610756754875183
[20/23] Train loss=0.2325725108385086
Test set avg_accuracy=81.54% avg_sensitivity=58.26%, avg_specificity=89.42% avg_auc=0.8558
Fold[1] Epoch: 85 [85/100 (85%)] Train loss=0.266619 Test loss=0.442152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18589405715465546
[5/23] Train loss=0.3182868957519531
[10/23] Train loss=0.24255086481571198
[15/23] Train loss=0.25676634907722473
[20/23] Train loss=0.22027981281280518
Test set avg_accuracy=81.69% avg_sensitivity=57.61%, avg_specificity=89.84% avg_auc=0.8568
Fold[1] Epoch: 86 [86/100 (86%)] Train loss=0.266354 Test loss=0.455387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1725369393825531
[5/23] Train loss=0.3210464119911194
[10/23] Train loss=0.23877976834774017
[15/23] Train loss=0.24766431748867035
[20/23] Train loss=0.22423498332500458
Test set avg_accuracy=81.24% avg_sensitivity=56.27%, avg_specificity=89.70% avg_auc=0.8577
Fold[1] Epoch: 87 [87/100 (87%)] Train loss=0.260916 Test loss=0.459065 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16721799969673157
[5/23] Train loss=0.3088138997554779
[10/23] Train loss=0.24209079146385193
[15/23] Train loss=0.24453085660934448
[20/23] Train loss=0.22753411531448364
Test set avg_accuracy=81.12% avg_sensitivity=54.23%, avg_specificity=90.22% avg_auc=0.8484
Fold[1] Epoch: 88 [88/100 (88%)] Train loss=0.259891 Test loss=0.455011 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17803393304347992
[5/23] Train loss=0.3167017996311188
[10/23] Train loss=0.24721075594425201
[15/23] Train loss=0.23740272223949432
[20/23] Train loss=0.22627146542072296
Test set avg_accuracy=80.73% avg_sensitivity=50.69%, avg_specificity=90.90% avg_auc=0.8440
Fold[1] Epoch: 89 [89/100 (89%)] Train loss=0.257612 Test loss=0.477500 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16251569986343384
[5/23] Train loss=0.30418485403060913
[10/23] Train loss=0.24926188588142395
[15/23] Train loss=0.24335278570652008
[20/23] Train loss=0.2120869904756546
Test set avg_accuracy=81.16% avg_sensitivity=56.71%, avg_specificity=89.44% avg_auc=0.8485
Fold[1] Epoch: 90 [90/100 (90%)] Train loss=0.254563 Test loss=0.473928 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16979825496673584
[5/23] Train loss=0.3124173581600189
[10/23] Train loss=0.23724649846553802
[15/23] Train loss=0.23637838661670685
[20/23] Train loss=0.22094561159610748
Test set avg_accuracy=81.52% avg_sensitivity=54.23%, avg_specificity=90.76% avg_auc=0.8577
Fold[1] Epoch: 91 [91/100 (91%)] Train loss=0.255489 Test loss=0.461553 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1653263121843338
[5/23] Train loss=0.29708608984947205
[10/23] Train loss=0.23762767016887665
[15/23] Train loss=0.23749089241027832
[20/23] Train loss=0.2153642624616623
Test set avg_accuracy=81.65% avg_sensitivity=56.79%, avg_specificity=90.06% avg_auc=0.8551
Fold[1] Epoch: 92 [92/100 (92%)] Train loss=0.251665 Test loss=0.458137 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16542750597000122
[5/23] Train loss=0.2966405749320984
[10/23] Train loss=0.23685602843761444
[15/23] Train loss=0.23239178955554962
[20/23] Train loss=0.20982518792152405
Test set avg_accuracy=81.20% avg_sensitivity=51.83%, avg_specificity=91.15% avg_auc=0.8473
Fold[1] Epoch: 93 [93/100 (93%)] Train loss=0.248192 Test loss=0.467579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16582061350345612
[5/23] Train loss=0.2911299467086792
[10/23] Train loss=0.22779050469398499
[15/23] Train loss=0.24176649749279022
[20/23] Train loss=0.21123576164245605
Test set avg_accuracy=81.10% avg_sensitivity=52.97%, avg_specificity=90.62% avg_auc=0.8483
Fold[1] Epoch: 94 [94/100 (94%)] Train loss=0.247201 Test loss=0.458390 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16084162890911102
[5/23] Train loss=0.3126305341720581
[10/23] Train loss=0.22122327983379364
[15/23] Train loss=0.23140914738178253
[20/23] Train loss=0.21240286529064178
Test set avg_accuracy=81.11% avg_sensitivity=57.36%, avg_specificity=89.15% avg_auc=0.8518
Fold[1] Epoch: 95 [95/100 (95%)] Train loss=0.246391 Test loss=0.463305 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16357432305812836
[5/23] Train loss=0.2832168936729431
[10/23] Train loss=0.23626552522182465
[15/23] Train loss=0.24071073532104492
[20/23] Train loss=0.2087613195180893
Test set avg_accuracy=81.21% avg_sensitivity=58.18%, avg_specificity=89.01% avg_auc=0.8551
Fold[1] Epoch: 96 [96/100 (96%)] Train loss=0.243521 Test loss=0.472148 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16400061547756195
[5/23] Train loss=0.27217864990234375
[10/23] Train loss=0.2239210307598114
[15/23] Train loss=0.22859443724155426
[20/23] Train loss=0.1905236542224884
Test set avg_accuracy=81.18% avg_sensitivity=54.31%, avg_specificity=90.28% avg_auc=0.8487
Fold[1] Epoch: 97 [97/100 (97%)] Train loss=0.241251 Test loss=0.476604 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14892375469207764
[5/23] Train loss=0.2985861599445343
[10/23] Train loss=0.22496509552001953
[15/23] Train loss=0.23182694613933563
[20/23] Train loss=0.20828337967395782
Test set avg_accuracy=81.16% avg_sensitivity=55.53%, avg_specificity=89.84% avg_auc=0.8525
Fold[1] Epoch: 98 [98/100 (98%)] Train loss=0.240913 Test loss=0.463603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1520109921693802
[5/23] Train loss=0.28258487582206726
[10/23] Train loss=0.22854074835777283
[15/23] Train loss=0.22826352715492249
[20/23] Train loss=0.20820161700248718
Test set avg_accuracy=81.27% avg_sensitivity=54.23%, avg_specificity=90.42% avg_auc=0.8503
Fold[1] Epoch: 99 [99/100 (99%)] Train loss=0.238458 Test loss=0.468987 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15143336355686188
[5/23] Train loss=0.2964757978916168
[10/23] Train loss=0.22984667122364044
[15/23] Train loss=0.23248134553432465
[20/23] Train loss=0.19845858216285706
Test set avg_accuracy=81.82% avg_sensitivity=55.94%, avg_specificity=90.58% avg_auc=0.8576
Fold[1] Epoch: 100 [100/100 (100%)] Train loss=0.239904 Test loss=0.466883 Current lr=[3.9999999999999996e-05]

Fold[1] Best Result: acc=81.7798353909465 sen=61.1879576891782, spe=88.74965574221977, auc=0.8607936942955058!
[0/23] Train loss=0.6740948557853699
[5/23] Train loss=0.632610023021698
[10/23] Train loss=0.5652276873588562
[15/23] Train loss=0.5526598691940308
[20/23] Train loss=0.5498847365379333
Test set avg_accuracy=76.91% avg_sensitivity=0.00%, avg_specificity=99.99% avg_auc=0.5574
Best model saved!! Metric=-93.35697246119145!!
Fold[2] Epoch: 1 [1/100 (1%)] Train loss=0.577474 Test loss=0.572768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5610813498497009
[5/23] Train loss=0.6047233939170837
[10/23] Train loss=0.5583013892173767
[15/23] Train loss=0.5441972613334656
[20/23] Train loss=0.5348074436187744
Test set avg_accuracy=76.96% avg_sensitivity=0.36%, avg_specificity=99.95% avg_auc=0.5839
Best model saved!! Metric=-90.3417182337465!!
Fold[2] Epoch: 2 [2/100 (2%)] Train loss=0.559223 Test loss=0.567181 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5656536221504211
[5/23] Train loss=0.6003965735435486
[10/23] Train loss=0.5525653958320618
[15/23] Train loss=0.5409644246101379
[20/23] Train loss=0.508785605430603
Test set avg_accuracy=76.66% avg_sensitivity=5.15%, avg_specificity=98.11% avg_auc=0.6122
Best model saved!! Metric=-84.85138021934159!!
Fold[2] Epoch: 3 [3/100 (3%)] Train loss=0.548867 Test loss=0.576101 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.544898271560669
[5/23] Train loss=0.580778956413269
[10/23] Train loss=0.5243021845817566
[15/23] Train loss=0.5230405330657959
[20/23] Train loss=0.47657737135887146
Test set avg_accuracy=76.86% avg_sensitivity=11.57%, avg_specificity=96.45% avg_auc=0.6709
Best model saved!! Metric=-74.02622744257243!!
Fold[2] Epoch: 4 [4/100 (4%)] Train loss=0.524390 Test loss=0.575835 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5141573548316956
[5/23] Train loss=0.5333766937255859
[10/23] Train loss=0.49444493651390076
[15/23] Train loss=0.5068610310554504
[20/23] Train loss=0.4398266077041626
Test set avg_accuracy=77.27% avg_sensitivity=17.13%, avg_specificity=95.31% avg_auc=0.7086
Best model saved!! Metric=-65.4296655792993!!
Fold[2] Epoch: 5 [5/100 (5%)] Train loss=0.497454 Test loss=0.578879 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48851239681243896
[5/23] Train loss=0.5026066899299622
[10/23] Train loss=0.45768892765045166
[15/23] Train loss=0.4991345703601837
[20/23] Train loss=0.4086790680885315
Test set avg_accuracy=78.16% avg_sensitivity=23.55%, avg_specificity=94.55% avg_auc=0.7354
Best model saved!! Metric=-56.196084345071185!!
Fold[2] Epoch: 6 [6/100 (6%)] Train loss=0.474199 Test loss=0.563998 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4578014314174652
[5/23] Train loss=0.48426440358161926
[10/23] Train loss=0.4405233860015869
[15/23] Train loss=0.4739167392253876
[20/23] Train loss=0.4019553065299988
Test set avg_accuracy=78.42% avg_sensitivity=26.22%, avg_specificity=94.09% avg_auc=0.7450
Best model saved!! Metric=-52.763299325637576!!
Fold[2] Epoch: 7 [7/100 (7%)] Train loss=0.458694 Test loss=0.586475 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4447055757045746
[5/23] Train loss=0.4590006172657013
[10/23] Train loss=0.42702236771583557
[15/23] Train loss=0.45479056239128113
[20/23] Train loss=0.3903603255748749
Test set avg_accuracy=78.51% avg_sensitivity=29.25%, avg_specificity=93.29% avg_auc=0.7597
Best model saved!! Metric=-48.98809056656662!!
Fold[2] Epoch: 8 [8/100 (8%)] Train loss=0.447029 Test loss=0.568541 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4291355311870575
[5/23] Train loss=0.46876856684684753
[10/23] Train loss=0.41036298871040344
[15/23] Train loss=0.43938812613487244
[20/23] Train loss=0.37550708651542664
Test set avg_accuracy=78.64% avg_sensitivity=31.37%, avg_specificity=92.83% avg_auc=0.7623
Best model saved!! Metric=-46.92988218478741!!
Fold[2] Epoch: 9 [9/100 (9%)] Train loss=0.438075 Test loss=0.562698 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.419831246137619
[5/23] Train loss=0.45948103070259094
[10/23] Train loss=0.41317835450172424
[15/23] Train loss=0.42341849207878113
[20/23] Train loss=0.3735427260398865
Test set avg_accuracy=78.73% avg_sensitivity=33.09%, avg_specificity=92.42% avg_auc=0.7622
Best model saved!! Metric=-45.545624329372814!!
Fold[2] Epoch: 10 [10/100 (10%)] Train loss=0.431901 Test loss=0.560630 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41649866104125977
[5/23] Train loss=0.4562860429286957
[10/23] Train loss=0.4171556532382965
[15/23] Train loss=0.4115792512893677
[20/23] Train loss=0.37043294310569763
Test set avg_accuracy=79.22% avg_sensitivity=35.22%, avg_specificity=92.42% avg_auc=0.7641
Best model saved!! Metric=-42.7362562612875!!
Fold[2] Epoch: 11 [11/100 (11%)] Train loss=0.427856 Test loss=0.560575 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.426918625831604
[5/23] Train loss=0.4464787244796753
[10/23] Train loss=0.3947681486606598
[15/23] Train loss=0.41316795349121094
[20/23] Train loss=0.36310872435569763
Test set avg_accuracy=79.32% avg_sensitivity=39.65%, avg_specificity=91.22% avg_auc=0.7927
Best model saved!! Metric=-36.531771058726555!!
Fold[2] Epoch: 12 [12/100 (12%)] Train loss=0.421712 Test loss=0.511218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4025488495826721
[5/23] Train loss=0.44340476393699646
[10/23] Train loss=0.3766072392463684
[15/23] Train loss=0.399761438369751
[20/23] Train loss=0.3662738800048828
Test set avg_accuracy=79.26% avg_sensitivity=41.14%, avg_specificity=90.70% avg_auc=0.7989
Best model saved!! Metric=-35.015836767026954!!
Fold[2] Epoch: 13 [13/100 (13%)] Train loss=0.411685 Test loss=0.498291 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40466687083244324
[5/23] Train loss=0.4415481388568878
[10/23] Train loss=0.3831431567668915
[15/23] Train loss=0.39758241176605225
[20/23] Train loss=0.35535237193107605
Test set avg_accuracy=79.20% avg_sensitivity=41.82%, avg_specificity=90.41% avg_auc=0.8004
Best model saved!! Metric=-34.539115242500706!!
Fold[2] Epoch: 14 [14/100 (14%)] Train loss=0.408765 Test loss=0.494745 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4002399146556854
[5/23] Train loss=0.43107375502586365
[10/23] Train loss=0.3850191831588745
[15/23] Train loss=0.38840383291244507
[20/23] Train loss=0.35678258538246155
Test set avg_accuracy=79.48% avg_sensitivity=40.24%, avg_specificity=91.25% avg_auc=0.8006
Fold[2] Epoch: 15 [15/100 (15%)] Train loss=0.408012 Test loss=0.502173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4050852358341217
[5/23] Train loss=0.4393062889575958
[10/23] Train loss=0.3745146095752716
[15/23] Train loss=0.38880741596221924
[20/23] Train loss=0.3523885905742645
Test set avg_accuracy=79.59% avg_sensitivity=41.14%, avg_specificity=91.13% avg_auc=0.8049
Best model saved!! Metric=-33.647082567205096!!
Fold[2] Epoch: 16 [16/100 (16%)] Train loss=0.407486 Test loss=0.497210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3892345130443573
[5/23] Train loss=0.4318186938762665
[10/23] Train loss=0.3671032190322876
[15/23] Train loss=0.381887823343277
[20/23] Train loss=0.3521968722343445
Test set avg_accuracy=79.81% avg_sensitivity=44.67%, avg_specificity=90.36% avg_auc=0.8154
Best model saved!! Metric=-29.624574272447774!!
Fold[2] Epoch: 17 [17/100 (17%)] Train loss=0.401710 Test loss=0.467384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38669899106025696
[5/23] Train loss=0.4275122582912445
[10/23] Train loss=0.3539680242538452
[15/23] Train loss=0.36092323064804077
[20/23] Train loss=0.3448924124240875
Test set avg_accuracy=79.91% avg_sensitivity=46.93%, avg_specificity=89.80% avg_auc=0.8182
Best model saved!! Metric=-27.551503508751686!!
Fold[2] Epoch: 18 [18/100 (18%)] Train loss=0.394381 Test loss=0.463300 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3908604681491852
[5/23] Train loss=0.4179098308086395
[10/23] Train loss=0.3574945330619812
[15/23] Train loss=0.3810604512691498
[20/23] Train loss=0.34636881947517395
Test set avg_accuracy=79.89% avg_sensitivity=47.02%, avg_specificity=89.75% avg_auc=0.8210
Best model saved!! Metric=-27.25159713403665!!
Fold[2] Epoch: 19 [19/100 (19%)] Train loss=0.392979 Test loss=0.449516 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38195645809173584
[5/23] Train loss=0.41666924953460693
[10/23] Train loss=0.3562980592250824
[15/23] Train loss=0.37414810061454773
[20/23] Train loss=0.3347311317920685
Test set avg_accuracy=79.86% avg_sensitivity=47.60%, avg_specificity=89.54% avg_auc=0.8214
Best model saved!! Metric=-26.84890136769701!!
Fold[2] Epoch: 20 [20/100 (20%)] Train loss=0.389004 Test loss=0.455836 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3783079981803894
[5/23] Train loss=0.4258466064929962
[10/23] Train loss=0.3645400106906891
[15/23] Train loss=0.3662940561771393
[20/23] Train loss=0.3410454988479614
Test set avg_accuracy=79.81% avg_sensitivity=45.93%, avg_specificity=89.98% avg_auc=0.8198
Fold[2] Epoch: 21 [21/100 (21%)] Train loss=0.390114 Test loss=0.454839 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38129615783691406
[5/23] Train loss=0.4153440296649933
[10/23] Train loss=0.358772873878479
[15/23] Train loss=0.3637655973434448
[20/23] Train loss=0.346375972032547
Test set avg_accuracy=79.96% avg_sensitivity=43.90%, avg_specificity=90.78% avg_auc=0.8175
Fold[2] Epoch: 22 [22/100 (22%)] Train loss=0.388171 Test loss=0.473503 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36294999718666077
[5/23] Train loss=0.4228048026561737
[10/23] Train loss=0.36102601885795593
[15/23] Train loss=0.3636482357978821
[20/23] Train loss=0.33295226097106934
Test set avg_accuracy=79.98% avg_sensitivity=46.79%, avg_specificity=89.94% avg_auc=0.8250
Best model saved!! Metric=-26.7940624068395!!
Fold[2] Epoch: 23 [23/100 (23%)] Train loss=0.386401 Test loss=0.452074 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.359975129365921
[5/23] Train loss=0.41480758786201477
[10/23] Train loss=0.3525415062904358
[15/23] Train loss=0.36536920070648193
[20/23] Train loss=0.33010193705558777
Test set avg_accuracy=79.87% avg_sensitivity=48.33%, avg_specificity=89.34% avg_auc=0.8305
Best model saved!! Metric=-25.40930404955685!!
Fold[2] Epoch: 24 [24/100 (24%)] Train loss=0.381988 Test loss=0.439502 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36890316009521484
[5/23] Train loss=0.41362178325653076
[10/23] Train loss=0.3430633246898651
[15/23] Train loss=0.35067296028137207
[20/23] Train loss=0.3255910575389862
Test set avg_accuracy=79.87% avg_sensitivity=51.36%, avg_specificity=88.43% avg_auc=0.8359
Best model saved!! Metric=-22.744042694468433!!
Fold[2] Epoch: 25 [25/100 (25%)] Train loss=0.376277 Test loss=0.429504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36069703102111816
[5/23] Train loss=0.41390079259872437
[10/23] Train loss=0.33785656094551086
[15/23] Train loss=0.3531233072280884
[20/23] Train loss=0.3232312500476837
Test set avg_accuracy=80.11% avg_sensitivity=51.31%, avg_specificity=88.76% avg_auc=0.8360
Best model saved!! Metric=-22.219518948811945!!
Fold[2] Epoch: 26 [26/100 (26%)] Train loss=0.374469 Test loss=0.429364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3568176329135895
[5/23] Train loss=0.40813812613487244
[10/23] Train loss=0.3388434052467346
[15/23] Train loss=0.35516253113746643
[20/23] Train loss=0.3207155466079712
Test set avg_accuracy=80.17% avg_sensitivity=51.08%, avg_specificity=88.89% avg_auc=0.8362
Fold[2] Epoch: 27 [27/100 (27%)] Train loss=0.371845 Test loss=0.427785 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3566211760044098
[5/23] Train loss=0.40831440687179565
[10/23] Train loss=0.33693769574165344
[15/23] Train loss=0.3479965329170227
[20/23] Train loss=0.31816819310188293
Test set avg_accuracy=80.33% avg_sensitivity=52.31%, avg_specificity=88.74% avg_auc=0.8354
Best model saved!! Metric=-21.075334355532213!!
Fold[2] Epoch: 28 [28/100 (28%)] Train loss=0.369998 Test loss=0.435095 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3549591302871704
[5/23] Train loss=0.40731188654899597
[10/23] Train loss=0.3356083929538727
[15/23] Train loss=0.3381991684436798
[20/23] Train loss=0.3184164762496948
Test set avg_accuracy=80.40% avg_sensitivity=53.21%, avg_specificity=88.55% avg_auc=0.8362
Best model saved!! Metric=-20.219178407416905!!
Fold[2] Epoch: 29 [29/100 (29%)] Train loss=0.370009 Test loss=0.427784 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35005393624305725
[5/23] Train loss=0.41438740491867065
[10/23] Train loss=0.33595916628837585
[15/23] Train loss=0.3434484601020813
[20/23] Train loss=0.3202524781227112
Test set avg_accuracy=80.35% avg_sensitivity=50.50%, avg_specificity=89.31% avg_auc=0.8289
Fold[2] Epoch: 30 [30/100 (30%)] Train loss=0.369799 Test loss=0.440969 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.350020170211792
[5/23] Train loss=0.39801034331321716
[10/23] Train loss=0.3395867943763733
[15/23] Train loss=0.33787187933921814
[20/23] Train loss=0.32996082305908203
Test set avg_accuracy=80.13% avg_sensitivity=49.59%, avg_specificity=89.29% avg_auc=0.8313
Fold[2] Epoch: 31 [31/100 (31%)] Train loss=0.366941 Test loss=0.441263 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3518027067184448
[5/23] Train loss=0.4041104316711426
[10/23] Train loss=0.3366135358810425
[15/23] Train loss=0.3339352011680603
[20/23] Train loss=0.3196626603603363
Test set avg_accuracy=80.25% avg_sensitivity=48.82%, avg_specificity=89.68% avg_auc=0.8303
Fold[2] Epoch: 32 [32/100 (32%)] Train loss=0.366093 Test loss=0.445323 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34579581022262573
[5/23] Train loss=0.4005304276943207
[10/23] Train loss=0.33835655450820923
[15/23] Train loss=0.3477150499820709
[20/23] Train loss=0.3117775321006775
Test set avg_accuracy=80.54% avg_sensitivity=48.78%, avg_specificity=90.07% avg_auc=0.8328
Fold[2] Epoch: 33 [33/100 (33%)] Train loss=0.364377 Test loss=0.440489 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34217023849487305
[5/23] Train loss=0.4034835398197174
[10/23] Train loss=0.32701143622398376
[15/23] Train loss=0.3350769877433777
[20/23] Train loss=0.31179705262184143
Test set avg_accuracy=80.23% avg_sensitivity=52.53%, avg_specificity=88.54% avg_auc=0.8350
Fold[2] Epoch: 34 [34/100 (34%)] Train loss=0.360533 Test loss=0.430403 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33591023087501526
[5/23] Train loss=0.39727163314819336
[10/23] Train loss=0.3295762240886688
[15/23] Train loss=0.33482804894447327
[20/23] Train loss=0.3119911551475525
Test set avg_accuracy=80.34% avg_sensitivity=54.70%, avg_specificity=88.04% avg_auc=0.8384
Best model saved!! Metric=-19.081153197081314!!
Fold[2] Epoch: 35 [35/100 (35%)] Train loss=0.358687 Test loss=0.424455 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34470510482788086
[5/23] Train loss=0.40140676498413086
[10/23] Train loss=0.32478979229927063
[15/23] Train loss=0.33244529366493225
[20/23] Train loss=0.309957891702652
Test set avg_accuracy=80.58% avg_sensitivity=54.84%, avg_specificity=88.31% avg_auc=0.8389
Best model saved!! Metric=-18.378262510219805!!
Fold[2] Epoch: 36 [36/100 (36%)] Train loss=0.354904 Test loss=0.427241 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3394944369792938
[5/23] Train loss=0.3865000307559967
[10/23] Train loss=0.3219515383243561
[15/23] Train loss=0.32609719038009644
[20/23] Train loss=0.30073297023773193
Test set avg_accuracy=80.63% avg_sensitivity=54.97%, avg_specificity=88.32% avg_auc=0.8389
Best model saved!! Metric=-18.191120805577768!!
Fold[2] Epoch: 37 [37/100 (37%)] Train loss=0.353012 Test loss=0.421949 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3445601761341095
[5/23] Train loss=0.3924229145050049
[10/23] Train loss=0.32253992557525635
[15/23] Train loss=0.31670188903808594
[20/23] Train loss=0.2960387170314789
Test set avg_accuracy=80.65% avg_sensitivity=53.16%, avg_specificity=88.89% avg_auc=0.8380
Fold[2] Epoch: 38 [38/100 (38%)] Train loss=0.351219 Test loss=0.427560 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3332602083683014
[5/23] Train loss=0.3960745334625244
[10/23] Train loss=0.3202960193157196
[15/23] Train loss=0.32179558277130127
[20/23] Train loss=0.3042120635509491
Test set avg_accuracy=80.61% avg_sensitivity=52.67%, avg_specificity=88.99% avg_auc=0.8395
Fold[2] Epoch: 39 [39/100 (39%)] Train loss=0.349800 Test loss=0.424508 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33655616641044617
[5/23] Train loss=0.38569462299346924
[10/23] Train loss=0.3173939883708954
[15/23] Train loss=0.31638750433921814
[20/23] Train loss=0.29984980821609497
Test set avg_accuracy=80.44% avg_sensitivity=54.70%, avg_specificity=88.16% avg_auc=0.8411
Fold[2] Epoch: 40 [40/100 (40%)] Train loss=0.346424 Test loss=0.428930 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33267953991889954
[5/23] Train loss=0.3952499032020569
[10/23] Train loss=0.31883925199508667
[15/23] Train loss=0.3166269361972809
[20/23] Train loss=0.29431867599487305
Test set avg_accuracy=80.78% avg_sensitivity=53.71%, avg_specificity=88.91% avg_auc=0.8372
Fold[2] Epoch: 41 [41/100 (41%)] Train loss=0.346207 Test loss=0.426489 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3297126889228821
[5/23] Train loss=0.38694366812705994
[10/23] Train loss=0.31341418623924255
[15/23] Train loss=0.3129860460758209
[20/23] Train loss=0.2955235242843628
Test set avg_accuracy=80.27% avg_sensitivity=53.03%, avg_specificity=88.44% avg_auc=0.8342
Fold[2] Epoch: 42 [42/100 (42%)] Train loss=0.346726 Test loss=0.430869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32771384716033936
[5/23] Train loss=0.3862200081348419
[10/23] Train loss=0.3155076801776886
[15/23] Train loss=0.31455591320991516
[20/23] Train loss=0.295595645904541
Test set avg_accuracy=80.09% avg_sensitivity=54.84%, avg_specificity=87.67% avg_auc=0.8342
Fold[2] Epoch: 43 [43/100 (43%)] Train loss=0.341495 Test loss=0.442175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32519251108169556
[5/23] Train loss=0.38607358932495117
[10/23] Train loss=0.3097129166126251
[15/23] Train loss=0.3121483325958252
[20/23] Train loss=0.2904786765575409
Test set avg_accuracy=80.54% avg_sensitivity=57.19%, avg_specificity=87.55% avg_auc=0.8396
Best model saved!! Metric=-16.760862988859817!!
Fold[2] Epoch: 44 [44/100 (44%)] Train loss=0.338056 Test loss=0.428361 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32649171352386475
[5/23] Train loss=0.3849414885044098
[10/23] Train loss=0.3021396994590759
[15/23] Train loss=0.30690744519233704
[20/23] Train loss=0.3002551794052124
Test set avg_accuracy=80.75% avg_sensitivity=55.88%, avg_specificity=88.21% avg_auc=0.8392
Fold[2] Epoch: 45 [45/100 (45%)] Train loss=0.339710 Test loss=0.423428 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31830865144729614
[5/23] Train loss=0.3846786618232727
[10/23] Train loss=0.30278030037879944
[15/23] Train loss=0.31320586800575256
[20/23] Train loss=0.2856912314891815
Test set avg_accuracy=80.26% avg_sensitivity=54.34%, avg_specificity=88.04% avg_auc=0.8356
Fold[2] Epoch: 46 [46/100 (46%)] Train loss=0.336022 Test loss=0.436767 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3248167037963867
[5/23] Train loss=0.3725164830684662
[10/23] Train loss=0.3162637948989868
[15/23] Train loss=0.31725090742111206
[20/23] Train loss=0.2907019555568695
Test set avg_accuracy=80.59% avg_sensitivity=54.20%, avg_specificity=88.51% avg_auc=0.8356
Fold[2] Epoch: 47 [47/100 (47%)] Train loss=0.335012 Test loss=0.429646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3219144344329834
[5/23] Train loss=0.37222614884376526
[10/23] Train loss=0.2974555194377899
[15/23] Train loss=0.30581334233283997
[20/23] Train loss=0.28559714555740356
Test set avg_accuracy=80.50% avg_sensitivity=54.16%, avg_specificity=88.40% avg_auc=0.8365
Fold[2] Epoch: 48 [48/100 (48%)] Train loss=0.332715 Test loss=0.434082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3177443742752075
[5/23] Train loss=0.3681296706199646
[10/23] Train loss=0.3046616315841675
[15/23] Train loss=0.3077128827571869
[20/23] Train loss=0.27852049469947815
Test set avg_accuracy=81.14% avg_sensitivity=54.34%, avg_specificity=89.18% avg_auc=0.8393
Fold[2] Epoch: 49 [49/100 (49%)] Train loss=0.330022 Test loss=0.426308 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31656941771507263
[5/23] Train loss=0.3757840394973755
[10/23] Train loss=0.3113045394420624
[15/23] Train loss=0.3036820888519287
[20/23] Train loss=0.28699198365211487
Test set avg_accuracy=80.64% avg_sensitivity=54.52%, avg_specificity=88.47% avg_auc=0.8374
Fold[2] Epoch: 50 [50/100 (50%)] Train loss=0.330381 Test loss=0.433833 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31852075457572937
[5/23] Train loss=0.3764324486255646
[10/23] Train loss=0.32051095366477966
[15/23] Train loss=0.29789623618125916
[20/23] Train loss=0.2942218780517578
Test set avg_accuracy=80.72% avg_sensitivity=48.64%, avg_specificity=90.34% avg_auc=0.8365
Fold[2] Epoch: 51 [51/100 (51%)] Train loss=0.331701 Test loss=0.446570 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.322229266166687
[5/23] Train loss=0.36250755190849304
[10/23] Train loss=0.3231527805328369
[15/23] Train loss=0.29647061228752136
[20/23] Train loss=0.2887384593486786
Test set avg_accuracy=80.09% avg_sensitivity=45.03%, avg_specificity=90.61% avg_auc=0.8279
Fold[2] Epoch: 52 [52/100 (52%)] Train loss=0.332945 Test loss=0.464340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3196307122707367
[5/23] Train loss=0.3726443648338318
[10/23] Train loss=0.30916041135787964
[15/23] Train loss=0.29993879795074463
[20/23] Train loss=0.2808536887168884
Test set avg_accuracy=80.31% avg_sensitivity=50.14%, avg_specificity=89.37% avg_auc=0.8310
Fold[2] Epoch: 53 [53/100 (53%)] Train loss=0.329048 Test loss=0.449733 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30431386828422546
[5/23] Train loss=0.374856561422348
[10/23] Train loss=0.30304738879203796
[15/23] Train loss=0.3034816086292267
[20/23] Train loss=0.2844159007072449
Test set avg_accuracy=80.29% avg_sensitivity=50.05%, avg_specificity=89.37% avg_auc=0.8299
Fold[2] Epoch: 54 [54/100 (54%)] Train loss=0.327063 Test loss=0.447589 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3030632734298706
[5/23] Train loss=0.3669424057006836
[10/23] Train loss=0.3000280261039734
[15/23] Train loss=0.3088148832321167
[20/23] Train loss=0.28235578536987305
Test set avg_accuracy=80.27% avg_sensitivity=53.48%, avg_specificity=88.31% avg_auc=0.8321
Fold[2] Epoch: 55 [55/100 (55%)] Train loss=0.322255 Test loss=0.451794 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29821908473968506
[5/23] Train loss=0.3633230924606323
[10/23] Train loss=0.2980616092681885
[15/23] Train loss=0.2967798113822937
[20/23] Train loss=0.2780202329158783
Test set avg_accuracy=80.65% avg_sensitivity=57.05%, avg_specificity=87.73% avg_auc=0.8353
Fold[2] Epoch: 56 [56/100 (56%)] Train loss=0.316343 Test loss=0.449076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3019496202468872
[5/23] Train loss=0.3618778586387634
[10/23] Train loss=0.29615724086761475
[15/23] Train loss=0.2829165756702423
[20/23] Train loss=0.27720674872398376
Test set avg_accuracy=80.49% avg_sensitivity=52.89%, avg_specificity=88.77% avg_auc=0.8322
Fold[2] Epoch: 57 [57/100 (57%)] Train loss=0.314134 Test loss=0.448225 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30687880516052246
[5/23] Train loss=0.36178523302078247
[10/23] Train loss=0.27915477752685547
[15/23] Train loss=0.28400689363479614
[20/23] Train loss=0.26937830448150635
Test set avg_accuracy=80.34% avg_sensitivity=54.48%, avg_specificity=88.11% avg_auc=0.8317
Fold[2] Epoch: 58 [58/100 (58%)] Train loss=0.311892 Test loss=0.449032 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30141469836235046
[5/23] Train loss=0.3632622957229614
[10/23] Train loss=0.2869204878807068
[15/23] Train loss=0.277937650680542
[20/23] Train loss=0.2760952413082123
Test set avg_accuracy=80.72% avg_sensitivity=56.33%, avg_specificity=88.04% avg_auc=0.8361
Fold[2] Epoch: 59 [59/100 (59%)] Train loss=0.311044 Test loss=0.442499 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2907002866268158
[5/23] Train loss=0.35660165548324585
[10/23] Train loss=0.28123801946640015
[15/23] Train loss=0.29176536202430725
[20/23] Train loss=0.27022305130958557
Test set avg_accuracy=80.45% avg_sensitivity=56.15%, avg_specificity=87.74% avg_auc=0.8350
Fold[2] Epoch: 60 [60/100 (60%)] Train loss=0.308632 Test loss=0.445406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29416966438293457
[5/23] Train loss=0.35572558641433716
[10/23] Train loss=0.28674423694610596
[15/23] Train loss=0.28286615014076233
[20/23] Train loss=0.2707619071006775
Test set avg_accuracy=80.68% avg_sensitivity=51.67%, avg_specificity=89.38% avg_auc=0.8340
Fold[2] Epoch: 61 [61/100 (61%)] Train loss=0.307555 Test loss=0.447780 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2853579521179199
[5/23] Train loss=0.3496094346046448
[10/23] Train loss=0.29601141810417175
[15/23] Train loss=0.2740691900253296
[20/23] Train loss=0.26195427775382996
Test set avg_accuracy=80.50% avg_sensitivity=48.82%, avg_specificity=90.00% avg_auc=0.8306
Fold[2] Epoch: 62 [62/100 (62%)] Train loss=0.307094 Test loss=0.458454 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29699164628982544
[5/23] Train loss=0.35123926401138306
[10/23] Train loss=0.3033715784549713
[15/23] Train loss=0.26879918575286865
[20/23] Train loss=0.27288949489593506
Test set avg_accuracy=80.80% avg_sensitivity=48.33%, avg_specificity=90.55% avg_auc=0.8289
Fold[2] Epoch: 63 [63/100 (63%)] Train loss=0.306602 Test loss=0.471604 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2971097528934479
[5/23] Train loss=0.34692513942718506
[10/23] Train loss=0.28125837445259094
[15/23] Train loss=0.27622151374816895
[20/23] Train loss=0.2596602141857147
Test set avg_accuracy=80.26% avg_sensitivity=46.34%, avg_specificity=90.44% avg_auc=0.8248
Fold[2] Epoch: 64 [64/100 (64%)] Train loss=0.304455 Test loss=0.474537 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2897125482559204
[5/23] Train loss=0.3591897189617157
[10/23] Train loss=0.27372339367866516
[15/23] Train loss=0.2675507366657257
[20/23] Train loss=0.2625724673271179
Test set avg_accuracy=80.24% avg_sensitivity=50.41%, avg_specificity=89.19% avg_auc=0.8277
Fold[2] Epoch: 65 [65/100 (65%)] Train loss=0.302208 Test loss=0.471903 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2819072902202606
[5/23] Train loss=0.35587722063064575
[10/23] Train loss=0.27279651165008545
[15/23] Train loss=0.2628768980503082
[20/23] Train loss=0.25774237513542175
Test set avg_accuracy=80.15% avg_sensitivity=51.13%, avg_specificity=88.85% avg_auc=0.8250
Fold[2] Epoch: 66 [66/100 (66%)] Train loss=0.300599 Test loss=0.471792 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2842969596385956
[5/23] Train loss=0.3361745774745941
[10/23] Train loss=0.2821895182132721
[15/23] Train loss=0.27738770842552185
[20/23] Train loss=0.2513870596885681
Test set avg_accuracy=79.81% avg_sensitivity=51.27%, avg_specificity=88.38% avg_auc=0.8209
Fold[2] Epoch: 67 [67/100 (67%)] Train loss=0.298207 Test loss=0.478219 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28670400381088257
[5/23] Train loss=0.34913474321365356
[10/23] Train loss=0.27958473563194275
[15/23] Train loss=0.27388516068458557
[20/23] Train loss=0.24930940568447113
Test set avg_accuracy=80.17% avg_sensitivity=55.74%, avg_specificity=87.49% avg_auc=0.8299
Fold[2] Epoch: 68 [68/100 (68%)] Train loss=0.296660 Test loss=0.473685 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2830463647842407
[5/23] Train loss=0.3403160274028778
[10/23] Train loss=0.2745380699634552
[15/23] Train loss=0.27528324723243713
[20/23] Train loss=0.25262781977653503
Test set avg_accuracy=80.31% avg_sensitivity=52.26%, avg_specificity=88.73% avg_auc=0.8277
Fold[2] Epoch: 69 [69/100 (69%)] Train loss=0.292950 Test loss=0.459078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27442970871925354
[5/23] Train loss=0.33524826169013977
[10/23] Train loss=0.28157156705856323
[15/23] Train loss=0.2653391659259796
[20/23] Train loss=0.2575869560241699
Test set avg_accuracy=80.61% avg_sensitivity=52.49%, avg_specificity=89.04% avg_auc=0.8301
Fold[2] Epoch: 70 [70/100 (70%)] Train loss=0.289644 Test loss=0.462773 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2769377529621124
[5/23] Train loss=0.3302544057369232
[10/23] Train loss=0.27722620964050293
[15/23] Train loss=0.2561832666397095
[20/23] Train loss=0.2595670521259308
Test set avg_accuracy=80.41% avg_sensitivity=50.36%, avg_specificity=89.42% avg_auc=0.8271
Fold[2] Epoch: 71 [71/100 (71%)] Train loss=0.290208 Test loss=0.471899 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27937641739845276
[5/23] Train loss=0.3359127640724182
[10/23] Train loss=0.2796804904937744
[15/23] Train loss=0.253508597612381
[20/23] Train loss=0.2599373757839203
Test set avg_accuracy=80.54% avg_sensitivity=47.60%, avg_specificity=90.42% avg_auc=0.8266
Fold[2] Epoch: 72 [72/100 (72%)] Train loss=0.288794 Test loss=0.474742 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27333343029022217
[5/23] Train loss=0.33126795291900635
[10/23] Train loss=0.2816152274608612
[15/23] Train loss=0.25753486156463623
[20/23] Train loss=0.24986019730567932
Test set avg_accuracy=80.39% avg_sensitivity=44.17%, avg_specificity=91.25% avg_auc=0.8233
Fold[2] Epoch: 73 [73/100 (73%)] Train loss=0.289040 Test loss=0.483385 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26852431893348694
[5/23] Train loss=0.34446239471435547
[10/23] Train loss=0.27135977149009705
[15/23] Train loss=0.25616946816444397
[20/23] Train loss=0.24995751678943634
Test set avg_accuracy=80.18% avg_sensitivity=47.20%, avg_specificity=90.07% avg_auc=0.8236
Fold[2] Epoch: 74 [74/100 (74%)] Train loss=0.290186 Test loss=0.477518 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2653011381626129
[5/23] Train loss=0.3460545837879181
[10/23] Train loss=0.26766344904899597
[15/23] Train loss=0.2581459879875183
[20/23] Train loss=0.25777360796928406
Test set avg_accuracy=80.02% avg_sensitivity=46.75%, avg_specificity=90.00% avg_auc=0.8230
Fold[2] Epoch: 75 [75/100 (75%)] Train loss=0.286820 Test loss=0.482545 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27006784081459045
[5/23] Train loss=0.32611027359962463
[10/23] Train loss=0.2649039328098297
[15/23] Train loss=0.2614637315273285
[20/23] Train loss=0.23871587216854095
Test set avg_accuracy=80.47% avg_sensitivity=54.66%, avg_specificity=88.21% avg_auc=0.8268
Fold[2] Epoch: 76 [76/100 (76%)] Train loss=0.284196 Test loss=0.461926 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2681991159915924
[5/23] Train loss=0.342634379863739
[10/23] Train loss=0.26171112060546875
[15/23] Train loss=0.25742602348327637
[20/23] Train loss=0.24109601974487305
Test set avg_accuracy=80.30% avg_sensitivity=51.40%, avg_specificity=88.97% avg_auc=0.8193
Fold[2] Epoch: 77 [77/100 (77%)] Train loss=0.283371 Test loss=0.487017 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26167747378349304
[5/23] Train loss=0.3255811929702759
[10/23] Train loss=0.2700904905796051
[15/23] Train loss=0.2492915689945221
[20/23] Train loss=0.24176877737045288
Test set avg_accuracy=80.73% avg_sensitivity=54.52%, avg_specificity=88.59% avg_auc=0.8292
Fold[2] Epoch: 78 [78/100 (78%)] Train loss=0.278485 Test loss=0.480271 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26141366362571716
[5/23] Train loss=0.30947229266166687
[10/23] Train loss=0.26522913575172424
[15/23] Train loss=0.2343427687883377
[20/23] Train loss=0.2410174161195755
Test set avg_accuracy=80.26% avg_sensitivity=44.98%, avg_specificity=90.84% avg_auc=0.8167
Fold[2] Epoch: 79 [79/100 (79%)] Train loss=0.274204 Test loss=0.493646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26094135642051697
[5/23] Train loss=0.3082260489463806
[10/23] Train loss=0.2652725279331207
[15/23] Train loss=0.23760871589183807
[20/23] Train loss=0.23868653178215027
Test set avg_accuracy=80.66% avg_sensitivity=48.24%, avg_specificity=90.38% avg_auc=0.8245
Fold[2] Epoch: 80 [80/100 (80%)] Train loss=0.273928 Test loss=0.477486 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2566755712032318
[5/23] Train loss=0.3137214779853821
[10/23] Train loss=0.2660684287548065
[15/23] Train loss=0.24276526272296906
[20/23] Train loss=0.24041344225406647
Test set avg_accuracy=80.34% avg_sensitivity=48.42%, avg_specificity=89.92% avg_auc=0.8188
Fold[2] Epoch: 81 [81/100 (81%)] Train loss=0.273309 Test loss=0.490603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2536378502845764
[5/23] Train loss=0.335683137178421
[10/23] Train loss=0.24945774674415588
[15/23] Train loss=0.22737884521484375
[20/23] Train loss=0.23666873574256897
Test set avg_accuracy=79.90% avg_sensitivity=50.86%, avg_specificity=88.61% avg_auc=0.8174
Fold[2] Epoch: 82 [82/100 (82%)] Train loss=0.272130 Test loss=0.488080 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2584298253059387
[5/23] Train loss=0.3183726966381073
[10/23] Train loss=0.2517508566379547
[15/23] Train loss=0.2510693669319153
[20/23] Train loss=0.24564582109451294
Test set avg_accuracy=80.28% avg_sensitivity=50.05%, avg_specificity=89.35% avg_auc=0.8205
Fold[2] Epoch: 83 [83/100 (83%)] Train loss=0.270108 Test loss=0.486927 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25738129019737244
[5/23] Train loss=0.3162054717540741
[10/23] Train loss=0.2705470025539398
[15/23] Train loss=0.2580097019672394
[20/23] Train loss=0.2194703072309494
Test set avg_accuracy=80.46% avg_sensitivity=51.22%, avg_specificity=89.23% avg_auc=0.8236
Fold[2] Epoch: 84 [84/100 (84%)] Train loss=0.271543 Test loss=0.478076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24928899109363556
[5/23] Train loss=0.3133190870285034
[10/23] Train loss=0.24733462929725647
[15/23] Train loss=0.24910812079906464
[20/23] Train loss=0.23175160586833954
Test set avg_accuracy=81.18% avg_sensitivity=48.82%, avg_specificity=90.89% avg_auc=0.8251
Fold[2] Epoch: 85 [85/100 (85%)] Train loss=0.265847 Test loss=0.488371 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25426235795021057
[5/23] Train loss=0.3098602890968323
[10/23] Train loss=0.25195303559303284
[15/23] Train loss=0.22778913378715515
[20/23] Train loss=0.2451745718717575
Test set avg_accuracy=80.78% avg_sensitivity=47.02%, avg_specificity=90.91% avg_auc=0.8239
Fold[2] Epoch: 86 [86/100 (86%)] Train loss=0.265420 Test loss=0.494005 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24404914677143097
[5/23] Train loss=0.30593839287757874
[10/23] Train loss=0.261462539434433
[15/23] Train loss=0.22830668091773987
[20/23] Train loss=0.22985629737377167
Test set avg_accuracy=80.49% avg_sensitivity=45.98%, avg_specificity=90.84% avg_auc=0.8209
Fold[2] Epoch: 87 [87/100 (87%)] Train loss=0.260171 Test loss=0.510483 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24727250635623932
[5/23] Train loss=0.31668105721473694
[10/23] Train loss=0.24677132070064545
[15/23] Train loss=0.22828714549541473
[20/23] Train loss=0.2289014458656311
Test set avg_accuracy=80.34% avg_sensitivity=47.56%, avg_specificity=90.18% avg_auc=0.8148
Fold[2] Epoch: 88 [88/100 (88%)] Train loss=0.260896 Test loss=0.508768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24150362610816956
[5/23] Train loss=0.31670433282852173
[10/23] Train loss=0.2619589865207672
[15/23] Train loss=0.22930699586868286
[20/23] Train loss=0.2244209349155426
Test set avg_accuracy=80.35% avg_sensitivity=50.09%, avg_specificity=89.43% avg_auc=0.8197
Fold[2] Epoch: 89 [89/100 (89%)] Train loss=0.256854 Test loss=0.499091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2470860481262207
[5/23] Train loss=0.29366907477378845
[10/23] Train loss=0.245694100856781
[15/23] Train loss=0.2343197762966156
[20/23] Train loss=0.21057385206222534
Test set avg_accuracy=80.69% avg_sensitivity=51.94%, avg_specificity=89.31% avg_auc=0.8217
Fold[2] Epoch: 90 [90/100 (90%)] Train loss=0.251137 Test loss=0.494371 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22973614931106567
[5/23] Train loss=0.30991101264953613
[10/23] Train loss=0.23643413186073303
[15/23] Train loss=0.23330999910831451
[20/23] Train loss=0.21471534669399261
Test set avg_accuracy=80.54% avg_sensitivity=47.65%, avg_specificity=90.41% avg_auc=0.8195
Fold[2] Epoch: 91 [91/100 (91%)] Train loss=0.250566 Test loss=0.495025 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2310105711221695
[5/23] Train loss=0.29151368141174316
[10/23] Train loss=0.24868017435073853
[15/23] Train loss=0.21539701521396637
[20/23] Train loss=0.22295965254306793
Test set avg_accuracy=80.79% avg_sensitivity=48.24%, avg_specificity=90.56% avg_auc=0.8192
Fold[2] Epoch: 92 [92/100 (92%)] Train loss=0.248505 Test loss=0.504085 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23499290645122528
[5/23] Train loss=0.29997536540031433
[10/23] Train loss=0.24642609059810638
[15/23] Train loss=0.22214995324611664
[20/23] Train loss=0.21983526647090912
Test set avg_accuracy=80.94% avg_sensitivity=47.74%, avg_specificity=90.90% avg_auc=0.8255
Fold[2] Epoch: 93 [93/100 (93%)] Train loss=0.249080 Test loss=0.511828 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22934094071388245
[5/23] Train loss=0.30404868721961975
[10/23] Train loss=0.23410604894161224
[15/23] Train loss=0.2244694083929062
[20/23] Train loss=0.2115475833415985
Test set avg_accuracy=80.96% avg_sensitivity=49.50%, avg_specificity=90.40% avg_auc=0.8245
Fold[2] Epoch: 94 [94/100 (94%)] Train loss=0.248208 Test loss=0.508512 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2266249805688858
[5/23] Train loss=0.30816975235939026
[10/23] Train loss=0.23003001511096954
[15/23] Train loss=0.22047771513462067
[20/23] Train loss=0.2110854536294937
Test set avg_accuracy=80.26% avg_sensitivity=49.05%, avg_specificity=89.62% avg_auc=0.8188
Fold[2] Epoch: 95 [95/100 (95%)] Train loss=0.244185 Test loss=0.509452 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22578808665275574
[5/23] Train loss=0.3012310862541199
[10/23] Train loss=0.24227215349674225
[15/23] Train loss=0.22485166788101196
[20/23] Train loss=0.20767860114574432
Test set avg_accuracy=80.80% avg_sensitivity=48.33%, avg_specificity=90.55% avg_auc=0.8119
Fold[2] Epoch: 96 [96/100 (96%)] Train loss=0.241072 Test loss=0.516118 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23389305174350739
[5/23] Train loss=0.29189684987068176
[10/23] Train loss=0.2413233071565628
[15/23] Train loss=0.2209751456975937
[20/23] Train loss=0.20789235830307007
Test set avg_accuracy=80.87% avg_sensitivity=53.39%, avg_specificity=89.11% avg_auc=0.8190
Fold[2] Epoch: 97 [97/100 (97%)] Train loss=0.242871 Test loss=0.511311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22070933878421783
[5/23] Train loss=0.29942232370376587
[10/23] Train loss=0.23453450202941895
[15/23] Train loss=0.2213609218597412
[20/23] Train loss=0.22134269773960114
Test set avg_accuracy=80.76% avg_sensitivity=52.85%, avg_specificity=89.14% avg_auc=0.8262
Fold[2] Epoch: 98 [98/100 (98%)] Train loss=0.241707 Test loss=0.510037 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2195649892091751
[5/23] Train loss=0.2803167402744293
[10/23] Train loss=0.23600804805755615
[15/23] Train loss=0.2236548364162445
[20/23] Train loss=0.2025061994791031
Test set avg_accuracy=80.89% avg_sensitivity=49.77%, avg_specificity=90.22% avg_auc=0.8214
Fold[2] Epoch: 99 [99/100 (99%)] Train loss=0.236847 Test loss=0.514070 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21849696338176727
[5/23] Train loss=0.29019075632095337
[10/23] Train loss=0.24276554584503174
[15/23] Train loss=0.2109811007976532
[20/23] Train loss=0.20846033096313477
Test set avg_accuracy=80.76% avg_sensitivity=43.85%, avg_specificity=91.84% avg_auc=0.8234
Fold[2] Epoch: 100 [100/100 (100%)] Train loss=0.237475 Test loss=0.531719 Current lr=[3.9999999999999996e-05]

Fold[2] Best Result: acc=80.54251434533126 sen=57.18806509945751, spe=87.54916587549167, auc=0.8395939169085975!
[0/23] Train loss=0.6838315725326538
[5/23] Train loss=0.7127845883369446
[10/23] Train loss=0.5767856240272522
[15/23] Train loss=0.565032958984375
[20/23] Train loss=0.544903576374054
Test set avg_accuracy=68.35% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5412
Fold[3] Epoch: 1 [1/100 (1%)] Train loss=0.572146 Test loss=0.794871 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5721522569656372
[5/23] Train loss=0.6158479452133179
[10/23] Train loss=0.5477185249328613
[15/23] Train loss=0.5416758060455322
[20/23] Train loss=0.5228637456893921
Test set avg_accuracy=68.30% avg_sensitivity=0.33%, avg_specificity=99.78% avg_auc=0.5702
Fold[3] Epoch: 2 [2/100 (2%)] Train loss=0.543442 Test loss=0.736367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5479721426963806
[5/23] Train loss=0.5966359972953796
[10/23] Train loss=0.5343654751777649
[15/23] Train loss=0.5305352807044983
[20/23] Train loss=0.4904540777206421
Test set avg_accuracy=68.49% avg_sensitivity=6.00%, avg_specificity=97.43% avg_auc=0.6372
Best model saved!! Metric=-90.34705965076463!!
Fold[3] Epoch: 3 [3/100 (3%)] Train loss=0.522449 Test loss=0.755239 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5279445648193359
[5/23] Train loss=0.5573883056640625
[10/23] Train loss=0.49971669912338257
[15/23] Train loss=0.5203571915626526
[20/23] Train loss=0.4496716260910034
Test set avg_accuracy=69.24% avg_sensitivity=13.17%, avg_specificity=95.21% avg_auc=0.6879
Best model saved!! Metric=-79.59133065356077!!
Fold[3] Epoch: 4 [4/100 (4%)] Train loss=0.495318 Test loss=0.744772 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.49557018280029297
[5/23] Train loss=0.5178744792938232
[10/23] Train loss=0.46649181842803955
[15/23] Train loss=0.5096367001533508
[20/23] Train loss=0.4331403970718384
Test set avg_accuracy=71.04% avg_sensitivity=19.64%, avg_specificity=94.85% avg_auc=0.7235
Best model saved!! Metric=-68.11933550835437!!
Fold[3] Epoch: 5 [5/100 (5%)] Train loss=0.471030 Test loss=0.735491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4593389928340912
[5/23] Train loss=0.5004855990409851
[10/23] Train loss=0.4316360354423523
[15/23] Train loss=0.4651653468608856
[20/23] Train loss=0.4041285216808319
Test set avg_accuracy=72.82% avg_sensitivity=25.44%, avg_specificity=94.76% avg_auc=0.7464
Best model saved!! Metric=-58.33801875311245!!
Fold[3] Epoch: 6 [6/100 (6%)] Train loss=0.450493 Test loss=0.732169 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4450799822807312
[5/23] Train loss=0.4779159724712372
[10/23] Train loss=0.41384562849998474
[15/23] Train loss=0.46927911043167114
[20/23] Train loss=0.411304771900177
Test set avg_accuracy=74.41% avg_sensitivity=30.68%, avg_specificity=94.67% avg_auc=0.7648
Best model saved!! Metric=-49.752387555631955!!
Fold[3] Epoch: 7 [7/100 (7%)] Train loss=0.440402 Test loss=0.718624 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4356546700000763
[5/23] Train loss=0.46970659494400024
[10/23] Train loss=0.40666210651397705
[15/23] Train loss=0.4484095871448517
[20/23] Train loss=0.38036632537841797
Test set avg_accuracy=75.12% avg_sensitivity=33.07%, avg_specificity=94.59% avg_auc=0.7761
Best model saved!! Metric=-45.6099774360174!!
Fold[3] Epoch: 8 [8/100 (8%)] Train loss=0.433023 Test loss=0.671425 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4304732084274292
[5/23] Train loss=0.45452994108200073
[10/23] Train loss=0.4017009139060974
[15/23] Train loss=0.4666048288345337
[20/23] Train loss=0.38609400391578674
Test set avg_accuracy=75.46% avg_sensitivity=34.46%, avg_specificity=94.45% avg_auc=0.7872
Best model saved!! Metric=-42.90149829008496!!
Fold[3] Epoch: 9 [9/100 (9%)] Train loss=0.427654 Test loss=0.664960 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42427554726600647
[5/23] Train loss=0.45192578434944153
[10/23] Train loss=0.39990222454071045
[15/23] Train loss=0.43990254402160645
[20/23] Train loss=0.38549748063087463
Test set avg_accuracy=75.86% avg_sensitivity=35.85%, avg_specificity=94.39% avg_auc=0.7961
Best model saved!! Metric=-40.27943943213165!!
Fold[3] Epoch: 10 [10/100 (10%)] Train loss=0.423194 Test loss=0.623507 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4229082763195038
[5/23] Train loss=0.45711764693260193
[10/23] Train loss=0.39199745655059814
[15/23] Train loss=0.4446231424808502
[20/23] Train loss=0.37583568692207336
Test set avg_accuracy=76.59% avg_sensitivity=38.28%, avg_specificity=94.33% avg_auc=0.8064
Best model saved!! Metric=-36.16624936005932!!
Fold[3] Epoch: 11 [11/100 (11%)] Train loss=0.419424 Test loss=0.611667 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43444913625717163
[5/23] Train loss=0.44971391558647156
[10/23] Train loss=0.3879718780517578
[15/23] Train loss=0.42237478494644165
[20/23] Train loss=0.37425363063812256
Test set avg_accuracy=77.13% avg_sensitivity=40.27%, avg_specificity=94.21% avg_auc=0.8111
Best model saved!! Metric=-33.27929103951078!!
Fold[3] Epoch: 12 [12/100 (12%)] Train loss=0.414921 Test loss=0.588450 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41410115361213684
[5/23] Train loss=0.43735620379447937
[10/23] Train loss=0.3824819028377533
[15/23] Train loss=0.4353252649307251
[20/23] Train loss=0.36544519662857056
Test set avg_accuracy=77.32% avg_sensitivity=41.26%, avg_specificity=94.02% avg_auc=0.8173
Best model saved!! Metric=-31.66461927774997!!
Fold[3] Epoch: 13 [13/100 (13%)] Train loss=0.410904 Test loss=0.580829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41576600074768066
[5/23] Train loss=0.44477391242980957
[10/23] Train loss=0.37846633791923523
[15/23] Train loss=0.4484405219554901
[20/23] Train loss=0.35845378041267395
Test set avg_accuracy=77.76% avg_sensitivity=42.02%, avg_specificity=94.32% avg_auc=0.8199
Best model saved!! Metric=-29.910389310788894!!
Fold[3] Epoch: 14 [14/100 (14%)] Train loss=0.410459 Test loss=0.582573 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40639573335647583
[5/23] Train loss=0.4478533864021301
[10/23] Train loss=0.37393227219581604
[15/23] Train loss=0.4296403229236603
[20/23] Train loss=0.35803088545799255
Test set avg_accuracy=76.87% avg_sensitivity=38.77%, avg_specificity=94.52% avg_auc=0.8071
Fold[3] Epoch: 15 [15/100 (15%)] Train loss=0.413769 Test loss=0.631544 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40024086833000183
[5/23] Train loss=0.4488627016544342
[10/23] Train loss=0.3887251019477844
[15/23] Train loss=0.40119993686676025
[20/23] Train loss=0.36058342456817627
Test set avg_accuracy=76.40% avg_sensitivity=36.19%, avg_specificity=95.02% avg_auc=0.8010
Fold[3] Epoch: 16 [16/100 (16%)] Train loss=0.413932 Test loss=0.654706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4159846305847168
[5/23] Train loss=0.4333958327770233
[10/23] Train loss=0.3883184790611267
[15/23] Train loss=0.4037778079509735
[20/23] Train loss=0.34825459122657776
Test set avg_accuracy=77.21% avg_sensitivity=39.57%, avg_specificity=94.64% avg_auc=0.8141
Fold[3] Epoch: 17 [17/100 (17%)] Train loss=0.409314 Test loss=0.643491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39821887016296387
[5/23] Train loss=0.43411484360694885
[10/23] Train loss=0.3691309094429016
[15/23] Train loss=0.3902285099029541
[20/23] Train loss=0.365039199590683
Test set avg_accuracy=77.20% avg_sensitivity=39.44%, avg_specificity=94.69% avg_auc=0.8285
Fold[3] Epoch: 18 [18/100 (18%)] Train loss=0.404665 Test loss=0.620108 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39721745252609253
[5/23] Train loss=0.42714154720306396
[10/23] Train loss=0.3722958564758301
[15/23] Train loss=0.3916281461715698
[20/23] Train loss=0.3536122739315033
Test set avg_accuracy=77.76% avg_sensitivity=41.46%, avg_specificity=94.58% avg_auc=0.8349
Best model saved!! Metric=-28.711476043026316!!
Fold[3] Epoch: 19 [19/100 (19%)] Train loss=0.398924 Test loss=0.594498 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3853871822357178
[5/23] Train loss=0.4349060356616974
[10/23] Train loss=0.35965844988822937
[15/23] Train loss=0.39294520020484924
[20/23] Train loss=0.3427041172981262
Test set avg_accuracy=78.34% avg_sensitivity=43.78%, avg_specificity=94.35% avg_auc=0.8337
Best model saved!! Metric=-26.160778370044465!!
Fold[3] Epoch: 20 [20/100 (20%)] Train loss=0.395400 Test loss=0.600205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3845686912536621
[5/23] Train loss=0.42717409133911133
[10/23] Train loss=0.35368573665618896
[15/23] Train loss=0.3801160752773285
[20/23] Train loss=0.33971038460731506
Test set avg_accuracy=78.72% avg_sensitivity=45.90%, avg_specificity=93.92% avg_auc=0.8401
Best model saved!! Metric=-23.447390653764177!!
Fold[3] Epoch: 21 [21/100 (21%)] Train loss=0.392031 Test loss=0.569088 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3844805359840393
[5/23] Train loss=0.4295983612537384
[10/23] Train loss=0.3495559096336365
[15/23] Train loss=0.3734559416770935
[20/23] Train loss=0.3345925509929657
Test set avg_accuracy=78.91% avg_sensitivity=47.16%, avg_specificity=93.61% avg_auc=0.8429
Best model saved!! Metric=-22.02653985375885!!
Fold[3] Epoch: 22 [22/100 (22%)] Train loss=0.387798 Test loss=0.547276 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37183767557144165
[5/23] Train loss=0.42612752318382263
[10/23] Train loss=0.3444649875164032
[15/23] Train loss=0.37992623448371887
[20/23] Train loss=0.34198471903800964
Test set avg_accuracy=79.16% avg_sensitivity=48.26%, avg_specificity=93.47% avg_auc=0.8454
Best model saved!! Metric=-20.57309282335534!!
Fold[3] Epoch: 23 [23/100 (23%)] Train loss=0.385283 Test loss=0.531754 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37630495429039
[5/23] Train loss=0.42362478375434875
[10/23] Train loss=0.3444128632545471
[15/23] Train loss=0.37717777490615845
[20/23] Train loss=0.337826669216156
Test set avg_accuracy=79.16% avg_sensitivity=47.93%, avg_specificity=93.63% avg_auc=0.8448
Fold[3] Epoch: 24 [24/100 (24%)] Train loss=0.382648 Test loss=0.534763 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3678726255893707
[5/23] Train loss=0.4166131913661957
[10/23] Train loss=0.3511351943016052
[15/23] Train loss=0.37769442796707153
[20/23] Train loss=0.3401663899421692
Test set avg_accuracy=79.02% avg_sensitivity=47.66%, avg_specificity=93.55% avg_auc=0.8451
Fold[3] Epoch: 25 [25/100 (25%)] Train loss=0.380619 Test loss=0.534468 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3686487376689911
[5/23] Train loss=0.4200347661972046
[10/23] Train loss=0.35159263014793396
[15/23] Train loss=0.3649423122406006
[20/23] Train loss=0.335136741399765
Test set avg_accuracy=79.03% avg_sensitivity=46.24%, avg_specificity=94.22% avg_auc=0.8458
Fold[3] Epoch: 26 [26/100 (26%)] Train loss=0.379692 Test loss=0.559570 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37428948283195496
[5/23] Train loss=0.4221058189868927
[10/23] Train loss=0.3416827619075775
[15/23] Train loss=0.3652314245700836
[20/23] Train loss=0.3295995891094208
Test set avg_accuracy=79.25% avg_sensitivity=48.96%, avg_specificity=93.29% avg_auc=0.8477
Best model saved!! Metric=-19.737670289207763!!
Fold[3] Epoch: 27 [27/100 (27%)] Train loss=0.376691 Test loss=0.532938 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3633234202861786
[5/23] Train loss=0.41948890686035156
[10/23] Train loss=0.34148356318473816
[15/23] Train loss=0.34442517161369324
[20/23] Train loss=0.32015088200569153
Test set avg_accuracy=79.39% avg_sensitivity=50.71%, avg_specificity=92.67% avg_auc=0.8488
Best model saved!! Metric=-18.343802996379594!!
Fold[3] Epoch: 28 [28/100 (28%)] Train loss=0.372541 Test loss=0.526978 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3622188866138458
[5/23] Train loss=0.41835451126098633
[10/23] Train loss=0.3398372232913971
[15/23] Train loss=0.3510070741176605
[20/23] Train loss=0.3265974223613739
Test set avg_accuracy=79.48% avg_sensitivity=51.18%, avg_specificity=92.58% avg_auc=0.8498
Best model saved!! Metric=-17.782379874638934!!
Fold[3] Epoch: 29 [29/100 (29%)] Train loss=0.372469 Test loss=0.514503 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3702872097492218
[5/23] Train loss=0.4175545573234558
[10/23] Train loss=0.33139774203300476
[15/23] Train loss=0.3379353880882263
[20/23] Train loss=0.32221555709838867
Test set avg_accuracy=79.52% avg_sensitivity=50.35%, avg_specificity=93.03% avg_auc=0.8487
Fold[3] Epoch: 30 [30/100 (30%)] Train loss=0.368701 Test loss=0.519846 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36041393876075745
[5/23] Train loss=0.4065830111503601
[10/23] Train loss=0.3330342173576355
[15/23] Train loss=0.34930574893951416
[20/23] Train loss=0.3209227919578552
Test set avg_accuracy=79.67% avg_sensitivity=51.71%, avg_specificity=92.63% avg_auc=0.8510
Best model saved!! Metric=-16.892256667242545!!
Fold[3] Epoch: 31 [31/100 (31%)] Train loss=0.365706 Test loss=0.512253 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35782721638679504
[5/23] Train loss=0.4072977304458618
[10/23] Train loss=0.3344469964504242
[15/23] Train loss=0.3475710153579712
[20/23] Train loss=0.3300401568412781
Test set avg_accuracy=79.37% avg_sensitivity=48.59%, avg_specificity=93.63% avg_auc=0.8477
Fold[3] Epoch: 32 [32/100 (32%)] Train loss=0.368072 Test loss=0.547275 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3594079911708832
[5/23] Train loss=0.4068494141101837
[10/23] Train loss=0.3376665413379669
[15/23] Train loss=0.3440489172935486
[20/23] Train loss=0.3210485577583313
Test set avg_accuracy=79.16% avg_sensitivity=47.50%, avg_specificity=93.82% avg_auc=0.8481
Fold[3] Epoch: 33 [33/100 (33%)] Train loss=0.368253 Test loss=0.544461 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3571099042892456
[5/23] Train loss=0.4027862548828125
[10/23] Train loss=0.3235015273094177
[15/23] Train loss=0.35019925236701965
[20/23] Train loss=0.3235575258731842
Test set avg_accuracy=79.33% avg_sensitivity=49.25%, avg_specificity=93.26% avg_auc=0.8496
Fold[3] Epoch: 34 [34/100 (34%)] Train loss=0.363511 Test loss=0.532800 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3567708730697632
[5/23] Train loss=0.4058985710144043
[10/23] Train loss=0.3209763765335083
[15/23] Train loss=0.34892338514328003
[20/23] Train loss=0.3191324770450592
Test set avg_accuracy=79.77% avg_sensitivity=53.23%, avg_specificity=92.06% avg_auc=0.8531
Best model saved!! Metric=-15.630863627201489!!
Fold[3] Epoch: 35 [35/100 (35%)] Train loss=0.359520 Test loss=0.500557 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3532956540584564
[5/23] Train loss=0.408550500869751
[10/23] Train loss=0.32143959403038025
[15/23] Train loss=0.33280184864997864
[20/23] Train loss=0.3100946545600891
Test set avg_accuracy=79.85% avg_sensitivity=53.50%, avg_specificity=92.06% avg_auc=0.8519
Best model saved!! Metric=-15.40176760524097!!
Fold[3] Epoch: 36 [36/100 (36%)] Train loss=0.357991 Test loss=0.500133 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34586939215660095
[5/23] Train loss=0.3982245922088623
[10/23] Train loss=0.3243008852005005
[15/23] Train loss=0.3413613438606262
[20/23] Train loss=0.3129635453224182
Test set avg_accuracy=79.90% avg_sensitivity=54.73%, avg_specificity=91.55% avg_auc=0.8533
Best model saved!! Metric=-14.492519260802577!!
Fold[3] Epoch: 37 [37/100 (37%)] Train loss=0.356499 Test loss=0.490676 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35114601254463196
[5/23] Train loss=0.39262503385543823
[10/23] Train loss=0.32323169708251953
[15/23] Train loss=0.3358667194843292
[20/23] Train loss=0.3176637887954712
Test set avg_accuracy=79.57% avg_sensitivity=52.31%, avg_specificity=92.20% avg_auc=0.8541
Fold[3] Epoch: 38 [38/100 (38%)] Train loss=0.356552 Test loss=0.494119 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34614112973213196
[5/23] Train loss=0.3982428014278412
[10/23] Train loss=0.3266730010509491
[15/23] Train loss=0.33086779713630676
[20/23] Train loss=0.3177439570426941
Test set avg_accuracy=79.31% avg_sensitivity=49.72%, avg_specificity=93.01% avg_auc=0.8508
Fold[3] Epoch: 39 [39/100 (39%)] Train loss=0.354797 Test loss=0.517958 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34672674536705017
[5/23] Train loss=0.39793065190315247
[10/23] Train loss=0.32872867584228516
[15/23] Train loss=0.33919206261634827
[20/23] Train loss=0.3043515980243683
Test set avg_accuracy=79.35% avg_sensitivity=49.19%, avg_specificity=93.32% avg_auc=0.8499
Fold[3] Epoch: 40 [40/100 (40%)] Train loss=0.354840 Test loss=0.525096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35381418466567993
[5/23] Train loss=0.39999011158943176
[10/23] Train loss=0.32118627429008484
[15/23] Train loss=0.32005923986434937
[20/23] Train loss=0.30708688497543335
Test set avg_accuracy=79.48% avg_sensitivity=49.25%, avg_specificity=93.47% avg_auc=0.8525
Fold[3] Epoch: 41 [41/100 (41%)] Train loss=0.352592 Test loss=0.517693 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3408995568752289
[5/23] Train loss=0.39536282420158386
[10/23] Train loss=0.3177010416984558
[15/23] Train loss=0.3303336203098297
[20/23] Train loss=0.3005516231060028
Test set avg_accuracy=79.77% avg_sensitivity=52.04%, avg_specificity=92.61% avg_auc=0.8543
Fold[3] Epoch: 42 [42/100 (42%)] Train loss=0.348708 Test loss=0.500029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3400788903236389
[5/23] Train loss=0.39423608779907227
[10/23] Train loss=0.30265021324157715
[15/23] Train loss=0.3195149600505829
[20/23] Train loss=0.30770811438560486
Test set avg_accuracy=79.84% avg_sensitivity=53.83%, avg_specificity=91.89% avg_auc=0.8517
Fold[3] Epoch: 43 [43/100 (43%)] Train loss=0.346095 Test loss=0.497600 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34048160910606384
[5/23] Train loss=0.40358641743659973
[10/23] Train loss=0.31371796131134033
[15/23] Train loss=0.31387990713119507
[20/23] Train loss=0.31273409724235535
Test set avg_accuracy=80.08% avg_sensitivity=54.36%, avg_specificity=92.00% avg_auc=0.8543
Best model saved!! Metric=-14.131257866559025!!
Fold[3] Epoch: 44 [44/100 (44%)] Train loss=0.343948 Test loss=0.502007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3370557725429535
[5/23] Train loss=0.3839019238948822
[10/23] Train loss=0.30973076820373535
[15/23] Train loss=0.3170822262763977
[20/23] Train loss=0.3051103353500366
Test set avg_accuracy=79.88% avg_sensitivity=54.89%, avg_specificity=91.46% avg_auc=0.8561
Fold[3] Epoch: 45 [45/100 (45%)] Train loss=0.341865 Test loss=0.494191 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34088003635406494
[5/23] Train loss=0.3936828076839447
[10/23] Train loss=0.30156368017196655
[15/23] Train loss=0.3259958326816559
[20/23] Train loss=0.2945926785469055
Test set avg_accuracy=80.15% avg_sensitivity=55.79%, avg_specificity=91.43% avg_auc=0.8572
Best model saved!! Metric=-12.9126714641331!!
Fold[3] Epoch: 46 [46/100 (46%)] Train loss=0.340010 Test loss=0.485090 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33222317695617676
[5/23] Train loss=0.39094972610473633
[10/23] Train loss=0.30706074833869934
[15/23] Train loss=0.3102121651172638
[20/23] Train loss=0.3066886067390442
Test set avg_accuracy=79.86% avg_sensitivity=53.63%, avg_specificity=92.01% avg_auc=0.8565
Fold[3] Epoch: 47 [47/100 (47%)] Train loss=0.339550 Test loss=0.494318 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32933229207992554
[5/23] Train loss=0.3892320394515991
[10/23] Train loss=0.3049415051937103
[15/23] Train loss=0.30984967947006226
[20/23] Train loss=0.29443359375
Test set avg_accuracy=79.65% avg_sensitivity=51.44%, avg_specificity=92.72% avg_auc=0.8547
Fold[3] Epoch: 48 [48/100 (48%)] Train loss=0.337839 Test loss=0.502691 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3372005522251129
[5/23] Train loss=0.37811508774757385
[10/23] Train loss=0.30594485998153687
[15/23] Train loss=0.3179958164691925
[20/23] Train loss=0.3086100220680237
Test set avg_accuracy=79.70% avg_sensitivity=53.47%, avg_specificity=91.84% avg_auc=0.8549
Fold[3] Epoch: 49 [49/100 (49%)] Train loss=0.335825 Test loss=0.499016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32320156693458557
[5/23] Train loss=0.3886461555957794
[10/23] Train loss=0.3096471130847931
[15/23] Train loss=0.3098794221878052
[20/23] Train loss=0.305482417345047
Test set avg_accuracy=79.51% avg_sensitivity=52.40%, avg_specificity=92.06% avg_auc=0.8538
Fold[3] Epoch: 50 [50/100 (50%)] Train loss=0.336436 Test loss=0.506294 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3221464455127716
[5/23] Train loss=0.37815919518470764
[10/23] Train loss=0.302205353975296
[15/23] Train loss=0.3089888393878937
[20/23] Train loss=0.2974819242954254
Test set avg_accuracy=79.42% avg_sensitivity=49.75%, avg_specificity=93.16% avg_auc=0.8547
Fold[3] Epoch: 51 [51/100 (51%)] Train loss=0.333776 Test loss=0.511900 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32578006386756897
[5/23] Train loss=0.38384565711021423
[10/23] Train loss=0.29755231738090515
[15/23] Train loss=0.29996317625045776
[20/23] Train loss=0.2918746769428253
Test set avg_accuracy=79.19% avg_sensitivity=47.89%, avg_specificity=93.69% avg_auc=0.8522
Fold[3] Epoch: 52 [52/100 (52%)] Train loss=0.332351 Test loss=0.525999 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3253077566623688
[5/23] Train loss=0.3810361921787262
[10/23] Train loss=0.3005557358264923
[15/23] Train loss=0.3105856776237488
[20/23] Train loss=0.28544265031814575
Test set avg_accuracy=79.85% avg_sensitivity=51.31%, avg_specificity=93.07% avg_auc=0.8530
Fold[3] Epoch: 53 [53/100 (53%)] Train loss=0.330932 Test loss=0.525551 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3172928988933563
[5/23] Train loss=0.38085198402404785
[10/23] Train loss=0.29393845796585083
[15/23] Train loss=0.30237647891044617
[20/23] Train loss=0.2860742211341858
Test set avg_accuracy=79.93% avg_sensitivity=52.17%, avg_specificity=92.78% avg_auc=0.8550
Fold[3] Epoch: 54 [54/100 (54%)] Train loss=0.327299 Test loss=0.500075 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3191238045692444
[5/23] Train loss=0.37618768215179443
[10/23] Train loss=0.2927548289299011
[15/23] Train loss=0.2972601652145386
[20/23] Train loss=0.2942304015159607
Test set avg_accuracy=80.00% avg_sensitivity=53.50%, avg_specificity=92.27% avg_auc=0.8559
Fold[3] Epoch: 55 [55/100 (55%)] Train loss=0.324566 Test loss=0.489502 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31506723165512085
[5/23] Train loss=0.36879563331604004
[10/23] Train loss=0.2941683530807495
[15/23] Train loss=0.29237574338912964
[20/23] Train loss=0.2957485020160675
Test set avg_accuracy=79.80% avg_sensitivity=51.44%, avg_specificity=92.93% avg_auc=0.8538
Fold[3] Epoch: 56 [56/100 (56%)] Train loss=0.323224 Test loss=0.511889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31056904792785645
[5/23] Train loss=0.3647630512714386
[10/23] Train loss=0.2892235815525055
[15/23] Train loss=0.316131591796875
[20/23] Train loss=0.2880338132381439
Test set avg_accuracy=80.28% avg_sensitivity=53.50%, avg_specificity=92.69% avg_auc=0.8565
Fold[3] Epoch: 57 [57/100 (57%)] Train loss=0.320931 Test loss=0.512102 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31305059790611267
[5/23] Train loss=0.3706934452056885
[10/23] Train loss=0.29335659742355347
[15/23] Train loss=0.29257339239120483
[20/23] Train loss=0.28567764163017273
Test set avg_accuracy=80.00% avg_sensitivity=52.84%, avg_specificity=92.58% avg_auc=0.8579
Fold[3] Epoch: 58 [58/100 (58%)] Train loss=0.320595 Test loss=0.506130 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30953848361968994
[5/23] Train loss=0.36757704615592957
[10/23] Train loss=0.28998157382011414
[15/23] Train loss=0.2970440983772278
[20/23] Train loss=0.28154313564300537
Test set avg_accuracy=79.57% avg_sensitivity=51.77%, avg_specificity=92.44% avg_auc=0.8573
Fold[3] Epoch: 59 [59/100 (59%)] Train loss=0.317487 Test loss=0.504208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3020308017730713
[5/23] Train loss=0.358015239238739
[10/23] Train loss=0.295616090297699
[15/23] Train loss=0.28446438908576965
[20/23] Train loss=0.27915069460868835
Test set avg_accuracy=79.62% avg_sensitivity=51.08%, avg_specificity=92.84% avg_auc=0.8558
Fold[3] Epoch: 60 [60/100 (60%)] Train loss=0.314526 Test loss=0.521153 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3094376027584076
[5/23] Train loss=0.37007367610931396
[10/23] Train loss=0.2846599221229553
[15/23] Train loss=0.2840266525745392
[20/23] Train loss=0.27142050862312317
Test set avg_accuracy=79.96% avg_sensitivity=54.23%, avg_specificity=91.87% avg_auc=0.8584
Fold[3] Epoch: 61 [61/100 (61%)] Train loss=0.314668 Test loss=0.500769 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29743897914886475
[5/23] Train loss=0.36941906809806824
[10/23] Train loss=0.2795719504356384
[15/23] Train loss=0.29671481251716614
[20/23] Train loss=0.26953229308128357
Test set avg_accuracy=80.15% avg_sensitivity=54.03%, avg_specificity=92.24% avg_auc=0.8552
Fold[3] Epoch: 62 [62/100 (62%)] Train loss=0.310396 Test loss=0.505733 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3040630519390106
[5/23] Train loss=0.363809198141098
[10/23] Train loss=0.2730088531970978
[15/23] Train loss=0.28819358348846436
[20/23] Train loss=0.26964640617370605
Test set avg_accuracy=80.06% avg_sensitivity=53.67%, avg_specificity=92.29% avg_auc=0.8579
Fold[3] Epoch: 63 [63/100 (63%)] Train loss=0.306818 Test loss=0.514220 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3006967604160309
[5/23] Train loss=0.3557189702987671
[10/23] Train loss=0.2718764543533325
[15/23] Train loss=0.28805339336395264
[20/23] Train loss=0.27449288964271545
Test set avg_accuracy=79.93% avg_sensitivity=52.80%, avg_specificity=92.49% avg_auc=0.8545
Fold[3] Epoch: 64 [64/100 (64%)] Train loss=0.306250 Test loss=0.516623 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29435741901397705
[5/23] Train loss=0.3533098101615906
[10/23] Train loss=0.28472205996513367
[15/23] Train loss=0.28302040696144104
[20/23] Train loss=0.2749946713447571
Test set avg_accuracy=79.94% avg_sensitivity=52.11%, avg_specificity=92.83% avg_auc=0.8551
Fold[3] Epoch: 65 [65/100 (65%)] Train loss=0.305169 Test loss=0.506668 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2867682874202728
[5/23] Train loss=0.3586021363735199
[10/23] Train loss=0.28070011734962463
[15/23] Train loss=0.2781873941421509
[20/23] Train loss=0.2633648216724396
Test set avg_accuracy=80.25% avg_sensitivity=53.73%, avg_specificity=92.53% avg_auc=0.8550
Fold[3] Epoch: 66 [66/100 (66%)] Train loss=0.301899 Test loss=0.510243 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2978985011577606
[5/23] Train loss=0.3518456518650055
[10/23] Train loss=0.2749330997467041
[15/23] Train loss=0.282723605632782
[20/23] Train loss=0.26402750611305237
Test set avg_accuracy=80.04% avg_sensitivity=53.30%, avg_specificity=92.43% avg_auc=0.8548
Fold[3] Epoch: 67 [67/100 (67%)] Train loss=0.302498 Test loss=0.513241 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2986592948436737
[5/23] Train loss=0.35299909114837646
[10/23] Train loss=0.27408233284950256
[15/23] Train loss=0.27196335792541504
[20/23] Train loss=0.26013925671577454
Test set avg_accuracy=79.96% avg_sensitivity=52.84%, avg_specificity=92.52% avg_auc=0.8570
Fold[3] Epoch: 68 [68/100 (68%)] Train loss=0.299651 Test loss=0.506238 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2945745885372162
[5/23] Train loss=0.35217058658599854
[10/23] Train loss=0.26683881878852844
[15/23] Train loss=0.26914355158805847
[20/23] Train loss=0.2708054184913635
Test set avg_accuracy=80.05% avg_sensitivity=52.70%, avg_specificity=92.72% avg_auc=0.8584
Fold[3] Epoch: 69 [69/100 (69%)] Train loss=0.296302 Test loss=0.504354 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28475067019462585
[5/23] Train loss=0.3359745740890503
[10/23] Train loss=0.2688255310058594
[15/23] Train loss=0.2685292959213257
[20/23] Train loss=0.26805177330970764
Test set avg_accuracy=80.07% avg_sensitivity=52.64%, avg_specificity=92.78% avg_auc=0.8517
Fold[3] Epoch: 70 [70/100 (70%)] Train loss=0.295606 Test loss=0.507739 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29157689213752747
[5/23] Train loss=0.3415566086769104
[10/23] Train loss=0.2673540711402893
[15/23] Train loss=0.2712644636631012
[20/23] Train loss=0.2600477635860443
Test set avg_accuracy=80.10% avg_sensitivity=52.57%, avg_specificity=92.86% avg_auc=0.8574
Fold[3] Epoch: 71 [71/100 (71%)] Train loss=0.293554 Test loss=0.506406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28384560346603394
[5/23] Train loss=0.3375951647758484
[10/23] Train loss=0.2667149603366852
[15/23] Train loss=0.27058666944503784
[20/23] Train loss=0.2554851770401001
Test set avg_accuracy=80.25% avg_sensitivity=53.67%, avg_specificity=92.57% avg_auc=0.8561
Fold[3] Epoch: 72 [72/100 (72%)] Train loss=0.290804 Test loss=0.503928 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2834651470184326
[5/23] Train loss=0.3367243707180023
[10/23] Train loss=0.25694453716278076
[15/23] Train loss=0.27070164680480957
[20/23] Train loss=0.25236445665359497
Test set avg_accuracy=79.95% avg_sensitivity=52.67%, avg_specificity=92.58% avg_auc=0.8560
Fold[3] Epoch: 73 [73/100 (73%)] Train loss=0.289721 Test loss=0.518308 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28662237524986267
[5/23] Train loss=0.32914969325065613
[10/23] Train loss=0.26256057620048523
[15/23] Train loss=0.2736285924911499
[20/23] Train loss=0.2635175585746765
Test set avg_accuracy=79.83% avg_sensitivity=51.87%, avg_specificity=92.78% avg_auc=0.8562
Fold[3] Epoch: 74 [74/100 (74%)] Train loss=0.288229 Test loss=0.511354 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2853735685348511
[5/23] Train loss=0.336931437253952
[10/23] Train loss=0.27825677394866943
[15/23] Train loss=0.2680272161960602
[20/23] Train loss=0.2649904191493988
Test set avg_accuracy=79.78% avg_sensitivity=53.07%, avg_specificity=92.15% avg_auc=0.8552
Fold[3] Epoch: 75 [75/100 (75%)] Train loss=0.288918 Test loss=0.520869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27581173181533813
[5/23] Train loss=0.3414972126483917
[10/23] Train loss=0.2610419690608978
[15/23] Train loss=0.2498917281627655
[20/23] Train loss=0.2475678026676178
Test set avg_accuracy=79.62% avg_sensitivity=49.39%, avg_specificity=93.63% avg_auc=0.8577
Fold[3] Epoch: 76 [76/100 (76%)] Train loss=0.285407 Test loss=0.536972 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2819918990135193
[5/23] Train loss=0.34525319933891296
[10/23] Train loss=0.2635195851325989
[15/23] Train loss=0.24717001616954803
[20/23] Train loss=0.24193011224269867
Test set avg_accuracy=79.32% avg_sensitivity=49.52%, avg_specificity=93.12% avg_auc=0.8552
Fold[3] Epoch: 77 [77/100 (77%)] Train loss=0.282633 Test loss=0.536709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27718016505241394
[5/23] Train loss=0.33908581733703613
[10/23] Train loss=0.2549504339694977
[15/23] Train loss=0.255720317363739
[20/23] Train loss=0.25151434540748596
Test set avg_accuracy=79.45% avg_sensitivity=49.68%, avg_specificity=93.24% avg_auc=0.8575
Fold[3] Epoch: 78 [78/100 (78%)] Train loss=0.280119 Test loss=0.532663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2787710428237915
[5/23] Train loss=0.3433658182621002
[10/23] Train loss=0.258277028799057
[15/23] Train loss=0.2600215971469879
[20/23] Train loss=0.2648618221282959
Test set avg_accuracy=79.93% avg_sensitivity=51.91%, avg_specificity=92.90% avg_auc=0.8532
Fold[3] Epoch: 79 [79/100 (79%)] Train loss=0.280237 Test loss=0.538346 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2776838541030884
[5/23] Train loss=0.3366793692111969
[10/23] Train loss=0.2571839988231659
[15/23] Train loss=0.24208195507526398
[20/23] Train loss=0.2494845986366272
Test set avg_accuracy=80.04% avg_sensitivity=52.24%, avg_specificity=92.92% avg_auc=0.8475
Fold[3] Epoch: 80 [80/100 (80%)] Train loss=0.278104 Test loss=0.545189 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2766128182411194
[5/23] Train loss=0.3218514025211334
[10/23] Train loss=0.2599857747554779
[15/23] Train loss=0.2602270245552063
[20/23] Train loss=0.2429538071155548
Test set avg_accuracy=79.73% avg_sensitivity=51.51%, avg_specificity=92.80% avg_auc=0.8471
Fold[3] Epoch: 81 [81/100 (81%)] Train loss=0.278907 Test loss=0.534217 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27634522318840027
[5/23] Train loss=0.3377496898174286
[10/23] Train loss=0.2527497112751007
[15/23] Train loss=0.24113111197948456
[20/23] Train loss=0.24695651233196259
Test set avg_accuracy=79.20% avg_sensitivity=47.66%, avg_specificity=93.81% avg_auc=0.8445
Fold[3] Epoch: 82 [82/100 (82%)] Train loss=0.278497 Test loss=0.561506 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2682900130748749
[5/23] Train loss=0.3252028822898865
[10/23] Train loss=0.26228466629981995
[15/23] Train loss=0.2548796236515045
[20/23] Train loss=0.2626660168170929
Test set avg_accuracy=79.43% avg_sensitivity=54.36%, avg_specificity=91.04% avg_auc=0.8319
Fold[3] Epoch: 83 [83/100 (83%)] Train loss=0.277339 Test loss=0.543992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2705051898956299
[5/23] Train loss=0.32202476263046265
[10/23] Train loss=0.2592959702014923
[15/23] Train loss=0.2645167410373688
[20/23] Train loss=0.23749940097332
Test set avg_accuracy=80.14% avg_sensitivity=55.26%, avg_specificity=91.66% avg_auc=0.8481
Fold[3] Epoch: 84 [84/100 (84%)] Train loss=0.274588 Test loss=0.518547 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2678757607936859
[5/23] Train loss=0.32643207907676697
[10/23] Train loss=0.252329021692276
[15/23] Train loss=0.26642677187919617
[20/23] Train loss=0.2449711114168167
Test set avg_accuracy=79.82% avg_sensitivity=54.69%, avg_specificity=91.46% avg_auc=0.8458
Fold[3] Epoch: 85 [85/100 (85%)] Train loss=0.273403 Test loss=0.521173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2788453996181488
[5/23] Train loss=0.3208563029766083
[10/23] Train loss=0.25554537773132324
[15/23] Train loss=0.26007574796676636
[20/23] Train loss=0.24496805667877197
Test set avg_accuracy=80.15% avg_sensitivity=56.05%, avg_specificity=91.31% avg_auc=0.8477
Fold[3] Epoch: 86 [86/100 (86%)] Train loss=0.271330 Test loss=0.505471 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26472869515419006
[5/23] Train loss=0.310585081577301
[10/23] Train loss=0.24487079679965973
[15/23] Train loss=0.24565710127353668
[20/23] Train loss=0.24300837516784668
Test set avg_accuracy=80.05% avg_sensitivity=54.46%, avg_specificity=91.90% avg_auc=0.8472
Fold[3] Epoch: 87 [87/100 (87%)] Train loss=0.266842 Test loss=0.524636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2643221914768219
[5/23] Train loss=0.31559380888938904
[10/23] Train loss=0.25392085313796997
[15/23] Train loss=0.23411458730697632
[20/23] Train loss=0.2320120632648468
Test set avg_accuracy=79.64% avg_sensitivity=53.13%, avg_specificity=91.92% avg_auc=0.8432
Fold[3] Epoch: 88 [88/100 (88%)] Train loss=0.262505 Test loss=0.525121 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26305750012397766
[5/23] Train loss=0.3096562623977661
[10/23] Train loss=0.2624480426311493
[15/23] Train loss=0.24527615308761597
[20/23] Train loss=0.24206817150115967
Test set avg_accuracy=79.54% avg_sensitivity=50.95%, avg_specificity=92.78% avg_auc=0.8489
Fold[3] Epoch: 89 [89/100 (89%)] Train loss=0.261036 Test loss=0.541839 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2530958652496338
[5/23] Train loss=0.31351280212402344
[10/23] Train loss=0.24361000955104828
[15/23] Train loss=0.250419557094574
[20/23] Train loss=0.2255079448223114
Test set avg_accuracy=79.07% avg_sensitivity=47.33%, avg_specificity=93.76% avg_auc=0.8522
Fold[3] Epoch: 90 [90/100 (90%)] Train loss=0.258830 Test loss=0.555847 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26443666219711304
[5/23] Train loss=0.312602162361145
[10/23] Train loss=0.2569766342639923
[15/23] Train loss=0.23295561969280243
[20/23] Train loss=0.23299336433410645
Test set avg_accuracy=78.90% avg_sensitivity=47.16%, avg_specificity=93.59% avg_auc=0.8482
Fold[3] Epoch: 91 [91/100 (91%)] Train loss=0.260374 Test loss=0.559441 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26303595304489136
[5/23] Train loss=0.31074318289756775
[10/23] Train loss=0.24718500673770905
[15/23] Train loss=0.23422680795192719
[20/23] Train loss=0.2229040414094925
Test set avg_accuracy=78.65% avg_sensitivity=45.97%, avg_specificity=93.78% avg_auc=0.8519
Fold[3] Epoch: 92 [92/100 (92%)] Train loss=0.258615 Test loss=0.569390 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25820693373680115
[5/23] Train loss=0.31425943970680237
[10/23] Train loss=0.2396528571844101
[15/23] Train loss=0.23453126847743988
[20/23] Train loss=0.2323690503835678
Test set avg_accuracy=79.23% avg_sensitivity=47.36%, avg_specificity=93.99% avg_auc=0.8476
Fold[3] Epoch: 93 [93/100 (93%)] Train loss=0.256944 Test loss=0.574509 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24677608907222748
[5/23] Train loss=0.3001653552055359
[10/23] Train loss=0.246670201420784
[15/23] Train loss=0.22947640717029572
[20/23] Train loss=0.22730225324630737
Test set avg_accuracy=78.53% avg_sensitivity=43.28%, avg_specificity=94.85% avg_auc=0.8464
Fold[3] Epoch: 94 [94/100 (94%)] Train loss=0.254223 Test loss=0.613600 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24984370172023773
[5/23] Train loss=0.32179999351501465
[10/23] Train loss=0.23567378520965576
[15/23] Train loss=0.2220594733953476
[20/23] Train loss=0.2265074998140335
Test set avg_accuracy=79.50% avg_sensitivity=50.91%, avg_specificity=92.73% avg_auc=0.8503
Fold[3] Epoch: 95 [95/100 (95%)] Train loss=0.253898 Test loss=0.572300 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2436107099056244
[5/23] Train loss=0.3131038248538971
[10/23] Train loss=0.23756615817546844
[15/23] Train loss=0.24453489482402802
[20/23] Train loss=0.22292913496494293
Test set avg_accuracy=79.76% avg_sensitivity=51.61%, avg_specificity=92.80% avg_auc=0.8500
Fold[3] Epoch: 96 [96/100 (96%)] Train loss=0.251493 Test loss=0.561959 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2608034908771515
[5/23] Train loss=0.3076533377170563
[10/23] Train loss=0.2415754497051239
[15/23] Train loss=0.23649893701076508
[20/23] Train loss=0.2315085530281067
Test set avg_accuracy=80.13% avg_sensitivity=54.53%, avg_specificity=91.98% avg_auc=0.8465
Fold[3] Epoch: 97 [97/100 (97%)] Train loss=0.253010 Test loss=0.529687 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25004759430885315
[5/23] Train loss=0.29171550273895264
[10/23] Train loss=0.24106138944625854
[15/23] Train loss=0.22361062467098236
[20/23] Train loss=0.21428924798965454
Test set avg_accuracy=80.09% avg_sensitivity=55.16%, avg_specificity=91.64% avg_auc=0.8464
Fold[3] Epoch: 98 [98/100 (98%)] Train loss=0.244907 Test loss=0.531295 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24358662962913513
[5/23] Train loss=0.2855382561683655
[10/23] Train loss=0.23570461571216583
[15/23] Train loss=0.22568564116954803
[20/23] Train loss=0.21263210475444794
Test set avg_accuracy=79.64% avg_sensitivity=54.33%, avg_specificity=91.37% avg_auc=0.8367
Fold[3] Epoch: 99 [99/100 (99%)] Train loss=0.240624 Test loss=0.554764 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24174796044826508
[5/23] Train loss=0.28502464294433594
[10/23] Train loss=0.23667550086975098
[15/23] Train loss=0.22762563824653625
[20/23] Train loss=0.21297802031040192
Test set avg_accuracy=79.54% avg_sensitivity=51.67%, avg_specificity=92.44% avg_auc=0.8395
Fold[3] Epoch: 100 [100/100 (100%)] Train loss=0.238980 Test loss=0.562872 Current lr=[3.9999999999999996e-05]

Fold[3] Best Result: acc=80.14698162729658 sen=55.787728026534, spe=91.42857142857143, auc=0.8572404745346489!
[0/23] Train loss=0.6886966824531555
[5/23] Train loss=0.6700364947319031
[10/23] Train loss=0.5923691391944885
[15/23] Train loss=0.550738513469696
[20/23] Train loss=0.5334874987602234
Test set avg_accuracy=75.73% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5661
Best model saved!! Metric=-93.66466265450276!!
Fold[4] Epoch: 1 [1/100 (1%)] Train loss=0.582984 Test loss=0.626574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5771361589431763
[5/23] Train loss=0.6062056422233582
[10/23] Train loss=0.5439413785934448
[15/23] Train loss=0.5334810614585876
[20/23] Train loss=0.5033601522445679
Test set avg_accuracy=75.83% avg_sensitivity=6.08%, avg_specificity=98.19% avg_auc=0.6128
Best model saved!! Metric=-84.6198259678323!!
Fold[4] Epoch: 2 [2/100 (2%)] Train loss=0.548714 Test loss=0.573152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5354232788085938
[5/23] Train loss=0.5512934923171997
[10/23] Train loss=0.5169491767883301
[15/23] Train loss=0.5052775740623474
[20/23] Train loss=0.4617205858230591
Test set avg_accuracy=75.36% avg_sensitivity=15.74%, avg_specificity=94.47% avg_auc=0.6734
Best model saved!! Metric=-73.08380265093096!!
Fold[4] Epoch: 3 [3/100 (3%)] Train loss=0.516626 Test loss=0.580548 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.508683979511261
[5/23] Train loss=0.49492666125297546
[10/23] Train loss=0.4713909924030304
[15/23] Train loss=0.4779472351074219
[20/23] Train loss=0.4195024371147156
Test set avg_accuracy=75.98% avg_sensitivity=21.95%, avg_specificity=93.30% avg_auc=0.7321
Best model saved!! Metric=-61.56127107863436!!
Fold[4] Epoch: 4 [4/100 (4%)] Train loss=0.483098 Test loss=0.565609 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.47233137488365173
[5/23] Train loss=0.47263845801353455
[10/23] Train loss=0.43016549944877625
[15/23] Train loss=0.4600851833820343
[20/23] Train loss=0.4027405381202698
Test set avg_accuracy=77.23% avg_sensitivity=27.81%, avg_specificity=93.06% avg_auc=0.7660
Best model saved!! Metric=-51.296789130784!!
Fold[4] Epoch: 5 [5/100 (5%)] Train loss=0.460257 Test loss=0.546023 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4605892598628998
[5/23] Train loss=0.4618542492389679
[10/23] Train loss=0.4175102412700653
[15/23] Train loss=0.44761931896209717
[20/23] Train loss=0.39221078157424927
Test set avg_accuracy=78.34% avg_sensitivity=34.50%, avg_specificity=92.39% avg_auc=0.7912
Best model saved!! Metric=-41.65843078350769!!
Fold[4] Epoch: 6 [6/100 (6%)] Train loss=0.448484 Test loss=0.507643 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.439052015542984
[5/23] Train loss=0.45355433225631714
[10/23] Train loss=0.4045566916465759
[15/23] Train loss=0.43844959139823914
[20/23] Train loss=0.38531234860420227
Test set avg_accuracy=78.81% avg_sensitivity=37.00%, avg_specificity=92.21% avg_auc=0.7912
Best model saved!! Metric=-38.868394422277206!!
Fold[4] Epoch: 7 [7/100 (7%)] Train loss=0.439918 Test loss=0.512319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43119969964027405
[5/23] Train loss=0.4439789950847626
[10/23] Train loss=0.3961668908596039
[15/23] Train loss=0.4191248416900635
[20/23] Train loss=0.37784630060195923
Test set avg_accuracy=79.20% avg_sensitivity=38.85%, avg_specificity=92.14% avg_auc=0.8030
Best model saved!! Metric=-35.50854200996947!!
Fold[4] Epoch: 8 [8/100 (8%)] Train loss=0.432923 Test loss=0.489434 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.417630136013031
[5/23] Train loss=0.4411877691745758
[10/23] Train loss=0.3957875669002533
[15/23] Train loss=0.4256364405155182
[20/23] Train loss=0.3757340908050537
Test set avg_accuracy=79.56% avg_sensitivity=41.70%, avg_specificity=91.69% avg_auc=0.8116
Best model saved!! Metric=-31.88361788221159!!
Fold[4] Epoch: 9 [9/100 (9%)] Train loss=0.429055 Test loss=0.475744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42576995491981506
[5/23] Train loss=0.434939980506897
[10/23] Train loss=0.3836043179035187
[15/23] Train loss=0.42112237215042114
[20/23] Train loss=0.3745101988315582
Test set avg_accuracy=79.55% avg_sensitivity=42.17%, avg_specificity=91.53% avg_auc=0.8172
Best model saved!! Metric=-31.032602359089026!!
Fold[4] Epoch: 10 [10/100 (10%)] Train loss=0.425024 Test loss=0.472031 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4234023094177246
[5/23] Train loss=0.4280346930027008
[10/23] Train loss=0.38565534353256226
[15/23] Train loss=0.4182159900665283
[20/23] Train loss=0.36452561616897583
Test set avg_accuracy=79.75% avg_sensitivity=42.39%, avg_specificity=91.72% avg_auc=0.8178
Best model saved!! Metric=-30.362554770007435!!
Fold[4] Epoch: 11 [11/100 (11%)] Train loss=0.423311 Test loss=0.476819 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41318726539611816
[5/23] Train loss=0.43174469470977783
[10/23] Train loss=0.3785756230354309
[15/23] Train loss=0.4074914753437042
[20/23] Train loss=0.37400612235069275
Test set avg_accuracy=79.74% avg_sensitivity=42.13%, avg_specificity=91.79% avg_auc=0.8144
Fold[4] Epoch: 12 [12/100 (12%)] Train loss=0.422984 Test loss=0.493735 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4090869128704071
[5/23] Train loss=0.42056378722190857
[10/23] Train loss=0.4040045142173767
[15/23] Train loss=0.3932326138019562
[20/23] Train loss=0.36553916335105896
Test set avg_accuracy=79.53% avg_sensitivity=38.68%, avg_specificity=92.62% avg_auc=0.8077
Fold[4] Epoch: 13 [13/100 (13%)] Train loss=0.425727 Test loss=0.516444 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4145126938819885
[5/23] Train loss=0.4159051477909088
[10/23] Train loss=0.38167431950569153
[15/23] Train loss=0.396066814661026
[20/23] Train loss=0.35537469387054443
Test set avg_accuracy=79.93% avg_sensitivity=42.73%, avg_specificity=91.85% avg_auc=0.8262
Best model saved!! Metric=-28.874996325161412!!
Fold[4] Epoch: 14 [14/100 (14%)] Train loss=0.418410 Test loss=0.472493 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4058329463005066
[5/23] Train loss=0.41837093234062195
[10/23] Train loss=0.3714878261089325
[15/23] Train loss=0.3837308883666992
[20/23] Train loss=0.354069322347641
Test set avg_accuracy=80.41% avg_sensitivity=46.36%, avg_specificity=91.32% avg_auc=0.8301
Best model saved!! Metric=-24.902240539540113!!
Fold[4] Epoch: 15 [15/100 (15%)] Train loss=0.409960 Test loss=0.459661 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4033506512641907
[5/23] Train loss=0.4172196388244629
[10/23] Train loss=0.37240222096443176
[15/23] Train loss=0.38243064284324646
[20/23] Train loss=0.3551039397716522
Test set avg_accuracy=80.35% avg_sensitivity=45.75%, avg_specificity=91.43% avg_auc=0.8293
Fold[4] Epoch: 16 [16/100 (16%)] Train loss=0.409356 Test loss=0.466759 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40140751004219055
[5/23] Train loss=0.411191463470459
[10/23] Train loss=0.36722928285598755
[15/23] Train loss=0.36997532844543457
[20/23] Train loss=0.3458823263645172
Test set avg_accuracy=80.67% avg_sensitivity=46.44%, avg_specificity=91.64% avg_auc=0.8337
Best model saved!! Metric=-23.882034574022782!!
Fold[4] Epoch: 17 [17/100 (17%)] Train loss=0.406162 Test loss=0.459869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39163199067115784
[5/23] Train loss=0.4078608751296997
[10/23] Train loss=0.3648068308830261
[15/23] Train loss=0.3762837052345276
[20/23] Train loss=0.35318392515182495
Test set avg_accuracy=80.48% avg_sensitivity=45.49%, avg_specificity=91.69% avg_auc=0.8397
Fold[4] Epoch: 18 [18/100 (18%)] Train loss=0.403966 Test loss=0.453661 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38934704661369324
[5/23] Train loss=0.413710355758667
[10/23] Train loss=0.36423641443252563
[15/23] Train loss=0.3593067228794098
[20/23] Train loss=0.3436109125614166
Test set avg_accuracy=80.44% avg_sensitivity=46.44%, avg_specificity=91.33% avg_auc=0.8430
Best model saved!! Metric=-23.486820305842908!!
Fold[4] Epoch: 19 [19/100 (19%)] Train loss=0.402420 Test loss=0.453634 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3787270486354828
[5/23] Train loss=0.4055666923522949
[10/23] Train loss=0.3608663082122803
[15/23] Train loss=0.3732246458530426
[20/23] Train loss=0.3487561345100403
Test set avg_accuracy=80.71% avg_sensitivity=47.05%, avg_specificity=91.50% avg_auc=0.8454
Best model saved!! Metric=-22.201123134479833!!
Fold[4] Epoch: 20 [20/100 (20%)] Train loss=0.399638 Test loss=0.443588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3804633617401123
[5/23] Train loss=0.4015454649925232
[10/23] Train loss=0.3468869626522064
[15/23] Train loss=0.3641916513442993
[20/23] Train loss=0.34312596917152405
Test set avg_accuracy=81.09% avg_sensitivity=49.89%, avg_specificity=91.09% avg_auc=0.8472
Best model saved!! Metric=-19.21254189178935!!
Fold[4] Epoch: 21 [21/100 (21%)] Train loss=0.396052 Test loss=0.440371 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38415682315826416
[5/23] Train loss=0.4000641107559204
[10/23] Train loss=0.34917783737182617
[15/23] Train loss=0.3560520112514496
[20/23] Train loss=0.33871686458587646
Test set avg_accuracy=81.14% avg_sensitivity=49.46%, avg_specificity=91.29% avg_auc=0.8483
Fold[4] Epoch: 22 [22/100 (22%)] Train loss=0.393578 Test loss=0.436603 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3768938183784485
[5/23] Train loss=0.40109097957611084
[10/23] Train loss=0.3507162928581238
[15/23] Train loss=0.3636074662208557
[20/23] Train loss=0.337248295545578
Test set avg_accuracy=81.40% avg_sensitivity=51.92%, avg_specificity=90.85% avg_auc=0.8513
Best model saved!! Metric=-16.69963239586846!!
Fold[4] Epoch: 23 [23/100 (23%)] Train loss=0.391949 Test loss=0.426478 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3754800260066986
[5/23] Train loss=0.3916279077529907
[10/23] Train loss=0.34728652238845825
[15/23] Train loss=0.35601574182510376
[20/23] Train loss=0.3349810838699341
Test set avg_accuracy=81.48% avg_sensitivity=52.13%, avg_specificity=90.88% avg_auc=0.8540
Best model saved!! Metric=-16.111687946587104!!
Fold[4] Epoch: 24 [24/100 (24%)] Train loss=0.389830 Test loss=0.421272 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37314727902412415
[5/23] Train loss=0.3902844190597534
[10/23] Train loss=0.3394601345062256
[15/23] Train loss=0.3422580063343048
[20/23] Train loss=0.330555260181427
Test set avg_accuracy=81.77% avg_sensitivity=54.42%, avg_specificity=90.53% avg_auc=0.8559
Best model saved!! Metric=-13.689705735758062!!
Fold[4] Epoch: 25 [25/100 (25%)] Train loss=0.384946 Test loss=0.419123 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37176513671875
[5/23] Train loss=0.38703158497810364
[10/23] Train loss=0.33064696192741394
[15/23] Train loss=0.3488171398639679
[20/23] Train loss=0.33435460925102234
Test set avg_accuracy=81.82% avg_sensitivity=56.27%, avg_specificity=90.01% avg_auc=0.8578
Best model saved!! Metric=-12.115287259409593!!
Fold[4] Epoch: 26 [26/100 (26%)] Train loss=0.383221 Test loss=0.409050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3708559572696686
[5/23] Train loss=0.37803083658218384
[10/23] Train loss=0.343404084444046
[15/23] Train loss=0.3424382209777832
[20/23] Train loss=0.3358689546585083
Test set avg_accuracy=81.87% avg_sensitivity=55.33%, avg_specificity=90.38% avg_auc=0.8567
Fold[4] Epoch: 27 [27/100 (27%)] Train loss=0.383158 Test loss=0.414527 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3623538613319397
[5/23] Train loss=0.38776931166648865
[10/23] Train loss=0.3326931893825531
[15/23] Train loss=0.34017425775527954
[20/23] Train loss=0.33542460203170776
Test set avg_accuracy=81.93% avg_sensitivity=55.58%, avg_specificity=90.37% avg_auc=0.8575
Fold[4] Epoch: 28 [28/100 (28%)] Train loss=0.380788 Test loss=0.414202 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3620556592941284
[5/23] Train loss=0.3799266517162323
[10/23] Train loss=0.3374325931072235
[15/23] Train loss=0.3497774600982666
[20/23] Train loss=0.3192320764064789
Test set avg_accuracy=81.89% avg_sensitivity=54.98%, avg_specificity=90.52% avg_auc=0.8575
Fold[4] Epoch: 29 [29/100 (29%)] Train loss=0.380452 Test loss=0.418052 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35930466651916504
[5/23] Train loss=0.3756990432739258
[10/23] Train loss=0.330060750246048
[15/23] Train loss=0.3466438949108124
[20/23] Train loss=0.3338082432746887
Test set avg_accuracy=81.77% avg_sensitivity=52.82%, avg_specificity=91.04% avg_auc=0.8571
Fold[4] Epoch: 30 [30/100 (30%)] Train loss=0.379817 Test loss=0.424456 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3494910001754761
[5/23] Train loss=0.37728625535964966
[10/23] Train loss=0.33000221848487854
[15/23] Train loss=0.333655446767807
[20/23] Train loss=0.3199170231819153
Test set avg_accuracy=81.93% avg_sensitivity=54.12%, avg_specificity=90.84% avg_auc=0.8575
Fold[4] Epoch: 31 [31/100 (31%)] Train loss=0.375524 Test loss=0.421483 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3612477779388428
[5/23] Train loss=0.37828031182289124
[10/23] Train loss=0.32248398661613464
[15/23] Train loss=0.3369583189487457
[20/23] Train loss=0.3175147771835327
Test set avg_accuracy=82.05% avg_sensitivity=57.14%, avg_specificity=90.04% avg_auc=0.8602
Best model saved!! Metric=-10.758633084838428!!
Fold[4] Epoch: 32 [32/100 (32%)] Train loss=0.371794 Test loss=0.414531 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3570154011249542
[5/23] Train loss=0.3763430416584015
[10/23] Train loss=0.32258570194244385
[15/23] Train loss=0.3348877727985382
[20/23] Train loss=0.3144581615924835
Test set avg_accuracy=82.03% avg_sensitivity=57.61%, avg_specificity=89.86% avg_auc=0.8603
Best model saved!! Metric=-10.47500175101773!!
Fold[4] Epoch: 33 [33/100 (33%)] Train loss=0.371152 Test loss=0.410562 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3522588312625885
[5/23] Train loss=0.3634408116340637
[10/23] Train loss=0.31644245982170105
[15/23] Train loss=0.32498323917388916
[20/23] Train loss=0.3178417384624481
Test set avg_accuracy=82.14% avg_sensitivity=58.21%, avg_specificity=89.80% avg_auc=0.8612
Best model saved!! Metric=-9.733865406963607!!
Fold[4] Epoch: 34 [34/100 (34%)] Train loss=0.369088 Test loss=0.408648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3490944802761078
[5/23] Train loss=0.3733358383178711
[10/23] Train loss=0.3300226628780365
[15/23] Train loss=0.327822208404541
[20/23] Train loss=0.3100492060184479
Test set avg_accuracy=82.35% avg_sensitivity=58.52%, avg_specificity=89.99% avg_auc=0.8606
Best model saved!! Metric=-9.07552884332175!!
Fold[4] Epoch: 35 [35/100 (35%)] Train loss=0.367150 Test loss=0.411343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3512468934059143
[5/23] Train loss=0.3687560260295868
[10/23] Train loss=0.31939923763275146
[15/23] Train loss=0.31653282046318054
[20/23] Train loss=0.30818042159080505
Test set avg_accuracy=82.06% avg_sensitivity=59.47%, avg_specificity=89.30% avg_auc=0.8614
Best model saved!! Metric=-9.025335970582496!!
Fold[4] Epoch: 36 [36/100 (36%)] Train loss=0.364132 Test loss=0.409144 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34938347339630127
[5/23] Train loss=0.36794260144233704
[10/23] Train loss=0.3165055215358734
[15/23] Train loss=0.3260369300842285
[20/23] Train loss=0.31265580654144287
Test set avg_accuracy=82.31% avg_sensitivity=58.47%, avg_specificity=89.95% avg_auc=0.8620
Fold[4] Epoch: 37 [37/100 (37%)] Train loss=0.362421 Test loss=0.416538 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34527912735939026
[5/23] Train loss=0.3689764142036438
[10/23] Train loss=0.3201059103012085
[15/23] Train loss=0.3194076418876648
[20/23] Train loss=0.31185680627822876
Test set avg_accuracy=82.27% avg_sensitivity=59.77%, avg_specificity=89.48% avg_auc=0.8614
Best model saved!! Metric=-8.34349371619041!!
Fold[4] Epoch: 38 [38/100 (38%)] Train loss=0.363041 Test loss=0.410384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3467968702316284
[5/23] Train loss=0.36740225553512573
[10/23] Train loss=0.32121410965919495
[15/23] Train loss=0.3127477467060089
[20/23] Train loss=0.31388789415359497
Test set avg_accuracy=82.29% avg_sensitivity=56.62%, avg_specificity=90.52% avg_auc=0.8596
Fold[4] Epoch: 39 [39/100 (39%)] Train loss=0.359378 Test loss=0.415859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3432033658027649
[5/23] Train loss=0.35611897706985474
[10/23] Train loss=0.3258918821811676
[15/23] Train loss=0.31157276034355164
[20/23] Train loss=0.3022775650024414
Test set avg_accuracy=82.12% avg_sensitivity=56.45%, avg_specificity=90.35% avg_auc=0.8613
Fold[4] Epoch: 40 [40/100 (40%)] Train loss=0.359617 Test loss=0.414407 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34271925687789917
[5/23] Train loss=0.360365092754364
[10/23] Train loss=0.31534284353256226
[15/23] Train loss=0.32022297382354736
[20/23] Train loss=0.3129965662956238
Test set avg_accuracy=82.27% avg_sensitivity=59.34%, avg_specificity=89.62% avg_auc=0.8628
Fold[4] Epoch: 41 [41/100 (41%)] Train loss=0.356341 Test loss=0.408786 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.338896781206131
[5/23] Train loss=0.36466261744499207
[10/23] Train loss=0.30397769808769226
[15/23] Train loss=0.3173152506351471
[20/23] Train loss=0.2933122515678406
Test set avg_accuracy=82.19% avg_sensitivity=60.41%, avg_specificity=89.17% avg_auc=0.8631
Best model saved!! Metric=-7.9251004797445574!!
Fold[4] Epoch: 42 [42/100 (42%)] Train loss=0.351632 Test loss=0.412370 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33431169390678406
[5/23] Train loss=0.3522294759750366
[10/23] Train loss=0.3093050420284271
[15/23] Train loss=0.30198419094085693
[20/23] Train loss=0.30437949299812317
Test set avg_accuracy=82.30% avg_sensitivity=58.69%, avg_specificity=89.87% avg_auc=0.8639
Fold[4] Epoch: 43 [43/100 (43%)] Train loss=0.350959 Test loss=0.410163 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3410152494907379
[5/23] Train loss=0.358548641204834
[10/23] Train loss=0.30121859908103943
[15/23] Train loss=0.3147521913051605
[20/23] Train loss=0.29699552059173584
Test set avg_accuracy=82.29% avg_sensitivity=58.52%, avg_specificity=89.91% avg_auc=0.8638
Fold[4] Epoch: 44 [44/100 (44%)] Train loss=0.349490 Test loss=0.415145 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33218297362327576
[5/23] Train loss=0.3501233458518982
[10/23] Train loss=0.30366575717926025
[15/23] Train loss=0.3137512803077698
[20/23] Train loss=0.29849299788475037
Test set avg_accuracy=82.31% avg_sensitivity=59.51%, avg_specificity=89.62% avg_auc=0.8649
Fold[4] Epoch: 45 [45/100 (45%)] Train loss=0.347553 Test loss=0.408424 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3363378345966339
[5/23] Train loss=0.35445451736450195
[10/23] Train loss=0.2947879731655121
[15/23] Train loss=0.29381680488586426
[20/23] Train loss=0.29475581645965576
Test set avg_accuracy=82.00% avg_sensitivity=59.42%, avg_specificity=89.23% avg_auc=0.8651
Fold[4] Epoch: 46 [46/100 (46%)] Train loss=0.344789 Test loss=0.405637 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3255539834499359
[5/23] Train loss=0.3534603714942932
[10/23] Train loss=0.3127092719078064
[15/23] Train loss=0.30225759744644165
[20/23] Train loss=0.30166563391685486
Test set avg_accuracy=82.48% avg_sensitivity=58.82%, avg_specificity=90.06% avg_auc=0.8639
Fold[4] Epoch: 47 [47/100 (47%)] Train loss=0.346676 Test loss=0.410523 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32287663221359253
[5/23] Train loss=0.3453117609024048
[10/23] Train loss=0.3041762709617615
[15/23] Train loss=0.3012580871582031
[20/23] Train loss=0.299470454454422
Test set avg_accuracy=82.35% avg_sensitivity=57.22%, avg_specificity=90.41% avg_auc=0.8632
Fold[4] Epoch: 48 [48/100 (48%)] Train loss=0.344454 Test loss=0.414480 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32344189286231995
[5/23] Train loss=0.34561553597450256
[10/23] Train loss=0.3058718740940094
[15/23] Train loss=0.30136942863464355
[20/23] Train loss=0.2887440323829651
Test set avg_accuracy=81.92% avg_sensitivity=57.35%, avg_specificity=89.79% avg_auc=0.8620
Fold[4] Epoch: 49 [49/100 (49%)] Train loss=0.340578 Test loss=0.416343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3276861310005188
[5/23] Train loss=0.34676122665405273
[10/23] Train loss=0.29835212230682373
[15/23] Train loss=0.2931084632873535
[20/23] Train loss=0.29285240173339844
Test set avg_accuracy=82.21% avg_sensitivity=59.94%, avg_specificity=89.34% avg_auc=0.8647
Fold[4] Epoch: 50 [50/100 (50%)] Train loss=0.339617 Test loss=0.412902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32288628816604614
[5/23] Train loss=0.3439035713672638
[10/23] Train loss=0.2898120582103729
[15/23] Train loss=0.2862107455730438
[20/23] Train loss=0.2883949279785156
Test set avg_accuracy=82.16% avg_sensitivity=59.38%, avg_specificity=89.46% avg_auc=0.8642
Fold[4] Epoch: 51 [51/100 (51%)] Train loss=0.336664 Test loss=0.412539 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32964378595352173
[5/23] Train loss=0.34242895245552063
[10/23] Train loss=0.28662753105163574
[15/23] Train loss=0.28989848494529724
[20/23] Train loss=0.29105669260025024
Test set avg_accuracy=82.08% avg_sensitivity=54.42%, avg_specificity=90.95% avg_auc=0.8630
Fold[4] Epoch: 52 [52/100 (52%)] Train loss=0.336832 Test loss=0.420958 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33535441756248474
[5/23] Train loss=0.32853955030441284
[10/23] Train loss=0.29402852058410645
[15/23] Train loss=0.2918846011161804
[20/23] Train loss=0.2870851755142212
Test set avg_accuracy=82.35% avg_sensitivity=56.49%, avg_specificity=90.64% avg_auc=0.8644
Fold[4] Epoch: 53 [53/100 (53%)] Train loss=0.334878 Test loss=0.420732 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3251315653324127
[5/23] Train loss=0.3381626009941101
[10/23] Train loss=0.2914603352546692
[15/23] Train loss=0.2801899313926697
[20/23] Train loss=0.2783704698085785
Test set avg_accuracy=81.89% avg_sensitivity=57.96%, avg_specificity=89.57% avg_auc=0.8638
Fold[4] Epoch: 54 [54/100 (54%)] Train loss=0.330097 Test loss=0.409351 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31457024812698364
[5/23] Train loss=0.3470176160335541
[10/23] Train loss=0.2980582118034363
[15/23] Train loss=0.28284594416618347
[20/23] Train loss=0.2760745584964752
Test set avg_accuracy=81.95% avg_sensitivity=60.67%, avg_specificity=88.76% avg_auc=0.8640
Fold[4] Epoch: 55 [55/100 (55%)] Train loss=0.329922 Test loss=0.413454 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3216075301170349
[5/23] Train loss=0.3451962172985077
[10/23] Train loss=0.29347750544548035
[15/23] Train loss=0.27582746744155884
[20/23] Train loss=0.28619086742401123
Test set avg_accuracy=81.72% avg_sensitivity=60.93%, avg_specificity=88.38% avg_auc=0.8623
Fold[4] Epoch: 56 [56/100 (56%)] Train loss=0.331731 Test loss=0.413292 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3123730421066284
[5/23] Train loss=0.3250049352645874
[10/23] Train loss=0.29487335681915283
[15/23] Train loss=0.28503260016441345
[20/23] Train loss=0.2776138186454773
Test set avg_accuracy=81.93% avg_sensitivity=61.41%, avg_specificity=88.50% avg_auc=0.8641
Best model saved!! Metric=-7.755079271514383!!
Fold[4] Epoch: 57 [57/100 (57%)] Train loss=0.326117 Test loss=0.415738 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30809155106544495
[5/23] Train loss=0.31477993726730347
[10/23] Train loss=0.27981287240982056
[15/23] Train loss=0.27654948830604553
[20/23] Train loss=0.27787378430366516
Test set avg_accuracy=82.09% avg_sensitivity=59.55%, avg_specificity=89.32% avg_auc=0.8647
Fold[4] Epoch: 58 [58/100 (58%)] Train loss=0.320894 Test loss=0.414502 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3095487058162689
[5/23] Train loss=0.3228079080581665
[10/23] Train loss=0.278312087059021
[15/23] Train loss=0.2872515022754669
[20/23] Train loss=0.27151525020599365
Test set avg_accuracy=82.02% avg_sensitivity=59.55%, avg_specificity=89.22% avg_auc=0.8619
Fold[4] Epoch: 59 [59/100 (59%)] Train loss=0.321986 Test loss=0.415306 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.304781973361969
[5/23] Train loss=0.3234192430973053
[10/23] Train loss=0.28567492961883545
[15/23] Train loss=0.2812398672103882
[20/23] Train loss=0.27026888728141785
Test set avg_accuracy=82.04% avg_sensitivity=59.85%, avg_specificity=89.15% avg_auc=0.8608
Fold[4] Epoch: 60 [60/100 (60%)] Train loss=0.321988 Test loss=0.420017 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30007246136665344
[5/23] Train loss=0.3186037838459015
[10/23] Train loss=0.28623008728027344
[15/23] Train loss=0.27469003200531006
[20/23] Train loss=0.2623412013053894
Test set avg_accuracy=81.92% avg_sensitivity=61.10%, avg_specificity=88.58% avg_auc=0.8626
Fold[4] Epoch: 61 [61/100 (61%)] Train loss=0.318885 Test loss=0.416680 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3107890188694
[5/23] Train loss=0.32361623644828796
[10/23] Train loss=0.2771168351173401
[15/23] Train loss=0.28730717301368713
[20/23] Train loss=0.27076777815818787
Test set avg_accuracy=82.06% avg_sensitivity=61.88%, avg_specificity=88.53% avg_auc=0.8624
Best model saved!! Metric=-7.290973191025225!!
Fold[4] Epoch: 62 [62/100 (62%)] Train loss=0.316159 Test loss=0.413954 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3019067645072937
[5/23] Train loss=0.3117603659629822
[10/23] Train loss=0.2819245159626007
[15/23] Train loss=0.2622547149658203
[20/23] Train loss=0.2635319232940674
Test set avg_accuracy=81.99% avg_sensitivity=62.44%, avg_specificity=88.25% avg_auc=0.8609
Best model saved!! Metric=-7.230960788086463!!
Fold[4] Epoch: 63 [63/100 (63%)] Train loss=0.313899 Test loss=0.418457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2992993891239166
[5/23] Train loss=0.3129783272743225
[10/23] Train loss=0.276146799325943
[15/23] Train loss=0.2622057795524597
[20/23] Train loss=0.2620971202850342
Test set avg_accuracy=81.68% avg_sensitivity=61.66%, avg_specificity=88.10% avg_auc=0.8590
Fold[4] Epoch: 64 [64/100 (64%)] Train loss=0.311917 Test loss=0.424631 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29757827520370483
[5/23] Train loss=0.3042163550853729
[10/23] Train loss=0.280971884727478
[15/23] Train loss=0.27215656638145447
[20/23] Train loss=0.2703821063041687
Test set avg_accuracy=81.84% avg_sensitivity=60.67%, avg_specificity=88.63% avg_auc=0.8598
Fold[4] Epoch: 65 [65/100 (65%)] Train loss=0.308829 Test loss=0.424445 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3027750551700592
[5/23] Train loss=0.30593985319137573
[10/23] Train loss=0.27121663093566895
[15/23] Train loss=0.2732708156108856
[20/23] Train loss=0.26617905497550964
Test set avg_accuracy=82.08% avg_sensitivity=59.29%, avg_specificity=89.39% avg_auc=0.8617
Fold[4] Epoch: 66 [66/100 (66%)] Train loss=0.307973 Test loss=0.420932 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29619526863098145
[5/23] Train loss=0.29523128271102905
[10/23] Train loss=0.27322378754615784
[15/23] Train loss=0.2706214189529419
[20/23] Train loss=0.255693644285202
Test set avg_accuracy=82.17% avg_sensitivity=57.05%, avg_specificity=90.22% avg_auc=0.8605
Fold[4] Epoch: 67 [67/100 (67%)] Train loss=0.306648 Test loss=0.419684 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2951233983039856
[5/23] Train loss=0.3014901280403137
[10/23] Train loss=0.2647126019001007
[15/23] Train loss=0.2696182131767273
[20/23] Train loss=0.25210726261138916
Test set avg_accuracy=82.09% avg_sensitivity=56.96%, avg_specificity=90.15% avg_auc=0.8637
Fold[4] Epoch: 68 [68/100 (68%)] Train loss=0.304413 Test loss=0.419923 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2980147898197174
[5/23] Train loss=0.3067617118358612
[10/23] Train loss=0.2735590934753418
[15/23] Train loss=0.2641061842441559
[20/23] Train loss=0.25307443737983704
Test set avg_accuracy=82.28% avg_sensitivity=53.82%, avg_specificity=91.40% avg_auc=0.8623
Fold[4] Epoch: 69 [69/100 (69%)] Train loss=0.304417 Test loss=0.422639 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2954435646533966
[5/23] Train loss=0.29895511269569397
[10/23] Train loss=0.2893262803554535
[15/23] Train loss=0.2571408748626709
[20/23] Train loss=0.252130389213562
Test set avg_accuracy=82.17% avg_sensitivity=54.25%, avg_specificity=91.11% avg_auc=0.8637
Fold[4] Epoch: 70 [70/100 (70%)] Train loss=0.301835 Test loss=0.424061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2862805724143982
[5/23] Train loss=0.3039519488811493
[10/23] Train loss=0.2671298384666443
[15/23] Train loss=0.25551581382751465
[20/23] Train loss=0.25149309635162354
Test set avg_accuracy=82.17% avg_sensitivity=54.29%, avg_specificity=91.10% avg_auc=0.8613
Fold[4] Epoch: 71 [71/100 (71%)] Train loss=0.299887 Test loss=0.432468 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29887720942497253
[5/23] Train loss=0.30063071846961975
[10/23] Train loss=0.26581504940986633
[15/23] Train loss=0.2647848129272461
[20/23] Train loss=0.26813802123069763
Test set avg_accuracy=81.75% avg_sensitivity=55.93%, avg_specificity=90.02% avg_auc=0.8591
Fold[4] Epoch: 72 [72/100 (72%)] Train loss=0.302570 Test loss=0.434275 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29228612780570984
[5/23] Train loss=0.2984780967235565
[10/23] Train loss=0.2624252438545227
[15/23] Train loss=0.254852294921875
[20/23] Train loss=0.24722811579704285
Test set avg_accuracy=81.72% avg_sensitivity=58.43%, avg_specificity=89.18% avg_auc=0.8562
Fold[4] Epoch: 73 [73/100 (73%)] Train loss=0.296780 Test loss=0.430554 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28836920857429504
[5/23] Train loss=0.30330827832221985
[10/23] Train loss=0.2580008804798126
[15/23] Train loss=0.25678661465644836
[20/23] Train loss=0.24513506889343262
Test set avg_accuracy=81.62% avg_sensitivity=58.60%, avg_specificity=89.00% avg_auc=0.8572
Fold[4] Epoch: 74 [74/100 (74%)] Train loss=0.292785 Test loss=0.423602 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2825039327144623
[5/23] Train loss=0.3012476861476898
[10/23] Train loss=0.24493572115898132
[15/23] Train loss=0.2522752583026886
[20/23] Train loss=0.23841789364814758
Test set avg_accuracy=81.76% avg_sensitivity=58.21%, avg_specificity=89.30% avg_auc=0.8558
Fold[4] Epoch: 75 [75/100 (75%)] Train loss=0.288544 Test loss=0.428494 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28543519973754883
[5/23] Train loss=0.28694069385528564
[10/23] Train loss=0.2597295939922333
[15/23] Train loss=0.2425999492406845
[20/23] Train loss=0.23540109395980835
Test set avg_accuracy=82.01% avg_sensitivity=59.59%, avg_specificity=89.19% avg_auc=0.8588
Fold[4] Epoch: 76 [76/100 (76%)] Train loss=0.289332 Test loss=0.430285 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28262096643447876
[5/23] Train loss=0.2911680340766907
[10/23] Train loss=0.25029256939888
[15/23] Train loss=0.25028133392333984
[20/23] Train loss=0.23517835140228271
Test set avg_accuracy=82.19% avg_sensitivity=57.35%, avg_specificity=90.15% avg_auc=0.8570
Fold[4] Epoch: 77 [77/100 (77%)] Train loss=0.287116 Test loss=0.435104 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2767665386199951
[5/23] Train loss=0.2845693826675415
[10/23] Train loss=0.25826892256736755
[15/23] Train loss=0.22936703264713287
[20/23] Train loss=0.24494320154190063
Test set avg_accuracy=81.60% avg_sensitivity=57.65%, avg_specificity=89.28% avg_auc=0.8530
Fold[4] Epoch: 78 [78/100 (78%)] Train loss=0.286427 Test loss=0.440237 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2744518518447876
[5/23] Train loss=0.27773961424827576
[10/23] Train loss=0.2585518956184387
[15/23] Train loss=0.2424650639295578
[20/23] Train loss=0.23668847978115082
Test set avg_accuracy=82.14% avg_sensitivity=61.06%, avg_specificity=88.89% avg_auc=0.8577
Fold[4] Epoch: 79 [79/100 (79%)] Train loss=0.279951 Test loss=0.445601 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2832561135292053
[5/23] Train loss=0.279092401266098
[10/23] Train loss=0.2470947504043579
[15/23] Train loss=0.23249667882919312
[20/23] Train loss=0.23337921500205994
Test set avg_accuracy=81.48% avg_sensitivity=60.24%, avg_specificity=88.28% avg_auc=0.8500
Fold[4] Epoch: 80 [80/100 (80%)] Train loss=0.278967 Test loss=0.447463 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27927273511886597
[5/23] Train loss=0.2801348865032196
[10/23] Train loss=0.2518244683742523
[15/23] Train loss=0.2394542396068573
[20/23] Train loss=0.22906537353992462
Test set avg_accuracy=81.70% avg_sensitivity=61.36%, avg_specificity=88.21% avg_auc=0.8547
Fold[4] Epoch: 81 [81/100 (81%)] Train loss=0.278958 Test loss=0.446813 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26682502031326294
[5/23] Train loss=0.27238890528678894
[10/23] Train loss=0.24999499320983887
[15/23] Train loss=0.24228520691394806
[20/23] Train loss=0.22341322898864746
Test set avg_accuracy=81.79% avg_sensitivity=62.31%, avg_specificity=88.03% avg_auc=0.8550
Fold[4] Epoch: 82 [82/100 (82%)] Train loss=0.273135 Test loss=0.449731 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27688148617744446
[5/23] Train loss=0.2622406780719757
[10/23] Train loss=0.25199729204177856
[15/23] Train loss=0.2370491772890091
[20/23] Train loss=0.21628718078136444
Test set avg_accuracy=82.01% avg_sensitivity=60.24%, avg_specificity=88.99% avg_auc=0.8545
Fold[4] Epoch: 83 [83/100 (83%)] Train loss=0.272170 Test loss=0.443475 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26839855313301086
[5/23] Train loss=0.27189138531684875
[10/23] Train loss=0.2443060725927353
[15/23] Train loss=0.23558777570724487
[20/23] Train loss=0.22067512571811676
Test set avg_accuracy=81.14% avg_sensitivity=61.06%, avg_specificity=87.58% avg_auc=0.8427
Fold[4] Epoch: 84 [84/100 (84%)] Train loss=0.269264 Test loss=0.459459 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27084970474243164
[5/23] Train loss=0.2763339877128601
[10/23] Train loss=0.2462342530488968
[15/23] Train loss=0.22364068031311035
[20/23] Train loss=0.2334652543067932
Test set avg_accuracy=81.97% avg_sensitivity=58.39%, avg_specificity=89.52% avg_auc=0.8538
Fold[4] Epoch: 85 [85/100 (85%)] Train loss=0.267848 Test loss=0.449859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26429829001426697
[5/23] Train loss=0.260046124458313
[10/23] Train loss=0.2472873330116272
[15/23] Train loss=0.23792427778244019
[20/23] Train loss=0.21427881717681885
Test set avg_accuracy=81.89% avg_sensitivity=57.27%, avg_specificity=89.79% avg_auc=0.8555
Fold[4] Epoch: 86 [86/100 (86%)] Train loss=0.266638 Test loss=0.448245 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2603828012943268
[5/23] Train loss=0.26731178164482117
[10/23] Train loss=0.252703994512558
[15/23] Train loss=0.23762333393096924
[20/23] Train loss=0.21901528537273407
Test set avg_accuracy=81.70% avg_sensitivity=60.07%, avg_specificity=88.63% avg_auc=0.8515
Fold[4] Epoch: 87 [87/100 (87%)] Train loss=0.268027 Test loss=0.454988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25572729110717773
[5/23] Train loss=0.2715550363063812
[10/23] Train loss=0.23678098618984222
[15/23] Train loss=0.2275829017162323
[20/23] Train loss=0.22357869148254395
Test set avg_accuracy=81.96% avg_sensitivity=59.81%, avg_specificity=89.05% avg_auc=0.8559
Fold[4] Epoch: 88 [88/100 (88%)] Train loss=0.263075 Test loss=0.453392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2575486898422241
[5/23] Train loss=0.2588527500629425
[10/23] Train loss=0.2408219575881958
[15/23] Train loss=0.2232065498828888
[20/23] Train loss=0.22503076493740082
Test set avg_accuracy=81.96% avg_sensitivity=58.65%, avg_specificity=89.43% avg_auc=0.8521
Fold[4] Epoch: 89 [89/100 (89%)] Train loss=0.264545 Test loss=0.456932 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25077736377716064
[5/23] Train loss=0.2547290623188019
[10/23] Train loss=0.24653463065624237
[15/23] Train loss=0.22816309332847595
[20/23] Train loss=0.21626530587673187
Test set avg_accuracy=81.96% avg_sensitivity=59.34%, avg_specificity=89.21% avg_auc=0.8570
Fold[4] Epoch: 90 [90/100 (90%)] Train loss=0.260368 Test loss=0.458551 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24955841898918152
[5/23] Train loss=0.2553664743900299
[10/23] Train loss=0.24277494847774506
[15/23] Train loss=0.21622078120708466
[20/23] Train loss=0.21142888069152832
Test set avg_accuracy=82.07% avg_sensitivity=58.65%, avg_specificity=89.58% avg_auc=0.8555
Fold[4] Epoch: 91 [91/100 (91%)] Train loss=0.258145 Test loss=0.456673 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25853437185287476
[5/23] Train loss=0.254410982131958
[10/23] Train loss=0.23873892426490784
[15/23] Train loss=0.2208806872367859
[20/23] Train loss=0.21446266770362854
Test set avg_accuracy=81.83% avg_sensitivity=57.78%, avg_specificity=89.54% avg_auc=0.8533
Fold[4] Epoch: 92 [92/100 (92%)] Train loss=0.257075 Test loss=0.460185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25830191373825073
[5/23] Train loss=0.2543334364891052
[10/23] Train loss=0.24045199155807495
[15/23] Train loss=0.22147314250469208
[20/23] Train loss=0.21453717350959778
Test set avg_accuracy=81.80% avg_sensitivity=57.65%, avg_specificity=89.54% avg_auc=0.8553
Fold[4] Epoch: 93 [93/100 (93%)] Train loss=0.257524 Test loss=0.470480 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2510588467121124
[5/23] Train loss=0.24177096784114838
[10/23] Train loss=0.24036657810211182
[15/23] Train loss=0.21573854982852936
[20/23] Train loss=0.2113279104232788
Test set avg_accuracy=81.85% avg_sensitivity=50.71%, avg_specificity=91.83% avg_auc=0.8567
Fold[4] Epoch: 94 [94/100 (94%)] Train loss=0.256114 Test loss=0.470406 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2518220543861389
[5/23] Train loss=0.25454699993133545
[10/23] Train loss=0.24943101406097412
[15/23] Train loss=0.21566158533096313
[20/23] Train loss=0.21389605104923248
Test set avg_accuracy=81.77% avg_sensitivity=51.62%, avg_specificity=91.43% avg_auc=0.8518
Fold[4] Epoch: 95 [95/100 (95%)] Train loss=0.254398 Test loss=0.461959 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25507140159606934
[5/23] Train loss=0.25287869572639465
[10/23] Train loss=0.2382120043039322
[15/23] Train loss=0.21921159327030182
[20/23] Train loss=0.21770687401294708
Test set avg_accuracy=82.21% avg_sensitivity=53.04%, avg_specificity=91.56% avg_auc=0.8581
Fold[4] Epoch: 96 [96/100 (96%)] Train loss=0.258649 Test loss=0.474701 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23750750720500946
[5/23] Train loss=0.2532065212726593
[10/23] Train loss=0.2410515993833542
[15/23] Train loss=0.22162079811096191
[20/23] Train loss=0.22534064948558807
Test set avg_accuracy=82.04% avg_sensitivity=55.11%, avg_specificity=90.67% avg_auc=0.8543
Fold[4] Epoch: 97 [97/100 (97%)] Train loss=0.259556 Test loss=0.467112 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2614577114582062
[5/23] Train loss=0.2585708200931549
[10/23] Train loss=0.23031027615070343
[15/23] Train loss=0.22353750467300415
[20/23] Train loss=0.20470407605171204
Test set avg_accuracy=82.15% avg_sensitivity=56.32%, avg_specificity=90.42% avg_auc=0.8539
Fold[4] Epoch: 98 [98/100 (98%)] Train loss=0.251417 Test loss=0.457973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2464369535446167
[5/23] Train loss=0.24828794598579407
[10/23] Train loss=0.22962243854999542
[15/23] Train loss=0.21864107251167297
[20/23] Train loss=0.19735103845596313
Test set avg_accuracy=82.03% avg_sensitivity=61.06%, avg_specificity=88.75% avg_auc=0.8485
Fold[4] Epoch: 99 [99/100 (99%)] Train loss=0.246707 Test loss=0.464984 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25040408968925476
[5/23] Train loss=0.24426086246967316
[10/23] Train loss=0.23118522763252258
[15/23] Train loss=0.2111448049545288
[20/23] Train loss=0.19639082252979279
Test set avg_accuracy=82.04% avg_sensitivity=57.96%, avg_specificity=89.76% avg_auc=0.8489
Fold[4] Epoch: 100 [100/100 (100%)] Train loss=0.242720 Test loss=0.475586 Current lr=[3.9999999999999996e-05]

Fold[4] Best Result: acc=81.98848770277341 sen=62.44070720137991, spe=88.25317855168602, auc=0.860866657560742!
[0/23] Train loss=0.6990309357643127
[5/23] Train loss=0.6884564161300659
[10/23] Train loss=0.582823634147644
[15/23] Train loss=0.5539336204528809
[20/23] Train loss=0.5439287424087524
Test set avg_accuracy=74.71% avg_sensitivity=0.04%, avg_specificity=99.99% avg_auc=0.5265
Best model saved!! Metric=-98.61050577541599!!
Fold[5] Epoch: 1 [1/100 (1%)] Train loss=0.587328 Test loss=0.634317 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5732843279838562
[5/23] Train loss=0.621617317199707
[10/23] Train loss=0.5446780323982239
[15/23] Train loss=0.5407128930091858
[20/23] Train loss=0.5297860503196716
Test set avg_accuracy=74.75% avg_sensitivity=0.21%, avg_specificity=99.97% avg_auc=0.5550
Best model saved!! Metric=-95.57759374340337!!
Fold[5] Epoch: 2 [2/100 (2%)] Train loss=0.559342 Test loss=0.612418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.562000036239624
[5/23] Train loss=0.6088602542877197
[10/23] Train loss=0.5340285897254944
[15/23] Train loss=0.5285146236419678
[20/23] Train loss=0.516680121421814
Test set avg_accuracy=74.78% avg_sensitivity=1.49%, avg_specificity=99.58% avg_auc=0.6032
Best model saved!! Metric=-89.83554576473453!!
Fold[5] Epoch: 3 [3/100 (3%)] Train loss=0.548379 Test loss=0.596402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5443344116210938
[5/23] Train loss=0.5762921571731567
[10/23] Train loss=0.5051116943359375
[15/23] Train loss=0.5125378966331482
[20/23] Train loss=0.48191556334495544
Test set avg_accuracy=74.89% avg_sensitivity=9.06%, avg_specificity=97.17% avg_auc=0.6725
Best model saved!! Metric=-77.62488830649528!!
Fold[5] Epoch: 4 [4/100 (4%)] Train loss=0.527148 Test loss=0.578428 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.522188663482666
[5/23] Train loss=0.522934079170227
[10/23] Train loss=0.47438424825668335
[15/23] Train loss=0.4952746033668518
[20/23] Train loss=0.4379173815250397
Test set avg_accuracy=76.34% avg_sensitivity=20.82%, avg_specificity=95.13% avg_auc=0.7172
Best model saved!! Metric=-61.99370404584617!!
Fold[5] Epoch: 5 [5/100 (5%)] Train loss=0.498592 Test loss=0.574859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.49128636717796326
[5/23] Train loss=0.48545077443122864
[10/23] Train loss=0.4499354958534241
[15/23] Train loss=0.4754655361175537
[20/23] Train loss=0.40870749950408936
Test set avg_accuracy=77.09% avg_sensitivity=30.34%, avg_specificity=92.91% avg_auc=0.7589
Best model saved!! Metric=-49.76328643170197!!
Fold[5] Epoch: 6 [6/100 (6%)] Train loss=0.473636 Test loss=0.549828 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.45439794659614563
[5/23] Train loss=0.4736202657222748
[10/23] Train loss=0.4245894253253937
[15/23] Train loss=0.4661235809326172
[20/23] Train loss=0.38962170481681824
Test set avg_accuracy=78.22% avg_sensitivity=37.13%, avg_specificity=92.13% avg_auc=0.7748
Best model saved!! Metric=-41.039328807662635!!
Fold[5] Epoch: 7 [7/100 (7%)] Train loss=0.454353 Test loss=0.538826 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.46151989698410034
[5/23] Train loss=0.4561862051486969
[10/23] Train loss=0.41509148478507996
[15/23] Train loss=0.4399031102657318
[20/23] Train loss=0.3852849006652832
Test set avg_accuracy=78.53% avg_sensitivity=40.44%, avg_specificity=91.43% avg_auc=0.7851
Best model saved!! Metric=-37.08810983903458!!
Fold[5] Epoch: 8 [8/100 (8%)] Train loss=0.444901 Test loss=0.530934 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42731425166130066
[5/23] Train loss=0.4557955265045166
[10/23] Train loss=0.40649914741516113
[15/23] Train loss=0.4390544891357422
[20/23] Train loss=0.3848956227302551
Test set avg_accuracy=78.77% avg_sensitivity=44.25%, avg_specificity=90.45% avg_auc=0.7968
Best model saved!! Metric=-32.85848982853383!!
Fold[5] Epoch: 9 [9/100 (9%)] Train loss=0.436150 Test loss=0.509086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4400002062320709
[5/23] Train loss=0.44459542632102966
[10/23] Train loss=0.40209296345710754
[15/23] Train loss=0.42505088448524475
[20/23] Train loss=0.3751482367515564
Test set avg_accuracy=78.98% avg_sensitivity=44.91%, avg_specificity=90.52% avg_auc=0.7959
Best model saved!! Metric=-31.996590927579653!!
Fold[5] Epoch: 10 [10/100 (10%)] Train loss=0.430167 Test loss=0.516965 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.419783353805542
[5/23] Train loss=0.4320492744445801
[10/23] Train loss=0.40520212054252625
[15/23] Train loss=0.4189126789569855
[20/23] Train loss=0.3687098026275635
Test set avg_accuracy=79.23% avg_sensitivity=45.57%, avg_specificity=90.61% avg_auc=0.8004
Best model saved!! Metric=-30.54746305460619!!
Fold[5] Epoch: 11 [11/100 (11%)] Train loss=0.425181 Test loss=0.513288 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40810632705688477
[5/23] Train loss=0.4312106668949127
[10/23] Train loss=0.39680805802345276
[15/23] Train loss=0.4004685580730438
[20/23] Train loss=0.37375786900520325
Test set avg_accuracy=79.47% avg_sensitivity=45.99%, avg_specificity=90.80% avg_auc=0.8035
Best model saved!! Metric=-29.401312531123242!!
Fold[5] Epoch: 12 [12/100 (12%)] Train loss=0.422593 Test loss=0.523978 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4061609208583832
[5/23] Train loss=0.4233153760433197
[10/23] Train loss=0.40234503149986267
[15/23] Train loss=0.39244648814201355
[20/23] Train loss=0.3665657341480255
Test set avg_accuracy=79.48% avg_sensitivity=45.36%, avg_specificity=91.02% avg_auc=0.8045
Fold[5] Epoch: 13 [13/100 (13%)] Train loss=0.423462 Test loss=0.525285 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40540093183517456
[5/23] Train loss=0.4246947169303894
[10/23] Train loss=0.39289391040802
[15/23] Train loss=0.40267693996429443
[20/23] Train loss=0.36032211780548096
Test set avg_accuracy=79.40% avg_sensitivity=47.48%, avg_specificity=90.21% avg_auc=0.8102
Best model saved!! Metric=-27.89194913961783!!
Fold[5] Epoch: 14 [14/100 (14%)] Train loss=0.420097 Test loss=0.502513 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4064605236053467
[5/23] Train loss=0.4209822118282318
[10/23] Train loss=0.369357168674469
[15/23] Train loss=0.39512181282043457
[20/23] Train loss=0.35849112272262573
Test set avg_accuracy=79.48% avg_sensitivity=50.83%, avg_specificity=89.17% avg_auc=0.8163
Best model saved!! Metric=-24.888667285059455!!
Fold[5] Epoch: 15 [15/100 (15%)] Train loss=0.415907 Test loss=0.471825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3987768590450287
[5/23] Train loss=0.41390901803970337
[10/23] Train loss=0.37146884202957153
[15/23] Train loss=0.3909745514392853
[20/23] Train loss=0.35499733686447144
Test set avg_accuracy=79.68% avg_sensitivity=51.82%, avg_specificity=89.10% avg_auc=0.8197
Best model saved!! Metric=-23.431526454287997!!
Fold[5] Epoch: 16 [16/100 (16%)] Train loss=0.407897 Test loss=0.463815 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39930492639541626
[5/23] Train loss=0.4070921838283539
[10/23] Train loss=0.36767637729644775
[15/23] Train loss=0.3827500641345978
[20/23] Train loss=0.35136184096336365
Test set avg_accuracy=79.59% avg_sensitivity=51.08%, avg_specificity=89.24% avg_auc=0.8197
Fold[5] Epoch: 17 [17/100 (17%)] Train loss=0.404449 Test loss=0.474184 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39829909801483154
[5/23] Train loss=0.4047151803970337
[10/23] Train loss=0.3673783540725708
[15/23] Train loss=0.3829777240753174
[20/23] Train loss=0.34317445755004883
Test set avg_accuracy=79.52% avg_sensitivity=52.24%, avg_specificity=88.75% avg_auc=0.8255
Best model saved!! Metric=-22.947927171165617!!
Fold[5] Epoch: 18 [18/100 (18%)] Train loss=0.401356 Test loss=0.464162 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38655975461006165
[5/23] Train loss=0.4054771363735199
[10/23] Train loss=0.364012748003006
[15/23] Train loss=0.364199161529541
[20/23] Train loss=0.34665849804878235
Test set avg_accuracy=79.71% avg_sensitivity=53.02%, avg_specificity=88.74% avg_auc=0.8274
Best model saved!! Metric=-21.788610053028563!!
Fold[5] Epoch: 19 [19/100 (19%)] Train loss=0.399771 Test loss=0.469948 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38592347502708435
[5/23] Train loss=0.4052164554595947
[10/23] Train loss=0.35893428325653076
[15/23] Train loss=0.3724767863750458
[20/23] Train loss=0.34532588720321655
Test set avg_accuracy=79.62% avg_sensitivity=52.98%, avg_specificity=88.64% avg_auc=0.8295
Fold[5] Epoch: 20 [20/100 (20%)] Train loss=0.396754 Test loss=0.462222 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38796478509902954
[5/23] Train loss=0.395461767911911
[10/23] Train loss=0.3595534861087799
[15/23] Train loss=0.3713912069797516
[20/23] Train loss=0.34426748752593994
Test set avg_accuracy=79.55% avg_sensitivity=52.86%, avg_specificity=88.58% avg_auc=0.8280
Fold[5] Epoch: 21 [21/100 (21%)] Train loss=0.393680 Test loss=0.473776 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37360575795173645
[5/23] Train loss=0.39525821805000305
[10/23] Train loss=0.3594212830066681
[15/23] Train loss=0.364287406206131
[20/23] Train loss=0.3415917456150055
Test set avg_accuracy=79.54% avg_sensitivity=53.81%, avg_specificity=88.25% avg_auc=0.8322
Best model saved!! Metric=-21.18515860644172!!
Fold[5] Epoch: 22 [22/100 (22%)] Train loss=0.391949 Test loss=0.455572 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3813563883304596
[5/23] Train loss=0.3898712396621704
[10/23] Train loss=0.3498493731021881
[15/23] Train loss=0.3540567457675934
[20/23] Train loss=0.3297019600868225
Test set avg_accuracy=79.40% avg_sensitivity=55.09%, avg_specificity=87.63% avg_auc=0.8321
Best model saved!! Metric=-20.664080858958204!!
Fold[5] Epoch: 23 [23/100 (23%)] Train loss=0.388160 Test loss=0.459526 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.371033638715744
[5/23] Train loss=0.38666442036628723
[10/23] Train loss=0.34998002648353577
[15/23] Train loss=0.3503546416759491
[20/23] Train loss=0.32529520988464355
Test set avg_accuracy=79.57% avg_sensitivity=55.34%, avg_specificity=87.77% avg_auc=0.8363
Best model saved!! Metric=-19.69124071073289!!
Fold[5] Epoch: 24 [24/100 (24%)] Train loss=0.386286 Test loss=0.443390 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3776164650917053
[5/23] Train loss=0.3867453932762146
[10/23] Train loss=0.34135276079177856
[15/23] Train loss=0.3494200110435486
[20/23] Train loss=0.3348941206932068
Test set avg_accuracy=79.52% avg_sensitivity=56.58%, avg_specificity=87.28% avg_auc=0.8362
Best model saved!! Metric=-18.995492359678657!!
Fold[5] Epoch: 25 [25/100 (25%)] Train loss=0.383500 Test loss=0.442591 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37524446845054626
[5/23] Train loss=0.38259583711624146
[10/23] Train loss=0.3508847653865814
[15/23] Train loss=0.34958040714263916
[20/23] Train loss=0.33029904961586
Test set avg_accuracy=79.61% avg_sensitivity=56.50%, avg_specificity=87.44% avg_auc=0.8376
Best model saved!! Metric=-18.69575316898959!!
Fold[5] Epoch: 26 [26/100 (26%)] Train loss=0.381450 Test loss=0.442305 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3663800060749054
[5/23] Train loss=0.3789554536342621
[10/23] Train loss=0.3464294672012329
[15/23] Train loss=0.3458682596683502
[20/23] Train loss=0.32838401198387146
Test set avg_accuracy=79.52% avg_sensitivity=57.53%, avg_specificity=86.96% avg_auc=0.8382
Best model saved!! Metric=-18.16599931754188!!
Fold[5] Epoch: 27 [27/100 (27%)] Train loss=0.380131 Test loss=0.439868 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37306973338127136
[5/23] Train loss=0.38344770669937134
[10/23] Train loss=0.3420436680316925
[15/23] Train loss=0.3419629633426666
[20/23] Train loss=0.3253500163555145
Test set avg_accuracy=79.46% avg_sensitivity=59.06%, avg_specificity=86.36% avg_auc=0.8382
Best model saved!! Metric=-17.298766202876017!!
Fold[5] Epoch: 28 [28/100 (28%)] Train loss=0.375444 Test loss=0.443088 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3663301467895508
[5/23] Train loss=0.37387973070144653
[10/23] Train loss=0.3383595645427704
[15/23] Train loss=0.3405814468860626
[20/23] Train loss=0.32093483209609985
Test set avg_accuracy=79.34% avg_sensitivity=57.08%, avg_specificity=86.87% avg_auc=0.8375
Fold[5] Epoch: 29 [29/100 (29%)] Train loss=0.373004 Test loss=0.448517 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3602903485298157
[5/23] Train loss=0.3692111670970917
[10/23] Train loss=0.34309834241867065
[15/23] Train loss=0.33668774366378784
[20/23] Train loss=0.31920745968818665
Test set avg_accuracy=79.76% avg_sensitivity=56.66%, avg_specificity=87.58% avg_auc=0.8361
Fold[5] Epoch: 30 [30/100 (30%)] Train loss=0.373470 Test loss=0.451988 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3545023500919342
[5/23] Train loss=0.37423035502433777
[10/23] Train loss=0.34349504113197327
[15/23] Train loss=0.3411458432674408
[20/23] Train loss=0.3191458582878113
Test set avg_accuracy=79.79% avg_sensitivity=56.13%, avg_specificity=87.80% avg_auc=0.8377
Fold[5] Epoch: 31 [31/100 (31%)] Train loss=0.372638 Test loss=0.455008 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3606112003326416
[5/23] Train loss=0.37430328130722046
[10/23] Train loss=0.338325172662735
[15/23] Train loss=0.3382168412208557
[20/23] Train loss=0.315251886844635
Test set avg_accuracy=79.53% avg_sensitivity=59.77%, avg_specificity=86.22% avg_auc=0.8381
Best model saved!! Metric=-16.677031145177317!!
Fold[5] Epoch: 32 [32/100 (32%)] Train loss=0.370724 Test loss=0.450475 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35671356320381165
[5/23] Train loss=0.3666750490665436
[10/23] Train loss=0.3336257040500641
[15/23] Train loss=0.3363223671913147
[20/23] Train loss=0.3178645670413971
Test set avg_accuracy=79.47% avg_sensitivity=60.84%, avg_specificity=85.77% avg_auc=0.8403
Best model saved!! Metric=-15.89146920248078!!
Fold[5] Epoch: 33 [33/100 (33%)] Train loss=0.368463 Test loss=0.445932 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36040353775024414
[5/23] Train loss=0.3642440140247345
[10/23] Train loss=0.326684832572937
[15/23] Train loss=0.33310288190841675
[20/23] Train loss=0.3123171627521515
Test set avg_accuracy=79.30% avg_sensitivity=60.68%, avg_specificity=85.60% avg_auc=0.8417
Fold[5] Epoch: 34 [34/100 (34%)] Train loss=0.364993 Test loss=0.438955 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3488081395626068
[5/23] Train loss=0.36378949880599976
[10/23] Train loss=0.33399492502212524
[15/23] Train loss=0.33088618516921997
[20/23] Train loss=0.31283849477767944
Test set avg_accuracy=79.46% avg_sensitivity=61.05%, avg_specificity=85.68% avg_auc=0.8431
Best model saved!! Metric=-15.495918492927215!!
Fold[5] Epoch: 35 [35/100 (35%)] Train loss=0.363681 Test loss=0.435064 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35002538561820984
[5/23] Train loss=0.358123242855072
[10/23] Train loss=0.3332313895225525
[15/23] Train loss=0.3287658095359802
[20/23] Train loss=0.3086029291152954
Test set avg_accuracy=79.58% avg_sensitivity=59.48%, avg_specificity=86.38% avg_auc=0.8414
Fold[5] Epoch: 36 [36/100 (36%)] Train loss=0.359301 Test loss=0.441699 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3514314591884613
[5/23] Train loss=0.36055049300193787
[10/23] Train loss=0.33015990257263184
[15/23] Train loss=0.33470386266708374
[20/23] Train loss=0.31503042578697205
Test set avg_accuracy=79.75% avg_sensitivity=58.94%, avg_specificity=86.79% avg_auc=0.8401
Fold[5] Epoch: 37 [37/100 (37%)] Train loss=0.361184 Test loss=0.444083 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3503091335296631
[5/23] Train loss=0.35151252150535583
[10/23] Train loss=0.33038613200187683
[15/23] Train loss=0.3219025433063507
[20/23] Train loss=0.3183191120624542
Test set avg_accuracy=79.63% avg_sensitivity=58.57%, avg_specificity=86.76% avg_auc=0.8406
Fold[5] Epoch: 38 [38/100 (38%)] Train loss=0.360163 Test loss=0.449368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3491787910461426
[5/23] Train loss=0.3539583086967468
[10/23] Train loss=0.3214457333087921
[15/23] Train loss=0.3204815685749054
[20/23] Train loss=0.31594982743263245
Test set avg_accuracy=79.53% avg_sensitivity=60.39%, avg_specificity=86.01% avg_auc=0.8400
Fold[5] Epoch: 39 [39/100 (39%)] Train loss=0.356933 Test loss=0.442424 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3438534736633301
[5/23] Train loss=0.358080118894577
[10/23] Train loss=0.32392802834510803
[15/23] Train loss=0.3202807307243347
[20/23] Train loss=0.3094843327999115
Test set avg_accuracy=79.27% avg_sensitivity=62.67%, avg_specificity=84.89% avg_auc=0.8405
Best model saved!! Metric=-15.129782313303313!!
Fold[5] Epoch: 40 [40/100 (40%)] Train loss=0.353399 Test loss=0.452324 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3513614237308502
[5/23] Train loss=0.3445001244544983
[10/23] Train loss=0.3104262351989746
[15/23] Train loss=0.32355865836143494
[20/23] Train loss=0.3118302524089813
Test set avg_accuracy=79.55% avg_sensitivity=62.21%, avg_specificity=85.42% avg_auc=0.8414
Best model saved!! Metric=-14.679737344110569!!
Fold[5] Epoch: 41 [41/100 (41%)] Train loss=0.352659 Test loss=0.442087 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.343898206949234
[5/23] Train loss=0.3400740325450897
[10/23] Train loss=0.3152109384536743
[15/23] Train loss=0.3143545687198639
[20/23] Train loss=0.2965502440929413
Test set avg_accuracy=79.10% avg_sensitivity=62.54%, avg_specificity=84.70% avg_auc=0.8432
Fold[5] Epoch: 42 [42/100 (42%)] Train loss=0.346674 Test loss=0.437906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.348794162273407
[5/23] Train loss=0.3504197895526886
[10/23] Train loss=0.30335021018981934
[15/23] Train loss=0.30805712938308716
[20/23] Train loss=0.2974742650985718
Test set avg_accuracy=79.52% avg_sensitivity=62.09%, avg_specificity=85.42% avg_auc=0.8423
Fold[5] Epoch: 43 [43/100 (43%)] Train loss=0.346814 Test loss=0.444835 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3358132839202881
[5/23] Train loss=0.34277692437171936
[10/23] Train loss=0.31385669112205505
[15/23] Train loss=0.3136410713195801
[20/23] Train loss=0.29155591130256653
Test set avg_accuracy=79.85% avg_sensitivity=60.02%, avg_specificity=86.57% avg_auc=0.8426
Fold[5] Epoch: 44 [44/100 (44%)] Train loss=0.345947 Test loss=0.438153 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34259113669395447
[5/23] Train loss=0.34371912479400635
[10/23] Train loss=0.31638848781585693
[15/23] Train loss=0.308397114276886
[20/23] Train loss=0.29445821046829224
Test set avg_accuracy=79.75% avg_sensitivity=61.96%, avg_specificity=85.77% avg_auc=0.8425
Best model saved!! Metric=-14.274874180365387!!
Fold[5] Epoch: 45 [45/100 (45%)] Train loss=0.346027 Test loss=0.436336 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3307349681854248
[5/23] Train loss=0.3323310613632202
[10/23] Train loss=0.3013231158256531
[15/23] Train loss=0.3087964355945587
[20/23] Train loss=0.2922140955924988
Test set avg_accuracy=80.14% avg_sensitivity=61.47%, avg_specificity=86.45% avg_auc=0.8443
Best model saved!! Metric=-13.515091021273852!!
Fold[5] Epoch: 46 [46/100 (46%)] Train loss=0.338895 Test loss=0.437265 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3347361981868744
[5/23] Train loss=0.3416286110877991
[10/23] Train loss=0.2999265491962433
[15/23] Train loss=0.3050692081451416
[20/23] Train loss=0.2906889319419861
Test set avg_accuracy=79.60% avg_sensitivity=62.96%, avg_specificity=85.24% avg_auc=0.8431
Fold[5] Epoch: 47 [47/100 (47%)] Train loss=0.340287 Test loss=0.442480 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33347582817077637
[5/23] Train loss=0.3304676115512848
[10/23] Train loss=0.3001042902469635
[15/23] Train loss=0.29971298575401306
[20/23] Train loss=0.28516843914985657
Test set avg_accuracy=79.63% avg_sensitivity=62.29%, avg_specificity=85.50% avg_auc=0.8434
Fold[5] Epoch: 48 [48/100 (48%)] Train loss=0.336171 Test loss=0.443163 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32766661047935486
[5/23] Train loss=0.330299973487854
[10/23] Train loss=0.30430638790130615
[15/23] Train loss=0.3162667751312256
[20/23] Train loss=0.2892876863479614
Test set avg_accuracy=80.32% avg_sensitivity=61.30%, avg_specificity=86.76% avg_auc=0.8441
Best model saved!! Metric=-13.204666493877557!!
Fold[5] Epoch: 49 [49/100 (49%)] Train loss=0.335513 Test loss=0.443867 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3257385492324829
[5/23] Train loss=0.3273757994174957
[10/23] Train loss=0.3046570122241974
[15/23] Train loss=0.30337363481521606
[20/23] Train loss=0.286933034658432
Test set avg_accuracy=80.77% avg_sensitivity=57.86%, avg_specificity=88.53% avg_auc=0.8448
Fold[5] Epoch: 50 [50/100 (50%)] Train loss=0.333814 Test loss=0.434513 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3262474238872528
[5/23] Train loss=0.33680659532546997
[10/23] Train loss=0.30145376920700073
[15/23] Train loss=0.3099680542945862
[20/23] Train loss=0.2924073040485382
Test set avg_accuracy=80.39% avg_sensitivity=58.03%, avg_specificity=87.95% avg_auc=0.8451
Fold[5] Epoch: 51 [51/100 (51%)] Train loss=0.334453 Test loss=0.432949 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.324624240398407
[5/23] Train loss=0.3243492543697357
[10/23] Train loss=0.30881449580192566
[15/23] Train loss=0.2978396415710449
[20/23] Train loss=0.2937740087509155
Test set avg_accuracy=80.99% avg_sensitivity=56.29%, avg_specificity=89.35% avg_auc=0.8428
Fold[5] Epoch: 52 [52/100 (52%)] Train loss=0.334710 Test loss=0.443020 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3371640145778656
[5/23] Train loss=0.3256184458732605
[10/23] Train loss=0.30182725191116333
[15/23] Train loss=0.2845909595489502
[20/23] Train loss=0.29584455490112305
Test set avg_accuracy=80.33% avg_sensitivity=60.26%, avg_specificity=87.13% avg_auc=0.8428
Fold[5] Epoch: 53 [53/100 (53%)] Train loss=0.334284 Test loss=0.447200 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3209441006183624
[5/23] Train loss=0.324151873588562
[10/23] Train loss=0.29991817474365234
[15/23] Train loss=0.30431005358695984
[20/23] Train loss=0.28699877858161926
Test set avg_accuracy=80.54% avg_sensitivity=60.60%, avg_specificity=87.30% avg_auc=0.8457
Best model saved!! Metric=-12.996821112950045!!
Fold[5] Epoch: 54 [54/100 (54%)] Train loss=0.331445 Test loss=0.429300 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3178834319114685
[5/23] Train loss=0.3312455117702484
[10/23] Train loss=0.28933849930763245
[15/23] Train loss=0.2925531566143036
[20/23] Train loss=0.28562793135643005
Test set avg_accuracy=80.48% avg_sensitivity=60.89%, avg_specificity=87.11% avg_auc=0.8461
Best model saved!! Metric=-12.911118468446688!!
Fold[5] Epoch: 55 [55/100 (55%)] Train loss=0.326427 Test loss=0.429921 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3230387568473816
[5/23] Train loss=0.32172995805740356
[10/23] Train loss=0.29831916093826294
[15/23] Train loss=0.29443225264549255
[20/23] Train loss=0.2741404175758362
Test set avg_accuracy=80.44% avg_sensitivity=62.09%, avg_specificity=86.65% avg_auc=0.8458
Best model saved!! Metric=-12.244300666628957!!
Fold[5] Epoch: 56 [56/100 (56%)] Train loss=0.323450 Test loss=0.437413 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3115396201610565
[5/23] Train loss=0.31988438963890076
[10/23] Train loss=0.28445202112197876
[15/23] Train loss=0.3002004027366638
[20/23] Train loss=0.27028828859329224
Test set avg_accuracy=80.13% avg_sensitivity=62.83%, avg_specificity=85.98% avg_auc=0.8462
Fold[5] Epoch: 57 [57/100 (57%)] Train loss=0.321004 Test loss=0.435692 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3173176944255829
[5/23] Train loss=0.3216606080532074
[10/23] Train loss=0.2805778980255127
[15/23] Train loss=0.28956517577171326
[20/23] Train loss=0.27113252878189087
Test set avg_accuracy=80.32% avg_sensitivity=62.58%, avg_specificity=86.33% avg_auc=0.8433
Fold[5] Epoch: 58 [58/100 (58%)] Train loss=0.320856 Test loss=0.445194 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3020300567150116
[5/23] Train loss=0.31388986110687256
[10/23] Train loss=0.29701319336891174
[15/23] Train loss=0.2863703668117523
[20/23] Train loss=0.2720252275466919
Test set avg_accuracy=80.72% avg_sensitivity=61.30%, avg_specificity=87.30% avg_auc=0.8459
Best model saved!! Metric=-12.092646961168956!!
Fold[5] Epoch: 59 [59/100 (59%)] Train loss=0.317476 Test loss=0.449117 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30845585465431213
[5/23] Train loss=0.3105020225048065
[10/23] Train loss=0.2787792980670929
[15/23] Train loss=0.2864032983779907
[20/23] Train loss=0.27713045477867126
Test set avg_accuracy=80.72% avg_sensitivity=61.13%, avg_specificity=87.35% avg_auc=0.8460
Fold[5] Epoch: 60 [60/100 (60%)] Train loss=0.318371 Test loss=0.432479 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3063729703426361
[5/23] Train loss=0.3166409730911255
[10/23] Train loss=0.2846046984195709
[15/23] Train loss=0.2808719575405121
[20/23] Train loss=0.27247384190559387
Test set avg_accuracy=79.72% avg_sensitivity=62.91%, avg_specificity=85.40% avg_auc=0.8429
Fold[5] Epoch: 61 [61/100 (61%)] Train loss=0.313464 Test loss=0.445428 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30888253450393677
[5/23] Train loss=0.32475975155830383
[10/23] Train loss=0.28823307156562805
[15/23] Train loss=0.2825639843940735
[20/23] Train loss=0.27413421869277954
Test set avg_accuracy=79.93% avg_sensitivity=62.67%, avg_specificity=85.77% avg_auc=0.8441
Fold[5] Epoch: 62 [62/100 (62%)] Train loss=0.314115 Test loss=0.452488 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30117371678352356
[5/23] Train loss=0.2990724742412567
[10/23] Train loss=0.28156915307044983
[15/23] Train loss=0.2808995246887207
[20/23] Train loss=0.2654997706413269
Test set avg_accuracy=80.37% avg_sensitivity=58.57%, avg_specificity=87.74% avg_auc=0.8424
Fold[5] Epoch: 63 [63/100 (63%)] Train loss=0.308977 Test loss=0.442314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30330899357795715
[5/23] Train loss=0.30860456824302673
[10/23] Train loss=0.27534809708595276
[15/23] Train loss=0.27814939618110657
[20/23] Train loss=0.25938984751701355
Test set avg_accuracy=80.59% avg_sensitivity=59.48%, avg_specificity=87.73% avg_auc=0.8436
Fold[5] Epoch: 64 [64/100 (64%)] Train loss=0.309467 Test loss=0.442664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3034403324127197
[5/23] Train loss=0.2936171591281891
[10/23] Train loss=0.2761346697807312
[15/23] Train loss=0.2812519371509552
[20/23] Train loss=0.26429498195648193
Test set avg_accuracy=80.44% avg_sensitivity=59.11%, avg_specificity=87.66% avg_auc=0.8409
Fold[5] Epoch: 65 [65/100 (65%)] Train loss=0.305873 Test loss=0.448713 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29611125588417053
[5/23] Train loss=0.2894822657108307
[10/23] Train loss=0.28160539269447327
[15/23] Train loss=0.2708217203617096
[20/23] Train loss=0.26230692863464355
Test set avg_accuracy=80.42% avg_sensitivity=59.35%, avg_specificity=87.55% avg_auc=0.8412
Fold[5] Epoch: 66 [66/100 (66%)] Train loss=0.304245 Test loss=0.449092 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29661765694618225
[5/23] Train loss=0.30037611722946167
[10/23] Train loss=0.2641074061393738
[15/23] Train loss=0.27162593603134155
[20/23] Train loss=0.25894448161125183
Test set avg_accuracy=80.60% avg_sensitivity=59.56%, avg_specificity=87.72% avg_auc=0.8396
Fold[5] Epoch: 67 [67/100 (67%)] Train loss=0.299847 Test loss=0.455417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2881774306297302
[5/23] Train loss=0.30458930134773254
[10/23] Train loss=0.2669376730918884
[15/23] Train loss=0.27970030903816223
[20/23] Train loss=0.2537139654159546
Test set avg_accuracy=80.13% avg_sensitivity=60.51%, avg_specificity=86.76% avg_auc=0.8391
Fold[5] Epoch: 68 [68/100 (68%)] Train loss=0.301833 Test loss=0.463444 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2957707941532135
[5/23] Train loss=0.3073080778121948
[10/23] Train loss=0.2663044035434723
[15/23] Train loss=0.2825154960155487
[20/23] Train loss=0.25334665179252625
Test set avg_accuracy=79.90% avg_sensitivity=64.74%, avg_specificity=85.03% avg_auc=0.8416
Fold[5] Epoch: 69 [69/100 (69%)] Train loss=0.301976 Test loss=0.464211 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29357436299324036
[5/23] Train loss=0.3025759756565094
[10/23] Train loss=0.2712515592575073
[15/23] Train loss=0.2676679491996765
[20/23] Train loss=0.26072192192077637
Test set avg_accuracy=79.63% avg_sensitivity=62.91%, avg_specificity=85.29% avg_auc=0.8402
Fold[5] Epoch: 70 [70/100 (70%)] Train loss=0.298084 Test loss=0.461503 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2915976941585541
[5/23] Train loss=0.2924782335758209
[10/23] Train loss=0.25939860939979553
[15/23] Train loss=0.26558735966682434
[20/23] Train loss=0.25898948311805725
Test set avg_accuracy=80.16% avg_sensitivity=62.91%, avg_specificity=85.99% avg_auc=0.8417
Fold[5] Epoch: 71 [71/100 (71%)] Train loss=0.294170 Test loss=0.455305 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2952631115913391
[5/23] Train loss=0.2843719720840454
[10/23] Train loss=0.26723602414131165
[15/23] Train loss=0.26158809661865234
[20/23] Train loss=0.2558799684047699
Test set avg_accuracy=79.78% avg_sensitivity=64.78%, avg_specificity=84.86% avg_auc=0.8425
Fold[5] Epoch: 72 [72/100 (72%)] Train loss=0.292683 Test loss=0.456407 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28226369619369507
[5/23] Train loss=0.2884170114994049
[10/23] Train loss=0.25833913683891296
[15/23] Train loss=0.2566380202770233
[20/23] Train loss=0.2457932084798813
Test set avg_accuracy=80.02% avg_sensitivity=64.11%, avg_specificity=85.40% avg_auc=0.8419
Fold[5] Epoch: 73 [73/100 (73%)] Train loss=0.289255 Test loss=0.457915 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28710976243019104
[5/23] Train loss=0.2848450839519501
[10/23] Train loss=0.25824999809265137
[15/23] Train loss=0.26651278138160706
[20/23] Train loss=0.24791042506694794
Test set avg_accuracy=79.90% avg_sensitivity=60.39%, avg_specificity=86.50% avg_auc=0.8367
Fold[5] Epoch: 74 [74/100 (74%)] Train loss=0.286174 Test loss=0.463226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27936384081840515
[5/23] Train loss=0.2839830219745636
[10/23] Train loss=0.2642557621002197
[15/23] Train loss=0.2627803087234497
[20/23] Train loss=0.2492707371711731
Test set avg_accuracy=79.96% avg_sensitivity=61.75%, avg_specificity=86.12% avg_auc=0.8383
Fold[5] Epoch: 75 [75/100 (75%)] Train loss=0.289191 Test loss=0.460690 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27948787808418274
[5/23] Train loss=0.2897642254829407
[10/23] Train loss=0.26606109738349915
[15/23] Train loss=0.26892054080963135
[20/23] Train loss=0.2425776869058609
Test set avg_accuracy=79.69% avg_sensitivity=64.32%, avg_specificity=84.89% avg_auc=0.8398
Fold[5] Epoch: 76 [76/100 (76%)] Train loss=0.287617 Test loss=0.468287 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28388553857803345
[5/23] Train loss=0.2993018925189972
[10/23] Train loss=0.2560747563838959
[15/23] Train loss=0.2551282048225403
[20/23] Train loss=0.24202579259872437
Test set avg_accuracy=79.48% avg_sensitivity=66.47%, avg_specificity=83.88% avg_auc=0.8447
Best model saved!! Metric=-11.707416131290737!!
Fold[5] Epoch: 77 [77/100 (77%)] Train loss=0.286250 Test loss=0.465281 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28200334310531616
[5/23] Train loss=0.28227588534355164
[10/23] Train loss=0.26746782660484314
[15/23] Train loss=0.25493744015693665
[20/23] Train loss=0.23822161555290222
Test set avg_accuracy=79.18% avg_sensitivity=66.27%, avg_specificity=83.56% avg_auc=0.8409
Fold[5] Epoch: 78 [78/100 (78%)] Train loss=0.282870 Test loss=0.471465 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28221678733825684
[5/23] Train loss=0.2747597396373749
[10/23] Train loss=0.26548805832862854
[15/23] Train loss=0.26027050614356995
[20/23] Train loss=0.24428196251392365
Test set avg_accuracy=79.62% avg_sensitivity=62.13%, avg_specificity=85.54% avg_auc=0.8420
Fold[5] Epoch: 79 [79/100 (79%)] Train loss=0.280590 Test loss=0.462747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27526941895484924
[5/23] Train loss=0.28155991435050964
[10/23] Train loss=0.26113003492355347
[15/23] Train loss=0.25492653250694275
[20/23] Train loss=0.24437746405601501
Test set avg_accuracy=80.54% avg_sensitivity=59.64%, avg_specificity=87.62% avg_auc=0.8403
Fold[5] Epoch: 80 [80/100 (80%)] Train loss=0.279409 Test loss=0.456151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27617332339286804
[5/23] Train loss=0.2705073356628418
[10/23] Train loss=0.25927719473838806
[15/23] Train loss=0.24566057324409485
[20/23] Train loss=0.23444564640522003
Test set avg_accuracy=80.76% avg_sensitivity=57.33%, avg_specificity=88.70% avg_auc=0.8404
Fold[5] Epoch: 81 [81/100 (81%)] Train loss=0.277109 Test loss=0.456973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27539464831352234
[5/23] Train loss=0.26164600253105164
[10/23] Train loss=0.25623276829719543
[15/23] Train loss=0.24855667352676392
[20/23] Train loss=0.23633411526679993
Test set avg_accuracy=80.96% avg_sensitivity=54.22%, avg_specificity=90.01% avg_auc=0.8435
Fold[5] Epoch: 82 [82/100 (82%)] Train loss=0.278289 Test loss=0.457370 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27391988039016724
[5/23] Train loss=0.2754758894443512
[10/23] Train loss=0.271637499332428
[15/23] Train loss=0.26020222902297974
[20/23] Train loss=0.24197784066200256
Test set avg_accuracy=80.83% avg_sensitivity=53.48%, avg_specificity=90.08% avg_auc=0.8358
Fold[5] Epoch: 83 [83/100 (83%)] Train loss=0.282055 Test loss=0.473417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26848334074020386
[5/23] Train loss=0.266230046749115
[10/23] Train loss=0.2465403527021408
[15/23] Train loss=0.23832790553569794
[20/23] Train loss=0.22927258908748627
Test set avg_accuracy=80.41% avg_sensitivity=60.51%, avg_specificity=87.14% avg_auc=0.8376
Fold[5] Epoch: 84 [84/100 (84%)] Train loss=0.272502 Test loss=0.474714 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2754127085208893
[5/23] Train loss=0.26401081681251526
[10/23] Train loss=0.24482841789722443
[15/23] Train loss=0.24036064743995667
[20/23] Train loss=0.2312028855085373
Test set avg_accuracy=80.39% avg_sensitivity=62.09%, avg_specificity=86.58% avg_auc=0.8421
Fold[5] Epoch: 85 [85/100 (85%)] Train loss=0.269985 Test loss=0.459499 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2595907151699066
[5/23] Train loss=0.262197881937027
[10/23] Train loss=0.2511884868144989
[15/23] Train loss=0.24159257113933563
[20/23] Train loss=0.2275533378124237
Test set avg_accuracy=79.95% avg_sensitivity=61.75%, avg_specificity=86.10% avg_auc=0.8375
Fold[5] Epoch: 86 [86/100 (86%)] Train loss=0.264441 Test loss=0.470361 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25729984045028687
[5/23] Train loss=0.26430732011795044
[10/23] Train loss=0.2349633425474167
[15/23] Train loss=0.2499626725912094
[20/23] Train loss=0.22061575949192047
Test set avg_accuracy=80.14% avg_sensitivity=61.84%, avg_specificity=86.33% avg_auc=0.8383
Fold[5] Epoch: 87 [87/100 (87%)] Train loss=0.263163 Test loss=0.476082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25710806250572205
[5/23] Train loss=0.25019147992134094
[10/23] Train loss=0.2437979280948639
[15/23] Train loss=0.24451300501823425
[20/23] Train loss=0.22444377839565277
Test set avg_accuracy=79.87% avg_sensitivity=62.75%, avg_specificity=85.67% avg_auc=0.8370
Fold[5] Epoch: 88 [88/100 (88%)] Train loss=0.260738 Test loss=0.477374 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2593490481376648
[5/23] Train loss=0.2548236548900604
[10/23] Train loss=0.23892392218112946
[15/23] Train loss=0.2335173487663269
[20/23] Train loss=0.22430264949798584
Test set avg_accuracy=80.88% avg_sensitivity=58.28%, avg_specificity=88.53% avg_auc=0.8372
Fold[5] Epoch: 89 [89/100 (89%)] Train loss=0.258874 Test loss=0.467374 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25492778420448303
[5/23] Train loss=0.25704917311668396
[10/23] Train loss=0.24289549887180328
[15/23] Train loss=0.23975826799869537
[20/23] Train loss=0.22057512402534485
Test set avg_accuracy=80.83% avg_sensitivity=56.91%, avg_specificity=88.92% avg_auc=0.8365
Fold[5] Epoch: 90 [90/100 (90%)] Train loss=0.255201 Test loss=0.467979 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24845649302005768
[5/23] Train loss=0.24903038144111633
[10/23] Train loss=0.23899996280670166
[15/23] Train loss=0.24253441393375397
[20/23] Train loss=0.21375848352909088
Test set avg_accuracy=80.97% avg_sensitivity=55.46%, avg_specificity=89.61% avg_auc=0.8377
Fold[5] Epoch: 91 [91/100 (91%)] Train loss=0.255717 Test loss=0.475439 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25432413816452026
[5/23] Train loss=0.24561090767383575
[10/23] Train loss=0.2422362118959427
[15/23] Train loss=0.23262210190296173
[20/23] Train loss=0.22128814458847046
Test set avg_accuracy=80.63% avg_sensitivity=56.71%, avg_specificity=88.72% avg_auc=0.8396
Fold[5] Epoch: 92 [92/100 (92%)] Train loss=0.257226 Test loss=0.483734 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24762819707393646
[5/23] Train loss=0.257807195186615
[10/23] Train loss=0.23822633922100067
[15/23] Train loss=0.2327965795993805
[20/23] Train loss=0.22832052409648895
Test set avg_accuracy=81.10% avg_sensitivity=55.38%, avg_specificity=89.80% avg_auc=0.8384
Fold[5] Epoch: 93 [93/100 (93%)] Train loss=0.258336 Test loss=0.476154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2341664433479309
[5/23] Train loss=0.24461640417575836
[10/23] Train loss=0.23060967028141022
[15/23] Train loss=0.2341049462556839
[20/23] Train loss=0.22397597134113312
Test set avg_accuracy=80.43% avg_sensitivity=59.02%, avg_specificity=87.67% avg_auc=0.8406
Fold[5] Epoch: 94 [94/100 (94%)] Train loss=0.251845 Test loss=0.474821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24156297743320465
[5/23] Train loss=0.25024449825286865
[10/23] Train loss=0.237559512257576
[15/23] Train loss=0.24873086810112
[20/23] Train loss=0.2113102227449417
Test set avg_accuracy=80.32% avg_sensitivity=61.63%, avg_specificity=86.65% avg_auc=0.8399
Fold[5] Epoch: 95 [95/100 (95%)] Train loss=0.250501 Test loss=0.479256 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24114848673343658
[5/23] Train loss=0.24693737924098969
[10/23] Train loss=0.22904548048973083
[15/23] Train loss=0.22705045342445374
[20/23] Train loss=0.2026033103466034
Test set avg_accuracy=80.47% avg_sensitivity=61.47%, avg_specificity=86.90% avg_auc=0.8406
Fold[5] Epoch: 96 [96/100 (96%)] Train loss=0.243911 Test loss=0.473226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22975948452949524
[5/23] Train loss=0.22604675590991974
[10/23] Train loss=0.22451192140579224
[15/23] Train loss=0.22318759560585022
[20/23] Train loss=0.2018238753080368
Test set avg_accuracy=80.76% avg_sensitivity=59.15%, avg_specificity=88.08% avg_auc=0.8352
Fold[5] Epoch: 97 [97/100 (97%)] Train loss=0.242030 Test loss=0.481872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25063079595565796
[5/23] Train loss=0.23636986315250397
[10/23] Train loss=0.22405730187892914
[15/23] Train loss=0.2283511459827423
[20/23] Train loss=0.20293450355529785
Test set avg_accuracy=80.04% avg_sensitivity=61.47%, avg_specificity=86.33% avg_auc=0.8345
Fold[5] Epoch: 98 [98/100 (98%)] Train loss=0.240734 Test loss=0.496950 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23154695332050323
[5/23] Train loss=0.23953020572662354
[10/23] Train loss=0.22630348801612854
[15/23] Train loss=0.22886259853839874
[20/23] Train loss=0.19646376371383667
Test set avg_accuracy=80.94% avg_sensitivity=57.78%, avg_specificity=88.78% avg_auc=0.8349
Fold[5] Epoch: 99 [99/100 (99%)] Train loss=0.237945 Test loss=0.483564 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22786377370357513
[5/23] Train loss=0.22932069003582
[10/23] Train loss=0.22468894720077515
[15/23] Train loss=0.22647303342819214
[20/23] Train loss=0.19869552552700043
Test set avg_accuracy=80.89% avg_sensitivity=56.58%, avg_specificity=89.12% avg_auc=0.8383
Fold[5] Epoch: 100 [100/100 (100%)] Train loss=0.236342 Test loss=0.484005 Current lr=[3.9999999999999996e-05]

Fold[5] Best Result: acc=79.47671376242805 sen=66.47350993377484, spe=83.87729373861885, auc=0.8446506643388754!
[0/23] Train loss=0.7035056352615356
[5/23] Train loss=0.6944675445556641
[10/23] Train loss=0.5634906888008118
[15/23] Train loss=0.5726096630096436
[20/23] Train loss=0.5419955849647522
Test set avg_accuracy=76.88% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5386
Best model saved!! Metric=-95.25764887579248!!
Fold[6] Epoch: 1 [1/100 (1%)] Train loss=0.590697 Test loss=0.585558 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5692098140716553
[5/23] Train loss=0.6289623975753784
[10/23] Train loss=0.5207058191299438
[15/23] Train loss=0.5477457046508789
[20/23] Train loss=0.521723210811615
Test set avg_accuracy=76.79% avg_sensitivity=0.91%, avg_specificity=99.62% avg_auc=0.5732
Best model saved!! Metric=-91.36172270608182!!
Fold[6] Epoch: 2 [2/100 (2%)] Train loss=0.561860 Test loss=0.554035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.550751268863678
[5/23] Train loss=0.5768684148788452
[10/23] Train loss=0.499588280916214
[15/23] Train loss=0.5166502594947815
[20/23] Train loss=0.48480546474456787
Test set avg_accuracy=75.85% avg_sensitivity=6.43%, avg_specificity=96.73% avg_auc=0.6547
Best model saved!! Metric=-81.50929208273523!!
Fold[6] Epoch: 3 [3/100 (3%)] Train loss=0.534082 Test loss=0.565606 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5294116735458374
[5/23] Train loss=0.5229474306106567
[10/23] Train loss=0.4815620183944702
[15/23] Train loss=0.4954572319984436
[20/23] Train loss=0.4463144540786743
Test set avg_accuracy=76.79% avg_sensitivity=15.47%, avg_specificity=95.24% avg_auc=0.7145
Best model saved!! Metric=-67.05569106823299!!
Fold[6] Epoch: 4 [4/100 (4%)] Train loss=0.507123 Test loss=0.561637 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4999711811542511
[5/23] Train loss=0.4876227080821991
[10/23] Train loss=0.4855354428291321
[15/23] Train loss=0.46675994992256165
[20/23] Train loss=0.41678816080093384
Test set avg_accuracy=78.03% avg_sensitivity=24.64%, avg_specificity=94.09% avg_auc=0.7536
Best model saved!! Metric=-53.894655033024996!!
Fold[6] Epoch: 5 [5/100 (5%)] Train loss=0.482772 Test loss=0.540669 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.46665406227111816
[5/23] Train loss=0.46939119696617126
[10/23] Train loss=0.47046735882759094
[15/23] Train loss=0.4725622534751892
[20/23] Train loss=0.40084123611450195
Test set avg_accuracy=79.16% avg_sensitivity=33.53%, avg_specificity=92.88% avg_auc=0.7759
Best model saved!! Metric=-42.844901180376084!!
Fold[6] Epoch: 6 [6/100 (6%)] Train loss=0.462580 Test loss=0.500771 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44004425406455994
[5/23] Train loss=0.46176624298095703
[10/23] Train loss=0.4787522256374359
[15/23] Train loss=0.43617740273475647
[20/23] Train loss=0.3856356143951416
Test set avg_accuracy=79.65% avg_sensitivity=35.77%, avg_specificity=92.85% avg_auc=0.7767
Best model saved!! Metric=-40.065238024978925!!
Fold[6] Epoch: 7 [7/100 (7%)] Train loss=0.447602 Test loss=0.525822 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43493369221687317
[5/23] Train loss=0.4501452147960663
[10/23] Train loss=0.47949910163879395
[15/23] Train loss=0.41844502091407776
[20/23] Train loss=0.3741132318973541
Test set avg_accuracy=80.12% avg_sensitivity=38.18%, avg_specificity=92.73% avg_auc=0.7910
Best model saved!! Metric=-35.87414858626107!!
Fold[6] Epoch: 8 [8/100 (8%)] Train loss=0.441001 Test loss=0.512591 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4218275845050812
[5/23] Train loss=0.44735726714134216
[10/23] Train loss=0.4838548004627228
[15/23] Train loss=0.4281472861766815
[20/23] Train loss=0.3723805248737335
Test set avg_accuracy=80.40% avg_sensitivity=39.51%, avg_specificity=92.70% avg_auc=0.7997
Best model saved!! Metric=-33.418411548527985!!
Fold[6] Epoch: 9 [9/100 (9%)] Train loss=0.437184 Test loss=0.501791 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41038596630096436
[5/23] Train loss=0.4406823217868805
[10/23] Train loss=0.4711291790008545
[15/23] Train loss=0.4088365435600281
[20/23] Train loss=0.3725402355194092
Test set avg_accuracy=80.56% avg_sensitivity=39.96%, avg_specificity=92.77% avg_auc=0.7981
Best model saved!! Metric=-32.89773658207597!!
Fold[6] Epoch: 10 [10/100 (10%)] Train loss=0.430637 Test loss=0.501413 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4054246246814728
[5/23] Train loss=0.43734651803970337
[10/23] Train loss=0.4769706428050995
[15/23] Train loss=0.4003806710243225
[20/23] Train loss=0.36309733986854553
Test set avg_accuracy=80.83% avg_sensitivity=40.51%, avg_specificity=92.96% avg_auc=0.8012
Best model saved!! Metric=-31.575419280702747!!
Fold[6] Epoch: 11 [11/100 (11%)] Train loss=0.428840 Test loss=0.501749 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4048141837120056
[5/23] Train loss=0.4260225296020508
[10/23] Train loss=0.48317378759384155
[15/23] Train loss=0.40023964643478394
[20/23] Train loss=0.3604797422885895
Test set avg_accuracy=80.90% avg_sensitivity=39.51%, avg_specificity=93.35% avg_auc=0.8034
Fold[6] Epoch: 12 [12/100 (12%)] Train loss=0.428182 Test loss=0.510063 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4100577235221863
[5/23] Train loss=0.4308336079120636
[10/23] Train loss=0.473238080739975
[15/23] Train loss=0.3907839059829712
[20/23] Train loss=0.36573389172554016
Test set avg_accuracy=81.07% avg_sensitivity=45.35%, avg_specificity=91.81% avg_auc=0.8155
Best model saved!! Metric=-26.229681262891027!!
Fold[6] Epoch: 13 [13/100 (13%)] Train loss=0.424309 Test loss=0.457083 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4064978063106537
[5/23] Train loss=0.4244888126850128
[10/23] Train loss=0.4576106369495392
[15/23] Train loss=0.39107856154441833
[20/23] Train loss=0.3577742576599121
Test set avg_accuracy=81.11% avg_sensitivity=47.90%, avg_specificity=91.09% avg_auc=0.8171
Best model saved!! Metric=-24.18275436260929!!
Fold[6] Epoch: 14 [14/100 (14%)] Train loss=0.417002 Test loss=0.451477 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4043462872505188
[5/23] Train loss=0.41321006417274475
[10/23] Train loss=0.46689334511756897
[15/23] Train loss=0.3860849440097809
[20/23] Train loss=0.36056041717529297
Test set avg_accuracy=81.16% avg_sensitivity=46.90%, avg_specificity=91.47% avg_auc=0.8140
Fold[6] Epoch: 15 [15/100 (15%)] Train loss=0.414338 Test loss=0.467135 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4001956582069397
[5/23] Train loss=0.4155866801738739
[10/23] Train loss=0.4596606492996216
[15/23] Train loss=0.3845716714859009
[20/23] Train loss=0.3510366976261139
Test set avg_accuracy=81.35% avg_sensitivity=45.44%, avg_specificity=92.15% avg_auc=0.8172
Fold[6] Epoch: 16 [16/100 (16%)] Train loss=0.415465 Test loss=0.470221 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40626558661460876
[5/23] Train loss=0.4101056754589081
[10/23] Train loss=0.46074292063713074
[15/23] Train loss=0.37590351700782776
[20/23] Train loss=0.35669928789138794
Test set avg_accuracy=81.50% avg_sensitivity=48.40%, avg_specificity=91.45% avg_auc=0.8338
Best model saved!! Metric=-21.26970762583165!!
Fold[6] Epoch: 17 [17/100 (17%)] Train loss=0.410569 Test loss=0.434680 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39352908730506897
[5/23] Train loss=0.4054611623287201
[10/23] Train loss=0.4564368724822998
[15/23] Train loss=0.3675057291984558
[20/23] Train loss=0.3492705225944519
Test set avg_accuracy=81.55% avg_sensitivity=49.45%, avg_specificity=91.20% avg_auc=0.8384
Best model saved!! Metric=-19.94942042095274!!
Fold[6] Epoch: 18 [18/100 (18%)] Train loss=0.404726 Test loss=0.431525 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.386825829744339
[5/23] Train loss=0.40526238083839417
[10/23] Train loss=0.46299001574516296
[15/23] Train loss=0.35656651854515076
[20/23] Train loss=0.35335102677345276
Test set avg_accuracy=81.65% avg_sensitivity=47.26%, avg_specificity=91.99% avg_auc=0.8387
Fold[6] Epoch: 19 [19/100 (19%)] Train loss=0.406044 Test loss=0.439993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.388581782579422
[5/23] Train loss=0.4035853147506714
[10/23] Train loss=0.46033385396003723
[15/23] Train loss=0.36808261275291443
[20/23] Train loss=0.3412477374076843
Test set avg_accuracy=81.68% avg_sensitivity=48.49%, avg_specificity=91.66% avg_auc=0.8411
Fold[6] Epoch: 20 [20/100 (20%)] Train loss=0.402698 Test loss=0.429577 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37934786081314087
[5/23] Train loss=0.40357649326324463
[10/23] Train loss=0.450453519821167
[15/23] Train loss=0.3564690947532654
[20/23] Train loss=0.34966781735420227
Test set avg_accuracy=81.65% avg_sensitivity=52.28%, avg_specificity=90.48% avg_auc=0.8472
Best model saved!! Metric=-16.87984399336627!!
Fold[6] Epoch: 21 [21/100 (21%)] Train loss=0.399865 Test loss=0.411894 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38026320934295654
[5/23] Train loss=0.3933717608451843
[10/23] Train loss=0.450324147939682
[15/23] Train loss=0.3521064519882202
[20/23] Train loss=0.3342052102088928
Test set avg_accuracy=81.61% avg_sensitivity=51.92%, avg_specificity=90.55% avg_auc=0.8474
Fold[6] Epoch: 22 [22/100 (22%)] Train loss=0.394788 Test loss=0.411586 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3770318031311035
[5/23] Train loss=0.3957652151584625
[10/23] Train loss=0.45084765553474426
[15/23] Train loss=0.3558611273765564
[20/23] Train loss=0.3372039794921875
Test set avg_accuracy=82.00% avg_sensitivity=51.82%, avg_specificity=91.08% avg_auc=0.8486
Best model saved!! Metric=-16.229822451350095!!
Fold[6] Epoch: 23 [23/100 (23%)] Train loss=0.393223 Test loss=0.409748 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3754272162914276
[5/23] Train loss=0.39599061012268066
[10/23] Train loss=0.4425218999385834
[15/23] Train loss=0.3544043302536011
[20/23] Train loss=0.3350423276424408
Test set avg_accuracy=81.90% avg_sensitivity=50.23%, avg_specificity=91.42% avg_auc=0.8484
Fold[6] Epoch: 24 [24/100 (24%)] Train loss=0.393132 Test loss=0.411302 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.376130074262619
[5/23] Train loss=0.38648486137390137
[10/23] Train loss=0.44837623834609985
[15/23] Train loss=0.34820640087127686
[20/23] Train loss=0.33444851636886597
Test set avg_accuracy=81.90% avg_sensitivity=53.83%, avg_specificity=90.34% avg_auc=0.8517
Best model saved!! Metric=-14.760889281404925!!
Fold[6] Epoch: 25 [25/100 (25%)] Train loss=0.390630 Test loss=0.405025 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37248536944389343
[5/23] Train loss=0.3859993517398834
[10/23] Train loss=0.4481659233570099
[15/23] Train loss=0.34793224930763245
[20/23] Train loss=0.32934895157814026
Test set avg_accuracy=82.00% avg_sensitivity=52.65%, avg_specificity=90.83% avg_auc=0.8544
Fold[6] Epoch: 26 [26/100 (26%)] Train loss=0.389480 Test loss=0.399770 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3703521192073822
[5/23] Train loss=0.3870788514614105
[10/23] Train loss=0.44887983798980713
[15/23] Train loss=0.3357265293598175
[20/23] Train loss=0.33158770203590393
Test set avg_accuracy=82.25% avg_sensitivity=56.39%, avg_specificity=90.02% avg_auc=0.8579
Best model saved!! Metric=-11.55210236694064!!
Fold[6] Epoch: 27 [27/100 (27%)] Train loss=0.387844 Test loss=0.393035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3673470914363861
[5/23] Train loss=0.3811851441860199
[10/23] Train loss=0.4433347284793854
[15/23] Train loss=0.33196011185646057
[20/23] Train loss=0.3259661793708801
Test set avg_accuracy=82.27% avg_sensitivity=56.98%, avg_specificity=89.87% avg_auc=0.8602
Best model saved!! Metric=-10.860538870328018!!
Fold[6] Epoch: 28 [28/100 (28%)] Train loss=0.383501 Test loss=0.389274 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36547794938087463
[5/23] Train loss=0.3808377683162689
[10/23] Train loss=0.4448610544204712
[15/23] Train loss=0.3356315791606903
[20/23] Train loss=0.3235967457294464
Test set avg_accuracy=82.54% avg_sensitivity=57.30%, avg_specificity=90.13% avg_auc=0.8633
Best model saved!! Metric=-9.698938465843572!!
Fold[6] Epoch: 29 [29/100 (29%)] Train loss=0.383143 Test loss=0.386286 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36917656660079956
[5/23] Train loss=0.3842277526855469
[10/23] Train loss=0.43751591444015503
[15/23] Train loss=0.3344329595565796
[20/23] Train loss=0.32103025913238525
Test set avg_accuracy=82.64% avg_sensitivity=53.28%, avg_specificity=91.47% avg_auc=0.8594
Fold[6] Epoch: 30 [30/100 (30%)] Train loss=0.383068 Test loss=0.394242 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3648434281349182
[5/23] Train loss=0.38048896193504333
[10/23] Train loss=0.4430685341358185
[15/23] Train loss=0.33797726035118103
[20/23] Train loss=0.3234143555164337
Test set avg_accuracy=82.43% avg_sensitivity=58.17%, avg_specificity=89.72% avg_auc=0.8635
Best model saved!! Metric=-9.331857542053365!!
Fold[6] Epoch: 31 [31/100 (31%)] Train loss=0.380136 Test loss=0.387094 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3628116548061371
[5/23] Train loss=0.3803339898586273
[10/23] Train loss=0.4360111951828003
[15/23] Train loss=0.3337041735649109
[20/23] Train loss=0.3207398056983948
Test set avg_accuracy=82.68% avg_sensitivity=58.39%, avg_specificity=89.98% avg_auc=0.8655
Best model saved!! Metric=-8.391876290114299!!
Fold[6] Epoch: 32 [32/100 (32%)] Train loss=0.375617 Test loss=0.381923 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.363471657037735
[5/23] Train loss=0.3746219277381897
[10/23] Train loss=0.4371725618839264
[15/23] Train loss=0.3271765410900116
[20/23] Train loss=0.3198221027851105
Test set avg_accuracy=82.87% avg_sensitivity=57.62%, avg_specificity=90.46% avg_auc=0.8654
Fold[6] Epoch: 33 [33/100 (33%)] Train loss=0.375263 Test loss=0.383896 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3641733229160309
[5/23] Train loss=0.3739720582962036
[10/23] Train loss=0.429393470287323
[15/23] Train loss=0.32363441586494446
[20/23] Train loss=0.31529292464256287
Test set avg_accuracy=82.93% avg_sensitivity=58.62%, avg_specificity=90.24% avg_auc=0.8674
Best model saved!! Metric=-7.461128043936123!!
Fold[6] Epoch: 34 [34/100 (34%)] Train loss=0.372809 Test loss=0.379321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35968977212905884
[5/23] Train loss=0.3723527193069458
[10/23] Train loss=0.42747247219085693
[15/23] Train loss=0.3224596679210663
[20/23] Train loss=0.31031039357185364
Test set avg_accuracy=82.80% avg_sensitivity=60.13%, avg_specificity=89.61% avg_auc=0.8665
Best model saved!! Metric=-6.813005789905852!!
Fold[6] Epoch: 35 [35/100 (35%)] Train loss=0.371849 Test loss=0.385156 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3557790517807007
[5/23] Train loss=0.3736250698566437
[10/23] Train loss=0.4230414927005768
[15/23] Train loss=0.3238746225833893
[20/23] Train loss=0.30665814876556396
Test set avg_accuracy=82.68% avg_sensitivity=61.91%, avg_specificity=88.93% avg_auc=0.8685
Best model saved!! Metric=-5.6357771230002704!!
Fold[6] Epoch: 36 [36/100 (36%)] Train loss=0.367350 Test loss=0.382050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3521464765071869
[5/23] Train loss=0.3615175485610962
[10/23] Train loss=0.4228307902812958
[15/23] Train loss=0.3144209086894989
[20/23] Train loss=0.3116123378276825
Test set avg_accuracy=82.88% avg_sensitivity=58.94%, avg_specificity=90.08% avg_auc=0.8686
Fold[6] Epoch: 37 [37/100 (37%)] Train loss=0.365490 Test loss=0.376620 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3519814908504486
[5/23] Train loss=0.3741145730018616
[10/23] Train loss=0.42363765835762024
[15/23] Train loss=0.3156725764274597
[20/23] Train loss=0.3052462935447693
Test set avg_accuracy=82.78% avg_sensitivity=60.90%, avg_specificity=89.37% avg_auc=0.8688
Fold[6] Epoch: 38 [38/100 (38%)] Train loss=0.363716 Test loss=0.378576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3465077877044678
[5/23] Train loss=0.36597877740859985
[10/23] Train loss=0.4164715111255646
[15/23] Train loss=0.31881776452064514
[20/23] Train loss=0.30542585253715515
Test set avg_accuracy=83.15% avg_sensitivity=57.89%, avg_specificity=90.75% avg_auc=0.8683
Fold[6] Epoch: 39 [39/100 (39%)] Train loss=0.364495 Test loss=0.380590 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3487371504306793
[5/23] Train loss=0.35664597153663635
[10/23] Train loss=0.4252139627933502
[15/23] Train loss=0.32153573632240295
[20/23] Train loss=0.3057307004928589
Test set avg_accuracy=82.90% avg_sensitivity=58.39%, avg_specificity=90.27% avg_auc=0.8689
Fold[6] Epoch: 40 [40/100 (40%)] Train loss=0.360210 Test loss=0.378472 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34366780519485474
[5/23] Train loss=0.3683772087097168
[10/23] Train loss=0.41726645827293396
[15/23] Train loss=0.3183586597442627
[20/23] Train loss=0.30539649724960327
Test set avg_accuracy=82.50% avg_sensitivity=63.00%, avg_specificity=88.36% avg_auc=0.8705
Best model saved!! Metric=-5.082251746696912!!
Fold[6] Epoch: 41 [41/100 (41%)] Train loss=0.360747 Test loss=0.375264 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34221920371055603
[5/23] Train loss=0.3669756352901459
[10/23] Train loss=0.4037166237831116
[15/23] Train loss=0.3133339285850525
[20/23] Train loss=0.30413997173309326
Test set avg_accuracy=82.71% avg_sensitivity=61.72%, avg_specificity=89.02% avg_auc=0.8701
Fold[6] Epoch: 42 [42/100 (42%)] Train loss=0.357362 Test loss=0.379742 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3381812572479248
[5/23] Train loss=0.35600775480270386
[10/23] Train loss=0.42051100730895996
[15/23] Train loss=0.3058692514896393
[20/23] Train loss=0.3048936128616333
Test set avg_accuracy=82.99% avg_sensitivity=60.58%, avg_specificity=89.72% avg_auc=0.8707
Fold[6] Epoch: 43 [43/100 (43%)] Train loss=0.353499 Test loss=0.378761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.341997355222702
[5/23] Train loss=0.35778987407684326
[10/23] Train loss=0.399231493473053
[15/23] Train loss=0.3039405941963196
[20/23] Train loss=0.2986670136451721
Test set avg_accuracy=82.34% avg_sensitivity=64.42%, avg_specificity=87.73% avg_auc=0.8709
Best model saved!! Metric=-4.415721793753363!!
Fold[6] Epoch: 44 [44/100 (44%)] Train loss=0.352206 Test loss=0.379488 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33676332235336304
[5/23] Train loss=0.3528113067150116
[10/23] Train loss=0.4040723443031311
[15/23] Train loss=0.30057594180107117
[20/23] Train loss=0.3020218014717102
Test set avg_accuracy=82.71% avg_sensitivity=59.72%, avg_specificity=89.63% avg_auc=0.8697
Fold[6] Epoch: 45 [45/100 (45%)] Train loss=0.351116 Test loss=0.381259 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33492714166641235
[5/23] Train loss=0.34779152274131775
[10/23] Train loss=0.4015803337097168
[15/23] Train loss=0.3037348687648773
[20/23] Train loss=0.2990480959415436
Test set avg_accuracy=82.93% avg_sensitivity=63.50%, avg_specificity=88.78% avg_auc=0.8730
Best model saved!! Metric=-3.4842377252841006!!
Fold[6] Epoch: 46 [46/100 (46%)] Train loss=0.348438 Test loss=0.376194 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3369908928871155
[5/23] Train loss=0.35586267709732056
[10/23] Train loss=0.3953621983528137
[15/23] Train loss=0.3090699017047882
[20/23] Train loss=0.2879360020160675
Test set avg_accuracy=83.03% avg_sensitivity=60.81%, avg_specificity=89.71% avg_auc=0.8719
Fold[6] Epoch: 47 [47/100 (47%)] Train loss=0.348729 Test loss=0.378194 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3348245918750763
[5/23] Train loss=0.3508087694644928
[10/23] Train loss=0.4129229485988617
[15/23] Train loss=0.2981189489364624
[20/23] Train loss=0.28762558102607727
Test set avg_accuracy=83.18% avg_sensitivity=56.75%, avg_specificity=91.12% avg_auc=0.8707
Fold[6] Epoch: 48 [48/100 (48%)] Train loss=0.348406 Test loss=0.375507 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3348262310028076
[5/23] Train loss=0.3519892692565918
[10/23] Train loss=0.4015592038631439
[15/23] Train loss=0.3099806010723114
[20/23] Train loss=0.2927115261554718
Test set avg_accuracy=82.91% avg_sensitivity=56.89%, avg_specificity=90.74% avg_auc=0.8717
Fold[6] Epoch: 49 [49/100 (49%)] Train loss=0.346987 Test loss=0.373422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33296748995780945
[5/23] Train loss=0.34506624937057495
[10/23] Train loss=0.39267224073410034
[15/23] Train loss=0.30067476630210876
[20/23] Train loss=0.2863997220993042
Test set avg_accuracy=82.46% avg_sensitivity=59.03%, avg_specificity=89.50% avg_auc=0.8695
Fold[6] Epoch: 50 [50/100 (50%)] Train loss=0.344049 Test loss=0.376878 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3282358944416046
[5/23] Train loss=0.347062349319458
[10/23] Train loss=0.3897855877876282
[15/23] Train loss=0.2964564561843872
[20/23] Train loss=0.2922409772872925
Test set avg_accuracy=82.70% avg_sensitivity=60.81%, avg_specificity=89.28% avg_auc=0.8692
Fold[6] Epoch: 51 [51/100 (51%)] Train loss=0.340212 Test loss=0.381637 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32203251123428345
[5/23] Train loss=0.34470322728157043
[10/23] Train loss=0.3837531805038452
[15/23] Train loss=0.2809907793998718
[20/23] Train loss=0.292616605758667
Test set avg_accuracy=82.85% avg_sensitivity=59.35%, avg_specificity=89.91% avg_auc=0.8689
Fold[6] Epoch: 52 [52/100 (52%)] Train loss=0.336975 Test loss=0.384595 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32667040824890137
[5/23] Train loss=0.3440391421318054
[10/23] Train loss=0.387228786945343
[15/23] Train loss=0.2899503707885742
[20/23] Train loss=0.3036367893218994
Test set avg_accuracy=82.48% avg_sensitivity=62.86%, avg_specificity=88.38% avg_auc=0.8702
Fold[6] Epoch: 53 [53/100 (53%)] Train loss=0.336975 Test loss=0.384180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3214032053947449
[5/23] Train loss=0.33547714352607727
[10/23] Train loss=0.376827210187912
[15/23] Train loss=0.29840585589408875
[20/23] Train loss=0.3055734932422638
Test set avg_accuracy=82.69% avg_sensitivity=63.37%, avg_specificity=88.50% avg_auc=0.8686
Fold[6] Epoch: 54 [54/100 (54%)] Train loss=0.336665 Test loss=0.384376 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3175411522388458
[5/23] Train loss=0.33841127157211304
[10/23] Train loss=0.3688896894454956
[15/23] Train loss=0.2864600718021393
[20/23] Train loss=0.27822092175483704
Test set avg_accuracy=81.86% avg_sensitivity=68.61%, avg_specificity=85.84% avg_auc=0.8700
Best model saved!! Metric=-2.688168570775387!!
Fold[6] Epoch: 55 [55/100 (55%)] Train loss=0.334254 Test loss=0.391716 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32286491990089417
[5/23] Train loss=0.33513393998146057
[10/23] Train loss=0.3649481534957886
[15/23] Train loss=0.2796971797943115
[20/23] Train loss=0.28045472502708435
Test set avg_accuracy=82.10% avg_sensitivity=63.82%, avg_specificity=87.60% avg_auc=0.8677
Fold[6] Epoch: 56 [56/100 (56%)] Train loss=0.331140 Test loss=0.391152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32266777753829956
[5/23] Train loss=0.32534560561180115
[10/23] Train loss=0.37241074442863464
[15/23] Train loss=0.2923196852207184
[20/23] Train loss=0.28221723437309265
Test set avg_accuracy=82.14% avg_sensitivity=61.82%, avg_specificity=88.25% avg_auc=0.8678
Fold[6] Epoch: 57 [57/100 (57%)] Train loss=0.329849 Test loss=0.384546 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3201168179512024
[5/23] Train loss=0.33086153864860535
[10/23] Train loss=0.37418869137763977
[15/23] Train loss=0.2823740243911743
[20/23] Train loss=0.2750827968120575
Test set avg_accuracy=82.06% avg_sensitivity=63.78%, avg_specificity=87.55% avg_auc=0.8662
Fold[6] Epoch: 58 [58/100 (58%)] Train loss=0.327296 Test loss=0.389058 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3099585175514221
[5/23] Train loss=0.32301828265190125
[10/23] Train loss=0.36542943120002747
[15/23] Train loss=0.28502461314201355
[20/23] Train loss=0.28055962920188904
Test set avg_accuracy=82.32% avg_sensitivity=63.46%, avg_specificity=87.99% avg_auc=0.8702
Fold[6] Epoch: 59 [59/100 (59%)] Train loss=0.323548 Test loss=0.386318 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31543055176734924
[5/23] Train loss=0.3256467878818512
[10/23] Train loss=0.36438924074172974
[15/23] Train loss=0.27967870235443115
[20/23] Train loss=0.2674767076969147
Test set avg_accuracy=82.86% avg_sensitivity=60.08%, avg_specificity=89.71% avg_auc=0.8687
Fold[6] Epoch: 60 [60/100 (60%)] Train loss=0.321650 Test loss=0.387289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3059352934360504
[5/23] Train loss=0.32544490694999695
[10/23] Train loss=0.3715254068374634
[15/23] Train loss=0.2628084123134613
[20/23] Train loss=0.29289716482162476
Test set avg_accuracy=82.76% avg_sensitivity=52.42%, avg_specificity=91.89% avg_auc=0.8669
Fold[6] Epoch: 61 [61/100 (61%)] Train loss=0.325344 Test loss=0.382661 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31913262605667114
[5/23] Train loss=0.3216651976108551
[10/23] Train loss=0.38190677762031555
[15/23] Train loss=0.27902859449386597
[20/23] Train loss=0.2739376127719879
Test set avg_accuracy=82.99% avg_sensitivity=52.10%, avg_specificity=92.27% avg_auc=0.8691
Fold[6] Epoch: 62 [62/100 (62%)] Train loss=0.324560 Test loss=0.379851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3101551830768585
[5/23] Train loss=0.3222305178642273
[10/23] Train loss=0.3703596591949463
[15/23] Train loss=0.27695533633232117
[20/23] Train loss=0.275762140750885
Test set avg_accuracy=82.75% avg_sensitivity=57.57%, avg_specificity=90.33% avg_auc=0.8675
Fold[6] Epoch: 63 [63/100 (63%)] Train loss=0.321749 Test loss=0.393310 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3055339753627777
[5/23] Train loss=0.3202904164791107
[10/23] Train loss=0.35523584485054016
[15/23] Train loss=0.2664978504180908
[20/23] Train loss=0.2742478549480438
Test set avg_accuracy=82.31% avg_sensitivity=62.41%, avg_specificity=88.30% avg_auc=0.8681
Fold[6] Epoch: 64 [64/100 (64%)] Train loss=0.315401 Test loss=0.393351 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29931411147117615
[5/23] Train loss=0.3082458972930908
[10/23] Train loss=0.35640621185302734
[15/23] Train loss=0.26559528708457947
[20/23] Train loss=0.2766934931278229
Test set avg_accuracy=82.20% avg_sensitivity=63.23%, avg_specificity=87.91% avg_auc=0.8655
Fold[6] Epoch: 65 [65/100 (65%)] Train loss=0.311492 Test loss=0.400968 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2961978316307068
[5/23] Train loss=0.30814671516418457
[10/23] Train loss=0.3662509024143219
[15/23] Train loss=0.27021023631095886
[20/23] Train loss=0.2669840455055237
Test set avg_accuracy=82.30% avg_sensitivity=59.40%, avg_specificity=89.19% avg_auc=0.8638
Fold[6] Epoch: 66 [66/100 (66%)] Train loss=0.312383 Test loss=0.391272 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2901654839515686
[5/23] Train loss=0.31306958198547363
[10/23] Train loss=0.34481513500213623
[15/23] Train loss=0.26073339581489563
[20/23] Train loss=0.2625748813152313
Test set avg_accuracy=82.09% avg_sensitivity=62.41%, avg_specificity=88.01% avg_auc=0.8643
Fold[6] Epoch: 67 [67/100 (67%)] Train loss=0.308123 Test loss=0.394440 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29658961296081543
[5/23] Train loss=0.30644160509109497
[10/23] Train loss=0.3464002013206482
[15/23] Train loss=0.26866331696510315
[20/23] Train loss=0.2623586356639862
Test set avg_accuracy=81.66% avg_sensitivity=60.08%, avg_specificity=88.14% avg_auc=0.8598
Fold[6] Epoch: 68 [68/100 (68%)] Train loss=0.303584 Test loss=0.403125 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2895674407482147
[5/23] Train loss=0.3086010217666626
[10/23] Train loss=0.33598703145980835
[15/23] Train loss=0.26212725043296814
[20/23] Train loss=0.2709519863128662
Test set avg_accuracy=82.33% avg_sensitivity=60.72%, avg_specificity=88.83% avg_auc=0.8634
Fold[6] Epoch: 69 [69/100 (69%)] Train loss=0.303914 Test loss=0.399690 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2851591110229492
[5/23] Train loss=0.3042201101779938
[10/23] Train loss=0.34009528160095215
[15/23] Train loss=0.25931409001350403
[20/23] Train loss=0.25412657856941223
Test set avg_accuracy=82.33% avg_sensitivity=60.63%, avg_specificity=88.86% avg_auc=0.8647
Fold[6] Epoch: 70 [70/100 (70%)] Train loss=0.302514 Test loss=0.392990 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28568872809410095
[5/23] Train loss=0.3037929832935333
[10/23] Train loss=0.33228564262390137
[15/23] Train loss=0.25419461727142334
[20/23] Train loss=0.25059306621551514
Test set avg_accuracy=81.93% avg_sensitivity=61.68%, avg_specificity=88.02% avg_auc=0.8651
Fold[6] Epoch: 71 [71/100 (71%)] Train loss=0.298370 Test loss=0.397208 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27824968099594116
[5/23] Train loss=0.30400019884109497
[10/23] Train loss=0.3350642919540405
[15/23] Train loss=0.2680374085903168
[20/23] Train loss=0.26144564151763916
Test set avg_accuracy=82.01% avg_sensitivity=60.63%, avg_specificity=88.45% avg_auc=0.8664
Fold[6] Epoch: 72 [72/100 (72%)] Train loss=0.298005 Test loss=0.396134 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2787947356700897
[5/23] Train loss=0.3037339746952057
[10/23] Train loss=0.3337242305278778
[15/23] Train loss=0.25463804602622986
[20/23] Train loss=0.2519341707229614
Test set avg_accuracy=83.00% avg_sensitivity=55.89%, avg_specificity=91.15% avg_auc=0.8661
Fold[6] Epoch: 73 [73/100 (73%)] Train loss=0.297449 Test loss=0.395431 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2787681221961975
[5/23] Train loss=0.29658809304237366
[10/23] Train loss=0.3449605703353882
[15/23] Train loss=0.24252480268478394
[20/23] Train loss=0.2517412304878235
Test set avg_accuracy=83.21% avg_sensitivity=54.52%, avg_specificity=91.84% avg_auc=0.8661
Fold[6] Epoch: 74 [74/100 (74%)] Train loss=0.295730 Test loss=0.396278 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2885204553604126
[5/23] Train loss=0.2961951196193695
[10/23] Train loss=0.3368431329727173
[15/23] Train loss=0.2423737645149231
[20/23] Train loss=0.25321120023727417
Test set avg_accuracy=82.66% avg_sensitivity=50.32%, avg_specificity=92.38% avg_auc=0.8641
Fold[6] Epoch: 75 [75/100 (75%)] Train loss=0.295620 Test loss=0.399776 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2946076989173889
[5/23] Train loss=0.29459044337272644
[10/23] Train loss=0.3446123003959656
[15/23] Train loss=0.25872281193733215
[20/23] Train loss=0.26934096217155457
Test set avg_accuracy=82.50% avg_sensitivity=52.05%, avg_specificity=91.66% avg_auc=0.8606
Fold[6] Epoch: 76 [76/100 (76%)] Train loss=0.301486 Test loss=0.401993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2755383551120758
[5/23] Train loss=0.29738351702690125
[10/23] Train loss=0.3287942111492157
[15/23] Train loss=0.26651379466056824
[20/23] Train loss=0.26056161522865295
Test set avg_accuracy=82.36% avg_sensitivity=59.35%, avg_specificity=89.28% avg_auc=0.8622
Fold[6] Epoch: 77 [77/100 (77%)] Train loss=0.294779 Test loss=0.397562 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27837494015693665
[5/23] Train loss=0.29000839591026306
[10/23] Train loss=0.31789276003837585
[15/23] Train loss=0.24517081677913666
[20/23] Train loss=0.25528812408447266
Test set avg_accuracy=81.42% avg_sensitivity=63.32%, avg_specificity=86.87% avg_auc=0.8609
Fold[6] Epoch: 78 [78/100 (78%)] Train loss=0.289939 Test loss=0.409096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28237003087997437
[5/23] Train loss=0.28875455260276794
[10/23] Train loss=0.31532612442970276
[15/23] Train loss=0.2463463395833969
[20/23] Train loss=0.24073457717895508
Test set avg_accuracy=81.33% avg_sensitivity=63.87%, avg_specificity=86.58% avg_auc=0.8568
Fold[6] Epoch: 79 [79/100 (79%)] Train loss=0.286633 Test loss=0.418881 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2736075520515442
[5/23] Train loss=0.28003889322280884
[10/23] Train loss=0.30895501375198364
[15/23] Train loss=0.24729014933109283
[20/23] Train loss=0.24740178883075714
Test set avg_accuracy=81.40% avg_sensitivity=61.13%, avg_specificity=87.50% avg_auc=0.8588
Fold[6] Epoch: 80 [80/100 (80%)] Train loss=0.281312 Test loss=0.410595 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2823738753795624
[5/23] Train loss=0.28764763474464417
[10/23] Train loss=0.31224969029426575
[15/23] Train loss=0.24253059923648834
[20/23] Train loss=0.24341849982738495
Test set avg_accuracy=81.58% avg_sensitivity=57.30%, avg_specificity=88.89% avg_auc=0.8550
Fold[6] Epoch: 81 [81/100 (81%)] Train loss=0.279551 Test loss=0.413889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2545040547847748
[5/23] Train loss=0.27740585803985596
[10/23] Train loss=0.3066175580024719
[15/23] Train loss=0.24248406291007996
[20/23] Train loss=0.25083571672439575
Test set avg_accuracy=81.37% avg_sensitivity=56.71%, avg_specificity=88.79% avg_auc=0.8545
Fold[6] Epoch: 82 [82/100 (82%)] Train loss=0.277021 Test loss=0.416866 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2685074210166931
[5/23] Train loss=0.27080005407333374
[10/23] Train loss=0.3080965280532837
[15/23] Train loss=0.24094466865062714
[20/23] Train loss=0.2516069710254669
Test set avg_accuracy=82.00% avg_sensitivity=60.26%, avg_specificity=88.54% avg_auc=0.8607
Fold[6] Epoch: 83 [83/100 (83%)] Train loss=0.278684 Test loss=0.414627 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25286179780960083
[5/23] Train loss=0.2764321565628052
[10/23] Train loss=0.29681023955345154
[15/23] Train loss=0.24629703164100647
[20/23] Train loss=0.24221275746822357
Test set avg_accuracy=81.93% avg_sensitivity=58.80%, avg_specificity=88.89% avg_auc=0.8555
Fold[6] Epoch: 84 [84/100 (84%)] Train loss=0.274507 Test loss=0.416038 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24607254564762115
[5/23] Train loss=0.26884496212005615
[10/23] Train loss=0.3048155903816223
[15/23] Train loss=0.2474869042634964
[20/23] Train loss=0.23255878686904907
Test set avg_accuracy=81.17% avg_sensitivity=58.67%, avg_specificity=87.94% avg_auc=0.8522
Fold[6] Epoch: 85 [85/100 (85%)] Train loss=0.270139 Test loss=0.420750 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25750303268432617
[5/23] Train loss=0.27294787764549255
[10/23] Train loss=0.29795801639556885
[15/23] Train loss=0.2307325005531311
[20/23] Train loss=0.23621612787246704
Test set avg_accuracy=81.31% avg_sensitivity=58.44%, avg_specificity=88.19% avg_auc=0.8524
Fold[6] Epoch: 86 [86/100 (86%)] Train loss=0.266122 Test loss=0.427128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25995954871177673
[5/23] Train loss=0.2713044285774231
[10/23] Train loss=0.28729841113090515
[15/23] Train loss=0.2314314842224121
[20/23] Train loss=0.23477502167224884
Test set avg_accuracy=81.35% avg_sensitivity=61.68%, avg_specificity=87.27% avg_auc=0.8541
Fold[6] Epoch: 87 [87/100 (87%)] Train loss=0.269702 Test loss=0.433833 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25519460439682007
[5/23] Train loss=0.2655395269393921
[10/23] Train loss=0.2853744626045227
[15/23] Train loss=0.23840056359767914
[20/23] Train loss=0.23463183641433716
Test set avg_accuracy=80.94% avg_sensitivity=60.49%, avg_specificity=87.09% avg_auc=0.8518
Fold[6] Epoch: 88 [88/100 (88%)] Train loss=0.265291 Test loss=0.434175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24382884800434113
[5/23] Train loss=0.262094646692276
[10/23] Train loss=0.27381861209869385
[15/23] Train loss=0.22435304522514343
[20/23] Train loss=0.2337123155593872
Test set avg_accuracy=80.89% avg_sensitivity=60.49%, avg_specificity=87.02% avg_auc=0.8493
Fold[6] Epoch: 89 [89/100 (89%)] Train loss=0.259604 Test loss=0.434892 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2528129518032074
[5/23] Train loss=0.2593609690666199
[10/23] Train loss=0.2779349982738495
[15/23] Train loss=0.2267485111951828
[20/23] Train loss=0.22686533629894257
Test set avg_accuracy=81.22% avg_sensitivity=58.49%, avg_specificity=88.06% avg_auc=0.8493
Fold[6] Epoch: 90 [90/100 (90%)] Train loss=0.258927 Test loss=0.430216 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2452734112739563
[5/23] Train loss=0.26064640283584595
[10/23] Train loss=0.2808922529220581
[15/23] Train loss=0.2242794632911682
[20/23] Train loss=0.2315705567598343
Test set avg_accuracy=81.36% avg_sensitivity=57.76%, avg_specificity=88.46% avg_auc=0.8544
Fold[6] Epoch: 91 [91/100 (91%)] Train loss=0.256337 Test loss=0.431640 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23437485098838806
[5/23] Train loss=0.25112974643707275
[10/23] Train loss=0.27763044834136963
[15/23] Train loss=0.2173829823732376
[20/23] Train loss=0.22366487979888916
Test set avg_accuracy=81.96% avg_sensitivity=57.25%, avg_specificity=89.39% avg_auc=0.8542
Fold[6] Epoch: 92 [92/100 (92%)] Train loss=0.255973 Test loss=0.426866 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2366410344839096
[5/23] Train loss=0.2501860558986664
[10/23] Train loss=0.27903056144714355
[15/23] Train loss=0.21426311135292053
[20/23] Train loss=0.2221200317144394
Test set avg_accuracy=80.77% avg_sensitivity=55.29%, avg_specificity=88.43% avg_auc=0.8428
Fold[6] Epoch: 93 [93/100 (93%)] Train loss=0.251982 Test loss=0.439198 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2451195865869522
[5/23] Train loss=0.25866425037384033
[10/23] Train loss=0.26782462000846863
[15/23] Train loss=0.23638206720352173
[20/23] Train loss=0.23287536203861237
Test set avg_accuracy=82.51% avg_sensitivity=52.33%, avg_specificity=91.59% avg_auc=0.8581
Fold[6] Epoch: 94 [94/100 (94%)] Train loss=0.259991 Test loss=0.420062 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2610126733779907
[5/23] Train loss=0.24782468378543854
[10/23] Train loss=0.2819772958755493
[15/23] Train loss=0.23637408018112183
[20/23] Train loss=0.21273945271968842
Test set avg_accuracy=81.99% avg_sensitivity=57.94%, avg_specificity=89.23% avg_auc=0.8568
Fold[6] Epoch: 95 [95/100 (95%)] Train loss=0.254520 Test loss=0.426920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23485228419303894
[5/23] Train loss=0.2549450695514679
[10/23] Train loss=0.27468085289001465
[15/23] Train loss=0.21846215426921844
[20/23] Train loss=0.2232280820608139
Test set avg_accuracy=82.06% avg_sensitivity=54.56%, avg_specificity=90.33% avg_auc=0.8528
Fold[6] Epoch: 96 [96/100 (96%)] Train loss=0.252343 Test loss=0.433248 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23620660603046417
[5/23] Train loss=0.25095146894454956
[10/23] Train loss=0.2762606739997864
[15/23] Train loss=0.2518249452114105
[20/23] Train loss=0.21552686393260956
Test set avg_accuracy=82.57% avg_sensitivity=53.56%, avg_specificity=91.30% avg_auc=0.8548
Fold[6] Epoch: 97 [97/100 (97%)] Train loss=0.249780 Test loss=0.435065 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22704052925109863
[5/23] Train loss=0.24356527626514435
[10/23] Train loss=0.27195003628730774
[15/23] Train loss=0.23425492644309998
[20/23] Train loss=0.20838865637779236
Test set avg_accuracy=82.25% avg_sensitivity=55.66%, avg_specificity=90.24% avg_auc=0.8553
Fold[6] Epoch: 98 [98/100 (98%)] Train loss=0.245703 Test loss=0.437451 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22721853852272034
[5/23] Train loss=0.25355270504951477
[10/23] Train loss=0.26323357224464417
[15/23] Train loss=0.22607474029064178
[20/23] Train loss=0.22666192054748535
Test set avg_accuracy=81.88% avg_sensitivity=57.34%, avg_specificity=89.26% avg_auc=0.8571
Fold[6] Epoch: 99 [99/100 (99%)] Train loss=0.247075 Test loss=0.434289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2268131673336029
[5/23] Train loss=0.24641339480876923
[10/23] Train loss=0.2540368437767029
[15/23] Train loss=0.20548978447914124
[20/23] Train loss=0.22487206757068634
Test set avg_accuracy=81.93% avg_sensitivity=58.35%, avg_specificity=89.02% avg_auc=0.8552
Fold[6] Epoch: 100 [100/100 (100%)] Train loss=0.243060 Test loss=0.445088 Current lr=[3.9999999999999996e-05]

Fold[6] Best Result: acc=81.85654008438819 sen=68.61313868613139, spe=85.8397365532382, auc=0.8700241610546684!
[0/23] Train loss=0.718008816242218
[5/23] Train loss=0.6922145485877991
[10/23] Train loss=0.5746883749961853
[15/23] Train loss=0.5455317497253418
[20/23] Train loss=0.5393224358558655
Test set avg_accuracy=75.67% avg_sensitivity=0.47%, avg_specificity=99.96% avg_auc=0.5489
Best model saved!! Metric=-95.01194578446241!!
Fold[7] Epoch: 1 [1/100 (1%)] Train loss=0.588524 Test loss=0.615927 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5764606595039368
[5/23] Train loss=0.6274088621139526
[10/23] Train loss=0.529160737991333
[15/23] Train loss=0.5378912687301636
[20/23] Train loss=0.5270683765411377
Test set avg_accuracy=75.68% avg_sensitivity=0.64%, avg_specificity=99.92% avg_auc=0.5692
Best model saved!! Metric=-92.84918244271266!!
Fold[7] Epoch: 2 [2/100 (2%)] Train loss=0.562093 Test loss=0.584132 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5545667409896851
[5/23] Train loss=0.601359486579895
[10/23] Train loss=0.5056602954864502
[15/23] Train loss=0.5113323926925659
[20/23] Train loss=0.5055173635482788
Test set avg_accuracy=75.74% avg_sensitivity=5.59%, avg_specificity=98.40% avg_auc=0.6016
Best model saved!! Metric=-86.11048755068967!!
Fold[7] Epoch: 3 [3/100 (3%)] Train loss=0.544505 Test loss=0.569508 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.542560875415802
[5/23] Train loss=0.5533235669136047
[10/23] Train loss=0.48340487480163574
[15/23] Train loss=0.49382779002189636
[20/23] Train loss=0.4695875942707062
Test set avg_accuracy=75.94% avg_sensitivity=13.23%, avg_specificity=96.20% avg_auc=0.6637
Best model saved!! Metric=-74.26693326177511!!
Fold[7] Epoch: 4 [4/100 (4%)] Train loss=0.520866 Test loss=0.579809 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5216816067695618
[5/23] Train loss=0.502091109752655
[10/23] Train loss=0.4844631850719452
[15/23] Train loss=0.47465264797210693
[20/23] Train loss=0.4333450496196747
Test set avg_accuracy=77.04% avg_sensitivity=19.58%, avg_specificity=95.60% avg_auc=0.7209
Best model saved!! Metric=-61.6820566212984!!
Fold[7] Epoch: 5 [5/100 (5%)] Train loss=0.495514 Test loss=0.571329 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.49418777227401733
[5/23] Train loss=0.4839021861553192
[10/23] Train loss=0.4873115122318268
[15/23] Train loss=0.46460914611816406
[20/23] Train loss=0.414265513420105
Test set avg_accuracy=78.43% avg_sensitivity=26.07%, avg_specificity=95.34% avg_auc=0.7442
Best model saved!! Metric=-51.744123336632136!!
Fold[7] Epoch: 6 [6/100 (6%)] Train loss=0.474551 Test loss=0.562916 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4628983438014984
[5/23] Train loss=0.4721675217151642
[10/23] Train loss=0.4797055423259735
[15/23] Train loss=0.4502653479576111
[20/23] Train loss=0.39669132232666016
Test set avg_accuracy=79.51% avg_sensitivity=32.42%, avg_specificity=94.72% avg_auc=0.7605
Best model saved!! Metric=-43.29202657437477!!
Fold[7] Epoch: 7 [7/100 (7%)] Train loss=0.457023 Test loss=0.548897 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44826290011405945
[5/23] Train loss=0.4614470601081848
[10/23] Train loss=0.47676461935043335
[15/23] Train loss=0.4339301288127899
[20/23] Train loss=0.3888065814971924
Test set avg_accuracy=79.77% avg_sensitivity=33.83%, avg_specificity=94.61% avg_auc=0.7745
Best model saved!! Metric=-40.33530361441099!!
Fold[7] Epoch: 8 [8/100 (8%)] Train loss=0.446155 Test loss=0.545061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43285784125328064
[5/23] Train loss=0.45213520526885986
[10/23] Train loss=0.46667400002479553
[15/23] Train loss=0.4218291938304901
[20/23] Train loss=0.3876210153102875
Test set avg_accuracy=79.71% avg_sensitivity=34.68%, avg_specificity=94.25% avg_auc=0.7831
Best model saved!! Metric=-39.04804975647631!!
Fold[7] Epoch: 9 [9/100 (9%)] Train loss=0.437891 Test loss=0.548116 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.43548259139060974
[5/23] Train loss=0.44579511880874634
[10/23] Train loss=0.47099030017852783
[15/23] Train loss=0.41287147998809814
[20/23] Train loss=0.38117265701293945
Test set avg_accuracy=79.84% avg_sensitivity=35.58%, avg_specificity=94.14% avg_auc=0.7876
Best model saved!! Metric=-37.67531413334285!!
Fold[7] Epoch: 10 [10/100 (10%)] Train loss=0.436801 Test loss=0.541728 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41973021626472473
[5/23] Train loss=0.442211389541626
[10/23] Train loss=0.47599583864212036
[15/23] Train loss=0.4113607108592987
[20/23] Train loss=0.376272588968277
Test set avg_accuracy=80.03% avg_sensitivity=35.28%, avg_specificity=94.49% avg_auc=0.7862
Best model saved!! Metric=-37.57515799564254!!
Fold[7] Epoch: 11 [11/100 (11%)] Train loss=0.434377 Test loss=0.553646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4148802161216736
[5/23] Train loss=0.4337240159511566
[10/23] Train loss=0.47390806674957275
[15/23] Train loss=0.39969173073768616
[20/23] Train loss=0.37445658445358276
Test set avg_accuracy=80.01% avg_sensitivity=35.11%, avg_specificity=94.51% avg_auc=0.7900
Best model saved!! Metric=-37.36159075287271!!
Fold[7] Epoch: 12 [12/100 (12%)] Train loss=0.431028 Test loss=0.554790 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42018237709999084
[5/23] Train loss=0.43027815222740173
[10/23] Train loss=0.47462305426597595
[15/23] Train loss=0.4032093286514282
[20/23] Train loss=0.3693772256374359
Test set avg_accuracy=80.33% avg_sensitivity=36.77%, avg_specificity=94.40% avg_auc=0.8054
Best model saved!! Metric=-33.948783902349696!!
Fold[7] Epoch: 13 [13/100 (13%)] Train loss=0.432472 Test loss=0.518224 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41676241159439087
[5/23] Train loss=0.42888444662094116
[10/23] Train loss=0.46007418632507324
[15/23] Train loss=0.38869157433509827
[20/23] Train loss=0.3750465512275696
Test set avg_accuracy=80.83% avg_sensitivity=41.60%, avg_specificity=93.51% avg_auc=0.8169
Best model saved!! Metric=-28.37285638937704!!
Fold[7] Epoch: 14 [14/100 (14%)] Train loss=0.424125 Test loss=0.476855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41451337933540344
[5/23] Train loss=0.42932552099227905
[10/23] Train loss=0.4547496438026428
[15/23] Train loss=0.38174498081207275
[20/23] Train loss=0.3683406114578247
Test set avg_accuracy=80.98% avg_sensitivity=43.22%, avg_specificity=93.18% avg_auc=0.8204
Best model saved!! Metric=-26.586495362827087!!
Fold[7] Epoch: 15 [15/100 (15%)] Train loss=0.417775 Test loss=0.475732 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4079662561416626
[5/23] Train loss=0.4121231138706207
[10/23] Train loss=0.46220001578330994
[15/23] Train loss=0.3752732574939728
[20/23] Train loss=0.3709058463573456
Test set avg_accuracy=81.19% avg_sensitivity=43.39%, avg_specificity=93.40% avg_auc=0.8225
Best model saved!! Metric=-25.776811987537208!!
Fold[7] Epoch: 16 [16/100 (16%)] Train loss=0.413645 Test loss=0.483358 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39956292510032654
[5/23] Train loss=0.4158584773540497
[10/23] Train loss=0.45381954312324524
[15/23] Train loss=0.3773314654827118
[20/23] Train loss=0.3515327572822571
Test set avg_accuracy=81.16% avg_sensitivity=42.88%, avg_specificity=93.52% avg_auc=0.8235
Fold[7] Epoch: 17 [17/100 (17%)] Train loss=0.412079 Test loss=0.479491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4065057933330536
[5/23] Train loss=0.4168247580528259
[10/23] Train loss=0.45937579870224
[15/23] Train loss=0.3747846186161041
[20/23] Train loss=0.34903255105018616
Test set avg_accuracy=81.28% avg_sensitivity=45.14%, avg_specificity=92.96% avg_auc=0.8289
Best model saved!! Metric=-23.739225228691527!!
Fold[7] Epoch: 18 [18/100 (18%)] Train loss=0.409526 Test loss=0.467169 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.396687388420105
[5/23] Train loss=0.4108259081840515
[10/23] Train loss=0.4501604735851288
[15/23] Train loss=0.36799705028533936
[20/23] Train loss=0.3602356016635895
Test set avg_accuracy=81.38% avg_sensitivity=45.31%, avg_specificity=93.03% avg_auc=0.8296
Best model saved!! Metric=-23.327349661901575!!
Fold[7] Epoch: 19 [19/100 (19%)] Train loss=0.407038 Test loss=0.472325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3966961205005646
[5/23] Train loss=0.4148198366165161
[10/23] Train loss=0.4511505365371704
[15/23] Train loss=0.3573892414569855
[20/23] Train loss=0.35043829679489136
Test set avg_accuracy=81.68% avg_sensitivity=46.08%, avg_specificity=93.18% avg_auc=0.8326
Best model saved!! Metric=-21.805621341343333!!
Fold[7] Epoch: 20 [20/100 (20%)] Train loss=0.404033 Test loss=0.471342 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3922278881072998
[5/23] Train loss=0.4014057517051697
[10/23] Train loss=0.44980567693710327
[15/23] Train loss=0.3619881570339203
[20/23] Train loss=0.34491562843322754
Test set avg_accuracy=81.62% avg_sensitivity=45.44%, avg_specificity=93.32% avg_auc=0.8349
Fold[7] Epoch: 21 [21/100 (21%)] Train loss=0.403766 Test loss=0.467730 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38782212138175964
[5/23] Train loss=0.40145888924598694
[10/23] Train loss=0.4564732611179352
[15/23] Train loss=0.3590729236602783
[20/23] Train loss=0.344475656747818
Test set avg_accuracy=81.62% avg_sensitivity=44.71%, avg_specificity=93.55% avg_auc=0.8374
Fold[7] Epoch: 22 [22/100 (22%)] Train loss=0.401477 Test loss=0.465512 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38735657930374146
[5/23] Train loss=0.4041195213794708
[10/23] Train loss=0.45027533173561096
[15/23] Train loss=0.3653090298175812
[20/23] Train loss=0.3404439687728882
Test set avg_accuracy=81.66% avg_sensitivity=46.03%, avg_specificity=93.16% avg_auc=0.8384
Best model saved!! Metric=-21.305728153421825!!
Fold[7] Epoch: 23 [23/100 (23%)] Train loss=0.399912 Test loss=0.454180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38674941658973694
[5/23] Train loss=0.3990379571914673
[10/23] Train loss=0.4429817795753479
[15/23] Train loss=0.35734307765960693
[20/23] Train loss=0.33931592106819153
Test set avg_accuracy=81.89% avg_sensitivity=51.07%, avg_specificity=91.84% avg_auc=0.8426
Best model saved!! Metric=-16.94841380339743!!
Fold[7] Epoch: 24 [24/100 (24%)] Train loss=0.394826 Test loss=0.438152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.385541707277298
[5/23] Train loss=0.39412206411361694
[10/23] Train loss=0.4342699944972992
[15/23] Train loss=0.3449576795101166
[20/23] Train loss=0.3360396921634674
Test set avg_accuracy=82.09% avg_sensitivity=50.21%, avg_specificity=92.39% avg_auc=0.8440
Best model saved!! Metric=-16.90031622646763!!
Fold[7] Epoch: 25 [25/100 (25%)] Train loss=0.390333 Test loss=0.441115 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38800951838493347
[5/23] Train loss=0.393669992685318
[10/23] Train loss=0.44139382243156433
[15/23] Train loss=0.347152441740036
[20/23] Train loss=0.3355943560600281
Test set avg_accuracy=81.97% avg_sensitivity=50.90%, avg_specificity=92.01% avg_auc=0.8452
Best model saved!! Metric=-16.60695291362967!!
Fold[7] Epoch: 26 [26/100 (26%)] Train loss=0.389953 Test loss=0.437548 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37494567036628723
[5/23] Train loss=0.39249947667121887
[10/23] Train loss=0.4383423924446106
[15/23] Train loss=0.3438599109649658
[20/23] Train loss=0.32998016476631165
Test set avg_accuracy=81.99% avg_sensitivity=49.57%, avg_specificity=92.46% avg_auc=0.8431
Fold[7] Epoch: 27 [27/100 (27%)] Train loss=0.386942 Test loss=0.444087 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3802262246608734
[5/23] Train loss=0.3923196792602539
[10/23] Train loss=0.4365994334220886
[15/23] Train loss=0.3463277220726013
[20/23] Train loss=0.3253893554210663
Test set avg_accuracy=82.17% avg_sensitivity=50.77%, avg_specificity=92.31% avg_auc=0.8460
Best model saved!! Metric=-16.159519311937377!!
Fold[7] Epoch: 28 [28/100 (28%)] Train loss=0.383418 Test loss=0.438450 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3761155307292938
[5/23] Train loss=0.3907676339149475
[10/23] Train loss=0.4283277690410614
[15/23] Train loss=0.3467746078968048
[20/23] Train loss=0.3254617154598236
Test set avg_accuracy=82.20% avg_sensitivity=51.88%, avg_specificity=91.99% avg_auc=0.8475
Best model saved!! Metric=-15.179437040374893!!
Fold[7] Epoch: 29 [29/100 (29%)] Train loss=0.384295 Test loss=0.435192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3720054626464844
[5/23] Train loss=0.3839733600616455
[10/23] Train loss=0.4355259835720062
[15/23] Train loss=0.3370594084262848
[20/23] Train loss=0.3217635154724121
Test set avg_accuracy=82.20% avg_sensitivity=51.45%, avg_specificity=92.13% avg_auc=0.8456
Fold[7] Epoch: 30 [30/100 (30%)] Train loss=0.380514 Test loss=0.442297 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3722487688064575
[5/23] Train loss=0.38378092646598816
[10/23] Train loss=0.4302483797073364
[15/23] Train loss=0.34112903475761414
[20/23] Train loss=0.31429189443588257
Test set avg_accuracy=82.25% avg_sensitivity=51.49%, avg_specificity=92.19% avg_auc=0.8486
Fold[7] Epoch: 31 [31/100 (31%)] Train loss=0.379497 Test loss=0.435448 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36550024151802063
[5/23] Train loss=0.3852926790714264
[10/23] Train loss=0.42626953125
[15/23] Train loss=0.3339337110519409
[20/23] Train loss=0.32578593492507935
Test set avg_accuracy=82.16% avg_sensitivity=53.84%, avg_specificity=91.30% avg_auc=0.8487
Best model saved!! Metric=-13.832774030013065!!
Fold[7] Epoch: 32 [32/100 (32%)] Train loss=0.377267 Test loss=0.431802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36757344007492065
[5/23] Train loss=0.3800587058067322
[10/23] Train loss=0.42497962713241577
[15/23] Train loss=0.3377258777618408
[20/23] Train loss=0.3144513666629791
Test set avg_accuracy=82.11% avg_sensitivity=52.56%, avg_specificity=91.66% avg_auc=0.8489
Fold[7] Epoch: 33 [33/100 (33%)] Train loss=0.375963 Test loss=0.430218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3628915846347809
[5/23] Train loss=0.3797209858894348
[10/23] Train loss=0.42053142189979553
[15/23] Train loss=0.3358771502971649
[20/23] Train loss=0.3210410475730896
Test set avg_accuracy=82.15% avg_sensitivity=52.99%, avg_specificity=91.57% avg_auc=0.8489
Fold[7] Epoch: 34 [34/100 (34%)] Train loss=0.373960 Test loss=0.429678 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.362258642911911
[5/23] Train loss=0.3790667653083801
[10/23] Train loss=0.4227919578552246
[15/23] Train loss=0.33934682607650757
[20/23] Train loss=0.31611964106559753
Test set avg_accuracy=82.45% avg_sensitivity=54.74%, avg_specificity=91.40% avg_auc=0.8523
Best model saved!! Metric=-12.18822263760688!!
Fold[7] Epoch: 35 [35/100 (35%)] Train loss=0.372922 Test loss=0.423020 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3660670220851898
[5/23] Train loss=0.38347312808036804
[10/23] Train loss=0.4226684868335724
[15/23] Train loss=0.3271341919898987
[20/23] Train loss=0.3199843168258667
Test set avg_accuracy=82.29% avg_sensitivity=54.74%, avg_specificity=91.19% avg_auc=0.8502
Fold[7] Epoch: 36 [36/100 (36%)] Train loss=0.372021 Test loss=0.426863 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.362934947013855
[5/23] Train loss=0.37027034163475037
[10/23] Train loss=0.422417014837265
[15/23] Train loss=0.320875346660614
[20/23] Train loss=0.3106168210506439
Test set avg_accuracy=82.42% avg_sensitivity=56.02%, avg_specificity=90.95% avg_auc=0.8543
Best model saved!! Metric=-11.193133014237633!!
Fold[7] Epoch: 37 [37/100 (37%)] Train loss=0.367060 Test loss=0.419558 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3650568127632141
[5/23] Train loss=0.37360742688179016
[10/23] Train loss=0.4187818467617035
[15/23] Train loss=0.3272251784801483
[20/23] Train loss=0.3141837418079376
Test set avg_accuracy=82.60% avg_sensitivity=55.42%, avg_specificity=91.39% avg_auc=0.8525
Fold[7] Epoch: 38 [38/100 (38%)] Train loss=0.367683 Test loss=0.426093 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36443039774894714
[5/23] Train loss=0.3714037835597992
[10/23] Train loss=0.41493362188339233
[15/23] Train loss=0.32309800386428833
[20/23] Train loss=0.3058246076107025
Test set avg_accuracy=82.73% avg_sensitivity=57.21%, avg_specificity=90.97% avg_auc=0.8531
Best model saved!! Metric=-9.780690069526226!!
Fold[7] Epoch: 39 [39/100 (39%)] Train loss=0.365061 Test loss=0.425493 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3520876169204712
[5/23] Train loss=0.37023821473121643
[10/23] Train loss=0.41281333565711975
[15/23] Train loss=0.32196366786956787
[20/23] Train loss=0.3056136965751648
Test set avg_accuracy=82.68% avg_sensitivity=57.38%, avg_specificity=90.85% avg_auc=0.8548
Best model saved!! Metric=-9.616473064384824!!
Fold[7] Epoch: 40 [40/100 (40%)] Train loss=0.362787 Test loss=0.419049 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34646809101104736
[5/23] Train loss=0.3682323098182678
[10/23] Train loss=0.41134026646614075
[15/23] Train loss=0.30592551827430725
[20/23] Train loss=0.3087978959083557
Test set avg_accuracy=82.81% avg_sensitivity=55.89%, avg_specificity=91.51% avg_auc=0.8545
Fold[7] Epoch: 41 [41/100 (41%)] Train loss=0.359455 Test loss=0.420265 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34914296865463257
[5/23] Train loss=0.3614039421081543
[10/23] Train loss=0.40690773725509644
[15/23] Train loss=0.3180737793445587
[20/23] Train loss=0.3046010732650757
Test set avg_accuracy=82.92% avg_sensitivity=56.02%, avg_specificity=91.61% avg_auc=0.8527
Fold[7] Epoch: 42 [42/100 (42%)] Train loss=0.360165 Test loss=0.425554 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34573766589164734
[5/23] Train loss=0.3658011555671692
[10/23] Train loss=0.40502384305000305
[15/23] Train loss=0.3139638304710388
[20/23] Train loss=0.30378273129463196
Test set avg_accuracy=82.75% avg_sensitivity=55.72%, avg_specificity=91.48% avg_auc=0.8542
Fold[7] Epoch: 43 [43/100 (43%)] Train loss=0.357535 Test loss=0.418236 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3500455915927887
[5/23] Train loss=0.3605729639530182
[10/23] Train loss=0.4006927013397217
[15/23] Train loss=0.3172907531261444
[20/23] Train loss=0.301380455493927
Test set avg_accuracy=82.96% avg_sensitivity=57.85%, avg_specificity=91.07% avg_auc=0.8555
Best model saved!! Metric=-8.576356564352844!!
Fold[7] Epoch: 44 [44/100 (44%)] Train loss=0.353390 Test loss=0.420365 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34217172861099243
[5/23] Train loss=0.3572683334350586
[10/23] Train loss=0.40709567070007324
[15/23] Train loss=0.3252253830432892
[20/23] Train loss=0.2969664931297302
Test set avg_accuracy=82.73% avg_sensitivity=57.89%, avg_specificity=90.75% avg_auc=0.8577
Fold[7] Epoch: 45 [45/100 (45%)] Train loss=0.354964 Test loss=0.413321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34075555205345154
[5/23] Train loss=0.3609265089035034
[10/23] Train loss=0.394914835691452
[15/23] Train loss=0.31232720613479614
[20/23] Train loss=0.3056851923465729
Test set avg_accuracy=82.65% avg_sensitivity=57.64%, avg_specificity=90.72% avg_auc=0.8577
Fold[7] Epoch: 46 [46/100 (46%)] Train loss=0.354159 Test loss=0.412243 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3323698937892914
[5/23] Train loss=0.3523569703102112
[10/23] Train loss=0.40087002515792847
[15/23] Train loss=0.308431476354599
[20/23] Train loss=0.3026755750179291
Test set avg_accuracy=82.84% avg_sensitivity=57.68%, avg_specificity=90.97% avg_auc=0.8581
Fold[7] Epoch: 47 [47/100 (47%)] Train loss=0.350831 Test loss=0.416639 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3392922282218933
[5/23] Train loss=0.3540440499782562
[10/23] Train loss=0.40348169207572937
[15/23] Train loss=0.3068208396434784
[20/23] Train loss=0.29136332869529724
Test set avg_accuracy=82.90% avg_sensitivity=57.51%, avg_specificity=91.10% avg_auc=0.8583
Fold[7] Epoch: 48 [48/100 (48%)] Train loss=0.350431 Test loss=0.410344 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33222079277038574
[5/23] Train loss=0.35527199506759644
[10/23] Train loss=0.4000946879386902
[15/23] Train loss=0.2993996739387512
[20/23] Train loss=0.2919962406158447
Test set avg_accuracy=82.96% avg_sensitivity=57.12%, avg_specificity=91.30% avg_auc=0.8585
Fold[7] Epoch: 49 [49/100 (49%)] Train loss=0.346556 Test loss=0.415086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34591275453567505
[5/23] Train loss=0.34547290205955505
[10/23] Train loss=0.3937538266181946
[15/23] Train loss=0.30240723490715027
[20/23] Train loss=0.2924808859825134
Test set avg_accuracy=82.93% avg_sensitivity=57.85%, avg_specificity=91.03% avg_auc=0.8595
Best model saved!! Metric=-8.245478340940704!!
Fold[7] Epoch: 50 [50/100 (50%)] Train loss=0.345351 Test loss=0.410339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33557838201522827
[5/23] Train loss=0.35652950406074524
[10/23] Train loss=0.3857032358646393
[15/23] Train loss=0.30400916934013367
[20/23] Train loss=0.2890235185623169
Test set avg_accuracy=82.89% avg_sensitivity=57.25%, avg_specificity=91.17% avg_auc=0.8576
Fold[7] Epoch: 51 [51/100 (51%)] Train loss=0.344826 Test loss=0.415407 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3240916430950165
[5/23] Train loss=0.34624770283699036
[10/23] Train loss=0.3902752101421356
[15/23] Train loss=0.2954843044281006
[20/23] Train loss=0.29050084948539734
Test set avg_accuracy=82.58% avg_sensitivity=59.90%, avg_specificity=89.91% avg_auc=0.8580
Best model saved!! Metric=-7.809512907132368!!
Fold[7] Epoch: 52 [52/100 (52%)] Train loss=0.339772 Test loss=0.411536 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32595309615135193
[5/23] Train loss=0.3427530527114868
[10/23] Train loss=0.38665130734443665
[15/23] Train loss=0.28454574942588806
[20/23] Train loss=0.29477164149284363
Test set avg_accuracy=82.45% avg_sensitivity=60.03%, avg_specificity=89.69% avg_auc=0.8600
Fold[7] Epoch: 53 [53/100 (53%)] Train loss=0.337577 Test loss=0.410289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32087740302085876
[5/23] Train loss=0.3374866247177124
[10/23] Train loss=0.38535264134407043
[15/23] Train loss=0.2912300229072571
[20/23] Train loss=0.28403031826019287
Test set avg_accuracy=82.59% avg_sensitivity=59.94%, avg_specificity=89.91% avg_auc=0.8591
Best model saved!! Metric=-7.642729237143039!!
Fold[7] Epoch: 54 [54/100 (54%)] Train loss=0.336327 Test loss=0.410552 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3273894190788269
[5/23] Train loss=0.33966079354286194
[10/23] Train loss=0.38073694705963135
[15/23] Train loss=0.2986307740211487
[20/23] Train loss=0.29492220282554626
Test set avg_accuracy=82.81% avg_sensitivity=59.94%, avg_specificity=90.20% avg_auc=0.8606
Best model saved!! Metric=-6.988982637882847!!
Fold[7] Epoch: 55 [55/100 (55%)] Train loss=0.335005 Test loss=0.403755 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.324232816696167
[5/23] Train loss=0.3403688371181488
[10/23] Train loss=0.3763209283351898
[15/23] Train loss=0.2806083858013153
[20/23] Train loss=0.27219918370246887
Test set avg_accuracy=82.77% avg_sensitivity=60.67%, avg_specificity=89.91% avg_auc=0.8601
Best model saved!! Metric=-6.645796566460078!!
Fold[7] Epoch: 56 [56/100 (56%)] Train loss=0.330793 Test loss=0.407605 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3256950378417969
[5/23] Train loss=0.32911375164985657
[10/23] Train loss=0.38070714473724365
[15/23] Train loss=0.2857508063316345
[20/23] Train loss=0.28052783012390137
Test set avg_accuracy=82.96% avg_sensitivity=58.79%, avg_specificity=90.77% avg_auc=0.8596
Fold[7] Epoch: 57 [57/100 (57%)] Train loss=0.330651 Test loss=0.414430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3250303566455841
[5/23] Train loss=0.32619115710258484
[10/23] Train loss=0.3664317727088928
[15/23] Train loss=0.3065682649612427
[20/23] Train loss=0.28639188408851624
Test set avg_accuracy=83.27% avg_sensitivity=57.72%, avg_specificity=91.52% avg_auc=0.8580
Fold[7] Epoch: 58 [58/100 (58%)] Train loss=0.330621 Test loss=0.420973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.332608699798584
[5/23] Train loss=0.33330070972442627
[10/23] Train loss=0.3780474364757538
[15/23] Train loss=0.29227158427238464
[20/23] Train loss=0.28794655203819275
Test set avg_accuracy=83.30% avg_sensitivity=56.91%, avg_specificity=91.83% avg_auc=0.8588
Fold[7] Epoch: 59 [59/100 (59%)] Train loss=0.331296 Test loss=0.420321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3167293667793274
[5/23] Train loss=0.32597440481185913
[10/23] Train loss=0.37957388162612915
[15/23] Train loss=0.29398050904273987
[20/23] Train loss=0.2778197228908539
Test set avg_accuracy=82.86% avg_sensitivity=58.49%, avg_specificity=90.74% avg_auc=0.8602
Fold[7] Epoch: 60 [60/100 (60%)] Train loss=0.327195 Test loss=0.411537 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31752046942710876
[5/23] Train loss=0.3355189859867096
[10/23] Train loss=0.3704579770565033
[15/23] Train loss=0.28952646255493164
[20/23] Train loss=0.2813801169395447
Test set avg_accuracy=82.73% avg_sensitivity=57.42%, avg_specificity=90.90% avg_auc=0.8541
Fold[7] Epoch: 61 [61/100 (61%)] Train loss=0.326575 Test loss=0.423866 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3166256248950958
[5/23] Train loss=0.32507580518722534
[10/23] Train loss=0.36293670535087585
[15/23] Train loss=0.291921466588974
[20/23] Train loss=0.27894923090934753
Test set avg_accuracy=82.44% avg_sensitivity=62.07%, avg_specificity=89.02% avg_auc=0.8615
Best model saved!! Metric=-6.321850505736576!!
Fold[7] Epoch: 62 [62/100 (62%)] Train loss=0.325447 Test loss=0.408893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3094065487384796
[5/23] Train loss=0.32975873351097107
[10/23] Train loss=0.3585592806339264
[15/23] Train loss=0.2899741530418396
[20/23] Train loss=0.276015967130661
Test set avg_accuracy=82.49% avg_sensitivity=64.59%, avg_specificity=88.27% avg_auc=0.8639
Best model saved!! Metric=-4.263098453376783!!
Fold[7] Epoch: 63 [63/100 (63%)] Train loss=0.323217 Test loss=0.402880 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31870684027671814
[5/23] Train loss=0.30935341119766235
[10/23] Train loss=0.35815954208374023
[15/23] Train loss=0.2740161716938019
[20/23] Train loss=0.2748604118824005
Test set avg_accuracy=82.93% avg_sensitivity=61.86%, avg_specificity=89.73% avg_auc=0.8644
Fold[7] Epoch: 64 [64/100 (64%)] Train loss=0.320176 Test loss=0.398869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31014519929885864
[5/23] Train loss=0.31440794467926025
[10/23] Train loss=0.3529827296733856
[15/23] Train loss=0.277082622051239
[20/23] Train loss=0.2689231336116791
Test set avg_accuracy=83.05% avg_sensitivity=61.01%, avg_specificity=90.17% avg_auc=0.8626
Fold[7] Epoch: 65 [65/100 (65%)] Train loss=0.315244 Test loss=0.404011 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3108820617198944
[5/23] Train loss=0.31512194871902466
[10/23] Train loss=0.3565521240234375
[15/23] Train loss=0.279900461435318
[20/23] Train loss=0.2621077299118042
Test set avg_accuracy=83.20% avg_sensitivity=60.24%, avg_specificity=90.61% avg_auc=0.8616
Fold[7] Epoch: 66 [66/100 (66%)] Train loss=0.314646 Test loss=0.409702 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30408844351768494
[5/23] Train loss=0.3074325919151306
[10/23] Train loss=0.3465740382671356
[15/23] Train loss=0.2874010503292084
[20/23] Train loss=0.2717568874359131
Test set avg_accuracy=83.35% avg_sensitivity=58.45%, avg_specificity=91.40% avg_auc=0.8633
Fold[7] Epoch: 67 [67/100 (67%)] Train loss=0.312400 Test loss=0.407420 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2982979118824005
[5/23] Train loss=0.3055237829685211
[10/23] Train loss=0.36679351329803467
[15/23] Train loss=0.27781280875205994
[20/23] Train loss=0.25445860624313354
Test set avg_accuracy=83.08% avg_sensitivity=57.59%, avg_specificity=91.32% avg_auc=0.8568
Fold[7] Epoch: 68 [68/100 (68%)] Train loss=0.311749 Test loss=0.426687 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3012889325618744
[5/23] Train loss=0.2999843955039978
[10/23] Train loss=0.33825379610061646
[15/23] Train loss=0.287350594997406
[20/23] Train loss=0.2644810676574707
Test set avg_accuracy=82.94% avg_sensitivity=57.12%, avg_specificity=91.28% avg_auc=0.8592
Fold[7] Epoch: 69 [69/100 (69%)] Train loss=0.311280 Test loss=0.414240 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3066841959953308
[5/23] Train loss=0.31967392563819885
[10/23] Train loss=0.3473585247993469
[15/23] Train loss=0.2643965482711792
[20/23] Train loss=0.26436901092529297
Test set avg_accuracy=83.20% avg_sensitivity=60.20%, avg_specificity=90.63% avg_auc=0.8585
Fold[7] Epoch: 70 [70/100 (70%)] Train loss=0.310978 Test loss=0.415012 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2977687418460846
[5/23] Train loss=0.31072553992271423
[10/23] Train loss=0.35086995363235474
[15/23] Train loss=0.28027844429016113
[20/23] Train loss=0.2717852294445038
Test set avg_accuracy=82.78% avg_sensitivity=62.24%, avg_specificity=89.42% avg_auc=0.8585
Fold[7] Epoch: 71 [71/100 (71%)] Train loss=0.306397 Test loss=0.418314 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29198163747787476
[5/23] Train loss=0.30016639828681946
[10/23] Train loss=0.3397262692451477
[15/23] Train loss=0.26862791180610657
[20/23] Train loss=0.26113325357437134
Test set avg_accuracy=82.73% avg_sensitivity=63.35%, avg_specificity=88.99% avg_auc=0.8608
Fold[7] Epoch: 72 [72/100 (72%)] Train loss=0.304641 Test loss=0.411596 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29904237389564514
[5/23] Train loss=0.29657697677612305
[10/23] Train loss=0.33149197697639465
[15/23] Train loss=0.2602994441986084
[20/23] Train loss=0.24778203666210175
Test set avg_accuracy=82.59% avg_sensitivity=65.49%, avg_specificity=88.12% avg_auc=0.8655
Best model saved!! Metric=-3.247646410549742!!
Fold[7] Epoch: 73 [73/100 (73%)] Train loss=0.302118 Test loss=0.403140 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30958208441734314
[5/23] Train loss=0.30215567350387573
[10/23] Train loss=0.33223554491996765
[15/23] Train loss=0.2602578103542328
[20/23] Train loss=0.25338223576545715
Test set avg_accuracy=83.15% avg_sensitivity=63.61%, avg_specificity=89.46% avg_auc=0.8649
Fold[7] Epoch: 74 [74/100 (74%)] Train loss=0.300240 Test loss=0.405521 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29964691400527954
[5/23] Train loss=0.2879970967769623
[10/23] Train loss=0.3303445875644684
[15/23] Train loss=0.25087592005729675
[20/23] Train loss=0.25465139746665955
Test set avg_accuracy=83.22% avg_sensitivity=61.60%, avg_specificity=90.20% avg_auc=0.8638
Fold[7] Epoch: 75 [75/100 (75%)] Train loss=0.298281 Test loss=0.415165 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2853211760520935
[5/23] Train loss=0.2910035252571106
[10/23] Train loss=0.34095653891563416
[15/23] Train loss=0.2605319321155548
[20/23] Train loss=0.26075947284698486
Test set avg_accuracy=83.43% avg_sensitivity=57.94%, avg_specificity=91.66% avg_auc=0.8621
Fold[7] Epoch: 76 [76/100 (76%)] Train loss=0.296827 Test loss=0.415648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2845290005207062
[5/23] Train loss=0.29597777128219604
[10/23] Train loss=0.3221472501754761
[15/23] Train loss=0.259446918964386
[20/23] Train loss=0.24824276566505432
Test set avg_accuracy=83.38% avg_sensitivity=57.64%, avg_specificity=91.69% avg_auc=0.8594
Fold[7] Epoch: 77 [77/100 (77%)] Train loss=0.296317 Test loss=0.419439 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.293107807636261
[5/23] Train loss=0.2956545948982239
[10/23] Train loss=0.3269771337509155
[15/23] Train loss=0.25832074880599976
[20/23] Train loss=0.25184985995292664
Test set avg_accuracy=83.24% avg_sensitivity=55.33%, avg_specificity=92.25% avg_auc=0.8585
Fold[7] Epoch: 78 [78/100 (78%)] Train loss=0.294446 Test loss=0.419747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2906439006328583
[5/23] Train loss=0.2834070324897766
[10/23] Train loss=0.3316712975502014
[15/23] Train loss=0.2524106800556183
[20/23] Train loss=0.25808897614479065
Test set avg_accuracy=82.76% avg_sensitivity=59.13%, avg_specificity=90.39% avg_auc=0.8556
Fold[7] Epoch: 79 [79/100 (79%)] Train loss=0.295709 Test loss=0.432811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2756679952144623
[5/23] Train loss=0.29104676842689514
[10/23] Train loss=0.3137238025665283
[15/23] Train loss=0.2627639174461365
[20/23] Train loss=0.24884067475795746
Test set avg_accuracy=83.21% avg_sensitivity=60.11%, avg_specificity=90.67% avg_auc=0.8595
Fold[7] Epoch: 80 [80/100 (80%)] Train loss=0.289832 Test loss=0.425604 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2799244821071625
[5/23] Train loss=0.2884291112422943
[10/23] Train loss=0.31996944546699524
[15/23] Train loss=0.2527725398540497
[20/23] Train loss=0.24989381432533264
Test set avg_accuracy=82.59% avg_sensitivity=61.82%, avg_specificity=89.31% avg_auc=0.8585
Fold[7] Epoch: 81 [81/100 (81%)] Train loss=0.291590 Test loss=0.421731 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2792283594608307
[5/23] Train loss=0.27588358521461487
[10/23] Train loss=0.3141915202140808
[15/23] Train loss=0.24937056005001068
[20/23] Train loss=0.2522956132888794
Test set avg_accuracy=82.48% avg_sensitivity=64.04%, avg_specificity=88.44% avg_auc=0.8597
Fold[7] Epoch: 82 [82/100 (82%)] Train loss=0.287263 Test loss=0.424232 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2815198302268982
[5/23] Train loss=0.2871122658252716
[10/23] Train loss=0.3027805984020233
[15/23] Train loss=0.24504640698432922
[20/23] Train loss=0.2423582524061203
Test set avg_accuracy=82.47% avg_sensitivity=65.10%, avg_specificity=88.08% avg_auc=0.8615
Fold[7] Epoch: 83 [83/100 (83%)] Train loss=0.283620 Test loss=0.421753 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2765409052371979
[5/23] Train loss=0.2715980112552643
[10/23] Train loss=0.30361321568489075
[15/23] Train loss=0.2538810968399048
[20/23] Train loss=0.23976033926010132
Test set avg_accuracy=82.32% avg_sensitivity=64.16%, avg_specificity=88.19% avg_auc=0.8576
Fold[7] Epoch: 84 [84/100 (84%)] Train loss=0.278998 Test loss=0.418670 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27515971660614014
[5/23] Train loss=0.2782260775566101
[10/23] Train loss=0.29786020517349243
[15/23] Train loss=0.24402067065238953
[20/23] Train loss=0.22534754872322083
Test set avg_accuracy=82.85% avg_sensitivity=64.38%, avg_specificity=88.82% avg_auc=0.8601
Fold[7] Epoch: 85 [85/100 (85%)] Train loss=0.277967 Test loss=0.420886 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2634159028530121
[5/23] Train loss=0.266592413187027
[10/23] Train loss=0.28574231266975403
[15/23] Train loss=0.238000750541687
[20/23] Train loss=0.2323428988456726
Test set avg_accuracy=82.88% avg_sensitivity=64.12%, avg_specificity=88.93% avg_auc=0.8610
Fold[7] Epoch: 86 [86/100 (86%)] Train loss=0.273695 Test loss=0.426313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2692974805831909
[5/23] Train loss=0.26913657784461975
[10/23] Train loss=0.2861509621143341
[15/23] Train loss=0.23731765151023865
[20/23] Train loss=0.2328760176897049
Test set avg_accuracy=82.73% avg_sensitivity=63.99%, avg_specificity=88.78% avg_auc=0.8607
Fold[7] Epoch: 87 [87/100 (87%)] Train loss=0.272950 Test loss=0.428875 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26497653126716614
[5/23] Train loss=0.2604425251483917
[10/23] Train loss=0.2844189405441284
[15/23] Train loss=0.24718908965587616
[20/23] Train loss=0.23592357337474823
Test set avg_accuracy=83.29% avg_sensitivity=60.41%, avg_specificity=90.68% avg_auc=0.8603
Fold[7] Epoch: 88 [88/100 (88%)] Train loss=0.271605 Test loss=0.421769 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27059805393218994
[5/23] Train loss=0.25854188203811646
[10/23] Train loss=0.304117351770401
[15/23] Train loss=0.2435685098171234
[20/23] Train loss=0.22532525658607483
Test set avg_accuracy=83.24% avg_sensitivity=58.53%, avg_specificity=91.22% avg_auc=0.8600
Fold[7] Epoch: 89 [89/100 (89%)] Train loss=0.269886 Test loss=0.419819 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2709900140762329
[5/23] Train loss=0.2694889008998871
[10/23] Train loss=0.30256563425064087
[15/23] Train loss=0.25182706117630005
[20/23] Train loss=0.22704218327999115
Test set avg_accuracy=83.06% avg_sensitivity=56.57%, avg_specificity=91.62% avg_auc=0.8576
Fold[7] Epoch: 90 [90/100 (90%)] Train loss=0.271759 Test loss=0.432345 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2715596854686737
[5/23] Train loss=0.26375073194503784
[10/23] Train loss=0.3013417720794678
[15/23] Train loss=0.25337278842926025
[20/23] Train loss=0.22530966997146606
Test set avg_accuracy=82.85% avg_sensitivity=53.54%, avg_specificity=92.32% avg_auc=0.8534
Fold[7] Epoch: 91 [91/100 (91%)] Train loss=0.276750 Test loss=0.451190 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2669312357902527
[5/23] Train loss=0.26034173369407654
[10/23] Train loss=0.2981968820095062
[15/23] Train loss=0.24359062314033508
[20/23] Train loss=0.23313170671463013
Test set avg_accuracy=82.68% avg_sensitivity=54.39%, avg_specificity=91.81% avg_auc=0.8530
Fold[7] Epoch: 92 [92/100 (92%)] Train loss=0.277451 Test loss=0.454341 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2665092945098877
[5/23] Train loss=0.2683701515197754
[10/23] Train loss=0.2854391634464264
[15/23] Train loss=0.23957496881484985
[20/23] Train loss=0.24306568503379822
Test set avg_accuracy=82.45% avg_sensitivity=63.18%, avg_specificity=88.67% avg_auc=0.8549
Fold[7] Epoch: 93 [93/100 (93%)] Train loss=0.275166 Test loss=0.442062 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26584455370903015
[5/23] Train loss=0.2673914134502411
[10/23] Train loss=0.2878706753253937
[15/23] Train loss=0.22922159731388092
[20/23] Train loss=0.2407950609922409
Test set avg_accuracy=82.77% avg_sensitivity=63.74%, avg_specificity=88.92% avg_auc=0.8603
Fold[7] Epoch: 94 [94/100 (94%)] Train loss=0.268148 Test loss=0.427869 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2649659514427185
[5/23] Train loss=0.256701797246933
[10/23] Train loss=0.2713686227798462
[15/23] Train loss=0.23592911660671234
[20/23] Train loss=0.21523892879486084
Test set avg_accuracy=82.40% avg_sensitivity=64.76%, avg_specificity=88.09% avg_auc=0.8622
Fold[7] Epoch: 95 [95/100 (95%)] Train loss=0.266241 Test loss=0.435912 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2603824734687805
[5/23] Train loss=0.24723798036575317
[10/23] Train loss=0.2708294093608856
[15/23] Train loss=0.2313743680715561
[20/23] Train loss=0.2156660556793213
Test set avg_accuracy=82.89% avg_sensitivity=62.37%, avg_specificity=89.51% avg_auc=0.8584
Fold[7] Epoch: 96 [96/100 (96%)] Train loss=0.258229 Test loss=0.434199 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25433725118637085
[5/23] Train loss=0.2420739233493805
[10/23] Train loss=0.25635451078414917
[15/23] Train loss=0.22821250557899475
[20/23] Train loss=0.21862870454788208
Test set avg_accuracy=82.71% avg_sensitivity=61.48%, avg_specificity=89.57% avg_auc=0.8562
Fold[7] Epoch: 97 [97/100 (97%)] Train loss=0.253970 Test loss=0.432773 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24852026998996735
[5/23] Train loss=0.23948532342910767
[10/23] Train loss=0.2607117295265198
[15/23] Train loss=0.2237800806760788
[20/23] Train loss=0.22023606300354004
Test set avg_accuracy=83.07% avg_sensitivity=57.55%, avg_specificity=91.32% avg_auc=0.8546
Fold[7] Epoch: 98 [98/100 (98%)] Train loss=0.253903 Test loss=0.438947 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24005630612373352
[5/23] Train loss=0.2503752112388611
[10/23] Train loss=0.26898881793022156
[15/23] Train loss=0.23680423200130463
[20/23] Train loss=0.2048189640045166
Test set avg_accuracy=82.80% avg_sensitivity=60.32%, avg_specificity=90.06% avg_auc=0.8537
Fold[7] Epoch: 99 [99/100 (99%)] Train loss=0.250101 Test loss=0.446276 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24253280460834503
[5/23] Train loss=0.24432624876499176
[10/23] Train loss=0.2688918709754944
[15/23] Train loss=0.23412208259105682
[20/23] Train loss=0.21325117349624634
Test set avg_accuracy=82.83% avg_sensitivity=58.40%, avg_specificity=90.72% avg_auc=0.8555
Fold[7] Epoch: 100 [100/100 (100%)] Train loss=0.251683 Test loss=0.441994 Current lr=[3.9999999999999996e-05]

Fold[7] Best Result: acc=82.59375 sen=65.48634812286689, spe=88.12017640573319, auc=0.8655207906085018!
[0/23] Train loss=0.7137225270271301
[5/23] Train loss=0.6920216083526611
[10/23] Train loss=0.5633107423782349
[15/23] Train loss=0.5803831815719604
[20/23] Train loss=0.5425354242324829
Test set avg_accuracy=76.87% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.5254
Best model saved!! Metric=-96.58945851183151!!
Fold[8] Epoch: 1 [1/100 (1%)] Train loss=0.591641 Test loss=0.586549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5658364295959473
[5/23] Train loss=0.630551278591156
[10/23] Train loss=0.5362500548362732
[15/23] Train loss=0.5657579302787781
[20/23] Train loss=0.5310327410697937
Test set avg_accuracy=76.82% avg_sensitivity=0.00%, avg_specificity=99.94% avg_auc=0.5719
Best model saved!! Metric=-92.04915822988855!!
Fold[8] Epoch: 2 [2/100 (2%)] Train loss=0.565080 Test loss=0.564509 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5614417195320129
[5/23] Train loss=0.6056543588638306
[10/23] Train loss=0.5092954039573669
[15/23] Train loss=0.5282473564147949
[20/23] Train loss=0.5037882924079895
Test set avg_accuracy=76.75% avg_sensitivity=4.86%, avg_specificity=98.39% avg_auc=0.6100
Best model saved!! Metric=-84.99406286174418!!
Fold[8] Epoch: 3 [3/100 (3%)] Train loss=0.544708 Test loss=0.541671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.537719190120697
[5/23] Train loss=0.5554273724555969
[10/23] Train loss=0.47668737173080444
[15/23] Train loss=0.4841513931751251
[20/23] Train loss=0.462726891040802
Test set avg_accuracy=76.91% avg_sensitivity=11.90%, avg_specificity=96.48% avg_auc=0.6719
Best model saved!! Metric=-73.51905389704739!!
Fold[8] Epoch: 4 [4/100 (4%)] Train loss=0.516128 Test loss=0.551459 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5098811984062195
[5/23] Train loss=0.5138487815856934
[10/23] Train loss=0.4701923429965973
[15/23] Train loss=0.4508153796195984
[20/23] Train loss=0.4270084798336029
Test set avg_accuracy=77.68% avg_sensitivity=16.82%, avg_specificity=96.00% avg_auc=0.7097
Best model saved!! Metric=-64.53449338372407!!
Fold[8] Epoch: 5 [5/100 (5%)] Train loss=0.489743 Test loss=0.571111 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4792088568210602
[5/23] Train loss=0.4800114929676056
[10/23] Train loss=0.4763864278793335
[15/23] Train loss=0.4326433837413788
[20/23] Train loss=0.4045972526073456
Test set avg_accuracy=78.78% avg_sensitivity=23.51%, avg_specificity=95.42% avg_auc=0.7322
Best model saved!! Metric=-55.06573881876571!!
Fold[8] Epoch: 6 [6/100 (6%)] Train loss=0.469341 Test loss=0.574205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.45657089352607727
[5/23] Train loss=0.46534836292266846
[10/23] Train loss=0.4686598777770996
[15/23] Train loss=0.4165278375148773
[20/23] Train loss=0.39584681391716003
Test set avg_accuracy=79.30% avg_sensitivity=26.54%, avg_specificity=95.18% avg_auc=0.7483
Best model saved!! Metric=-50.15675595207763!!
Fold[8] Epoch: 7 [7/100 (7%)] Train loss=0.455199 Test loss=0.571061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4373554587364197
[5/23] Train loss=0.4561126232147217
[10/23] Train loss=0.4734082818031311
[15/23] Train loss=0.41294386982917786
[20/23] Train loss=0.3886924982070923
Test set avg_accuracy=79.44% avg_sensitivity=28.08%, avg_specificity=94.89% avg_auc=0.7630
Best model saved!! Metric=-47.295134234718944!!
Fold[8] Epoch: 8 [8/100 (8%)] Train loss=0.446961 Test loss=0.563811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4291449785232544
[5/23] Train loss=0.45152372121810913
[10/23] Train loss=0.4709607660770416
[15/23] Train loss=0.41092491149902344
[20/23] Train loss=0.3890097141265869
Test set avg_accuracy=79.87% avg_sensitivity=28.77%, avg_specificity=95.25% avg_auc=0.7731
Best model saved!! Metric=-44.7915650028943!!
Fold[8] Epoch: 9 [9/100 (9%)] Train loss=0.441408 Test loss=0.564523 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4154330790042877
[5/23] Train loss=0.4455064535140991
[10/23] Train loss=0.47289448976516724
[15/23] Train loss=0.41907498240470886
[20/23] Train loss=0.3739829957485199
Test set avg_accuracy=79.68% avg_sensitivity=28.47%, avg_specificity=95.09% avg_auc=0.7761
Fold[8] Epoch: 10 [10/100 (10%)] Train loss=0.440342 Test loss=0.566229 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4239431321620941
[5/23] Train loss=0.4418408274650574
[10/23] Train loss=0.46459972858428955
[15/23] Train loss=0.4254951775074005
[20/23] Train loss=0.37629687786102295
Test set avg_accuracy=80.03% avg_sensitivity=31.15%, avg_specificity=94.75% avg_auc=0.7808
Best model saved!! Metric=-41.98596402256858!!
Fold[8] Epoch: 11 [11/100 (11%)] Train loss=0.439638 Test loss=0.523608 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4233810007572174
[5/23] Train loss=0.43584147095680237
[10/23] Train loss=0.4650072455406189
[15/23] Train loss=0.4252662658691406
[20/23] Train loss=0.3714640140533447
Test set avg_accuracy=80.00% avg_sensitivity=31.94%, avg_specificity=94.46% avg_auc=0.7837
Best model saved!! Metric=-41.227536329753065!!
Fold[8] Epoch: 12 [12/100 (12%)] Train loss=0.436790 Test loss=0.526667 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4226647615432739
[5/23] Train loss=0.4417243003845215
[10/23] Train loss=0.4622831642627716
[15/23] Train loss=0.41608843207359314
[20/23] Train loss=0.37029024958610535
Test set avg_accuracy=80.29% avg_sensitivity=34.08%, avg_specificity=94.19% avg_auc=0.8079
Best model saved!! Metric=-36.64981858211428!!
Fold[8] Epoch: 13 [13/100 (13%)] Train loss=0.431445 Test loss=0.509277 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4046441614627838
[5/23] Train loss=0.4365425109863281
[10/23] Train loss=0.4631640911102295
[15/23] Train loss=0.40837380290031433
[20/23] Train loss=0.36690160632133484
Test set avg_accuracy=80.68% avg_sensitivity=36.41%, avg_specificity=94.00% avg_auc=0.8176
Best model saved!! Metric=-33.15944008335247!!
Fold[8] Epoch: 14 [14/100 (14%)] Train loss=0.424700 Test loss=0.482389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4022534489631653
[5/23] Train loss=0.42436137795448303
[10/23] Train loss=0.4608672559261322
[15/23] Train loss=0.39801397919654846
[20/23] Train loss=0.36443817615509033
Test set avg_accuracy=80.72% avg_sensitivity=38.10%, avg_specificity=93.55% avg_auc=0.8231
Best model saved!! Metric=-31.315602985160517!!
Fold[8] Epoch: 15 [15/100 (15%)] Train loss=0.417161 Test loss=0.468883 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4087681174278259
[5/23] Train loss=0.4237029254436493
[10/23] Train loss=0.4589787423610687
[15/23] Train loss=0.40297532081604004
[20/23] Train loss=0.35480108857154846
Test set avg_accuracy=80.99% avg_sensitivity=39.19%, avg_specificity=93.57% avg_auc=0.8293
Best model saved!! Metric=-29.333268583543095!!
Fold[8] Epoch: 16 [16/100 (16%)] Train loss=0.416211 Test loss=0.463004 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40072616934776306
[5/23] Train loss=0.4232836067676544
[10/23] Train loss=0.4519485831260681
[15/23] Train loss=0.3991988003253937
[20/23] Train loss=0.3561949133872986
Test set avg_accuracy=80.83% avg_sensitivity=38.59%, avg_specificity=93.54% avg_auc=0.8332
Fold[8] Epoch: 17 [17/100 (17%)] Train loss=0.414290 Test loss=0.456528 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39611533284187317
[5/23] Train loss=0.41540026664733887
[10/23] Train loss=0.4508063793182373
[15/23] Train loss=0.3860015869140625
[20/23] Train loss=0.3533790409564972
Test set avg_accuracy=81.16% avg_sensitivity=41.57%, avg_specificity=93.07% avg_auc=0.8374
Best model saved!! Metric=-26.464490765398835!!
Fold[8] Epoch: 18 [18/100 (18%)] Train loss=0.409019 Test loss=0.444029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3876412808895111
[5/23] Train loss=0.41541704535484314
[10/23] Train loss=0.4541693925857544
[15/23] Train loss=0.3815470039844513
[20/23] Train loss=0.3458329737186432
Test set avg_accuracy=81.23% avg_sensitivity=41.87%, avg_specificity=93.07% avg_auc=0.8399
Best model saved!! Metric=-25.838665236797173!!
Fold[8] Epoch: 19 [19/100 (19%)] Train loss=0.405764 Test loss=0.435095 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3937920331954956
[5/23] Train loss=0.40902483463287354
[10/23] Train loss=0.4487602412700653
[15/23] Train loss=0.377467542886734
[20/23] Train loss=0.33950453996658325
Test set avg_accuracy=81.29% avg_sensitivity=42.36%, avg_specificity=93.00% avg_auc=0.8424
Best model saved!! Metric=-25.115111666820965!!
Fold[8] Epoch: 20 [20/100 (20%)] Train loss=0.402919 Test loss=0.432295 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39026737213134766
[5/23] Train loss=0.40155354142189026
[10/23] Train loss=0.452414333820343
[15/23] Train loss=0.3754619061946869
[20/23] Train loss=0.3434599041938782
Test set avg_accuracy=81.46% avg_sensitivity=42.71%, avg_specificity=93.12% avg_auc=0.8468
Best model saved!! Metric=-24.032248057620492!!
Fold[8] Epoch: 21 [21/100 (21%)] Train loss=0.399896 Test loss=0.429928 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38494768738746643
[5/23] Train loss=0.4073018431663513
[10/23] Train loss=0.44207486510276794
[15/23] Train loss=0.3831348419189453
[20/23] Train loss=0.3368189036846161
Test set avg_accuracy=81.46% avg_sensitivity=42.21%, avg_specificity=93.27% avg_auc=0.8458
Fold[8] Epoch: 22 [22/100 (22%)] Train loss=0.402038 Test loss=0.439192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3800109326839447
[5/23] Train loss=0.3986993432044983
[10/23] Train loss=0.44642373919487
[15/23] Train loss=0.37551912665367126
[20/23] Train loss=0.3363247811794281
Test set avg_accuracy=81.47% avg_sensitivity=43.25%, avg_specificity=92.97% avg_auc=0.8495
Best model saved!! Metric=-23.353537214489634!!
Fold[8] Epoch: 23 [23/100 (23%)] Train loss=0.399783 Test loss=0.427653 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.384453684091568
[5/23] Train loss=0.4055677652359009
[10/23] Train loss=0.44028687477111816
[15/23] Train loss=0.37281396985054016
[20/23] Train loss=0.33468252420425415
Test set avg_accuracy=81.50% avg_sensitivity=44.64%, avg_specificity=92.60% avg_auc=0.8520
Best model saved!! Metric=-22.0591235687495!!
Fold[8] Epoch: 24 [24/100 (24%)] Train loss=0.397155 Test loss=0.418386 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37939751148223877
[5/23] Train loss=0.3962036371231079
[10/23] Train loss=0.4386289715766907
[15/23] Train loss=0.3699599504470825
[20/23] Train loss=0.3324379324913025
Test set avg_accuracy=81.51% avg_sensitivity=46.28%, avg_specificity=92.12% avg_auc=0.8557
Best model saved!! Metric=-20.51534491165922!!
Fold[8] Epoch: 25 [25/100 (25%)] Train loss=0.394127 Test loss=0.407538 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37504464387893677
[5/23] Train loss=0.3921387791633606
[10/23] Train loss=0.4401772916316986
[15/23] Train loss=0.3598114848136902
[20/23] Train loss=0.32158350944519043
Test set avg_accuracy=81.78% avg_sensitivity=48.91%, avg_specificity=91.67% avg_auc=0.8591
Best model saved!! Metric=-17.72963752378704!!
Fold[8] Epoch: 26 [26/100 (26%)] Train loss=0.387266 Test loss=0.399078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37233009934425354
[5/23] Train loss=0.396750271320343
[10/23] Train loss=0.434821218252182
[15/23] Train loss=0.355557382106781
[20/23] Train loss=0.3274352252483368
Test set avg_accuracy=81.73% avg_sensitivity=46.88%, avg_specificity=92.22% avg_auc=0.8585
Fold[8] Epoch: 27 [27/100 (27%)] Train loss=0.387744 Test loss=0.403440 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36264297366142273
[5/23] Train loss=0.39531412720680237
[10/23] Train loss=0.4308887720108032
[15/23] Train loss=0.35646486282348633
[20/23] Train loss=0.3252505362033844
Test set avg_accuracy=81.82% avg_sensitivity=49.06%, avg_specificity=91.69% avg_auc=0.8609
Best model saved!! Metric=-17.33989390555063!!
Fold[8] Epoch: 28 [28/100 (28%)] Train loss=0.383394 Test loss=0.397706 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36329689621925354
[5/23] Train loss=0.38831621408462524
[10/23] Train loss=0.4342528283596039
[15/23] Train loss=0.35867953300476074
[20/23] Train loss=0.32542189955711365
Test set avg_accuracy=82.12% avg_sensitivity=48.16%, avg_specificity=92.34% avg_auc=0.8591
Fold[8] Epoch: 29 [29/100 (29%)] Train loss=0.385056 Test loss=0.403676 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.366015762090683
[5/23] Train loss=0.3824918866157532
[10/23] Train loss=0.42483624815940857
[15/23] Train loss=0.3575400412082672
[20/23] Train loss=0.3200283646583557
Test set avg_accuracy=82.19% avg_sensitivity=49.85%, avg_specificity=91.92% avg_auc=0.8628
Best model saved!! Metric=-15.754512009467796!!
Fold[8] Epoch: 30 [30/100 (30%)] Train loss=0.382518 Test loss=0.393323 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3665126860141754
[5/23] Train loss=0.38866761326789856
[10/23] Train loss=0.42643943428993225
[15/23] Train loss=0.3520580530166626
[20/23] Train loss=0.3190558850765228
Test set avg_accuracy=82.01% avg_sensitivity=49.36%, avg_specificity=91.83% avg_auc=0.8610
Fold[8] Epoch: 31 [31/100 (31%)] Train loss=0.379850 Test loss=0.400733 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36325541138648987
[5/23] Train loss=0.38448360562324524
[10/23] Train loss=0.4267454147338867
[15/23] Train loss=0.35078561305999756
[20/23] Train loss=0.3196980059146881
Test set avg_accuracy=82.31% avg_sensitivity=50.50%, avg_specificity=91.88% avg_auc=0.8620
Best model saved!! Metric=-15.116931048499687!!
Fold[8] Epoch: 32 [32/100 (32%)] Train loss=0.378489 Test loss=0.398537 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3619302213191986
[5/23] Train loss=0.39029866456985474
[10/23] Train loss=0.4277018904685974
[15/23] Train loss=0.343904584646225
[20/23] Train loss=0.3207756578922272
Test set avg_accuracy=82.18% avg_sensitivity=49.11%, avg_specificity=92.13% avg_auc=0.8591
Fold[8] Epoch: 33 [33/100 (33%)] Train loss=0.377864 Test loss=0.408655 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3561611473560333
[5/23] Train loss=0.3822339177131653
[10/23] Train loss=0.42254185676574707
[15/23] Train loss=0.34708184003829956
[20/23] Train loss=0.3154480755329132
Test set avg_accuracy=82.39% avg_sensitivity=51.39%, avg_specificity=91.72% avg_auc=0.8648
Best model saved!! Metric=-14.026590203462739!!
Fold[8] Epoch: 34 [34/100 (34%)] Train loss=0.374431 Test loss=0.393044 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35728269815444946
[5/23] Train loss=0.39299726486206055
[10/23] Train loss=0.4172598123550415
[15/23] Train loss=0.34695762395858765
[20/23] Train loss=0.31248098611831665
Test set avg_accuracy=82.31% avg_sensitivity=50.30%, avg_specificity=91.94% avg_auc=0.8639
Fold[8] Epoch: 35 [35/100 (35%)] Train loss=0.374435 Test loss=0.395372 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35786277055740356
[5/23] Train loss=0.38308143615722656
[10/23] Train loss=0.41758647561073303
[15/23] Train loss=0.34638699889183044
[20/23] Train loss=0.3128683865070343
Test set avg_accuracy=82.48% avg_sensitivity=50.00%, avg_specificity=92.25% avg_auc=0.8637
Fold[8] Epoch: 36 [36/100 (36%)] Train loss=0.371967 Test loss=0.396860 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3552524745464325
[5/23] Train loss=0.3803042471408844
[10/23] Train loss=0.4259883165359497
[15/23] Train loss=0.3386003077030182
[20/23] Train loss=0.3131081163883209
Test set avg_accuracy=82.51% avg_sensitivity=51.64%, avg_specificity=91.80% avg_auc=0.8640
Best model saved!! Metric=-13.644832131003426!!
Fold[8] Epoch: 37 [37/100 (37%)] Train loss=0.370779 Test loss=0.394646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35474711656570435
[5/23] Train loss=0.3822407126426697
[10/23] Train loss=0.4122343063354492
[15/23] Train loss=0.3317113518714905
[20/23] Train loss=0.30927708745002747
Test set avg_accuracy=82.88% avg_sensitivity=54.17%, avg_specificity=91.52% avg_auc=0.8654
Best model saved!! Metric=-10.897052151340235!!
Fold[8] Epoch: 38 [38/100 (38%)] Train loss=0.366993 Test loss=0.392542 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3478873670101166
[5/23] Train loss=0.36895543336868286
[10/23] Train loss=0.4095298945903778
[15/23] Train loss=0.33471420407295227
[20/23] Train loss=0.30646705627441406
Test set avg_accuracy=82.99% avg_sensitivity=56.55%, avg_specificity=90.95% avg_auc=0.8665
Best model saved!! Metric=-8.85502161012207!!
Fold[8] Epoch: 39 [39/100 (39%)] Train loss=0.364935 Test loss=0.388225 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35089433193206787
[5/23] Train loss=0.3662886917591095
[10/23] Train loss=0.40858739614486694
[15/23] Train loss=0.3274901807308197
[20/23] Train loss=0.31225600838661194
Test set avg_accuracy=83.20% avg_sensitivity=57.44%, avg_specificity=90.95% avg_auc=0.8679
Best model saved!! Metric=-7.61500764607775!!
Fold[8] Epoch: 40 [40/100 (40%)] Train loss=0.361158 Test loss=0.384616 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34692755341529846
[5/23] Train loss=0.370913565158844
[10/23] Train loss=0.41680121421813965
[15/23] Train loss=0.32555824518203735
[20/23] Train loss=0.3012728691101074
Test set avg_accuracy=83.26% avg_sensitivity=56.75%, avg_specificity=91.24% avg_auc=0.8700
Fold[8] Epoch: 41 [41/100 (41%)] Train loss=0.360640 Test loss=0.381093 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3452623188495636
[5/23] Train loss=0.36997807025909424
[10/23] Train loss=0.4054831862449646
[15/23] Train loss=0.3209284543991089
[20/23] Train loss=0.3023006319999695
Test set avg_accuracy=83.17% avg_sensitivity=57.34%, avg_specificity=90.94% avg_auc=0.8693
Fold[8] Epoch: 42 [42/100 (42%)] Train loss=0.357653 Test loss=0.385339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35151731967926025
[5/23] Train loss=0.36544284224510193
[10/23] Train loss=0.4073818325996399
[15/23] Train loss=0.3278719484806061
[20/23] Train loss=0.29568904638290405
Test set avg_accuracy=83.13% avg_sensitivity=57.89%, avg_specificity=90.73% avg_auc=0.8695
Best model saved!! Metric=-7.295899732824763!!
Fold[8] Epoch: 43 [43/100 (43%)] Train loss=0.355770 Test loss=0.384712 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.344611257314682
[5/23] Train loss=0.3746529519557953
[10/23] Train loss=0.40800803899765015
[15/23] Train loss=0.32139724493026733
[20/23] Train loss=0.300471693277359
Test set avg_accuracy=82.96% avg_sensitivity=54.81%, avg_specificity=91.43% avg_auc=0.8694
Fold[8] Epoch: 44 [44/100 (44%)] Train loss=0.355932 Test loss=0.387167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34023264050483704
[5/23] Train loss=0.36685144901275635
[10/23] Train loss=0.40528661012649536
[15/23] Train loss=0.3157779276371002
[20/23] Train loss=0.2986849844455719
Test set avg_accuracy=82.97% avg_sensitivity=56.75%, avg_specificity=90.86% avg_auc=0.8702
Fold[8] Epoch: 45 [45/100 (45%)] Train loss=0.356018 Test loss=0.381158 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34003743529319763
[5/23] Train loss=0.37344568967819214
[10/23] Train loss=0.39358723163604736
[15/23] Train loss=0.3235369622707367
[20/23] Train loss=0.29475167393684387
Test set avg_accuracy=82.82% avg_sensitivity=54.61%, avg_specificity=91.31% avg_auc=0.8650
Fold[8] Epoch: 46 [46/100 (46%)] Train loss=0.355954 Test loss=0.394805 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3371690809726715
[5/23] Train loss=0.359989732503891
[10/23] Train loss=0.4002228379249573
[15/23] Train loss=0.31384143233299255
[20/23] Train loss=0.29677116870880127
Test set avg_accuracy=82.86% avg_sensitivity=56.40%, avg_specificity=90.82% avg_auc=0.8674
Fold[8] Epoch: 47 [47/100 (47%)] Train loss=0.350563 Test loss=0.386076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33737337589263916
[5/23] Train loss=0.3631185293197632
[10/23] Train loss=0.39153364300727844
[15/23] Train loss=0.31185877323150635
[20/23] Train loss=0.2934435307979584
Test set avg_accuracy=83.03% avg_sensitivity=56.50%, avg_specificity=91.01% avg_auc=0.8674
Fold[8] Epoch: 48 [48/100 (48%)] Train loss=0.348938 Test loss=0.389065 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34471920132637024
[5/23] Train loss=0.35378435254096985
[10/23] Train loss=0.3903791308403015
[15/23] Train loss=0.31580474972724915
[20/23] Train loss=0.2916091978549957
Test set avg_accuracy=83.18% avg_sensitivity=57.24%, avg_specificity=90.98% avg_auc=0.8676
Fold[8] Epoch: 49 [49/100 (49%)] Train loss=0.347525 Test loss=0.383360 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3391583561897278
[5/23] Train loss=0.35785382986068726
[10/23] Train loss=0.38563990592956543
[15/23] Train loss=0.30930793285369873
[20/23] Train loss=0.28889143466949463
Test set avg_accuracy=83.27% avg_sensitivity=56.75%, avg_specificity=91.25% avg_auc=0.8664
Fold[8] Epoch: 50 [50/100 (50%)] Train loss=0.343217 Test loss=0.386665 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3254531919956207
[5/23] Train loss=0.35127806663513184
[10/23] Train loss=0.39405545592308044
[15/23] Train loss=0.3078417181968689
[20/23] Train loss=0.2878688871860504
Test set avg_accuracy=83.34% avg_sensitivity=55.75%, avg_specificity=91.64% avg_auc=0.8670
Fold[8] Epoch: 51 [51/100 (51%)] Train loss=0.342796 Test loss=0.395424 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33095258474349976
[5/23] Train loss=0.35818204283714294
[10/23] Train loss=0.38571953773498535
[15/23] Train loss=0.31078988313674927
[20/23] Train loss=0.28393179178237915
Test set avg_accuracy=83.11% avg_sensitivity=53.12%, avg_specificity=92.13% avg_auc=0.8706
Fold[8] Epoch: 52 [52/100 (52%)] Train loss=0.342219 Test loss=0.388765 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32483309507369995
[5/23] Train loss=0.3517259955406189
[10/23] Train loss=0.3807457685470581
[15/23] Train loss=0.30323919653892517
[20/23] Train loss=0.2737632691860199
Test set avg_accuracy=83.12% avg_sensitivity=55.36%, avg_specificity=91.48% avg_auc=0.8702
Fold[8] Epoch: 53 [53/100 (53%)] Train loss=0.338194 Test loss=0.385185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33223867416381836
[5/23] Train loss=0.3399980664253235
[10/23] Train loss=0.3738475441932678
[15/23] Train loss=0.2917327284812927
[20/23] Train loss=0.27995675802230835
Test set avg_accuracy=83.11% avg_sensitivity=53.87%, avg_specificity=91.91% avg_auc=0.8664
Fold[8] Epoch: 54 [54/100 (54%)] Train loss=0.337004 Test loss=0.397569 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33061766624450684
[5/23] Train loss=0.34467798471450806
[10/23] Train loss=0.3808777630329132
[15/23] Train loss=0.29265332221984863
[20/23] Train loss=0.27532878518104553
Test set avg_accuracy=83.04% avg_sensitivity=53.52%, avg_specificity=91.92% avg_auc=0.8679
Fold[8] Epoch: 55 [55/100 (55%)] Train loss=0.335458 Test loss=0.393720 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32468080520629883
[5/23] Train loss=0.34921151399612427
[10/23] Train loss=0.3816945552825928
[15/23] Train loss=0.29832345247268677
[20/23] Train loss=0.2848903238773346
Test set avg_accuracy=83.35% avg_sensitivity=53.77%, avg_specificity=92.25% avg_auc=0.8729
Fold[8] Epoch: 56 [56/100 (56%)] Train loss=0.334610 Test loss=0.385813 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3284083902835846
[5/23] Train loss=0.3397987186908722
[10/23] Train loss=0.37476980686187744
[15/23] Train loss=0.28722110390663147
[20/23] Train loss=0.281643807888031
Test set avg_accuracy=83.25% avg_sensitivity=53.57%, avg_specificity=92.18% avg_auc=0.8686
Fold[8] Epoch: 57 [57/100 (57%)] Train loss=0.332074 Test loss=0.394155 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32760724425315857
[5/23] Train loss=0.33757472038269043
[10/23] Train loss=0.38419297337532043
[15/23] Train loss=0.29369837045669556
[20/23] Train loss=0.2769714593887329
Test set avg_accuracy=83.16% avg_sensitivity=52.13%, avg_specificity=92.49% avg_auc=0.8686
Fold[8] Epoch: 58 [58/100 (58%)] Train loss=0.330723 Test loss=0.408062 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32014891505241394
[5/23] Train loss=0.3407951593399048
[10/23] Train loss=0.3784434199333191
[15/23] Train loss=0.28672462701797485
[20/23] Train loss=0.2726146876811981
Test set avg_accuracy=83.06% avg_sensitivity=50.84%, avg_specificity=92.76% avg_auc=0.8693
Fold[8] Epoch: 59 [59/100 (59%)] Train loss=0.330512 Test loss=0.407555 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32427871227264404
[5/23] Train loss=0.33075034618377686
[10/23] Train loss=0.38320112228393555
[15/23] Train loss=0.29681286215782166
[20/23] Train loss=0.27778351306915283
Test set avg_accuracy=82.93% avg_sensitivity=50.79%, avg_specificity=92.60% avg_auc=0.8656
Fold[8] Epoch: 60 [60/100 (60%)] Train loss=0.332208 Test loss=0.412735 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3252340853214264
[5/23] Train loss=0.3434825837612152
[10/23] Train loss=0.38045942783355713
[15/23] Train loss=0.3139497935771942
[20/23] Train loss=0.2772360146045685
Test set avg_accuracy=82.47% avg_sensitivity=46.78%, avg_specificity=93.21% avg_auc=0.8596
Fold[8] Epoch: 61 [61/100 (61%)] Train loss=0.335192 Test loss=0.437081 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3244149088859558
[5/23] Train loss=0.3381020426750183
[10/23] Train loss=0.3692915141582489
[15/23] Train loss=0.301118940114975
[20/23] Train loss=0.29136791825294495
Test set avg_accuracy=82.97% avg_sensitivity=50.60%, avg_specificity=92.72% avg_auc=0.8600
Fold[8] Epoch: 62 [62/100 (62%)] Train loss=0.335671 Test loss=0.413896 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3087734878063202
[5/23] Train loss=0.33826202154159546
[10/23] Train loss=0.3686593472957611
[15/23] Train loss=0.28021490573883057
[20/23] Train loss=0.27898353338241577
Test set avg_accuracy=83.42% avg_sensitivity=57.34%, avg_specificity=91.27% avg_auc=0.8676
Best model saved!! Metric=-7.216114038536739!!
Fold[8] Epoch: 63 [63/100 (63%)] Train loss=0.324511 Test loss=0.392426 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3112768232822418
[5/23] Train loss=0.331959992647171
[10/23] Train loss=0.35769158601760864
[15/23] Train loss=0.277974396944046
[20/23] Train loss=0.26170966029167175
Test set avg_accuracy=83.43% avg_sensitivity=55.46%, avg_specificity=91.85% avg_auc=0.8672
Fold[8] Epoch: 64 [64/100 (64%)] Train loss=0.320366 Test loss=0.403915 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30902498960494995
[5/23] Train loss=0.3226841986179352
[10/23] Train loss=0.3552761375904083
[15/23] Train loss=0.2696230709552765
[20/23] Train loss=0.26627662777900696
Test set avg_accuracy=83.40% avg_sensitivity=54.56%, avg_specificity=92.07% avg_auc=0.8662
Fold[8] Epoch: 65 [65/100 (65%)] Train loss=0.315687 Test loss=0.412915 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31516751646995544
[5/23] Train loss=0.3258523643016815
[10/23] Train loss=0.36559411883354187
[15/23] Train loss=0.27371472120285034
[20/23] Train loss=0.2614230513572693
Test set avg_accuracy=83.24% avg_sensitivity=56.60%, avg_specificity=91.25% avg_auc=0.8635
Fold[8] Epoch: 66 [66/100 (66%)] Train loss=0.315321 Test loss=0.397099 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3059133291244507
[5/23] Train loss=0.3257827162742615
[10/23] Train loss=0.3513394296169281
[15/23] Train loss=0.28052273392677307
[20/23] Train loss=0.2526693344116211
Test set avg_accuracy=83.30% avg_sensitivity=55.56%, avg_specificity=91.66% avg_auc=0.8632
Fold[8] Epoch: 67 [67/100 (67%)] Train loss=0.314279 Test loss=0.405537 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3040156960487366
[5/23] Train loss=0.31978240609169006
[10/23] Train loss=0.3604215383529663
[15/23] Train loss=0.2778608500957489
[20/23] Train loss=0.26496538519859314
Test set avg_accuracy=83.33% avg_sensitivity=54.66%, avg_specificity=91.95% avg_auc=0.8626
Fold[8] Epoch: 68 [68/100 (68%)] Train loss=0.312881 Test loss=0.401830 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30624082684516907
[5/23] Train loss=0.3236723840236664
[10/23] Train loss=0.34642183780670166
[15/23] Train loss=0.25955572724342346
[20/23] Train loss=0.25896885991096497
Test set avg_accuracy=83.28% avg_sensitivity=55.26%, avg_specificity=91.72% avg_auc=0.8644
Fold[8] Epoch: 69 [69/100 (69%)] Train loss=0.309967 Test loss=0.394269 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.305803120136261
[5/23] Train loss=0.302909791469574
[10/23] Train loss=0.3441639244556427
[15/23] Train loss=0.2611604332923889
[20/23] Train loss=0.25002655386924744
Test set avg_accuracy=82.74% avg_sensitivity=55.21%, avg_specificity=91.03% avg_auc=0.8558
Fold[8] Epoch: 70 [70/100 (70%)] Train loss=0.308892 Test loss=0.411679 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3154217600822449
[5/23] Train loss=0.3119819760322571
[10/23] Train loss=0.33336225152015686
[15/23] Train loss=0.2653779685497284
[20/23] Train loss=0.2561706602573395
Test set avg_accuracy=83.11% avg_sensitivity=57.99%, avg_specificity=90.67% avg_auc=0.8634
Fold[8] Epoch: 71 [71/100 (71%)] Train loss=0.305319 Test loss=0.403471 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30250340700149536
[5/23] Train loss=0.31557896733283997
[10/23] Train loss=0.34233418107032776
[15/23] Train loss=0.26210257411003113
[20/23] Train loss=0.2530877888202667
Test set avg_accuracy=83.33% avg_sensitivity=56.80%, avg_specificity=91.31% avg_auc=0.8629
Fold[8] Epoch: 72 [72/100 (72%)] Train loss=0.304288 Test loss=0.399156 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3049817383289337
[5/23] Train loss=0.30556705594062805
[10/23] Train loss=0.333597332239151
[15/23] Train loss=0.24889543652534485
[20/23] Train loss=0.24555832147598267
Test set avg_accuracy=83.18% avg_sensitivity=55.70%, avg_specificity=91.45% avg_auc=0.8635
Fold[8] Epoch: 73 [73/100 (73%)] Train loss=0.299658 Test loss=0.403943 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2983320355415344
[5/23] Train loss=0.3067995607852936
[10/23] Train loss=0.33401134610176086
[15/23] Train loss=0.2568706274032593
[20/23] Train loss=0.25138089060783386
Test set avg_accuracy=83.01% avg_sensitivity=53.82%, avg_specificity=91.79% avg_auc=0.8598
Fold[8] Epoch: 74 [74/100 (74%)] Train loss=0.298561 Test loss=0.405866 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29604479670524597
[5/23] Train loss=0.3082776665687561
[10/23] Train loss=0.3392614424228668
[15/23] Train loss=0.24816380441188812
[20/23] Train loss=0.2494623064994812
Test set avg_accuracy=82.98% avg_sensitivity=55.06%, avg_specificity=91.39% avg_auc=0.8624
Fold[8] Epoch: 75 [75/100 (75%)] Train loss=0.297454 Test loss=0.407029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2973078489303589
[5/23] Train loss=0.3165537118911743
[10/23] Train loss=0.32415640354156494
[15/23] Train loss=0.24554923176765442
[20/23] Train loss=0.24837726354599
Test set avg_accuracy=83.11% avg_sensitivity=58.28%, avg_specificity=90.58% avg_auc=0.8666
Fold[8] Epoch: 76 [76/100 (76%)] Train loss=0.293023 Test loss=0.394461 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29077988862991333
[5/23] Train loss=0.3112525939941406
[10/23] Train loss=0.3209235668182373
[15/23] Train loss=0.25022298097610474
[20/23] Train loss=0.23701082170009613
Test set avg_accuracy=82.94% avg_sensitivity=55.01%, avg_specificity=91.34% avg_auc=0.8618
Fold[8] Epoch: 77 [77/100 (77%)] Train loss=0.293912 Test loss=0.416700 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2951066493988037
[5/23] Train loss=0.3028751313686371
[10/23] Train loss=0.31984594464302063
[15/23] Train loss=0.2444514036178589
[20/23] Train loss=0.23335683345794678
Test set avg_accuracy=83.26% avg_sensitivity=56.94%, avg_specificity=91.18% avg_auc=0.8685
Fold[8] Epoch: 78 [78/100 (78%)] Train loss=0.290575 Test loss=0.405659 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2909436821937561
[5/23] Train loss=0.29961803555488586
[10/23] Train loss=0.3133906126022339
[15/23] Train loss=0.23984192311763763
[20/23] Train loss=0.247794508934021
Test set avg_accuracy=83.09% avg_sensitivity=52.93%, avg_specificity=92.16% avg_auc=0.8586
Fold[8] Epoch: 79 [79/100 (79%)] Train loss=0.290675 Test loss=0.424685 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28874513506889343
[5/23] Train loss=0.29670459032058716
[10/23] Train loss=0.3206184506416321
[15/23] Train loss=0.24195274710655212
[20/23] Train loss=0.23615463078022003
Test set avg_accuracy=83.28% avg_sensitivity=56.25%, avg_specificity=91.42% avg_auc=0.8659
Fold[8] Epoch: 80 [80/100 (80%)] Train loss=0.284893 Test loss=0.410787 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28290483355522156
[5/23] Train loss=0.29801085591316223
[10/23] Train loss=0.3138923943042755
[15/23] Train loss=0.24071457982063293
[20/23] Train loss=0.23915237188339233
Test set avg_accuracy=82.73% avg_sensitivity=50.55%, avg_specificity=92.42% avg_auc=0.8603
Fold[8] Epoch: 81 [81/100 (81%)] Train loss=0.287956 Test loss=0.424042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2889750003814697
[5/23] Train loss=0.2912289798259735
[10/23] Train loss=0.3072810471057892
[15/23] Train loss=0.2439125031232834
[20/23] Train loss=0.24254725873470306
Test set avg_accuracy=83.28% avg_sensitivity=55.80%, avg_specificity=91.55% avg_auc=0.8654
Fold[8] Epoch: 82 [82/100 (82%)] Train loss=0.283364 Test loss=0.407286 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28125277161598206
[5/23] Train loss=0.294542521238327
[10/23] Train loss=0.3067101836204529
[15/23] Train loss=0.23190391063690186
[20/23] Train loss=0.2330903708934784
Test set avg_accuracy=82.83% avg_sensitivity=53.72%, avg_specificity=91.60% avg_auc=0.8633
Fold[8] Epoch: 83 [83/100 (83%)] Train loss=0.280394 Test loss=0.418351 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28509068489074707
[5/23] Train loss=0.3001636564731598
[10/23] Train loss=0.3070935606956482
[15/23] Train loss=0.24232275784015656
[20/23] Train loss=0.23247462511062622
Test set avg_accuracy=82.82% avg_sensitivity=51.59%, avg_specificity=92.22% avg_auc=0.8605
Fold[8] Epoch: 84 [84/100 (84%)] Train loss=0.280104 Test loss=0.423567 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2880987226963043
[5/23] Train loss=0.2855217158794403
[10/23] Train loss=0.30178365111351013
[15/23] Train loss=0.23528608679771423
[20/23] Train loss=0.2328997552394867
Test set avg_accuracy=82.90% avg_sensitivity=50.10%, avg_specificity=92.78% avg_auc=0.8579
Fold[8] Epoch: 85 [85/100 (85%)] Train loss=0.279744 Test loss=0.434864 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29088085889816284
[5/23] Train loss=0.2880443036556244
[10/23] Train loss=0.3045823276042938
[15/23] Train loss=0.23237179219722748
[20/23] Train loss=0.22433795034885406
Test set avg_accuracy=83.14% avg_sensitivity=50.15%, avg_specificity=93.07% avg_auc=0.8666
Fold[8] Epoch: 86 [86/100 (86%)] Train loss=0.280165 Test loss=0.424979 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2817980647087097
[5/23] Train loss=0.2930498421192169
[10/23] Train loss=0.31261706352233887
[15/23] Train loss=0.22719821333885193
[20/23] Train loss=0.2208113968372345
Test set avg_accuracy=82.77% avg_sensitivity=50.94%, avg_specificity=92.34% avg_auc=0.8571
Fold[8] Epoch: 87 [87/100 (87%)] Train loss=0.279047 Test loss=0.447108 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2786327004432678
[5/23] Train loss=0.27629345655441284
[10/23] Train loss=0.3032022714614868
[15/23] Train loss=0.23755201697349548
[20/23] Train loss=0.22686171531677246
Test set avg_accuracy=82.89% avg_sensitivity=48.76%, avg_specificity=93.16% avg_auc=0.8597
Fold[8] Epoch: 88 [88/100 (88%)] Train loss=0.277548 Test loss=0.450053 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29215577244758606
[5/23] Train loss=0.28837940096855164
[10/23] Train loss=0.29588761925697327
[15/23] Train loss=0.2377958595752716
[20/23] Train loss=0.257536917924881
Test set avg_accuracy=82.69% avg_sensitivity=47.37%, avg_specificity=93.31% avg_auc=0.8599
Fold[8] Epoch: 89 [89/100 (89%)] Train loss=0.283256 Test loss=0.463110 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27967458963394165
[5/23] Train loss=0.28370118141174316
[10/23] Train loss=0.30976754426956177
[15/23] Train loss=0.2352474331855774
[20/23] Train loss=0.24643032252788544
Test set avg_accuracy=82.82% avg_sensitivity=52.28%, avg_specificity=92.01% avg_auc=0.8529
Fold[8] Epoch: 90 [90/100 (90%)] Train loss=0.283080 Test loss=0.444777 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2781026363372803
[5/23] Train loss=0.29824793338775635
[10/23] Train loss=0.29156967997550964
[15/23] Train loss=0.22348061203956604
[20/23] Train loss=0.22469940781593323
Test set avg_accuracy=83.05% avg_sensitivity=58.63%, avg_specificity=90.40% avg_auc=0.8617
Fold[8] Epoch: 91 [91/100 (91%)] Train loss=0.280965 Test loss=0.413210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2771206796169281
[5/23] Train loss=0.2772793173789978
[10/23] Train loss=0.2934400737285614
[15/23] Train loss=0.21754218637943268
[20/23] Train loss=0.2263423502445221
Test set avg_accuracy=82.79% avg_sensitivity=58.88%, avg_specificity=89.98% avg_auc=0.8584
Fold[8] Epoch: 92 [92/100 (92%)] Train loss=0.269679 Test loss=0.424798 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2718980312347412
[5/23] Train loss=0.27373507618904114
[10/23] Train loss=0.2847435772418976
[15/23] Train loss=0.22820568084716797
[20/23] Train loss=0.21400336921215057
Test set avg_accuracy=82.71% avg_sensitivity=58.18%, avg_specificity=90.09% avg_auc=0.8612
Fold[8] Epoch: 93 [93/100 (93%)] Train loss=0.264479 Test loss=0.427695 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2787724733352661
[5/23] Train loss=0.2635805606842041
[10/23] Train loss=0.2799453139305115
[15/23] Train loss=0.21926607191562653
[20/23] Train loss=0.21700350940227509
Test set avg_accuracy=82.54% avg_sensitivity=52.23%, avg_specificity=91.66% avg_auc=0.8529
Fold[8] Epoch: 94 [94/100 (94%)] Train loss=0.267315 Test loss=0.437343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2626034617424011
[5/23] Train loss=0.2678355276584625
[10/23] Train loss=0.281796395778656
[15/23] Train loss=0.20974159240722656
[20/23] Train loss=0.21808746457099915
Test set avg_accuracy=82.70% avg_sensitivity=55.61%, avg_specificity=90.85% avg_auc=0.8588
Fold[8] Epoch: 95 [95/100 (95%)] Train loss=0.260912 Test loss=0.431650 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25175589323043823
[5/23] Train loss=0.2614407241344452
[10/23] Train loss=0.2851082682609558
[15/23] Train loss=0.1984301507472992
[20/23] Train loss=0.21455414593219757
Test set avg_accuracy=82.79% avg_sensitivity=53.52%, avg_specificity=91.60% avg_auc=0.8573
Fold[8] Epoch: 96 [96/100 (96%)] Train loss=0.257664 Test loss=0.431145 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2558940351009369
[5/23] Train loss=0.26882538199424744
[10/23] Train loss=0.2782742381095886
[15/23] Train loss=0.2177702635526657
[20/23] Train loss=0.2146163433790207
Test set avg_accuracy=82.62% avg_sensitivity=53.37%, avg_specificity=91.42% avg_auc=0.8596
Fold[8] Epoch: 97 [97/100 (97%)] Train loss=0.258214 Test loss=0.443628 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2723236083984375
[5/23] Train loss=0.252593994140625
[10/23] Train loss=0.28074678778648376
[15/23] Train loss=0.21593843400478363
[20/23] Train loss=0.2102718949317932
Test set avg_accuracy=82.81% avg_sensitivity=52.08%, avg_specificity=92.06% avg_auc=0.8627
Fold[8] Epoch: 98 [98/100 (98%)] Train loss=0.255508 Test loss=0.444308 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25535646080970764
[5/23] Train loss=0.2650839388370514
[10/23] Train loss=0.2671377956867218
[15/23] Train loss=0.21314097940921783
[20/23] Train loss=0.2017296403646469
Test set avg_accuracy=82.95% avg_sensitivity=50.25%, avg_specificity=92.79% avg_auc=0.8639
Fold[8] Epoch: 99 [99/100 (99%)] Train loss=0.258586 Test loss=0.446486 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24755394458770752
[5/23] Train loss=0.26470038294792175
[10/23] Train loss=0.27737146615982056
[15/23] Train loss=0.2057315558195114
[20/23] Train loss=0.21494658291339874
Test set avg_accuracy=82.59% avg_sensitivity=50.50%, avg_specificity=92.25% avg_auc=0.8552
Fold[8] Epoch: 100 [100/100 (100%)] Train loss=0.257143 Test loss=0.452763 Current lr=[3.9999999999999996e-05]

Fold[8] Best Result: acc=83.4193918531268 sen=57.341269841269835, spe=91.26735333631886, auc=0.8675587093074777!
[0/23] Train loss=0.7046026587486267
[5/23] Train loss=0.6850548386573792
[10/23] Train loss=0.5816448926925659
[15/23] Train loss=0.5689574480056763
[20/23] Train loss=0.5788918137550354
Test set avg_accuracy=74.63% avg_sensitivity=0.51%, avg_specificity=99.84% avg_auc=0.5772
Best model saved!! Metric=-93.29279877132507!!
Fold[9] Epoch: 1 [1/100 (1%)] Train loss=0.585778 Test loss=0.627935 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5789002776145935
[5/23] Train loss=0.6164810657501221
[10/23] Train loss=0.5376704335212708
[15/23] Train loss=0.563494086265564
[20/23] Train loss=0.5528411269187927
Test set avg_accuracy=74.61% avg_sensitivity=1.12%, avg_specificity=99.60% avg_auc=0.6293
Best model saved!! Metric=-87.7445256909015!!
Fold[9] Epoch: 2 [2/100 (2%)] Train loss=0.560246 Test loss=0.582525 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5575194358825684
[5/23] Train loss=0.6119212508201599
[10/23] Train loss=0.5097734332084656
[15/23] Train loss=0.5396018028259277
[20/23] Train loss=0.5350139737129211
Test set avg_accuracy=75.49% avg_sensitivity=6.74%, avg_specificity=98.88% avg_auc=0.6726
Best model saved!! Metric=-77.63382920824029!!
Fold[9] Epoch: 3 [3/100 (3%)] Train loss=0.545522 Test loss=0.542994 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5420386791229248
[5/23] Train loss=0.5667116045951843
[10/23] Train loss=0.48368310928344727
[15/23] Train loss=0.4945635199546814
[20/23] Train loss=0.5030519366264343
Test set avg_accuracy=76.45% avg_sensitivity=18.78%, avg_specificity=96.06% avg_auc=0.7278
Best model saved!! Metric=-61.9251385834919!!
Fold[9] Epoch: 4 [4/100 (4%)] Train loss=0.519379 Test loss=0.530698 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5171635746955872
[5/23] Train loss=0.5231033563613892
[10/23] Train loss=0.47429221868515015
[15/23] Train loss=0.463461697101593
[20/23] Train loss=0.4700847864151001
Test set avg_accuracy=77.30% avg_sensitivity=27.06%, avg_specificity=94.39% avg_auc=0.7539
Best model saved!! Metric=-51.866674946770885!!
Fold[9] Epoch: 5 [5/100 (5%)] Train loss=0.491835 Test loss=0.531039 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4851076900959015
[5/23] Train loss=0.4875198304653168
[10/23] Train loss=0.48046424984931946
[15/23] Train loss=0.44273778796195984
[20/23] Train loss=0.4636644423007965
Test set avg_accuracy=78.28% avg_sensitivity=34.03%, avg_specificity=93.33% avg_auc=0.7790
Best model saved!! Metric=-42.46683284931325!!
Fold[9] Epoch: 6 [6/100 (6%)] Train loss=0.471000 Test loss=0.530566 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4567766487598419
[5/23] Train loss=0.4624612033367157
[10/23] Train loss=0.4783216118812561
[15/23] Train loss=0.42160719633102417
[20/23] Train loss=0.45469745993614197
Test set avg_accuracy=79.02% avg_sensitivity=38.26%, avg_specificity=92.88% avg_auc=0.7946
Best model saved!! Metric=-36.37152142169704!!
Fold[9] Epoch: 7 [7/100 (7%)] Train loss=0.451737 Test loss=0.518725 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4375452399253845
[5/23] Train loss=0.45508942008018494
[10/23] Train loss=0.469362735748291
[15/23] Train loss=0.4133354127407074
[20/23] Train loss=0.44273966550827026
Test set avg_accuracy=79.19% avg_sensitivity=39.66%, avg_specificity=92.63% avg_auc=0.7996
Best model saved!! Metric=-34.56979550671985!!
Fold[9] Epoch: 8 [8/100 (8%)] Train loss=0.442379 Test loss=0.519270 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42666077613830566
[5/23] Train loss=0.4404727518558502
[10/23] Train loss=0.47894588112831116
[15/23] Train loss=0.4203633964061737
[20/23] Train loss=0.4324638247489929
Test set avg_accuracy=79.07% avg_sensitivity=39.14%, avg_specificity=92.65% avg_auc=0.8019
Fold[9] Epoch: 9 [9/100 (9%)] Train loss=0.439344 Test loss=0.524430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4243193566799164
[5/23] Train loss=0.44172951579093933
[10/23] Train loss=0.4731192886829376
[15/23] Train loss=0.42500096559524536
[20/23] Train loss=0.41917136311531067
Test set avg_accuracy=79.00% avg_sensitivity=38.91%, avg_specificity=92.63% avg_auc=0.8076
Fold[9] Epoch: 10 [10/100 (10%)] Train loss=0.436469 Test loss=0.517804 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4298571050167084
[5/23] Train loss=0.44363969564437866
[10/23] Train loss=0.4694352149963379
[15/23] Train loss=0.41866350173950195
[20/23] Train loss=0.4140179455280304
Test set avg_accuracy=79.74% avg_sensitivity=44.21%, avg_specificity=91.82% avg_auc=0.8099
Best model saved!! Metric=-29.228667785931506!!
Fold[9] Epoch: 11 [11/100 (11%)] Train loss=0.432672 Test loss=0.482490 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4125552177429199
[5/23] Train loss=0.42978435754776
[10/23] Train loss=0.4696560502052307
[15/23] Train loss=0.4057265818119049
[20/23] Train loss=0.4073248505592346
Test set avg_accuracy=79.48% avg_sensitivity=43.19%, avg_specificity=91.82% avg_auc=0.8072
Fold[9] Epoch: 12 [12/100 (12%)] Train loss=0.423706 Test loss=0.500145 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42659279704093933
[5/23] Train loss=0.4277401268482208
[10/23] Train loss=0.4643646478652954
[15/23] Train loss=0.407320111989975
[20/23] Train loss=0.4143742024898529
Test set avg_accuracy=79.34% avg_sensitivity=42.49%, avg_specificity=91.87% avg_auc=0.8162
Fold[9] Epoch: 13 [13/100 (13%)] Train loss=0.422349 Test loss=0.504948 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41308531165122986
[5/23] Train loss=0.4341564178466797
[10/23] Train loss=0.4597799479961395
[15/23] Train loss=0.40552860498428345
[20/23] Train loss=0.41661447286605835
Test set avg_accuracy=79.71% avg_sensitivity=44.77%, avg_specificity=91.59% avg_auc=0.8247
Best model saved!! Metric=-27.46547477196099!!
Fold[9] Epoch: 14 [14/100 (14%)] Train loss=0.421389 Test loss=0.482322 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4018969237804413
[5/23] Train loss=0.42454293370246887
[10/23] Train loss=0.46173250675201416
[15/23] Train loss=0.39640098810195923
[20/23] Train loss=0.4088827669620514
Test set avg_accuracy=79.78% avg_sensitivity=46.82%, avg_specificity=90.99% avg_auc=0.8299
Best model saved!! Metric=-25.434548269154934!!
Fold[9] Epoch: 15 [15/100 (15%)] Train loss=0.411603 Test loss=0.466172 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40934228897094727
[5/23] Train loss=0.41546913981437683
[10/23] Train loss=0.4623695909976959
[15/23] Train loss=0.39248043298721313
[20/23] Train loss=0.3933321237564087
Test set avg_accuracy=79.66% avg_sensitivity=45.65%, avg_specificity=91.22% avg_auc=0.8293
Fold[9] Epoch: 16 [16/100 (16%)] Train loss=0.407458 Test loss=0.470527 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4048692286014557
[5/23] Train loss=0.40872177481651306
[10/23] Train loss=0.45206815004348755
[15/23] Train loss=0.3856683373451233
[20/23] Train loss=0.4005962908267975
Test set avg_accuracy=79.60% avg_sensitivity=44.63%, avg_specificity=91.49% avg_auc=0.8305
Fold[9] Epoch: 17 [17/100 (17%)] Train loss=0.405550 Test loss=0.474530 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39501991868019104
[5/23] Train loss=0.40724244713783264
[10/23] Train loss=0.4650360345840454
[15/23] Train loss=0.3915063440799713
[20/23] Train loss=0.3915247321128845
Test set avg_accuracy=79.79% avg_sensitivity=45.70%, avg_specificity=91.38% avg_auc=0.8354
Fold[9] Epoch: 18 [18/100 (18%)] Train loss=0.406152 Test loss=0.469439 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39432254433631897
[5/23] Train loss=0.41276049613952637
[10/23] Train loss=0.45558568835258484
[15/23] Train loss=0.38727903366088867
[20/23] Train loss=0.3868332505226135
Test set avg_accuracy=80.00% avg_sensitivity=48.72%, avg_specificity=90.64% avg_auc=0.8389
Best model saved!! Metric=-22.748322640044154!!
Fold[9] Epoch: 19 [19/100 (19%)] Train loss=0.399987 Test loss=0.451302 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38923633098602295
[5/23] Train loss=0.4063306748867035
[10/23] Train loss=0.45539140701293945
[15/23] Train loss=0.3771265745162964
[20/23] Train loss=0.38448429107666016
Test set avg_accuracy=80.06% avg_sensitivity=48.30%, avg_specificity=90.86% avg_auc=0.8394
Fold[9] Epoch: 20 [20/100 (20%)] Train loss=0.396341 Test loss=0.453504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3869687616825104
[5/23] Train loss=0.402241587638855
[10/23] Train loss=0.45676252245903015
[15/23] Train loss=0.37954121828079224
[20/23] Train loss=0.37849706411361694
Test set avg_accuracy=80.15% avg_sensitivity=47.70%, avg_specificity=91.19% avg_auc=0.8384
Fold[9] Epoch: 21 [21/100 (21%)] Train loss=0.393992 Test loss=0.458692 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38622838258743286
[5/23] Train loss=0.4038594663143158
[10/23] Train loss=0.4488665759563446
[15/23] Train loss=0.37664738297462463
[20/23] Train loss=0.3775208294391632
Test set avg_accuracy=80.21% avg_sensitivity=49.33%, avg_specificity=90.72% avg_auc=0.8416
Best model saved!! Metric=-21.58846784692983!!
Fold[9] Epoch: 22 [22/100 (22%)] Train loss=0.391563 Test loss=0.449347 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3776348829269409
[5/23] Train loss=0.3965488076210022
[10/23] Train loss=0.4450952708721161
[15/23] Train loss=0.37523844838142395
[20/23] Train loss=0.3772883713245392
Test set avg_accuracy=80.38% avg_sensitivity=49.65%, avg_specificity=90.83% avg_auc=0.8406
Best model saved!! Metric=-21.080121943485427!!
Fold[9] Epoch: 23 [23/100 (23%)] Train loss=0.389033 Test loss=0.452035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3770476281642914
[5/23] Train loss=0.38780373334884644
[10/23] Train loss=0.4482581317424774
[15/23] Train loss=0.3697783350944519
[20/23] Train loss=0.37553325295448303
Test set avg_accuracy=80.45% avg_sensitivity=50.63%, avg_specificity=90.59% avg_auc=0.8432
Best model saved!! Metric=-20.01669331099017!!
Fold[9] Epoch: 24 [24/100 (24%)] Train loss=0.384730 Test loss=0.447772 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37684136629104614
[5/23] Train loss=0.3886010944843292
[10/23] Train loss=0.4447932243347168
[15/23] Train loss=0.36027324199676514
[20/23] Train loss=0.3799135982990265
Test set avg_accuracy=80.29% avg_sensitivity=49.93%, avg_specificity=90.62% avg_auc=0.8422
Fold[9] Epoch: 25 [25/100 (25%)] Train loss=0.384253 Test loss=0.449250 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3722401559352875
[5/23] Train loss=0.3881998062133789
[10/23] Train loss=0.4387510120868683
[15/23] Train loss=0.3715741038322449
[20/23] Train loss=0.366240531206131
Test set avg_accuracy=80.42% avg_sensitivity=50.12%, avg_specificity=90.73% avg_auc=0.8428
Fold[9] Epoch: 26 [26/100 (26%)] Train loss=0.382769 Test loss=0.452478 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37098583579063416
[5/23] Train loss=0.3884056508541107
[10/23] Train loss=0.444713294506073
[15/23] Train loss=0.3674253523349762
[20/23] Train loss=0.3679754137992859
Test set avg_accuracy=80.66% avg_sensitivity=51.65%, avg_specificity=90.53% avg_auc=0.8440
Best model saved!! Metric=-18.761866289846065!!
Fold[9] Epoch: 27 [27/100 (27%)] Train loss=0.381479 Test loss=0.443682 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37037816643714905
[5/23] Train loss=0.38619208335876465
[10/23] Train loss=0.43704524636268616
[15/23] Train loss=0.36285004019737244
[20/23] Train loss=0.37444376945495605
Test set avg_accuracy=80.70% avg_sensitivity=54.02%, avg_specificity=89.77% avg_auc=0.8459
Best model saved!! Metric=-16.92533324491925!!
Fold[9] Epoch: 28 [28/100 (28%)] Train loss=0.380066 Test loss=0.436617 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3675571382045746
[5/23] Train loss=0.38367435336112976
[10/23] Train loss=0.43209409713745117
[15/23] Train loss=0.35511088371276855
[20/23] Train loss=0.3705284297466278
Test set avg_accuracy=80.64% avg_sensitivity=52.53%, avg_specificity=90.20% avg_auc=0.8460
Fold[9] Epoch: 29 [29/100 (29%)] Train loss=0.375515 Test loss=0.441653 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3608132302761078
[5/23] Train loss=0.3818298876285553
[10/23] Train loss=0.43820664286613464
[15/23] Train loss=0.3556913733482361
[20/23] Train loss=0.36975499987602234
Test set avg_accuracy=80.47% avg_sensitivity=49.28%, avg_specificity=91.08% avg_auc=0.8436
Fold[9] Epoch: 30 [30/100 (30%)] Train loss=0.373738 Test loss=0.453924 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36227330565452576
[5/23] Train loss=0.3838255703449249
[10/23] Train loss=0.44034940004348755
[15/23] Train loss=0.3573496639728546
[20/23] Train loss=0.3667701482772827
Test set avg_accuracy=80.65% avg_sensitivity=52.30%, avg_specificity=90.29% avg_auc=0.8450
Fold[9] Epoch: 31 [31/100 (31%)] Train loss=0.374546 Test loss=0.447083 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3588908016681671
[5/23] Train loss=0.3887294828891754
[10/23] Train loss=0.4352991282939911
[15/23] Train loss=0.3522467613220215
[20/23] Train loss=0.3663427531719208
Test set avg_accuracy=80.64% avg_sensitivity=54.72%, avg_specificity=89.45% avg_auc=0.8456
Best model saved!! Metric=-16.629215468283892!!
Fold[9] Epoch: 32 [32/100 (32%)] Train loss=0.371244 Test loss=0.441300 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35489535331726074
[5/23] Train loss=0.37620529532432556
[10/23] Train loss=0.4231971204280853
[15/23] Train loss=0.3457252085208893
[20/23] Train loss=0.36044424772262573
Test set avg_accuracy=80.73% avg_sensitivity=54.21%, avg_specificity=89.75% avg_auc=0.8475
Best model saved!! Metric=-16.553231670755586!!
Fold[9] Epoch: 33 [33/100 (33%)] Train loss=0.367081 Test loss=0.442855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3543948233127594
[5/23] Train loss=0.3762107491493225
[10/23] Train loss=0.4277803301811218
[15/23] Train loss=0.34175077080726624
[20/23] Train loss=0.3565334975719452
Test set avg_accuracy=80.85% avg_sensitivity=54.95%, avg_specificity=89.66% avg_auc=0.8482
Best model saved!! Metric=-15.720740452046964!!
Fold[9] Epoch: 34 [34/100 (34%)] Train loss=0.364930 Test loss=0.442133 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3502742350101471
[5/23] Train loss=0.3783710300922394
[10/23] Train loss=0.4250069260597229
[15/23] Train loss=0.34130528569221497
[20/23] Train loss=0.350019633769989
Test set avg_accuracy=80.92% avg_sensitivity=55.23%, avg_specificity=89.66% avg_auc=0.8465
Best model saved!! Metric=-15.539136933034678!!
Fold[9] Epoch: 35 [35/100 (35%)] Train loss=0.364386 Test loss=0.444122 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3481179475784302
[5/23] Train loss=0.37144970893859863
[10/23] Train loss=0.42210838198661804
[15/23] Train loss=0.3445807993412018
[20/23] Train loss=0.3596027195453644
Test set avg_accuracy=81.07% avg_sensitivity=55.42%, avg_specificity=89.80% avg_auc=0.8476
Best model saved!! Metric=-14.950360269106447!!
Fold[9] Epoch: 36 [36/100 (36%)] Train loss=0.363369 Test loss=0.442340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3484030067920685
[5/23] Train loss=0.3754550516605377
[10/23] Train loss=0.416670024394989
[15/23] Train loss=0.33639827370643616
[20/23] Train loss=0.3525978624820709
Test set avg_accuracy=81.14% avg_sensitivity=55.00%, avg_specificity=90.04% avg_auc=0.8475
Fold[9] Epoch: 37 [37/100 (37%)] Train loss=0.360247 Test loss=0.443880 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3465479016304016
[5/23] Train loss=0.3753642737865448
[10/23] Train loss=0.41740891337394714
[15/23] Train loss=0.3289008140563965
[20/23] Train loss=0.3512454628944397
Test set avg_accuracy=81.29% avg_sensitivity=56.11%, avg_specificity=89.85% avg_auc=0.8484
Best model saved!! Metric=-13.909920978129737!!
Fold[9] Epoch: 38 [38/100 (38%)] Train loss=0.359126 Test loss=0.445183 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3421494960784912
[5/23] Train loss=0.3707066476345062
[10/23] Train loss=0.4096040725708008
[15/23] Train loss=0.3467874825000763
[20/23] Train loss=0.3519952893257141
Test set avg_accuracy=81.04% avg_sensitivity=57.23%, avg_specificity=89.14% avg_auc=0.8486
Best model saved!! Metric=-13.738857465270149!!
Fold[9] Epoch: 39 [39/100 (39%)] Train loss=0.358294 Test loss=0.439569 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34165066480636597
[5/23] Train loss=0.3675774931907654
[10/23] Train loss=0.414044588804245
[15/23] Train loss=0.3389968276023865
[20/23] Train loss=0.3467937707901001
Test set avg_accuracy=80.92% avg_sensitivity=55.65%, avg_specificity=89.52% avg_auc=0.8474
Fold[9] Epoch: 40 [40/100 (40%)] Train loss=0.354459 Test loss=0.446416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33346760272979736
[5/23] Train loss=0.36781105399131775
[10/23] Train loss=0.4135875701904297
[15/23] Train loss=0.3312871754169464
[20/23] Train loss=0.3464898467063904
Test set avg_accuracy=81.10% avg_sensitivity=56.11%, avg_specificity=89.60% avg_auc=0.8488
Fold[9] Epoch: 41 [41/100 (41%)] Train loss=0.354678 Test loss=0.443369 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34427326917648315
[5/23] Train loss=0.37184813618659973
[10/23] Train loss=0.4134405851364136
[15/23] Train loss=0.33425503969192505
[20/23] Train loss=0.3466982841491699
Test set avg_accuracy=81.11% avg_sensitivity=56.67%, avg_specificity=89.42% avg_auc=0.8464
Fold[9] Epoch: 42 [42/100 (42%)] Train loss=0.353140 Test loss=0.444234 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3358047604560852
[5/23] Train loss=0.3616522550582886
[10/23] Train loss=0.40598157048225403
[15/23] Train loss=0.3276118338108063
[20/23] Train loss=0.34541934728622437
Test set avg_accuracy=81.16% avg_sensitivity=56.62%, avg_specificity=89.50% avg_auc=0.8492
Fold[9] Epoch: 43 [43/100 (43%)] Train loss=0.349555 Test loss=0.445713 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33825773000717163
[5/23] Train loss=0.35699981451034546
[10/23] Train loss=0.40515729784965515
[15/23] Train loss=0.32873496413230896
[20/23] Train loss=0.3352377116680145
Test set avg_accuracy=81.30% avg_sensitivity=57.79%, avg_specificity=89.29% avg_auc=0.8498
Best model saved!! Metric=-12.644141173884988!!
Fold[9] Epoch: 44 [44/100 (44%)] Train loss=0.348877 Test loss=0.440448 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3336254954338074
[5/23] Train loss=0.35735782980918884
[10/23] Train loss=0.4113796353340149
[15/23] Train loss=0.3269854187965393
[20/23] Train loss=0.33580055832862854
Test set avg_accuracy=81.36% avg_sensitivity=57.69%, avg_specificity=89.41% avg_auc=0.8495
Best model saved!! Metric=-12.590444454754563!!
Fold[9] Epoch: 45 [45/100 (45%)] Train loss=0.344686 Test loss=0.443644 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33881649374961853
[5/23] Train loss=0.3508356809616089
[10/23] Train loss=0.4044174551963806
[15/23] Train loss=0.32898956537246704
[20/23] Train loss=0.3377174735069275
Test set avg_accuracy=81.38% avg_sensitivity=56.44%, avg_specificity=89.86% avg_auc=0.8494
Fold[9] Epoch: 46 [46/100 (46%)] Train loss=0.345444 Test loss=0.443810 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3456723988056183
[5/23] Train loss=0.35909709334373474
[10/23] Train loss=0.39369872212409973
[15/23] Train loss=0.32004913687705994
[20/23] Train loss=0.33057594299316406
Test set avg_accuracy=81.62% avg_sensitivity=57.18%, avg_specificity=89.93% avg_auc=0.8512
Best model saved!! Metric=-12.152329641110503!!
Fold[9] Epoch: 47 [47/100 (47%)] Train loss=0.343008 Test loss=0.437021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3292113244533539
[5/23] Train loss=0.35775962471961975
[10/23] Train loss=0.39624324440956116
[15/23] Train loss=0.3218201994895935
[20/23] Train loss=0.34326186776161194
Test set avg_accuracy=81.26% avg_sensitivity=58.21%, avg_specificity=89.10% avg_auc=0.8489
Fold[9] Epoch: 48 [48/100 (48%)] Train loss=0.342024 Test loss=0.447328 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3296705484390259
[5/23] Train loss=0.3516141176223755
[10/23] Train loss=0.39491623640060425
[15/23] Train loss=0.31809794902801514
[20/23] Train loss=0.3256416618824005
Test set avg_accuracy=81.59% avg_sensitivity=57.32%, avg_specificity=89.85% avg_auc=0.8513
Best model saved!! Metric=-12.102073016560672!!
Fold[9] Epoch: 49 [49/100 (49%)] Train loss=0.340535 Test loss=0.444303 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32774487137794495
[5/23] Train loss=0.3489281237125397
[10/23] Train loss=0.39659640192985535
[15/23] Train loss=0.3155224621295929
[20/23] Train loss=0.3314952850341797
Test set avg_accuracy=81.56% avg_sensitivity=58.48%, avg_specificity=89.41% avg_auc=0.8508
Best model saved!! Metric=-11.473856570863289!!
Fold[9] Epoch: 50 [50/100 (50%)] Train loss=0.338742 Test loss=0.440866 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3238285481929779
[5/23] Train loss=0.3490543067455292
[10/23] Train loss=0.39492371678352356
[15/23] Train loss=0.3125639855861664
[20/23] Train loss=0.3155214786529541
Test set avg_accuracy=81.60% avg_sensitivity=58.95%, avg_specificity=89.31% avg_auc=0.8504
Best model saved!! Metric=-11.09592489150491!!
Fold[9] Epoch: 51 [51/100 (51%)] Train loss=0.333079 Test loss=0.444909 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3227393329143524
[5/23] Train loss=0.34879931807518005
[10/23] Train loss=0.3909218907356262
[15/23] Train loss=0.31223049759864807
[20/23] Train loss=0.31973880529403687
Test set avg_accuracy=81.82% avg_sensitivity=57.93%, avg_specificity=89.94% avg_auc=0.8508
Fold[9] Epoch: 52 [52/100 (52%)] Train loss=0.335190 Test loss=0.445364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3266421854496002
[5/23] Train loss=0.3409002423286438
[10/23] Train loss=0.3839836120605469
[15/23] Train loss=0.3083186447620392
[20/23] Train loss=0.3219844102859497
Test set avg_accuracy=81.82% avg_sensitivity=57.32%, avg_specificity=90.15% avg_auc=0.8516
Fold[9] Epoch: 53 [53/100 (53%)] Train loss=0.332548 Test loss=0.448003 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32818591594696045
[5/23] Train loss=0.34483179450035095
[10/23] Train loss=0.3820611536502838
[15/23] Train loss=0.31009039282798767
[20/23] Train loss=0.3237220346927643
Test set avg_accuracy=81.81% avg_sensitivity=57.74%, avg_specificity=89.99% avg_auc=0.8533
Fold[9] Epoch: 54 [54/100 (54%)] Train loss=0.332456 Test loss=0.440612 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3201702833175659
[5/23] Train loss=0.3414774239063263
[10/23] Train loss=0.3852454125881195
[15/23] Train loss=0.31063511967658997
[20/23] Train loss=0.3144826889038086
Test set avg_accuracy=81.56% avg_sensitivity=58.81%, avg_specificity=89.29% avg_auc=0.8501
Fold[9] Epoch: 55 [55/100 (55%)] Train loss=0.328927 Test loss=0.443930 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32652145624160767
[5/23] Train loss=0.33840519189834595
[10/23] Train loss=0.383907675743103
[15/23] Train loss=0.3034844994544983
[20/23] Train loss=0.31795239448547363
Test set avg_accuracy=81.49% avg_sensitivity=60.20%, avg_specificity=88.73% avg_auc=0.8514
Best model saved!! Metric=-10.440673474880146!!
Fold[9] Epoch: 56 [56/100 (56%)] Train loss=0.327492 Test loss=0.440645 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3248679041862488
[5/23] Train loss=0.3297024071216583
[10/23] Train loss=0.3721790015697479
[15/23] Train loss=0.2905489206314087
[20/23] Train loss=0.3100617527961731
Test set avg_accuracy=81.50% avg_sensitivity=59.74%, avg_specificity=88.90% avg_auc=0.8512
Fold[9] Epoch: 57 [57/100 (57%)] Train loss=0.322768 Test loss=0.446711 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31948167085647583
[5/23] Train loss=0.33390572667121887
[10/23] Train loss=0.37385523319244385
[15/23] Train loss=0.29148778319358826
[20/23] Train loss=0.31807756423950195
Test set avg_accuracy=81.38% avg_sensitivity=58.81%, avg_specificity=89.06% avg_auc=0.8524
Fold[9] Epoch: 58 [58/100 (58%)] Train loss=0.320770 Test loss=0.449111 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3177286386489868
[5/23] Train loss=0.3288429379463196
[10/23] Train loss=0.37053561210632324
[15/23] Train loss=0.3007611632347107
[20/23] Train loss=0.31442752480506897
Test set avg_accuracy=81.46% avg_sensitivity=58.30%, avg_specificity=89.34% avg_auc=0.8495
Fold[9] Epoch: 59 [59/100 (59%)] Train loss=0.319946 Test loss=0.448673 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3131633400917053
[5/23] Train loss=0.3283654451370239
[10/23] Train loss=0.3691980242729187
[15/23] Train loss=0.28805211186408997
[20/23] Train loss=0.30795013904571533
Test set avg_accuracy=81.46% avg_sensitivity=59.04%, avg_specificity=89.09% avg_auc=0.8508
Fold[9] Epoch: 60 [60/100 (60%)] Train loss=0.318140 Test loss=0.448870 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.303488165140152
[5/23] Train loss=0.3318302035331726
[10/23] Train loss=0.3621816337108612
[15/23] Train loss=0.28617003560066223
[20/23] Train loss=0.29975658655166626
Test set avg_accuracy=81.66% avg_sensitivity=59.51%, avg_specificity=89.20% avg_auc=0.8513
Fold[9] Epoch: 61 [61/100 (61%)] Train loss=0.315898 Test loss=0.452850 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30867406725883484
[5/23] Train loss=0.321996808052063
[10/23] Train loss=0.3576250970363617
[15/23] Train loss=0.2944736182689667
[20/23] Train loss=0.3088286519050598
Test set avg_accuracy=81.36% avg_sensitivity=59.09%, avg_specificity=88.93% avg_auc=0.8507
Fold[9] Epoch: 62 [62/100 (62%)] Train loss=0.312876 Test loss=0.454719 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30311986804008484
[5/23] Train loss=0.3217398226261139
[10/23] Train loss=0.3595851957798004
[15/23] Train loss=0.2787819802761078
[20/23] Train loss=0.3039397895336151
Test set avg_accuracy=81.73% avg_sensitivity=57.18%, avg_specificity=90.09% avg_auc=0.8507
Fold[9] Epoch: 63 [63/100 (63%)] Train loss=0.313016 Test loss=0.451158 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3108445405960083
[5/23] Train loss=0.3297039270401001
[10/23] Train loss=0.35318318009376526
[15/23] Train loss=0.2875594198703766
[20/23] Train loss=0.31016024947166443
Test set avg_accuracy=81.58% avg_sensitivity=56.72%, avg_specificity=90.04% avg_auc=0.8509
Fold[9] Epoch: 64 [64/100 (64%)] Train loss=0.314334 Test loss=0.458733 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30341997742652893
[5/23] Train loss=0.326667457818985
[10/23] Train loss=0.36409586668014526
[15/23] Train loss=0.29361477494239807
[20/23] Train loss=0.3078263998031616
Test set avg_accuracy=81.00% avg_sensitivity=55.37%, avg_specificity=89.72% avg_auc=0.8490
Fold[9] Epoch: 65 [65/100 (65%)] Train loss=0.314733 Test loss=0.458310 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3077315390110016
[5/23] Train loss=0.3366100490093231
[10/23] Train loss=0.36062294244766235
[15/23] Train loss=0.28088557720184326
[20/23] Train loss=0.2964887022972107
Test set avg_accuracy=81.42% avg_sensitivity=59.09%, avg_specificity=89.01% avg_auc=0.8494
Fold[9] Epoch: 66 [66/100 (66%)] Train loss=0.313099 Test loss=0.456978 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3103092312812805
[5/23] Train loss=0.32577866315841675
[10/23] Train loss=0.3431108593940735
[15/23] Train loss=0.279697060585022
[20/23] Train loss=0.29172492027282715
Test set avg_accuracy=81.57% avg_sensitivity=59.37%, avg_specificity=89.12% avg_auc=0.8499
Fold[9] Epoch: 67 [67/100 (67%)] Train loss=0.306999 Test loss=0.463939 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3042292296886444
[5/23] Train loss=0.3167438507080078
[10/23] Train loss=0.33757641911506653
[15/23] Train loss=0.28319671750068665
[20/23] Train loss=0.2880380153656006
Test set avg_accuracy=81.68% avg_sensitivity=59.93%, avg_specificity=89.07% avg_auc=0.8505
Best model saved!! Metric=-10.279494624949233!!
Fold[9] Epoch: 68 [68/100 (68%)] Train loss=0.305247 Test loss=0.458143 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3038208782672882
[5/23] Train loss=0.31973859667778015
[10/23] Train loss=0.33975479006767273
[15/23] Train loss=0.2728078067302704
[20/23] Train loss=0.28818050026893616
Test set avg_accuracy=81.17% avg_sensitivity=57.09%, avg_specificity=89.36% avg_auc=0.8506
Fold[9] Epoch: 69 [69/100 (69%)] Train loss=0.304928 Test loss=0.452824 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29730191826820374
[5/23] Train loss=0.3180597126483917
[10/23] Train loss=0.345223069190979
[15/23] Train loss=0.2721579968929291
[20/23] Train loss=0.2830199897289276
Test set avg_accuracy=81.38% avg_sensitivity=58.95%, avg_specificity=89.01% avg_auc=0.8498
Fold[9] Epoch: 70 [70/100 (70%)] Train loss=0.302380 Test loss=0.452546 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2975011169910431
[5/23] Train loss=0.3153790533542633
[10/23] Train loss=0.33443835377693176
[15/23] Train loss=0.2725943922996521
[20/23] Train loss=0.2815987765789032
Test set avg_accuracy=81.47% avg_sensitivity=61.74%, avg_specificity=88.19% avg_auc=0.8505
Best model saved!! Metric=-9.545851632008443!!
Fold[9] Epoch: 71 [71/100 (71%)] Train loss=0.301633 Test loss=0.452946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29933133721351624
[5/23] Train loss=0.31608712673187256
[10/23] Train loss=0.34256651997566223
[15/23] Train loss=0.2574767768383026
[20/23] Train loss=0.28356075286865234
Test set avg_accuracy=81.47% avg_sensitivity=62.72%, avg_specificity=87.86% avg_auc=0.8526
Best model saved!! Metric=-8.694519962435042!!
Fold[9] Epoch: 72 [72/100 (72%)] Train loss=0.298375 Test loss=0.457097 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29385673999786377
[5/23] Train loss=0.31119105219841003
[10/23] Train loss=0.3320334255695343
[15/23] Train loss=0.26295533776283264
[20/23] Train loss=0.28106823563575745
Test set avg_accuracy=81.52% avg_sensitivity=62.67%, avg_specificity=87.93% avg_auc=0.8522
Best model saved!! Metric=-8.658727958340604!!
Fold[9] Epoch: 73 [73/100 (73%)] Train loss=0.295747 Test loss=0.460620 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30003970861434937
[5/23] Train loss=0.29151061177253723
[10/23] Train loss=0.32389572262763977
[15/23] Train loss=0.26719337701797485
[20/23] Train loss=0.27694153785705566
Test set avg_accuracy=81.59% avg_sensitivity=61.88%, avg_specificity=88.30% avg_auc=0.8507
Fold[9] Epoch: 74 [74/100 (74%)] Train loss=0.290331 Test loss=0.458708 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2917574346065521
[5/23] Train loss=0.3015158772468567
[10/23] Train loss=0.3357793986797333
[15/23] Train loss=0.25730037689208984
[20/23] Train loss=0.2682264745235443
Test set avg_accuracy=81.49% avg_sensitivity=59.83%, avg_specificity=88.85% avg_auc=0.8510
Fold[9] Epoch: 75 [75/100 (75%)] Train loss=0.290323 Test loss=0.457863 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28767719864845276
[5/23] Train loss=0.2887835204601288
[10/23] Train loss=0.3246500790119171
[15/23] Train loss=0.25942546129226685
[20/23] Train loss=0.28154444694519043
Test set avg_accuracy=81.58% avg_sensitivity=58.30%, avg_specificity=89.50% avg_auc=0.8521
Fold[9] Epoch: 76 [76/100 (76%)] Train loss=0.286537 Test loss=0.457981 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2910718619823456
[5/23] Train loss=0.29376861453056335
[10/23] Train loss=0.3258965313434601
[15/23] Train loss=0.2501639723777771
[20/23] Train loss=0.2801951467990875
Test set avg_accuracy=81.30% avg_sensitivity=54.07%, avg_specificity=90.56% avg_auc=0.8502
Fold[9] Epoch: 77 [77/100 (77%)] Train loss=0.288409 Test loss=0.463078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28415924310684204
[5/23] Train loss=0.3076287806034088
[10/23] Train loss=0.3373180329799652
[15/23] Train loss=0.2594076991081238
[20/23] Train loss=0.2791597843170166
Test set avg_accuracy=81.31% avg_sensitivity=53.05%, avg_specificity=90.92% avg_auc=0.8505
Fold[9] Epoch: 78 [78/100 (78%)] Train loss=0.289079 Test loss=0.467544 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3096279799938202
[5/23] Train loss=0.3121626675128937
[10/23] Train loss=0.3159911036491394
[15/23] Train loss=0.2565598785877228
[20/23] Train loss=0.2713257968425751
Test set avg_accuracy=81.43% avg_sensitivity=55.56%, avg_specificity=90.23% avg_auc=0.8512
Fold[9] Epoch: 79 [79/100 (79%)] Train loss=0.289726 Test loss=0.463744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28768154978752136
[5/23] Train loss=0.30298081040382385
[10/23] Train loss=0.29897627234458923
[15/23] Train loss=0.26398366689682007
[20/23] Train loss=0.26208552718162537
Test set avg_accuracy=81.57% avg_sensitivity=58.11%, avg_specificity=89.55% avg_auc=0.8508
Fold[9] Epoch: 80 [80/100 (80%)] Train loss=0.287291 Test loss=0.469215 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28726425766944885
[5/23] Train loss=0.2907719612121582
[10/23] Train loss=0.3015976846218109
[15/23] Train loss=0.2571299076080322
[20/23] Train loss=0.2632819414138794
Test set avg_accuracy=81.55% avg_sensitivity=61.92%, avg_specificity=88.22% avg_auc=0.8511
Fold[9] Epoch: 81 [81/100 (81%)] Train loss=0.284961 Test loss=0.481785 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28261587023735046
[5/23] Train loss=0.2910231649875641
[10/23] Train loss=0.3083552122116089
[15/23] Train loss=0.25418806076049805
[20/23] Train loss=0.26710063219070435
Test set avg_accuracy=81.31% avg_sensitivity=60.07%, avg_specificity=88.54% avg_auc=0.8492
Fold[9] Epoch: 82 [82/100 (82%)] Train loss=0.281392 Test loss=0.483363 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2759970724582672
[5/23] Train loss=0.2901308834552765
[10/23] Train loss=0.31269779801368713
[15/23] Train loss=0.2530513405799866
[20/23] Train loss=0.26563560962677
Test set avg_accuracy=81.53% avg_sensitivity=59.51%, avg_specificity=89.03% avg_auc=0.8482
Fold[9] Epoch: 83 [83/100 (83%)] Train loss=0.282155 Test loss=0.468416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2675337493419647
[5/23] Train loss=0.2809390425682068
[10/23] Train loss=0.31061607599258423
[15/23] Train loss=0.23231637477874756
[20/23] Train loss=0.25686579942703247
Test set avg_accuracy=81.42% avg_sensitivity=60.67%, avg_specificity=88.47% avg_auc=0.8520
Fold[9] Epoch: 84 [84/100 (84%)] Train loss=0.274026 Test loss=0.465214 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2652801275253296
[5/23] Train loss=0.2866929769515991
[10/23] Train loss=0.2983090877532959
[15/23] Train loss=0.2412634640932083
[20/23] Train loss=0.2555898427963257
Test set avg_accuracy=81.62% avg_sensitivity=60.02%, avg_specificity=88.96% avg_auc=0.8529
Fold[9] Epoch: 85 [85/100 (85%)] Train loss=0.271617 Test loss=0.464334 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27434393763542175
[5/23] Train loss=0.2818774878978729
[10/23] Train loss=0.2962075471878052
[15/23] Train loss=0.24176645278930664
[20/23] Train loss=0.25612208247184753
Test set avg_accuracy=81.58% avg_sensitivity=58.25%, avg_specificity=89.52% avg_auc=0.8522
Fold[9] Epoch: 86 [86/100 (86%)] Train loss=0.272454 Test loss=0.471343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2681550681591034
[5/23] Train loss=0.28236958384513855
[10/23] Train loss=0.29879477620124817
[15/23] Train loss=0.23621080815792084
[20/23] Train loss=0.24775578081607819
Test set avg_accuracy=81.49% avg_sensitivity=58.02%, avg_specificity=89.47% avg_auc=0.8516
Fold[9] Epoch: 87 [87/100 (87%)] Train loss=0.268893 Test loss=0.472252 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2756320536136627
[5/23] Train loss=0.2787134051322937
[10/23] Train loss=0.2962358593940735
[15/23] Train loss=0.2397506833076477
[20/23] Train loss=0.24750322103500366
Test set avg_accuracy=80.98% avg_sensitivity=55.42%, avg_specificity=89.67% avg_auc=0.8479
Fold[9] Epoch: 88 [88/100 (88%)] Train loss=0.268615 Test loss=0.483292 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2684292793273926
[5/23] Train loss=0.2804763615131378
[10/23] Train loss=0.28339648246765137
[15/23] Train loss=0.23308417201042175
[20/23] Train loss=0.24436071515083313
Test set avg_accuracy=81.32% avg_sensitivity=59.09%, avg_specificity=88.88% avg_auc=0.8508
Fold[9] Epoch: 89 [89/100 (89%)] Train loss=0.262389 Test loss=0.470841 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2690230906009674
[5/23] Train loss=0.2775484621524811
[10/23] Train loss=0.2988612651824951
[15/23] Train loss=0.22972360253334045
[20/23] Train loss=0.24251572787761688
Test set avg_accuracy=81.45% avg_sensitivity=59.97%, avg_specificity=88.76% avg_auc=0.8513
Fold[9] Epoch: 90 [90/100 (90%)] Train loss=0.264749 Test loss=0.480469 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25620564818382263
[5/23] Train loss=0.2746692895889282
[10/23] Train loss=0.2838321626186371
[15/23] Train loss=0.22867819666862488
[20/23] Train loss=0.23744440078735352
Test set avg_accuracy=81.60% avg_sensitivity=61.04%, avg_specificity=88.60% avg_auc=0.8534
Fold[9] Epoch: 91 [91/100 (91%)] Train loss=0.259777 Test loss=0.485783 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26275476813316345
[5/23] Train loss=0.2658366560935974
[10/23] Train loss=0.2752389907836914
[15/23] Train loss=0.22993583977222443
[20/23] Train loss=0.24100936949253082
Test set avg_accuracy=81.37% avg_sensitivity=61.46%, avg_specificity=88.14% avg_auc=0.8486
Fold[9] Epoch: 92 [92/100 (92%)] Train loss=0.261159 Test loss=0.492952 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2659701108932495
[5/23] Train loss=0.26717814803123474
[10/23] Train loss=0.29314008355140686
[15/23] Train loss=0.22354722023010254
[20/23] Train loss=0.24940422177314758
Test set avg_accuracy=81.19% avg_sensitivity=60.53%, avg_specificity=88.22% avg_auc=0.8473
Fold[9] Epoch: 93 [93/100 (93%)] Train loss=0.258719 Test loss=0.476507 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2636078894138336
[5/23] Train loss=0.26191967725753784
[10/23] Train loss=0.26696476340293884
[15/23] Train loss=0.22465136647224426
[20/23] Train loss=0.23711811006069183
Test set avg_accuracy=81.38% avg_sensitivity=61.55%, avg_specificity=88.12% avg_auc=0.8434
Fold[9] Epoch: 94 [94/100 (94%)] Train loss=0.258330 Test loss=0.485242 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25696033239364624
[5/23] Train loss=0.2797887921333313
[10/23] Train loss=0.27012985944747925
[15/23] Train loss=0.22205428779125214
[20/23] Train loss=0.23709659278392792
Test set avg_accuracy=81.58% avg_sensitivity=60.30%, avg_specificity=88.82% avg_auc=0.8477
Fold[9] Epoch: 95 [95/100 (95%)] Train loss=0.261006 Test loss=0.487417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.253481924533844
[5/23] Train loss=0.26486992835998535
[10/23] Train loss=0.29128319025039673
[15/23] Train loss=0.2323274463415146
[20/23] Train loss=0.23446516692638397
Test set avg_accuracy=81.69% avg_sensitivity=59.97%, avg_specificity=89.07% avg_auc=0.8528
Fold[9] Epoch: 96 [96/100 (96%)] Train loss=0.253697 Test loss=0.488059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25829795002937317
[5/23] Train loss=0.2636036276817322
[10/23] Train loss=0.2728475034236908
[15/23] Train loss=0.24211713671684265
[20/23] Train loss=0.2401161640882492
Test set avg_accuracy=81.57% avg_sensitivity=53.60%, avg_specificity=91.08% avg_auc=0.8505
Fold[9] Epoch: 97 [97/100 (97%)] Train loss=0.260045 Test loss=0.492380 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2543693780899048
[5/23] Train loss=0.2660619020462036
[10/23] Train loss=0.2753082513809204
[15/23] Train loss=0.2231614738702774
[20/23] Train loss=0.2295445203781128
Test set avg_accuracy=81.23% avg_sensitivity=55.42%, avg_specificity=90.01% avg_auc=0.8484
Fold[9] Epoch: 98 [98/100 (98%)] Train loss=0.254086 Test loss=0.487701 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2526695132255554
[5/23] Train loss=0.26488202810287476
[10/23] Train loss=0.2792958617210388
[15/23] Train loss=0.22678402066230774
[20/23] Train loss=0.22847682237625122
Test set avg_accuracy=81.38% avg_sensitivity=61.60%, avg_specificity=88.11% avg_auc=0.8489
Fold[9] Epoch: 99 [99/100 (99%)] Train loss=0.254851 Test loss=0.487659 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2602860927581787
[5/23] Train loss=0.2681335508823395
[10/23] Train loss=0.25821465253829956
[15/23] Train loss=0.20840118825435638
[20/23] Train loss=0.23023587465286255
Test set avg_accuracy=81.44% avg_sensitivity=64.95%, avg_specificity=87.05% avg_auc=0.8514
Best model saved!! Metric=-7.42019978198182!!
Fold[9] Epoch: 100 [100/100 (100%)] Train loss=0.247806 Test loss=0.496966 Current lr=[3.9999999999999996e-05]

Fold[9] Best Result: acc=81.43952802359881 sen=64.94653649465366, spe=87.0493358633776, auc=0.8514439983638811!
[0/23] Train loss=0.7165992259979248
[5/23] Train loss=0.6958315968513489
[10/23] Train loss=0.581922173500061
[15/23] Train loss=0.5738610029220581
[20/23] Train loss=0.6249651908874512
Test set avg_accuracy=77.58% avg_sensitivity=0.10%, avg_specificity=100.00% avg_auc=0.5534
Best model saved!! Metric=-92.9754947457273!!
Fold[10] Epoch: 1 [1/100 (1%)] Train loss=0.594582 Test loss=0.571437 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5805323123931885
[5/23] Train loss=0.6139631867408752
[10/23] Train loss=0.5451952815055847
[15/23] Train loss=0.5576536059379578
[20/23] Train loss=0.6087680459022522
Test set avg_accuracy=77.57% avg_sensitivity=0.26%, avg_specificity=99.94% avg_auc=0.5563
Best model saved!! Metric=-92.6105835178546!!
Fold[10] Epoch: 2 [2/100 (2%)] Train loss=0.565617 Test loss=0.554160 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5600106716156006
[5/23] Train loss=0.605036199092865
[10/23] Train loss=0.5112869143486023
[15/23] Train loss=0.5360308885574341
[20/23] Train loss=0.5845077633857727
Test set avg_accuracy=76.91% avg_sensitivity=3.24%, avg_specificity=98.23% avg_auc=0.6263
Best model saved!! Metric=-84.99421369515834!!
Fold[10] Epoch: 3 [3/100 (3%)] Train loss=0.549666 Test loss=0.532673 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5404269695281982
[5/23] Train loss=0.5537706613540649
[10/23] Train loss=0.48379871249198914
[15/23] Train loss=0.4877574145793915
[20/23] Train loss=0.5599823594093323
Test set avg_accuracy=77.58% avg_sensitivity=14.03%, avg_specificity=95.97% avg_auc=0.7034
Best model saved!! Metric=-68.08016498251314!!
Fold[10] Epoch: 4 [4/100 (4%)] Train loss=0.522235 Test loss=0.523575 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.512239396572113
[5/23] Train loss=0.5021935105323792
[10/23] Train loss=0.481414258480072
[15/23] Train loss=0.4504510164260864
[20/23] Train loss=0.5651779770851135
Test set avg_accuracy=78.45% avg_sensitivity=20.09%, avg_specificity=95.35% avg_auc=0.7404
Best model saved!! Metric=-58.06934696489298!!
Fold[10] Epoch: 5 [5/100 (5%)] Train loss=0.494288 Test loss=0.533648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.47876137495040894
[5/23] Train loss=0.48361140489578247
[10/23] Train loss=0.48171356320381165
[15/23] Train loss=0.43166929483413696
[20/23] Train loss=0.5753841400146484
Test set avg_accuracy=79.40% avg_sensitivity=24.72%, avg_specificity=95.23% avg_auc=0.7625
Best model saved!! Metric=-50.40778732252866!!
Fold[10] Epoch: 6 [6/100 (6%)] Train loss=0.474518 Test loss=0.525204 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.44799768924713135
[5/23] Train loss=0.4777091145515442
[10/23] Train loss=0.4813704788684845
[15/23] Train loss=0.4167386591434479
[20/23] Train loss=0.5709783434867859
Test set avg_accuracy=80.00% avg_sensitivity=27.13%, avg_specificity=95.30% avg_auc=0.7740
Best model saved!! Metric=-46.16262633642555!!
Fold[10] Epoch: 7 [7/100 (7%)] Train loss=0.462854 Test loss=0.520285 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4380365312099457
[5/23] Train loss=0.47078123688697815
[10/23] Train loss=0.49925464391708374
[15/23] Train loss=0.4228026270866394
[20/23] Train loss=0.5516171455383301
Test set avg_accuracy=80.22% avg_sensitivity=27.85%, avg_specificity=95.37% avg_auc=0.7829
Best model saved!! Metric=-44.262324990652786!!
Fold[10] Epoch: 8 [8/100 (8%)] Train loss=0.456686 Test loss=0.523712 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4284711480140686
[5/23] Train loss=0.45220044255256653
[10/23] Train loss=0.4814315140247345
[15/23] Train loss=0.4243336021900177
[20/23] Train loss=0.5409383177757263
Test set avg_accuracy=80.51% avg_sensitivity=29.65%, avg_specificity=95.23% avg_auc=0.8044
Best model saved!! Metric=-40.1753450350422!!
Fold[10] Epoch: 9 [9/100 (9%)] Train loss=0.449624 Test loss=0.507486 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4212442636489868
[5/23] Train loss=0.4536396265029907
[10/23] Train loss=0.4821620583534241
[15/23] Train loss=0.42600342631340027
[20/23] Train loss=0.5138781666755676
Test set avg_accuracy=80.95% avg_sensitivity=33.61%, avg_specificity=94.65% avg_auc=0.8096
Best model saved!! Metric=-35.84014155467925!!
Fold[10] Epoch: 10 [10/100 (10%)] Train loss=0.442548 Test loss=0.481393 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41714906692504883
[5/23] Train loss=0.4461708962917328
[10/23] Train loss=0.4724314510822296
[15/23] Train loss=0.4106750190258026
[20/23] Train loss=0.5255414843559265
Test set avg_accuracy=81.28% avg_sensitivity=35.92%, avg_specificity=94.41% avg_auc=0.8102
Best model saved!! Metric=-33.36816492969652!!
Fold[10] Epoch: 11 [11/100 (11%)] Train loss=0.437075 Test loss=0.479785 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4169166386127472
[5/23] Train loss=0.43825557827949524
[10/23] Train loss=0.4833938181400299
[15/23] Train loss=0.41124194860458374
[20/23] Train loss=0.530750572681427
Test set avg_accuracy=81.45% avg_sensitivity=35.92%, avg_specificity=94.63% avg_auc=0.8159
Best model saved!! Metric=-32.40311587611129!!
Fold[10] Epoch: 12 [12/100 (12%)] Train loss=0.436255 Test loss=0.488345 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4022243618965149
[5/23] Train loss=0.43092143535614014
[10/23] Train loss=0.47233062982559204
[15/23] Train loss=0.4219759702682495
[20/23] Train loss=0.5188438892364502
Test set avg_accuracy=81.64% avg_sensitivity=36.13%, avg_specificity=94.81% avg_auc=0.8226
Best model saved!! Metric=-31.169752158944036!!
Fold[10] Epoch: 13 [13/100 (13%)] Train loss=0.431475 Test loss=0.475034 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4078199863433838
[5/23] Train loss=0.4235183894634247
[10/23] Train loss=0.46728745102882385
[15/23] Train loss=0.40878933668136597
[20/23] Train loss=0.4984070658683777
Test set avg_accuracy=82.11% avg_sensitivity=40.03%, avg_specificity=94.29% avg_auc=0.8323
Best model saved!! Metric=-26.338032628918782!!
Fold[10] Epoch: 14 [14/100 (14%)] Train loss=0.425289 Test loss=0.445453 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40674272179603577
[5/23] Train loss=0.42380088567733765
[10/23] Train loss=0.46674013137817383
[15/23] Train loss=0.4034880995750427
[20/23] Train loss=0.5047348737716675
Test set avg_accuracy=82.28% avg_sensitivity=41.42%, avg_specificity=94.11% avg_auc=0.8343
Best model saved!! Metric=-24.758034470624835!!
Fold[10] Epoch: 15 [15/100 (15%)] Train loss=0.420505 Test loss=0.443031 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39684614539146423
[5/23] Train loss=0.41747400164604187
[10/23] Train loss=0.4670846462249756
[15/23] Train loss=0.3968210518360138
[20/23] Train loss=0.5050970911979675
Test set avg_accuracy=82.38% avg_sensitivity=42.29%, avg_specificity=93.98% avg_auc=0.8404
Best model saved!! Metric=-23.31918761946654!!
Fold[10] Epoch: 16 [16/100 (16%)] Train loss=0.416245 Test loss=0.431735 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3917991816997528
[5/23] Train loss=0.41498124599456787
[10/23] Train loss=0.46386751532554626
[15/23] Train loss=0.39554840326309204
[20/23] Train loss=0.4892114996910095
Test set avg_accuracy=82.25% avg_sensitivity=42.14%, avg_specificity=93.86% avg_auc=0.8432
Fold[10] Epoch: 17 [17/100 (17%)] Train loss=0.414467 Test loss=0.431191 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.39602962136268616
[5/23] Train loss=0.40801557898521423
[10/23] Train loss=0.45554977655410767
[15/23] Train loss=0.3923169672489166
[20/23] Train loss=0.48406827449798584
Test set avg_accuracy=82.39% avg_sensitivity=43.99%, avg_specificity=93.50% avg_auc=0.8469
Best model saved!! Metric=-21.438121345326238!!
Fold[10] Epoch: 18 [18/100 (18%)] Train loss=0.411815 Test loss=0.420218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3879605531692505
[5/23] Train loss=0.41232234239578247
[10/23] Train loss=0.4591570794582367
[15/23] Train loss=0.3835127353668213
[20/23] Train loss=0.4926871061325073
Test set avg_accuracy=82.61% avg_sensitivity=45.32%, avg_specificity=93.40% avg_auc=0.8482
Best model saved!! Metric=-19.85534621143855!!
Fold[10] Epoch: 19 [19/100 (19%)] Train loss=0.406741 Test loss=0.417026 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38328808546066284
[5/23] Train loss=0.409677118062973
[10/23] Train loss=0.4625585079193115
[15/23] Train loss=0.3869662284851074
[20/23] Train loss=0.4882594048976898
Test set avg_accuracy=82.53% avg_sensitivity=45.99%, avg_specificity=93.10% avg_auc=0.8541
Best model saved!! Metric=-18.969481959270162!!
Fold[10] Epoch: 20 [20/100 (20%)] Train loss=0.407636 Test loss=0.401048 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38198670744895935
[5/23] Train loss=0.40156304836273193
[10/23] Train loss=0.4581950604915619
[15/23] Train loss=0.3858996629714966
[20/23] Train loss=0.4865182638168335
Test set avg_accuracy=82.81% avg_sensitivity=46.40%, avg_specificity=93.35% avg_auc=0.8522
Best model saved!! Metric=-18.20657300945373!!
Fold[10] Epoch: 21 [21/100 (21%)] Train loss=0.404994 Test loss=0.404026 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38200098276138306
[5/23] Train loss=0.39877891540527344
[10/23] Train loss=0.4597279131412506
[15/23] Train loss=0.3781806528568268
[20/23] Train loss=0.484505832195282
Test set avg_accuracy=82.73% avg_sensitivity=49.13%, avg_specificity=92.46% avg_auc=0.8585
Best model saved!! Metric=-15.828821617723602!!
Fold[10] Epoch: 22 [22/100 (22%)] Train loss=0.402539 Test loss=0.388393 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.382142573595047
[5/23] Train loss=0.4002777636051178
[10/23] Train loss=0.4502664804458618
[15/23] Train loss=0.37751278281211853
[20/23] Train loss=0.47729671001434326
Test set avg_accuracy=82.61% avg_sensitivity=48.77%, avg_specificity=92.40% avg_auc=0.8614
Fold[10] Epoch: 23 [23/100 (23%)] Train loss=0.398075 Test loss=0.383889 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38360679149627686
[5/23] Train loss=0.39313259720802307
[10/23] Train loss=0.44997063279151917
[15/23] Train loss=0.3717629611492157
[20/23] Train loss=0.48313799500465393
Test set avg_accuracy=82.93% avg_sensitivity=50.31%, avg_specificity=92.37% avg_auc=0.8615
Best model saved!! Metric=-14.24387170513883!!
Fold[10] Epoch: 24 [24/100 (24%)] Train loss=0.395834 Test loss=0.382285 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3759891092777252
[5/23] Train loss=0.391589492559433
[10/23] Train loss=0.45450136065483093
[15/23] Train loss=0.3703609108924866
[20/23] Train loss=0.4793890714645386
Test set avg_accuracy=83.18% avg_sensitivity=51.13%, avg_specificity=92.46% avg_auc=0.8606
Best model saved!! Metric=-13.162650511250202!!
Fold[10] Epoch: 25 [25/100 (25%)] Train loss=0.393463 Test loss=0.385949 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3721415102481842
[5/23] Train loss=0.38680413365364075
[10/23] Train loss=0.4512414336204529
[15/23] Train loss=0.3612763285636902
[20/23] Train loss=0.4677303731441498
Test set avg_accuracy=83.17% avg_sensitivity=53.08%, avg_specificity=91.88% avg_auc=0.8635
Best model saved!! Metric=-11.516797520258688!!
Fold[10] Epoch: 26 [26/100 (26%)] Train loss=0.390159 Test loss=0.377247 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37722474336624146
[5/23] Train loss=0.3895129859447479
[10/23] Train loss=0.4484493136405945
[15/23] Train loss=0.36287400126457214
[20/23] Train loss=0.4767882227897644
Test set avg_accuracy=83.28% avg_sensitivity=51.85%, avg_specificity=92.37% avg_auc=0.8609
Fold[10] Epoch: 27 [27/100 (27%)] Train loss=0.390627 Test loss=0.384829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37038397789001465
[5/23] Train loss=0.3873404860496521
[10/23] Train loss=0.44075027108192444
[15/23] Train loss=0.3644252419471741
[20/23] Train loss=0.46602800488471985
Test set avg_accuracy=83.34% avg_sensitivity=52.21%, avg_specificity=92.36% avg_auc=0.8632
Fold[10] Epoch: 28 [28/100 (28%)] Train loss=0.387894 Test loss=0.384221 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36958423256874084
[5/23] Train loss=0.3884522616863251
[10/23] Train loss=0.44845476746559143
[15/23] Train loss=0.36294353008270264
[20/23] Train loss=0.4680425226688385
Test set avg_accuracy=83.26% avg_sensitivity=53.55%, avg_specificity=91.86% avg_auc=0.8648
Best model saved!! Metric=-10.84544961292149!!
Fold[10] Epoch: 29 [29/100 (29%)] Train loss=0.385814 Test loss=0.380027 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3616713583469391
[5/23] Train loss=0.38584643602371216
[10/23] Train loss=0.4418413043022156
[15/23] Train loss=0.36611244082450867
[20/23] Train loss=0.45758384466171265
Test set avg_accuracy=83.45% avg_sensitivity=52.62%, avg_specificity=92.37% avg_auc=0.8646
Fold[10] Epoch: 30 [30/100 (30%)] Train loss=0.385297 Test loss=0.377059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36756250262260437
[5/23] Train loss=0.37858203053474426
[10/23] Train loss=0.4399898052215576
[15/23] Train loss=0.35363733768463135
[20/23] Train loss=0.45910128951072693
Test set avg_accuracy=82.56% avg_sensitivity=57.40%, avg_specificity=89.84% avg_auc=0.8574
Best model saved!! Metric=-10.460427185594277!!
Fold[10] Epoch: 31 [31/100 (31%)] Train loss=0.383519 Test loss=0.381527 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3648167550563812
[5/23] Train loss=0.38262447714805603
[10/23] Train loss=0.4342644512653351
[15/23] Train loss=0.3474953770637512
[20/23] Train loss=0.4508722722530365
Test set avg_accuracy=83.23% avg_sensitivity=54.52%, avg_specificity=91.54% avg_auc=0.8687
Best model saved!! Metric=-9.837319545195385!!
Fold[10] Epoch: 32 [32/100 (32%)] Train loss=0.382917 Test loss=0.369563 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35720622539520264
[5/23] Train loss=0.3851034939289093
[10/23] Train loss=0.43891260027885437
[15/23] Train loss=0.34853389859199524
[20/23] Train loss=0.47066718339920044
Test set avg_accuracy=83.29% avg_sensitivity=56.47%, avg_specificity=91.05% avg_auc=0.8707
Best model saved!! Metric=-8.12374502651204!!
Fold[10] Epoch: 33 [33/100 (33%)] Train loss=0.378732 Test loss=0.368607 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35754236578941345
[5/23] Train loss=0.37806349992752075
[10/23] Train loss=0.4272410571575165
[15/23] Train loss=0.34229740500450134
[20/23] Train loss=0.4785153567790985
Test set avg_accuracy=83.04% avg_sensitivity=58.07%, avg_specificity=90.27% avg_auc=0.8639
Fold[10] Epoch: 34 [34/100 (34%)] Train loss=0.375176 Test loss=0.378849 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.354297399520874
[5/23] Train loss=0.37663698196411133
[10/23] Train loss=0.4265322983264923
[15/23] Train loss=0.34518077969551086
[20/23] Train loss=0.4660423994064331
Test set avg_accuracy=83.28% avg_sensitivity=55.14%, avg_specificity=91.42% avg_auc=0.8616
Fold[10] Epoch: 35 [35/100 (35%)] Train loss=0.374815 Test loss=0.377415 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35697054862976074
[5/23] Train loss=0.3789713680744171
[10/23] Train loss=0.4260149598121643
[15/23] Train loss=0.3560350835323334
[20/23] Train loss=0.46754735708236694
Test set avg_accuracy=83.62% avg_sensitivity=51.90%, avg_specificity=92.80% avg_auc=0.8655
Fold[10] Epoch: 36 [36/100 (36%)] Train loss=0.374508 Test loss=0.380991 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3571721613407135
[5/23] Train loss=0.37582990527153015
[10/23] Train loss=0.4231456220149994
[15/23] Train loss=0.3464057445526123
[20/23] Train loss=0.452968567609787
Test set avg_accuracy=83.26% avg_sensitivity=53.75%, avg_specificity=91.81% avg_auc=0.8653
Fold[10] Epoch: 37 [37/100 (37%)] Train loss=0.374508 Test loss=0.375684 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35636425018310547
[5/23] Train loss=0.3672482371330261
[10/23] Train loss=0.41466331481933594
[15/23] Train loss=0.3347264528274536
[20/23] Train loss=0.4380396604537964
Test set avg_accuracy=82.93% avg_sensitivity=58.48%, avg_specificity=90.01% avg_auc=0.8615
Fold[10] Epoch: 38 [38/100 (38%)] Train loss=0.369450 Test loss=0.380651 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3483988046646118
[5/23] Train loss=0.3649637997150421
[10/23] Train loss=0.4179255962371826
[15/23] Train loss=0.3361223340034485
[20/23] Train loss=0.4500599503517151
Test set avg_accuracy=82.76% avg_sensitivity=58.89%, avg_specificity=89.66% avg_auc=0.8582
Fold[10] Epoch: 39 [39/100 (39%)] Train loss=0.363926 Test loss=0.384367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3471285104751587
[5/23] Train loss=0.3652138113975525
[10/23] Train loss=0.40935447812080383
[15/23] Train loss=0.3322712779045105
[20/23] Train loss=0.4603056311607361
Test set avg_accuracy=82.72% avg_sensitivity=58.27%, avg_specificity=89.80% avg_auc=0.8636
Fold[10] Epoch: 40 [40/100 (40%)] Train loss=0.363467 Test loss=0.379467 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35337215662002563
[5/23] Train loss=0.3698023855686188
[10/23] Train loss=0.40682855248451233
[15/23] Train loss=0.32536616921424866
[20/23] Train loss=0.44876009225845337
Test set avg_accuracy=83.10% avg_sensitivity=57.09%, avg_specificity=90.63% avg_auc=0.8663
Fold[10] Epoch: 41 [41/100 (41%)] Train loss=0.361399 Test loss=0.376039 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.344515323638916
[5/23] Train loss=0.36330172419548035
[10/23] Train loss=0.4070221185684204
[15/23] Train loss=0.3245234489440918
[20/23] Train loss=0.4316469430923462
Test set avg_accuracy=83.52% avg_sensitivity=54.98%, avg_specificity=91.78% avg_auc=0.8661
Fold[10] Epoch: 42 [42/100 (42%)] Train loss=0.362094 Test loss=0.379692 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3484165072441101
[5/23] Train loss=0.3599153757095337
[10/23] Train loss=0.4054867625236511
[15/23] Train loss=0.32925471663475037
[20/23] Train loss=0.43225526809692383
Test set avg_accuracy=82.81% avg_sensitivity=57.97%, avg_specificity=90.01% avg_auc=0.8613
Fold[10] Epoch: 43 [43/100 (43%)] Train loss=0.360797 Test loss=0.378092 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3447647988796234
[5/23] Train loss=0.36293086409568787
[10/23] Train loss=0.4019317328929901
[15/23] Train loss=0.3273739814758301
[20/23] Train loss=0.42898309230804443
Test set avg_accuracy=82.68% avg_sensitivity=57.76%, avg_specificity=89.89% avg_auc=0.8636
Fold[10] Epoch: 44 [44/100 (44%)] Train loss=0.358194 Test loss=0.380131 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33875182271003723
[5/23] Train loss=0.3561367392539978
[10/23] Train loss=0.40728726983070374
[15/23] Train loss=0.31772467494010925
[20/23] Train loss=0.43278709053993225
Test set avg_accuracy=82.11% avg_sensitivity=59.87%, avg_specificity=88.55% avg_auc=0.8634
Fold[10] Epoch: 45 [45/100 (45%)] Train loss=0.353084 Test loss=0.385546 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3480064868927002
[5/23] Train loss=0.3587615489959717
[10/23] Train loss=0.390842467546463
[15/23] Train loss=0.3181326687335968
[20/23] Train loss=0.43740254640579224
Test set avg_accuracy=82.12% avg_sensitivity=59.35%, avg_specificity=88.71% avg_auc=0.8567
Fold[10] Epoch: 46 [46/100 (46%)] Train loss=0.350136 Test loss=0.389573 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3331235349178314
[5/23] Train loss=0.3565163016319275
[10/23] Train loss=0.39601078629493713
[15/23] Train loss=0.3103012144565582
[20/23] Train loss=0.4368951916694641
Test set avg_accuracy=82.81% avg_sensitivity=57.91%, avg_specificity=90.02% avg_auc=0.8584
Fold[10] Epoch: 47 [47/100 (47%)] Train loss=0.351191 Test loss=0.385371 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33473265171051025
[5/23] Train loss=0.35422804951667786
[10/23] Train loss=0.401643842458725
[15/23] Train loss=0.3175918161869049
[20/23] Train loss=0.4364435076713562
Test set avg_accuracy=83.32% avg_sensitivity=54.88%, avg_specificity=91.55% avg_auc=0.8647
Fold[10] Epoch: 48 [48/100 (48%)] Train loss=0.351684 Test loss=0.383279 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33366379141807556
[5/23] Train loss=0.3488844335079193
[10/23] Train loss=0.39536407589912415
[15/23] Train loss=0.3249364197254181
[20/23] Train loss=0.43034273386001587
Test set avg_accuracy=83.26% avg_sensitivity=54.93%, avg_specificity=91.46% avg_auc=0.8597
Fold[10] Epoch: 49 [49/100 (49%)] Train loss=0.348470 Test loss=0.378392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33743464946746826
[5/23] Train loss=0.34530895948410034
[10/23] Train loss=0.3952958881855011
[15/23] Train loss=0.32070791721343994
[20/23] Train loss=0.4251534342765808
Test set avg_accuracy=83.09% avg_sensitivity=52.16%, avg_specificity=92.04% avg_auc=0.8606
Fold[10] Epoch: 50 [50/100 (50%)] Train loss=0.350317 Test loss=0.385549 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.335310697555542
[5/23] Train loss=0.35128897428512573
[10/23] Train loss=0.397093266248703
[15/23] Train loss=0.3127177059650421
[20/23] Train loss=0.40567538142204285
Test set avg_accuracy=82.87% avg_sensitivity=55.86%, avg_specificity=90.69% avg_auc=0.8544
Fold[10] Epoch: 51 [51/100 (51%)] Train loss=0.348466 Test loss=0.393416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33350157737731934
[5/23] Train loss=0.33891576528549194
[10/23] Train loss=0.3939386010169983
[15/23] Train loss=0.30762776732444763
[20/23] Train loss=0.4153286814689636
Test set avg_accuracy=81.75% avg_sensitivity=59.25%, avg_specificity=88.27% avg_auc=0.8430
Fold[10] Epoch: 52 [52/100 (52%)] Train loss=0.342706 Test loss=0.409893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3313760757446289
[5/23] Train loss=0.34856167435646057
[10/23] Train loss=0.3868580460548401
[15/23] Train loss=0.30412039160728455
[20/23] Train loss=0.4088212847709656
Test set avg_accuracy=82.84% avg_sensitivity=58.58%, avg_specificity=89.86% avg_auc=0.8609
Fold[10] Epoch: 53 [53/100 (53%)] Train loss=0.341152 Test loss=0.389011 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3295835554599762
[5/23] Train loss=0.3501252233982086
[10/23] Train loss=0.3780839443206787
[15/23] Train loss=0.3048783838748932
[20/23] Train loss=0.4270639717578888
Test set avg_accuracy=82.56% avg_sensitivity=58.32%, avg_specificity=89.57% avg_auc=0.8548
Fold[10] Epoch: 54 [54/100 (54%)] Train loss=0.338262 Test loss=0.394097 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32956087589263916
[5/23] Train loss=0.3414548933506012
[10/23] Train loss=0.39053893089294434
[15/23] Train loss=0.30929237604141235
[20/23] Train loss=0.41017085313796997
Test set avg_accuracy=82.40% avg_sensitivity=59.20%, avg_specificity=89.11% avg_auc=0.8511
Fold[10] Epoch: 55 [55/100 (55%)] Train loss=0.337711 Test loss=0.394143 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3285033702850342
[5/23] Train loss=0.34594252705574036
[10/23] Train loss=0.3737560510635376
[15/23] Train loss=0.3072183430194855
[20/23] Train loss=0.4029386043548584
Test set avg_accuracy=82.27% avg_sensitivity=57.45%, avg_specificity=89.46% avg_auc=0.8490
Fold[10] Epoch: 56 [56/100 (56%)] Train loss=0.333171 Test loss=0.393002 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32383933663368225
[5/23] Train loss=0.34123843908309937
[10/23] Train loss=0.3749562203884125
[15/23] Train loss=0.29679739475250244
[20/23] Train loss=0.40146252512931824
Test set avg_accuracy=81.60% avg_sensitivity=60.17%, avg_specificity=87.80% avg_auc=0.8406
Fold[10] Epoch: 57 [57/100 (57%)] Train loss=0.332895 Test loss=0.410440 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3242891728878021
[5/23] Train loss=0.3392007350921631
[10/23] Train loss=0.3736041486263275
[15/23] Train loss=0.29421451687812805
[20/23] Train loss=0.41311874985694885
Test set avg_accuracy=80.91% avg_sensitivity=62.69%, avg_specificity=86.18% avg_auc=0.8352
Fold[10] Epoch: 58 [58/100 (58%)] Train loss=0.332327 Test loss=0.428413 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31162014603614807
[5/23] Train loss=0.3404068350791931
[10/23] Train loss=0.369258314371109
[15/23] Train loss=0.2906624674797058
[20/23] Train loss=0.3932815194129944
Test set avg_accuracy=82.12% avg_sensitivity=61.20%, avg_specificity=88.18% avg_auc=0.8548
Fold[10] Epoch: 59 [59/100 (59%)] Train loss=0.331408 Test loss=0.401422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3152140974998474
[5/23] Train loss=0.3416720926761627
[10/23] Train loss=0.36457952857017517
[15/23] Train loss=0.2952600121498108
[20/23] Train loss=0.3970622420310974
Test set avg_accuracy=82.60% avg_sensitivity=57.66%, avg_specificity=89.81% avg_auc=0.8563
Fold[10] Epoch: 60 [60/100 (60%)] Train loss=0.329412 Test loss=0.409400 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32261747121810913
[5/23] Train loss=0.3255155682563782
[10/23] Train loss=0.36150336265563965
[15/23] Train loss=0.2792689800262451
[20/23] Train loss=0.40241503715515137
Test set avg_accuracy=82.40% avg_sensitivity=59.97%, avg_specificity=88.89% avg_auc=0.8515
Fold[10] Epoch: 61 [61/100 (61%)] Train loss=0.325067 Test loss=0.406459 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3208147883415222
[5/23] Train loss=0.3233489990234375
[10/23] Train loss=0.35811054706573486
[15/23] Train loss=0.2964487373828888
[20/23] Train loss=0.39412549138069153
Test set avg_accuracy=81.76% avg_sensitivity=60.79%, avg_specificity=87.83% avg_auc=0.8338
Fold[10] Epoch: 62 [62/100 (62%)] Train loss=0.323722 Test loss=0.419643 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32139402627944946
[5/23] Train loss=0.32176023721694946
[10/23] Train loss=0.3668690621852875
[15/23] Train loss=0.2836119830608368
[20/23] Train loss=0.39195144176483154
Test set avg_accuracy=82.27% avg_sensitivity=58.02%, avg_specificity=89.29% avg_auc=0.8542
Fold[10] Epoch: 63 [63/100 (63%)] Train loss=0.321200 Test loss=0.396801 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3135175108909607
[5/23] Train loss=0.31924086809158325
[10/23] Train loss=0.35337385535240173
[15/23] Train loss=0.2716751992702484
[20/23] Train loss=0.39159703254699707
Test set avg_accuracy=82.28% avg_sensitivity=59.87%, avg_specificity=88.77% avg_auc=0.8508
Fold[10] Epoch: 64 [64/100 (64%)] Train loss=0.317456 Test loss=0.400340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.31485193967819214
[5/23] Train loss=0.31836241483688354
[10/23] Train loss=0.3660171627998352
[15/23] Train loss=0.2775372862815857
[20/23] Train loss=0.3949368894100189
Test set avg_accuracy=82.40% avg_sensitivity=58.27%, avg_specificity=89.38% avg_auc=0.8480
Fold[10] Epoch: 65 [65/100 (65%)] Train loss=0.317566 Test loss=0.400542 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3145945072174072
[5/23] Train loss=0.314999520778656
[10/23] Train loss=0.34960997104644775
[15/23] Train loss=0.27177584171295166
[20/23] Train loss=0.3869397044181824
Test set avg_accuracy=82.60% avg_sensitivity=56.47%, avg_specificity=90.15% avg_auc=0.8532
Fold[10] Epoch: 66 [66/100 (66%)] Train loss=0.312852 Test loss=0.395915 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3132886290550232
[5/23] Train loss=0.32587164640426636
[10/23] Train loss=0.34904900193214417
[15/23] Train loss=0.27653300762176514
[20/23] Train loss=0.3924335837364197
Test set avg_accuracy=82.17% avg_sensitivity=56.06%, avg_specificity=89.72% avg_auc=0.8448
Fold[10] Epoch: 67 [67/100 (67%)] Train loss=0.314416 Test loss=0.401187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30914971232414246
[5/23] Train loss=0.31475600600242615
[10/23] Train loss=0.35596632957458496
[15/23] Train loss=0.2865367531776428
[20/23] Train loss=0.38703882694244385
Test set avg_accuracy=82.98% avg_sensitivity=53.29%, avg_specificity=91.57% avg_auc=0.8563
Fold[10] Epoch: 68 [68/100 (68%)] Train loss=0.316957 Test loss=0.390273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3087940514087677
[5/23] Train loss=0.3137824237346649
[10/23] Train loss=0.34402719140052795
[15/23] Train loss=0.2840239405632019
[20/23] Train loss=0.3817172348499298
Test set avg_accuracy=82.71% avg_sensitivity=53.19%, avg_specificity=91.26% avg_auc=0.8485
Fold[10] Epoch: 69 [69/100 (69%)] Train loss=0.316787 Test loss=0.393782 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3057152032852173
[5/23] Train loss=0.3039214611053467
[10/23] Train loss=0.34895384311676025
[15/23] Train loss=0.26843780279159546
[20/23] Train loss=0.3692510724067688
Test set avg_accuracy=80.93% avg_sensitivity=57.76%, avg_specificity=87.64% avg_auc=0.8242
Fold[10] Epoch: 70 [70/100 (70%)] Train loss=0.308737 Test loss=0.431982 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30655407905578613
[5/23] Train loss=0.3302401900291443
[10/23] Train loss=0.3406762480735779
[15/23] Train loss=0.2661215364933014
[20/23] Train loss=0.3744606673717499
Test set avg_accuracy=81.81% avg_sensitivity=58.17%, avg_specificity=88.65% avg_auc=0.8515
Fold[10] Epoch: 71 [71/100 (71%)] Train loss=0.314315 Test loss=0.408641 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30438175797462463
[5/23] Train loss=0.3087429404258728
[10/23] Train loss=0.3316207826137543
[15/23] Train loss=0.2592395842075348
[20/23] Train loss=0.38139742612838745
Test set avg_accuracy=82.26% avg_sensitivity=59.56%, avg_specificity=88.83% avg_auc=0.8517
Fold[10] Epoch: 72 [72/100 (72%)] Train loss=0.305477 Test loss=0.412805 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.303699791431427
[5/23] Train loss=0.30402451753616333
[10/23] Train loss=0.33710864186286926
[15/23] Train loss=0.26544541120529175
[20/23] Train loss=0.3626936078071594
Test set avg_accuracy=81.97% avg_sensitivity=59.56%, avg_specificity=88.46% avg_auc=0.8439
Fold[10] Epoch: 73 [73/100 (73%)] Train loss=0.302431 Test loss=0.413574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3070348799228668
[5/23] Train loss=0.30522623658180237
[10/23] Train loss=0.3292926251888275
[15/23] Train loss=0.25097304582595825
[20/23] Train loss=0.3604341447353363
Test set avg_accuracy=81.51% avg_sensitivity=58.48%, avg_specificity=88.18% avg_auc=0.8312
Fold[10] Epoch: 74 [74/100 (74%)] Train loss=0.298751 Test loss=0.424383 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29934680461883545
[5/23] Train loss=0.3066544532775879
[10/23] Train loss=0.3340700566768646
[15/23] Train loss=0.2449004352092743
[20/23] Train loss=0.3641630709171295
Test set avg_accuracy=78.05% avg_sensitivity=61.15%, avg_specificity=82.94% avg_auc=0.8031
Fold[10] Epoch: 75 [75/100 (75%)] Train loss=0.296503 Test loss=0.476053 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2987591326236725
[5/23] Train loss=0.307936429977417
[10/23] Train loss=0.33517712354660034
[15/23] Train loss=0.25424924492836
[20/23] Train loss=0.3524003326892853
Test set avg_accuracy=81.65% avg_sensitivity=58.43%, avg_specificity=88.37% avg_auc=0.8389
Fold[10] Epoch: 76 [76/100 (76%)] Train loss=0.294223 Test loss=0.425993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2933488190174103
[5/23] Train loss=0.29064854979515076
[10/23] Train loss=0.3238072097301483
[15/23] Train loss=0.25274911522865295
[20/23] Train loss=0.3875928521156311
Test set avg_accuracy=80.87% avg_sensitivity=59.20%, avg_specificity=87.14% avg_auc=0.8300
Fold[10] Epoch: 77 [77/100 (77%)] Train loss=0.293188 Test loss=0.434133 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29380813241004944
[5/23] Train loss=0.2911568880081177
[10/23] Train loss=0.31886160373687744
[15/23] Train loss=0.2507631480693817
[20/23] Train loss=0.35816749930381775
Test set avg_accuracy=82.42% avg_sensitivity=54.16%, avg_specificity=90.60% avg_auc=0.8405
Fold[10] Epoch: 78 [78/100 (78%)] Train loss=0.293578 Test loss=0.416937 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2889954447746277
[5/23] Train loss=0.2995717525482178
[10/23] Train loss=0.318945050239563
[15/23] Train loss=0.2513027787208557
[20/23] Train loss=0.346092164516449
Test set avg_accuracy=82.26% avg_sensitivity=56.17%, avg_specificity=89.81% avg_auc=0.8359
Fold[10] Epoch: 79 [79/100 (79%)] Train loss=0.289736 Test loss=0.419047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2891712486743927
[5/23] Train loss=0.29598554968833923
[10/23] Train loss=0.3147066533565521
[15/23] Train loss=0.24736300110816956
[20/23] Train loss=0.35881558060646057
Test set avg_accuracy=82.25% avg_sensitivity=57.86%, avg_specificity=89.31% avg_auc=0.8454
Fold[10] Epoch: 80 [80/100 (80%)] Train loss=0.288411 Test loss=0.412159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28512606024742126
[5/23] Train loss=0.279089093208313
[10/23] Train loss=0.3246798515319824
[15/23] Train loss=0.2589721083641052
[20/23] Train loss=0.35398221015930176
Test set avg_accuracy=82.54% avg_sensitivity=56.37%, avg_specificity=90.11% avg_auc=0.8508
Fold[10] Epoch: 81 [81/100 (81%)] Train loss=0.287746 Test loss=0.408180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2898487150669098
[5/23] Train loss=0.2853042185306549
[10/23] Train loss=0.33932653069496155
[15/23] Train loss=0.26761314272880554
[20/23] Train loss=0.3666515648365021
Test set avg_accuracy=82.40% avg_sensitivity=50.36%, avg_specificity=91.67% avg_auc=0.8430
Fold[10] Epoch: 82 [82/100 (82%)] Train loss=0.294961 Test loss=0.407962 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28681838512420654
[5/23] Train loss=0.28603747487068176
[10/23] Train loss=0.32984358072280884
[15/23] Train loss=0.24223291873931885
[20/23] Train loss=0.366313099861145
Test set avg_accuracy=75.54% avg_sensitivity=62.49%, avg_specificity=79.31% avg_auc=0.7894
Fold[10] Epoch: 83 [83/100 (83%)] Train loss=0.289895 Test loss=0.537096 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.280404657125473
[5/23] Train loss=0.3014794588088989
[10/23] Train loss=0.3208260238170624
[15/23] Train loss=0.24510756134986877
[20/23] Train loss=0.34370025992393494
Test set avg_accuracy=77.00% avg_sensitivity=60.53%, avg_specificity=81.77% avg_auc=0.7974
Fold[10] Epoch: 84 [84/100 (84%)] Train loss=0.287995 Test loss=0.513806 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27147242426872253
[5/23] Train loss=0.29979002475738525
[10/23] Train loss=0.30198124051094055
[15/23] Train loss=0.2337203174829483
[20/23] Train loss=0.3483128547668457
Test set avg_accuracy=82.34% avg_sensitivity=59.30%, avg_specificity=89.01% avg_auc=0.8537
Fold[10] Epoch: 85 [85/100 (85%)] Train loss=0.284450 Test loss=0.430426 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2814842462539673
[5/23] Train loss=0.28041329979896545
[10/23] Train loss=0.297351211309433
[15/23] Train loss=0.2332705557346344
[20/23] Train loss=0.338274747133255
Test set avg_accuracy=81.40% avg_sensitivity=59.15%, avg_specificity=87.83% avg_auc=0.8273
Fold[10] Epoch: 86 [86/100 (86%)] Train loss=0.276432 Test loss=0.442821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2701365053653717
[5/23] Train loss=0.2754882872104645
[10/23] Train loss=0.30365073680877686
[15/23] Train loss=0.22770915925502777
[20/23] Train loss=0.35057690739631653
Test set avg_accuracy=75.59% avg_sensitivity=58.94%, avg_specificity=80.41% avg_auc=0.7759
Fold[10] Epoch: 87 [87/100 (87%)] Train loss=0.273902 Test loss=0.521781 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27528607845306396
[5/23] Train loss=0.2760213017463684
[10/23] Train loss=0.29831165075302124
[15/23] Train loss=0.22878584265708923
[20/23] Train loss=0.3361983299255371
Test set avg_accuracy=81.86% avg_sensitivity=56.47%, avg_specificity=89.20% avg_auc=0.8393
Fold[10] Epoch: 88 [88/100 (88%)] Train loss=0.272013 Test loss=0.439071 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26848405599594116
[5/23] Train loss=0.28799596428871155
[10/23] Train loss=0.299640953540802
[15/23] Train loss=0.2370661199092865
[20/23] Train loss=0.33900371193885803
Test set avg_accuracy=81.01% avg_sensitivity=60.07%, avg_specificity=87.08% avg_auc=0.8275
Fold[10] Epoch: 89 [89/100 (89%)] Train loss=0.274742 Test loss=0.457794 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27591845393180847
[5/23] Train loss=0.2606343924999237
[10/23] Train loss=0.29215744137763977
[15/23] Train loss=0.22398869693279266
[20/23] Train loss=0.3338961601257324
Test set avg_accuracy=81.42% avg_sensitivity=59.30%, avg_specificity=87.82% avg_auc=0.8187
Fold[10] Epoch: 90 [90/100 (90%)] Train loss=0.271263 Test loss=0.452887 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27954035997390747
[5/23] Train loss=0.26290079951286316
[10/23] Train loss=0.29538246989250183
[15/23] Train loss=0.2225671112537384
[20/23] Train loss=0.33390405774116516
Test set avg_accuracy=81.74% avg_sensitivity=58.43%, avg_specificity=88.49% avg_auc=0.8292
Fold[10] Epoch: 91 [91/100 (91%)] Train loss=0.265742 Test loss=0.445308 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27674269676208496
[5/23] Train loss=0.2713836431503296
[10/23] Train loss=0.2942309081554413
[15/23] Train loss=0.22286733984947205
[20/23] Train loss=0.32573798298835754
Test set avg_accuracy=82.04% avg_sensitivity=55.70%, avg_specificity=89.66% avg_auc=0.8247
Fold[10] Epoch: 92 [92/100 (92%)] Train loss=0.264174 Test loss=0.442942 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2650470435619354
[5/23] Train loss=0.263423353433609
[10/23] Train loss=0.2853892743587494
[15/23] Train loss=0.21567416191101074
[20/23] Train loss=0.3244262933731079
Test set avg_accuracy=82.57% avg_sensitivity=53.91%, avg_specificity=90.87% avg_auc=0.8379
Fold[10] Epoch: 93 [93/100 (93%)] Train loss=0.263908 Test loss=0.432787 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2719491422176361
[5/23] Train loss=0.2631336748600006
[10/23] Train loss=0.2812488079071045
[15/23] Train loss=0.2305939793586731
[20/23] Train loss=0.3291870057582855
Test set avg_accuracy=82.42% avg_sensitivity=54.37%, avg_specificity=90.54% avg_auc=0.8398
Fold[10] Epoch: 94 [94/100 (94%)] Train loss=0.263836 Test loss=0.433387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25749701261520386
[5/23] Train loss=0.2729819715023041
[10/23] Train loss=0.27378061413764954
[15/23] Train loss=0.23958873748779297
[20/23] Train loss=0.34199005365371704
Test set avg_accuracy=82.27% avg_sensitivity=54.21%, avg_specificity=90.39% avg_auc=0.8308
Fold[10] Epoch: 95 [95/100 (95%)] Train loss=0.261744 Test loss=0.434739 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.252435564994812
[5/23] Train loss=0.2675051987171173
[10/23] Train loss=0.26796969771385193
[15/23] Train loss=0.21269309520721436
[20/23] Train loss=0.31824609637260437
Test set avg_accuracy=81.58% avg_sensitivity=52.36%, avg_specificity=90.04% avg_auc=0.8220
Fold[10] Epoch: 96 [96/100 (96%)] Train loss=0.259931 Test loss=0.444633 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2530008852481842
[5/23] Train loss=0.2564958333969116
[10/23] Train loss=0.27272677421569824
[15/23] Train loss=0.2160978466272354
[20/23] Train loss=0.31112974882125854
Test set avg_accuracy=82.68% avg_sensitivity=51.03%, avg_specificity=91.84% avg_auc=0.8461
Fold[10] Epoch: 97 [97/100 (97%)] Train loss=0.257949 Test loss=0.467814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2500174045562744
[5/23] Train loss=0.2779950201511383
[10/23] Train loss=0.2594318091869354
[15/23] Train loss=0.21269023418426514
[20/23] Train loss=0.31972846388816833
Test set avg_accuracy=81.82% avg_sensitivity=59.30%, avg_specificity=88.34% avg_auc=0.8327
Fold[10] Epoch: 98 [98/100 (98%)] Train loss=0.257979 Test loss=0.450362 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25454655289649963
[5/23] Train loss=0.25707003474235535
[10/23] Train loss=0.26320043206214905
[15/23] Train loss=0.2116622030735016
[20/23] Train loss=0.30086061358451843
Test set avg_accuracy=80.74% avg_sensitivity=62.54%, avg_specificity=86.01% avg_auc=0.8245
Fold[10] Epoch: 99 [99/100 (99%)] Train loss=0.248562 Test loss=0.471267 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24605078995227814
[5/23] Train loss=0.2480725795030594
[10/23] Train loss=0.2734389007091522
[15/23] Train loss=0.20318013429641724
[20/23] Train loss=0.3090347945690155
Test set avg_accuracy=82.58% avg_sensitivity=55.86%, avg_specificity=90.32% avg_auc=0.8406
Fold[10] Epoch: 100 [100/100 (100%)] Train loss=0.247048 Test loss=0.447106 Current lr=[3.9999999999999996e-05]

Fold[10] Best Result: acc=83.28719723183391 sen=56.4748201438849, spe=91.04699583581201, auc=0.8706724176195714!
Final Avg Result: avg_acc=81.653094% avg_sen=61.594008% avg_spe=88.318146% avg_auc=0.858837
