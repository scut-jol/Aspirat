/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/23] Train loss=0.6784453392028809
[5/23] Train loss=0.6218223571777344
[10/23] Train loss=0.5480393171310425
[15/23] Train loss=0.5261784791946411
[20/23] Train loss=0.47533008456230164
Test set avg_accuracy=74.67% avg_sensitivity=2.64%, avg_specificity=99.05% avg_auc=0.7755
Best model saved!! Metric=-72.0832367633586!!
Fold[1] Epoch: 1 [1/100 (1%)] Train loss=0.548308 Test loss=0.532046 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3867807686328888
[5/23] Train loss=0.49953585863113403
[10/23] Train loss=0.43029099702835083
[15/23] Train loss=0.45202285051345825
[20/23] Train loss=0.38030824065208435
Test set avg_accuracy=80.31% avg_sensitivity=43.90%, avg_specificity=92.63% avg_auc=0.8549
Best model saved!! Metric=-23.666932921178734!!
Fold[1] Epoch: 2 [2/100 (2%)] Train loss=0.436850 Test loss=0.442683 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32903003692626953
[5/23] Train loss=0.4512466490268707
[10/23] Train loss=0.376514196395874
[15/23] Train loss=0.3744997978210449
[20/23] Train loss=0.334430068731308
Test set avg_accuracy=81.14% avg_sensitivity=43.82%, avg_specificity=93.78% avg_auc=0.8722
Best model saved!! Metric=-20.04920120478694!!
Fold[1] Epoch: 3 [3/100 (3%)] Train loss=0.393476 Test loss=0.475910 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2889808118343353
[5/23] Train loss=0.44256576895713806
[10/23] Train loss=0.3451133072376251
[15/23] Train loss=0.3476312458515167
[20/23] Train loss=0.3196566104888916
Test set avg_accuracy=82.08% avg_sensitivity=46.42%, avg_specificity=94.15% avg_auc=0.8738
Best model saved!! Metric=-15.97781564211061!!
Fold[1] Epoch: 4 [4/100 (4%)] Train loss=0.375649 Test loss=0.460564 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2772444486618042
[5/23] Train loss=0.43720880150794983
[10/23] Train loss=0.3274347484111786
[15/23] Train loss=0.3316178321838379
[20/23] Train loss=0.3003859519958496
Test set avg_accuracy=83.74% avg_sensitivity=54.11%, avg_specificity=93.78% avg_auc=0.8858
Best model saved!! Metric=-5.794894966199319!!
Fold[1] Epoch: 5 [5/100 (5%)] Train loss=0.362473 Test loss=0.410724 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25732123851776123
[5/23] Train loss=0.43121013045310974
[10/23] Train loss=0.30831411480903625
[15/23] Train loss=0.3123508393764496
[20/23] Train loss=0.2878204882144928
Test set avg_accuracy=84.60% avg_sensitivity=57.73%, avg_specificity=93.69% avg_auc=0.8930
Best model saved!! Metric=-0.6810657790679109!!
Fold[1] Epoch: 6 [6/100 (6%)] Train loss=0.349577 Test loss=0.387747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25682422518730164
[5/23] Train loss=0.4201580882072449
[10/23] Train loss=0.3031916618347168
[15/23] Train loss=0.29779908061027527
[20/23] Train loss=0.266960084438324
Test set avg_accuracy=85.62% avg_sensitivity=62.77%, avg_specificity=93.35% avg_auc=0.9045
Best model saved!! Metric=6.1930927071010355!!
Fold[1] Epoch: 7 [7/100 (7%)] Train loss=0.339086 Test loss=0.358269 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23955662548542023
[5/23] Train loss=0.39659780263900757
[10/23] Train loss=0.2948957681655884
[15/23] Train loss=0.26736193895339966
[20/23] Train loss=0.2630251348018646
Test set avg_accuracy=86.20% avg_sensitivity=62.49%, avg_specificity=94.23% avg_auc=0.9125
Best model saved!! Metric=8.174061792299348!!
Fold[1] Epoch: 8 [8/100 (8%)] Train loss=0.330963 Test loss=0.352106 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22911083698272705
[5/23] Train loss=0.40000078082084656
[10/23] Train loss=0.2832341492176056
[15/23] Train loss=0.2647562026977539
[20/23] Train loss=0.2616589665412903
Test set avg_accuracy=86.54% avg_sensitivity=62.12%, avg_specificity=94.81% avg_auc=0.9159
Best model saved!! Metric=9.069780974934512!!
Fold[1] Epoch: 9 [9/100 (9%)] Train loss=0.326181 Test loss=0.349141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21403230726718903
[5/23] Train loss=0.3983508050441742
[10/23] Train loss=0.2788597047328949
[15/23] Train loss=0.26890432834625244
[20/23] Train loss=0.2512425184249878
Test set avg_accuracy=86.76% avg_sensitivity=62.29%, avg_specificity=95.04% avg_auc=0.9197
Best model saved!! Metric=10.05740476024424!!
Fold[1] Epoch: 10 [10/100 (10%)] Train loss=0.316447 Test loss=0.344325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21818578243255615
[5/23] Train loss=0.39586541056632996
[10/23] Train loss=0.25901564955711365
[15/23] Train loss=0.2625609040260315
[20/23] Train loss=0.230528324842453
Test set avg_accuracy=87.25% avg_sensitivity=64.93%, avg_specificity=94.81% avg_auc=0.9237
Best model saved!! Metric=13.358865603120991!!
Fold[1] Epoch: 11 [11/100 (11%)] Train loss=0.310176 Test loss=0.328822 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2081546038389206
[5/23] Train loss=0.40357881784439087
[10/23] Train loss=0.24658042192459106
[15/23] Train loss=0.25417274236679077
[20/23] Train loss=0.22736917436122894
Test set avg_accuracy=87.67% avg_sensitivity=69.45%, avg_specificity=93.84% avg_auc=0.9276
Best model saved!! Metric=17.72910295781907!!
Fold[1] Epoch: 12 [12/100 (12%)] Train loss=0.305801 Test loss=0.309831 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21199539303779602
[5/23] Train loss=0.3794456720352173
[10/23] Train loss=0.23831242322921753
[15/23] Train loss=0.24652428925037384
[20/23] Train loss=0.2209288626909256
Test set avg_accuracy=87.96% avg_sensitivity=70.18%, avg_specificity=93.98% avg_auc=0.9291
Best model saved!! Metric=19.03208779638028!!
Fold[1] Epoch: 13 [13/100 (13%)] Train loss=0.297758 Test loss=0.308710 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21134069561958313
[5/23] Train loss=0.39341220259666443
[10/23] Train loss=0.25117865204811096
[15/23] Train loss=0.23115244507789612
[20/23] Train loss=0.22310806810855865
Test set avg_accuracy=88.06% avg_sensitivity=72.01%, avg_specificity=93.49% avg_auc=0.9317
Best model saved!! Metric=20.717170941911935!!
Fold[1] Epoch: 14 [14/100 (14%)] Train loss=0.295459 Test loss=0.298956 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20581530034542084
[5/23] Train loss=0.3897393047809601
[10/23] Train loss=0.2352624386548996
[15/23] Train loss=0.23254597187042236
[20/23] Train loss=0.21354174613952637
Test set avg_accuracy=88.23% avg_sensitivity=73.11%, avg_specificity=93.35% avg_auc=0.9331
Best model saved!! Metric=21.998446460441947!!
Fold[1] Epoch: 15 [15/100 (15%)] Train loss=0.289189 Test loss=0.295283 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19645841419696808
[5/23] Train loss=0.3942747116088867
[10/23] Train loss=0.2386545091867447
[15/23] Train loss=0.2328270673751831
[20/23] Train loss=0.21439197659492493
Test set avg_accuracy=88.41% avg_sensitivity=72.38%, avg_specificity=93.83% avg_auc=0.9348
Best model saved!! Metric=22.094508828223923!!
Fold[1] Epoch: 16 [16/100 (16%)] Train loss=0.287741 Test loss=0.288152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1976168155670166
[5/23] Train loss=0.3737436532974243
[10/23] Train loss=0.228692427277565
[15/23] Train loss=0.22942858934402466
[20/23] Train loss=0.2019187957048416
Test set avg_accuracy=88.48% avg_sensitivity=72.13%, avg_specificity=94.01% avg_auc=0.9356
Best model saved!! Metric=22.174430052805384!!
Fold[1] Epoch: 17 [17/100 (17%)] Train loss=0.280970 Test loss=0.292224 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18515457212924957
[5/23] Train loss=0.3840082585811615
[10/23] Train loss=0.2279404252767563
[15/23] Train loss=0.2280702143907547
[20/23] Train loss=0.20909655094146729
Test set avg_accuracy=88.47% avg_sensitivity=73.07%, avg_specificity=93.68% avg_auc=0.9360
Best model saved!! Metric=22.811366221633865!!
Fold[1] Epoch: 18 [18/100 (18%)] Train loss=0.281721 Test loss=0.288076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18776850402355194
[5/23] Train loss=0.38573282957077026
[10/23] Train loss=0.23700211942195892
[15/23] Train loss=0.21720153093338013
[20/23] Train loss=0.19890105724334717
Test set avg_accuracy=88.58% avg_sensitivity=74.49%, avg_specificity=93.35% avg_auc=0.9370
Best model saved!! Metric=24.11715426078637!!
Fold[1] Epoch: 19 [19/100 (19%)] Train loss=0.277929 Test loss=0.284697 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1836404651403427
[5/23] Train loss=0.37860941886901855
[10/23] Train loss=0.2186310887336731
[15/23] Train loss=0.22227801382541656
[20/23] Train loss=0.1891397088766098
Test set avg_accuracy=88.59% avg_sensitivity=74.94%, avg_specificity=93.21% avg_auc=0.9366
Best model saved!! Metric=24.4024255815282!!
Fold[1] Epoch: 20 [20/100 (20%)] Train loss=0.273528 Test loss=0.285967 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18184392154216766
[5/23] Train loss=0.3855147957801819
[10/23] Train loss=0.22420227527618408
[15/23] Train loss=0.22416754066944122
[20/23] Train loss=0.19323810935020447
Test set avg_accuracy=88.66% avg_sensitivity=74.69%, avg_specificity=93.39% avg_auc=0.9380
Best model saved!! Metric=24.552638138387856!!
Fold[1] Epoch: 21 [21/100 (21%)] Train loss=0.273618 Test loss=0.280641 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1839400678873062
[5/23] Train loss=0.36407920718193054
[10/23] Train loss=0.21646526455879211
[15/23] Train loss=0.21880359947681427
[20/23] Train loss=0.1955697238445282
Test set avg_accuracy=88.83% avg_sensitivity=74.74%, avg_specificity=93.60% avg_auc=0.9383
Best model saved!! Metric=24.992457337591173!!
Fold[1] Epoch: 22 [22/100 (22%)] Train loss=0.270745 Test loss=0.280234 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1827346831560135
[5/23] Train loss=0.3714064657688141
[10/23] Train loss=0.2272922396659851
[15/23] Train loss=0.2222675383090973
[20/23] Train loss=0.19686852395534515
Test set avg_accuracy=88.85% avg_sensitivity=74.57%, avg_specificity=93.68% avg_auc=0.9384
Fold[1] Epoch: 23 [23/100 (23%)] Train loss=0.271947 Test loss=0.278630 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1811661273241043
[5/23] Train loss=0.3631454110145569
[10/23] Train loss=0.22074593603610992
[15/23] Train loss=0.21513310074806213
[20/23] Train loss=0.1943124532699585
Test set avg_accuracy=88.88% avg_sensitivity=75.35%, avg_specificity=93.46% avg_auc=0.9396
Best model saved!! Metric=25.641225531756692!!
Fold[1] Epoch: 24 [24/100 (24%)] Train loss=0.266700 Test loss=0.276298 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18023088574409485
[5/23] Train loss=0.36088836193084717
[10/23] Train loss=0.22451451420783997
[15/23] Train loss=0.20923343300819397
[20/23] Train loss=0.19846241176128387
Test set avg_accuracy=88.77% avg_sensitivity=75.31%, avg_specificity=93.32% avg_auc=0.9392
Fold[1] Epoch: 25 [25/100 (25%)] Train loss=0.265182 Test loss=0.277271 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16807307302951813
[5/23] Train loss=0.36647430062294006
[10/23] Train loss=0.21899089217185974
[15/23] Train loss=0.21472294628620148
[20/23] Train loss=0.18964038789272308
Test set avg_accuracy=88.90% avg_sensitivity=75.79%, avg_specificity=93.34% avg_auc=0.9395
Best model saved!! Metric=25.975347952193793!!
Fold[1] Epoch: 26 [26/100 (26%)] Train loss=0.265882 Test loss=0.275365 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17267125844955444
[5/23] Train loss=0.3569486737251282
[10/23] Train loss=0.21449525654315948
[15/23] Train loss=0.208521768450737
[20/23] Train loss=0.18406687676906586
Test set avg_accuracy=88.94% avg_sensitivity=75.51%, avg_specificity=93.49% avg_auc=0.9403
Fold[1] Epoch: 27 [27/100 (27%)] Train loss=0.262156 Test loss=0.274380 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15921901166439056
[5/23] Train loss=0.3594488501548767
[10/23] Train loss=0.21266280114650726
[15/23] Train loss=0.21677933633327484
[20/23] Train loss=0.18861505389213562
Test set avg_accuracy=88.93% avg_sensitivity=74.61%, avg_specificity=93.78% avg_auc=0.9397
Fold[1] Epoch: 28 [28/100 (28%)] Train loss=0.261148 Test loss=0.274855 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16302649676799774
[5/23] Train loss=0.3502941429615021
[10/23] Train loss=0.211279958486557
[15/23] Train loss=0.21451424062252045
[20/23] Train loss=0.1782602220773697
Test set avg_accuracy=88.95% avg_sensitivity=76.16%, avg_specificity=93.28% avg_auc=0.9406
Best model saved!! Metric=26.451018068354152!!
Fold[1] Epoch: 29 [29/100 (29%)] Train loss=0.258095 Test loss=0.273430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15954189002513885
[5/23] Train loss=0.3622685670852661
[10/23] Train loss=0.22189123928546906
[15/23] Train loss=0.21348431706428528
[20/23] Train loss=0.17495954036712646
Test set avg_accuracy=89.19% avg_sensitivity=76.04%, avg_specificity=93.64% avg_auc=0.9400
Best model saved!! Metric=26.86729628408017!!
Fold[1] Epoch: 30 [30/100 (30%)] Train loss=0.258431 Test loss=0.272449 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1602625697851181
[5/23] Train loss=0.3468642234802246
[10/23] Train loss=0.21265359222888947
[15/23] Train loss=0.20767194032669067
[20/23] Train loss=0.17477761209011078
Test set avg_accuracy=88.91% avg_sensitivity=76.24%, avg_specificity=93.20% avg_auc=0.9402
Fold[1] Epoch: 31 [31/100 (31%)] Train loss=0.254981 Test loss=0.271938 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16918088495731354
[5/23] Train loss=0.3505640923976898
[10/23] Train loss=0.2056787610054016
[15/23] Train loss=0.2058131992816925
[20/23] Train loss=0.17441894114017487
Test set avg_accuracy=88.90% avg_sensitivity=78.15%, avg_specificity=92.54% avg_auc=0.9412
Best model saved!! Metric=27.704894558254665!!
Fold[1] Epoch: 32 [32/100 (32%)] Train loss=0.254024 Test loss=0.270561 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16363126039505005
[5/23] Train loss=0.33344748616218567
[10/23] Train loss=0.20758622884750366
[15/23] Train loss=0.2125036120414734
[20/23] Train loss=0.17705997824668884
Test set avg_accuracy=88.90% avg_sensitivity=76.93%, avg_specificity=92.95% avg_auc=0.9404
Fold[1] Epoch: 33 [33/100 (33%)] Train loss=0.250752 Test loss=0.272400 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1564270406961441
[5/23] Train loss=0.3473992645740509
[10/23] Train loss=0.20829148590564728
[15/23] Train loss=0.209315225481987
[20/23] Train loss=0.17403537034988403
Test set avg_accuracy=89.02% avg_sensitivity=76.12%, avg_specificity=93.39% avg_auc=0.9407
Fold[1] Epoch: 34 [34/100 (34%)] Train loss=0.252729 Test loss=0.271224 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15948182344436646
[5/23] Train loss=0.3437674641609192
[10/23] Train loss=0.212563619017601
[15/23] Train loss=0.20779550075531006
[20/23] Train loss=0.1791515052318573
Test set avg_accuracy=89.08% avg_sensitivity=76.28%, avg_specificity=93.42% avg_auc=0.9413
Fold[1] Epoch: 35 [35/100 (35%)] Train loss=0.252114 Test loss=0.269082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1599016636610031
[5/23] Train loss=0.3422898054122925
[10/23] Train loss=0.20867961645126343
[15/23] Train loss=0.2038479894399643
[20/23] Train loss=0.17454893887043
Test set avg_accuracy=89.10% avg_sensitivity=75.83%, avg_specificity=93.60% avg_auc=0.9409
Fold[1] Epoch: 36 [36/100 (36%)] Train loss=0.249444 Test loss=0.268496 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15306665003299713
[5/23] Train loss=0.33504384756088257
[10/23] Train loss=0.21397264301776886
[15/23] Train loss=0.19733011722564697
[20/23] Train loss=0.17014145851135254
Test set avg_accuracy=88.98% avg_sensitivity=77.30%, avg_specificity=92.94% avg_auc=0.9415
Fold[1] Epoch: 37 [37/100 (37%)] Train loss=0.247071 Test loss=0.269901 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1531910002231598
[5/23] Train loss=0.341979444026947
[10/23] Train loss=0.19712382555007935
[15/23] Train loss=0.1999012529850006
[20/23] Train loss=0.16958092153072357
Test set avg_accuracy=88.82% avg_sensitivity=76.85%, avg_specificity=92.87% avg_auc=0.9412
Fold[1] Epoch: 38 [38/100 (38%)] Train loss=0.244868 Test loss=0.269747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1548583060503006
[5/23] Train loss=0.3342512547969818
[10/23] Train loss=0.20607315003871918
[15/23] Train loss=0.19738037884235382
[20/23] Train loss=0.18068666756153107
Test set avg_accuracy=88.85% avg_sensitivity=76.53%, avg_specificity=93.02% avg_auc=0.9418
Fold[1] Epoch: 39 [39/100 (39%)] Train loss=0.244045 Test loss=0.267881 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15194661915302277
[5/23] Train loss=0.34777572751045227
[10/23] Train loss=0.2095385193824768
[15/23] Train loss=0.19950105249881744
[20/23] Train loss=0.16844847798347473
Test set avg_accuracy=88.92% avg_sensitivity=76.08%, avg_specificity=93.27% avg_auc=0.9405
Fold[1] Epoch: 40 [40/100 (40%)] Train loss=0.246493 Test loss=0.271665 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1600591242313385
[5/23] Train loss=0.3328307867050171
[10/23] Train loss=0.21305501461029053
[15/23] Train loss=0.19655339419841766
[20/23] Train loss=0.16703516244888306
Test set avg_accuracy=89.02% avg_sensitivity=78.44%, avg_specificity=92.61% avg_auc=0.9431
Best model saved!! Metric=28.371421498085702!!
Fold[1] Epoch: 41 [41/100 (41%)] Train loss=0.244452 Test loss=0.264699 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1402459740638733
[5/23] Train loss=0.3336537182331085
[10/23] Train loss=0.20748235285282135
[15/23] Train loss=0.1980728954076767
[20/23] Train loss=0.1671503484249115
Test set avg_accuracy=88.95% avg_sensitivity=78.19%, avg_specificity=92.59% avg_auc=0.9415
Fold[1] Epoch: 42 [42/100 (42%)] Train loss=0.240994 Test loss=0.268951 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15176789462566376
[5/23] Train loss=0.32948893308639526
[10/23] Train loss=0.20471881330013275
[15/23] Train loss=0.1988297402858734
[20/23] Train loss=0.16871941089630127
Test set avg_accuracy=88.98% avg_sensitivity=76.89%, avg_specificity=93.07% avg_auc=0.9413
Fold[1] Epoch: 43 [43/100 (43%)] Train loss=0.242579 Test loss=0.269120 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14363501965999603
[5/23] Train loss=0.3436879515647888
[10/23] Train loss=0.20538052916526794
[15/23] Train loss=0.19177119433879852
[20/23] Train loss=0.1633259505033493
Test set avg_accuracy=88.89% avg_sensitivity=76.40%, avg_specificity=93.11% avg_auc=0.9412
Fold[1] Epoch: 44 [44/100 (44%)] Train loss=0.241308 Test loss=0.268230 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15337280929088593
[5/23] Train loss=0.32446566224098206
[10/23] Train loss=0.20995394885540009
[15/23] Train loss=0.18966926634311676
[20/23] Train loss=0.15896031260490417
Test set avg_accuracy=88.84% avg_sensitivity=76.77%, avg_specificity=92.92% avg_auc=0.9409
Fold[1] Epoch: 45 [45/100 (45%)] Train loss=0.240408 Test loss=0.268946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14553800225257874
[5/23] Train loss=0.33523622155189514
[10/23] Train loss=0.2064964920282364
[15/23] Train loss=0.18895292282104492
[20/23] Train loss=0.17160777747631073
Test set avg_accuracy=88.59% avg_sensitivity=77.79%, avg_specificity=92.25% avg_auc=0.9407
Fold[1] Epoch: 46 [46/100 (46%)] Train loss=0.237691 Test loss=0.271718 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14929065108299255
[5/23] Train loss=0.3253922462463379
[10/23] Train loss=0.2053346484899521
[15/23] Train loss=0.18926648795604706
[20/23] Train loss=0.15783385932445526
Test set avg_accuracy=89.01% avg_sensitivity=77.83%, avg_specificity=92.80% avg_auc=0.9423
Fold[1] Epoch: 47 [47/100 (47%)] Train loss=0.236914 Test loss=0.266984 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14654140174388885
[5/23] Train loss=0.3214859366416931
[10/23] Train loss=0.19911076128482819
[15/23] Train loss=0.18782822787761688
[20/23] Train loss=0.16604231297969818
Test set avg_accuracy=88.95% avg_sensitivity=77.66%, avg_specificity=92.77% avg_auc=0.9417
Fold[1] Epoch: 48 [48/100 (48%)] Train loss=0.236501 Test loss=0.270033 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1484466940164566
[5/23] Train loss=0.3131457567214966
[10/23] Train loss=0.2045430690050125
[15/23] Train loss=0.18920667469501495
[20/23] Train loss=0.16654172539710999
Test set avg_accuracy=88.79% avg_sensitivity=77.14%, avg_specificity=92.73% avg_auc=0.9409
Fold[1] Epoch: 49 [49/100 (49%)] Train loss=0.234157 Test loss=0.271021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14805111289024353
[5/23] Train loss=0.3209298551082611
[10/23] Train loss=0.21454790234565735
[15/23] Train loss=0.18879802525043488
[20/23] Train loss=0.16407856345176697
Test set avg_accuracy=89.08% avg_sensitivity=78.11%, avg_specificity=92.80% avg_auc=0.9430
Fold[1] Epoch: 50 [50/100 (50%)] Train loss=0.236245 Test loss=0.265986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14483793079853058
[5/23] Train loss=0.3192405700683594
[10/23] Train loss=0.19912713766098022
[15/23] Train loss=0.19162148237228394
[20/23] Train loss=0.15961076319217682
Test set avg_accuracy=89.03% avg_sensitivity=77.95%, avg_specificity=92.78% avg_auc=0.9422
Fold[1] Epoch: 51 [51/100 (51%)] Train loss=0.233743 Test loss=0.267203 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14902380108833313
[5/23] Train loss=0.3114711344242096
[10/23] Train loss=0.19681595265865326
[15/23] Train loss=0.18943174183368683
[20/23] Train loss=0.15541861951351166
Test set avg_accuracy=88.91% avg_sensitivity=77.79%, avg_specificity=92.67% avg_auc=0.9417
Fold[1] Epoch: 52 [52/100 (52%)] Train loss=0.229775 Test loss=0.270535 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13785922527313232
[5/23] Train loss=0.3184252679347992
[10/23] Train loss=0.2020404040813446
[15/23] Train loss=0.1888435035943985
[20/23] Train loss=0.16097359359264374
Test set avg_accuracy=88.78% avg_sensitivity=77.10%, avg_specificity=92.73% avg_auc=0.9419
Fold[1] Epoch: 53 [53/100 (53%)] Train loss=0.231938 Test loss=0.269173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.145382359623909
[5/23] Train loss=0.3119889497756958
[10/23] Train loss=0.20343415439128876
[15/23] Train loss=0.18578968942165375
[20/23] Train loss=0.1521444022655487
Test set avg_accuracy=88.59% avg_sensitivity=77.83%, avg_specificity=92.23% avg_auc=0.9411
Fold[1] Epoch: 54 [54/100 (54%)] Train loss=0.231321 Test loss=0.272514 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14892102777957916
[5/23] Train loss=0.3148775100708008
[10/23] Train loss=0.19416944682598114
[15/23] Train loss=0.1926378607749939
[20/23] Train loss=0.15584558248519897
Test set avg_accuracy=88.58% avg_sensitivity=77.42%, avg_specificity=92.36% avg_auc=0.9413
Fold[1] Epoch: 55 [55/100 (55%)] Train loss=0.227258 Test loss=0.273014 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14342279732227325
[5/23] Train loss=0.31029027700424194
[10/23] Train loss=0.20116166770458221
[15/23] Train loss=0.18772439658641815
[20/23] Train loss=0.15216587483882904
Test set avg_accuracy=88.62% avg_sensitivity=76.77%, avg_specificity=92.63% avg_auc=0.9407
Fold[1] Epoch: 56 [56/100 (56%)] Train loss=0.227098 Test loss=0.272677 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1429220736026764
[5/23] Train loss=0.3048202693462372
[10/23] Train loss=0.19485048949718475
[15/23] Train loss=0.18240438401699066
[20/23] Train loss=0.15497949719429016
Test set avg_accuracy=88.78% avg_sensitivity=77.75%, avg_specificity=92.51% avg_auc=0.9419
Fold[1] Epoch: 57 [57/100 (57%)] Train loss=0.225594 Test loss=0.269993 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1351700723171234
[5/23] Train loss=0.29927441477775574
[10/23] Train loss=0.19666579365730286
[15/23] Train loss=0.18129710853099823
[20/23] Train loss=0.1516798883676529
Test set avg_accuracy=88.70% avg_sensitivity=78.11%, avg_specificity=92.29% avg_auc=0.9415
Fold[1] Epoch: 58 [58/100 (58%)] Train loss=0.225850 Test loss=0.271154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13474388420581818
[5/23] Train loss=0.30611249804496765
[10/23] Train loss=0.19009044766426086
[15/23] Train loss=0.17780929803848267
[20/23] Train loss=0.15773093700408936
Test set avg_accuracy=88.63% avg_sensitivity=76.81%, avg_specificity=92.63% avg_auc=0.9401
Fold[1] Epoch: 59 [59/100 (59%)] Train loss=0.223110 Test loss=0.276107 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1312578171491623
[5/23] Train loss=0.3116583526134491
[10/23] Train loss=0.19921934604644775
[15/23] Train loss=0.18352356553077698
[20/23] Train loss=0.1480100452899933
Test set avg_accuracy=88.72% avg_sensitivity=76.61%, avg_specificity=92.83% avg_auc=0.9401
Fold[1] Epoch: 60 [60/100 (60%)] Train loss=0.226566 Test loss=0.272094 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13704054057598114
[5/23] Train loss=0.31111419200897217
[10/23] Train loss=0.19881808757781982
[15/23] Train loss=0.18577489256858826
[20/23] Train loss=0.15215358138084412
Test set avg_accuracy=88.76% avg_sensitivity=77.62%, avg_specificity=92.52% avg_auc=0.9411
Fold[1] Epoch: 61 [61/100 (61%)] Train loss=0.224263 Test loss=0.272154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13359658420085907
[5/23] Train loss=0.30200305581092834
[10/23] Train loss=0.18950685858726501
[15/23] Train loss=0.1895708292722702
[20/23] Train loss=0.15475405752658844
Test set avg_accuracy=88.38% avg_sensitivity=78.40%, avg_specificity=91.77% avg_auc=0.9378
Fold[1] Epoch: 62 [62/100 (62%)] Train loss=0.224383 Test loss=0.281184 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13336703181266785
[5/23] Train loss=0.3064483404159546
[10/23] Train loss=0.19312095642089844
[15/23] Train loss=0.18141207098960876
[20/23] Train loss=0.15033471584320068
Test set avg_accuracy=88.71% avg_sensitivity=78.97%, avg_specificity=92.01% avg_auc=0.9412
Fold[1] Epoch: 63 [63/100 (63%)] Train loss=0.222355 Test loss=0.273159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1374504119157791
[5/23] Train loss=0.3010093569755554
[10/23] Train loss=0.18700194358825684
[15/23] Train loss=0.17240937054157257
[20/23] Train loss=0.14927437901496887
Test set avg_accuracy=88.55% avg_sensitivity=79.13%, avg_specificity=91.74% avg_auc=0.9389
Fold[1] Epoch: 64 [64/100 (64%)] Train loss=0.216776 Test loss=0.281227 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13360312581062317
[5/23] Train loss=0.3006601929664612
[10/23] Train loss=0.1874595433473587
[15/23] Train loss=0.17568804323673248
[20/23] Train loss=0.1509816199541092
Test set avg_accuracy=88.69% avg_sensitivity=78.03%, avg_specificity=92.30% avg_auc=0.9406
Fold[1] Epoch: 65 [65/100 (65%)] Train loss=0.217939 Test loss=0.274924 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12989652156829834
[5/23] Train loss=0.29834437370300293
[10/23] Train loss=0.19819161295890808
[15/23] Train loss=0.1758766621351242
[20/23] Train loss=0.1521056443452835
Test set avg_accuracy=88.89% avg_sensitivity=77.50%, avg_specificity=92.74% avg_auc=0.9406
Fold[1] Epoch: 66 [66/100 (66%)] Train loss=0.217426 Test loss=0.274525 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13088534772396088
[5/23] Train loss=0.29758837819099426
[10/23] Train loss=0.19169679284095764
[15/23] Train loss=0.17730407416820526
[20/23] Train loss=0.14879021048545837
Test set avg_accuracy=88.64% avg_sensitivity=77.34%, avg_specificity=92.47% avg_auc=0.9399
Fold[1] Epoch: 67 [67/100 (67%)] Train loss=0.217653 Test loss=0.277093 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13199350237846375
[5/23] Train loss=0.29940009117126465
[10/23] Train loss=0.1945071667432785
[15/23] Train loss=0.17908018827438354
[20/23] Train loss=0.15297068655490875
Test set avg_accuracy=88.60% avg_sensitivity=77.10%, avg_specificity=92.50% avg_auc=0.9400
Fold[1] Epoch: 68 [68/100 (68%)] Train loss=0.219461 Test loss=0.275166 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12454000860452652
[5/23] Train loss=0.3007495403289795
[10/23] Train loss=0.19687263667583466
[15/23] Train loss=0.18172286450862885
[20/23] Train loss=0.1462688148021698
Test set avg_accuracy=88.81% avg_sensitivity=78.07%, avg_specificity=92.44% avg_auc=0.9420
Fold[1] Epoch: 69 [69/100 (69%)] Train loss=0.216645 Test loss=0.270976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12453801184892654
[5/23] Train loss=0.30324482917785645
[10/23] Train loss=0.19180551171302795
[15/23] Train loss=0.17743422091007233
[20/23] Train loss=0.14714567363262177
Test set avg_accuracy=88.70% avg_sensitivity=78.93%, avg_specificity=92.01% avg_auc=0.9406
Fold[1] Epoch: 70 [70/100 (70%)] Train loss=0.216302 Test loss=0.274381 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12474920600652695
[5/23] Train loss=0.28826937079429626
[10/23] Train loss=0.18754734098911285
[15/23] Train loss=0.17193666100502014
[20/23] Train loss=0.14151638746261597
Test set avg_accuracy=88.54% avg_sensitivity=79.21%, avg_specificity=91.70% avg_auc=0.9401
Fold[1] Epoch: 71 [71/100 (71%)] Train loss=0.213693 Test loss=0.277930 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13636237382888794
[5/23] Train loss=0.2887226939201355
[10/23] Train loss=0.18567389249801636
[15/23] Train loss=0.16719244420528412
[20/23] Train loss=0.14571470022201538
Test set avg_accuracy=88.63% avg_sensitivity=79.78%, avg_specificity=91.63% avg_auc=0.9384
Fold[1] Epoch: 72 [72/100 (72%)] Train loss=0.211324 Test loss=0.283743 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12337237596511841
[5/23] Train loss=0.2896523177623749
[10/23] Train loss=0.18355144560337067
[15/23] Train loss=0.1681111603975296
[20/23] Train loss=0.14323744177818298
Test set avg_accuracy=88.60% avg_sensitivity=78.56%, avg_specificity=92.00% avg_auc=0.9386
Fold[1] Epoch: 73 [73/100 (73%)] Train loss=0.208734 Test loss=0.281006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13002417981624603
[5/23] Train loss=0.27119648456573486
[10/23] Train loss=0.18530766665935516
[15/23] Train loss=0.17080369591712952
[20/23] Train loss=0.14829741418361664
Test set avg_accuracy=88.64% avg_sensitivity=79.74%, avg_specificity=91.66% avg_auc=0.9400
Fold[1] Epoch: 74 [74/100 (74%)] Train loss=0.208707 Test loss=0.280256 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11672305315732956
[5/23] Train loss=0.2859972417354584
[10/23] Train loss=0.1866985708475113
[15/23] Train loss=0.16705162823200226
[20/23] Train loss=0.13792866468429565
Test set avg_accuracy=88.64% avg_sensitivity=79.45%, avg_specificity=91.75% avg_auc=0.9394
Fold[1] Epoch: 75 [75/100 (75%)] Train loss=0.208003 Test loss=0.279782 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12224800139665604
[5/23] Train loss=0.2780799865722656
[10/23] Train loss=0.19229131937026978
[15/23] Train loss=0.163486048579216
[20/23] Train loss=0.14052677154541016
Test set avg_accuracy=88.69% avg_sensitivity=78.07%, avg_specificity=92.29% avg_auc=0.9396
Fold[1] Epoch: 76 [76/100 (76%)] Train loss=0.206432 Test loss=0.278123 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1318449079990387
[5/23] Train loss=0.2684607207775116
[10/23] Train loss=0.18861861526966095
[15/23] Train loss=0.1672065109014511
[20/23] Train loss=0.13719366490840912
Test set avg_accuracy=88.84% avg_sensitivity=78.48%, avg_specificity=92.34% avg_auc=0.9389
Fold[1] Epoch: 77 [77/100 (77%)] Train loss=0.207406 Test loss=0.282554 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13318760693073273
[5/23] Train loss=0.2920181155204773
[10/23] Train loss=0.17994120717048645
[15/23] Train loss=0.17657586932182312
[20/23] Train loss=0.13626110553741455
Test set avg_accuracy=88.87% avg_sensitivity=78.89%, avg_specificity=92.25% avg_auc=0.9407
Fold[1] Epoch: 78 [78/100 (78%)] Train loss=0.207029 Test loss=0.273876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12089303880929947
[5/23] Train loss=0.27078285813331604
[10/23] Train loss=0.18296866118907928
[15/23] Train loss=0.17130395770072937
[20/23] Train loss=0.13050836324691772
Test set avg_accuracy=88.45% avg_sensitivity=77.50%, avg_specificity=92.15% avg_auc=0.9363
Fold[1] Epoch: 79 [79/100 (79%)] Train loss=0.202667 Test loss=0.287856 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1271062195301056
[5/23] Train loss=0.2707367241382599
[10/23] Train loss=0.17981457710266113
[15/23] Train loss=0.16861464083194733
[20/23] Train loss=0.1416155844926834
Test set avg_accuracy=88.69% avg_sensitivity=78.19%, avg_specificity=92.25% avg_auc=0.9389
Fold[1] Epoch: 80 [80/100 (80%)] Train loss=0.203606 Test loss=0.283128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12378085404634476
[5/23] Train loss=0.27151742577552795
[10/23] Train loss=0.17729343473911285
[15/23] Train loss=0.17107164859771729
[20/23] Train loss=0.13882145285606384
Test set avg_accuracy=88.81% avg_sensitivity=80.07%, avg_specificity=91.77% avg_auc=0.9396
Best model saved!! Metric=28.60150386800422!!
Fold[1] Epoch: 81 [81/100 (81%)] Train loss=0.202050 Test loss=0.282035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12022516876459122
[5/23] Train loss=0.2769136428833008
[10/23] Train loss=0.1796722114086151
[15/23] Train loss=0.16093768179416656
[20/23] Train loss=0.13605459034442902
Test set avg_accuracy=88.59% avg_sensitivity=79.70%, avg_specificity=91.60% avg_auc=0.9407
Fold[1] Epoch: 82 [82/100 (82%)] Train loss=0.201953 Test loss=0.278164 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.13411511480808258
[5/23] Train loss=0.26254114508628845
[10/23] Train loss=0.17646339535713196
[15/23] Train loss=0.16813643276691437
[20/23] Train loss=0.13777358829975128
Test set avg_accuracy=88.67% avg_sensitivity=79.17%, avg_specificity=91.89% avg_auc=0.9385
Fold[1] Epoch: 83 [83/100 (83%)] Train loss=0.200665 Test loss=0.284749 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12230974435806274
[5/23] Train loss=0.28701379895210266
[10/23] Train loss=0.1809690296649933
[15/23] Train loss=0.16700489819049835
[20/23] Train loss=0.13626495003700256
Test set avg_accuracy=88.45% avg_sensitivity=79.45%, avg_specificity=91.49% avg_auc=0.9390
Fold[1] Epoch: 84 [84/100 (84%)] Train loss=0.201165 Test loss=0.283914 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11331255733966827
[5/23] Train loss=0.28420814871788025
[10/23] Train loss=0.17707981169223785
[15/23] Train loss=0.16457365453243256
[20/23] Train loss=0.1318567395210266
Test set avg_accuracy=88.61% avg_sensitivity=78.84%, avg_specificity=91.92% avg_auc=0.9394
Fold[1] Epoch: 85 [85/100 (85%)] Train loss=0.196980 Test loss=0.280105 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11851157248020172
[5/23] Train loss=0.26137199997901917
[10/23] Train loss=0.17785193026065826
[15/23] Train loss=0.16118019819259644
[20/23] Train loss=0.13053029775619507
Test set avg_accuracy=88.72% avg_sensitivity=78.07%, avg_specificity=92.33% avg_auc=0.9375
Fold[1] Epoch: 86 [86/100 (86%)] Train loss=0.195919 Test loss=0.287480 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11570269614458084
[5/23] Train loss=0.2591390013694763
[10/23] Train loss=0.177672877907753
[15/23] Train loss=0.1612856388092041
[20/23] Train loss=0.12944552302360535
Test set avg_accuracy=88.99% avg_sensitivity=78.64%, avg_specificity=92.50% avg_auc=0.9392
Fold[1] Epoch: 87 [87/100 (87%)] Train loss=0.195058 Test loss=0.280195 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12962394952774048
[5/23] Train loss=0.2678893506526947
[10/23] Train loss=0.1856716126203537
[15/23] Train loss=0.16248460114002228
[20/23] Train loss=0.13757599890232086
Test set avg_accuracy=88.78% avg_sensitivity=76.69%, avg_specificity=92.87% avg_auc=0.9373
Fold[1] Epoch: 88 [88/100 (88%)] Train loss=0.196938 Test loss=0.284969 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12417909502983093
[5/23] Train loss=0.2643255591392517
[10/23] Train loss=0.18088509142398834
[15/23] Train loss=0.16841711103916168
[20/23] Train loss=0.12480565160512924
Test set avg_accuracy=88.79% avg_sensitivity=78.44%, avg_specificity=92.29% avg_auc=0.9389
Fold[1] Epoch: 89 [89/100 (89%)] Train loss=0.198506 Test loss=0.279768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11968643218278885
[5/23] Train loss=0.25839221477508545
[10/23] Train loss=0.17261971533298492
[15/23] Train loss=0.15628135204315186
[20/23] Train loss=0.13554979860782623
Test set avg_accuracy=88.71% avg_sensitivity=79.50%, avg_specificity=91.83% avg_auc=0.9372
Fold[1] Epoch: 90 [90/100 (90%)] Train loss=0.192418 Test loss=0.293966 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11283309757709503
[5/23] Train loss=0.2775658965110779
[10/23] Train loss=0.18660923838615417
[15/23] Train loss=0.16974683105945587
[20/23] Train loss=0.13098692893981934
Test set avg_accuracy=88.59% avg_sensitivity=79.29%, avg_specificity=91.74% avg_auc=0.9387
Fold[1] Epoch: 91 [91/100 (91%)] Train loss=0.195211 Test loss=0.280663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12725354731082916
[5/23] Train loss=0.25934451818466187
[10/23] Train loss=0.1678023636341095
[15/23] Train loss=0.16303668916225433
[20/23] Train loss=0.1243511438369751
Test set avg_accuracy=88.50% avg_sensitivity=81.04%, avg_specificity=91.02% avg_auc=0.9382
Fold[1] Epoch: 92 [92/100 (92%)] Train loss=0.190907 Test loss=0.291980 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.12841205298900604
[5/23] Train loss=0.2586361765861511
[10/23] Train loss=0.16943632066249847
[15/23] Train loss=0.1551506668329239
[20/23] Train loss=0.1288606822490692
Test set avg_accuracy=88.49% avg_sensitivity=80.51%, avg_specificity=91.19% avg_auc=0.9390
Fold[1] Epoch: 93 [93/100 (93%)] Train loss=0.188393 Test loss=0.286906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.10936558246612549
[5/23] Train loss=0.2624738812446594
[10/23] Train loss=0.1712360978126526
[15/23] Train loss=0.1464775800704956
[20/23] Train loss=0.11865025758743286
Test set avg_accuracy=88.46% avg_sensitivity=79.62%, avg_specificity=91.45% avg_auc=0.9371
Fold[1] Epoch: 94 [94/100 (94%)] Train loss=0.188536 Test loss=0.294347 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1191609799861908
[5/23] Train loss=0.26211678981781006
[10/23] Train loss=0.1639804095029831
[15/23] Train loss=0.1470824033021927
[20/23] Train loss=0.1259598582983017
Test set avg_accuracy=88.59% avg_sensitivity=79.86%, avg_specificity=91.55% avg_auc=0.9385
Fold[1] Epoch: 95 [95/100 (95%)] Train loss=0.186394 Test loss=0.286672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11353886127471924
[5/23] Train loss=0.24916388094425201
[10/23] Train loss=0.17877811193466187
[15/23] Train loss=0.1476384401321411
[20/23] Train loss=0.12425116449594498
Test set avg_accuracy=88.24% avg_sensitivity=80.23%, avg_specificity=90.95% avg_auc=0.9370
Fold[1] Epoch: 96 [96/100 (96%)] Train loss=0.187692 Test loss=0.295664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11978838592767715
[5/23] Train loss=0.25383228063583374
[10/23] Train loss=0.16918057203292847
[15/23] Train loss=0.15271203219890594
[20/23] Train loss=0.11717835813760757
Test set avg_accuracy=88.23% avg_sensitivity=81.20%, avg_specificity=90.61% avg_auc=0.9393
Fold[1] Epoch: 97 [97/100 (97%)] Train loss=0.182220 Test loss=0.290537 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11488930881023407
[5/23] Train loss=0.24891822040081024
[10/23] Train loss=0.17742066085338593
[15/23] Train loss=0.15443935990333557
[20/23] Train loss=0.1249716728925705
Test set avg_accuracy=88.42% avg_sensitivity=78.84%, avg_specificity=91.66% avg_auc=0.9370
Fold[1] Epoch: 98 [98/100 (98%)] Train loss=0.183003 Test loss=0.291732 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1075844094157219
[5/23] Train loss=0.24564482271671295
[10/23] Train loss=0.16911159455776215
[15/23] Train loss=0.1482742726802826
[20/23] Train loss=0.12555158138275146
Test set avg_accuracy=88.58% avg_sensitivity=78.40%, avg_specificity=92.03% avg_auc=0.9371
Fold[1] Epoch: 99 [99/100 (99%)] Train loss=0.182932 Test loss=0.292134 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.11227738857269287
[5/23] Train loss=0.24623098969459534
[10/23] Train loss=0.17133760452270508
[15/23] Train loss=0.14698426425457
[20/23] Train loss=0.12507300078868866
Test set avg_accuracy=88.70% avg_sensitivity=78.76%, avg_specificity=92.07% avg_auc=0.9371
Fold[1] Epoch: 100 [100/100 (100%)] Train loss=0.180772 Test loss=0.294668 Current lr=[3.9999999999999996e-05]

Fold[1] Best Result: acc=88.80658436213992 sen=80.06509357200976, spe=91.76535389699806, auc=0.9396447203685648!
[0/23] Train loss=0.6925216317176819
[5/23] Train loss=0.6254982352256775
[10/23] Train loss=0.5547733902931213
[15/23] Train loss=0.5296916961669922
[20/23] Train loss=0.5008565187454224
Test set avg_accuracy=76.86% avg_sensitivity=0.45%, avg_specificity=99.78% avg_auc=0.6698
Best model saved!! Metric=-81.92609252383147!!
Fold[2] Epoch: 1 [1/100 (1%)] Train loss=0.557726 Test loss=0.568404 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.48913460969924927
[5/23] Train loss=0.5027520060539246
[10/23] Train loss=0.44726765155792236
[15/23] Train loss=0.46106335520744324
[20/23] Train loss=0.3874515891075134
Test set avg_accuracy=77.70% avg_sensitivity=33.91%, avg_specificity=90.84% avg_auc=0.8045
Best model saved!! Metric=-43.09788314235095!!
Fold[2] Epoch: 2 [2/100 (2%)] Train loss=0.455444 Test loss=0.500789 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3993683159351349
[5/23] Train loss=0.4582342803478241
[10/23] Train loss=0.3861544132232666
[15/23] Train loss=0.3929385840892792
[20/23] Train loss=0.3538608253002167
Test set avg_accuracy=79.07% avg_sensitivity=35.76%, avg_specificity=92.07% avg_auc=0.8215
Best model saved!! Metric=-36.95044589368719!!
Fold[2] Epoch: 3 [3/100 (3%)] Train loss=0.405737 Test loss=0.563859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36188387870788574
[5/23] Train loss=0.44752201437950134
[10/23] Train loss=0.3542949855327606
[15/23] Train loss=0.357399046421051
[20/23] Train loss=0.32206758856773376
Test set avg_accuracy=80.05% avg_sensitivity=35.08%, avg_specificity=93.54% avg_auc=0.8239
Best model saved!! Metric=-34.93118712827626!!
Fold[2] Epoch: 4 [4/100 (4%)] Train loss=0.382086 Test loss=0.572788 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.33309537172317505
[5/23] Train loss=0.4314025342464447
[10/23] Train loss=0.33991003036499023
[15/23] Train loss=0.33683907985687256
[20/23] Train loss=0.30125659704208374
Test set avg_accuracy=81.68% avg_sensitivity=41.05%, avg_specificity=93.87% avg_auc=0.8468
Best model saved!! Metric=-24.719610882798424!!
Fold[2] Epoch: 5 [5/100 (5%)] Train loss=0.365084 Test loss=0.499399 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3185324966907501
[5/23] Train loss=0.4210900366306305
[10/23] Train loss=0.31592655181884766
[15/23] Train loss=0.31286466121673584
[20/23] Train loss=0.284921258687973
Test set avg_accuracy=83.47% avg_sensitivity=47.11%, avg_specificity=94.38% avg_auc=0.8688
Best model saved!! Metric=-14.159199232107742!!
Fold[2] Epoch: 6 [6/100 (6%)] Train loss=0.351330 Test loss=0.452319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30943599343299866
[5/23] Train loss=0.4219789206981659
[10/23] Train loss=0.2985551953315735
[15/23] Train loss=0.2970479428768158
[20/23] Train loss=0.25741812586784363
Test set avg_accuracy=84.75% avg_sensitivity=50.72%, avg_specificity=94.95% avg_auc=0.8877
Best model saved!! Metric=-6.807258959391481!!
Fold[2] Epoch: 7 [7/100 (7%)] Train loss=0.338069 Test loss=0.409705 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29022422432899475
[5/23] Train loss=0.4077104330062866
[10/23] Train loss=0.30182725191116333
[15/23] Train loss=0.2855572998523712
[20/23] Train loss=0.26473966240882874
Test set avg_accuracy=85.23% avg_sensitivity=50.36%, avg_specificity=95.69% avg_auc=0.8950
Best model saved!! Metric=-5.220541522828398!!
Fold[2] Epoch: 8 [8/100 (8%)] Train loss=0.332828 Test loss=0.404945 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2835314869880676
[5/23] Train loss=0.39519748091697693
[10/23] Train loss=0.2832452058792114
[15/23] Train loss=0.2769419550895691
[20/23] Train loss=0.24062851071357727
Test set avg_accuracy=85.62% avg_sensitivity=50.18%, avg_specificity=96.26% avg_auc=0.9007
Best model saved!! Metric=-3.870095384992071!!
Fold[2] Epoch: 9 [9/100 (9%)] Train loss=0.324733 Test loss=0.397294 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29437747597694397
[5/23] Train loss=0.4175083339214325
[10/23] Train loss=0.2733778655529022
[15/23] Train loss=0.27317506074905396
[20/23] Train loss=0.23748311400413513
Test set avg_accuracy=86.41% avg_sensitivity=53.53%, avg_specificity=96.27% avg_auc=0.9061
Best model saved!! Metric=0.8080209792221567!!
Fold[2] Epoch: 10 [10/100 (10%)] Train loss=0.318711 Test loss=0.373401 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27769753336906433
[5/23] Train loss=0.41117581725120544
[10/23] Train loss=0.26580482721328735
[15/23] Train loss=0.26552602648735046
[20/23] Train loss=0.22643955051898956
Test set avg_accuracy=87.18% avg_sensitivity=61.21%, avg_specificity=94.97% avg_auc=0.9138
Best model saved!! Metric=8.735380153332898!!
Fold[2] Epoch: 11 [11/100 (11%)] Train loss=0.308998 Test loss=0.334251 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2586503326892853
[5/23] Train loss=0.38403740525245667
[10/23] Train loss=0.2462494820356369
[15/23] Train loss=0.2524045705795288
[20/23] Train loss=0.21345111727714539
Test set avg_accuracy=87.44% avg_sensitivity=61.84%, avg_specificity=95.12% avg_auc=0.9171
Best model saved!! Metric=10.111016135016037!!
Fold[2] Epoch: 12 [12/100 (12%)] Train loss=0.299896 Test loss=0.328129 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24435681104660034
[5/23] Train loss=0.40394124388694763
[10/23] Train loss=0.2470192015171051
[15/23] Train loss=0.2515897750854492
[20/23] Train loss=0.2214556485414505
Test set avg_accuracy=87.63% avg_sensitivity=60.90%, avg_specificity=95.65% avg_auc=0.9184
Fold[2] Epoch: 13 [13/100 (13%)] Train loss=0.294719 Test loss=0.327466 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24660515785217285
[5/23] Train loss=0.39187678694725037
[10/23] Train loss=0.23778210580348969
[15/23] Train loss=0.24206192791461945
[20/23] Train loss=0.20675358176231384
Test set avg_accuracy=87.72% avg_sensitivity=61.53%, avg_specificity=95.58% avg_auc=0.9206
Best model saved!! Metric=10.882169934010726!!
Fold[2] Epoch: 14 [14/100 (14%)] Train loss=0.291196 Test loss=0.320893 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24389080703258514
[5/23] Train loss=0.37511035799980164
[10/23] Train loss=0.23975178599357605
[15/23] Train loss=0.22771397233009338
[20/23] Train loss=0.20172153413295746
Test set avg_accuracy=87.71% avg_sensitivity=61.75%, avg_specificity=95.50% avg_auc=0.9219
Best model saved!! Metric=11.15276147022381!!
Fold[2] Epoch: 15 [15/100 (15%)] Train loss=0.286477 Test loss=0.321505 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.243814617395401
[5/23] Train loss=0.39277610182762146
[10/23] Train loss=0.2276572287082672
[15/23] Train loss=0.23748177289962769
[20/23] Train loss=0.20467106997966766
Test set avg_accuracy=87.96% avg_sensitivity=62.48%, avg_specificity=95.61% avg_auc=0.9231
Best model saved!! Metric=12.348837796231514!!
Fold[2] Epoch: 16 [16/100 (16%)] Train loss=0.288849 Test loss=0.312459 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23655912280082703
[5/23] Train loss=0.38202208280563354
[10/23] Train loss=0.2275247722864151
[15/23] Train loss=0.232666015625
[20/23] Train loss=0.20138360559940338
Test set avg_accuracy=88.08% avg_sensitivity=64.24%, avg_specificity=95.23% avg_auc=0.9237
Best model saved!! Metric=13.907894408659207!!
Fold[2] Epoch: 17 [17/100 (17%)] Train loss=0.281722 Test loss=0.311092 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22508008778095245
[5/23] Train loss=0.3915178179740906
[10/23] Train loss=0.23370525240898132
[15/23] Train loss=0.2373320609331131
[20/23] Train loss=0.2011883556842804
Test set avg_accuracy=88.13% avg_sensitivity=63.38%, avg_specificity=95.55% avg_auc=0.9242
Fold[2] Epoch: 18 [18/100 (18%)] Train loss=0.279347 Test loss=0.310375 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22683154046535492
[5/23] Train loss=0.38341230154037476
[10/23] Train loss=0.22321610152721405
[15/23] Train loss=0.22549158334732056
[20/23] Train loss=0.2014797180891037
Test set avg_accuracy=87.96% avg_sensitivity=62.21%, avg_specificity=95.69% avg_auc=0.9246
Fold[2] Epoch: 19 [19/100 (19%)] Train loss=0.276841 Test loss=0.309375 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22126145660877228
[5/23] Train loss=0.3958234488964081
[10/23] Train loss=0.2290317714214325
[15/23] Train loss=0.23255087435245514
[20/23] Train loss=0.19795750081539154
Test set avg_accuracy=88.22% avg_sensitivity=63.97%, avg_specificity=95.50% avg_auc=0.9247
Best model saved!! Metric=14.158958846228739!!
Fold[2] Epoch: 20 [20/100 (20%)] Train loss=0.276025 Test loss=0.304744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22055158019065857
[5/23] Train loss=0.3692931532859802
[10/23] Train loss=0.22540000081062317
[15/23] Train loss=0.2179369330406189
[20/23] Train loss=0.1944279670715332
Test set avg_accuracy=88.43% avg_sensitivity=65.24%, avg_specificity=95.39% avg_auc=0.9266
Best model saved!! Metric=15.71475767988942!!
Fold[2] Epoch: 21 [21/100 (21%)] Train loss=0.270221 Test loss=0.298450 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21870461106300354
[5/23] Train loss=0.3672817647457123
[10/23] Train loss=0.2207479476928711
[15/23] Train loss=0.21430952847003937
[20/23] Train loss=0.18973220884799957
Test set avg_accuracy=88.27% avg_sensitivity=64.15%, avg_specificity=95.51% avg_auc=0.9256
Fold[2] Epoch: 22 [22/100 (22%)] Train loss=0.265855 Test loss=0.304636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2180769443511963
[5/23] Train loss=0.38321906328201294
[10/23] Train loss=0.22170144319534302
[15/23] Train loss=0.2161346971988678
[20/23] Train loss=0.18964989483356476
Test set avg_accuracy=88.47% avg_sensitivity=65.87%, avg_specificity=95.25% avg_auc=0.9265
Best model saved!! Metric=16.239190105354645!!
Fold[2] Epoch: 23 [23/100 (23%)] Train loss=0.265488 Test loss=0.298016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21652531623840332
[5/23] Train loss=0.3632388114929199
[10/23] Train loss=0.21960699558258057
[15/23] Train loss=0.2121080458164215
[20/23] Train loss=0.18955428898334503
Test set avg_accuracy=88.40% avg_sensitivity=64.83%, avg_specificity=95.47% avg_auc=0.9265
Fold[2] Epoch: 24 [24/100 (24%)] Train loss=0.261511 Test loss=0.298041 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21719330549240112
[5/23] Train loss=0.37105944752693176
[10/23] Train loss=0.21922580897808075
[15/23] Train loss=0.21500743925571442
[20/23] Train loss=0.19542120397090912
Test set avg_accuracy=88.63% avg_sensitivity=65.33%, avg_specificity=95.62% avg_auc=0.9272
Best model saved!! Metric=16.291209058737593!!
Fold[2] Epoch: 25 [25/100 (25%)] Train loss=0.265725 Test loss=0.291077 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2091367542743683
[5/23] Train loss=0.36980292201042175
[10/23] Train loss=0.2206869274377823
[15/23] Train loss=0.21843931078910828
[20/23] Train loss=0.17707917094230652
Test set avg_accuracy=88.66% avg_sensitivity=65.91%, avg_specificity=95.48% avg_auc=0.9279
Best model saved!! Metric=16.84463441605597!!
Fold[2] Epoch: 26 [26/100 (26%)] Train loss=0.261599 Test loss=0.293497 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21314017474651337
[5/23] Train loss=0.35925355553627014
[10/23] Train loss=0.21979816257953644
[15/23] Train loss=0.20832006633281708
[20/23] Train loss=0.18591298162937164
Test set avg_accuracy=88.67% avg_sensitivity=67.86%, avg_specificity=94.91% avg_auc=0.9274
Best model saved!! Metric=18.181534315899743!!
Fold[2] Epoch: 27 [27/100 (27%)] Train loss=0.260948 Test loss=0.288931 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20390497148036957
[5/23] Train loss=0.3635559678077698
[10/23] Train loss=0.2143588662147522
[15/23] Train loss=0.2005418986082077
[20/23] Train loss=0.18496167659759521
Test set avg_accuracy=88.70% avg_sensitivity=67.18%, avg_specificity=95.16% avg_auc=0.9262
Fold[2] Epoch: 28 [28/100 (28%)] Train loss=0.257278 Test loss=0.291648 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20851938426494598
[5/23] Train loss=0.34674587845802307
[10/23] Train loss=0.2127199023962021
[15/23] Train loss=0.20682959258556366
[20/23] Train loss=0.18695974349975586
Test set avg_accuracy=88.52% avg_sensitivity=67.63%, avg_specificity=94.79% avg_auc=0.9267
Fold[2] Epoch: 29 [29/100 (29%)] Train loss=0.257019 Test loss=0.289495 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20627354085445404
[5/23] Train loss=0.37363380193710327
[10/23] Train loss=0.2151678204536438
[15/23] Train loss=0.20387256145477295
[20/23] Train loss=0.17844675481319427
Test set avg_accuracy=88.53% avg_sensitivity=65.78%, avg_specificity=95.36% avg_auc=0.9265
Fold[2] Epoch: 30 [30/100 (30%)] Train loss=0.253610 Test loss=0.289784 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20544196665287018
[5/23] Train loss=0.34886616468429565
[10/23] Train loss=0.2092917114496231
[15/23] Train loss=0.20556406676769257
[20/23] Train loss=0.1752852201461792
Test set avg_accuracy=88.47% avg_sensitivity=65.37%, avg_specificity=95.40% avg_auc=0.9254
Fold[2] Epoch: 31 [31/100 (31%)] Train loss=0.254590 Test loss=0.291402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1949160099029541
[5/23] Train loss=0.36326920986175537
[10/23] Train loss=0.20748095214366913
[15/23] Train loss=0.2104668915271759
[20/23] Train loss=0.17901915311813354
Test set avg_accuracy=88.46% avg_sensitivity=64.96%, avg_specificity=95.51% avg_auc=0.9249
Fold[2] Epoch: 32 [32/100 (32%)] Train loss=0.253055 Test loss=0.289761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20070931315422058
[5/23] Train loss=0.3555709421634674
[10/23] Train loss=0.2137090116739273
[15/23] Train loss=0.21594427525997162
[20/23] Train loss=0.18105381727218628
Test set avg_accuracy=88.63% avg_sensitivity=66.14%, avg_specificity=95.38% avg_auc=0.9270
Fold[2] Epoch: 33 [33/100 (33%)] Train loss=0.250743 Test loss=0.287929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20300191640853882
[5/23] Train loss=0.36084988713264465
[10/23] Train loss=0.21385455131530762
[15/23] Train loss=0.20824198424816132
[20/23] Train loss=0.17318442463874817
Test set avg_accuracy=88.56% avg_sensitivity=67.31%, avg_specificity=94.93% avg_auc=0.9259
Fold[2] Epoch: 34 [34/100 (34%)] Train loss=0.248741 Test loss=0.288288 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2009957730770111
[5/23] Train loss=0.33951500058174133
[10/23] Train loss=0.21048405766487122
[15/23] Train loss=0.20132200419902802
[20/23] Train loss=0.180922731757164
Test set avg_accuracy=88.51% avg_sensitivity=67.04%, avg_specificity=94.95% avg_auc=0.9257
Fold[2] Epoch: 35 [35/100 (35%)] Train loss=0.247213 Test loss=0.287346 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20238330960273743
[5/23] Train loss=0.3410678207874298
[10/23] Train loss=0.21295948326587677
[15/23] Train loss=0.1919681578874588
[20/23] Train loss=0.1743517518043518
Test set avg_accuracy=88.59% avg_sensitivity=66.50%, avg_specificity=95.21% avg_auc=0.9262
Fold[2] Epoch: 36 [36/100 (36%)] Train loss=0.245106 Test loss=0.285933 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20384900271892548
[5/23] Train loss=0.35378387570381165
[10/23] Train loss=0.2048722207546234
[15/23] Train loss=0.1954926997423172
[20/23] Train loss=0.16863852739334106
Test set avg_accuracy=88.62% avg_sensitivity=67.00%, avg_specificity=95.10% avg_auc=0.9260
Fold[2] Epoch: 37 [37/100 (37%)] Train loss=0.247716 Test loss=0.286568 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1989053338766098
[5/23] Train loss=0.3535834550857544
[10/23] Train loss=0.2035500854253769
[15/23] Train loss=0.20502543449401855
[20/23] Train loss=0.1696564108133316
Test set avg_accuracy=88.56% avg_sensitivity=67.04%, avg_specificity=95.01% avg_auc=0.9255
Fold[2] Epoch: 38 [38/100 (38%)] Train loss=0.244045 Test loss=0.286642 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19815848767757416
[5/23] Train loss=0.3501025140285492
[10/23] Train loss=0.2089197188615799
[15/23] Train loss=0.19607333838939667
[20/23] Train loss=0.17479602992534637
Test set avg_accuracy=88.71% avg_sensitivity=67.45%, avg_specificity=95.09% avg_auc=0.9255
Fold[2] Epoch: 39 [39/100 (39%)] Train loss=0.242384 Test loss=0.285292 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19969022274017334
[5/23] Train loss=0.33648958802223206
[10/23] Train loss=0.20327794551849365
[15/23] Train loss=0.20012736320495605
[20/23] Train loss=0.16479238867759705
Test set avg_accuracy=88.52% avg_sensitivity=67.59%, avg_specificity=94.81% avg_auc=0.9242
Fold[2] Epoch: 40 [40/100 (40%)] Train loss=0.242594 Test loss=0.286807 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1914721578359604
[5/23] Train loss=0.34746813774108887
[10/23] Train loss=0.20068885385990143
[15/23] Train loss=0.1923855096101761
[20/23] Train loss=0.16623935103416443
Test set avg_accuracy=88.68% avg_sensitivity=70.89%, avg_specificity=94.02% avg_auc=0.9251
Best model saved!! Metric=20.097749684014026!!
Fold[2] Epoch: 41 [41/100 (41%)] Train loss=0.242018 Test loss=0.284094 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18387919664382935
[5/23] Train loss=0.3471032977104187
[10/23] Train loss=0.204238161444664
[15/23] Train loss=0.1953015774488449
[20/23] Train loss=0.17002767324447632
Test set avg_accuracy=88.70% avg_sensitivity=71.47%, avg_specificity=93.87% avg_auc=0.9249
Best model saved!! Metric=20.53084007747887!!
Fold[2] Epoch: 42 [42/100 (42%)] Train loss=0.239246 Test loss=0.283392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19309771060943604
[5/23] Train loss=0.33698123693466187
[10/23] Train loss=0.20768220722675323
[15/23] Train loss=0.1920153796672821
[20/23] Train loss=0.16218233108520508
Test set avg_accuracy=88.66% avg_sensitivity=71.07%, avg_specificity=93.94% avg_auc=0.9248
Fold[2] Epoch: 43 [43/100 (43%)] Train loss=0.235403 Test loss=0.285253 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1821993887424469
[5/23] Train loss=0.33488187193870544
[10/23] Train loss=0.2056674063205719
[15/23] Train loss=0.18801216781139374
[20/23] Train loss=0.17230010032653809
Test set avg_accuracy=88.49% avg_sensitivity=70.16%, avg_specificity=93.99% avg_auc=0.9235
Fold[2] Epoch: 44 [44/100 (44%)] Train loss=0.239239 Test loss=0.288243 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19824792444705963
[5/23] Train loss=0.33109599351882935
[10/23] Train loss=0.19959159195423126
[15/23] Train loss=0.1849125623703003
[20/23] Train loss=0.17063914239406586
Test set avg_accuracy=88.60% avg_sensitivity=69.98%, avg_specificity=94.18% avg_auc=0.9243
Fold[2] Epoch: 45 [45/100 (45%)] Train loss=0.234291 Test loss=0.286154 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19094039499759674
[5/23] Train loss=0.33665671944618225
[10/23] Train loss=0.21454526484012604
[15/23] Train loss=0.1942378431558609
[20/23] Train loss=0.16103316843509674
Test set avg_accuracy=88.66% avg_sensitivity=69.39%, avg_specificity=94.44% avg_auc=0.9225
Fold[2] Epoch: 46 [46/100 (46%)] Train loss=0.236580 Test loss=0.285418 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18426670134067535
[5/23] Train loss=0.3504655957221985
[10/23] Train loss=0.20120000839233398
[15/23] Train loss=0.17981381714344025
[20/23] Train loss=0.1695946305990219
Test set avg_accuracy=88.82% avg_sensitivity=70.80%, avg_specificity=94.22% avg_auc=0.9246
Fold[2] Epoch: 47 [47/100 (47%)] Train loss=0.233522 Test loss=0.281832 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1843801587820053
[5/23] Train loss=0.326381653547287
[10/23] Train loss=0.20425482094287872
[15/23] Train loss=0.19421835243701935
[20/23] Train loss=0.16268423199653625
Test set avg_accuracy=88.63% avg_sensitivity=71.25%, avg_specificity=93.84% avg_auc=0.9242
Fold[2] Epoch: 48 [48/100 (48%)] Train loss=0.233379 Test loss=0.283853 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18321359157562256
[5/23] Train loss=0.33121398091316223
[10/23] Train loss=0.19765295088291168
[15/23] Train loss=0.18168267607688904
[20/23] Train loss=0.16847167909145355
Test set avg_accuracy=88.66% avg_sensitivity=70.75%, avg_specificity=94.03% avg_auc=0.9232
Fold[2] Epoch: 49 [49/100 (49%)] Train loss=0.233143 Test loss=0.286517 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19182166457176208
[5/23] Train loss=0.34091413021087646
[10/23] Train loss=0.19145943224430084
[15/23] Train loss=0.18840184807777405
[20/23] Train loss=0.1507432609796524
Test set avg_accuracy=88.64% avg_sensitivity=71.29%, avg_specificity=93.84% avg_auc=0.9238
Fold[2] Epoch: 50 [50/100 (50%)] Train loss=0.230293 Test loss=0.285212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17818832397460938
[5/23] Train loss=0.33790549635887146
[10/23] Train loss=0.19671539962291718
[15/23] Train loss=0.19341690838336945
[20/23] Train loss=0.1624145209789276
Test set avg_accuracy=88.49% avg_sensitivity=70.98%, avg_specificity=93.75% avg_auc=0.9216
Fold[2] Epoch: 51 [51/100 (51%)] Train loss=0.228864 Test loss=0.287323 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1875593662261963
[5/23] Train loss=0.32052186131477356
[10/23] Train loss=0.19039598107337952
[15/23] Train loss=0.18491773307323456
[20/23] Train loss=0.15492896735668182
Test set avg_accuracy=88.51% avg_sensitivity=70.89%, avg_specificity=93.80% avg_auc=0.9219
Fold[2] Epoch: 52 [52/100 (52%)] Train loss=0.229844 Test loss=0.286354 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1861473172903061
[5/23] Train loss=0.3302345871925354
[10/23] Train loss=0.19590535759925842
[15/23] Train loss=0.1850767582654953
[20/23] Train loss=0.1622200608253479
Test set avg_accuracy=88.43% avg_sensitivity=72.33%, avg_specificity=93.26% avg_auc=0.9204
Fold[2] Epoch: 53 [53/100 (53%)] Train loss=0.227828 Test loss=0.291693 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18713092803955078
[5/23] Train loss=0.3323456645011902
[10/23] Train loss=0.19419613480567932
[15/23] Train loss=0.18428726494312286
[20/23] Train loss=0.15333984792232513
Test set avg_accuracy=88.33% avg_sensitivity=70.98%, avg_specificity=93.53% avg_auc=0.9187
Fold[2] Epoch: 54 [54/100 (54%)] Train loss=0.226527 Test loss=0.292325 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1894206404685974
[5/23] Train loss=0.3278805613517761
[10/23] Train loss=0.1993127465248108
[15/23] Train loss=0.17809323966503143
[20/23] Train loss=0.1533074975013733
Test set avg_accuracy=88.58% avg_sensitivity=72.38%, avg_specificity=93.44% avg_auc=0.9193
Fold[2] Epoch: 55 [55/100 (55%)] Train loss=0.224964 Test loss=0.291912 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18557269871234894
[5/23] Train loss=0.3214382529258728
[10/23] Train loss=0.19829507172107697
[15/23] Train loss=0.19266796112060547
[20/23] Train loss=0.15379750728607178
Test set avg_accuracy=88.44% avg_sensitivity=71.25%, avg_specificity=93.60% avg_auc=0.9198
Fold[2] Epoch: 56 [56/100 (56%)] Train loss=0.226239 Test loss=0.289580 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1785850077867508
[5/23] Train loss=0.3199080526828766
[10/23] Train loss=0.19971540570259094
[15/23] Train loss=0.18278886377811432
[20/23] Train loss=0.15749911963939667
Test set avg_accuracy=88.38% avg_sensitivity=70.89%, avg_specificity=93.63% avg_auc=0.9190
Fold[2] Epoch: 57 [57/100 (57%)] Train loss=0.223576 Test loss=0.289976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18901386857032776
[5/23] Train loss=0.31080183386802673
[10/23] Train loss=0.19671301543712616
[15/23] Train loss=0.18144671618938446
[20/23] Train loss=0.1551297903060913
Test set avg_accuracy=88.25% avg_sensitivity=71.65%, avg_specificity=93.23% avg_auc=0.9185
Fold[2] Epoch: 58 [58/100 (58%)] Train loss=0.224796 Test loss=0.292484 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18843971192836761
[5/23] Train loss=0.3135265111923218
[10/23] Train loss=0.19384728372097015
[15/23] Train loss=0.179525226354599
[20/23] Train loss=0.15873421728610992
Test set avg_accuracy=88.27% avg_sensitivity=71.70%, avg_specificity=93.25% avg_auc=0.9196
Fold[2] Epoch: 59 [59/100 (59%)] Train loss=0.221716 Test loss=0.291180 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17836667597293854
[5/23] Train loss=0.32278233766555786
[10/23] Train loss=0.20138554275035858
[15/23] Train loss=0.17415142059326172
[20/23] Train loss=0.15124475955963135
Test set avg_accuracy=88.28% avg_sensitivity=71.70%, avg_specificity=93.26% avg_auc=0.9167
Fold[2] Epoch: 60 [60/100 (60%)] Train loss=0.220865 Test loss=0.296327 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1751299649477005
[5/23] Train loss=0.3183007836341858
[10/23] Train loss=0.1941978633403778
[15/23] Train loss=0.17569409310817719
[20/23] Train loss=0.1502806842327118
Test set avg_accuracy=88.56% avg_sensitivity=71.34%, avg_specificity=93.72% avg_auc=0.9178
Fold[2] Epoch: 61 [61/100 (61%)] Train loss=0.219282 Test loss=0.293225 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1824292093515396
[5/23] Train loss=0.31244781613349915
[10/23] Train loss=0.20220360159873962
[15/23] Train loss=0.18570588529109955
[20/23] Train loss=0.14649420976638794
Test set avg_accuracy=88.28% avg_sensitivity=70.89%, avg_specificity=93.50% avg_auc=0.9164
Fold[2] Epoch: 62 [62/100 (62%)] Train loss=0.219343 Test loss=0.295166 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1731954663991928
[5/23] Train loss=0.3159625828266144
[10/23] Train loss=0.18786019086837769
[15/23] Train loss=0.17356978356838226
[20/23] Train loss=0.14374057948589325
Test set avg_accuracy=88.17% avg_sensitivity=72.33%, avg_specificity=92.92% avg_auc=0.9156
Fold[2] Epoch: 63 [63/100 (63%)] Train loss=0.215920 Test loss=0.297819 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1771058738231659
[5/23] Train loss=0.2932429909706116
[10/23] Train loss=0.18441960215568542
[15/23] Train loss=0.17921093106269836
[20/23] Train loss=0.1506202071905136
Test set avg_accuracy=88.01% avg_sensitivity=72.33%, avg_specificity=92.72% avg_auc=0.9124
Fold[2] Epoch: 64 [64/100 (64%)] Train loss=0.213959 Test loss=0.304011 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1826576590538025
[5/23] Train loss=0.30740368366241455
[10/23] Train loss=0.190921813249588
[15/23] Train loss=0.18293198943138123
[20/23] Train loss=0.15139128267765045
Test set avg_accuracy=88.11% avg_sensitivity=72.47%, avg_specificity=92.80% avg_auc=0.9120
Fold[2] Epoch: 65 [65/100 (65%)] Train loss=0.216319 Test loss=0.302655 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17687620222568512
[5/23] Train loss=0.3087952733039856
[10/23] Train loss=0.18894338607788086
[15/23] Train loss=0.17523087561130524
[20/23] Train loss=0.14293818175792694
Test set avg_accuracy=87.91% avg_sensitivity=73.60%, avg_specificity=92.20% avg_auc=0.9115
Fold[2] Epoch: 66 [66/100 (66%)] Train loss=0.215344 Test loss=0.309168 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17766067385673523
[5/23] Train loss=0.3036262094974518
[10/23] Train loss=0.1861712485551834
[15/23] Train loss=0.16506798565387726
[20/23] Train loss=0.14654935896396637
Test set avg_accuracy=87.82% avg_sensitivity=73.60%, avg_specificity=92.09% avg_auc=0.9055
Fold[2] Epoch: 67 [67/100 (67%)] Train loss=0.213390 Test loss=0.317352 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19123564660549164
[5/23] Train loss=0.29954949021339417
[10/23] Train loss=0.19639059901237488
[15/23] Train loss=0.17789654433727264
[20/23] Train loss=0.14312489330768585
Test set avg_accuracy=87.76% avg_sensitivity=74.23%, avg_specificity=91.82% avg_auc=0.9089
Fold[2] Epoch: 68 [68/100 (68%)] Train loss=0.213384 Test loss=0.314788 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17522534728050232
[5/23] Train loss=0.294607937335968
[10/23] Train loss=0.19024105370044708
[15/23] Train loss=0.16952267289161682
[20/23] Train loss=0.15218056738376617
Test set avg_accuracy=88.18% avg_sensitivity=73.19%, avg_specificity=92.68% avg_auc=0.9117
Fold[2] Epoch: 69 [69/100 (69%)] Train loss=0.210351 Test loss=0.303813 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18252526223659515
[5/23] Train loss=0.27583810687065125
[10/23] Train loss=0.1890689730644226
[15/23] Train loss=0.17660905420780182
[20/23] Train loss=0.15206392109394073
Test set avg_accuracy=87.76% avg_sensitivity=71.88%, avg_specificity=92.53% avg_auc=0.9092
Fold[2] Epoch: 70 [70/100 (70%)] Train loss=0.209222 Test loss=0.311346 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17728480696678162
[5/23] Train loss=0.30556532740592957
[10/23] Train loss=0.18745872378349304
[15/23] Train loss=0.16921654343605042
[20/23] Train loss=0.14755810797214508
Test set avg_accuracy=87.68% avg_sensitivity=70.30%, avg_specificity=92.89% avg_auc=0.9048
Fold[2] Epoch: 71 [71/100 (71%)] Train loss=0.208344 Test loss=0.314498 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18396775424480438
[5/23] Train loss=0.29123273491859436
[10/23] Train loss=0.1849246621131897
[15/23] Train loss=0.17269718647003174
[20/23] Train loss=0.14298512041568756
Test set avg_accuracy=87.65% avg_sensitivity=73.28%, avg_specificity=91.96% avg_auc=0.9075
Fold[2] Epoch: 72 [72/100 (72%)] Train loss=0.209996 Test loss=0.316209 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1821400672197342
[5/23] Train loss=0.2859402298927307
[10/23] Train loss=0.19049072265625
[15/23] Train loss=0.17179477214813232
[20/23] Train loss=0.14293858408927917
Test set avg_accuracy=87.44% avg_sensitivity=73.92%, avg_specificity=91.50% avg_auc=0.9022
Fold[2] Epoch: 73 [73/100 (73%)] Train loss=0.206659 Test loss=0.327464 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16886411607265472
[5/23] Train loss=0.28692662715911865
[10/23] Train loss=0.18560421466827393
[15/23] Train loss=0.16823704540729523
[20/23] Train loss=0.14480894804000854
Test set avg_accuracy=87.64% avg_sensitivity=74.55%, avg_specificity=91.56% avg_auc=0.9042
Fold[2] Epoch: 74 [74/100 (74%)] Train loss=0.205896 Test loss=0.324276 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18074354529380798
[5/23] Train loss=0.2837819457054138
[10/23] Train loss=0.1823672652244568
[15/23] Train loss=0.17218592762947083
[20/23] Train loss=0.1478477269411087
Test set avg_accuracy=87.61% avg_sensitivity=73.96%, avg_specificity=91.70% avg_auc=0.9025
Fold[2] Epoch: 75 [75/100 (75%)] Train loss=0.203887 Test loss=0.326226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16726262867450714
[5/23] Train loss=0.2860408127307892
[10/23] Train loss=0.18074263632297516
[15/23] Train loss=0.1652410924434662
[20/23] Train loss=0.14894117414951324
Test set avg_accuracy=87.55% avg_sensitivity=73.60%, avg_specificity=91.74% avg_auc=0.9015
Fold[2] Epoch: 76 [76/100 (76%)] Train loss=0.204893 Test loss=0.328172 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17265594005584717
[5/23] Train loss=0.27980586886405945
[10/23] Train loss=0.18831871449947357
[15/23] Train loss=0.1772945076227188
[20/23] Train loss=0.1379399597644806
Test set avg_accuracy=87.40% avg_sensitivity=72.33%, avg_specificity=91.92% avg_auc=0.8977
Fold[2] Epoch: 77 [77/100 (77%)] Train loss=0.203598 Test loss=0.332522 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16673560440540314
[5/23] Train loss=0.2807908058166504
[10/23] Train loss=0.18233785033226013
[15/23] Train loss=0.1780332773923874
[20/23] Train loss=0.13515716791152954
Test set avg_accuracy=87.44% avg_sensitivity=72.97%, avg_specificity=91.78% avg_auc=0.9011
Fold[2] Epoch: 78 [78/100 (78%)] Train loss=0.201640 Test loss=0.329764 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17484013736248016
[5/23] Train loss=0.2870546579360962
[10/23] Train loss=0.18183358013629913
[15/23] Train loss=0.16284698247909546
[20/23] Train loss=0.14238686859607697
Test set avg_accuracy=87.44% avg_sensitivity=73.42%, avg_specificity=91.65% avg_auc=0.9009
Fold[2] Epoch: 79 [79/100 (79%)] Train loss=0.202663 Test loss=0.329593 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17198556661605835
[5/23] Train loss=0.2875375747680664
[10/23] Train loss=0.17762047052383423
[15/23] Train loss=0.15998131036758423
[20/23] Train loss=0.13678298890590668
Test set avg_accuracy=87.13% avg_sensitivity=72.24%, avg_specificity=91.59% avg_auc=0.9007
Fold[2] Epoch: 80 [80/100 (80%)] Train loss=0.199410 Test loss=0.331116 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16556842625141144
[5/23] Train loss=0.29356488585472107
[10/23] Train loss=0.17795006930828094
[15/23] Train loss=0.1599653959274292
[20/23] Train loss=0.13512878119945526
Test set avg_accuracy=87.32% avg_sensitivity=72.69%, avg_specificity=91.71% avg_auc=0.8972
Fold[2] Epoch: 81 [81/100 (81%)] Train loss=0.200490 Test loss=0.335602 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16729196906089783
[5/23] Train loss=0.29343798756599426
[10/23] Train loss=0.1768895536661148
[15/23] Train loss=0.16512955725193024
[20/23] Train loss=0.14048154652118683
Test set avg_accuracy=87.21% avg_sensitivity=74.37%, avg_specificity=91.06% avg_auc=0.8975
Fold[2] Epoch: 82 [82/100 (82%)] Train loss=0.196344 Test loss=0.343214 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1737881749868393
[5/23] Train loss=0.27039316296577454
[10/23] Train loss=0.17180001735687256
[15/23] Train loss=0.16266493499279022
[20/23] Train loss=0.13512520492076874
Test set avg_accuracy=86.97% avg_sensitivity=74.19%, avg_specificity=90.80% avg_auc=0.8982
Fold[2] Epoch: 83 [83/100 (83%)] Train loss=0.197831 Test loss=0.345315 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16508932411670685
[5/23] Train loss=0.2816917300224304
[10/23] Train loss=0.1703997254371643
[15/23] Train loss=0.15997517108917236
[20/23] Train loss=0.13818272948265076
Test set avg_accuracy=86.54% avg_sensitivity=73.87%, avg_specificity=90.34% avg_auc=0.8917
Fold[2] Epoch: 84 [84/100 (84%)] Train loss=0.196803 Test loss=0.356976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15491311252117157
[5/23] Train loss=0.2728389501571655
[10/23] Train loss=0.17380103468894958
[15/23] Train loss=0.1509729027748108
[20/23] Train loss=0.12877079844474792
Test set avg_accuracy=86.65% avg_sensitivity=75.00%, avg_specificity=90.14% avg_auc=0.8973
Fold[2] Epoch: 85 [85/100 (85%)] Train loss=0.195222 Test loss=0.354296 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16061918437480927
[5/23] Train loss=0.26525336503982544
[10/23] Train loss=0.18618564307689667
[15/23] Train loss=0.16079863905906677
[20/23] Train loss=0.14105693995952606
Test set avg_accuracy=86.24% avg_sensitivity=73.92%, avg_specificity=89.94% avg_auc=0.8924
Fold[2] Epoch: 86 [86/100 (86%)] Train loss=0.192416 Test loss=0.360992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1684338003396988
[5/23] Train loss=0.2692931890487671
[10/23] Train loss=0.17467297613620758
[15/23] Train loss=0.1601109504699707
[20/23] Train loss=0.12499519437551498
Test set avg_accuracy=86.17% avg_sensitivity=74.86%, avg_specificity=89.56% avg_auc=0.8924
Fold[2] Epoch: 87 [87/100 (87%)] Train loss=0.191495 Test loss=0.364844 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17474055290222168
[5/23] Train loss=0.25225070118904114
[10/23] Train loss=0.1669517606496811
[15/23] Train loss=0.16456405818462372
[20/23] Train loss=0.1343042552471161
Test set avg_accuracy=86.81% avg_sensitivity=73.82%, avg_specificity=90.71% avg_auc=0.8947
Fold[2] Epoch: 88 [88/100 (88%)] Train loss=0.189553 Test loss=0.350424 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17290866374969482
[5/23] Train loss=0.2617419362068176
[10/23] Train loss=0.1696232706308365
[15/23] Train loss=0.15100595355033875
[20/23] Train loss=0.13408733904361725
Test set avg_accuracy=86.45% avg_sensitivity=73.69%, avg_specificity=90.28% avg_auc=0.8903
Fold[2] Epoch: 89 [89/100 (89%)] Train loss=0.188429 Test loss=0.359831 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16254909336566925
[5/23] Train loss=0.2557763457298279
[10/23] Train loss=0.17426574230194092
[15/23] Train loss=0.1581427901983261
[20/23] Train loss=0.12051520496606827
Test set avg_accuracy=86.51% avg_sensitivity=73.33%, avg_specificity=90.47% avg_auc=0.8896
Fold[2] Epoch: 90 [90/100 (90%)] Train loss=0.187691 Test loss=0.358319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16307666897773743
[5/23] Train loss=0.2623944580554962
[10/23] Train loss=0.17238792777061462
[15/23] Train loss=0.1634170413017273
[20/23] Train loss=0.13395024836063385
Test set avg_accuracy=86.24% avg_sensitivity=72.74%, avg_specificity=90.29% avg_auc=0.8875
Fold[2] Epoch: 91 [91/100 (91%)] Train loss=0.189232 Test loss=0.368027 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17259277403354645
[5/23] Train loss=0.26166924834251404
[10/23] Train loss=0.16904588043689728
[15/23] Train loss=0.1473778784275055
[20/23] Train loss=0.13500748574733734
Test set avg_accuracy=86.48% avg_sensitivity=73.51%, avg_specificity=90.37% avg_auc=0.8935
Fold[2] Epoch: 92 [92/100 (92%)] Train loss=0.186983 Test loss=0.358084 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16300880908966064
[5/23] Train loss=0.2619326114654541
[10/23] Train loss=0.16530001163482666
[15/23] Train loss=0.1579904556274414
[20/23] Train loss=0.12693320214748383
Test set avg_accuracy=86.36% avg_sensitivity=73.37%, avg_specificity=90.26% avg_auc=0.8902
Fold[2] Epoch: 93 [93/100 (93%)] Train loss=0.185193 Test loss=0.365461 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15752865374088287
[5/23] Train loss=0.2515404224395752
[10/23] Train loss=0.17061439156532288
[15/23] Train loss=0.15384234488010406
[20/23] Train loss=0.12845733761787415
Test set avg_accuracy=86.33% avg_sensitivity=72.06%, avg_specificity=90.61% avg_auc=0.8823
Fold[2] Epoch: 94 [94/100 (94%)] Train loss=0.185542 Test loss=0.370164 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15800797939300537
[5/23] Train loss=0.24869805574417114
[10/23] Train loss=0.15993744134902954
[15/23] Train loss=0.14097069203853607
[20/23] Train loss=0.12046898156404495
Test set avg_accuracy=86.11% avg_sensitivity=74.59%, avg_specificity=89.57% avg_auc=0.8901
Fold[2] Epoch: 95 [95/100 (95%)] Train loss=0.182388 Test loss=0.373507 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16174231469631195
[5/23] Train loss=0.2460666000843048
[10/23] Train loss=0.16396945714950562
[15/23] Train loss=0.15420113503932953
[20/23] Train loss=0.13016194105148315
Test set avg_accuracy=86.26% avg_sensitivity=71.47%, avg_specificity=90.70% avg_auc=0.8826
Fold[2] Epoch: 96 [96/100 (96%)] Train loss=0.184159 Test loss=0.373710 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16237863898277283
[5/23] Train loss=0.24786290526390076
[10/23] Train loss=0.1599697321653366
[15/23] Train loss=0.15774251520633698
[20/23] Train loss=0.12185599654912949
Test set avg_accuracy=86.36% avg_sensitivity=73.96%, avg_specificity=90.09% avg_auc=0.8898
Fold[2] Epoch: 97 [97/100 (97%)] Train loss=0.181450 Test loss=0.367668 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16084197163581848
[5/23] Train loss=0.25345826148986816
[10/23] Train loss=0.16946391761302948
[15/23] Train loss=0.15700644254684448
[20/23] Train loss=0.11947464942932129
Test set avg_accuracy=85.72% avg_sensitivity=73.73%, avg_specificity=89.31% avg_auc=0.8823
Fold[2] Epoch: 98 [98/100 (98%)] Train loss=0.181119 Test loss=0.383103 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15929821133613586
[5/23] Train loss=0.24622024595737457
[10/23] Train loss=0.16420918703079224
[15/23] Train loss=0.14438924193382263
[20/23] Train loss=0.12448596954345703
Test set avg_accuracy=85.53% avg_sensitivity=73.55%, avg_specificity=89.12% avg_auc=0.8817
Fold[2] Epoch: 99 [99/100 (99%)] Train loss=0.177524 Test loss=0.383103 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15952202677726746
[5/23] Train loss=0.24973759055137634
[10/23] Train loss=0.16513772308826447
[15/23] Train loss=0.1484401375055313
[20/23] Train loss=0.12537726759910583
Test set avg_accuracy=85.25% avg_sensitivity=73.10%, avg_specificity=88.89% avg_auc=0.8806
Fold[2] Epoch: 100 [100/100 (100%)] Train loss=0.176821 Test loss=0.389208 Current lr=[3.9999999999999996e-05]

Fold[2] Best Result: acc=88.70109546165884 sen=71.47377938517178, spe=93.86952393869524, auc=0.9248644129195301!
[0/23] Train loss=0.6958971619606018
[5/23] Train loss=0.6835086345672607
[10/23] Train loss=0.5533612966537476
[15/23] Train loss=0.529504656791687
[20/23] Train loss=0.4845634698867798
Test set avg_accuracy=68.33% avg_sensitivity=0.00%, avg_specificity=99.97% avg_auc=0.6841
Best model saved!! Metric=-89.29046006145397!!
Fold[3] Epoch: 1 [1/100 (1%)] Train loss=0.546343 Test loss=0.819352 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4826110005378723
[5/23] Train loss=0.5008578896522522
[10/23] Train loss=0.4350398778915405
[15/23] Train loss=0.4373696744441986
[20/23] Train loss=0.38126951456069946
Test set avg_accuracy=72.97% avg_sensitivity=26.63%, avg_specificity=94.42% avg_auc=0.8348
Best model saved!! Metric=-48.49543933392535!!
Fold[3] Epoch: 2 [2/100 (2%)] Train loss=0.429407 Test loss=0.662574 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.38042858242988586
[5/23] Train loss=0.4536939263343811
[10/23] Train loss=0.3670477271080017
[15/23] Train loss=0.37647122144699097
[20/23] Train loss=0.33664608001708984
Test set avg_accuracy=76.68% avg_sensitivity=39.77%, avg_specificity=93.78% avg_auc=0.8567
Best model saved!! Metric=-30.09919695682398!!
Fold[3] Epoch: 3 [3/100 (3%)] Train loss=0.381420 Test loss=0.620987 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3534046411514282
[5/23] Train loss=0.44510409235954285
[10/23] Train loss=0.3301912546157837
[15/23] Train loss=0.34604495763778687
[20/23] Train loss=0.3007931113243103
Test set avg_accuracy=77.75% avg_sensitivity=41.99%, avg_specificity=94.32% avg_auc=0.8601
Best model saved!! Metric=-25.9338594952954!!
Fold[3] Epoch: 4 [4/100 (4%)] Train loss=0.354552 Test loss=0.614187 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3244989514350891
[5/23] Train loss=0.43684151768684387
[10/23] Train loss=0.3077533543109894
[15/23] Train loss=0.318043053150177
[20/23] Train loss=0.2720828950405121
Test set avg_accuracy=79.36% avg_sensitivity=46.67%, avg_specificity=94.50% avg_auc=0.8707
Best model saved!! Metric=-18.406342001343866!!
Fold[3] Epoch: 5 [5/100 (5%)] Train loss=0.336951 Test loss=0.566130 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.311021625995636
[5/23] Train loss=0.42597702145576477
[10/23] Train loss=0.2863944470882416
[15/23] Train loss=0.2933303415775299
[20/23] Train loss=0.2596234679222107
Test set avg_accuracy=81.18% avg_sensitivity=53.03%, avg_specificity=94.21% avg_auc=0.8818
Best model saved!! Metric=-9.400532845446968!!
Fold[3] Epoch: 6 [6/100 (6%)] Train loss=0.321387 Test loss=0.515125 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29937225580215454
[5/23] Train loss=0.41283702850341797
[10/23] Train loss=0.2754504382610321
[15/23] Train loss=0.2800780236721039
[20/23] Train loss=0.24103687703609467
Test set avg_accuracy=81.90% avg_sensitivity=56.38%, avg_specificity=93.72% avg_auc=0.8870
Best model saved!! Metric=-5.294231015217143!!
Fold[3] Epoch: 7 [7/100 (7%)] Train loss=0.315049 Test loss=0.486565 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27879220247268677
[5/23] Train loss=0.3922387957572937
[10/23] Train loss=0.26924118399620056
[15/23] Train loss=0.275020033121109
[20/23] Train loss=0.22989515960216522
Test set avg_accuracy=82.54% avg_sensitivity=60.43%, avg_specificity=92.78% avg_auc=0.8928
Best model saved!! Metric=-0.972178269082117!!
Fold[3] Epoch: 8 [8/100 (8%)] Train loss=0.301892 Test loss=0.463334 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2696206867694855
[5/23] Train loss=0.3915526866912842
[10/23] Train loss=0.2530948221683502
[15/23] Train loss=0.25926217436790466
[20/23] Train loss=0.23459982872009277
Test set avg_accuracy=82.67% avg_sensitivity=60.40%, avg_specificity=92.98% avg_auc=0.8959
Best model saved!! Metric=-0.3672676046291885!!
Fold[3] Epoch: 9 [9/100 (9%)] Train loss=0.294115 Test loss=0.466807 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2653508186340332
[5/23] Train loss=0.41164630651474
[10/23] Train loss=0.25293222069740295
[15/23] Train loss=0.25653156638145447
[20/23] Train loss=0.22827616333961487
Test set avg_accuracy=83.10% avg_sensitivity=61.76%, avg_specificity=92.98% avg_auc=0.8995
Best model saved!! Metric=1.789057642870847!!
Fold[3] Epoch: 10 [10/100 (10%)] Train loss=0.292719 Test loss=0.448018 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25230100750923157
[5/23] Train loss=0.39545249938964844
[10/23] Train loss=0.2491411715745926
[15/23] Train loss=0.2484530806541443
[20/23] Train loss=0.20846712589263916
Test set avg_accuracy=83.07% avg_sensitivity=61.92%, avg_specificity=92.86% avg_auc=0.9002
Best model saved!! Metric=1.8694420138583787!!
Fold[3] Epoch: 11 [11/100 (11%)] Train loss=0.284800 Test loss=0.450653 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25013697147369385
[5/23] Train loss=0.3812333643436432
[10/23] Train loss=0.236763134598732
[15/23] Train loss=0.24491310119628906
[20/23] Train loss=0.21917499601840973
Test set avg_accuracy=83.39% avg_sensitivity=63.35%, avg_specificity=92.67% avg_auc=0.9013
Best model saved!! Metric=3.543447897130306!!
Fold[3] Epoch: 12 [12/100 (12%)] Train loss=0.278628 Test loss=0.445447 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25172126293182373
[5/23] Train loss=0.39550650119781494
[10/23] Train loss=0.2423182874917984
[15/23] Train loss=0.24453118443489075
[20/23] Train loss=0.21179738640785217
Test set avg_accuracy=83.46% avg_sensitivity=64.15%, avg_specificity=92.41% avg_auc=0.9021
Best model saved!! Metric=4.227241013907128!!
Fold[3] Epoch: 13 [13/100 (13%)] Train loss=0.276326 Test loss=0.436340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23645098507404327
[5/23] Train loss=0.39058810472488403
[10/23] Train loss=0.23662640154361725
[15/23] Train loss=0.21778343617916107
[20/23] Train loss=0.20065072178840637
Test set avg_accuracy=83.74% avg_sensitivity=64.28%, avg_specificity=92.75% avg_auc=0.9042
Best model saved!! Metric=5.184909340994549!!
Fold[3] Epoch: 14 [14/100 (14%)] Train loss=0.269401 Test loss=0.439700 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2355622947216034
[5/23] Train loss=0.3944588303565979
[10/23] Train loss=0.23415853083133698
[15/23] Train loss=0.23274020850658417
[20/23] Train loss=0.20229877531528473
Test set avg_accuracy=83.76% avg_sensitivity=65.01%, avg_specificity=92.44% avg_auc=0.9051
Best model saved!! Metric=5.718943172546377!!
Fold[3] Epoch: 15 [15/100 (15%)] Train loss=0.269868 Test loss=0.426768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2272031605243683
[5/23] Train loss=0.3905799984931946
[10/23] Train loss=0.2355620115995407
[15/23] Train loss=0.21831023693084717
[20/23] Train loss=0.1976776421070099
Test set avg_accuracy=83.84% avg_sensitivity=64.61%, avg_specificity=92.75% avg_auc=0.9061
Best model saved!! Metric=5.816851813439889!!
Fold[3] Epoch: 16 [16/100 (16%)] Train loss=0.266183 Test loss=0.432086 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2258002758026123
[5/23] Train loss=0.38881194591522217
[10/23] Train loss=0.22189368307590485
[15/23] Train loss=0.2363075613975525
[20/23] Train loss=0.19671644270420074
Test set avg_accuracy=83.82% avg_sensitivity=65.54%, avg_specificity=92.29% avg_auc=0.9061
Best model saved!! Metric=6.2620182427445314!!
Fold[3] Epoch: 17 [17/100 (17%)] Train loss=0.264226 Test loss=0.424160 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22819431126117706
[5/23] Train loss=0.38182932138442993
[10/23] Train loss=0.22136546671390533
[15/23] Train loss=0.21874043345451355
[20/23] Train loss=0.20262135565280914
Test set avg_accuracy=83.92% avg_sensitivity=64.84%, avg_specificity=92.75% avg_auc=0.9056
Fold[3] Epoch: 18 [18/100 (18%)] Train loss=0.260617 Test loss=0.430246 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22298873960971832
[5/23] Train loss=0.3791985511779785
[10/23] Train loss=0.2152659147977829
[15/23] Train loss=0.21282392740249634
[20/23] Train loss=0.18602746725082397
Test set avg_accuracy=83.85% avg_sensitivity=63.75%, avg_specificity=93.16% avg_auc=0.9045
Fold[3] Epoch: 19 [19/100 (19%)] Train loss=0.259846 Test loss=0.434752 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21564950048923492
[5/23] Train loss=0.3690345287322998
[10/23] Train loss=0.22461441159248352
[15/23] Train loss=0.21262085437774658
[20/23] Train loss=0.18876169621944427
Test set avg_accuracy=84.25% avg_sensitivity=66.17%, avg_specificity=92.63% avg_auc=0.9079
Best model saved!! Metric=7.841588249550966!!
Fold[3] Epoch: 20 [20/100 (20%)] Train loss=0.254293 Test loss=0.420076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21444319188594818
[5/23] Train loss=0.37026140093803406
[10/23] Train loss=0.21160729229450226
[15/23] Train loss=0.2206328958272934
[20/23] Train loss=0.18386180698871613
Test set avg_accuracy=84.07% avg_sensitivity=66.04%, avg_specificity=92.43% avg_auc=0.9070
Fold[3] Epoch: 21 [21/100 (21%)] Train loss=0.254702 Test loss=0.415811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21716493368148804
[5/23] Train loss=0.365682989358902
[10/23] Train loss=0.21433863043785095
[15/23] Train loss=0.20748202502727509
[20/23] Train loss=0.17579685151576996
Test set avg_accuracy=84.25% avg_sensitivity=67.00%, avg_specificity=92.24% avg_auc=0.9077
Best model saved!! Metric=8.261215662919353!!
Fold[3] Epoch: 22 [22/100 (22%)] Train loss=0.249658 Test loss=0.410218 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21468010544776917
[5/23] Train loss=0.3766275644302368
[10/23] Train loss=0.2120233029127121
[15/23] Train loss=0.22258669137954712
[20/23] Train loss=0.1825360804796219
Test set avg_accuracy=84.25% avg_sensitivity=67.20%, avg_specificity=92.15% avg_auc=0.9094
Best model saved!! Metric=8.53594034977693!!
Fold[3] Epoch: 23 [23/100 (23%)] Train loss=0.252243 Test loss=0.401130 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2115778923034668
[5/23] Train loss=0.35975757241249084
[10/23] Train loss=0.21802404522895813
[15/23] Train loss=0.20979012548923492
[20/23] Train loss=0.17754605412483215
Test set avg_accuracy=83.98% avg_sensitivity=64.91%, avg_specificity=92.81% avg_auc=0.9065
Fold[3] Epoch: 24 [24/100 (24%)] Train loss=0.247410 Test loss=0.418337 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21579895913600922
[5/23] Train loss=0.3626719117164612
[10/23] Train loss=0.21786552667617798
[15/23] Train loss=0.21023425459861755
[20/23] Train loss=0.17831750214099884
Test set avg_accuracy=84.23% avg_sensitivity=65.51%, avg_specificity=92.90% avg_auc=0.9068
Fold[3] Epoch: 25 [25/100 (25%)] Train loss=0.248264 Test loss=0.412137 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20973901450634003
[5/23] Train loss=0.3659866452217102
[10/23] Train loss=0.21351736783981323
[15/23] Train loss=0.21222376823425293
[20/23] Train loss=0.17832759022712708
Test set avg_accuracy=84.26% avg_sensitivity=64.88%, avg_specificity=93.24% avg_auc=0.9092
Fold[3] Epoch: 26 [26/100 (26%)] Train loss=0.246388 Test loss=0.409987 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20366114377975464
[5/23] Train loss=0.37132298946380615
[10/23] Train loss=0.20773033797740936
[15/23] Train loss=0.2137317806482315
[20/23] Train loss=0.17695245146751404
Test set avg_accuracy=84.16% avg_sensitivity=64.44%, avg_specificity=93.29% avg_auc=0.9079
Fold[3] Epoch: 27 [27/100 (27%)] Train loss=0.244480 Test loss=0.412909 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20683905482292175
[5/23] Train loss=0.3658032715320587
[10/23] Train loss=0.20990660786628723
[15/23] Train loss=0.20207691192626953
[20/23] Train loss=0.17085714638233185
Test set avg_accuracy=84.10% avg_sensitivity=65.04%, avg_specificity=92.93% avg_auc=0.9084
Fold[3] Epoch: 28 [28/100 (28%)] Train loss=0.242273 Test loss=0.404384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1996079683303833
[5/23] Train loss=0.35738497972488403
[10/23] Train loss=0.2118428647518158
[15/23] Train loss=0.19709166884422302
[20/23] Train loss=0.17616528272628784
Test set avg_accuracy=84.17% avg_sensitivity=64.88%, avg_specificity=93.10% avg_auc=0.9096
Fold[3] Epoch: 29 [29/100 (29%)] Train loss=0.240782 Test loss=0.397795 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19853892922401428
[5/23] Train loss=0.3514397144317627
[10/23] Train loss=0.20453009009361267
[15/23] Train loss=0.20259998738765717
[20/23] Train loss=0.17276129126548767
Test set avg_accuracy=84.23% avg_sensitivity=64.81%, avg_specificity=93.23% avg_auc=0.9091
Fold[3] Epoch: 30 [30/100 (30%)] Train loss=0.238855 Test loss=0.398913 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2055688053369522
[5/23] Train loss=0.351535826921463
[10/23] Train loss=0.20343290269374847
[15/23] Train loss=0.19886274635791779
[20/23] Train loss=0.1701229363679886
Test set avg_accuracy=84.44% avg_sensitivity=66.00%, avg_specificity=92.98% avg_auc=0.9107
Fold[3] Epoch: 31 [31/100 (31%)] Train loss=0.237412 Test loss=0.390273 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2074911892414093
[5/23] Train loss=0.3435786962509155
[10/23] Train loss=0.21626752614974976
[15/23] Train loss=0.20179025828838348
[20/23] Train loss=0.17323166131973267
Test set avg_accuracy=84.51% avg_sensitivity=65.64%, avg_specificity=93.26% avg_auc=0.9121
Best model saved!! Metric=8.619883877057507!!
Fold[3] Epoch: 32 [32/100 (32%)] Train loss=0.238231 Test loss=0.390193 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19913414120674133
[5/23] Train loss=0.35068219900131226
[10/23] Train loss=0.20705285668373108
[15/23] Train loss=0.19123117625713348
[20/23] Train loss=0.17725732922554016
Test set avg_accuracy=84.30% avg_sensitivity=64.74%, avg_specificity=93.36% avg_auc=0.9120
Fold[3] Epoch: 33 [33/100 (33%)] Train loss=0.237702 Test loss=0.390501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19932813942432404
[5/23] Train loss=0.3409431278705597
[10/23] Train loss=0.19971925020217896
[15/23] Train loss=0.1963711380958557
[20/23] Train loss=0.16718865931034088
Test set avg_accuracy=83.94% avg_sensitivity=63.08%, avg_specificity=93.59% avg_auc=0.9085
Fold[3] Epoch: 34 [34/100 (34%)] Train loss=0.233353 Test loss=0.405792 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19960971176624298
[5/23] Train loss=0.35029667615890503
[10/23] Train loss=0.2009817510843277
[15/23] Train loss=0.19042880833148956
[20/23] Train loss=0.16887050867080688
Test set avg_accuracy=84.38% avg_sensitivity=65.51%, avg_specificity=93.12% avg_auc=0.9121
Fold[3] Epoch: 35 [35/100 (35%)] Train loss=0.234381 Test loss=0.386774 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19998398423194885
[5/23] Train loss=0.3441973924636841
[10/23] Train loss=0.19666612148284912
[15/23] Train loss=0.19479458034038544
[20/23] Train loss=0.17166225612163544
Test set avg_accuracy=84.44% avg_sensitivity=65.14%, avg_specificity=93.38% avg_auc=0.9115
Fold[3] Epoch: 36 [36/100 (36%)] Train loss=0.231377 Test loss=0.392941 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19054795801639557
[5/23] Train loss=0.35180190205574036
[10/23] Train loss=0.20062030851840973
[15/23] Train loss=0.18996809422969818
[20/23] Train loss=0.16105544567108154
Test set avg_accuracy=84.51% avg_sensitivity=65.87%, avg_specificity=93.15% avg_auc=0.9114
Best model saved!! Metric=8.672590135830186!!
Fold[3] Epoch: 37 [37/100 (37%)] Train loss=0.230169 Test loss=0.391274 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1916220784187317
[5/23] Train loss=0.3558845520019531
[10/23] Train loss=0.2043861448764801
[15/23] Train loss=0.1916753351688385
[20/23] Train loss=0.16820676624774933
Test set avg_accuracy=84.08% avg_sensitivity=63.91%, avg_specificity=93.43% avg_auc=0.9101
Fold[3] Epoch: 38 [38/100 (38%)] Train loss=0.231618 Test loss=0.392468 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18775713443756104
[5/23] Train loss=0.34838125109672546
[10/23] Train loss=0.19956056773662567
[15/23] Train loss=0.19428889453411102
[20/23] Train loss=0.1672314703464508
Test set avg_accuracy=84.14% avg_sensitivity=64.58%, avg_specificity=93.20% avg_auc=0.9101
Fold[3] Epoch: 39 [39/100 (39%)] Train loss=0.227411 Test loss=0.396321 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19596394896507263
[5/23] Train loss=0.33499017357826233
[10/23] Train loss=0.2059195637702942
[15/23] Train loss=0.18259736895561218
[20/23] Train loss=0.1603524088859558
Test set avg_accuracy=84.25% avg_sensitivity=65.80%, avg_specificity=92.80% avg_auc=0.9109
Fold[3] Epoch: 40 [40/100 (40%)] Train loss=0.227969 Test loss=0.385715 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1901446431875229
[5/23] Train loss=0.3358176052570343
[10/23] Train loss=0.19729921221733093
[15/23] Train loss=0.19081375002861023
[20/23] Train loss=0.1661200374364853
Test set avg_accuracy=83.94% avg_sensitivity=63.95%, avg_specificity=93.20% avg_auc=0.9097
Fold[3] Epoch: 41 [41/100 (41%)] Train loss=0.225075 Test loss=0.394416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18941569328308105
[5/23] Train loss=0.33608922362327576
[10/23] Train loss=0.19774891436100006
[15/23] Train loss=0.1910417526960373
[20/23] Train loss=0.1587817668914795
Test set avg_accuracy=84.28% avg_sensitivity=65.21%, avg_specificity=93.12% avg_auc=0.9124
Fold[3] Epoch: 42 [42/100 (42%)] Train loss=0.225949 Test loss=0.386737 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18979161977767944
[5/23] Train loss=0.33186450600624084
[10/23] Train loss=0.2000061422586441
[15/23] Train loss=0.18882083892822266
[20/23] Train loss=0.1670936793088913
Test set avg_accuracy=84.33% avg_sensitivity=64.54%, avg_specificity=93.49% avg_auc=0.9128
Fold[3] Epoch: 43 [43/100 (43%)] Train loss=0.224985 Test loss=0.391215 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1917048543691635
[5/23] Train loss=0.3466586768627167
[10/23] Train loss=0.1986408829689026
[15/23] Train loss=0.1783633977174759
[20/23] Train loss=0.1531878560781479
Test set avg_accuracy=83.93% avg_sensitivity=63.08%, avg_specificity=93.58% avg_auc=0.9095
Fold[3] Epoch: 44 [44/100 (44%)] Train loss=0.223321 Test loss=0.406178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1880183219909668
[5/23] Train loss=0.3328859806060791
[10/23] Train loss=0.19904036819934845
[15/23] Train loss=0.18623709678649902
[20/23] Train loss=0.1618620902299881
Test set avg_accuracy=84.07% avg_sensitivity=63.78%, avg_specificity=93.47% avg_auc=0.9112
Fold[3] Epoch: 45 [45/100 (45%)] Train loss=0.220706 Test loss=0.401188 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19250504672527313
[5/23] Train loss=0.3429710865020752
[10/23] Train loss=0.2060471624135971
[15/23] Train loss=0.19131606817245483
[20/23] Train loss=0.15727871656417847
Test set avg_accuracy=84.15% avg_sensitivity=64.21%, avg_specificity=93.38% avg_auc=0.9113
Fold[3] Epoch: 46 [46/100 (46%)] Train loss=0.223357 Test loss=0.395256 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1760869324207306
[5/23] Train loss=0.33336055278778076
[10/23] Train loss=0.19481703639030457
[15/23] Train loss=0.18406565487384796
[20/23] Train loss=0.16022075712680817
Test set avg_accuracy=84.10% avg_sensitivity=63.28%, avg_specificity=93.75% avg_auc=0.9118
Fold[3] Epoch: 47 [47/100 (47%)] Train loss=0.219777 Test loss=0.398376 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18194110691547394
[5/23] Train loss=0.33750346302986145
[10/23] Train loss=0.1896548867225647
[15/23] Train loss=0.1840260773897171
[20/23] Train loss=0.16180749237537384
Test set avg_accuracy=84.24% avg_sensitivity=63.78%, avg_specificity=93.72% avg_auc=0.9126
Fold[3] Epoch: 48 [48/100 (48%)] Train loss=0.219720 Test loss=0.397380 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18496370315551758
[5/23] Train loss=0.33764854073524475
[10/23] Train loss=0.19181182980537415
[15/23] Train loss=0.17822867631912231
[20/23] Train loss=0.15433651208877563
Test set avg_accuracy=84.13% avg_sensitivity=62.29%, avg_specificity=94.24% avg_auc=0.9114
Fold[3] Epoch: 49 [49/100 (49%)] Train loss=0.217541 Test loss=0.400547 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1824997216463089
[5/23] Train loss=0.3341864049434662
[10/23] Train loss=0.2060236632823944
[15/23] Train loss=0.17103613913059235
[20/23] Train loss=0.15336041152477264
Test set avg_accuracy=83.87% avg_sensitivity=61.69%, avg_specificity=94.15% avg_auc=0.9103
Fold[3] Epoch: 50 [50/100 (50%)] Train loss=0.217828 Test loss=0.405532 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18160179257392883
[5/23] Train loss=0.33261680603027344
[10/23] Train loss=0.19451148808002472
[15/23] Train loss=0.17670311033725739
[20/23] Train loss=0.1575808823108673
Test set avg_accuracy=83.91% avg_sensitivity=62.19%, avg_specificity=93.96% avg_auc=0.9088
Fold[3] Epoch: 51 [51/100 (51%)] Train loss=0.217498 Test loss=0.410886 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18366356194019318
[5/23] Train loss=0.32849547266960144
[10/23] Train loss=0.20088420808315277
[15/23] Train loss=0.18708668649196625
[20/23] Train loss=0.15373533964157104
Test set avg_accuracy=84.27% avg_sensitivity=63.25%, avg_specificity=94.01% avg_auc=0.9105
Fold[3] Epoch: 52 [52/100 (52%)] Train loss=0.217115 Test loss=0.402283 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1886180192232132
[5/23] Train loss=0.3335081934928894
[10/23] Train loss=0.19562463462352753
[15/23] Train loss=0.18014714121818542
[20/23] Train loss=0.15409809350967407
Test set avg_accuracy=84.22% avg_sensitivity=63.02%, avg_specificity=94.04% avg_auc=0.9112
Fold[3] Epoch: 53 [53/100 (53%)] Train loss=0.215970 Test loss=0.408352 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18045388162136078
[5/23] Train loss=0.33242174983024597
[10/23] Train loss=0.19636434316635132
[15/23] Train loss=0.17581675946712494
[20/23] Train loss=0.15142488479614258
Test set avg_accuracy=84.05% avg_sensitivity=61.00%, avg_specificity=94.73% avg_auc=0.9106
Fold[3] Epoch: 54 [54/100 (54%)] Train loss=0.215709 Test loss=0.417175 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18217094242572784
[5/23] Train loss=0.34470751881599426
[10/23] Train loss=0.19629818201065063
[15/23] Train loss=0.1813431680202484
[20/23] Train loss=0.1502687931060791
Test set avg_accuracy=83.86% avg_sensitivity=60.63%, avg_specificity=94.62% avg_auc=0.9096
Fold[3] Epoch: 55 [55/100 (55%)] Train loss=0.216027 Test loss=0.422881 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17904457449913025
[5/23] Train loss=0.3401758074760437
[10/23] Train loss=0.18556435406208038
[15/23] Train loss=0.1709151268005371
[20/23] Train loss=0.14856332540512085
Test set avg_accuracy=84.06% avg_sensitivity=62.22%, avg_specificity=94.18% avg_auc=0.9116
Fold[3] Epoch: 56 [56/100 (56%)] Train loss=0.213213 Test loss=0.411152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18142500519752502
[5/23] Train loss=0.34114721417427063
[10/23] Train loss=0.18534791469573975
[15/23] Train loss=0.18019595742225647
[20/23] Train loss=0.15654471516609192
Test set avg_accuracy=84.09% avg_sensitivity=62.85%, avg_specificity=93.93% avg_auc=0.9110
Fold[3] Epoch: 57 [57/100 (57%)] Train loss=0.212852 Test loss=0.405387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1857164204120636
[5/23] Train loss=0.3498457074165344
[10/23] Train loss=0.17817559838294983
[15/23] Train loss=0.1729637086391449
[20/23] Train loss=0.15249380469322205
Test set avg_accuracy=84.23% avg_sensitivity=62.62%, avg_specificity=94.24% avg_auc=0.9118
Fold[3] Epoch: 58 [58/100 (58%)] Train loss=0.213156 Test loss=0.408024 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17316724359989166
[5/23] Train loss=0.3326857089996338
[10/23] Train loss=0.1864195168018341
[15/23] Train loss=0.18281811475753784
[20/23] Train loss=0.15810365974903107
Test set avg_accuracy=84.08% avg_sensitivity=62.26%, avg_specificity=94.19% avg_auc=0.9115
Fold[3] Epoch: 59 [59/100 (59%)] Train loss=0.212032 Test loss=0.409217 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18174880743026733
[5/23] Train loss=0.329305499792099
[10/23] Train loss=0.1886780560016632
[15/23] Train loss=0.1702098548412323
[20/23] Train loss=0.1506039947271347
Test set avg_accuracy=84.21% avg_sensitivity=63.05%, avg_specificity=94.01% avg_auc=0.9112
Fold[3] Epoch: 60 [60/100 (60%)] Train loss=0.207769 Test loss=0.411547 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17290262877941132
[5/23] Train loss=0.3370018005371094
[10/23] Train loss=0.19090069830417633
[15/23] Train loss=0.1778561770915985
[20/23] Train loss=0.15746130049228668
Test set avg_accuracy=84.29% avg_sensitivity=63.22%, avg_specificity=94.06% avg_auc=0.9116
Fold[3] Epoch: 61 [61/100 (61%)] Train loss=0.208941 Test loss=0.405659 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17155218124389648
[5/23] Train loss=0.3259572386741638
[10/23] Train loss=0.18324296176433563
[15/23] Train loss=0.17525005340576172
[20/23] Train loss=0.14809776842594147
Test set avg_accuracy=84.35% avg_sensitivity=64.11%, avg_specificity=93.72% avg_auc=0.9118
Fold[3] Epoch: 62 [62/100 (62%)] Train loss=0.205099 Test loss=0.401205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18275868892669678
[5/23] Train loss=0.3215256929397583
[10/23] Train loss=0.18703056871891022
[15/23] Train loss=0.17153851687908173
[20/23] Train loss=0.14946934580802917
Test set avg_accuracy=84.34% avg_sensitivity=64.81%, avg_specificity=93.38% avg_auc=0.9121
Fold[3] Epoch: 63 [63/100 (63%)] Train loss=0.205831 Test loss=0.396257 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17971357703208923
[5/23] Train loss=0.3155079185962677
[10/23] Train loss=0.18889762461185455
[15/23] Train loss=0.17257297039031982
[20/23] Train loss=0.1440882533788681
Test set avg_accuracy=83.82% avg_sensitivity=61.79%, avg_specificity=94.02% avg_auc=0.9085
Fold[3] Epoch: 64 [64/100 (64%)] Train loss=0.204126 Test loss=0.412178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17682377994060516
[5/23] Train loss=0.31176456809043884
[10/23] Train loss=0.18286484479904175
[15/23] Train loss=0.1612531691789627
[20/23] Train loss=0.1398027539253235
Test set avg_accuracy=84.24% avg_sensitivity=64.41%, avg_specificity=93.43% avg_auc=0.9123
Fold[3] Epoch: 65 [65/100 (65%)] Train loss=0.202273 Test loss=0.399490 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17696674168109894
[5/23] Train loss=0.312454491853714
[10/23] Train loss=0.1807287484407425
[15/23] Train loss=0.17196707427501678
[20/23] Train loss=0.15171284973621368
Test set avg_accuracy=84.20% avg_sensitivity=64.01%, avg_specificity=93.55% avg_auc=0.9101
Fold[3] Epoch: 66 [66/100 (66%)] Train loss=0.203827 Test loss=0.401871 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16799624264240265
[5/23] Train loss=0.3020784556865692
[10/23] Train loss=0.17628377676010132
[15/23] Train loss=0.17164842784404755
[20/23] Train loss=0.14565588533878326
Test set avg_accuracy=84.03% avg_sensitivity=62.79%, avg_specificity=93.87% avg_auc=0.9103
Fold[3] Epoch: 67 [67/100 (67%)] Train loss=0.201004 Test loss=0.406848 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16811151802539825
[5/23] Train loss=0.3098631799221039
[10/23] Train loss=0.1797577291727066
[15/23] Train loss=0.16528981924057007
[20/23] Train loss=0.14482446014881134
Test set avg_accuracy=84.00% avg_sensitivity=61.99%, avg_specificity=94.19% avg_auc=0.9081
Fold[3] Epoch: 68 [68/100 (68%)] Train loss=0.200564 Test loss=0.419689 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1639421582221985
[5/23] Train loss=0.2966613471508026
[10/23] Train loss=0.17838919162750244
[15/23] Train loss=0.16287139058113098
[20/23] Train loss=0.14181753993034363
Test set avg_accuracy=84.06% avg_sensitivity=63.35%, avg_specificity=93.66% avg_auc=0.9100
Fold[3] Epoch: 69 [69/100 (69%)] Train loss=0.197133 Test loss=0.410588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17351384460926056
[5/23] Train loss=0.31662294268608093
[10/23] Train loss=0.1690755933523178
[15/23] Train loss=0.17519620060920715
[20/23] Train loss=0.13933680951595306
Test set avg_accuracy=84.26% avg_sensitivity=64.11%, avg_specificity=93.59% avg_auc=0.9105
Fold[3] Epoch: 70 [70/100 (70%)] Train loss=0.198958 Test loss=0.400364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1748967170715332
[5/23] Train loss=0.3049165904521942
[10/23] Train loss=0.1779801845550537
[15/23] Train loss=0.1687612533569336
[20/23] Train loss=0.14406661689281464
Test set avg_accuracy=84.14% avg_sensitivity=63.71%, avg_specificity=93.59% avg_auc=0.9097
Fold[3] Epoch: 71 [71/100 (71%)] Train loss=0.198584 Test loss=0.411191 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16826558113098145
[5/23] Train loss=0.31311869621276855
[10/23] Train loss=0.1798620969057083
[15/23] Train loss=0.16566163301467896
[20/23] Train loss=0.13863001763820648
Test set avg_accuracy=84.17% avg_sensitivity=62.52%, avg_specificity=94.19% avg_auc=0.9083
Fold[3] Epoch: 72 [72/100 (72%)] Train loss=0.197138 Test loss=0.417442 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17101170122623444
[5/23] Train loss=0.30319929122924805
[10/23] Train loss=0.17004674673080444
[15/23] Train loss=0.1661190539598465
[20/23] Train loss=0.14048150181770325
Test set avg_accuracy=84.01% avg_sensitivity=62.02%, avg_specificity=94.19% avg_auc=0.9082
Fold[3] Epoch: 73 [73/100 (73%)] Train loss=0.194834 Test loss=0.420968 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1757591962814331
[5/23] Train loss=0.3005770444869995
[10/23] Train loss=0.1841597557067871
[15/23] Train loss=0.16556738317012787
[20/23] Train loss=0.1339796781539917
Test set avg_accuracy=83.75% avg_sensitivity=60.46%, avg_specificity=94.53% avg_auc=0.9048
Fold[3] Epoch: 74 [74/100 (74%)] Train loss=0.194652 Test loss=0.440292 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1750696301460266
[5/23] Train loss=0.29894793033599854
[10/23] Train loss=0.17225629091262817
[15/23] Train loss=0.15421664714813232
[20/23] Train loss=0.14199671149253845
Test set avg_accuracy=84.00% avg_sensitivity=61.79%, avg_specificity=94.29% avg_auc=0.9047
Fold[3] Epoch: 75 [75/100 (75%)] Train loss=0.193466 Test loss=0.438946 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16467201709747314
[5/23] Train loss=0.2963073253631592
[10/23] Train loss=0.17539192736148834
[15/23] Train loss=0.1546669900417328
[20/23] Train loss=0.1421392560005188
Test set avg_accuracy=84.28% avg_sensitivity=63.58%, avg_specificity=93.87% avg_auc=0.9076
Fold[3] Epoch: 76 [76/100 (76%)] Train loss=0.192206 Test loss=0.421059 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.162821963429451
[5/23] Train loss=0.2945817708969116
[10/23] Train loss=0.17427097260951996
[15/23] Train loss=0.16119015216827393
[20/23] Train loss=0.1353827863931656
Test set avg_accuracy=83.80% avg_sensitivity=61.92%, avg_specificity=93.93% avg_auc=0.9063
Fold[3] Epoch: 77 [77/100 (77%)] Train loss=0.190499 Test loss=0.427983 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1643582433462143
[5/23] Train loss=0.28954100608825684
[10/23] Train loss=0.16651003062725067
[15/23] Train loss=0.15910093486309052
[20/23] Train loss=0.12641815841197968
Test set avg_accuracy=84.07% avg_sensitivity=62.85%, avg_specificity=93.90% avg_auc=0.9063
Fold[3] Epoch: 78 [78/100 (78%)] Train loss=0.187677 Test loss=0.429006 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1630866974592209
[5/23] Train loss=0.29568982124328613
[10/23] Train loss=0.17523416876792908
[15/23] Train loss=0.1609550565481186
[20/23] Train loss=0.13524286448955536
Test set avg_accuracy=83.81% avg_sensitivity=60.53%, avg_specificity=94.59% avg_auc=0.9062
Fold[3] Epoch: 79 [79/100 (79%)] Train loss=0.190297 Test loss=0.437719 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1649489551782608
[5/23] Train loss=0.29488250613212585
[10/23] Train loss=0.16748462617397308
[15/23] Train loss=0.1565905660390854
[20/23] Train loss=0.13004188239574432
Test set avg_accuracy=84.06% avg_sensitivity=62.22%, avg_specificity=94.18% avg_auc=0.9064
Fold[3] Epoch: 80 [80/100 (80%)] Train loss=0.188915 Test loss=0.435226 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1663219928741455
[5/23] Train loss=0.30286067724227905
[10/23] Train loss=0.17872413992881775
[15/23] Train loss=0.14563949406147003
[20/23] Train loss=0.13151812553405762
Test set avg_accuracy=84.10% avg_sensitivity=62.89%, avg_specificity=93.93% avg_auc=0.9083
Fold[3] Epoch: 81 [81/100 (81%)] Train loss=0.187925 Test loss=0.426563 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1618761122226715
[5/23] Train loss=0.3042515516281128
[10/23] Train loss=0.15825703740119934
[15/23] Train loss=0.15514113008975983
[20/23] Train loss=0.13244836032390594
Test set avg_accuracy=83.84% avg_sensitivity=61.86%, avg_specificity=94.02% avg_auc=0.9052
Fold[3] Epoch: 82 [82/100 (82%)] Train loss=0.185979 Test loss=0.434233 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16037185490131378
[5/23] Train loss=0.3008922338485718
[10/23] Train loss=0.15898548066616058
[15/23] Train loss=0.15467917919158936
[20/23] Train loss=0.12910369038581848
Test set avg_accuracy=83.76% avg_sensitivity=61.39%, avg_specificity=94.12% avg_auc=0.9046
Fold[3] Epoch: 83 [83/100 (83%)] Train loss=0.182837 Test loss=0.437176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15698188543319702
[5/23] Train loss=0.29091155529022217
[10/23] Train loss=0.16976317763328552
[15/23] Train loss=0.14950869977474213
[20/23] Train loss=0.13559271395206451
Test set avg_accuracy=83.74% avg_sensitivity=60.83%, avg_specificity=94.35% avg_auc=0.9036
Fold[3] Epoch: 84 [84/100 (84%)] Train loss=0.181813 Test loss=0.452672 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1575714498758316
[5/23] Train loss=0.2790874242782593
[10/23] Train loss=0.16900508105754852
[15/23] Train loss=0.1458267718553543
[20/23] Train loss=0.12657193839550018
Test set avg_accuracy=83.95% avg_sensitivity=61.49%, avg_specificity=94.35% avg_auc=0.9032
Fold[3] Epoch: 85 [85/100 (85%)] Train loss=0.180825 Test loss=0.448663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15654121339321136
[5/23] Train loss=0.296505331993103
[10/23] Train loss=0.16563047468662262
[15/23] Train loss=0.15017156302928925
[20/23] Train loss=0.13441036641597748
Test set avg_accuracy=84.04% avg_sensitivity=62.59%, avg_specificity=93.98% avg_auc=0.9054
Fold[3] Epoch: 86 [86/100 (86%)] Train loss=0.182904 Test loss=0.439042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16590628027915955
[5/23] Train loss=0.29076409339904785
[10/23] Train loss=0.16826961934566498
[15/23] Train loss=0.148156076669693
[20/23] Train loss=0.12201981246471405
Test set avg_accuracy=83.79% avg_sensitivity=61.66%, avg_specificity=94.04% avg_auc=0.9034
Fold[3] Epoch: 87 [87/100 (87%)] Train loss=0.180600 Test loss=0.455942 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1530994474887848
[5/23] Train loss=0.27340951561927795
[10/23] Train loss=0.16286151111125946
[15/23] Train loss=0.15279366075992584
[20/23] Train loss=0.1267310082912445
Test set avg_accuracy=83.64% avg_sensitivity=60.43%, avg_specificity=94.39% avg_auc=0.9019
Fold[3] Epoch: 88 [88/100 (88%)] Train loss=0.179285 Test loss=0.460829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1590513288974762
[5/23] Train loss=0.27792567014694214
[10/23] Train loss=0.1585530936717987
[15/23] Train loss=0.14777526259422302
[20/23] Train loss=0.1241607517004013
Test set avg_accuracy=83.79% avg_sensitivity=62.59%, avg_specificity=93.61% avg_auc=0.9033
Fold[3] Epoch: 89 [89/100 (89%)] Train loss=0.177844 Test loss=0.446454 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1579790562391281
[5/23] Train loss=0.27184516191482544
[10/23] Train loss=0.1706043928861618
[15/23] Train loss=0.15270361304283142
[20/23] Train loss=0.1268547773361206
Test set avg_accuracy=83.85% avg_sensitivity=62.06%, avg_specificity=93.95% avg_auc=0.9018
Fold[3] Epoch: 90 [90/100 (90%)] Train loss=0.176089 Test loss=0.458390 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15693417191505432
[5/23] Train loss=0.27227550745010376
[10/23] Train loss=0.15795780718326569
[15/23] Train loss=0.15442602336406708
[20/23] Train loss=0.12920311093330383
Test set avg_accuracy=83.73% avg_sensitivity=61.13%, avg_specificity=94.19% avg_auc=0.9007
Fold[3] Epoch: 91 [91/100 (91%)] Train loss=0.177748 Test loss=0.471267 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16380155086517334
[5/23] Train loss=0.2867685556411743
[10/23] Train loss=0.16178590059280396
[15/23] Train loss=0.1455409675836563
[20/23] Train loss=0.13239438831806183
Test set avg_accuracy=83.78% avg_sensitivity=61.00%, avg_specificity=94.33% avg_auc=0.9030
Fold[3] Epoch: 92 [92/100 (92%)] Train loss=0.176772 Test loss=0.463438 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15750154852867126
[5/23] Train loss=0.26329195499420166
[10/23] Train loss=0.16207478940486908
[15/23] Train loss=0.14456740021705627
[20/23] Train loss=0.12652795016765594
Test set avg_accuracy=83.67% avg_sensitivity=61.53%, avg_specificity=93.93% avg_auc=0.9010
Fold[3] Epoch: 93 [93/100 (93%)] Train loss=0.173812 Test loss=0.459787 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15978489816188812
[5/23] Train loss=0.25969192385673523
[10/23] Train loss=0.15227578580379486
[15/23] Train loss=0.14535391330718994
[20/23] Train loss=0.12173351645469666
Test set avg_accuracy=84.07% avg_sensitivity=63.22%, avg_specificity=93.73% avg_auc=0.9035
Fold[3] Epoch: 94 [94/100 (94%)] Train loss=0.172858 Test loss=0.447721 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15707051753997803
[5/23] Train loss=0.25728949904441833
[10/23] Train loss=0.15058274567127228
[15/23] Train loss=0.13674519956111908
[20/23] Train loss=0.12120469659566879
Test set avg_accuracy=84.09% avg_sensitivity=64.05%, avg_specificity=93.38% avg_auc=0.9033
Fold[3] Epoch: 95 [95/100 (95%)] Train loss=0.172447 Test loss=0.441278 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15782150626182556
[5/23] Train loss=0.27772921323776245
[10/23] Train loss=0.15773431956768036
[15/23] Train loss=0.13820938766002655
[20/23] Train loss=0.12385979294776917
Test set avg_accuracy=84.17% avg_sensitivity=63.65%, avg_specificity=93.67% avg_auc=0.9031
Fold[3] Epoch: 96 [96/100 (96%)] Train loss=0.170916 Test loss=0.449671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14577357470989227
[5/23] Train loss=0.2609648108482361
[10/23] Train loss=0.15231047570705414
[15/23] Train loss=0.1491006761789322
[20/23] Train loss=0.12998269498348236
Test set avg_accuracy=83.91% avg_sensitivity=63.38%, avg_specificity=93.41% avg_auc=0.9005
Fold[3] Epoch: 97 [97/100 (97%)] Train loss=0.169036 Test loss=0.455016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15249422192573547
[5/23] Train loss=0.2640872001647949
[10/23] Train loss=0.15369871258735657
[15/23] Train loss=0.1552925556898117
[20/23] Train loss=0.11877447366714478
Test set avg_accuracy=83.72% avg_sensitivity=62.65%, avg_specificity=93.47% avg_auc=0.9017
Fold[3] Epoch: 98 [98/100 (98%)] Train loss=0.167290 Test loss=0.457267 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14662393927574158
[5/23] Train loss=0.27838459610939026
[10/23] Train loss=0.14825263619422913
[15/23] Train loss=0.14180003106594086
[20/23] Train loss=0.11611312627792358
Test set avg_accuracy=84.03% avg_sensitivity=63.78%, avg_specificity=93.41% avg_auc=0.9018
Fold[3] Epoch: 99 [99/100 (99%)] Train loss=0.168870 Test loss=0.457921 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14265669882297516
[5/23] Train loss=0.2596878707408905
[10/23] Train loss=0.1599256545305252
[15/23] Train loss=0.15078598260879517
[20/23] Train loss=0.1263086497783661
Test set avg_accuracy=84.04% avg_sensitivity=63.91%, avg_specificity=93.36% avg_auc=0.8999
Fold[3] Epoch: 100 [100/100 (100%)] Train loss=0.167331 Test loss=0.461750 Current lr=[3.9999999999999996e-05]

Fold[3] Best Result: acc=84.51443569553805 sen=65.87064676616914, spe=93.14900153609831, auc=0.9113850613802468!
[0/23] Train loss=0.7046997547149658
[5/23] Train loss=0.6880863904953003
[10/23] Train loss=0.5847214460372925
[15/23] Train loss=0.5397964715957642
[20/23] Train loss=0.5109504461288452
Test set avg_accuracy=75.73% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6287
Best model saved!! Metric=-87.40085329346931!!
Fold[4] Epoch: 1 [1/100 (1%)] Train loss=0.575457 Test loss=0.699068 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5250189900398254
[5/23] Train loss=0.557622492313385
[10/23] Train loss=0.4816291928291321
[15/23] Train loss=0.4435631334781647
[20/23] Train loss=0.3980677127838135
Test set avg_accuracy=75.74% avg_sensitivity=9.06%, avg_specificity=97.11% avg_auc=0.7724
Best model saved!! Metric=-66.85325899568538!!
Fold[4] Epoch: 2 [2/100 (2%)] Train loss=0.480716 Test loss=0.718185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42135530710220337
[5/23] Train loss=0.45140811800956726
[10/23] Train loss=0.38356491923332214
[15/23] Train loss=0.38802066445350647
[20/23] Train loss=0.3724044859409332
Test set avg_accuracy=78.80% avg_sensitivity=32.73%, avg_specificity=93.56% avg_auc=0.8283
Best model saved!! Metric=-38.085557125458806!!
Fold[4] Epoch: 3 [3/100 (3%)] Train loss=0.416791 Test loss=0.574632 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.37467920780181885
[5/23] Train loss=0.43719595670700073
[10/23] Train loss=0.3426376283168793
[15/23] Train loss=0.3456829786300659
[20/23] Train loss=0.33874061703681946
Test set avg_accuracy=79.76% avg_sensitivity=35.40%, avg_specificity=93.97% avg_auc=0.8405
Best model saved!! Metric=-32.80830790305365!!
Fold[4] Epoch: 4 [4/100 (4%)] Train loss=0.388145 Test loss=0.556619 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35170283913612366
[5/23] Train loss=0.41460657119750977
[10/23] Train loss=0.33209481835365295
[15/23] Train loss=0.3377281427383423
[20/23] Train loss=0.3163430392742157
Test set avg_accuracy=80.13% avg_sensitivity=32.38%, avg_specificity=95.43% avg_auc=0.8500
Fold[4] Epoch: 5 [5/100 (5%)] Train loss=0.366511 Test loss=0.562000 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3423968553543091
[5/23] Train loss=0.4033859968185425
[10/23] Train loss=0.30298081040382385
[15/23] Train loss=0.31692907214164734
[20/23] Train loss=0.2882844805717468
Test set avg_accuracy=81.99% avg_sensitivity=37.73%, avg_specificity=96.17% avg_auc=0.8706
Best model saved!! Metric=-23.042957772166087!!
Fold[4] Epoch: 6 [6/100 (6%)] Train loss=0.351892 Test loss=0.502426 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32674670219421387
[5/23] Train loss=0.3954777717590332
[10/23] Train loss=0.2913604974746704
[15/23] Train loss=0.29324066638946533
[20/23] Train loss=0.2806158661842346
Test set avg_accuracy=83.46% avg_sensitivity=42.48%, avg_specificity=96.60% avg_auc=0.8847
Best model saved!! Metric=-14.990119421105334!!
Fold[4] Epoch: 7 [7/100 (7%)] Train loss=0.340310 Test loss=0.475079 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3100351393222809
[5/23] Train loss=0.398047536611557
[10/23] Train loss=0.27236899733543396
[15/23] Train loss=0.2697581350803375
[20/23] Train loss=0.25949785113334656
Test set avg_accuracy=85.01% avg_sensitivity=50.58%, avg_specificity=96.05% avg_auc=0.8978
Best model saved!! Metric=-4.579172897670055!!
Fold[4] Epoch: 8 [8/100 (8%)] Train loss=0.327470 Test loss=0.427084 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27218350768089294
[5/23] Train loss=0.393064945936203
[10/23] Train loss=0.2626233696937561
[15/23] Train loss=0.2589625120162964
[20/23] Train loss=0.23821836709976196
Test set avg_accuracy=85.39% avg_sensitivity=52.09%, avg_specificity=96.06% avg_auc=0.9055
Best model saved!! Metric=-1.9057174299664403!!
Fold[4] Epoch: 9 [9/100 (9%)] Train loss=0.313226 Test loss=0.411923 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27674680948257446
[5/23] Train loss=0.37914541363716125
[10/23] Train loss=0.2501678168773651
[15/23] Train loss=0.2552506625652313
[20/23] Train loss=0.2302745133638382
Test set avg_accuracy=85.79% avg_sensitivity=52.61%, avg_specificity=96.42% avg_auc=0.9101
Best model saved!! Metric=-0.17509846805799256!!
Fold[4] Epoch: 10 [10/100 (10%)] Train loss=0.308521 Test loss=0.405329 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2745812237262726
[5/23] Train loss=0.36458835005760193
[10/23] Train loss=0.2490401268005371
[15/23] Train loss=0.2557641565799713
[20/23] Train loss=0.22166158258914948
Test set avg_accuracy=85.79% avg_sensitivity=51.83%, avg_specificity=96.67% avg_auc=0.9110
Fold[4] Epoch: 11 [11/100 (11%)] Train loss=0.304361 Test loss=0.416356 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27215316891670227
[5/23] Train loss=0.38307759165763855
[10/23] Train loss=0.2567327618598938
[15/23] Train loss=0.24592678248882294
[20/23] Train loss=0.20804263651371002
Test set avg_accuracy=86.08% avg_sensitivity=52.70%, avg_specificity=96.78% avg_auc=0.9152
Best model saved!! Metric=1.0726932463527534!!
Fold[4] Epoch: 12 [12/100 (12%)] Train loss=0.300943 Test loss=0.410196 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2671922445297241
[5/23] Train loss=0.39470991492271423
[10/23] Train loss=0.2396821677684784
[15/23] Train loss=0.2545423209667206
[20/23] Train loss=0.21468105912208557
Test set avg_accuracy=86.96% avg_sensitivity=58.09%, avg_specificity=96.21% avg_auc=0.9196
Best model saved!! Metric=7.21794370945447!!
Fold[4] Epoch: 13 [13/100 (13%)] Train loss=0.299292 Test loss=0.375368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2592228949069977
[5/23] Train loss=0.3790072798728943
[10/23] Train loss=0.23206497728824615
[15/23] Train loss=0.2424801141023636
[20/23] Train loss=0.21845096349716187
Test set avg_accuracy=87.33% avg_sensitivity=62.23%, avg_specificity=95.37% avg_auc=0.9224
Best model saved!! Metric=11.164508271521704!!
Fold[4] Epoch: 14 [14/100 (14%)] Train loss=0.291829 Test loss=0.348620 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.243424654006958
[5/23] Train loss=0.36219385266304016
[10/23] Train loss=0.22160935401916504
[15/23] Train loss=0.22757519781589508
[20/23] Train loss=0.19813604652881622
Test set avg_accuracy=87.57% avg_sensitivity=64.60%, avg_specificity=94.93% avg_auc=0.9247
Best model saved!! Metric=13.560990963512186!!
Fold[4] Epoch: 15 [15/100 (15%)] Train loss=0.285154 Test loss=0.338026 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24272271990776062
[5/23] Train loss=0.35354161262512207
[10/23] Train loss=0.22647938132286072
[15/23] Train loss=0.22484190762043
[20/23] Train loss=0.2115674912929535
Test set avg_accuracy=87.63% avg_sensitivity=64.17%, avg_specificity=95.15% avg_auc=0.9250
Fold[4] Epoch: 16 [16/100 (16%)] Train loss=0.283758 Test loss=0.337359 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2274741679430008
[5/23] Train loss=0.354071706533432
[10/23] Train loss=0.22477120161056519
[15/23] Train loss=0.22396233677864075
[20/23] Train loss=0.19743703305721283
Test set avg_accuracy=87.63% avg_sensitivity=62.27%, avg_specificity=95.76% avg_auc=0.9255
Fold[4] Epoch: 17 [17/100 (17%)] Train loss=0.276997 Test loss=0.346332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23444153368473053
[5/23] Train loss=0.3477703928947449
[10/23] Train loss=0.2166692614555359
[15/23] Train loss=0.2258031666278839
[20/23] Train loss=0.1900828629732132
Test set avg_accuracy=87.80% avg_sensitivity=62.35%, avg_specificity=95.95% avg_auc=0.9264
Fold[4] Epoch: 18 [18/100 (18%)] Train loss=0.274542 Test loss=0.348851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22656846046447754
[5/23] Train loss=0.3582216501235962
[10/23] Train loss=0.22602137923240662
[15/23] Train loss=0.22833791375160217
[20/23] Train loss=0.19756636023521423
Test set avg_accuracy=87.77% avg_sensitivity=62.35%, avg_specificity=95.91% avg_auc=0.9263
Fold[4] Epoch: 19 [19/100 (19%)] Train loss=0.273214 Test loss=0.346646 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22787828743457794
[5/23] Train loss=0.35774677991867065
[10/23] Train loss=0.21660685539245605
[15/23] Train loss=0.22316071391105652
[20/23] Train loss=0.18630272150039673
Test set avg_accuracy=87.83% avg_sensitivity=63.13%, avg_specificity=95.74% avg_auc=0.9279
Fold[4] Epoch: 20 [20/100 (20%)] Train loss=0.270539 Test loss=0.338476 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2274283617734909
[5/23] Train loss=0.3505646884441376
[10/23] Train loss=0.20480364561080933
[15/23] Train loss=0.2188892513513565
[20/23] Train loss=0.19138748943805695
Test set avg_accuracy=87.88% avg_sensitivity=63.43%, avg_specificity=95.72% avg_auc=0.9278
Best model saved!! Metric=13.808816626525342!!
Fold[4] Epoch: 21 [21/100 (21%)] Train loss=0.268128 Test loss=0.336311 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22286584973335266
[5/23] Train loss=0.35035255551338196
[10/23] Train loss=0.21253551542758942
[15/23] Train loss=0.2138306349515915
[20/23] Train loss=0.18141460418701172
Test set avg_accuracy=87.92% avg_sensitivity=63.78%, avg_specificity=95.66% avg_auc=0.9282
Best model saved!! Metric=14.177405223379834!!
Fold[4] Epoch: 22 [22/100 (22%)] Train loss=0.265607 Test loss=0.333027 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22670641541481018
[5/23] Train loss=0.3535613715648651
[10/23] Train loss=0.21378719806671143
[15/23] Train loss=0.2066752165555954
[20/23] Train loss=0.1820111870765686
Test set avg_accuracy=87.93% avg_sensitivity=63.04%, avg_specificity=95.91% avg_auc=0.9287
Fold[4] Epoch: 23 [23/100 (23%)] Train loss=0.264063 Test loss=0.331709 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21878622472286224
[5/23] Train loss=0.3423001766204834
[10/23] Train loss=0.22477205097675323
[15/23] Train loss=0.21600092947483063
[20/23] Train loss=0.1795918494462967
Test set avg_accuracy=87.95% avg_sensitivity=62.61%, avg_specificity=96.08% avg_auc=0.9291
Fold[4] Epoch: 24 [24/100 (24%)] Train loss=0.262708 Test loss=0.333465 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21095266938209534
[5/23] Train loss=0.3558506965637207
[10/23] Train loss=0.20228765904903412
[15/23] Train loss=0.19983328878879547
[20/23] Train loss=0.18382792174816132
Test set avg_accuracy=88.05% avg_sensitivity=62.66%, avg_specificity=96.19% avg_auc=0.9278
Fold[4] Epoch: 25 [25/100 (25%)] Train loss=0.258366 Test loss=0.339961 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22441792488098145
[5/23] Train loss=0.3529888689517975
[10/23] Train loss=0.19889825582504272
[15/23] Train loss=0.2100602090358734
[20/23] Train loss=0.18016915023326874
Test set avg_accuracy=88.11% avg_sensitivity=64.25%, avg_specificity=95.76% avg_auc=0.9292
Best model saved!! Metric=15.035702437223758!!
Fold[4] Epoch: 26 [26/100 (26%)] Train loss=0.260176 Test loss=0.331763 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2218870222568512
[5/23] Train loss=0.3364057242870331
[10/23] Train loss=0.20737199485301971
[15/23] Train loss=0.20224812626838684
[20/23] Train loss=0.1800651252269745
Test set avg_accuracy=87.99% avg_sensitivity=62.92%, avg_specificity=96.02% avg_auc=0.9278
Fold[4] Epoch: 27 [27/100 (27%)] Train loss=0.258672 Test loss=0.333152 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21959979832172394
[5/23] Train loss=0.34114745259284973
[10/23] Train loss=0.20395703613758087
[15/23] Train loss=0.2072044312953949
[20/23] Train loss=0.1728937178850174
Test set avg_accuracy=88.11% avg_sensitivity=63.95%, avg_specificity=95.85% avg_auc=0.9279
Fold[4] Epoch: 28 [28/100 (28%)] Train loss=0.256465 Test loss=0.330052 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21585799753665924
[5/23] Train loss=0.34041985869407654
[10/23] Train loss=0.20112083852291107
[15/23] Train loss=0.19832545518875122
[20/23] Train loss=0.17399433255195618
Test set avg_accuracy=88.27% avg_sensitivity=63.82%, avg_specificity=96.10% avg_auc=0.9283
Fold[4] Epoch: 29 [29/100 (29%)] Train loss=0.253520 Test loss=0.328616 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20488379895687103
[5/23] Train loss=0.3419068455696106
[10/23] Train loss=0.2149665504693985
[15/23] Train loss=0.2041417360305786
[20/23] Train loss=0.17358219623565674
Test set avg_accuracy=87.88% avg_sensitivity=61.75%, avg_specificity=96.25% avg_auc=0.9276
Fold[4] Epoch: 30 [30/100 (30%)] Train loss=0.251311 Test loss=0.337514 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2079962193965912
[5/23] Train loss=0.340431809425354
[10/23] Train loss=0.210943803191185
[15/23] Train loss=0.20359419286251068
[20/23] Train loss=0.16391639411449432
Test set avg_accuracy=87.95% avg_sensitivity=61.49%, avg_specificity=96.43% avg_auc=0.9268
Fold[4] Epoch: 31 [31/100 (31%)] Train loss=0.251380 Test loss=0.340355 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20544517040252686
[5/23] Train loss=0.3281663954257965
[10/23] Train loss=0.20568400621414185
[15/23] Train loss=0.20007900893688202
[20/23] Train loss=0.18086472153663635
Test set avg_accuracy=88.16% avg_sensitivity=62.18%, avg_specificity=96.49% avg_auc=0.9276
Fold[4] Epoch: 32 [32/100 (32%)] Train loss=0.250509 Test loss=0.336567 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21134886145591736
[5/23] Train loss=0.3372407555580139
[10/23] Train loss=0.19538380205631256
[15/23] Train loss=0.19351333379745483
[20/23] Train loss=0.17407141625881195
Test set avg_accuracy=88.39% avg_sensitivity=64.29%, avg_specificity=96.12% avg_auc=0.9274
Best model saved!! Metric=15.543666516202666!!
Fold[4] Epoch: 33 [33/100 (33%)] Train loss=0.249850 Test loss=0.328393 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20615209639072418
[5/23] Train loss=0.33184534311294556
[10/23] Train loss=0.20473283529281616
[15/23] Train loss=0.20355218648910522
[20/23] Train loss=0.16817641258239746
Test set avg_accuracy=87.88% avg_sensitivity=61.32%, avg_specificity=96.39% avg_auc=0.9252
Fold[4] Epoch: 34 [34/100 (34%)] Train loss=0.247058 Test loss=0.343420 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2001371830701828
[5/23] Train loss=0.3352523744106293
[10/23] Train loss=0.20387494564056396
[15/23] Train loss=0.19547466933727264
[20/23] Train loss=0.17179428040981293
Test set avg_accuracy=87.93% avg_sensitivity=61.45%, avg_specificity=96.42% avg_auc=0.9270
Fold[4] Epoch: 35 [35/100 (35%)] Train loss=0.246402 Test loss=0.339609 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21013657748699188
[5/23] Train loss=0.34021446108818054
[10/23] Train loss=0.2011238932609558
[15/23] Train loss=0.19336506724357605
[20/23] Train loss=0.16742651164531708
Test set avg_accuracy=88.14% avg_sensitivity=62.10%, avg_specificity=96.49% avg_auc=0.9270
Fold[4] Epoch: 36 [36/100 (36%)] Train loss=0.245233 Test loss=0.335713 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20416025817394257
[5/23] Train loss=0.33200421929359436
[10/23] Train loss=0.2019921839237213
[15/23] Train loss=0.19131013751029968
[20/23] Train loss=0.16442763805389404
Test set avg_accuracy=88.18% avg_sensitivity=62.74%, avg_specificity=96.34% avg_auc=0.9262
Fold[4] Epoch: 37 [37/100 (37%)] Train loss=0.244456 Test loss=0.339458 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20703177154064178
[5/23] Train loss=0.3186293840408325
[10/23] Train loss=0.2022475004196167
[15/23] Train loss=0.19685016572475433
[20/23] Train loss=0.1656777411699295
Test set avg_accuracy=88.16% avg_sensitivity=61.71%, avg_specificity=96.64% avg_auc=0.9275
Fold[4] Epoch: 38 [38/100 (38%)] Train loss=0.243502 Test loss=0.336249 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2083529531955719
[5/23] Train loss=0.33171799778938293
[10/23] Train loss=0.2058783918619156
[15/23] Train loss=0.19483070075511932
[20/23] Train loss=0.1614668369293213
Test set avg_accuracy=88.25% avg_sensitivity=62.87%, avg_specificity=96.38% avg_auc=0.9276
Fold[4] Epoch: 39 [39/100 (39%)] Train loss=0.241191 Test loss=0.337497 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20611518621444702
[5/23] Train loss=0.32884812355041504
[10/23] Train loss=0.19007697701454163
[15/23] Train loss=0.1897565871477127
[20/23] Train loss=0.1582358479499817
Test set avg_accuracy=88.31% avg_sensitivity=62.70%, avg_specificity=96.52% avg_auc=0.9278
Fold[4] Epoch: 40 [40/100 (40%)] Train loss=0.239443 Test loss=0.335297 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.207078218460083
[5/23] Train loss=0.32306739687919617
[10/23] Train loss=0.20046311616897583
[15/23] Train loss=0.18993288278579712
[20/23] Train loss=0.15816281735897064
Test set avg_accuracy=88.17% avg_sensitivity=61.92%, avg_specificity=96.59% avg_auc=0.9267
Fold[4] Epoch: 41 [41/100 (41%)] Train loss=0.238932 Test loss=0.339038 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21013912558555603
[5/23] Train loss=0.31299319863319397
[10/23] Train loss=0.19172364473342896
[15/23] Train loss=0.19109374284744263
[20/23] Train loss=0.1632511168718338
Test set avg_accuracy=87.76% avg_sensitivity=59.34%, avg_specificity=96.86% avg_auc=0.9254
Fold[4] Epoch: 42 [42/100 (42%)] Train loss=0.238000 Test loss=0.354141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20431122183799744
[5/23] Train loss=0.3194553554058075
[10/23] Train loss=0.1931866705417633
[15/23] Train loss=0.1881379634141922
[20/23] Train loss=0.16213825345039368
Test set avg_accuracy=88.32% avg_sensitivity=63.26%, avg_specificity=96.35% avg_auc=0.9273
Fold[4] Epoch: 43 [43/100 (43%)] Train loss=0.239654 Test loss=0.335596 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20266108214855194
[5/23] Train loss=0.3291330933570862
[10/23] Train loss=0.19263149797916412
[15/23] Train loss=0.1864032745361328
[20/23] Train loss=0.15697874128818512
Test set avg_accuracy=88.34% avg_sensitivity=63.26%, avg_specificity=96.38% avg_auc=0.9268
Fold[4] Epoch: 44 [44/100 (44%)] Train loss=0.235786 Test loss=0.330504 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20063689351081848
[5/23] Train loss=0.3116312026977539
[10/23] Train loss=0.18744748830795288
[15/23] Train loss=0.18413591384887695
[20/23] Train loss=0.15631265938282013
Test set avg_accuracy=88.31% avg_sensitivity=62.48%, avg_specificity=96.59% avg_auc=0.9265
Fold[4] Epoch: 45 [45/100 (45%)] Train loss=0.233295 Test loss=0.337032 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20473062992095947
[5/23] Train loss=0.3274570107460022
[10/23] Train loss=0.1969916969537735
[15/23] Train loss=0.1868964284658432
[20/23] Train loss=0.17002423107624054
Test set avg_accuracy=87.71% avg_sensitivity=59.38%, avg_specificity=96.79% avg_auc=0.9248
Fold[4] Epoch: 46 [46/100 (46%)] Train loss=0.235762 Test loss=0.350005 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19604626297950745
[5/23] Train loss=0.3204566538333893
[10/23] Train loss=0.18549185991287231
[15/23] Train loss=0.18973678350448608
[20/23] Train loss=0.15250128507614136
Test set avg_accuracy=88.27% avg_sensitivity=62.48%, avg_specificity=96.53% avg_auc=0.9268
Fold[4] Epoch: 47 [47/100 (47%)] Train loss=0.231765 Test loss=0.340872 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19704332947731018
[5/23] Train loss=0.3142407238483429
[10/23] Train loss=0.18254506587982178
[15/23] Train loss=0.1936144381761551
[20/23] Train loss=0.15478214621543884
Test set avg_accuracy=88.08% avg_sensitivity=61.15%, avg_specificity=96.71% avg_auc=0.9266
Fold[4] Epoch: 48 [48/100 (48%)] Train loss=0.231981 Test loss=0.345727 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19382967054843903
[5/23] Train loss=0.315016508102417
[10/23] Train loss=0.18755663931369781
[15/23] Train loss=0.18898504972457886
[20/23] Train loss=0.15145519375801086
Test set avg_accuracy=88.10% avg_sensitivity=61.45%, avg_specificity=96.64% avg_auc=0.9266
Fold[4] Epoch: 49 [49/100 (49%)] Train loss=0.229815 Test loss=0.343033 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19793689250946045
[5/23] Train loss=0.3236597776412964
[10/23] Train loss=0.18501253426074982
[15/23] Train loss=0.1866794228553772
[20/23] Train loss=0.1542854607105255
Test set avg_accuracy=88.14% avg_sensitivity=61.58%, avg_specificity=96.66% avg_auc=0.9267
Fold[4] Epoch: 50 [50/100 (50%)] Train loss=0.229685 Test loss=0.343165 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19142583012580872
[5/23] Train loss=0.3084196448326111
[10/23] Train loss=0.1941421926021576
[15/23] Train loss=0.18465912342071533
[20/23] Train loss=0.16305144131183624
Test set avg_accuracy=88.00% avg_sensitivity=60.03%, avg_specificity=96.96% avg_auc=0.9262
Fold[4] Epoch: 51 [51/100 (51%)] Train loss=0.228623 Test loss=0.350691 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20258834958076477
[5/23] Train loss=0.30858978629112244
[10/23] Train loss=0.1893080323934555
[15/23] Train loss=0.17755763232707977
[20/23] Train loss=0.15627750754356384
Test set avg_accuracy=88.11% avg_sensitivity=60.63%, avg_specificity=96.92% avg_auc=0.9265
Fold[4] Epoch: 52 [52/100 (52%)] Train loss=0.229877 Test loss=0.346066 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19776026904582977
[5/23] Train loss=0.3070850372314453
[10/23] Train loss=0.1945001780986786
[15/23] Train loss=0.17546527087688446
[20/23] Train loss=0.1623549461364746
Test set avg_accuracy=88.02% avg_sensitivity=60.11%, avg_specificity=96.96% avg_auc=0.9263
Fold[4] Epoch: 53 [53/100 (53%)] Train loss=0.225604 Test loss=0.348669 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1900881826877594
[5/23] Train loss=0.29863718152046204
[10/23] Train loss=0.1868928223848343
[15/23] Train loss=0.17866288125514984
[20/23] Train loss=0.15611204504966736
Test set avg_accuracy=87.51% avg_sensitivity=57.44%, avg_specificity=97.15% avg_auc=0.9254
Fold[4] Epoch: 54 [54/100 (54%)] Train loss=0.224626 Test loss=0.361858 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18607884645462036
[5/23] Train loss=0.2943391799926758
[10/23] Train loss=0.179973766207695
[15/23] Train loss=0.17267686128616333
[20/23] Train loss=0.1468280553817749
Test set avg_accuracy=87.74% avg_sensitivity=58.34%, avg_specificity=97.17% avg_auc=0.9260
Fold[4] Epoch: 55 [55/100 (55%)] Train loss=0.221623 Test loss=0.365651 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19259147346019745
[5/23] Train loss=0.30644145607948303
[10/23] Train loss=0.1914532333612442
[15/23] Train loss=0.1758766621351242
[20/23] Train loss=0.15445251762866974
Test set avg_accuracy=87.72% avg_sensitivity=58.21%, avg_specificity=97.18% avg_auc=0.9269
Fold[4] Epoch: 56 [56/100 (56%)] Train loss=0.223842 Test loss=0.361598 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19009830057621002
[5/23] Train loss=0.3060542643070221
[10/23] Train loss=0.18758761882781982
[15/23] Train loss=0.18020738661289215
[20/23] Train loss=0.15569321811199188
Test set avg_accuracy=87.77% avg_sensitivity=58.34%, avg_specificity=97.19% avg_auc=0.9263
Fold[4] Epoch: 57 [57/100 (57%)] Train loss=0.223051 Test loss=0.363658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19193415343761444
[5/23] Train loss=0.2998242974281311
[10/23] Train loss=0.17967405915260315
[15/23] Train loss=0.1735391914844513
[20/23] Train loss=0.1443445235490799
Test set avg_accuracy=87.80% avg_sensitivity=58.69%, avg_specificity=97.13% avg_auc=0.9259
Fold[4] Epoch: 58 [58/100 (58%)] Train loss=0.217936 Test loss=0.360929 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1912180334329605
[5/23] Train loss=0.3121461868286133
[10/23] Train loss=0.17956368625164032
[15/23] Train loss=0.17588762938976288
[20/23] Train loss=0.13977615535259247
Test set avg_accuracy=87.79% avg_sensitivity=58.52%, avg_specificity=97.17% avg_auc=0.9262
Fold[4] Epoch: 59 [59/100 (59%)] Train loss=0.221798 Test loss=0.359436 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.184569850564003
[5/23] Train loss=0.30977994203567505
[10/23] Train loss=0.18362583220005035
[15/23] Train loss=0.17613323032855988
[20/23] Train loss=0.15351881086826324
Test set avg_accuracy=87.90% avg_sensitivity=59.51%, avg_specificity=97.00% avg_auc=0.9261
Fold[4] Epoch: 60 [60/100 (60%)] Train loss=0.219304 Test loss=0.355726 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1896248161792755
[5/23] Train loss=0.3012710511684418
[10/23] Train loss=0.17847943305969238
[15/23] Train loss=0.16959235072135925
[20/23] Train loss=0.1465478241443634
Test set avg_accuracy=87.69% avg_sensitivity=58.04%, avg_specificity=97.19% avg_auc=0.9253
Fold[4] Epoch: 61 [61/100 (61%)] Train loss=0.216645 Test loss=0.364402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18725132942199707
[5/23] Train loss=0.29296135902404785
[10/23] Train loss=0.17765776813030243
[15/23] Train loss=0.1770390421152115
[20/23] Train loss=0.14657533168792725
Test set avg_accuracy=87.67% avg_sensitivity=57.70%, avg_specificity=97.28% avg_auc=0.9245
Fold[4] Epoch: 62 [62/100 (62%)] Train loss=0.217571 Test loss=0.372721 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18723486363887787
[5/23] Train loss=0.30182215571403503
[10/23] Train loss=0.17587678134441376
[15/23] Train loss=0.1712445169687271
[20/23] Train loss=0.14409160614013672
Test set avg_accuracy=87.66% avg_sensitivity=57.65%, avg_specificity=97.28% avg_auc=0.9255
Fold[4] Epoch: 63 [63/100 (63%)] Train loss=0.216922 Test loss=0.368118 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19522733986377716
[5/23] Train loss=0.2997814118862152
[10/23] Train loss=0.1769142597913742
[15/23] Train loss=0.17099504172801971
[20/23] Train loss=0.1427936553955078
Test set avg_accuracy=87.63% avg_sensitivity=58.09%, avg_specificity=97.10% avg_auc=0.9251
Fold[4] Epoch: 64 [64/100 (64%)] Train loss=0.215271 Test loss=0.365323 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1834920346736908
[5/23] Train loss=0.303824782371521
[10/23] Train loss=0.1764385849237442
[15/23] Train loss=0.17063063383102417
[20/23] Train loss=0.14635615050792694
Test set avg_accuracy=87.77% avg_sensitivity=58.78%, avg_specificity=97.06% avg_auc=0.9251
Fold[4] Epoch: 65 [65/100 (65%)] Train loss=0.214546 Test loss=0.370042 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1854734718799591
[5/23] Train loss=0.28438857197761536
[10/23] Train loss=0.17431548237800598
[15/23] Train loss=0.16438491642475128
[20/23] Train loss=0.14803405106067657
Test set avg_accuracy=87.62% avg_sensitivity=57.57%, avg_specificity=97.25% avg_auc=0.9250
Fold[4] Epoch: 66 [66/100 (66%)] Train loss=0.213349 Test loss=0.376411 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18191444873809814
[5/23] Train loss=0.28495463728904724
[10/23] Train loss=0.18108512461185455
[15/23] Train loss=0.1613752394914627
[20/23] Train loss=0.14264695346355438
Test set avg_accuracy=87.28% avg_sensitivity=55.71%, avg_specificity=97.40% avg_auc=0.9216
Fold[4] Epoch: 67 [67/100 (67%)] Train loss=0.209961 Test loss=0.399920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18455232679843903
[5/23] Train loss=0.2974669933319092
[10/23] Train loss=0.18788577616214752
[15/23] Train loss=0.17225252091884613
[20/23] Train loss=0.14965619146823883
Test set avg_accuracy=87.45% avg_sensitivity=56.40%, avg_specificity=97.40% avg_auc=0.9251
Fold[4] Epoch: 68 [68/100 (68%)] Train loss=0.212115 Test loss=0.376774 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17953653633594513
[5/23] Train loss=0.2946980893611908
[10/23] Train loss=0.17442606389522552
[15/23] Train loss=0.16219563782215118
[20/23] Train loss=0.13670970499515533
Test set avg_accuracy=87.33% avg_sensitivity=56.06%, avg_specificity=97.35% avg_auc=0.9233
Fold[4] Epoch: 69 [69/100 (69%)] Train loss=0.210266 Test loss=0.384786 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1874811202287674
[5/23] Train loss=0.29969874024391174
[10/23] Train loss=0.17234840989112854
[15/23] Train loss=0.16406597197055817
[20/23] Train loss=0.14022015035152435
Test set avg_accuracy=87.62% avg_sensitivity=57.83%, avg_specificity=97.17% avg_auc=0.9235
Fold[4] Epoch: 70 [70/100 (70%)] Train loss=0.208073 Test loss=0.374272 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18766407668590546
[5/23] Train loss=0.29778575897216797
[10/23] Train loss=0.1785035878419876
[15/23] Train loss=0.15944312512874603
[20/23] Train loss=0.14397601783275604
Test set avg_accuracy=87.62% avg_sensitivity=58.21%, avg_specificity=97.04% avg_auc=0.9240
Fold[4] Epoch: 71 [71/100 (71%)] Train loss=0.209944 Test loss=0.366926 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17475415766239166
[5/23] Train loss=0.2877747118473053
[10/23] Train loss=0.17671680450439453
[15/23] Train loss=0.1581089049577713
[20/23] Train loss=0.1369170993566513
Test set avg_accuracy=87.96% avg_sensitivity=59.94%, avg_specificity=96.95% avg_auc=0.9254
Fold[4] Epoch: 72 [72/100 (72%)] Train loss=0.205194 Test loss=0.366028 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18322722613811493
[5/23] Train loss=0.2796069085597992
[10/23] Train loss=0.1714242547750473
[15/23] Train loss=0.1641777753829956
[20/23] Train loss=0.14064422249794006
Test set avg_accuracy=87.45% avg_sensitivity=57.22%, avg_specificity=97.14% avg_auc=0.9235
Fold[4] Epoch: 73 [73/100 (73%)] Train loss=0.203513 Test loss=0.378051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.173055037856102
[5/23] Train loss=0.26955947279930115
[10/23] Train loss=0.1650443822145462
[15/23] Train loss=0.16703931987285614
[20/23] Train loss=0.13844700157642365
Test set avg_accuracy=88.02% avg_sensitivity=60.24%, avg_specificity=96.92% avg_auc=0.9254
Fold[4] Epoch: 74 [74/100 (74%)] Train loss=0.203047 Test loss=0.369844 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17870691418647766
[5/23] Train loss=0.2756255865097046
[10/23] Train loss=0.17577826976776123
[15/23] Train loss=0.15147972106933594
[20/23] Train loss=0.1302841752767563
Test set avg_accuracy=88.08% avg_sensitivity=60.46%, avg_specificity=96.93% avg_auc=0.9261
Fold[4] Epoch: 75 [75/100 (75%)] Train loss=0.202130 Test loss=0.370167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17675265669822693
[5/23] Train loss=0.2762930989265442
[10/23] Train loss=0.17589065432548523
[15/23] Train loss=0.16623738408088684
[20/23] Train loss=0.13454225659370422
Test set avg_accuracy=87.65% avg_sensitivity=57.91%, avg_specificity=97.18% avg_auc=0.9236
Fold[4] Epoch: 76 [76/100 (76%)] Train loss=0.203798 Test loss=0.381761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1844175159931183
[5/23] Train loss=0.2675485610961914
[10/23] Train loss=0.17112426459789276
[15/23] Train loss=0.15497159957885742
[20/23] Train loss=0.13538780808448792
Test set avg_accuracy=87.55% avg_sensitivity=57.61%, avg_specificity=97.14% avg_auc=0.9236
Fold[4] Epoch: 77 [77/100 (77%)] Train loss=0.200919 Test loss=0.381768 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1825409084558487
[5/23] Train loss=0.27538180351257324
[10/23] Train loss=0.1734926402568817
[15/23] Train loss=0.16047801077365875
[20/23] Train loss=0.1429196000099182
Test set avg_accuracy=87.40% avg_sensitivity=57.01%, avg_specificity=97.14% avg_auc=0.9232
Fold[4] Epoch: 78 [78/100 (78%)] Train loss=0.199509 Test loss=0.389772 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17641258239746094
[5/23] Train loss=0.27121701836586
[10/23] Train loss=0.17825791239738464
[15/23] Train loss=0.1555667668581009
[20/23] Train loss=0.13223347067832947
Test set avg_accuracy=87.65% avg_sensitivity=58.26%, avg_specificity=97.07% avg_auc=0.9246
Fold[4] Epoch: 79 [79/100 (79%)] Train loss=0.199313 Test loss=0.374194 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18018518388271332
[5/23] Train loss=0.2735971510410309
[10/23] Train loss=0.17453260719776154
[15/23] Train loss=0.15834841132164001
[20/23] Train loss=0.13519719243049622
Test set avg_accuracy=87.40% avg_sensitivity=57.27%, avg_specificity=97.06% avg_auc=0.9229
Fold[4] Epoch: 80 [80/100 (80%)] Train loss=0.197000 Test loss=0.386606 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17804884910583496
[5/23] Train loss=0.2710516154766083
[10/23] Train loss=0.17670613527297974
[15/23] Train loss=0.14757560193538666
[20/23] Train loss=0.13830818235874176
Test set avg_accuracy=87.74% avg_sensitivity=58.56%, avg_specificity=97.10% avg_auc=0.9237
Fold[4] Epoch: 81 [81/100 (81%)] Train loss=0.196483 Test loss=0.385061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17399944365024567
[5/23] Train loss=0.2710617780685425
[10/23] Train loss=0.1731477528810501
[15/23] Train loss=0.15713031589984894
[20/23] Train loss=0.1346348524093628
Test set avg_accuracy=87.69% avg_sensitivity=58.00%, avg_specificity=97.21% avg_auc=0.9236
Fold[4] Epoch: 82 [82/100 (82%)] Train loss=0.196083 Test loss=0.391103 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17319552600383759
[5/23] Train loss=0.27879059314727783
[10/23] Train loss=0.1681692898273468
[15/23] Train loss=0.15418638288974762
[20/23] Train loss=0.137007936835289
Test set avg_accuracy=87.36% avg_sensitivity=56.83%, avg_specificity=97.14% avg_auc=0.9218
Fold[4] Epoch: 83 [83/100 (83%)] Train loss=0.196075 Test loss=0.393998 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17412066459655762
[5/23] Train loss=0.2684115767478943
[10/23] Train loss=0.17172114551067352
[15/23] Train loss=0.16102203726768494
[20/23] Train loss=0.13147494196891785
Test set avg_accuracy=87.25% avg_sensitivity=56.32%, avg_specificity=97.17% avg_auc=0.9217
Fold[4] Epoch: 84 [84/100 (84%)] Train loss=0.195142 Test loss=0.402788 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16737423837184906
[5/23] Train loss=0.27482080459594727
[10/23] Train loss=0.16584943234920502
[15/23] Train loss=0.1500304788351059
[20/23] Train loss=0.1374024599790573
Test set avg_accuracy=87.54% avg_sensitivity=57.65%, avg_specificity=97.11% avg_auc=0.9235
Fold[4] Epoch: 85 [85/100 (85%)] Train loss=0.194552 Test loss=0.394312 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17819778621196747
[5/23] Train loss=0.2626907229423523
[10/23] Train loss=0.16806408762931824
[15/23] Train loss=0.14778326451778412
[20/23] Train loss=0.12895116209983826
Test set avg_accuracy=87.40% avg_sensitivity=56.79%, avg_specificity=97.21% avg_auc=0.9225
Fold[4] Epoch: 86 [86/100 (86%)] Train loss=0.190658 Test loss=0.393335 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16886107623577118
[5/23] Train loss=0.2545301616191864
[10/23] Train loss=0.1669175624847412
[15/23] Train loss=0.14901989698410034
[20/23] Train loss=0.1334524154663086
Test set avg_accuracy=87.54% avg_sensitivity=57.70%, avg_specificity=97.10% avg_auc=0.9224
Fold[4] Epoch: 87 [87/100 (87%)] Train loss=0.190665 Test loss=0.396447 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16275107860565186
[5/23] Train loss=0.26539498567581177
[10/23] Train loss=0.16452915966510773
[15/23] Train loss=0.14797161519527435
[20/23] Train loss=0.12945252656936646
Test set avg_accuracy=87.48% avg_sensitivity=57.35%, avg_specificity=97.14% avg_auc=0.9214
Fold[4] Epoch: 88 [88/100 (88%)] Train loss=0.190170 Test loss=0.401035 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17021672427654266
[5/23] Train loss=0.2526218593120575
[10/23] Train loss=0.15545424818992615
[15/23] Train loss=0.1492135226726532
[20/23] Train loss=0.13342803716659546
Test set avg_accuracy=87.27% avg_sensitivity=56.10%, avg_specificity=97.26% avg_auc=0.9207
Fold[4] Epoch: 89 [89/100 (89%)] Train loss=0.187996 Test loss=0.412640 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16924789547920227
[5/23] Train loss=0.25167062878608704
[10/23] Train loss=0.16296857595443726
[15/23] Train loss=0.15403123199939728
[20/23] Train loss=0.12478996068239212
Test set avg_accuracy=87.28% avg_sensitivity=56.23%, avg_specificity=97.24% avg_auc=0.9208
Fold[4] Epoch: 90 [90/100 (90%)] Train loss=0.187685 Test loss=0.418029 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17115192115306854
[5/23] Train loss=0.2599429190158844
[10/23] Train loss=0.1634964495897293
[15/23] Train loss=0.15447549521923065
[20/23] Train loss=0.12560336291790009
Test set avg_accuracy=87.18% avg_sensitivity=55.80%, avg_specificity=97.24% avg_auc=0.9201
Fold[4] Epoch: 91 [91/100 (91%)] Train loss=0.185690 Test loss=0.424340 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16379787027835846
[5/23] Train loss=0.2660534381866455
[10/23] Train loss=0.1678144484758377
[15/23] Train loss=0.14731135964393616
[20/23] Train loss=0.11913979798555374
Test set avg_accuracy=87.07% avg_sensitivity=55.41%, avg_specificity=97.22% avg_auc=0.9201
Fold[4] Epoch: 92 [92/100 (92%)] Train loss=0.186111 Test loss=0.417573 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16119030117988586
[5/23] Train loss=0.26657336950302124
[10/23] Train loss=0.15765465795993805
[15/23] Train loss=0.14728614687919617
[20/23] Train loss=0.13030119240283966
Test set avg_accuracy=87.69% avg_sensitivity=58.69%, avg_specificity=96.99% avg_auc=0.9216
Fold[4] Epoch: 93 [93/100 (93%)] Train loss=0.184310 Test loss=0.403183 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1570136845111847
[5/23] Train loss=0.2508203089237213
[10/23] Train loss=0.1677413135766983
[15/23] Train loss=0.14035017788410187
[20/23] Train loss=0.12709617614746094
Test set avg_accuracy=87.38% avg_sensitivity=57.01%, avg_specificity=97.11% avg_auc=0.9204
Fold[4] Epoch: 94 [94/100 (94%)] Train loss=0.182394 Test loss=0.412003 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16411782801151276
[5/23] Train loss=0.2535412311553955
[10/23] Train loss=0.14747940003871918
[15/23] Train loss=0.14457711577415466
[20/23] Train loss=0.13144353032112122
Test set avg_accuracy=87.95% avg_sensitivity=60.41%, avg_specificity=96.78% avg_auc=0.9222
Fold[4] Epoch: 95 [95/100 (95%)] Train loss=0.179495 Test loss=0.389202 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15718069672584534
[5/23] Train loss=0.24474556744098663
[10/23] Train loss=0.1598876714706421
[15/23] Train loss=0.1359640657901764
[20/23] Train loss=0.12334149330854416
Test set avg_accuracy=87.86% avg_sensitivity=59.81%, avg_specificity=96.85% avg_auc=0.9219
Fold[4] Epoch: 96 [96/100 (96%)] Train loss=0.179164 Test loss=0.390503 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16111619770526886
[5/23] Train loss=0.2485828846693039
[10/23] Train loss=0.16143308579921722
[15/23] Train loss=0.14783529937267303
[20/23] Train loss=0.11760913580656052
Test set avg_accuracy=87.99% avg_sensitivity=60.50%, avg_specificity=96.79% avg_auc=0.9218
Fold[4] Epoch: 97 [97/100 (97%)] Train loss=0.178607 Test loss=0.396453 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1605493128299713
[5/23] Train loss=0.22727663815021515
[10/23] Train loss=0.153524711728096
[15/23] Train loss=0.14268431067466736
[20/23] Train loss=0.12106463313102722
Test set avg_accuracy=87.49% avg_sensitivity=57.61%, avg_specificity=97.07% avg_auc=0.9207
Fold[4] Epoch: 98 [98/100 (98%)] Train loss=0.175380 Test loss=0.410963 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16019581258296967
[5/23] Train loss=0.23289965093135834
[10/23] Train loss=0.15539681911468506
[15/23] Train loss=0.13730773329734802
[20/23] Train loss=0.11990469694137573
Test set avg_accuracy=87.45% avg_sensitivity=57.09%, avg_specificity=97.18% avg_auc=0.9193
Fold[4] Epoch: 99 [99/100 (99%)] Train loss=0.174080 Test loss=0.420173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1603228598833084
[5/23] Train loss=0.23583434522151947
[10/23] Train loss=0.15741054713726044
[15/23] Train loss=0.13562516868114471
[20/23] Train loss=0.1127033531665802
Test set avg_accuracy=87.36% avg_sensitivity=57.01%, avg_specificity=97.08% avg_auc=0.9194
Fold[4] Epoch: 100 [100/100 (100%)] Train loss=0.171283 Test loss=0.431346 Current lr=[3.9999999999999996e-05]

Fold[4] Best Result: acc=88.39351125065411 sen=64.29495472186288, spe=96.11663902708679, auc=0.9273856151659888!
[0/23] Train loss=0.7110764980316162
[5/23] Train loss=0.6768974661827087
[10/23] Train loss=0.5596213340759277
[15/23] Train loss=0.5055419206619263
[20/23] Train loss=0.46885859966278076
Test set avg_accuracy=74.64% avg_sensitivity=0.83%, avg_specificity=99.62% avg_auc=0.7777
Best model saved!! Metric=-73.14291211547469!!
Fold[5] Epoch: 1 [1/100 (1%)] Train loss=0.553747 Test loss=0.574430 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4685349762439728
[5/23] Train loss=0.4695250689983368
[10/23] Train loss=0.4391070604324341
[15/23] Train loss=0.41520175337791443
[20/23] Train loss=0.3488004207611084
Test set avg_accuracy=79.11% avg_sensitivity=38.91%, avg_specificity=92.72% avg_auc=0.8437
Best model saved!! Metric=-30.892528076373438!!
Fold[5] Epoch: 2 [2/100 (2%)] Train loss=0.433254 Test loss=0.469215 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3776874840259552
[5/23] Train loss=0.4130801558494568
[10/23] Train loss=0.36103373765945435
[15/23] Train loss=0.3731142580509186
[20/23] Train loss=0.3423808813095093
Test set avg_accuracy=81.79% avg_sensitivity=53.27%, avg_specificity=91.44% avg_auc=0.8702
Best model saved!! Metric=-12.478207492653!!
Fold[5] Epoch: 3 [3/100 (3%)] Train loss=0.393730 Test loss=0.421667 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3584526777267456
[5/23] Train loss=0.4274619519710541
[10/23] Train loss=0.3298399746417999
[15/23] Train loss=0.34506386518478394
[20/23] Train loss=0.30884161591529846
Test set avg_accuracy=83.35% avg_sensitivity=63.78%, avg_specificity=89.97% avg_auc=0.8877
Best model saved!! Metric=-0.1320393149602861!!
Fold[5] Epoch: 4 [4/100 (4%)] Train loss=0.373717 Test loss=0.369525 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3407957851886749
[5/23] Train loss=0.399692177772522
[10/23] Train loss=0.3153231739997864
[15/23] Train loss=0.32017162442207336
[20/23] Train loss=0.2819904685020447
Test set avg_accuracy=84.26% avg_sensitivity=65.23%, avg_specificity=90.70% avg_auc=0.8966
Best model saved!! Metric=3.846146868609198!!
Fold[5] Epoch: 5 [5/100 (5%)] Train loss=0.352941 Test loss=0.362090 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3285714387893677
[5/23] Train loss=0.40454959869384766
[10/23] Train loss=0.30646607279777527
[15/23] Train loss=0.2914939224720001
[20/23] Train loss=0.2625591456890106
Test set avg_accuracy=84.98% avg_sensitivity=65.52%, avg_specificity=91.57% avg_auc=0.9043
Best model saved!! Metric=6.503262196294775!!
Fold[5] Epoch: 6 [6/100 (6%)] Train loss=0.340427 Test loss=0.355212 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3075900971889496
[5/23] Train loss=0.39411357045173645
[10/23] Train loss=0.2947392761707306
[15/23] Train loss=0.28285571932792664
[20/23] Train loss=0.2584490478038788
Test set avg_accuracy=85.36% avg_sensitivity=64.90%, avg_specificity=92.28% avg_auc=0.9080
Best model saved!! Metric=7.345930536812947!!
Fold[5] Epoch: 7 [7/100 (7%)] Train loss=0.331164 Test loss=0.348052 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29734793305397034
[5/23] Train loss=0.39755088090896606
[10/23] Train loss=0.283454030752182
[15/23] Train loss=0.2725246846675873
[20/23] Train loss=0.25166094303131104
Test set avg_accuracy=85.69% avg_sensitivity=69.50%, avg_specificity=91.18% avg_auc=0.9141
Best model saved!! Metric=11.769621972523847!!
Fold[5] Epoch: 8 [8/100 (8%)] Train loss=0.325387 Test loss=0.331630 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.285700261592865
[5/23] Train loss=0.3889486789703369
[10/23] Train loss=0.26276516914367676
[15/23] Train loss=0.2663700580596924
[20/23] Train loss=0.23972497880458832
Test set avg_accuracy=85.65% avg_sensitivity=74.05%, avg_specificity=89.58% avg_auc=0.9173
Best model saved!! Metric=15.003928867458455!!
Fold[5] Epoch: 9 [9/100 (9%)] Train loss=0.317295 Test loss=0.327576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27628692984580994
[5/23] Train loss=0.38214510679244995
[10/23] Train loss=0.26499128341674805
[15/23] Train loss=0.25680747628211975
[20/23] Train loss=0.22891566157341003
Test set avg_accuracy=85.76% avg_sensitivity=75.95%, avg_specificity=89.07% avg_auc=0.9206
Best model saved!! Metric=16.840166863941498!!
Fold[5] Epoch: 10 [10/100 (10%)] Train loss=0.306515 Test loss=0.323471 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26604199409484863
[5/23] Train loss=0.374962717294693
[10/23] Train loss=0.24914586544036865
[15/23] Train loss=0.2406764179468155
[20/23] Train loss=0.2165500968694687
Test set avg_accuracy=85.97% avg_sensitivity=75.46%, avg_specificity=89.52% avg_auc=0.9234
Best model saved!! Metric=17.278243549493588!!
Fold[5] Epoch: 11 [11/100 (11%)] Train loss=0.301065 Test loss=0.313891 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26289641857147217
[5/23] Train loss=0.36869603395462036
[10/23] Train loss=0.2521372437477112
[15/23] Train loss=0.2351820319890976
[20/23] Train loss=0.21989451348781586
Test set avg_accuracy=86.14% avg_sensitivity=75.66%, avg_specificity=89.69% avg_auc=0.9248
Best model saved!! Metric=17.97411896167715!!
Fold[5] Epoch: 12 [12/100 (12%)] Train loss=0.296972 Test loss=0.311401 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27134254574775696
[5/23] Train loss=0.3703572452068329
[10/23] Train loss=0.24900193512439728
[15/23] Train loss=0.24334393441677094
[20/23] Train loss=0.2184535264968872
Test set avg_accuracy=86.20% avg_sensitivity=76.32%, avg_specificity=89.54% avg_auc=0.9262
Best model saved!! Metric=18.672059460880185!!
Fold[5] Epoch: 13 [13/100 (13%)] Train loss=0.295518 Test loss=0.307497 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2568363547325134
[5/23] Train loss=0.36214935779571533
[10/23] Train loss=0.2371894270181656
[15/23] Train loss=0.2417033463716507
[20/23] Train loss=0.21351976692676544
Test set avg_accuracy=86.36% avg_sensitivity=76.66%, avg_specificity=89.65% avg_auc=0.9271
Best model saved!! Metric=19.381938901714264!!
Fold[5] Epoch: 14 [14/100 (14%)] Train loss=0.288629 Test loss=0.307202 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24995967745780945
[5/23] Train loss=0.35208532214164734
[10/23] Train loss=0.23665751516819
[15/23] Train loss=0.23743359744548798
[20/23] Train loss=0.21155163645744324
Test set avg_accuracy=86.66% avg_sensitivity=76.66%, avg_specificity=90.04% avg_auc=0.9307
Best model saved!! Metric=20.42283005408612!!
Fold[5] Epoch: 15 [15/100 (15%)] Train loss=0.285750 Test loss=0.295402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23824620246887207
[5/23] Train loss=0.3568137586116791
[10/23] Train loss=0.23932631313800812
[15/23] Train loss=0.21861720085144043
[20/23] Train loss=0.20600533485412598
Test set avg_accuracy=86.86% avg_sensitivity=76.24%, avg_specificity=90.45% avg_auc=0.9321
Best model saved!! Metric=20.758327946014994!!
Fold[5] Epoch: 16 [16/100 (16%)] Train loss=0.283465 Test loss=0.290112 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23460988700389862
[5/23] Train loss=0.347382128238678
[10/23] Train loss=0.22362935543060303
[15/23] Train loss=0.23167714476585388
[20/23] Train loss=0.19531115889549255
Test set avg_accuracy=87.03% avg_sensitivity=76.82%, avg_specificity=90.49% avg_auc=0.9336
Best model saved!! Metric=21.705310396396534!!
Fold[5] Epoch: 17 [17/100 (17%)] Train loss=0.278829 Test loss=0.287471 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2412078082561493
[5/23] Train loss=0.3572938144207001
[10/23] Train loss=0.22906740009784698
[15/23] Train loss=0.23699504137039185
[20/23] Train loss=0.19526050984859467
Test set avg_accuracy=87.06% avg_sensitivity=77.94%, avg_specificity=90.15% avg_auc=0.9340
Best model saved!! Metric=22.553393200096046!!
Fold[5] Epoch: 18 [18/100 (18%)] Train loss=0.277306 Test loss=0.288078 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2342071533203125
[5/23] Train loss=0.33577868342399597
[10/23] Train loss=0.22644203901290894
[15/23] Train loss=0.22230349481105804
[20/23] Train loss=0.18957458436489105
Test set avg_accuracy=87.15% avg_sensitivity=78.44%, avg_specificity=90.10% avg_auc=0.9356
Best model saved!! Metric=23.243801325107203!!
Fold[5] Epoch: 19 [19/100 (19%)] Train loss=0.273448 Test loss=0.286666 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23517200350761414
[5/23] Train loss=0.35533174872398376
[10/23] Train loss=0.22626140713691711
[15/23] Train loss=0.2182517945766449
[20/23] Train loss=0.19424346089363098
Test set avg_accuracy=87.58% avg_sensitivity=77.57%, avg_specificity=90.97% avg_auc=0.9370
Best model saved!! Metric=23.804808332156625!!
Fold[5] Epoch: 20 [20/100 (20%)] Train loss=0.273409 Test loss=0.278229 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22940297424793243
[5/23] Train loss=0.3525451421737671
[10/23] Train loss=0.22486209869384766
[15/23] Train loss=0.20966236293315887
[20/23] Train loss=0.19072523713111877
Test set avg_accuracy=87.57% avg_sensitivity=77.40%, avg_specificity=91.01% avg_auc=0.9370
Fold[5] Epoch: 21 [21/100 (21%)] Train loss=0.267783 Test loss=0.277493 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23211126029491425
[5/23] Train loss=0.3569301664829254
[10/23] Train loss=0.22105945646762848
[15/23] Train loss=0.21017031371593475
[20/23] Train loss=0.1835637241601944
Test set avg_accuracy=87.88% avg_sensitivity=77.69%, avg_specificity=91.33% avg_auc=0.9387
Best model saved!! Metric=24.770635579571305!!
Fold[5] Epoch: 22 [22/100 (22%)] Train loss=0.268916 Test loss=0.271681 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22995524108409882
[5/23] Train loss=0.34831133484840393
[10/23] Train loss=0.22287438809871674
[15/23] Train loss=0.2111823409795761
[20/23] Train loss=0.18484841287136078
Test set avg_accuracy=87.96% avg_sensitivity=77.32%, avg_specificity=91.57% avg_auc=0.9390
Fold[5] Epoch: 23 [23/100 (23%)] Train loss=0.266064 Test loss=0.271575 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21920202672481537
[5/23] Train loss=0.3398831784725189
[10/23] Train loss=0.22334209084510803
[15/23] Train loss=0.20279023051261902
[20/23] Train loss=0.1837277114391327
Test set avg_accuracy=88.07% avg_sensitivity=77.98%, avg_specificity=91.48% avg_auc=0.9390
Best model saved!! Metric=25.428080693448557!!
Fold[5] Epoch: 24 [24/100 (24%)] Train loss=0.262254 Test loss=0.272285 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21589738130569458
[5/23] Train loss=0.342234343290329
[10/23] Train loss=0.207856684923172
[15/23] Train loss=0.2035152167081833
[20/23] Train loss=0.19165951013565063
Test set avg_accuracy=87.97% avg_sensitivity=77.32%, avg_specificity=91.58% avg_auc=0.9396
Fold[5] Epoch: 25 [25/100 (25%)] Train loss=0.263953 Test loss=0.269936 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2200125753879547
[5/23] Train loss=0.3402937054634094
[10/23] Train loss=0.21135692298412323
[15/23] Train loss=0.2011280208826065
[20/23] Train loss=0.1825529783964157
Test set avg_accuracy=88.06% avg_sensitivity=77.32%, avg_specificity=91.69% avg_auc=0.9393
Fold[5] Epoch: 26 [26/100 (26%)] Train loss=0.257569 Test loss=0.270197 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2195749282836914
[5/23] Train loss=0.3412364423274994
[10/23] Train loss=0.2128109484910965
[15/23] Train loss=0.20246736705303192
[20/23] Train loss=0.18329362571239471
Test set avg_accuracy=88.33% avg_sensitivity=79.06%, avg_specificity=91.47% avg_auc=0.9410
Best model saved!! Metric=26.95865489594689!!
Fold[5] Epoch: 27 [27/100 (27%)] Train loss=0.260276 Test loss=0.266973 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.228128120303154
[5/23] Train loss=0.34017640352249146
[10/23] Train loss=0.21064509451389313
[15/23] Train loss=0.19849751889705658
[20/23] Train loss=0.18385635316371918
Test set avg_accuracy=88.06% avg_sensitivity=78.56%, avg_specificity=91.27% avg_auc=0.9399
Fold[5] Epoch: 28 [28/100 (28%)] Train loss=0.256878 Test loss=0.270542 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2169395387172699
[5/23] Train loss=0.3346642553806305
[10/23] Train loss=0.20535285770893097
[15/23] Train loss=0.19869370758533478
[20/23] Train loss=0.1801971048116684
Test set avg_accuracy=88.36% avg_sensitivity=79.64%, avg_specificity=91.32% avg_auc=0.9414
Best model saved!! Metric=27.454249756819518!!
Fold[5] Epoch: 29 [29/100 (29%)] Train loss=0.253781 Test loss=0.267437 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22294382750988007
[5/23] Train loss=0.3260847330093384
[10/23] Train loss=0.21999484300613403
[15/23] Train loss=0.20127317309379578
[20/23] Train loss=0.17737632989883423
Test set avg_accuracy=88.45% avg_sensitivity=78.48%, avg_specificity=91.82% avg_auc=0.9417
Fold[5] Epoch: 30 [30/100 (30%)] Train loss=0.254585 Test loss=0.264498 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21297721564769745
[5/23] Train loss=0.32858750224113464
[10/23] Train loss=0.21765989065170288
[15/23] Train loss=0.19791224598884583
[20/23] Train loss=0.1782686710357666
Test set avg_accuracy=88.64% avg_sensitivity=78.52%, avg_specificity=92.07% avg_auc=0.9428
Best model saved!! Metric=27.51644290192132!!
Fold[5] Epoch: 31 [31/100 (31%)] Train loss=0.253953 Test loss=0.261259 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21063730120658875
[5/23] Train loss=0.3285016119480133
[10/23] Train loss=0.2104262113571167
[15/23] Train loss=0.19980710744857788
[20/23] Train loss=0.1734798401594162
Test set avg_accuracy=88.36% avg_sensitivity=79.55%, avg_specificity=91.34% avg_auc=0.9428
Best model saved!! Metric=27.539808375692257!!
Fold[5] Epoch: 32 [32/100 (32%)] Train loss=0.251692 Test loss=0.263000 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2061896175146103
[5/23] Train loss=0.32485249638557434
[10/23] Train loss=0.2118832767009735
[15/23] Train loss=0.1876920908689499
[20/23] Train loss=0.16713540256023407
Test set avg_accuracy=88.39% avg_sensitivity=78.85%, avg_specificity=91.62% avg_auc=0.9434
Fold[5] Epoch: 33 [33/100 (33%)] Train loss=0.248880 Test loss=0.260456 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2055504024028778
[5/23] Train loss=0.3254997432231903
[10/23] Train loss=0.2165045589208603
[15/23] Train loss=0.19995957612991333
[20/23] Train loss=0.1795250028371811
Test set avg_accuracy=88.16% avg_sensitivity=77.48%, avg_specificity=91.78% avg_auc=0.9400
Fold[5] Epoch: 34 [34/100 (34%)] Train loss=0.252163 Test loss=0.267043 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20847271382808685
[5/23] Train loss=0.3247838020324707
[10/23] Train loss=0.20364205539226532
[15/23] Train loss=0.19678813219070435
[20/23] Train loss=0.1696861833333969
Test set avg_accuracy=88.45% avg_sensitivity=78.56%, avg_specificity=91.79% avg_auc=0.9418
Fold[5] Epoch: 35 [35/100 (35%)] Train loss=0.247093 Test loss=0.263699 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20808753371238708
[5/23] Train loss=0.3267456591129303
[10/23] Train loss=0.20603738725185394
[15/23] Train loss=0.19847331941127777
[20/23] Train loss=0.169458270072937
Test set avg_accuracy=88.35% avg_sensitivity=78.56%, avg_specificity=91.67% avg_auc=0.9425
Fold[5] Epoch: 36 [36/100 (36%)] Train loss=0.245450 Test loss=0.261685 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21563729643821716
[5/23] Train loss=0.33553212881088257
[10/23] Train loss=0.20420944690704346
[15/23] Train loss=0.193983793258667
[20/23] Train loss=0.1659376472234726
Test set avg_accuracy=88.30% avg_sensitivity=78.31%, avg_specificity=91.68% avg_auc=0.9428
Fold[5] Epoch: 37 [37/100 (37%)] Train loss=0.248296 Test loss=0.261161 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21004913747310638
[5/23] Train loss=0.338900625705719
[10/23] Train loss=0.20160798728466034
[15/23] Train loss=0.18484826385974884
[20/23] Train loss=0.16436469554901123
Test set avg_accuracy=88.19% avg_sensitivity=78.27%, avg_specificity=91.55% avg_auc=0.9436
Fold[5] Epoch: 38 [38/100 (38%)] Train loss=0.244205 Test loss=0.260246 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20065748691558838
[5/23] Train loss=0.3162609338760376
[10/23] Train loss=0.19957932829856873
[15/23] Train loss=0.19906160235404968
[20/23] Train loss=0.17511403560638428
Test set avg_accuracy=88.36% avg_sensitivity=76.66%, avg_specificity=92.32% avg_auc=0.9422
Fold[5] Epoch: 39 [39/100 (39%)] Train loss=0.242643 Test loss=0.260931 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20383819937705994
[5/23] Train loss=0.3263232111930847
[10/23] Train loss=0.2054547220468521
[15/23] Train loss=0.18152111768722534
[20/23] Train loss=0.17288358509540558
Test set avg_accuracy=88.58% avg_sensitivity=78.31%, avg_specificity=92.06% avg_auc=0.9439
Fold[5] Epoch: 40 [40/100 (40%)] Train loss=0.242219 Test loss=0.258151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20473255217075348
[5/23] Train loss=0.32232558727264404
[10/23] Train loss=0.20416314899921417
[15/23] Train loss=0.18760782480239868
[20/23] Train loss=0.1669442355632782
Test set avg_accuracy=88.62% avg_sensitivity=77.69%, avg_specificity=92.32% avg_auc=0.9439
Fold[5] Epoch: 41 [41/100 (41%)] Train loss=0.241295 Test loss=0.257459 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20318318903446198
[5/23] Train loss=0.3159072697162628
[10/23] Train loss=0.20567090809345245
[15/23] Train loss=0.1872287094593048
[20/23] Train loss=0.1641796976327896
Test set avg_accuracy=88.60% avg_sensitivity=78.85%, avg_specificity=91.90% avg_auc=0.9440
Best model saved!! Metric=27.758372323616424!!
Fold[5] Epoch: 42 [42/100 (42%)] Train loss=0.237645 Test loss=0.259339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1962389349937439
[5/23] Train loss=0.3120209276676178
[10/23] Train loss=0.19493770599365234
[15/23] Train loss=0.1799563318490982
[20/23] Train loss=0.16029874980449677
Test set avg_accuracy=88.44% avg_sensitivity=78.93%, avg_specificity=91.65% avg_auc=0.9431
Fold[5] Epoch: 43 [43/100 (43%)] Train loss=0.238551 Test loss=0.260651 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1957462579011917
[5/23] Train loss=0.30106523633003235
[10/23] Train loss=0.1944493055343628
[15/23] Train loss=0.18742883205413818
[20/23] Train loss=0.16057781875133514
Test set avg_accuracy=88.59% avg_sensitivity=78.81%, avg_specificity=91.90% avg_auc=0.9438
Fold[5] Epoch: 44 [44/100 (44%)] Train loss=0.233958 Test loss=0.258906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19182656705379486
[5/23] Train loss=0.30526721477508545
[10/23] Train loss=0.19994810223579407
[15/23] Train loss=0.1862151026725769
[20/23] Train loss=0.15832579135894775
Test set avg_accuracy=88.62% avg_sensitivity=78.93%, avg_specificity=91.90% avg_auc=0.9441
Best model saved!! Metric=27.87243436165037!!
Fold[5] Epoch: 45 [45/100 (45%)] Train loss=0.234385 Test loss=0.258895 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20067192614078522
[5/23] Train loss=0.3140934109687805
[10/23] Train loss=0.20009282231330872
[15/23] Train loss=0.18077196180820465
[20/23] Train loss=0.15993180871009827
Test set avg_accuracy=88.87% avg_sensitivity=78.10%, avg_specificity=92.52% avg_auc=0.9437
Fold[5] Epoch: 46 [46/100 (46%)] Train loss=0.234015 Test loss=0.258369 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20346617698669434
[5/23] Train loss=0.3058239817619324
[10/23] Train loss=0.1983644962310791
[15/23] Train loss=0.19159187376499176
[20/23] Train loss=0.16138039529323578
Test set avg_accuracy=88.66% avg_sensitivity=78.19%, avg_specificity=92.20% avg_auc=0.9440
Fold[5] Epoch: 47 [47/100 (47%)] Train loss=0.233416 Test loss=0.258561 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18805396556854248
[5/23] Train loss=0.30545827746391296
[10/23] Train loss=0.2018842101097107
[15/23] Train loss=0.1781754344701767
[20/23] Train loss=0.15620702505111694
Test set avg_accuracy=88.85% avg_sensitivity=77.86%, avg_specificity=92.58% avg_auc=0.9431
Fold[5] Epoch: 48 [48/100 (48%)] Train loss=0.230645 Test loss=0.258421 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19497928023338318
[5/23] Train loss=0.3095652163028717
[10/23] Train loss=0.1995062381029129
[15/23] Train loss=0.18661004304885864
[20/23] Train loss=0.1571131944656372
Test set avg_accuracy=88.64% avg_sensitivity=77.65%, avg_specificity=92.37% avg_auc=0.9438
Fold[5] Epoch: 49 [49/100 (49%)] Train loss=0.231927 Test loss=0.258022 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19401097297668457
[5/23] Train loss=0.31828123331069946
[10/23] Train loss=0.2038002908229828
[15/23] Train loss=0.17464756965637207
[20/23] Train loss=0.16184362769126892
Test set avg_accuracy=88.45% avg_sensitivity=79.97%, avg_specificity=91.32% avg_auc=0.9442
Best model saved!! Metric=28.150742707371574!!
Fold[5] Epoch: 50 [50/100 (50%)] Train loss=0.232239 Test loss=0.261129 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1935914158821106
[5/23] Train loss=0.3104207217693329
[10/23] Train loss=0.18843507766723633
[15/23] Train loss=0.18481799960136414
[20/23] Train loss=0.16219061613082886
Test set avg_accuracy=88.28% avg_sensitivity=78.77%, avg_specificity=91.50% avg_auc=0.9420
Fold[5] Epoch: 51 [51/100 (51%)] Train loss=0.229523 Test loss=0.264922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19391120970249176
[5/23] Train loss=0.2928716540336609
[10/23] Train loss=0.19490677118301392
[15/23] Train loss=0.17765313386917114
[20/23] Train loss=0.15435096621513367
Test set avg_accuracy=88.57% avg_sensitivity=78.68%, avg_specificity=91.92% avg_auc=0.9434
Fold[5] Epoch: 52 [52/100 (52%)] Train loss=0.226219 Test loss=0.261405 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.182074174284935
[5/23] Train loss=0.3126264810562134
[10/23] Train loss=0.18850158154964447
[15/23] Train loss=0.1870158165693283
[20/23] Train loss=0.1562405675649643
Test set avg_accuracy=88.44% avg_sensitivity=78.68%, avg_specificity=91.74% avg_auc=0.9427
Fold[5] Epoch: 53 [53/100 (53%)] Train loss=0.228346 Test loss=0.262277 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.192109152674675
[5/23] Train loss=0.31005188822746277
[10/23] Train loss=0.19562506675720215
[15/23] Train loss=0.1790473610162735
[20/23] Train loss=0.15479901432991028
Test set avg_accuracy=88.45% avg_sensitivity=78.39%, avg_specificity=91.85% avg_auc=0.9421
Fold[5] Epoch: 54 [54/100 (54%)] Train loss=0.228261 Test loss=0.263952 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18794701993465424
[5/23] Train loss=0.2972021996974945
[10/23] Train loss=0.19147300720214844
[15/23] Train loss=0.17488591372966766
[20/23] Train loss=0.15838511288166046
Test set avg_accuracy=88.51% avg_sensitivity=78.73%, avg_specificity=91.82% avg_auc=0.9423
Fold[5] Epoch: 55 [55/100 (55%)] Train loss=0.222181 Test loss=0.263446 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19282256066799164
[5/23] Train loss=0.30642440915107727
[10/23] Train loss=0.18947012722492218
[15/23] Train loss=0.16925303637981415
[20/23] Train loss=0.1582002192735672
Test set avg_accuracy=88.51% avg_sensitivity=79.35%, avg_specificity=91.61% avg_auc=0.9427
Fold[5] Epoch: 56 [56/100 (56%)] Train loss=0.223547 Test loss=0.263654 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17981703579425812
[5/23] Train loss=0.29371950030326843
[10/23] Train loss=0.1892627328634262
[15/23] Train loss=0.1787191778421402
[20/23] Train loss=0.1488058865070343
Test set avg_accuracy=88.67% avg_sensitivity=77.81%, avg_specificity=92.34% avg_auc=0.9425
Fold[5] Epoch: 57 [57/100 (57%)] Train loss=0.221389 Test loss=0.261663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18800602853298187
[5/23] Train loss=0.2940642237663269
[10/23] Train loss=0.19328714907169342
[15/23] Train loss=0.17097392678260803
[20/23] Train loss=0.1406334638595581
Test set avg_accuracy=88.39% avg_sensitivity=77.15%, avg_specificity=92.20% avg_auc=0.9414
Fold[5] Epoch: 58 [58/100 (58%)] Train loss=0.218625 Test loss=0.264266 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1865079402923584
[5/23] Train loss=0.2918608486652374
[10/23] Train loss=0.19157907366752625
[15/23] Train loss=0.17362716794013977
[20/23] Train loss=0.14844246208667755
Test set avg_accuracy=88.23% avg_sensitivity=77.77%, avg_specificity=91.76% avg_auc=0.9409
Fold[5] Epoch: 59 [59/100 (59%)] Train loss=0.221758 Test loss=0.266361 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18954633176326752
[5/23] Train loss=0.2882712185382843
[10/23] Train loss=0.18137502670288086
[15/23] Train loss=0.166466623544693
[20/23] Train loss=0.15197855234146118
Test set avg_accuracy=88.42% avg_sensitivity=77.36%, avg_specificity=92.17% avg_auc=0.9409
Fold[5] Epoch: 60 [60/100 (60%)] Train loss=0.218074 Test loss=0.265942 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18235038220882416
[5/23] Train loss=0.28185343742370605
[10/23] Train loss=0.18877901136875153
[15/23] Train loss=0.1663898527622223
[20/23] Train loss=0.14707791805267334
Test set avg_accuracy=88.48% avg_sensitivity=77.03%, avg_specificity=92.35% avg_auc=0.9400
Fold[5] Epoch: 61 [61/100 (61%)] Train loss=0.215652 Test loss=0.267708 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1799459010362625
[5/23] Train loss=0.29872238636016846
[10/23] Train loss=0.1886310577392578
[15/23] Train loss=0.17221319675445557
[20/23] Train loss=0.15260516107082367
Test set avg_accuracy=88.62% avg_sensitivity=78.02%, avg_specificity=92.21% avg_auc=0.9416
Fold[5] Epoch: 62 [62/100 (62%)] Train loss=0.218594 Test loss=0.263633 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1859452724456787
[5/23] Train loss=0.28705039620399475
[10/23] Train loss=0.1788928210735321
[15/23] Train loss=0.17294619977474213
[20/23] Train loss=0.14511527121067047
Test set avg_accuracy=88.26% avg_sensitivity=78.31%, avg_specificity=91.62% avg_auc=0.9402
Fold[5] Epoch: 63 [63/100 (63%)] Train loss=0.216583 Test loss=0.269576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1849396824836731
[5/23] Train loss=0.27710089087486267
[10/23] Train loss=0.18501746654510498
[15/23] Train loss=0.16910438239574432
[20/23] Train loss=0.13679464161396027
Test set avg_accuracy=88.49% avg_sensitivity=76.99%, avg_specificity=92.38% avg_auc=0.9396
Fold[5] Epoch: 64 [64/100 (64%)] Train loss=0.212753 Test loss=0.268153 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18114198744297028
[5/23] Train loss=0.2799715995788574
[10/23] Train loss=0.19080783426761627
[15/23] Train loss=0.1671718955039978
[20/23] Train loss=0.14058901369571686
Test set avg_accuracy=88.47% avg_sensitivity=76.03%, avg_specificity=92.67% avg_auc=0.9397
Fold[5] Epoch: 65 [65/100 (65%)] Train loss=0.210344 Test loss=0.267920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17804817855358124
[5/23] Train loss=0.2977619171142578
[10/23] Train loss=0.1877446323633194
[15/23] Train loss=0.16157416999340057
[20/23] Train loss=0.14349231123924255
Test set avg_accuracy=88.42% avg_sensitivity=75.08%, avg_specificity=92.94% avg_auc=0.9397
Fold[5] Epoch: 66 [66/100 (66%)] Train loss=0.212646 Test loss=0.267796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17820169031620026
[5/23] Train loss=0.2904163897037506
[10/23] Train loss=0.18028485774993896
[15/23] Train loss=0.16363655030727386
[20/23] Train loss=0.1450165957212448
Test set avg_accuracy=88.49% avg_sensitivity=76.24%, avg_specificity=92.63% avg_auc=0.9398
Fold[5] Epoch: 67 [67/100 (67%)] Train loss=0.212447 Test loss=0.268779 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1757388412952423
[5/23] Train loss=0.2800401747226715
[10/23] Train loss=0.18191447854042053
[15/23] Train loss=0.1674509346485138
[20/23] Train loss=0.14186568558216095
Test set avg_accuracy=87.93% avg_sensitivity=76.45%, avg_specificity=91.82% avg_auc=0.9375
Fold[5] Epoch: 68 [68/100 (68%)] Train loss=0.209411 Test loss=0.274122 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18965770304203033
[5/23] Train loss=0.27913105487823486
[10/23] Train loss=0.17386700212955475
[15/23] Train loss=0.16003242135047913
[20/23] Train loss=0.14160722494125366
Test set avg_accuracy=87.84% avg_sensitivity=77.90%, avg_specificity=91.20% avg_auc=0.9377
Fold[5] Epoch: 69 [69/100 (69%)] Train loss=0.210438 Test loss=0.277046 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1800854355096817
[5/23] Train loss=0.2717312276363373
[10/23] Train loss=0.18290618062019348
[15/23] Train loss=0.16345393657684326
[20/23] Train loss=0.14578109979629517
Test set avg_accuracy=88.02% avg_sensitivity=77.24%, avg_specificity=91.67% avg_auc=0.9379
Fold[5] Epoch: 70 [70/100 (70%)] Train loss=0.207671 Test loss=0.276319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17835001647472382
[5/23] Train loss=0.2779088020324707
[10/23] Train loss=0.17719484865665436
[15/23] Train loss=0.15426643192768097
[20/23] Train loss=0.14076854288578033
Test set avg_accuracy=88.10% avg_sensitivity=77.40%, avg_specificity=91.72% avg_auc=0.9390
Fold[5] Epoch: 71 [71/100 (71%)] Train loss=0.206694 Test loss=0.272501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17506003379821777
[5/23] Train loss=0.27125826478004456
[10/23] Train loss=0.17042505741119385
[15/23] Train loss=0.15482719242572784
[20/23] Train loss=0.14128141105175018
Test set avg_accuracy=88.18% avg_sensitivity=76.70%, avg_specificity=92.07% avg_auc=0.9381
Fold[5] Epoch: 72 [72/100 (72%)] Train loss=0.203868 Test loss=0.274107 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17617583274841309
[5/23] Train loss=0.28418317437171936
[10/23] Train loss=0.18089208006858826
[15/23] Train loss=0.1595705896615982
[20/23] Train loss=0.13522188365459442
Test set avg_accuracy=88.12% avg_sensitivity=76.20%, avg_specificity=92.16% avg_auc=0.9373
Fold[5] Epoch: 73 [73/100 (73%)] Train loss=0.205481 Test loss=0.274451 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.176431804895401
[5/23] Train loss=0.26214009523391724
[10/23] Train loss=0.1821514070034027
[15/23] Train loss=0.1626928597688675
[20/23] Train loss=0.1350201815366745
Test set avg_accuracy=87.95% avg_sensitivity=74.88%, avg_specificity=92.38% avg_auc=0.9366
Fold[5] Epoch: 74 [74/100 (74%)] Train loss=0.202436 Test loss=0.275616 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17891712486743927
[5/23] Train loss=0.28337201476097107
[10/23] Train loss=0.17551381886005402
[15/23] Train loss=0.15543554723262787
[20/23] Train loss=0.13989746570587158
Test set avg_accuracy=88.11% avg_sensitivity=75.70%, avg_specificity=92.31% avg_auc=0.9376
Fold[5] Epoch: 75 [75/100 (75%)] Train loss=0.204066 Test loss=0.275069 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16141389310359955
[5/23] Train loss=0.27013084292411804
[10/23] Train loss=0.1770438849925995
[15/23] Train loss=0.164934441447258
[20/23] Train loss=0.13761717081069946
Test set avg_accuracy=88.13% avg_sensitivity=77.65%, avg_specificity=91.68% avg_auc=0.9388
Fold[5] Epoch: 76 [76/100 (76%)] Train loss=0.201775 Test loss=0.273829 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16725099086761475
[5/23] Train loss=0.2671176493167877
[10/23] Train loss=0.1673089563846588
[15/23] Train loss=0.157120019197464
[20/23] Train loss=0.1365516483783722
Test set avg_accuracy=88.33% avg_sensitivity=76.28%, avg_specificity=92.41% avg_auc=0.9380
Fold[5] Epoch: 77 [77/100 (77%)] Train loss=0.199918 Test loss=0.274012 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16618691384792328
[5/23] Train loss=0.2609454095363617
[10/23] Train loss=0.17688371241092682
[15/23] Train loss=0.16612383723258972
[20/23] Train loss=0.12460025399923325
Test set avg_accuracy=88.07% avg_sensitivity=75.95%, avg_specificity=92.17% avg_auc=0.9379
Fold[5] Epoch: 78 [78/100 (78%)] Train loss=0.200048 Test loss=0.277498 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16894268989562988
[5/23] Train loss=0.2617398202419281
[10/23] Train loss=0.1802135556936264
[15/23] Train loss=0.16169990599155426
[20/23] Train loss=0.14139263331890106
Test set avg_accuracy=87.87% avg_sensitivity=76.20%, avg_specificity=91.82% avg_auc=0.9355
Fold[5] Epoch: 79 [79/100 (79%)] Train loss=0.198172 Test loss=0.281910 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1684020459651947
[5/23] Train loss=0.2627207934856415
[10/23] Train loss=0.1699034422636032
[15/23] Train loss=0.1604718416929245
[20/23] Train loss=0.13095217943191528
Test set avg_accuracy=87.80% avg_sensitivity=76.12%, avg_specificity=91.75% avg_auc=0.9351
Fold[5] Epoch: 80 [80/100 (80%)] Train loss=0.196038 Test loss=0.284488 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16952604055404663
[5/23] Train loss=0.27145543694496155
[10/23] Train loss=0.1722802221775055
[15/23] Train loss=0.15509481728076935
[20/23] Train loss=0.1279749572277069
Test set avg_accuracy=87.79% avg_sensitivity=76.28%, avg_specificity=91.68% avg_auc=0.9350
Fold[5] Epoch: 81 [81/100 (81%)] Train loss=0.194696 Test loss=0.285670 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16381016373634338
[5/23] Train loss=0.27330824732780457
[10/23] Train loss=0.1682145595550537
[15/23] Train loss=0.1546555757522583
[20/23] Train loss=0.12936019897460938
Test set avg_accuracy=88.10% avg_sensitivity=77.48%, avg_specificity=91.69% avg_auc=0.9373
Fold[5] Epoch: 82 [82/100 (82%)] Train loss=0.194347 Test loss=0.279775 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17284315824508667
[5/23] Train loss=0.2636181116104126
[10/23] Train loss=0.16378989815711975
[15/23] Train loss=0.15357720851898193
[20/23] Train loss=0.1262761950492859
Test set avg_accuracy=87.56% avg_sensitivity=77.03%, avg_specificity=91.12% avg_auc=0.9333
Fold[5] Epoch: 83 [83/100 (83%)] Train loss=0.192630 Test loss=0.290192 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1640535444021225
[5/23] Train loss=0.25871312618255615
[10/23] Train loss=0.1653946340084076
[15/23] Train loss=0.15205250680446625
[20/23] Train loss=0.1268676221370697
Test set avg_accuracy=88.22% avg_sensitivity=76.32%, avg_specificity=92.24% avg_auc=0.9353
Fold[5] Epoch: 84 [84/100 (84%)] Train loss=0.191483 Test loss=0.283851 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1584809422492981
[5/23] Train loss=0.26681825518608093
[10/23] Train loss=0.16198590397834778
[15/23] Train loss=0.15516337752342224
[20/23] Train loss=0.12701039016246796
Test set avg_accuracy=87.92% avg_sensitivity=76.82%, avg_specificity=91.68% avg_auc=0.9345
Fold[5] Epoch: 85 [85/100 (85%)] Train loss=0.189403 Test loss=0.285758 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16311492025852203
[5/23] Train loss=0.2529211640357971
[10/23] Train loss=0.16804681718349457
[15/23] Train loss=0.1482134610414505
[20/23] Train loss=0.12889786064624786
Test set avg_accuracy=87.62% avg_sensitivity=76.66%, avg_specificity=91.33% avg_auc=0.9328
Fold[5] Epoch: 86 [86/100 (86%)] Train loss=0.189843 Test loss=0.291703 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16615106165409088
[5/23] Train loss=0.2516363859176636
[10/23] Train loss=0.16285791993141174
[15/23] Train loss=0.15957708656787872
[20/23] Train loss=0.12488695979118347
Test set avg_accuracy=87.73% avg_sensitivity=77.65%, avg_specificity=91.15% avg_auc=0.9340
Fold[5] Epoch: 87 [87/100 (87%)] Train loss=0.187109 Test loss=0.288368 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1687544286251068
[5/23] Train loss=0.24949230253696442
[10/23] Train loss=0.15571711957454681
[15/23] Train loss=0.1495501846075058
[20/23] Train loss=0.12095706909894943
Test set avg_accuracy=87.70% avg_sensitivity=77.52%, avg_specificity=91.15% avg_auc=0.9332
Fold[5] Epoch: 88 [88/100 (88%)] Train loss=0.186621 Test loss=0.292662 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16384682059288025
[5/23] Train loss=0.24267102777957916
[10/23] Train loss=0.16106559336185455
[15/23] Train loss=0.14655005931854248
[20/23] Train loss=0.12818896770477295
Test set avg_accuracy=87.69% avg_sensitivity=77.28%, avg_specificity=91.22% avg_auc=0.9331
Fold[5] Epoch: 89 [89/100 (89%)] Train loss=0.184428 Test loss=0.292570 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16752617061138153
[5/23] Train loss=0.257437139749527
[10/23] Train loss=0.16787371039390564
[15/23] Train loss=0.1528068333864212
[20/23] Train loss=0.11853358894586563
Test set avg_accuracy=87.62% avg_sensitivity=75.17%, avg_specificity=91.83% avg_auc=0.9318
Fold[5] Epoch: 90 [90/100 (90%)] Train loss=0.186044 Test loss=0.293028 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15643192827701569
[5/23] Train loss=0.24708107113838196
[10/23] Train loss=0.1599774807691574
[15/23] Train loss=0.15265457332134247
[20/23] Train loss=0.12266683578491211
Test set avg_accuracy=87.90% avg_sensitivity=76.03%, avg_specificity=91.92% avg_auc=0.9338
Fold[5] Epoch: 91 [91/100 (91%)] Train loss=0.182395 Test loss=0.285982 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16178534924983978
[5/23] Train loss=0.24260582029819489
[10/23] Train loss=0.16265298426151276
[15/23] Train loss=0.14673921465873718
[20/23] Train loss=0.11952850222587585
Test set avg_accuracy=87.65% avg_sensitivity=76.20%, avg_specificity=91.53% avg_auc=0.9328
Fold[5] Epoch: 92 [92/100 (92%)] Train loss=0.182504 Test loss=0.291922 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15456274151802063
[5/23] Train loss=0.25132060050964355
[10/23] Train loss=0.16151291131973267
[15/23] Train loss=0.14908544719219208
[20/23] Train loss=0.12380344420671463
Test set avg_accuracy=87.46% avg_sensitivity=75.83%, avg_specificity=91.40% avg_auc=0.9302
Fold[5] Epoch: 93 [93/100 (93%)] Train loss=0.179769 Test loss=0.296598 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1599740833044052
[5/23] Train loss=0.25950393080711365
[10/23] Train loss=0.16406963765621185
[15/23] Train loss=0.13470391929149628
[20/23] Train loss=0.12758950889110565
Test set avg_accuracy=87.36% avg_sensitivity=76.16%, avg_specificity=91.15% avg_auc=0.9297
Fold[5] Epoch: 94 [94/100 (94%)] Train loss=0.178822 Test loss=0.301316 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15601256489753723
[5/23] Train loss=0.23994481563568115
[10/23] Train loss=0.15947578847408295
[15/23] Train loss=0.14002935588359833
[20/23] Train loss=0.11650969088077545
Test set avg_accuracy=87.46% avg_sensitivity=75.12%, avg_specificity=91.64% avg_auc=0.9295
Fold[5] Epoch: 95 [95/100 (95%)] Train loss=0.176812 Test loss=0.299517 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15380440652370453
[5/23] Train loss=0.23304231464862823
[10/23] Train loss=0.16244463622570038
[15/23] Train loss=0.13720150291919708
[20/23] Train loss=0.11494850367307663
Test set avg_accuracy=87.49% avg_sensitivity=77.40%, avg_specificity=90.91% avg_auc=0.9307
Fold[5] Epoch: 96 [96/100 (96%)] Train loss=0.174102 Test loss=0.301718 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15259869396686554
[5/23] Train loss=0.23372574150562286
[10/23] Train loss=0.15524160861968994
[15/23] Train loss=0.15144756436347961
[20/23] Train loss=0.11334968358278275
Test set avg_accuracy=87.44% avg_sensitivity=76.08%, avg_specificity=91.29% avg_auc=0.9296
Fold[5] Epoch: 97 [97/100 (97%)] Train loss=0.176681 Test loss=0.301409 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15428626537322998
[5/23] Train loss=0.2372734695672989
[10/23] Train loss=0.15417422354221344
[15/23] Train loss=0.1428101658821106
[20/23] Train loss=0.11640158295631409
Test set avg_accuracy=87.68% avg_sensitivity=76.74%, avg_specificity=91.39% avg_auc=0.9314
Fold[5] Epoch: 98 [98/100 (98%)] Train loss=0.175810 Test loss=0.296664 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15266378223896027
[5/23] Train loss=0.2339700311422348
[10/23] Train loss=0.1619952917098999
[15/23] Train loss=0.13021431863307953
[20/23] Train loss=0.11629864573478699
Test set avg_accuracy=87.76% avg_sensitivity=75.75%, avg_specificity=91.82% avg_auc=0.9310
Fold[5] Epoch: 99 [99/100 (99%)] Train loss=0.172002 Test loss=0.299457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14734525978565216
[5/23] Train loss=0.23677441477775574
[10/23] Train loss=0.1517927050590515
[15/23] Train loss=0.1350700557231903
[20/23] Train loss=0.11827334016561508
Test set avg_accuracy=87.49% avg_sensitivity=77.11%, avg_specificity=91.01% avg_auc=0.9301
Fold[5] Epoch: 100 [100/100 (100%)] Train loss=0.170450 Test loss=0.303789 Current lr=[3.9999999999999996e-05]

Fold[5] Best Result: acc=88.4458398744113 sen=79.96688741721854, spe=91.31531026754448, auc=0.9442270514819725!
[0/23] Train loss=0.7009167075157166
[5/23] Train loss=0.6964386105537415
[10/23] Train loss=0.5498353838920593
[15/23] Train loss=0.5519000291824341
[20/23] Train loss=0.5139151811599731
Test set avg_accuracy=76.88% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6778
Best model saved!! Metric=-81.33942789259443!!
Fold[6] Epoch: 1 [1/100 (1%)] Train loss=0.577017 Test loss=0.567392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5197944641113281
[5/23] Train loss=0.5411534905433655
[10/23] Train loss=0.49377360939979553
[15/23] Train loss=0.4319697618484497
[20/23] Train loss=0.37982675433158875
Test set avg_accuracy=79.08% avg_sensitivity=25.78%, avg_specificity=95.12% avg_auc=0.8436
Best model saved!! Metric=-41.664992555467684!!
Fold[6] Epoch: 2 [2/100 (2%)] Train loss=0.471562 Test loss=0.465427 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4028949439525604
[5/23] Train loss=0.4453628361225128
[10/23] Train loss=0.42847737669944763
[15/23] Train loss=0.3767533302307129
[20/23] Train loss=0.35796600580215454
Test set avg_accuracy=82.63% avg_sensitivity=50.46%, avg_specificity=92.30% avg_auc=0.8818
Best model saved!! Metric=-12.432601351042981!!
Fold[6] Epoch: 3 [3/100 (3%)] Train loss=0.407044 Test loss=0.385609 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3543175160884857
[5/23] Train loss=0.43436750769615173
[10/23] Train loss=0.39430925250053406
[15/23] Train loss=0.3415602743625641
[20/23] Train loss=0.32966315746307373
Test set avg_accuracy=84.54% avg_sensitivity=58.99%, avg_specificity=92.22% avg_auc=0.8997
Best model saved!! Metric=-0.2826883674638401!!
Fold[6] Epoch: 4 [4/100 (4%)] Train loss=0.383795 Test loss=0.340717 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35054731369018555
[5/23] Train loss=0.41502317786216736
[10/23] Train loss=0.3805573284626007
[15/23] Train loss=0.3261660635471344
[20/23] Train loss=0.31413301825523376
Test set avg_accuracy=85.77% avg_sensitivity=57.25%, avg_specificity=94.35% avg_auc=0.9120
Best model saved!! Metric=2.5741943049519778!!
Fold[6] Epoch: 5 [5/100 (5%)] Train loss=0.364497 Test loss=0.334617 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3296976387500763
[5/23] Train loss=0.39172759652137756
[10/23] Train loss=0.38132011890411377
[15/23] Train loss=0.3056219220161438
[20/23] Train loss=0.2842733561992645
Test set avg_accuracy=87.30% avg_sensitivity=58.26%, avg_specificity=96.03% avg_auc=0.9253
Best model saved!! Metric=8.124181496779546!!
Fold[6] Epoch: 6 [6/100 (6%)] Train loss=0.349926 Test loss=0.315118 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3164424002170563
[5/23] Train loss=0.3954220116138458
[10/23] Train loss=0.3613937497138977
[15/23] Train loss=0.28472408652305603
[20/23] Train loss=0.2751932144165039
Test set avg_accuracy=87.81% avg_sensitivity=59.58%, avg_specificity=96.30% avg_auc=0.9304
Best model saved!! Metric=10.720694104017271!!
Fold[6] Epoch: 7 [7/100 (7%)] Train loss=0.340526 Test loss=0.308436 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3017370402812958
[5/23] Train loss=0.38742610812187195
[10/23] Train loss=0.36610352993011475
[15/23] Train loss=0.27302202582359314
[20/23] Train loss=0.24983376264572144
Test set avg_accuracy=87.47% avg_sensitivity=57.21%, avg_specificity=96.57% avg_auc=0.9292
Fold[6] Epoch: 8 [8/100 (8%)] Train loss=0.328844 Test loss=0.324258 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29077550768852234
[5/23] Train loss=0.39233285188674927
[10/23] Train loss=0.36445358395576477
[15/23] Train loss=0.2666648030281067
[20/23] Train loss=0.2387053221464157
Test set avg_accuracy=87.85% avg_sensitivity=58.71%, avg_specificity=96.61% avg_auc=0.9335
Fold[6] Epoch: 9 [9/100 (9%)] Train loss=0.322391 Test loss=0.313923 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2756032645702362
[5/23] Train loss=0.3952559530735016
[10/23] Train loss=0.35213571786880493
[15/23] Train loss=0.2619747221469879
[20/23] Train loss=0.23284544050693512
Test set avg_accuracy=88.35% avg_sensitivity=61.72%, avg_specificity=96.36% avg_auc=0.9383
Best model saved!! Metric=14.269649978807813!!
Fold[6] Epoch: 10 [10/100 (10%)] Train loss=0.315943 Test loss=0.299727 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27181366086006165
[5/23] Train loss=0.39030295610427856
[10/23] Train loss=0.32532480359077454
[15/23] Train loss=0.24980658292770386
[20/23] Train loss=0.22498469054698944
Test set avg_accuracy=89.26% avg_sensitivity=68.98%, avg_specificity=95.36% avg_auc=0.9439
Best model saved!! Metric=21.99271546258982!!
Fold[6] Epoch: 11 [11/100 (11%)] Train loss=0.310548 Test loss=0.267496 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25653576850891113
[5/23] Train loss=0.38498303294181824
[10/23] Train loss=0.3297038674354553
[15/23] Train loss=0.23529420793056488
[20/23] Train loss=0.22838591039180756
Test set avg_accuracy=89.48% avg_sensitivity=74.36%, avg_specificity=94.03% avg_auc=0.9460
Best model saved!! Metric=26.478956681056474!!
Fold[6] Epoch: 12 [12/100 (12%)] Train loss=0.303610 Test loss=0.254444 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2530274987220764
[5/23] Train loss=0.35835692286491394
[10/23] Train loss=0.31146106123924255
[15/23] Train loss=0.23215655982494354
[20/23] Train loss=0.22083933651447296
Test set avg_accuracy=89.31% avg_sensitivity=75.59%, avg_specificity=93.44% avg_auc=0.9471
Best model saved!! Metric=27.063590450005027!!
Fold[6] Epoch: 13 [13/100 (13%)] Train loss=0.295616 Test loss=0.251181 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2503775656223297
[5/23] Train loss=0.3533748984336853
[10/23] Train loss=0.3093317151069641
[15/23] Train loss=0.22882451117038727
[20/23] Train loss=0.20755957067012787
Test set avg_accuracy=89.36% avg_sensitivity=72.45%, avg_specificity=94.44% avg_auc=0.9468
Fold[6] Epoch: 14 [14/100 (14%)] Train loss=0.289939 Test loss=0.255472 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2517569065093994
[5/23] Train loss=0.35530462861061096
[10/23] Train loss=0.3028320372104645
[15/23] Train loss=0.23180416226387024
[20/23] Train loss=0.20664921402931213
Test set avg_accuracy=89.34% avg_sensitivity=70.80%, avg_specificity=94.91% avg_auc=0.9469
Fold[6] Epoch: 15 [15/100 (15%)] Train loss=0.288708 Test loss=0.257445 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2474609762430191
[5/23] Train loss=0.3427240550518036
[10/23] Train loss=0.30497172474861145
[15/23] Train loss=0.22789357602596283
[20/23] Train loss=0.212523952126503
Test set avg_accuracy=89.69% avg_sensitivity=73.08%, avg_specificity=94.69% avg_auc=0.9490
Fold[6] Epoch: 16 [16/100 (16%)] Train loss=0.286321 Test loss=0.250012 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.235929474234581
[5/23] Train loss=0.35555168986320496
[10/23] Train loss=0.2916674017906189
[15/23] Train loss=0.21913957595825195
[20/23] Train loss=0.20549772679805756
Test set avg_accuracy=89.69% avg_sensitivity=74.27%, avg_specificity=94.33% avg_auc=0.9496
Best model saved!! Metric=27.257534781381796!!
Fold[6] Epoch: 17 [17/100 (17%)] Train loss=0.283659 Test loss=0.245007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24406585097312927
[5/23] Train loss=0.361934095621109
[10/23] Train loss=0.2905353009700775
[15/23] Train loss=0.21369263529777527
[20/23] Train loss=0.20312952995300293
Test set avg_accuracy=89.84% avg_sensitivity=75.36%, avg_specificity=94.20% avg_auc=0.9501
Best model saved!! Metric=28.411962275449493!!
Fold[6] Epoch: 18 [18/100 (18%)] Train loss=0.277789 Test loss=0.244250 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22979235649108887
[5/23] Train loss=0.35186532139778137
[10/23] Train loss=0.2918226718902588
[15/23] Train loss=0.21742399036884308
[20/23] Train loss=0.19588272273540497
Test set avg_accuracy=89.85% avg_sensitivity=75.73%, avg_specificity=94.10% avg_auc=0.9505
Best model saved!! Metric=28.734796092149388!!
Fold[6] Epoch: 19 [19/100 (19%)] Train loss=0.276517 Test loss=0.242202 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2417798638343811
[5/23] Train loss=0.3381780683994293
[10/23] Train loss=0.2913586497306824
[15/23] Train loss=0.22218848764896393
[20/23] Train loss=0.1970130354166031
Test set avg_accuracy=89.87% avg_sensitivity=75.50%, avg_specificity=94.20% avg_auc=0.9504
Fold[6] Epoch: 20 [20/100 (20%)] Train loss=0.274876 Test loss=0.241761 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22703199088573456
[5/23] Train loss=0.3487314283847809
[10/23] Train loss=0.295291543006897
[15/23] Train loss=0.21229587495326996
[20/23] Train loss=0.19308848679065704
Test set avg_accuracy=89.97% avg_sensitivity=76.05%, avg_specificity=94.15% avg_auc=0.9514
Best model saved!! Metric=29.3132093864319!!
Fold[6] Epoch: 21 [21/100 (21%)] Train loss=0.270638 Test loss=0.240018 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2253461480140686
[5/23] Train loss=0.3474560081958771
[10/23] Train loss=0.2892201542854309
[15/23] Train loss=0.2089403122663498
[20/23] Train loss=0.1978333592414856
Test set avg_accuracy=89.97% avg_sensitivity=76.82%, avg_specificity=93.92% avg_auc=0.9518
Best model saved!! Metric=29.892910695252734!!
Fold[6] Epoch: 22 [22/100 (22%)] Train loss=0.272900 Test loss=0.236080 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22521165013313293
[5/23] Train loss=0.34881076216697693
[10/23] Train loss=0.2804904580116272
[15/23] Train loss=0.21681739389896393
[20/23] Train loss=0.18607842922210693
Test set avg_accuracy=89.97% avg_sensitivity=76.23%, avg_specificity=94.10% avg_auc=0.9520
Fold[6] Epoch: 23 [23/100 (23%)] Train loss=0.269709 Test loss=0.236200 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22796018421649933
[5/23] Train loss=0.33480358123779297
[10/23] Train loss=0.28280380368232727
[15/23] Train loss=0.21376575529575348
[20/23] Train loss=0.18697760999202728
Test set avg_accuracy=89.97% avg_sensitivity=76.23%, avg_specificity=94.10% avg_auc=0.9520
Fold[6] Epoch: 24 [24/100 (24%)] Train loss=0.266514 Test loss=0.236470 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21606847643852234
[5/23] Train loss=0.33592915534973145
[10/23] Train loss=0.2842830717563629
[15/23] Train loss=0.21181181073188782
[20/23] Train loss=0.18802767992019653
Test set avg_accuracy=89.94% avg_sensitivity=76.09%, avg_specificity=94.10% avg_auc=0.9519
Fold[6] Epoch: 25 [25/100 (25%)] Train loss=0.262715 Test loss=0.236743 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21303842961788177
[5/23] Train loss=0.33428725600242615
[10/23] Train loss=0.27992939949035645
[15/23] Train loss=0.20138539373874664
[20/23] Train loss=0.18784141540527344
Test set avg_accuracy=89.92% avg_sensitivity=74.95%, avg_specificity=94.42% avg_auc=0.9519
Fold[6] Epoch: 26 [26/100 (26%)] Train loss=0.262224 Test loss=0.235642 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2200312316417694
[5/23] Train loss=0.34613436460494995
[10/23] Train loss=0.26307258009910583
[15/23] Train loss=0.21226105093955994
[20/23] Train loss=0.1873750239610672
Test set avg_accuracy=89.93% avg_sensitivity=75.50%, avg_specificity=94.26% avg_auc=0.9520
Fold[6] Epoch: 27 [27/100 (27%)] Train loss=0.261174 Test loss=0.234671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21890190243721008
[5/23] Train loss=0.3314257860183716
[10/23] Train loss=0.2709237039089203
[15/23] Train loss=0.2094779759645462
[20/23] Train loss=0.17833177745342255
Test set avg_accuracy=89.99% avg_sensitivity=74.00%, avg_specificity=94.80% avg_auc=0.9520
Fold[6] Epoch: 28 [28/100 (28%)] Train loss=0.259751 Test loss=0.236593 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2145647257566452
[5/23] Train loss=0.34181445837020874
[10/23] Train loss=0.27259361743927
[15/23] Train loss=0.2084866166114807
[20/23] Train loss=0.17777761816978455
Test set avg_accuracy=90.06% avg_sensitivity=75.59%, avg_specificity=94.42% avg_auc=0.9530
Fold[6] Epoch: 29 [29/100 (29%)] Train loss=0.258870 Test loss=0.232379 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2069171518087387
[5/23] Train loss=0.3228851556777954
[10/23] Train loss=0.2664077579975128
[15/23] Train loss=0.19542309641838074
[20/23] Train loss=0.17567090690135956
Test set avg_accuracy=90.07% avg_sensitivity=76.23%, avg_specificity=94.24% avg_auc=0.9524
Fold[6] Epoch: 30 [30/100 (30%)] Train loss=0.256090 Test loss=0.233647 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20559820532798767
[5/23] Train loss=0.32691922783851624
[10/23] Train loss=0.28014516830444336
[15/23] Train loss=0.20049336552619934
[20/23] Train loss=0.17187820374965668
Test set avg_accuracy=90.09% avg_sensitivity=75.91%, avg_specificity=94.36% avg_auc=0.9523
Fold[6] Epoch: 31 [31/100 (31%)] Train loss=0.253452 Test loss=0.234031 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2147383838891983
[5/23] Train loss=0.3298459053039551
[10/23] Train loss=0.26644134521484375
[15/23] Train loss=0.199139803647995
[20/23] Train loss=0.18222974240779877
Test set avg_accuracy=90.16% avg_sensitivity=75.82%, avg_specificity=94.47% avg_auc=0.9522
Fold[6] Epoch: 32 [32/100 (32%)] Train loss=0.253572 Test loss=0.233596 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20211189985275269
[5/23] Train loss=0.32391828298568726
[10/23] Train loss=0.2592131197452545
[15/23] Train loss=0.19489359855651855
[20/23] Train loss=0.17800763249397278
Test set avg_accuracy=90.36% avg_sensitivity=76.37%, avg_specificity=94.57% avg_auc=0.9533
Best model saved!! Metric=30.62853924835472!!
Fold[6] Epoch: 33 [33/100 (33%)] Train loss=0.250402 Test loss=0.231671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20584921538829803
[5/23] Train loss=0.3188798427581787
[10/23] Train loss=0.26630228757858276
[15/23] Train loss=0.20221973955631256
[20/23] Train loss=0.16434819996356964
Test set avg_accuracy=90.17% avg_sensitivity=75.64%, avg_specificity=94.54% avg_auc=0.9517
Fold[6] Epoch: 34 [34/100 (34%)] Train loss=0.247913 Test loss=0.235958 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21116891503334045
[5/23] Train loss=0.3188694417476654
[10/23] Train loss=0.2628578245639801
[15/23] Train loss=0.19351355731487274
[20/23] Train loss=0.1768503189086914
Test set avg_accuracy=90.01% avg_sensitivity=74.45%, avg_specificity=94.69% avg_auc=0.9510
Fold[6] Epoch: 35 [35/100 (35%)] Train loss=0.249507 Test loss=0.237091 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2044229358434677
[5/23] Train loss=0.3254007399082184
[10/23] Train loss=0.26660528779029846
[15/23] Train loss=0.19237908720970154
[20/23] Train loss=0.174518421292305
Test set avg_accuracy=90.16% avg_sensitivity=75.59%, avg_specificity=94.54% avg_auc=0.9517
Fold[6] Epoch: 36 [36/100 (36%)] Train loss=0.246494 Test loss=0.235507 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2071208655834198
[5/23] Train loss=0.32959648966789246
[10/23] Train loss=0.25764045119285583
[15/23] Train loss=0.19818614423274994
[20/23] Train loss=0.17687708139419556
Test set avg_accuracy=90.22% avg_sensitivity=75.50%, avg_specificity=94.65% avg_auc=0.9518
Fold[6] Epoch: 37 [37/100 (37%)] Train loss=0.247544 Test loss=0.234874 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20850138366222382
[5/23] Train loss=0.31493526697158813
[10/23] Train loss=0.2549807131290436
[15/23] Train loss=0.19458366930484772
[20/23] Train loss=0.17861692607402802
Test set avg_accuracy=90.14% avg_sensitivity=77.42%, avg_specificity=93.96% avg_auc=0.9514
Best model saved!! Metric=30.653181584095783!!
Fold[6] Epoch: 38 [38/100 (38%)] Train loss=0.246523 Test loss=0.235108 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2067725509405136
[5/23] Train loss=0.3110182583332062
[10/23] Train loss=0.25079146027565
[15/23] Train loss=0.1896388679742813
[20/23] Train loss=0.1698782742023468
Test set avg_accuracy=90.27% avg_sensitivity=77.55%, avg_specificity=94.10% avg_auc=0.9513
Best model saved!! Metric=31.054795748094968!!
Fold[6] Epoch: 39 [39/100 (39%)] Train loss=0.244328 Test loss=0.236237 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20284853875637054
[5/23] Train loss=0.30842676758766174
[10/23] Train loss=0.26468560099601746
[15/23] Train loss=0.18859127163887024
[20/23] Train loss=0.16609086096286774
Test set avg_accuracy=90.21% avg_sensitivity=76.46%, avg_specificity=94.35% avg_auc=0.9515
Fold[6] Epoch: 40 [40/100 (40%)] Train loss=0.241357 Test loss=0.235171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19786082208156586
[5/23] Train loss=0.3068894147872925
[10/23] Train loss=0.25772273540496826
[15/23] Train loss=0.18147319555282593
[20/23] Train loss=0.16379746794700623
Test set avg_accuracy=90.18% avg_sensitivity=75.23%, avg_specificity=94.68% avg_auc=0.9514
Fold[6] Epoch: 41 [41/100 (41%)] Train loss=0.240591 Test loss=0.235124 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19501499831676483
[5/23] Train loss=0.3050205111503601
[10/23] Train loss=0.26892441511154175
[15/23] Train loss=0.18947291374206543
[20/23] Train loss=0.16438503563404083
Test set avg_accuracy=90.20% avg_sensitivity=75.78%, avg_specificity=94.54% avg_auc=0.9513
Fold[6] Epoch: 42 [42/100 (42%)] Train loss=0.242112 Test loss=0.235215 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19671131670475006
[5/23] Train loss=0.33126339316368103
[10/23] Train loss=0.2551570534706116
[15/23] Train loss=0.18937040865421295
[20/23] Train loss=0.17110411822795868
Test set avg_accuracy=90.42% avg_sensitivity=77.65%, avg_specificity=94.26% avg_auc=0.9523
Best model saved!! Metric=31.566624820199188!!
Fold[6] Epoch: 43 [43/100 (43%)] Train loss=0.240665 Test loss=0.232332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1959884613752365
[5/23] Train loss=0.31164708733558655
[10/23] Train loss=0.24513235688209534
[15/23] Train loss=0.18652038276195526
[20/23] Train loss=0.16897928714752197
Test set avg_accuracy=90.23% avg_sensitivity=77.46%, avg_specificity=94.07% avg_auc=0.9513
Fold[6] Epoch: 44 [44/100 (44%)] Train loss=0.237845 Test loss=0.235051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19591914117336273
[5/23] Train loss=0.299566388130188
[10/23] Train loss=0.2547700107097626
[15/23] Train loss=0.17911642789840698
[20/23] Train loss=0.1689135879278183
Test set avg_accuracy=90.25% avg_sensitivity=76.05%, avg_specificity=94.53% avg_auc=0.9522
Fold[6] Epoch: 45 [45/100 (45%)] Train loss=0.237571 Test loss=0.232329 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19218382239341736
[5/23] Train loss=0.3072029650211334
[10/23] Train loss=0.2538236379623413
[15/23] Train loss=0.18816819787025452
[20/23] Train loss=0.15753784775733948
Test set avg_accuracy=90.38% avg_sensitivity=76.73%, avg_specificity=94.48% avg_auc=0.9517
Fold[6] Epoch: 46 [46/100 (46%)] Train loss=0.236052 Test loss=0.234167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19082306325435638
[5/23] Train loss=0.29441753029823303
[10/23] Train loss=0.25052186846733093
[15/23] Train loss=0.1837204396724701
[20/23] Train loss=0.16197961568832397
Test set avg_accuracy=90.30% avg_sensitivity=76.82%, avg_specificity=94.35% avg_auc=0.9507
Fold[6] Epoch: 47 [47/100 (47%)] Train loss=0.235426 Test loss=0.236055 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19392549991607666
[5/23] Train loss=0.31032031774520874
[10/23] Train loss=0.24866251647472382
[15/23] Train loss=0.18939940631389618
[20/23] Train loss=0.16522084176540375
Test set avg_accuracy=90.45% avg_sensitivity=77.92%, avg_specificity=94.22% avg_auc=0.9513
Best model saved!! Metric=31.730637264273582!!
Fold[6] Epoch: 48 [48/100 (48%)] Train loss=0.230442 Test loss=0.236033 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1921808272600174
[5/23] Train loss=0.3029056489467621
[10/23] Train loss=0.25513967871665955
[15/23] Train loss=0.1843135952949524
[20/23] Train loss=0.16125565767288208
Test set avg_accuracy=90.24% avg_sensitivity=76.28%, avg_specificity=94.44% avg_auc=0.9505
Fold[6] Epoch: 49 [49/100 (49%)] Train loss=0.230667 Test loss=0.237269 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1961793750524521
[5/23] Train loss=0.3081497550010681
[10/23] Train loss=0.25399887561798096
[15/23] Train loss=0.18360501527786255
[20/23] Train loss=0.1646253615617752
Test set avg_accuracy=90.33% avg_sensitivity=77.37%, avg_specificity=94.22% avg_auc=0.9516
Fold[6] Epoch: 50 [50/100 (50%)] Train loss=0.231154 Test loss=0.234808 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18941953778266907
[5/23] Train loss=0.3003915846347809
[10/23] Train loss=0.25023818016052246
[15/23] Train loss=0.1742650866508484
[20/23] Train loss=0.15718665719032288
Test set avg_accuracy=90.56% avg_sensitivity=77.46%, avg_specificity=94.50% avg_auc=0.9522
Best model saved!! Metric=31.74354205213525!!
Fold[6] Epoch: 51 [51/100 (51%)] Train loss=0.229431 Test loss=0.232846 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19323386251926422
[5/23] Train loss=0.3009352684020996
[10/23] Train loss=0.25169897079467773
[15/23] Train loss=0.18161597847938538
[20/23] Train loss=0.16173155605793
Test set avg_accuracy=90.42% avg_sensitivity=76.78%, avg_specificity=94.53% avg_auc=0.9511
Fold[6] Epoch: 52 [52/100 (52%)] Train loss=0.229164 Test loss=0.235339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18719486892223358
[5/23] Train loss=0.2892303168773651
[10/23] Train loss=0.24388054013252258
[15/23] Train loss=0.18245208263397217
[20/23] Train loss=0.15648308396339417
Test set avg_accuracy=90.47% avg_sensitivity=77.92%, avg_specificity=94.25% avg_auc=0.9519
Best model saved!! Metric=31.83252780584362!!
Fold[6] Epoch: 53 [53/100 (53%)] Train loss=0.227504 Test loss=0.234262 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1894715577363968
[5/23] Train loss=0.2877715528011322
[10/23] Train loss=0.240136057138443
[15/23] Train loss=0.1803044080734253
[20/23] Train loss=0.15891039371490479
Test set avg_accuracy=90.57% avg_sensitivity=79.38%, avg_specificity=93.94% avg_auc=0.9530
Best model saved!! Metric=33.187178262731315!!
Fold[6] Epoch: 54 [54/100 (54%)] Train loss=0.224346 Test loss=0.232789 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18696458637714386
[5/23] Train loss=0.29547005891799927
[10/23] Train loss=0.24618422985076904
[15/23] Train loss=0.1879185438156128
[20/23] Train loss=0.1607968658208847
Test set avg_accuracy=90.50% avg_sensitivity=78.83%, avg_specificity=94.00% avg_auc=0.9517
Fold[6] Epoch: 55 [55/100 (55%)] Train loss=0.225280 Test loss=0.234863 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18901517987251282
[5/23] Train loss=0.2962965667247772
[10/23] Train loss=0.24614320695400238
[15/23] Train loss=0.1775723099708557
[20/23] Train loss=0.1517336070537567
Test set avg_accuracy=90.61% avg_sensitivity=78.10%, avg_specificity=94.37% avg_auc=0.9523
Fold[6] Epoch: 56 [56/100 (56%)] Train loss=0.223995 Test loss=0.234702 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18456222116947174
[5/23] Train loss=0.2859790027141571
[10/23] Train loss=0.2360374629497528
[15/23] Train loss=0.17527686059474945
[20/23] Train loss=0.15694963932037354
Test set avg_accuracy=90.55% avg_sensitivity=77.83%, avg_specificity=94.37% avg_auc=0.9512
Fold[6] Epoch: 57 [57/100 (57%)] Train loss=0.223146 Test loss=0.236183 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18136247992515564
[5/23] Train loss=0.2866421341896057
[10/23] Train loss=0.23844300210475922
[15/23] Train loss=0.17477178573608398
[20/23] Train loss=0.15526336431503296
Test set avg_accuracy=90.58% avg_sensitivity=77.97%, avg_specificity=94.37% avg_auc=0.9517
Fold[6] Epoch: 58 [58/100 (58%)] Train loss=0.219980 Test loss=0.235054 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1808471977710724
[5/23] Train loss=0.2908726632595062
[10/23] Train loss=0.2362334430217743
[15/23] Train loss=0.17749878764152527
[20/23] Train loss=0.1549508422613144
Test set avg_accuracy=90.55% avg_sensitivity=78.38%, avg_specificity=94.21% avg_auc=0.9513
Fold[6] Epoch: 59 [59/100 (59%)] Train loss=0.219646 Test loss=0.236729 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19164739549160004
[5/23] Train loss=0.2829541862010956
[10/23] Train loss=0.24682122468948364
[15/23] Train loss=0.17313867807388306
[20/23] Train loss=0.14539799094200134
Test set avg_accuracy=90.52% avg_sensitivity=78.42%, avg_specificity=94.15% avg_auc=0.9521
Fold[6] Epoch: 60 [60/100 (60%)] Train loss=0.220362 Test loss=0.236030 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18323375284671783
[5/23] Train loss=0.2729818522930145
[10/23] Train loss=0.24099691212177277
[15/23] Train loss=0.17026422917842865
[20/23] Train loss=0.15313658118247986
Test set avg_accuracy=90.54% avg_sensitivity=77.97%, avg_specificity=94.32% avg_auc=0.9515
Fold[6] Epoch: 61 [61/100 (61%)] Train loss=0.217620 Test loss=0.236984 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17618858814239502
[5/23] Train loss=0.28966787457466125
[10/23] Train loss=0.22503206133842468
[15/23] Train loss=0.16192497313022614
[20/23] Train loss=0.15555110573768616
Test set avg_accuracy=90.76% avg_sensitivity=78.19%, avg_specificity=94.54% avg_auc=0.9523
Fold[6] Epoch: 62 [62/100 (62%)] Train loss=0.216534 Test loss=0.235141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19059425592422485
[5/23] Train loss=0.2670084536075592
[10/23] Train loss=0.22962939739227295
[15/23] Train loss=0.17346148192882538
[20/23] Train loss=0.15023192763328552
Test set avg_accuracy=90.72% avg_sensitivity=78.97%, avg_specificity=94.25% avg_auc=0.9520
Fold[6] Epoch: 63 [63/100 (63%)] Train loss=0.215599 Test loss=0.236573 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18735679984092712
[5/23] Train loss=0.2718771994113922
[10/23] Train loss=0.2416328489780426
[15/23] Train loss=0.17020495235919952
[20/23] Train loss=0.14925554394721985
Test set avg_accuracy=90.58% avg_sensitivity=78.15%, avg_specificity=94.32% avg_auc=0.9521
Fold[6] Epoch: 64 [64/100 (64%)] Train loss=0.217053 Test loss=0.235577 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18417640030384064
[5/23] Train loss=0.2757313549518585
[10/23] Train loss=0.23406925797462463
[15/23] Train loss=0.17303143441677094
[20/23] Train loss=0.14880973100662231
Test set avg_accuracy=90.80% avg_sensitivity=79.33%, avg_specificity=94.25% avg_auc=0.9525
Best model saved!! Metric=33.64145135870373!!
Fold[6] Epoch: 65 [65/100 (65%)] Train loss=0.213750 Test loss=0.235121 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18801282346248627
[5/23] Train loss=0.26693040132522583
[10/23] Train loss=0.22873900830745697
[15/23] Train loss=0.16621486842632294
[20/23] Train loss=0.1483551561832428
Test set avg_accuracy=90.70% avg_sensitivity=79.20%, avg_specificity=94.15% avg_auc=0.9521
Fold[6] Epoch: 66 [66/100 (66%)] Train loss=0.211319 Test loss=0.235902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17541563510894775
[5/23] Train loss=0.266429603099823
[10/23] Train loss=0.2352166622877121
[15/23] Train loss=0.1694040298461914
[20/23] Train loss=0.1421944946050644
Test set avg_accuracy=90.79% avg_sensitivity=78.51%, avg_specificity=94.48% avg_auc=0.9512
Fold[6] Epoch: 67 [67/100 (67%)] Train loss=0.211869 Test loss=0.238168 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1790827512741089
[5/23] Train loss=0.2736700475215912
[10/23] Train loss=0.23745191097259521
[15/23] Train loss=0.15862886607646942
[20/23] Train loss=0.1512531042098999
Test set avg_accuracy=90.63% avg_sensitivity=78.33%, avg_specificity=94.33% avg_auc=0.9515
Fold[6] Epoch: 68 [68/100 (68%)] Train loss=0.209974 Test loss=0.237908 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1782415509223938
[5/23] Train loss=0.2620851993560791
[10/23] Train loss=0.22954605519771576
[15/23] Train loss=0.1549961119890213
[20/23] Train loss=0.14219222962856293
Test set avg_accuracy=90.68% avg_sensitivity=79.06%, avg_specificity=94.17% avg_auc=0.9516
Fold[6] Epoch: 69 [69/100 (69%)] Train loss=0.206038 Test loss=0.238501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17721837759017944
[5/23] Train loss=0.272032231092453
[10/23] Train loss=0.21200203895568848
[15/23] Train loss=0.15939243137836456
[20/23] Train loss=0.1403224915266037
Test set avg_accuracy=90.60% avg_sensitivity=79.24%, avg_specificity=94.02% avg_auc=0.9505
Fold[6] Epoch: 70 [70/100 (70%)] Train loss=0.206942 Test loss=0.241213 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17150190472602844
[5/23] Train loss=0.26373544335365295
[10/23] Train loss=0.21897076070308685
[15/23] Train loss=0.15727610886096954
[20/23] Train loss=0.1446356177330017
Test set avg_accuracy=90.62% avg_sensitivity=79.01%, avg_specificity=94.11% avg_auc=0.9518
Fold[6] Epoch: 71 [71/100 (71%)] Train loss=0.204646 Test loss=0.239407 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17894133925437927
[5/23] Train loss=0.2696971893310547
[10/23] Train loss=0.2320396453142166
[15/23] Train loss=0.16035185754299164
[20/23] Train loss=0.14361967146396637
Test set avg_accuracy=90.74% avg_sensitivity=78.56%, avg_specificity=94.40% avg_auc=0.9515
Fold[6] Epoch: 72 [72/100 (72%)] Train loss=0.206135 Test loss=0.239877 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1758081316947937
[5/23] Train loss=0.2483833134174347
[10/23] Train loss=0.22823651134967804
[15/23] Train loss=0.15353380143642426
[20/23] Train loss=0.1342640519142151
Test set avg_accuracy=90.63% avg_sensitivity=78.10%, avg_specificity=94.40% avg_auc=0.9509
Fold[6] Epoch: 73 [73/100 (73%)] Train loss=0.200217 Test loss=0.241529 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17772364616394043
[5/23] Train loss=0.25802674889564514
[10/23] Train loss=0.21832852065563202
[15/23] Train loss=0.15958133339881897
[20/23] Train loss=0.13459967076778412
Test set avg_accuracy=90.59% avg_sensitivity=78.70%, avg_specificity=94.17% avg_auc=0.9516
Fold[6] Epoch: 74 [74/100 (74%)] Train loss=0.200900 Test loss=0.240362 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1790999174118042
[5/23] Train loss=0.2661406099796295
[10/23] Train loss=0.20718887448310852
[15/23] Train loss=0.16579122841358185
[20/23] Train loss=0.13905026018619537
Test set avg_accuracy=90.82% avg_sensitivity=77.69%, avg_specificity=94.77% avg_auc=0.9509
Fold[6] Epoch: 75 [75/100 (75%)] Train loss=0.200602 Test loss=0.241666 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17046257853507996
[5/23] Train loss=0.25842148065567017
[10/23] Train loss=0.22690889239311218
[15/23] Train loss=0.15320518612861633
[20/23] Train loss=0.1417199820280075
Test set avg_accuracy=90.51% avg_sensitivity=78.97%, avg_specificity=93.98% avg_auc=0.9499
Fold[6] Epoch: 76 [76/100 (76%)] Train loss=0.198487 Test loss=0.245357 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1757054328918457
[5/23] Train loss=0.2467966079711914
[10/23] Train loss=0.2129872888326645
[15/23] Train loss=0.1511249542236328
[20/23] Train loss=0.13368776440620422
Test set avg_accuracy=90.60% avg_sensitivity=79.06%, avg_specificity=94.07% avg_auc=0.9506
Fold[6] Epoch: 77 [77/100 (77%)] Train loss=0.197024 Test loss=0.244742 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17090614140033722
[5/23] Train loss=0.24990828335285187
[10/23] Train loss=0.21579352021217346
[15/23] Train loss=0.157616525888443
[20/23] Train loss=0.1257912516593933
Test set avg_accuracy=90.69% avg_sensitivity=79.24%, avg_specificity=94.13% avg_auc=0.9502
Fold[6] Epoch: 78 [78/100 (78%)] Train loss=0.195560 Test loss=0.245576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1671094447374344
[5/23] Train loss=0.25276103615760803
[10/23] Train loss=0.20534516870975494
[15/23] Train loss=0.1477857530117035
[20/23] Train loss=0.1317489743232727
Test set avg_accuracy=90.58% avg_sensitivity=78.88%, avg_specificity=94.10% avg_auc=0.9506
Fold[6] Epoch: 79 [79/100 (79%)] Train loss=0.193463 Test loss=0.244457 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16917480528354645
[5/23] Train loss=0.26115891337394714
[10/23] Train loss=0.21697315573692322
[15/23] Train loss=0.1653553992509842
[20/23] Train loss=0.13745099306106567
Test set avg_accuracy=90.49% avg_sensitivity=77.24%, avg_specificity=94.47% avg_auc=0.9513
Fold[6] Epoch: 80 [80/100 (80%)] Train loss=0.194063 Test loss=0.242956 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1750621795654297
[5/23] Train loss=0.2500934600830078
[10/23] Train loss=0.20919649302959442
[15/23] Train loss=0.15723922848701477
[20/23] Train loss=0.12765254080295563
Test set avg_accuracy=90.63% avg_sensitivity=77.24%, avg_specificity=94.66% avg_auc=0.9514
Fold[6] Epoch: 81 [81/100 (81%)] Train loss=0.191556 Test loss=0.243429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16764651238918304
[5/23] Train loss=0.2441573590040207
[10/23] Train loss=0.21938617527484894
[15/23] Train loss=0.15638940036296844
[20/23] Train loss=0.14075967669487
Test set avg_accuracy=90.60% avg_sensitivity=77.65%, avg_specificity=94.50% avg_auc=0.9518
Fold[6] Epoch: 82 [82/100 (82%)] Train loss=0.190288 Test loss=0.241464 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16733777523040771
[5/23] Train loss=0.2455504834651947
[10/23] Train loss=0.2157069593667984
[15/23] Train loss=0.14408208429813385
[20/23] Train loss=0.13371120393276215
Test set avg_accuracy=90.54% avg_sensitivity=77.83%, avg_specificity=94.36% avg_auc=0.9512
Fold[6] Epoch: 83 [83/100 (83%)] Train loss=0.191734 Test loss=0.243908 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16173608601093292
[5/23] Train loss=0.2546843886375427
[10/23] Train loss=0.19779232144355774
[15/23] Train loss=0.15010930597782135
[20/23] Train loss=0.12939119338989258
Test set avg_accuracy=90.58% avg_sensitivity=79.33%, avg_specificity=93.96% avg_auc=0.9514
Fold[6] Epoch: 84 [84/100 (84%)] Train loss=0.187649 Test loss=0.245845 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17036473751068115
[5/23] Train loss=0.24803785979747772
[10/23] Train loss=0.2053690403699875
[15/23] Train loss=0.1496572345495224
[20/23] Train loss=0.13165026903152466
Test set avg_accuracy=90.44% avg_sensitivity=78.51%, avg_specificity=94.03% avg_auc=0.9515
Fold[6] Epoch: 85 [85/100 (85%)] Train loss=0.188291 Test loss=0.246411 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1602325588464737
[5/23] Train loss=0.24023565649986267
[10/23] Train loss=0.20590074360370636
[15/23] Train loss=0.14429694414138794
[20/23] Train loss=0.12274787575006485
Test set avg_accuracy=90.46% avg_sensitivity=78.15%, avg_specificity=94.17% avg_auc=0.9507
Fold[6] Epoch: 86 [86/100 (86%)] Train loss=0.185012 Test loss=0.247515 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15571275353431702
[5/23] Train loss=0.2347411960363388
[10/23] Train loss=0.20168843865394592
[15/23] Train loss=0.14427262544631958
[20/23] Train loss=0.13217107951641083
Test set avg_accuracy=90.22% avg_sensitivity=78.10%, avg_specificity=93.87% avg_auc=0.9495
Fold[6] Epoch: 87 [87/100 (87%)] Train loss=0.185970 Test loss=0.249921 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15981733798980713
[5/23] Train loss=0.22808577120304108
[10/23] Train loss=0.20815792679786682
[15/23] Train loss=0.14253394305706024
[20/23] Train loss=0.13154296576976776
Test set avg_accuracy=90.43% avg_sensitivity=79.06%, avg_specificity=93.85% avg_auc=0.9506
Fold[6] Epoch: 88 [88/100 (88%)] Train loss=0.183778 Test loss=0.250658 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15545469522476196
[5/23] Train loss=0.23385202884674072
[10/23] Train loss=0.2136981189250946
[15/23] Train loss=0.13698217272758484
[20/23] Train loss=0.1242244690656662
Test set avg_accuracy=90.44% avg_sensitivity=79.06%, avg_specificity=93.87% avg_auc=0.9494
Fold[6] Epoch: 89 [89/100 (89%)] Train loss=0.181173 Test loss=0.254654 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16287221014499664
[5/23] Train loss=0.2361713945865631
[10/23] Train loss=0.18899086117744446
[15/23] Train loss=0.15233714878559113
[20/23] Train loss=0.1179468110203743
Test set avg_accuracy=90.32% avg_sensitivity=79.20%, avg_specificity=93.66% avg_auc=0.9489
Fold[6] Epoch: 90 [90/100 (90%)] Train loss=0.181036 Test loss=0.255127 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15664474666118622
[5/23] Train loss=0.22253017127513885
[10/23] Train loss=0.19249823689460754
[15/23] Train loss=0.1332833617925644
[20/23] Train loss=0.1272852122783661
Test set avg_accuracy=90.32% avg_sensitivity=80.57%, avg_specificity=93.25% avg_auc=0.9489
Fold[6] Epoch: 91 [91/100 (91%)] Train loss=0.177557 Test loss=0.259518 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15817144513130188
[5/23] Train loss=0.21870417892932892
[10/23] Train loss=0.1874438226222992
[15/23] Train loss=0.13461095094680786
[20/23] Train loss=0.12254606932401657
Test set avg_accuracy=90.18% avg_sensitivity=79.38%, avg_specificity=93.43% avg_auc=0.9479
Fold[6] Epoch: 92 [92/100 (92%)] Train loss=0.173813 Test loss=0.261772 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16417431831359863
[5/23] Train loss=0.22034461796283722
[10/23] Train loss=0.19098126888275146
[15/23] Train loss=0.1460229605436325
[20/23] Train loss=0.12054789066314697
Test set avg_accuracy=90.24% avg_sensitivity=79.20%, avg_specificity=93.56% avg_auc=0.9484
Fold[6] Epoch: 93 [93/100 (93%)] Train loss=0.176904 Test loss=0.257950 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16891683638095856
[5/23] Train loss=0.21703599393367767
[10/23] Train loss=0.1873464733362198
[15/23] Train loss=0.1325940638780594
[20/23] Train loss=0.11791414767503738
Test set avg_accuracy=90.45% avg_sensitivity=78.60%, avg_specificity=94.02% avg_auc=0.9506
Fold[6] Epoch: 94 [94/100 (94%)] Train loss=0.175591 Test loss=0.252084 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16144244372844696
[5/23] Train loss=0.22627995908260345
[10/23] Train loss=0.18753938376903534
[15/23] Train loss=0.12972795963287354
[20/23] Train loss=0.11223593354225159
Test set avg_accuracy=90.21% avg_sensitivity=78.60%, avg_specificity=93.70% avg_auc=0.9499
Fold[6] Epoch: 95 [95/100 (95%)] Train loss=0.169914 Test loss=0.255052 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1548510193824768
[5/23] Train loss=0.2128366082906723
[10/23] Train loss=0.19436445832252502
[15/23] Train loss=0.1342698186635971
[20/23] Train loss=0.11502391844987869
Test set avg_accuracy=90.02% avg_sensitivity=79.24%, avg_specificity=93.26% avg_auc=0.9474
Fold[6] Epoch: 96 [96/100 (96%)] Train loss=0.168076 Test loss=0.265740 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14772161841392517
[5/23] Train loss=0.22035467624664307
[10/23] Train loss=0.17341533303260803
[15/23] Train loss=0.1314898282289505
[20/23] Train loss=0.1147293969988823
Test set avg_accuracy=89.88% avg_sensitivity=79.20%, avg_specificity=93.10% avg_auc=0.9467
Fold[6] Epoch: 97 [97/100 (97%)] Train loss=0.168057 Test loss=0.267076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.153286412358284
[5/23] Train loss=0.20771664381027222
[10/23] Train loss=0.18091744184494019
[15/23] Train loss=0.134268119931221
[20/23] Train loss=0.12340408563613892
Test set avg_accuracy=89.83% avg_sensitivity=79.33%, avg_specificity=92.99% avg_auc=0.9462
Fold[6] Epoch: 98 [98/100 (98%)] Train loss=0.167279 Test loss=0.267976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14476023614406586
[5/23] Train loss=0.21564418077468872
[10/23] Train loss=0.17362582683563232
[15/23] Train loss=0.1362704634666443
[20/23] Train loss=0.11781375110149384
Test set avg_accuracy=90.06% avg_sensitivity=78.97%, avg_specificity=93.40% avg_auc=0.9480
Fold[6] Epoch: 99 [99/100 (99%)] Train loss=0.164876 Test loss=0.265837 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.14280793070793152
[5/23] Train loss=0.20785808563232422
[10/23] Train loss=0.18261203169822693
[15/23] Train loss=0.13241785764694214
[20/23] Train loss=0.11422285437583923
Test set avg_accuracy=89.93% avg_sensitivity=77.69%, avg_specificity=93.61% avg_auc=0.9460
Fold[6] Epoch: 100 [100/100 (100%)] Train loss=0.162373 Test loss=0.270544 Current lr=[3.9999999999999996e-05]

Fold[6] Best Result: acc=90.80168776371308 sen=79.33394160583941, spe=94.25082327113063, auc=0.9525499871802062!
[0/23] Train loss=0.7104974389076233
[5/23] Train loss=0.6964263916015625
[10/23] Train loss=0.5499327182769775
[15/23] Train loss=0.5269352793693542
[20/23] Train loss=0.5111497640609741
Test set avg_accuracy=75.58% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6550
Best model saved!! Metric=-84.91679848649048!!
Fold[7] Epoch: 1 [1/100 (1%)] Train loss=0.572311 Test loss=0.583852 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5170586109161377
[5/23] Train loss=0.5415505170822144
[10/23] Train loss=0.4792129397392273
[15/23] Train loss=0.42673438787460327
[20/23] Train loss=0.38330063223838806
Test set avg_accuracy=76.36% avg_sensitivity=12.41%, avg_specificity=97.02% avg_auc=0.7962
Best model saved!! Metric=-60.57501861077975!!
Fold[7] Epoch: 2 [2/100 (2%)] Train loss=0.470955 Test loss=0.581666 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.4085833430290222
[5/23] Train loss=0.44471853971481323
[10/23] Train loss=0.4412623941898346
[15/23] Train loss=0.374525249004364
[20/23] Train loss=0.3387387990951538
Test set avg_accuracy=80.44% avg_sensitivity=37.03%, avg_specificity=94.46% avg_auc=0.8494
Best model saved!! Metric=-29.127537149436876!!
Fold[7] Epoch: 3 [3/100 (3%)] Train loss=0.410009 Test loss=0.479365 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35308852791786194
[5/23] Train loss=0.4425274431705475
[10/23] Train loss=0.4092329144477844
[15/23] Train loss=0.3279416263103485
[20/23] Train loss=0.32470703125
Test set avg_accuracy=83.58% avg_sensitivity=52.90%, avg_specificity=93.50% avg_auc=0.8804
Best model saved!! Metric=-7.980504502648472!!
Fold[7] Epoch: 4 [4/100 (4%)] Train loss=0.381215 Test loss=0.389316 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34656211733818054
[5/23] Train loss=0.4086090922355652
[10/23] Train loss=0.3636029064655304
[15/23] Train loss=0.2937917113304138
[20/23] Train loss=0.28754371404647827
Test set avg_accuracy=84.81% avg_sensitivity=51.66%, avg_specificity=95.52% avg_auc=0.8946
Best model saved!! Metric=-4.546330846356177!!
Fold[7] Epoch: 5 [5/100 (5%)] Train loss=0.354325 Test loss=0.384061 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32378384470939636
[5/23] Train loss=0.40498435497283936
[10/23] Train loss=0.36432376503944397
[15/23] Train loss=0.2797220051288605
[20/23] Train loss=0.2647945284843445
Test set avg_accuracy=85.62% avg_sensitivity=51.83%, avg_specificity=96.54% avg_auc=0.9010
Best model saved!! Metric=-1.9045456320013745!!
Fold[7] Epoch: 6 [6/100 (6%)] Train loss=0.342918 Test loss=0.382588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2962884306907654
[5/23] Train loss=0.4066498577594757
[10/23] Train loss=0.35958343744277954
[15/23] Train loss=0.2653878629207611
[20/23] Train loss=0.26440340280532837
Test set avg_accuracy=86.39% avg_sensitivity=55.76%, avg_specificity=96.28% avg_auc=0.9064
Best model saved!! Metric=3.065488895933938!!
Fold[7] Epoch: 7 [7/100 (7%)] Train loss=0.332874 Test loss=0.361967 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29531025886535645
[5/23] Train loss=0.3925786018371582
[10/23] Train loss=0.34341147541999817
[15/23] Train loss=0.26146620512008667
[20/23] Train loss=0.24320590496063232
Test set avg_accuracy=87.50% avg_sensitivity=62.80%, avg_specificity=95.48% avg_auc=0.9157
Best model saved!! Metric=11.344838307287654!!
Fold[7] Epoch: 8 [8/100 (8%)] Train loss=0.324396 Test loss=0.328753 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2758398950099945
[5/23] Train loss=0.3872518241405487
[10/23] Train loss=0.3335214853286743
[15/23] Train loss=0.24766820669174194
[20/23] Train loss=0.23547977209091187
Test set avg_accuracy=87.86% avg_sensitivity=64.63%, avg_specificity=95.37% avg_auc=0.9214
Best model saved!! Metric=14.006520240438105!!
Fold[7] Epoch: 9 [9/100 (9%)] Train loss=0.314385 Test loss=0.314579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.269263356924057
[5/23] Train loss=0.3727659285068512
[10/23] Train loss=0.3237597942352295
[15/23] Train loss=0.25549960136413574
[20/23] Train loss=0.23277613520622253
Test set avg_accuracy=88.19% avg_sensitivity=65.36%, avg_specificity=95.56% avg_auc=0.9242
Best model saved!! Metric=15.526621960030251!!
Fold[7] Epoch: 10 [10/100 (10%)] Train loss=0.310460 Test loss=0.308834 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26277899742126465
[5/23] Train loss=0.3787817358970642
[10/23] Train loss=0.3219684958457947
[15/23] Train loss=0.23947928845882416
[20/23] Train loss=0.22345539927482605
Test set avg_accuracy=88.28% avg_sensitivity=65.10%, avg_specificity=95.77% avg_auc=0.9252
Best model saved!! Metric=15.671024403482953!!
Fold[7] Epoch: 11 [11/100 (11%)] Train loss=0.302524 Test loss=0.309953 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2471943348646164
[5/23] Train loss=0.36999285221099854
[10/23] Train loss=0.324540913105011
[15/23] Train loss=0.22557593882083893
[20/23] Train loss=0.2140648514032364
Test set avg_accuracy=88.60% avg_sensitivity=65.66%, avg_specificity=96.02% avg_auc=0.9276
Best model saved!! Metric=17.033653761729333!!
Fold[7] Epoch: 12 [12/100 (12%)] Train loss=0.296102 Test loss=0.308784 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2437879741191864
[5/23] Train loss=0.3657040297985077
[10/23] Train loss=0.31659117341041565
[15/23] Train loss=0.2344622164964676
[20/23] Train loss=0.21445611119270325
Test set avg_accuracy=88.76% avg_sensitivity=65.61%, avg_specificity=96.24% avg_auc=0.9293
Best model saved!! Metric=17.537662330841023!!
Fold[7] Epoch: 13 [13/100 (13%)] Train loss=0.294865 Test loss=0.306588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24752816557884216
[5/23] Train loss=0.37200799584388733
[10/23] Train loss=0.3035958707332611
[15/23] Train loss=0.2252362072467804
[20/23] Train loss=0.2169247269630432
Test set avg_accuracy=88.81% avg_sensitivity=65.49%, avg_specificity=96.35% avg_auc=0.9301
Best model saved!! Metric=17.655191090532103!!
Fold[7] Epoch: 14 [14/100 (14%)] Train loss=0.292933 Test loss=0.307188 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23944374918937683
[5/23] Train loss=0.36701077222824097
[10/23] Train loss=0.3078440725803375
[15/23] Train loss=0.2242855429649353
[20/23] Train loss=0.2079681158065796
Test set avg_accuracy=89.01% avg_sensitivity=66.81%, avg_specificity=96.18% avg_auc=0.9313
Best model saved!! Metric=19.136081527758428!!
Fold[7] Epoch: 15 [15/100 (15%)] Train loss=0.290046 Test loss=0.299345 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2334984689950943
[5/23] Train loss=0.36277565360069275
[10/23] Train loss=0.3040873408317566
[15/23] Train loss=0.23145699501037598
[20/23] Train loss=0.20327337086200714
Test set avg_accuracy=89.14% avg_sensitivity=66.68%, avg_specificity=96.39% avg_auc=0.9318
Best model saved!! Metric=19.38457882880341!!
Fold[7] Epoch: 16 [16/100 (16%)] Train loss=0.284760 Test loss=0.299861 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23906515538692474
[5/23] Train loss=0.36544540524482727
[10/23] Train loss=0.3025006651878357
[15/23] Train loss=0.21972480416297913
[20/23] Train loss=0.20354343950748444
Test set avg_accuracy=89.23% avg_sensitivity=66.98%, avg_specificity=96.42% avg_auc=0.9324
Best model saved!! Metric=19.866283036877896!!
Fold[7] Epoch: 17 [17/100 (17%)] Train loss=0.282112 Test loss=0.297047 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23238150775432587
[5/23] Train loss=0.33990395069122314
[10/23] Train loss=0.2986980080604553
[15/23] Train loss=0.22418378293514252
[20/23] Train loss=0.19446244835853577
Test set avg_accuracy=89.32% avg_sensitivity=66.51%, avg_specificity=96.69% avg_auc=0.9333
Fold[7] Epoch: 18 [18/100 (18%)] Train loss=0.278322 Test loss=0.297699 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2358817309141159
[5/23] Train loss=0.35780447721481323
[10/23] Train loss=0.2929602563381195
[15/23] Train loss=0.22834567725658417
[20/23] Train loss=0.19459505379199982
Test set avg_accuracy=89.43% avg_sensitivity=66.72%, avg_specificity=96.76% avg_auc=0.9342
Best model saved!! Metric=20.332363675646235!!
Fold[7] Epoch: 19 [19/100 (19%)] Train loss=0.278890 Test loss=0.294636 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22415578365325928
[5/23] Train loss=0.3483869433403015
[10/23] Train loss=0.28560730814933777
[15/23] Train loss=0.2277614176273346
[20/23] Train loss=0.1942179650068283
Test set avg_accuracy=89.56% avg_sensitivity=67.06%, avg_specificity=96.83% avg_auc=0.9349
Best model saved!! Metric=20.948055463573027!!
Fold[7] Epoch: 20 [20/100 (20%)] Train loss=0.276044 Test loss=0.293626 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22656524181365967
[5/23] Train loss=0.3681066334247589
[10/23] Train loss=0.286426305770874
[15/23] Train loss=0.21859537065029144
[20/23] Train loss=0.19425350427627563
Test set avg_accuracy=89.62% avg_sensitivity=67.70%, avg_specificity=96.71% avg_auc=0.9354
Best model saved!! Metric=21.575352256435547!!
Fold[7] Epoch: 21 [21/100 (21%)] Train loss=0.274612 Test loss=0.288122 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21883359551429749
[5/23] Train loss=0.3567329943180084
[10/23] Train loss=0.27542510628700256
[15/23] Train loss=0.21220582723617554
[20/23] Train loss=0.185309499502182
Test set avg_accuracy=90.05% avg_sensitivity=70.22%, avg_specificity=96.46% avg_auc=0.9373
Best model saved!! Metric=24.462780282733323!!
Fold[7] Epoch: 22 [22/100 (22%)] Train loss=0.271337 Test loss=0.278912 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22138850390911102
[5/23] Train loss=0.3433321416378021
[10/23] Train loss=0.2756686806678772
[15/23] Train loss=0.2128690481185913
[20/23] Train loss=0.19041909277439117
Test set avg_accuracy=90.01% avg_sensitivity=69.92%, avg_specificity=96.50% avg_auc=0.9372
Fold[7] Epoch: 23 [23/100 (23%)] Train loss=0.268652 Test loss=0.279133 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22960145771503448
[5/23] Train loss=0.32799088954925537
[10/23] Train loss=0.28345897793769836
[15/23] Train loss=0.21487034857273102
[20/23] Train loss=0.18864959478378296
Test set avg_accuracy=89.84% avg_sensitivity=68.64%, avg_specificity=96.69% avg_auc=0.9366
Fold[7] Epoch: 24 [24/100 (24%)] Train loss=0.268736 Test loss=0.281677 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2156587392091751
[5/23] Train loss=0.33859074115753174
[10/23] Train loss=0.2772315442562103
[15/23] Train loss=0.21206249296665192
[20/23] Train loss=0.18387581408023834
Test set avg_accuracy=89.85% avg_sensitivity=69.16%, avg_specificity=96.54% avg_auc=0.9377
Fold[7] Epoch: 25 [25/100 (25%)] Train loss=0.265658 Test loss=0.277871 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22513368725776672
[5/23] Train loss=0.35248181223869324
[10/23] Train loss=0.27182167768478394
[15/23] Train loss=0.20551517605781555
[20/23] Train loss=0.1844368726015091
Test set avg_accuracy=90.10% avg_sensitivity=70.09%, avg_specificity=96.57% avg_auc=0.9392
Best model saved!! Metric=24.687058405550026!!
Fold[7] Epoch: 26 [26/100 (26%)] Train loss=0.264327 Test loss=0.274441 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20882374048233032
[5/23] Train loss=0.34336164593696594
[10/23] Train loss=0.2672812342643738
[15/23] Train loss=0.21054476499557495
[20/23] Train loss=0.1801578551530838
Test set avg_accuracy=89.75% avg_sensitivity=68.00%, avg_specificity=96.78% avg_auc=0.9387
Fold[7] Epoch: 27 [27/100 (27%)] Train loss=0.260031 Test loss=0.279626 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21498247981071472
[5/23] Train loss=0.34408068656921387
[10/23] Train loss=0.260455459356308
[15/23] Train loss=0.21244977414608002
[20/23] Train loss=0.1873679906129837
Test set avg_accuracy=90.02% avg_sensitivity=69.41%, avg_specificity=96.68% avg_auc=0.9398
Fold[7] Epoch: 28 [28/100 (28%)] Train loss=0.263584 Test loss=0.272511 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2202303409576416
[5/23] Train loss=0.34166207909584045
[10/23] Train loss=0.26800036430358887
[15/23] Train loss=0.21322740614414215
[20/23] Train loss=0.1773206889629364
Test set avg_accuracy=90.04% avg_sensitivity=69.75%, avg_specificity=96.60% avg_auc=0.9402
Fold[7] Epoch: 29 [29/100 (29%)] Train loss=0.260272 Test loss=0.271129 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20584408938884735
[5/23] Train loss=0.3284150958061218
[10/23] Train loss=0.263820618391037
[15/23] Train loss=0.2026781141757965
[20/23] Train loss=0.18423494696617126
Test set avg_accuracy=89.92% avg_sensitivity=68.73%, avg_specificity=96.76% avg_auc=0.9395
Fold[7] Epoch: 30 [30/100 (30%)] Train loss=0.257800 Test loss=0.272237 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20975707471370697
[5/23] Train loss=0.3427102267742157
[10/23] Train loss=0.2609773576259613
[15/23] Train loss=0.2066032439470291
[20/23] Train loss=0.18048793077468872
Test set avg_accuracy=89.76% avg_sensitivity=67.36%, avg_specificity=97.00% avg_auc=0.9394
Fold[7] Epoch: 31 [31/100 (31%)] Train loss=0.256868 Test loss=0.276443 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21146731078624725
[5/23] Train loss=0.31877222657203674
[10/23] Train loss=0.26426205039024353
[15/23] Train loss=0.2001751810312271
[20/23] Train loss=0.17699062824249268
Test set avg_accuracy=89.66% avg_sensitivity=66.89%, avg_specificity=97.01% avg_auc=0.9391
Fold[7] Epoch: 32 [32/100 (32%)] Train loss=0.253141 Test loss=0.278088 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1969827115535736
[5/23] Train loss=0.32783815264701843
[10/23] Train loss=0.2563616931438446
[15/23] Train loss=0.20395445823669434
[20/23] Train loss=0.17257842421531677
Test set avg_accuracy=89.66% avg_sensitivity=66.64%, avg_specificity=97.09% avg_auc=0.9389
Fold[7] Epoch: 33 [33/100 (33%)] Train loss=0.252736 Test loss=0.277230 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20912660658359528
[5/23] Train loss=0.3301825523376465
[10/23] Train loss=0.2670571208000183
[15/23] Train loss=0.19939042627811432
[20/23] Train loss=0.17165611684322357
Test set avg_accuracy=89.88% avg_sensitivity=68.56%, avg_specificity=96.76% avg_auc=0.9394
Fold[7] Epoch: 34 [34/100 (34%)] Train loss=0.252528 Test loss=0.272328 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1970200389623642
[5/23] Train loss=0.3240627944469452
[10/23] Train loss=0.2557416558265686
[15/23] Train loss=0.2051769345998764
[20/23] Train loss=0.17436985671520233
Test set avg_accuracy=89.81% avg_sensitivity=67.70%, avg_specificity=96.95% avg_auc=0.9391
Fold[7] Epoch: 35 [35/100 (35%)] Train loss=0.250122 Test loss=0.272744 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20409254729747772
[5/23] Train loss=0.32552871108055115
[10/23] Train loss=0.24875092506408691
[15/23] Train loss=0.20748092234134674
[20/23] Train loss=0.17182764410972595
Test set avg_accuracy=89.88% avg_sensitivity=67.28%, avg_specificity=97.17% avg_auc=0.9393
Fold[7] Epoch: 36 [36/100 (36%)] Train loss=0.247868 Test loss=0.274781 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20534589886665344
[5/23] Train loss=0.3222673833370209
[10/23] Train loss=0.2593698501586914
[15/23] Train loss=0.21131682395935059
[20/23] Train loss=0.17652618885040283
Test set avg_accuracy=90.15% avg_sensitivity=68.73%, avg_specificity=97.06% avg_auc=0.9411
Fold[7] Epoch: 37 [37/100 (37%)] Train loss=0.250478 Test loss=0.266671 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20165027678012848
[5/23] Train loss=0.3171576261520386
[10/23] Train loss=0.2676360011100769
[15/23] Train loss=0.2012154906988144
[20/23] Train loss=0.17732776701450348
Test set avg_accuracy=90.02% avg_sensitivity=69.28%, avg_specificity=96.72% avg_auc=0.9400
Fold[7] Epoch: 38 [38/100 (38%)] Train loss=0.247235 Test loss=0.268493 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2008066326379776
[5/23] Train loss=0.3207438886165619
[10/23] Train loss=0.2641647458076477
[15/23] Train loss=0.1937515288591385
[20/23] Train loss=0.16525384783744812
Test set avg_accuracy=90.03% avg_sensitivity=68.98%, avg_specificity=96.83% avg_auc=0.9398
Fold[7] Epoch: 39 [39/100 (39%)] Train loss=0.243709 Test loss=0.270887 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20208144187927246
[5/23] Train loss=0.33184516429901123
[10/23] Train loss=0.2548421025276184
[15/23] Train loss=0.19592474400997162
[20/23] Train loss=0.17096063494682312
Test set avg_accuracy=89.83% avg_sensitivity=67.53%, avg_specificity=97.04% avg_auc=0.9402
Fold[7] Epoch: 40 [40/100 (40%)] Train loss=0.245547 Test loss=0.272072 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1976955533027649
[5/23] Train loss=0.3227432072162628
[10/23] Train loss=0.24039436876773834
[15/23] Train loss=0.19657260179519653
[20/23] Train loss=0.1713964194059372
Test set avg_accuracy=90.07% avg_sensitivity=68.73%, avg_specificity=96.97% avg_auc=0.9404
Fold[7] Epoch: 41 [41/100 (41%)] Train loss=0.244918 Test loss=0.267773 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20318356156349182
[5/23] Train loss=0.3169739246368408
[10/23] Train loss=0.2538977265357971
[15/23] Train loss=0.1934986710548401
[20/23] Train loss=0.1633402556180954
Test set avg_accuracy=89.95% avg_sensitivity=68.30%, avg_specificity=96.94% avg_auc=0.9403
Fold[7] Epoch: 42 [42/100 (42%)] Train loss=0.241955 Test loss=0.271449 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1958065778017044
[5/23] Train loss=0.30670851469039917
[10/23] Train loss=0.2451365441083908
[15/23] Train loss=0.1953030526638031
[20/23] Train loss=0.1656237691640854
Test set avg_accuracy=89.64% avg_sensitivity=68.09%, avg_specificity=96.60% avg_auc=0.9392
Fold[7] Epoch: 43 [43/100 (43%)] Train loss=0.240099 Test loss=0.271232 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19199036061763763
[5/23] Train loss=0.3038047254085541
[10/23] Train loss=0.25549232959747314
[15/23] Train loss=0.189207524061203
[20/23] Train loss=0.173468217253685
Test set avg_accuracy=89.74% avg_sensitivity=67.11%, avg_specificity=97.05% avg_auc=0.9389
Fold[7] Epoch: 44 [44/100 (44%)] Train loss=0.240866 Test loss=0.274982 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1904212385416031
[5/23] Train loss=0.32444682717323303
[10/23] Train loss=0.25115108489990234
[15/23] Train loss=0.192122682929039
[20/23] Train loss=0.16619767248630524
Test set avg_accuracy=89.69% avg_sensitivity=66.13%, avg_specificity=97.30% avg_auc=0.9399
Fold[7] Epoch: 45 [45/100 (45%)] Train loss=0.239400 Test loss=0.275264 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19600649178028107
[5/23] Train loss=0.31713443994522095
[10/23] Train loss=0.23785331845283508
[15/23] Train loss=0.19562286138534546
[20/23] Train loss=0.1601993292570114
Test set avg_accuracy=89.97% avg_sensitivity=68.47%, avg_specificity=96.91% avg_auc=0.9414
Fold[7] Epoch: 46 [46/100 (46%)] Train loss=0.239466 Test loss=0.266254 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19624878466129303
[5/23] Train loss=0.3134694993495941
[10/23] Train loss=0.24976089596748352
[15/23] Train loss=0.19066670536994934
[20/23] Train loss=0.1658436506986618
Test set avg_accuracy=90.08% avg_sensitivity=69.50%, avg_specificity=96.73% avg_auc=0.9414
Fold[7] Epoch: 47 [47/100 (47%)] Train loss=0.237102 Test loss=0.262999 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18376386165618896
[5/23] Train loss=0.2983914613723755
[10/23] Train loss=0.2548618018627167
[15/23] Train loss=0.19183851778507233
[20/23] Train loss=0.1594545692205429
Test set avg_accuracy=90.09% avg_sensitivity=69.37%, avg_specificity=96.79% avg_auc=0.9423
Fold[7] Epoch: 48 [48/100 (48%)] Train loss=0.235635 Test loss=0.263164 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19662223756313324
[5/23] Train loss=0.31270647048950195
[10/23] Train loss=0.24731765687465668
[15/23] Train loss=0.19329233467578888
[20/23] Train loss=0.15949931740760803
Test set avg_accuracy=89.99% avg_sensitivity=68.39%, avg_specificity=96.97% avg_auc=0.9411
Fold[7] Epoch: 49 [49/100 (49%)] Train loss=0.234588 Test loss=0.267003 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1959567815065384
[5/23] Train loss=0.30871638655662537
[10/23] Train loss=0.24562862515449524
[15/23] Train loss=0.20032578706741333
[20/23] Train loss=0.17146003246307373
Test set avg_accuracy=89.95% avg_sensitivity=67.62%, avg_specificity=97.16% avg_auc=0.9406
Fold[7] Epoch: 50 [50/100 (50%)] Train loss=0.234747 Test loss=0.270387 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1981702595949173
[5/23] Train loss=0.3147706389427185
[10/23] Train loss=0.24851827323436737
[15/23] Train loss=0.18644651770591736
[20/23] Train loss=0.16260963678359985
Test set avg_accuracy=90.08% avg_sensitivity=68.56%, avg_specificity=97.04% avg_auc=0.9409
Fold[7] Epoch: 51 [51/100 (51%)] Train loss=0.232533 Test loss=0.264843 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18769223988056183
[5/23] Train loss=0.30558738112449646
[10/23] Train loss=0.24053914844989777
[15/23] Train loss=0.1849251240491867
[20/23] Train loss=0.15447857975959778
Test set avg_accuracy=89.91% avg_sensitivity=67.79%, avg_specificity=97.05% avg_auc=0.9404
Fold[7] Epoch: 52 [52/100 (52%)] Train loss=0.228937 Test loss=0.270420 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19256924092769623
[5/23] Train loss=0.30871695280075073
[10/23] Train loss=0.233541339635849
[15/23] Train loss=0.18979611992835999
[20/23] Train loss=0.1694677621126175
Test set avg_accuracy=89.73% avg_sensitivity=66.42%, avg_specificity=97.26% avg_auc=0.9395
Fold[7] Epoch: 53 [53/100 (53%)] Train loss=0.229718 Test loss=0.278015 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18976972997188568
[5/23] Train loss=0.29007819294929504
[10/23] Train loss=0.23049713671207428
[15/23] Train loss=0.18112340569496155
[20/23] Train loss=0.1536891907453537
Test set avg_accuracy=89.72% avg_sensitivity=66.51%, avg_specificity=97.22% avg_auc=0.9394
Fold[7] Epoch: 54 [54/100 (54%)] Train loss=0.228319 Test loss=0.275814 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18772803246974945
[5/23] Train loss=0.3114795684814453
[10/23] Train loss=0.24607452750205994
[15/23] Train loss=0.19111043214797974
[20/23] Train loss=0.1552300751209259
Test set avg_accuracy=89.97% avg_sensitivity=68.47%, avg_specificity=96.91% avg_auc=0.9403
Fold[7] Epoch: 55 [55/100 (55%)] Train loss=0.230096 Test loss=0.267830 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1856224089860916
[5/23] Train loss=0.2955467700958252
[10/23] Train loss=0.24690333008766174
[15/23] Train loss=0.17905808985233307
[20/23] Train loss=0.15444067120552063
Test set avg_accuracy=89.98% avg_sensitivity=68.39%, avg_specificity=96.95% avg_auc=0.9410
Fold[7] Epoch: 56 [56/100 (56%)] Train loss=0.226518 Test loss=0.267497 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19355885684490204
[5/23] Train loss=0.29753023386001587
[10/23] Train loss=0.23294128477573395
[15/23] Train loss=0.18585361540317535
[20/23] Train loss=0.1603069007396698
Test set avg_accuracy=89.75% avg_sensitivity=66.68%, avg_specificity=97.20% avg_auc=0.9396
Fold[7] Epoch: 57 [57/100 (57%)] Train loss=0.225785 Test loss=0.276649 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18901513516902924
[5/23] Train loss=0.29541024565696716
[10/23] Train loss=0.24291977286338806
[15/23] Train loss=0.19075247645378113
[20/23] Train loss=0.1579161435365677
Test set avg_accuracy=90.07% avg_sensitivity=68.69%, avg_specificity=96.98% avg_auc=0.9400
Fold[7] Epoch: 58 [58/100 (58%)] Train loss=0.226208 Test loss=0.269692 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19758038222789764
[5/23] Train loss=0.2905922830104828
[10/23] Train loss=0.24289725720882416
[15/23] Train loss=0.17278489470481873
[20/23] Train loss=0.1641310304403305
Test set avg_accuracy=89.92% avg_sensitivity=68.43%, avg_specificity=96.86% avg_auc=0.9389
Fold[7] Epoch: 59 [59/100 (59%)] Train loss=0.224690 Test loss=0.271853 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19240212440490723
[5/23] Train loss=0.2869950830936432
[10/23] Train loss=0.23347260057926178
[15/23] Train loss=0.1804133951663971
[20/23] Train loss=0.1504562944173813
Test set avg_accuracy=90.09% avg_sensitivity=68.90%, avg_specificity=96.94% avg_auc=0.9389
Fold[7] Epoch: 60 [60/100 (60%)] Train loss=0.221358 Test loss=0.270361 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19198089838027954
[5/23] Train loss=0.2904506027698517
[10/23] Train loss=0.22998839616775513
[15/23] Train loss=0.1826663613319397
[20/23] Train loss=0.15122441947460175
Test set avg_accuracy=89.68% avg_sensitivity=66.51%, avg_specificity=97.16% avg_auc=0.9375
Fold[7] Epoch: 61 [61/100 (61%)] Train loss=0.224153 Test loss=0.278475 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18405000865459442
[5/23] Train loss=0.29274240136146545
[10/23] Train loss=0.23850013315677643
[15/23] Train loss=0.17682136595249176
[20/23] Train loss=0.1509433388710022
Test set avg_accuracy=89.97% avg_sensitivity=69.07%, avg_specificity=96.72% avg_auc=0.9392
Fold[7] Epoch: 62 [62/100 (62%)] Train loss=0.221869 Test loss=0.271261 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18614447116851807
[5/23] Train loss=0.27837151288986206
[10/23] Train loss=0.23385103046894073
[15/23] Train loss=0.184882253408432
[20/23] Train loss=0.15857887268066406
Test set avg_accuracy=89.77% avg_sensitivity=67.92%, avg_specificity=96.83% avg_auc=0.9385
Fold[7] Epoch: 63 [63/100 (63%)] Train loss=0.221752 Test loss=0.274783 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17856159806251526
[5/23] Train loss=0.300192266702652
[10/23] Train loss=0.23068082332611084
[15/23] Train loss=0.18225066363811493
[20/23] Train loss=0.15361356735229492
Test set avg_accuracy=90.05% avg_sensitivity=68.34%, avg_specificity=97.06% avg_auc=0.9380
Fold[7] Epoch: 64 [64/100 (64%)] Train loss=0.219962 Test loss=0.275589 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17996719479560852
[5/23] Train loss=0.2772883176803589
[10/23] Train loss=0.23017646372318268
[15/23] Train loss=0.16959598660469055
[20/23] Train loss=0.15281075239181519
Test set avg_accuracy=90.15% avg_sensitivity=69.24%, avg_specificity=96.90% avg_auc=0.9388
Fold[7] Epoch: 65 [65/100 (65%)] Train loss=0.217627 Test loss=0.272736 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1810578554868698
[5/23] Train loss=0.2769264280796051
[10/23] Train loss=0.23100319504737854
[15/23] Train loss=0.17095091938972473
[20/23] Train loss=0.14831697940826416
Test set avg_accuracy=90.00% avg_sensitivity=68.69%, avg_specificity=96.89% avg_auc=0.9374
Fold[7] Epoch: 66 [66/100 (66%)] Train loss=0.215290 Test loss=0.275798 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18039263784885406
[5/23] Train loss=0.28066208958625793
[10/23] Train loss=0.2377118170261383
[15/23] Train loss=0.18264199793338776
[20/23] Train loss=0.15668536722660065
Test set avg_accuracy=89.84% avg_sensitivity=67.45%, avg_specificity=97.08% avg_auc=0.9368
Fold[7] Epoch: 67 [67/100 (67%)] Train loss=0.214563 Test loss=0.278380 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18576858937740326
[5/23] Train loss=0.2919420599937439
[10/23] Train loss=0.2266419529914856
[15/23] Train loss=0.1760597676038742
[20/23] Train loss=0.15351156890392303
Test set avg_accuracy=89.77% avg_sensitivity=67.32%, avg_specificity=97.02% avg_auc=0.9367
Fold[7] Epoch: 68 [68/100 (68%)] Train loss=0.215325 Test loss=0.278520 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1796901971101761
[5/23] Train loss=0.2755000591278076
[10/23] Train loss=0.2291370928287506
[15/23] Train loss=0.18003684282302856
[20/23] Train loss=0.148859903216362
Test set avg_accuracy=89.97% avg_sensitivity=68.98%, avg_specificity=96.75% avg_auc=0.9372
Fold[7] Epoch: 69 [69/100 (69%)] Train loss=0.214868 Test loss=0.274000 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18612036108970642
[5/23] Train loss=0.27843162417411804
[10/23] Train loss=0.22331683337688446
[15/23] Train loss=0.17869648337364197
[20/23] Train loss=0.14338864386081696
Test set avg_accuracy=90.03% avg_sensitivity=69.24%, avg_specificity=96.75% avg_auc=0.9362
Fold[7] Epoch: 70 [70/100 (70%)] Train loss=0.211581 Test loss=0.274705 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19151081144809723
[5/23] Train loss=0.27618882060050964
[10/23] Train loss=0.23450729250907898
[15/23] Train loss=0.1700717955827713
[20/23] Train loss=0.14256486296653748
Test set avg_accuracy=89.93% avg_sensitivity=69.11%, avg_specificity=96.65% avg_auc=0.9373
Fold[7] Epoch: 71 [71/100 (71%)] Train loss=0.210017 Test loss=0.271742 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17662948369979858
[5/23] Train loss=0.26683422923088074
[10/23] Train loss=0.23578037321567535
[15/23] Train loss=0.1707189828157425
[20/23] Train loss=0.14332956075668335
Test set avg_accuracy=89.88% avg_sensitivity=68.30%, avg_specificity=96.84% avg_auc=0.9358
Fold[7] Epoch: 72 [72/100 (72%)] Train loss=0.207881 Test loss=0.280052 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1716509908437729
[5/23] Train loss=0.28054723143577576
[10/23] Train loss=0.22518675029277802
[15/23] Train loss=0.17160344123840332
[20/23] Train loss=0.13746874034404755
Test set avg_accuracy=89.73% avg_sensitivity=67.32%, avg_specificity=96.97% avg_auc=0.9348
Fold[7] Epoch: 73 [73/100 (73%)] Train loss=0.210688 Test loss=0.284219 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17560476064682007
[5/23] Train loss=0.30072587728500366
[10/23] Train loss=0.22713498771190643
[15/23] Train loss=0.17235694825649261
[20/23] Train loss=0.14554934203624725
Test set avg_accuracy=89.89% avg_sensitivity=69.16%, avg_specificity=96.58% avg_auc=0.9373
Fold[7] Epoch: 74 [74/100 (74%)] Train loss=0.209663 Test loss=0.274552 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1870976686477661
[5/23] Train loss=0.2847353219985962
[10/23] Train loss=0.22451452910900116
[15/23] Train loss=0.17048592865467072
[20/23] Train loss=0.13902150094509125
Test set avg_accuracy=89.97% avg_sensitivity=69.84%, avg_specificity=96.47% avg_auc=0.9373
Fold[7] Epoch: 75 [75/100 (75%)] Train loss=0.207046 Test loss=0.272791 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17552891373634338
[5/23] Train loss=0.2674925923347473
[10/23] Train loss=0.2046269178390503
[15/23] Train loss=0.1645306795835495
[20/23] Train loss=0.1394384503364563
Test set avg_accuracy=89.77% avg_sensitivity=69.11%, avg_specificity=96.44% avg_auc=0.9360
Fold[7] Epoch: 76 [76/100 (76%)] Train loss=0.202727 Test loss=0.278082 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17530030012130737
[5/23] Train loss=0.2648915648460388
[10/23] Train loss=0.22058787941932678
[15/23] Train loss=0.16198782622814178
[20/23] Train loss=0.13521507382392883
Test set avg_accuracy=89.85% avg_sensitivity=68.98%, avg_specificity=96.60% avg_auc=0.9355
Fold[7] Epoch: 77 [77/100 (77%)] Train loss=0.202935 Test loss=0.282752 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1848716139793396
[5/23] Train loss=0.2648221552371979
[10/23] Train loss=0.22461006045341492
[15/23] Train loss=0.16553965210914612
[20/23] Train loss=0.12671053409576416
Test set avg_accuracy=89.88% avg_sensitivity=67.83%, avg_specificity=97.00% avg_auc=0.9353
Fold[7] Epoch: 78 [78/100 (78%)] Train loss=0.203044 Test loss=0.283567 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17144538462162018
[5/23] Train loss=0.26832038164138794
[10/23] Train loss=0.21672187745571136
[15/23] Train loss=0.16337476670742035
[20/23] Train loss=0.13535235822200775
Test set avg_accuracy=90.07% avg_sensitivity=68.98%, avg_specificity=96.89% avg_auc=0.9361
Fold[7] Epoch: 79 [79/100 (79%)] Train loss=0.202363 Test loss=0.277131 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1693684607744217
[5/23] Train loss=0.27360445261001587
[10/23] Train loss=0.22449851036071777
[15/23] Train loss=0.16592831909656525
[20/23] Train loss=0.13273221254348755
Test set avg_accuracy=89.86% avg_sensitivity=69.16%, avg_specificity=96.55% avg_auc=0.9345
Fold[7] Epoch: 80 [80/100 (80%)] Train loss=0.201959 Test loss=0.281397 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1829589456319809
[5/23] Train loss=0.27234259247779846
[10/23] Train loss=0.2182631939649582
[15/23] Train loss=0.1655014157295227
[20/23] Train loss=0.12752720713615417
Test set avg_accuracy=89.97% avg_sensitivity=69.54%, avg_specificity=96.57% avg_auc=0.9361
Fold[7] Epoch: 81 [81/100 (81%)] Train loss=0.200636 Test loss=0.277735 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.173737570643425
[5/23] Train loss=0.26020553708076477
[10/23] Train loss=0.21317985653877258
[15/23] Train loss=0.15826457738876343
[20/23] Train loss=0.12634170055389404
Test set avg_accuracy=89.90% avg_sensitivity=70.09%, avg_specificity=96.29% avg_auc=0.9351
Fold[7] Epoch: 82 [82/100 (82%)] Train loss=0.197509 Test loss=0.277674 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17795076966285706
[5/23] Train loss=0.2568749189376831
[10/23] Train loss=0.2151435911655426
[15/23] Train loss=0.1460845023393631
[20/23] Train loss=0.12369827926158905
Test set avg_accuracy=89.99% avg_sensitivity=70.78%, avg_specificity=96.20% avg_auc=0.9356
Fold[7] Epoch: 83 [83/100 (83%)] Train loss=0.195840 Test loss=0.277012 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17437753081321716
[5/23] Train loss=0.27182021737098694
[10/23] Train loss=0.213552325963974
[15/23] Train loss=0.15877440571784973
[20/23] Train loss=0.14053624868392944
Test set avg_accuracy=89.75% avg_sensitivity=68.94%, avg_specificity=96.47% avg_auc=0.9336
Fold[7] Epoch: 84 [84/100 (84%)] Train loss=0.195996 Test loss=0.282714 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1669989675283432
[5/23] Train loss=0.2602204978466034
[10/23] Train loss=0.20833764970302582
[15/23] Train loss=0.15308764576911926
[20/23] Train loss=0.12863387167453766
Test set avg_accuracy=90.06% avg_sensitivity=70.52%, avg_specificity=96.38% avg_auc=0.9355
Fold[7] Epoch: 85 [85/100 (85%)] Train loss=0.192914 Test loss=0.280176 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1643303632736206
[5/23] Train loss=0.2527048885822296
[10/23] Train loss=0.20233024656772614
[15/23] Train loss=0.14567118883132935
[20/23] Train loss=0.1277484893798828
Test set avg_accuracy=89.70% avg_sensitivity=68.86%, avg_specificity=96.43% avg_auc=0.9327
Fold[7] Epoch: 86 [86/100 (86%)] Train loss=0.191988 Test loss=0.287933 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1726318895816803
[5/23] Train loss=0.25273454189300537
[10/23] Train loss=0.20613788068294525
[15/23] Train loss=0.15696436166763306
[20/23] Train loss=0.12409618496894836
Test set avg_accuracy=89.82% avg_sensitivity=70.01%, avg_specificity=96.22% avg_auc=0.9336
Fold[7] Epoch: 87 [87/100 (87%)] Train loss=0.189036 Test loss=0.285835 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17178961634635925
[5/23] Train loss=0.24314258992671967
[10/23] Train loss=0.21102575957775116
[15/23] Train loss=0.15273475646972656
[20/23] Train loss=0.13238097727298737
Test set avg_accuracy=89.69% avg_sensitivity=68.47%, avg_specificity=96.54% avg_auc=0.9319
Fold[7] Epoch: 88 [88/100 (88%)] Train loss=0.188717 Test loss=0.293110 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16793303191661835
[5/23] Train loss=0.2520607113838196
[10/23] Train loss=0.2096230685710907
[15/23] Train loss=0.14620032906532288
[20/23] Train loss=0.1274486631155014
Test set avg_accuracy=89.80% avg_sensitivity=69.24%, avg_specificity=96.44% avg_auc=0.9325
Fold[7] Epoch: 89 [89/100 (89%)] Train loss=0.189330 Test loss=0.289802 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16324707865715027
[5/23] Train loss=0.24676650762557983
[10/23] Train loss=0.20167265832424164
[15/23] Train loss=0.1431807279586792
[20/23] Train loss=0.13023696839809418
Test set avg_accuracy=89.65% avg_sensitivity=68.52%, avg_specificity=96.47% avg_auc=0.9331
Fold[7] Epoch: 90 [90/100 (90%)] Train loss=0.186021 Test loss=0.293442 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16167296469211578
[5/23] Train loss=0.2485443651676178
[10/23] Train loss=0.19686155021190643
[15/23] Train loss=0.15572230517864227
[20/23] Train loss=0.12576885521411896
Test set avg_accuracy=89.69% avg_sensitivity=69.67%, avg_specificity=96.15% avg_auc=0.9320
Fold[7] Epoch: 91 [91/100 (91%)] Train loss=0.186446 Test loss=0.291007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1688622385263443
[5/23] Train loss=0.24581310153007507
[10/23] Train loss=0.20726840198040009
[15/23] Train loss=0.14564402401447296
[20/23] Train loss=0.1308894157409668
Test set avg_accuracy=89.77% avg_sensitivity=69.07%, avg_specificity=96.46% avg_auc=0.9318
Fold[7] Epoch: 92 [92/100 (92%)] Train loss=0.185453 Test loss=0.294631 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16928543150424957
[5/23] Train loss=0.2372168004512787
[10/23] Train loss=0.19546279311180115
[15/23] Train loss=0.14703692495822906
[20/23] Train loss=0.12239750474691391
Test set avg_accuracy=89.75% avg_sensitivity=69.41%, avg_specificity=96.32% avg_auc=0.9299
Fold[7] Epoch: 93 [93/100 (93%)] Train loss=0.184099 Test loss=0.296389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16067473590373993
[5/23] Train loss=0.2472601979970932
[10/23] Train loss=0.20126555860042572
[15/23] Train loss=0.13685502111911774
[20/23] Train loss=0.11740675568580627
Test set avg_accuracy=89.78% avg_sensitivity=69.33%, avg_specificity=96.39% avg_auc=0.9311
Fold[7] Epoch: 94 [94/100 (94%)] Train loss=0.182062 Test loss=0.295289 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16808921098709106
[5/23] Train loss=0.2489137351512909
[10/23] Train loss=0.20002079010009766
[15/23] Train loss=0.14435693621635437
[20/23] Train loss=0.11668000370264053
Test set avg_accuracy=89.72% avg_sensitivity=70.05%, avg_specificity=96.07% avg_auc=0.9311
Fold[7] Epoch: 95 [95/100 (95%)] Train loss=0.180021 Test loss=0.290508 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1581287533044815
[5/23] Train loss=0.24020379781723022
[10/23] Train loss=0.18911057710647583
[15/23] Train loss=0.14165851473808289
[20/23] Train loss=0.11222286522388458
Test set avg_accuracy=89.62% avg_sensitivity=69.11%, avg_specificity=96.25% avg_auc=0.9304
Fold[7] Epoch: 96 [96/100 (96%)] Train loss=0.176230 Test loss=0.299967 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.169793501496315
[5/23] Train loss=0.2291184961795807
[10/23] Train loss=0.19594979286193848
[15/23] Train loss=0.14600250124931335
[20/23] Train loss=0.11738736927509308
Test set avg_accuracy=89.36% avg_sensitivity=68.43%, avg_specificity=96.13% avg_auc=0.9283
Fold[7] Epoch: 97 [97/100 (97%)] Train loss=0.179283 Test loss=0.304572 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15654423832893372
[5/23] Train loss=0.2335374355316162
[10/23] Train loss=0.19436684250831604
[15/23] Train loss=0.140951007604599
[20/23] Train loss=0.12194730341434479
Test set avg_accuracy=89.35% avg_sensitivity=67.75%, avg_specificity=96.33% avg_auc=0.9270
Fold[7] Epoch: 98 [98/100 (98%)] Train loss=0.175416 Test loss=0.307624 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15333245694637299
[5/23] Train loss=0.23399628698825836
[10/23] Train loss=0.19359175860881805
[15/23] Train loss=0.14217090606689453
[20/23] Train loss=0.10976295173168182
Test set avg_accuracy=89.39% avg_sensitivity=67.79%, avg_specificity=96.36% avg_auc=0.9263
Fold[7] Epoch: 99 [99/100 (99%)] Train loss=0.173766 Test loss=0.310762 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15623430907726288
[5/23] Train loss=0.23379020392894745
[10/23] Train loss=0.1889910250902176
[15/23] Train loss=0.1427234411239624
[20/23] Train loss=0.1072993278503418
Test set avg_accuracy=89.12% avg_sensitivity=66.30%, avg_specificity=96.50% avg_auc=0.9270
Fold[7] Epoch: 100 [100/100 (100%)] Train loss=0.175454 Test loss=0.316314 Current lr=[3.9999999999999996e-05]

Fold[7] Best Result: acc=90.10416666666666 sen=70.0938566552901, spe=96.5683572216097, auc=0.9392067786198357!
[0/23] Train loss=0.7082873582839966
[5/23] Train loss=0.6960119009017944
[10/23] Train loss=0.5589525699615479
[15/23] Train loss=0.5634576678276062
[20/23] Train loss=0.5216587781906128
Test set avg_accuracy=76.87% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6239
Best model saved!! Metric=-86.74398361863493!!
Fold[8] Epoch: 1 [1/100 (1%)] Train loss=0.582633 Test loss=0.592986 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.5319594740867615
[5/23] Train loss=0.5911076664924622
[10/23] Train loss=0.49744105339050293
[15/23] Train loss=0.4872806668281555
[20/23] Train loss=0.42581936717033386
Test set avg_accuracy=77.35% avg_sensitivity=19.54%, avg_specificity=94.75% avg_auc=0.8077
Best model saved!! Metric=-53.589824266963866!!
Fold[8] Epoch: 2 [2/100 (2%)] Train loss=0.503624 Test loss=0.487811 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.42832252383232117
[5/23] Train loss=0.4669094383716583
[10/23] Train loss=0.4485844671726227
[15/23] Train loss=0.4211587607860565
[20/23] Train loss=0.37102505564689636
Test set avg_accuracy=81.25% avg_sensitivity=40.97%, avg_specificity=93.37% avg_auc=0.8630
Best model saved!! Metric=-24.109042031474377!!
Fold[8] Epoch: 3 [3/100 (3%)] Train loss=0.431171 Test loss=0.422278 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3848044276237488
[5/23] Train loss=0.4443610906600952
[10/23] Train loss=0.41198432445526123
[15/23] Train loss=0.3601105511188507
[20/23] Train loss=0.346088707447052
Test set avg_accuracy=83.95% avg_sensitivity=54.56%, avg_specificity=92.79% avg_auc=0.8880
Best model saved!! Metric=-5.895526204505975!!
Fold[8] Epoch: 4 [4/100 (4%)] Train loss=0.397836 Test loss=0.373367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3571108281612396
[5/23] Train loss=0.4211302399635315
[10/23] Train loss=0.3993525505065918
[15/23] Train loss=0.3605065643787384
[20/23] Train loss=0.31576335430145264
Test set avg_accuracy=84.73% avg_sensitivity=56.00%, avg_specificity=93.37% avg_auc=0.8970
Best model saved!! Metric=-2.2028695394177014!!
Fold[8] Epoch: 5 [5/100 (5%)] Train loss=0.379173 Test loss=0.369690 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.34458670020103455
[5/23] Train loss=0.4089495837688446
[10/23] Train loss=0.3895743191242218
[15/23] Train loss=0.3438401222229004
[20/23] Train loss=0.2983406186103821
Test set avg_accuracy=86.36% avg_sensitivity=59.57%, avg_specificity=94.42% avg_auc=0.9096
Best model saved!! Metric=5.304625681480376!!
Fold[8] Epoch: 6 [6/100 (6%)] Train loss=0.367376 Test loss=0.346854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3254137933254242
[5/23] Train loss=0.4252660274505615
[10/23] Train loss=0.36898502707481384
[15/23] Train loss=0.3316650688648224
[20/23] Train loss=0.2611893117427826
Test set avg_accuracy=88.10% avg_sensitivity=63.69%, avg_specificity=95.45% avg_auc=0.9262
Best model saved!! Metric=13.859307537730595!!
Fold[8] Epoch: 7 [7/100 (7%)] Train loss=0.357076 Test loss=0.306663 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30461281538009644
[5/23] Train loss=0.40806612372398376
[10/23] Train loss=0.35641419887542725
[15/23] Train loss=0.3196626901626587
[20/23] Train loss=0.2576998174190521
Test set avg_accuracy=88.73% avg_sensitivity=65.72%, avg_specificity=95.66% avg_auc=0.9342
Best model saved!! Metric=17.53015460358627!!
Fold[8] Epoch: 8 [8/100 (8%)] Train loss=0.345261 Test loss=0.289854 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2994624972343445
[5/23] Train loss=0.40878573060035706
[10/23] Train loss=0.35421299934387207
[15/23] Train loss=0.3250269889831543
[20/23] Train loss=0.25451621413230896
Test set avg_accuracy=89.09% avg_sensitivity=67.96%, avg_specificity=95.45% avg_auc=0.9393
Best model saved!! Metric=20.422792674832863!!
Fold[8] Epoch: 9 [9/100 (9%)] Train loss=0.338361 Test loss=0.276757 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2842864394187927
[5/23] Train loss=0.3998498022556305
[10/23] Train loss=0.34074437618255615
[15/23] Train loss=0.31554341316223145
[20/23] Train loss=0.2425490766763687
Test set avg_accuracy=89.49% avg_sensitivity=70.83%, avg_specificity=95.10% avg_auc=0.9418
Best model saved!! Metric=23.60625679310767!!
Fold[8] Epoch: 10 [10/100 (10%)] Train loss=0.332120 Test loss=0.266020 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27179309725761414
[5/23] Train loss=0.39006268978118896
[10/23] Train loss=0.3299902677536011
[15/23] Train loss=0.3164716958999634
[20/23] Train loss=0.24351198971271515
Test set avg_accuracy=89.54% avg_sensitivity=72.72%, avg_specificity=94.60% avg_auc=0.9439
Best model saved!! Metric=25.240300377934666!!
Fold[8] Epoch: 11 [11/100 (11%)] Train loss=0.323117 Test loss=0.256205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2679915428161621
[5/23] Train loss=0.3829475939273834
[10/23] Train loss=0.33108383417129517
[15/23] Train loss=0.28558027744293213
[20/23] Train loss=0.22513458132743835
Test set avg_accuracy=89.81% avg_sensitivity=74.16%, avg_specificity=94.52% avg_auc=0.9465
Best model saved!! Metric=27.14093021479217!!
Fold[8] Epoch: 12 [12/100 (12%)] Train loss=0.312526 Test loss=0.251056 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25810593366622925
[5/23] Train loss=0.36930063366889954
[10/23] Train loss=0.3227401375770569
[15/23] Train loss=0.2809765636920929
[20/23] Train loss=0.2193823754787445
Test set avg_accuracy=89.90% avg_sensitivity=73.81%, avg_specificity=94.75% avg_auc=0.9471
Best model saved!! Metric=27.16434111791032!!
Fold[8] Epoch: 13 [13/100 (13%)] Train loss=0.306968 Test loss=0.251165 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2614206075668335
[5/23] Train loss=0.37677204608917236
[10/23] Train loss=0.3095642924308777
[15/23] Train loss=0.2878805994987488
[20/23] Train loss=0.22345931828022003
Test set avg_accuracy=90.15% avg_sensitivity=75.30%, avg_specificity=94.63% avg_auc=0.9487
Best model saved!! Metric=28.947432412638058!!
Fold[8] Epoch: 14 [14/100 (14%)] Train loss=0.302825 Test loss=0.245131 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24823243916034698
[5/23] Train loss=0.3690250813961029
[10/23] Train loss=0.31611567735671997
[15/23] Train loss=0.28571105003356934
[20/23] Train loss=0.21043792366981506
Test set avg_accuracy=90.24% avg_sensitivity=75.10%, avg_specificity=94.79% avg_auc=0.9495
Best model saved!! Metric=29.07552054049623!!
Fold[8] Epoch: 15 [15/100 (15%)] Train loss=0.297893 Test loss=0.245141 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2469395250082016
[5/23] Train loss=0.36411964893341064
[10/23] Train loss=0.3088322579860687
[15/23] Train loss=0.27750349044799805
[20/23] Train loss=0.2090717852115631
Test set avg_accuracy=90.28% avg_sensitivity=74.95%, avg_specificity=94.89% avg_auc=0.9501
Best model saved!! Metric=29.132858469184043!!
Fold[8] Epoch: 16 [16/100 (16%)] Train loss=0.293705 Test loss=0.246215 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24166062474250793
[5/23] Train loss=0.36352115869522095
[10/23] Train loss=0.2969058156013489
[15/23] Train loss=0.26575154066085815
[20/23] Train loss=0.20891369879245758
Test set avg_accuracy=90.32% avg_sensitivity=75.84%, avg_specificity=94.67% avg_auc=0.9503
Best model saved!! Metric=29.86098586514042!!
Fold[8] Epoch: 17 [17/100 (17%)] Train loss=0.292071 Test loss=0.242055 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23533593118190765
[5/23] Train loss=0.36777186393737793
[10/23] Train loss=0.30459079146385193
[15/23] Train loss=0.2663159668445587
[20/23] Train loss=0.19971811771392822
Test set avg_accuracy=90.48% avg_sensitivity=76.98%, avg_specificity=94.54% avg_auc=0.9516
Best model saved!! Metric=31.152908838561554!!
Fold[8] Epoch: 18 [18/100 (18%)] Train loss=0.290016 Test loss=0.238347 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22449304163455963
[5/23] Train loss=0.37194547057151794
[10/23] Train loss=0.2864435315132141
[15/23] Train loss=0.257444828748703
[20/23] Train loss=0.20083387196063995
Test set avg_accuracy=90.56% avg_sensitivity=78.37%, avg_specificity=94.22% avg_auc=0.9521
Best model saved!! Metric=32.36290373644223!!
Fold[8] Epoch: 19 [19/100 (19%)] Train loss=0.285144 Test loss=0.236190 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22423434257507324
[5/23] Train loss=0.3670375645160675
[10/23] Train loss=0.29392921924591064
[15/23] Train loss=0.26672637462615967
[20/23] Train loss=0.1983623206615448
Test set avg_accuracy=90.55% avg_sensitivity=77.38%, avg_specificity=94.51% avg_auc=0.9526
Fold[8] Epoch: 20 [20/100 (20%)] Train loss=0.281941 Test loss=0.234313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23499585688114166
[5/23] Train loss=0.34953901171684265
[10/23] Train loss=0.2913644313812256
[15/23] Train loss=0.2628381550312042
[20/23] Train loss=0.19342246651649475
Test set avg_accuracy=90.72% avg_sensitivity=78.22%, avg_specificity=94.48% avg_auc=0.9535
Best model saved!! Metric=32.76712684587039!!
Fold[8] Epoch: 21 [21/100 (21%)] Train loss=0.280322 Test loss=0.231352 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23078201711177826
[5/23] Train loss=0.3617030680179596
[10/23] Train loss=0.28360557556152344
[15/23] Train loss=0.2637892961502075
[20/23] Train loss=0.19560599327087402
Test set avg_accuracy=90.67% avg_sensitivity=78.12%, avg_specificity=94.45% avg_auc=0.9538
Fold[8] Epoch: 22 [22/100 (22%)] Train loss=0.277485 Test loss=0.231089 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22496695816516876
[5/23] Train loss=0.34892702102661133
[10/23] Train loss=0.2749719023704529
[15/23] Train loss=0.2513047158718109
[20/23] Train loss=0.19074782729148865
Test set avg_accuracy=90.71% avg_sensitivity=78.57%, avg_specificity=94.36% avg_auc=0.9543
Best model saved!! Metric=33.06759185106566!!
Fold[8] Epoch: 23 [23/100 (23%)] Train loss=0.273867 Test loss=0.230341 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2205670177936554
[5/23] Train loss=0.36592090129852295
[10/23] Train loss=0.2828039824962616
[15/23] Train loss=0.2554871737957001
[20/23] Train loss=0.18325269222259521
Test set avg_accuracy=90.84% avg_sensitivity=78.67%, avg_specificity=94.51% avg_auc=0.9549
Best model saved!! Metric=33.51498877889166!!
Fold[8] Epoch: 24 [24/100 (24%)] Train loss=0.275134 Test loss=0.226632 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21810148656368256
[5/23] Train loss=0.36505329608917236
[10/23] Train loss=0.28608402609825134
[15/23] Train loss=0.25355908274650574
[20/23] Train loss=0.19601503014564514
Test set avg_accuracy=90.76% avg_sensitivity=78.92%, avg_specificity=94.33% avg_auc=0.9545
Fold[8] Epoch: 25 [25/100 (25%)] Train loss=0.271693 Test loss=0.228901 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21338041126728058
[5/23] Train loss=0.33825817704200745
[10/23] Train loss=0.28221774101257324
[15/23] Train loss=0.2531962990760803
[20/23] Train loss=0.193984255194664
Test set avg_accuracy=90.69% avg_sensitivity=79.51%, avg_specificity=94.06% avg_auc=0.9544
Best model saved!! Metric=33.71014771559315!!
Fold[8] Epoch: 26 [26/100 (26%)] Train loss=0.268388 Test loss=0.227685 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21055680513381958
[5/23] Train loss=0.3424021601676941
[10/23] Train loss=0.27544423937797546
[15/23] Train loss=0.25053080916404724
[20/23] Train loss=0.18714939057826996
Test set avg_accuracy=90.89% avg_sensitivity=78.87%, avg_specificity=94.51% avg_auc=0.9553
Best model saved!! Metric=33.79219783262309!!
Fold[8] Epoch: 27 [27/100 (27%)] Train loss=0.267160 Test loss=0.225923 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21742893755435944
[5/23] Train loss=0.3545404374599457
[10/23] Train loss=0.2829001247882843
[15/23] Train loss=0.2530490458011627
[20/23] Train loss=0.18094345927238464
Test set avg_accuracy=90.82% avg_sensitivity=77.98%, avg_specificity=94.69% avg_auc=0.9551
Fold[8] Epoch: 28 [28/100 (28%)] Train loss=0.270535 Test loss=0.224182 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21401578187942505
[5/23] Train loss=0.3398876488208771
[10/23] Train loss=0.27112287282943726
[15/23] Train loss=0.2531851828098297
[20/23] Train loss=0.18651509284973145
Test set avg_accuracy=90.88% avg_sensitivity=79.12%, avg_specificity=94.42% avg_auc=0.9559
Best model saved!! Metric=33.99877296560334!!
Fold[8] Epoch: 29 [29/100 (29%)] Train loss=0.265715 Test loss=0.223291 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20702329277992249
[5/23] Train loss=0.3514220714569092
[10/23] Train loss=0.276289165019989
[15/23] Train loss=0.24562467634677887
[20/23] Train loss=0.18540115654468536
Test set avg_accuracy=90.85% avg_sensitivity=79.71%, avg_specificity=94.21% avg_auc=0.9563
Best model saved!! Metric=34.404566797175406!!
Fold[8] Epoch: 30 [30/100 (30%)] Train loss=0.263699 Test loss=0.222100 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20575657486915588
[5/23] Train loss=0.3516896367073059
[10/23] Train loss=0.27415451407432556
[15/23] Train loss=0.2382684201002121
[20/23] Train loss=0.1817077249288559
Test set avg_accuracy=90.97% avg_sensitivity=79.56%, avg_specificity=94.40% avg_auc=0.9561
Best model saved!! Metric=34.54069957350568!!
Fold[8] Epoch: 31 [31/100 (31%)] Train loss=0.262200 Test loss=0.222266 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20635275542736053
[5/23] Train loss=0.3243255019187927
[10/23] Train loss=0.27778875827789307
[15/23] Train loss=0.2503352165222168
[20/23] Train loss=0.1844116896390915
Test set avg_accuracy=90.89% avg_sensitivity=79.51%, avg_specificity=94.31% avg_auc=0.9563
Fold[8] Epoch: 32 [32/100 (32%)] Train loss=0.260634 Test loss=0.221159 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20437091588974
[5/23] Train loss=0.32693299651145935
[10/23] Train loss=0.2777525782585144
[15/23] Train loss=0.24182172119617462
[20/23] Train loss=0.17135943472385406
Test set avg_accuracy=90.89% avg_sensitivity=79.17%, avg_specificity=94.42% avg_auc=0.9565
Fold[8] Epoch: 33 [33/100 (33%)] Train loss=0.257055 Test loss=0.221327 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20522475242614746
[5/23] Train loss=0.34444376826286316
[10/23] Train loss=0.262710303068161
[15/23] Train loss=0.23825398087501526
[20/23] Train loss=0.17118042707443237
Test set avg_accuracy=90.89% avg_sensitivity=79.46%, avg_specificity=94.33% avg_auc=0.9554
Fold[8] Epoch: 34 [34/100 (34%)] Train loss=0.257461 Test loss=0.223579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20421989262104034
[5/23] Train loss=0.33587244153022766
[10/23] Train loss=0.27051830291748047
[15/23] Train loss=0.23672066628932953
[20/23] Train loss=0.18168096244335175
Test set avg_accuracy=90.95% avg_sensitivity=78.52%, avg_specificity=94.69% avg_auc=0.9565
Fold[8] Epoch: 35 [35/100 (35%)] Train loss=0.256314 Test loss=0.220455 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20864516496658325
[5/23] Train loss=0.33992353081703186
[10/23] Train loss=0.26650556921958923
[15/23] Train loss=0.23654504120349884
[20/23] Train loss=0.17914947867393494
Test set avg_accuracy=90.88% avg_sensitivity=78.42%, avg_specificity=94.63% avg_auc=0.9564
Fold[8] Epoch: 36 [36/100 (36%)] Train loss=0.255588 Test loss=0.219742 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20615889132022858
[5/23] Train loss=0.34174105525016785
[10/23] Train loss=0.2629656195640564
[15/23] Train loss=0.245050311088562
[20/23] Train loss=0.1770077794790268
Test set avg_accuracy=90.89% avg_sensitivity=78.47%, avg_specificity=94.63% avg_auc=0.9571
Fold[8] Epoch: 37 [37/100 (37%)] Train loss=0.252359 Test loss=0.218363 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20499281585216522
[5/23] Train loss=0.3331730365753174
[10/23] Train loss=0.2557521462440491
[15/23] Train loss=0.24368847906589508
[20/23] Train loss=0.17186973989009857
Test set avg_accuracy=90.97% avg_sensitivity=78.87%, avg_specificity=94.61% avg_auc=0.9568
Fold[8] Epoch: 38 [38/100 (38%)] Train loss=0.253537 Test loss=0.218960 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.204299658536911
[5/23] Train loss=0.33086133003234863
[10/23] Train loss=0.2791609466075897
[15/23] Train loss=0.24518519639968872
[20/23] Train loss=0.1708829253911972
Test set avg_accuracy=90.84% avg_sensitivity=78.87%, avg_specificity=94.45% avg_auc=0.9567
Fold[8] Epoch: 39 [39/100 (39%)] Train loss=0.253847 Test loss=0.218700 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20278312265872955
[5/23] Train loss=0.3243372142314911
[10/23] Train loss=0.26120585203170776
[15/23] Train loss=0.24540860950946808
[20/23] Train loss=0.17265944182872772
Test set avg_accuracy=90.87% avg_sensitivity=79.61%, avg_specificity=94.25% avg_auc=0.9571
Fold[8] Epoch: 40 [40/100 (40%)] Train loss=0.250014 Test loss=0.219243 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19762161374092102
[5/23] Train loss=0.3160145878791809
[10/23] Train loss=0.2586873769760132
[15/23] Train loss=0.2400585561990738
[20/23] Train loss=0.17473481595516205
Test set avg_accuracy=90.81% avg_sensitivity=79.32%, avg_specificity=94.27% avg_auc=0.9569
Fold[8] Epoch: 41 [41/100 (41%)] Train loss=0.250144 Test loss=0.219372 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2068367302417755
[5/23] Train loss=0.335182249546051
[10/23] Train loss=0.24444063007831573
[15/23] Train loss=0.2401803731918335
[20/23] Train loss=0.16510304808616638
Test set avg_accuracy=90.97% avg_sensitivity=80.06%, avg_specificity=94.25% avg_auc=0.9571
Best model saved!! Metric=34.99500660108855!!
Fold[8] Epoch: 42 [42/100 (42%)] Train loss=0.246551 Test loss=0.218902 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19971835613250732
[5/23] Train loss=0.3290676772594452
[10/23] Train loss=0.26268038153648376
[15/23] Train loss=0.2340184599161148
[20/23] Train loss=0.16835488379001617
Test set avg_accuracy=90.87% avg_sensitivity=79.91%, avg_specificity=94.16% avg_auc=0.9566
Fold[8] Epoch: 43 [43/100 (43%)] Train loss=0.247621 Test loss=0.220228 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19921071827411652
[5/23] Train loss=0.3250540792942047
[10/23] Train loss=0.26879769563674927
[15/23] Train loss=0.24141985177993774
[20/23] Train loss=0.1683264821767807
Test set avg_accuracy=91.03% avg_sensitivity=79.22%, avg_specificity=94.58% avg_auc=0.9571
Fold[8] Epoch: 44 [44/100 (44%)] Train loss=0.247793 Test loss=0.217821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19376857578754425
[5/23] Train loss=0.328130841255188
[10/23] Train loss=0.2643374502658844
[15/23] Train loss=0.23112943768501282
[20/23] Train loss=0.16930024325847626
Test set avg_accuracy=91.06% avg_sensitivity=78.67%, avg_specificity=94.79% avg_auc=0.9569
Fold[8] Epoch: 45 [45/100 (45%)] Train loss=0.246210 Test loss=0.219222 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19878293573856354
[5/23] Train loss=0.3167523741722107
[10/23] Train loss=0.2516181468963623
[15/23] Train loss=0.23289421200752258
[20/23] Train loss=0.15674278140068054
Test set avg_accuracy=91.11% avg_sensitivity=79.56%, avg_specificity=94.58% avg_auc=0.9573
Fold[8] Epoch: 46 [46/100 (46%)] Train loss=0.243939 Test loss=0.217724 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1908017247915268
[5/23] Train loss=0.3313281834125519
[10/23] Train loss=0.24536630511283875
[15/23] Train loss=0.23298794031143188
[20/23] Train loss=0.16757994890213013
Test set avg_accuracy=91.07% avg_sensitivity=79.37%, avg_specificity=94.60% avg_auc=0.9575
Fold[8] Epoch: 47 [47/100 (47%)] Train loss=0.241479 Test loss=0.217708 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19485248625278473
[5/23] Train loss=0.32299724221229553
[10/23] Train loss=0.2529526352882385
[15/23] Train loss=0.230947345495224
[20/23] Train loss=0.1651363968849182
Test set avg_accuracy=91.07% avg_sensitivity=79.51%, avg_specificity=94.55% avg_auc=0.9574
Fold[8] Epoch: 48 [48/100 (48%)] Train loss=0.242373 Test loss=0.217925 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20071516931056976
[5/23] Train loss=0.3203278183937073
[10/23] Train loss=0.2532289922237396
[15/23] Train loss=0.22331784665584564
[20/23] Train loss=0.16690076887607574
Test set avg_accuracy=91.18% avg_sensitivity=78.42%, avg_specificity=95.01% avg_auc=0.9566
Fold[8] Epoch: 49 [49/100 (49%)] Train loss=0.241304 Test loss=0.218837 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19583429396152496
[5/23] Train loss=0.33324500918388367
[10/23] Train loss=0.25056204199790955
[15/23] Train loss=0.2327093780040741
[20/23] Train loss=0.16534985601902008
Test set avg_accuracy=91.06% avg_sensitivity=79.37%, avg_specificity=94.58% avg_auc=0.9569
Fold[8] Epoch: 50 [50/100 (50%)] Train loss=0.241047 Test loss=0.218367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1972052901983261
[5/23] Train loss=0.3243396580219269
[10/23] Train loss=0.2510932683944702
[15/23] Train loss=0.23852060735225677
[20/23] Train loss=0.1594846397638321
Test set avg_accuracy=90.96% avg_sensitivity=79.76%, avg_specificity=94.33% avg_auc=0.9568
Fold[8] Epoch: 51 [51/100 (51%)] Train loss=0.239517 Test loss=0.218892 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19768041372299194
[5/23] Train loss=0.3149995803833008
[10/23] Train loss=0.24371075630187988
[15/23] Train loss=0.2253488004207611
[20/23] Train loss=0.1564873307943344
Test set avg_accuracy=91.13% avg_sensitivity=79.81%, avg_specificity=94.54% avg_auc=0.9572
Best model saved!! Metric=35.19612992305732!!
Fold[8] Epoch: 52 [52/100 (52%)] Train loss=0.236892 Test loss=0.219146 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19215495884418488
[5/23] Train loss=0.3079465627670288
[10/23] Train loss=0.24549396336078644
[15/23] Train loss=0.2261081486940384
[20/23] Train loss=0.16951636970043182
Test set avg_accuracy=90.98% avg_sensitivity=78.92%, avg_specificity=94.61% avg_auc=0.9569
Fold[8] Epoch: 53 [53/100 (53%)] Train loss=0.237009 Test loss=0.218825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19967398047447205
[5/23] Train loss=0.31728407740592957
[10/23] Train loss=0.24548786878585815
[15/23] Train loss=0.22870634496212006
[20/23] Train loss=0.15324144065380096
Test set avg_accuracy=90.97% avg_sensitivity=79.27%, avg_specificity=94.49% avg_auc=0.9559
Fold[8] Epoch: 54 [54/100 (54%)] Train loss=0.236228 Test loss=0.221649 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19895179569721222
[5/23] Train loss=0.3189046084880829
[10/23] Train loss=0.2611037790775299
[15/23] Train loss=0.22359013557434082
[20/23] Train loss=0.1551060825586319
Test set avg_accuracy=91.05% avg_sensitivity=79.71%, avg_specificity=94.46% avg_auc=0.9570
Fold[8] Epoch: 55 [55/100 (55%)] Train loss=0.233139 Test loss=0.218880 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1855079084634781
[5/23] Train loss=0.32062092423439026
[10/23] Train loss=0.2622397840023041
[15/23] Train loss=0.23260781168937683
[20/23] Train loss=0.15762700140476227
Test set avg_accuracy=91.06% avg_sensitivity=78.72%, avg_specificity=94.78% avg_auc=0.9562
Fold[8] Epoch: 56 [56/100 (56%)] Train loss=0.233295 Test loss=0.219676 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18785792589187622
[5/23] Train loss=0.31386643648147583
[10/23] Train loss=0.24646973609924316
[15/23] Train loss=0.22698108851909637
[20/23] Train loss=0.15870775282382965
Test set avg_accuracy=90.92% avg_sensitivity=78.32%, avg_specificity=94.72% avg_auc=0.9563
Fold[8] Epoch: 57 [57/100 (57%)] Train loss=0.235945 Test loss=0.218734 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19085921347141266
[5/23] Train loss=0.30714404582977295
[10/23] Train loss=0.23879241943359375
[15/23] Train loss=0.2243736982345581
[20/23] Train loss=0.15436922013759613
Test set avg_accuracy=90.98% avg_sensitivity=78.72%, avg_specificity=94.67% avg_auc=0.9561
Fold[8] Epoch: 58 [58/100 (58%)] Train loss=0.232443 Test loss=0.220030 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18300527334213257
[5/23] Train loss=0.30784308910369873
[10/23] Train loss=0.2570575177669525
[15/23] Train loss=0.2316075563430786
[20/23] Train loss=0.15653865039348602
Test set avg_accuracy=91.07% avg_sensitivity=79.27%, avg_specificity=94.63% avg_auc=0.9560
Fold[8] Epoch: 59 [59/100 (59%)] Train loss=0.231713 Test loss=0.219525 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1862240880727768
[5/23] Train loss=0.2981969118118286
[10/23] Train loss=0.23800328373908997
[15/23] Train loss=0.22747652232646942
[20/23] Train loss=0.15324534475803375
Test set avg_accuracy=90.92% avg_sensitivity=79.32%, avg_specificity=94.42% avg_auc=0.9551
Fold[8] Epoch: 60 [60/100 (60%)] Train loss=0.227743 Test loss=0.222085 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.193644717335701
[5/23] Train loss=0.3176428973674774
[10/23] Train loss=0.2413022369146347
[15/23] Train loss=0.2237650454044342
[20/23] Train loss=0.15005913376808167
Test set avg_accuracy=90.96% avg_sensitivity=78.82%, avg_specificity=94.61% avg_auc=0.9549
Fold[8] Epoch: 61 [61/100 (61%)] Train loss=0.230663 Test loss=0.222665 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18625858426094055
[5/23] Train loss=0.3116970956325531
[10/23] Train loss=0.24438521265983582
[15/23] Train loss=0.22245638072490692
[20/23] Train loss=0.15281522274017334
Test set avg_accuracy=91.13% avg_sensitivity=80.16%, avg_specificity=94.43% avg_auc=0.9563
Best model saved!! Metric=35.347390357569026!!
Fold[8] Epoch: 62 [62/100 (62%)] Train loss=0.228018 Test loss=0.218696 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18282344937324524
[5/23] Train loss=0.29916220903396606
[10/23] Train loss=0.24068662524223328
[15/23] Train loss=0.21629592776298523
[20/23] Train loss=0.15500178933143616
Test set avg_accuracy=90.98% avg_sensitivity=79.12%, avg_specificity=94.55% avg_auc=0.9555
Fold[8] Epoch: 63 [63/100 (63%)] Train loss=0.226066 Test loss=0.220317 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18259944021701813
[5/23] Train loss=0.3094783425331116
[10/23] Train loss=0.24497008323669434
[15/23] Train loss=0.21827398240566254
[20/23] Train loss=0.1466667652130127
Test set avg_accuracy=90.87% avg_sensitivity=77.88%, avg_specificity=94.78% avg_auc=0.9548
Fold[8] Epoch: 64 [64/100 (64%)] Train loss=0.227202 Test loss=0.221756 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1808791309595108
[5/23] Train loss=0.29960665106773376
[10/23] Train loss=0.2436002790927887
[15/23] Train loss=0.221061110496521
[20/23] Train loss=0.14743712544441223
Test set avg_accuracy=91.16% avg_sensitivity=78.97%, avg_specificity=94.84% avg_auc=0.9565
Fold[8] Epoch: 65 [65/100 (65%)] Train loss=0.222874 Test loss=0.217899 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1862569898366928
[5/23] Train loss=0.2995341122150421
[10/23] Train loss=0.23349830508232117
[15/23] Train loss=0.21764931082725525
[20/23] Train loss=0.14811210334300995
Test set avg_accuracy=91.04% avg_sensitivity=78.37%, avg_specificity=94.85% avg_auc=0.9552
Fold[8] Epoch: 66 [66/100 (66%)] Train loss=0.222421 Test loss=0.219866 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18447662889957428
[5/23] Train loss=0.3077116310596466
[10/23] Train loss=0.2387440800666809
[15/23] Train loss=0.219246968626976
[20/23] Train loss=0.1503971517086029
Test set avg_accuracy=90.98% avg_sensitivity=77.93%, avg_specificity=94.91% avg_auc=0.9548
Fold[8] Epoch: 67 [67/100 (67%)] Train loss=0.223220 Test loss=0.221438 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1825553923845291
[5/23] Train loss=0.2974920868873596
[10/23] Train loss=0.2440098226070404
[15/23] Train loss=0.22878508269786835
[20/23] Train loss=0.14601366221904755
Test set avg_accuracy=91.15% avg_sensitivity=78.27%, avg_specificity=95.03% avg_auc=0.9547
Fold[8] Epoch: 68 [68/100 (68%)] Train loss=0.221987 Test loss=0.220399 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18626241385936737
[5/23] Train loss=0.29466837644577026
[10/23] Train loss=0.2311163991689682
[15/23] Train loss=0.22908559441566467
[20/23] Train loss=0.14896762371063232
Test set avg_accuracy=90.97% avg_sensitivity=79.37%, avg_specificity=94.46% avg_auc=0.9546
Fold[8] Epoch: 69 [69/100 (69%)] Train loss=0.220608 Test loss=0.221254 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17578859627246857
[5/23] Train loss=0.30653390288352966
[10/23] Train loss=0.23898974061012268
[15/23] Train loss=0.22510193288326263
[20/23] Train loss=0.14563584327697754
Test set avg_accuracy=90.96% avg_sensitivity=79.81%, avg_specificity=94.31% avg_auc=0.9535
Fold[8] Epoch: 70 [70/100 (70%)] Train loss=0.219755 Test loss=0.224564 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1813189536333084
[5/23] Train loss=0.3074178993701935
[10/23] Train loss=0.2383798360824585
[15/23] Train loss=0.21435941755771637
[20/23] Train loss=0.14436060190200806
Test set avg_accuracy=91.07% avg_sensitivity=80.65%, avg_specificity=94.21% avg_auc=0.9550
Best model saved!! Metric=35.439827150996976!!
Fold[8] Epoch: 71 [71/100 (71%)] Train loss=0.220169 Test loss=0.221461 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1841830313205719
[5/23] Train loss=0.29626402258872986
[10/23] Train loss=0.2257528156042099
[15/23] Train loss=0.21130172908306122
[20/23] Train loss=0.1449817717075348
Test set avg_accuracy=90.98% avg_sensitivity=79.96%, avg_specificity=94.30% avg_auc=0.9551
Fold[8] Epoch: 72 [72/100 (72%)] Train loss=0.217488 Test loss=0.221348 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17401233315467834
[5/23] Train loss=0.2962667942047119
[10/23] Train loss=0.22234907746315002
[15/23] Train loss=0.22655916213989258
[20/23] Train loss=0.15079791843891144
Test set avg_accuracy=91.05% avg_sensitivity=79.86%, avg_specificity=94.42% avg_auc=0.9546
Fold[8] Epoch: 73 [73/100 (73%)] Train loss=0.216750 Test loss=0.221885 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17686352133750916
[5/23] Train loss=0.2924269735813141
[10/23] Train loss=0.2292984575033188
[15/23] Train loss=0.21379508078098297
[20/23] Train loss=0.1425422579050064
Test set avg_accuracy=91.08% avg_sensitivity=80.51%, avg_specificity=94.27% avg_auc=0.9546
Fold[8] Epoch: 74 [74/100 (74%)] Train loss=0.214450 Test loss=0.222100 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18342901766300201
[5/23] Train loss=0.29879844188690186
[10/23] Train loss=0.2182319462299347
[15/23] Train loss=0.21240143477916718
[20/23] Train loss=0.14904427528381348
Test set avg_accuracy=91.00% avg_sensitivity=79.96%, avg_specificity=94.33% avg_auc=0.9539
Fold[8] Epoch: 75 [75/100 (75%)] Train loss=0.212714 Test loss=0.223339 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17636239528656006
[5/23] Train loss=0.3046511113643646
[10/23] Train loss=0.21894317865371704
[15/23] Train loss=0.21091246604919434
[20/23] Train loss=0.13985803723335266
Test set avg_accuracy=91.12% avg_sensitivity=79.17%, avg_specificity=94.72% avg_auc=0.9527
Fold[8] Epoch: 76 [76/100 (76%)] Train loss=0.211016 Test loss=0.225056 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17483755946159363
[5/23] Train loss=0.2891083061695099
[10/23] Train loss=0.2319469153881073
[15/23] Train loss=0.2192368060350418
[20/23] Train loss=0.14444684982299805
Test set avg_accuracy=90.84% avg_sensitivity=78.03%, avg_specificity=94.70% avg_auc=0.9517
Fold[8] Epoch: 77 [77/100 (77%)] Train loss=0.212921 Test loss=0.226204 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17524170875549316
[5/23] Train loss=0.2915147542953491
[10/23] Train loss=0.22236114740371704
[15/23] Train loss=0.2125786691904068
[20/23] Train loss=0.13988329470157623
Test set avg_accuracy=91.05% avg_sensitivity=80.11%, avg_specificity=94.34% avg_auc=0.9530
Fold[8] Epoch: 78 [78/100 (78%)] Train loss=0.212198 Test loss=0.225343 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17536763846874237
[5/23] Train loss=0.2890346646308899
[10/23] Train loss=0.2221831977367401
[15/23] Train loss=0.21447399258613586
[20/23] Train loss=0.1426534503698349
Test set avg_accuracy=90.99% avg_sensitivity=79.76%, avg_specificity=94.37% avg_auc=0.9523
Fold[8] Epoch: 79 [79/100 (79%)] Train loss=0.211367 Test loss=0.226133 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17173025012016296
[5/23] Train loss=0.2834857404232025
[10/23] Train loss=0.22510196268558502
[15/23] Train loss=0.2061087042093277
[20/23] Train loss=0.1332482546567917
Test set avg_accuracy=91.03% avg_sensitivity=79.96%, avg_specificity=94.36% avg_auc=0.9524
Fold[8] Epoch: 80 [80/100 (80%)] Train loss=0.207565 Test loss=0.225822 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16931487619876862
[5/23] Train loss=0.28013700246810913
[10/23] Train loss=0.2210712879896164
[15/23] Train loss=0.20721910893917084
[20/23] Train loss=0.14216077327728271
Test set avg_accuracy=90.90% avg_sensitivity=80.16%, avg_specificity=94.13% avg_auc=0.9521
Fold[8] Epoch: 81 [81/100 (81%)] Train loss=0.206917 Test loss=0.227728 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17684531211853027
[5/23] Train loss=0.272026389837265
[10/23] Train loss=0.21261930465698242
[15/23] Train loss=0.20812614262104034
[20/23] Train loss=0.1379699856042862
Test set avg_accuracy=91.12% avg_sensitivity=81.40%, avg_specificity=94.04% avg_auc=0.9543
Best model saved!! Metric=35.987428670317854!!
Fold[8] Epoch: 82 [82/100 (82%)] Train loss=0.205329 Test loss=0.224731 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16455207765102386
[5/23] Train loss=0.27104586362838745
[10/23] Train loss=0.2235846370458603
[15/23] Train loss=0.20447935163974762
[20/23] Train loss=0.14082518219947815
Test set avg_accuracy=90.97% avg_sensitivity=79.71%, avg_specificity=94.36% avg_auc=0.9519
Fold[8] Epoch: 83 [83/100 (83%)] Train loss=0.203457 Test loss=0.228225 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1738307923078537
[5/23] Train loss=0.2791689932346344
[10/23] Train loss=0.21529029309749603
[15/23] Train loss=0.20151501893997192
[20/23] Train loss=0.14048203825950623
Test set avg_accuracy=90.82% avg_sensitivity=80.46%, avg_specificity=93.94% avg_auc=0.9523
Fold[8] Epoch: 84 [84/100 (84%)] Train loss=0.202953 Test loss=0.229564 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1847582310438156
[5/23] Train loss=0.2672734260559082
[10/23] Train loss=0.21266792714595795
[15/23] Train loss=0.21118173003196716
[20/23] Train loss=0.13139291107654572
Test set avg_accuracy=91.04% avg_sensitivity=81.50%, avg_specificity=93.91% avg_auc=0.9526
Fold[8] Epoch: 85 [85/100 (85%)] Train loss=0.201700 Test loss=0.229891 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17348235845565796
[5/23] Train loss=0.2831449508666992
[10/23] Train loss=0.21363747119903564
[15/23] Train loss=0.2016867995262146
[20/23] Train loss=0.1340404748916626
Test set avg_accuracy=90.99% avg_sensitivity=80.80%, avg_specificity=94.06% avg_auc=0.9527
Fold[8] Epoch: 86 [86/100 (86%)] Train loss=0.201209 Test loss=0.228425 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1694219410419464
[5/23] Train loss=0.2861768901348114
[10/23] Train loss=0.22276702523231506
[15/23] Train loss=0.20619559288024902
[20/23] Train loss=0.13738948106765747
Test set avg_accuracy=91.05% avg_sensitivity=79.76%, avg_specificity=94.45% avg_auc=0.9527
Fold[8] Epoch: 87 [87/100 (87%)] Train loss=0.199928 Test loss=0.226976 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17749053239822388
[5/23] Train loss=0.28427812457084656
[10/23] Train loss=0.20921896398067474
[15/23] Train loss=0.20236538350582123
[20/23] Train loss=0.12732703983783722
Test set avg_accuracy=91.14% avg_sensitivity=80.21%, avg_specificity=94.43% avg_auc=0.9527
Fold[8] Epoch: 88 [88/100 (88%)] Train loss=0.200105 Test loss=0.226437 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16825444996356964
[5/23] Train loss=0.2680094838142395
[10/23] Train loss=0.21647460758686066
[15/23] Train loss=0.1984834522008896
[20/23] Train loss=0.1331016570329666
Test set avg_accuracy=91.23% avg_sensitivity=80.01%, avg_specificity=94.61% avg_auc=0.9521
Fold[8] Epoch: 89 [89/100 (89%)] Train loss=0.197626 Test loss=0.226050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16914276778697968
[5/23] Train loss=0.26698216795921326
[10/23] Train loss=0.21657578647136688
[15/23] Train loss=0.21063707768917084
[20/23] Train loss=0.12252474576234818
Test set avg_accuracy=91.16% avg_sensitivity=79.27%, avg_specificity=94.75% avg_auc=0.9525
Fold[8] Epoch: 90 [90/100 (90%)] Train loss=0.197673 Test loss=0.225527 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16230113804340363
[5/23] Train loss=0.2768440544605255
[10/23] Train loss=0.2064739316701889
[15/23] Train loss=0.20290589332580566
[20/23] Train loss=0.1267925351858139
Test set avg_accuracy=91.06% avg_sensitivity=79.32%, avg_specificity=94.60% avg_auc=0.9525
Fold[8] Epoch: 91 [91/100 (91%)] Train loss=0.197950 Test loss=0.226151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16345526278018951
[5/23] Train loss=0.27206867933273315
[10/23] Train loss=0.2037660926580429
[15/23] Train loss=0.19983293116092682
[20/23] Train loss=0.12644967436790466
Test set avg_accuracy=91.24% avg_sensitivity=80.90%, avg_specificity=94.36% avg_auc=0.9541
Fold[8] Epoch: 92 [92/100 (92%)] Train loss=0.192723 Test loss=0.226016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16243231296539307
[5/23] Train loss=0.2716662287712097
[10/23] Train loss=0.20710507035255432
[15/23] Train loss=0.20366409420967102
[20/23] Train loss=0.12810118496418
Test set avg_accuracy=91.04% avg_sensitivity=80.21%, avg_specificity=94.30% avg_auc=0.9526
Fold[8] Epoch: 93 [93/100 (93%)] Train loss=0.191889 Test loss=0.227886 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16937336325645447
[5/23] Train loss=0.26745492219924927
[10/23] Train loss=0.19787351787090302
[15/23] Train loss=0.1922125220298767
[20/23] Train loss=0.12584960460662842
Test set avg_accuracy=91.03% avg_sensitivity=81.25%, avg_specificity=93.97% avg_auc=0.9531
Fold[8] Epoch: 94 [94/100 (94%)] Train loss=0.191186 Test loss=0.230405 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15939223766326904
[5/23] Train loss=0.26901304721832275
[10/23] Train loss=0.1991606503725052
[15/23] Train loss=0.20592977106571198
[20/23] Train loss=0.12392895668745041
Test set avg_accuracy=91.19% avg_sensitivity=80.90%, avg_specificity=94.28% avg_auc=0.9536
Fold[8] Epoch: 95 [95/100 (95%)] Train loss=0.191082 Test loss=0.226590 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15959881246089935
[5/23] Train loss=0.25521042943000793
[10/23] Train loss=0.2062908560037613
[15/23] Train loss=0.19838786125183105
[20/23] Train loss=0.1209891140460968
Test set avg_accuracy=90.79% avg_sensitivity=79.76%, avg_specificity=94.10% avg_auc=0.9517
Fold[8] Epoch: 96 [96/100 (96%)] Train loss=0.187645 Test loss=0.231909 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16519023478031158
[5/23] Train loss=0.2653946578502655
[10/23] Train loss=0.2102101445198059
[15/23] Train loss=0.19359339773654938
[20/23] Train loss=0.12652963399887085
Test set avg_accuracy=90.92% avg_sensitivity=79.61%, avg_specificity=94.33% avg_auc=0.9530
Fold[8] Epoch: 97 [97/100 (97%)] Train loss=0.187113 Test loss=0.228734 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1616782397031784
[5/23] Train loss=0.2634197175502777
[10/23] Train loss=0.20663322508335114
[15/23] Train loss=0.20179535448551178
[20/23] Train loss=0.1275588423013687
Test set avg_accuracy=90.67% avg_sensitivity=79.66%, avg_specificity=93.98% avg_auc=0.9496
Fold[8] Epoch: 98 [98/100 (98%)] Train loss=0.188496 Test loss=0.235149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16079996526241302
[5/23] Train loss=0.25749582052230835
[10/23] Train loss=0.20113039016723633
[15/23] Train loss=0.19876015186309814
[20/23] Train loss=0.11996040493249893
Test set avg_accuracy=90.64% avg_sensitivity=80.65%, avg_specificity=93.64% avg_auc=0.9519
Fold[8] Epoch: 99 [99/100 (99%)] Train loss=0.184825 Test loss=0.234007 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15550339221954346
[5/23] Train loss=0.2517910897731781
[10/23] Train loss=0.2023344188928604
[15/23] Train loss=0.194861501455307
[20/23] Train loss=0.11958839744329453
Test set avg_accuracy=90.59% avg_sensitivity=81.70%, avg_specificity=93.27% avg_auc=0.9517
Fold[8] Epoch: 100 [100/100 (100%)] Train loss=0.182902 Test loss=0.236742 Current lr=[3.9999999999999996e-05]

Fold[8] Best Result: acc=91.11876075731497 sen=81.39880952380952, spe=94.04388714733543, auc=0.9542597124185794!
[0/23] Train loss=0.6991267800331116
[5/23] Train loss=0.6815316081047058
[10/23] Train loss=0.574806809425354
[15/23] Train loss=0.5380207300186157
[20/23] Train loss=0.529018223285675
Test set avg_accuracy=74.62% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6113
Best model saved!! Metric=-90.24635129267094!!
Fold[9] Epoch: 1 [1/100 (1%)] Train loss=0.564350 Test loss=0.610221 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.501889705657959
[5/23] Train loss=0.5113858580589294
[10/23] Train loss=0.48568955063819885
[15/23] Train loss=0.44283175468444824
[20/23] Train loss=0.41877707839012146
Test set avg_accuracy=76.33% avg_sensitivity=21.80%, avg_specificity=94.88% avg_auc=0.7868
Best model saved!! Metric=-54.312588868354254!!
Fold[9] Epoch: 2 [2/100 (2%)] Train loss=0.461206 Test loss=0.534051 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.40311524271965027
[5/23] Train loss=0.44331979751586914
[10/23] Train loss=0.43048009276390076
[15/23] Train loss=0.39976879954338074
[20/23] Train loss=0.3954315185546875
Test set avg_accuracy=79.87% avg_sensitivity=40.86%, avg_specificity=93.14% avg_auc=0.8473
Best model saved!! Metric=-27.393285094927908!!
Fold[9] Epoch: 3 [3/100 (3%)] Train loss=0.408030 Test loss=0.447818 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.36997365951538086
[5/23] Train loss=0.4344451427459717
[10/23] Train loss=0.40606480836868286
[15/23] Train loss=0.3554583489894867
[20/23] Train loss=0.356393963098526
Test set avg_accuracy=81.01% avg_sensitivity=47.19%, avg_specificity=92.52% avg_auc=0.8628
Best model saved!! Metric=-18.99247521361253!!
Fold[9] Epoch: 4 [4/100 (4%)] Train loss=0.382533 Test loss=0.420392 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.35477086901664734
[5/23] Train loss=0.40820643305778503
[10/23] Train loss=0.37688034772872925
[15/23] Train loss=0.33556511998176575
[20/23] Train loss=0.3363005816936493
Test set avg_accuracy=82.48% avg_sensitivity=49.37%, avg_specificity=93.74% avg_auc=0.8683
Best model saved!! Metric=-13.582678521619158!!
Fold[9] Epoch: 5 [5/100 (5%)] Train loss=0.361707 Test loss=0.410038 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3375920057296753
[5/23] Train loss=0.40501663088798523
[10/23] Train loss=0.3611992597579956
[15/23] Train loss=0.3283880949020386
[20/23] Train loss=0.30545786023139954
Test set avg_accuracy=84.14% avg_sensitivity=53.23%, avg_specificity=94.66% avg_auc=0.8851
Best model saved!! Metric=-5.464841990257888!!
Fold[9] Epoch: 6 [6/100 (6%)] Train loss=0.347143 Test loss=0.379841 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30952364206314087
[5/23] Train loss=0.4017176330089569
[10/23] Train loss=0.3723312020301819
[15/23] Train loss=0.31253066658973694
[20/23] Train loss=0.3086206316947937
Test set avg_accuracy=84.88% avg_sensitivity=56.44%, avg_specificity=94.56% avg_auc=0.8978
Best model saved!! Metric=-0.332724211301354!!
Fold[9] Epoch: 7 [7/100 (7%)] Train loss=0.340083 Test loss=0.361906 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30192071199417114
[5/23] Train loss=0.39225488901138306
[10/23] Train loss=0.3698972463607788
[15/23] Train loss=0.3138956129550934
[20/23] Train loss=0.28823012113571167
Test set avg_accuracy=84.84% avg_sensitivity=53.60%, avg_specificity=95.46% avg_auc=0.8995
Fold[9] Epoch: 8 [8/100 (8%)] Train loss=0.330582 Test loss=0.367413 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.30599847435951233
[5/23] Train loss=0.38914626836776733
[10/23] Train loss=0.3734232783317566
[15/23] Train loss=0.2994990944862366
[20/23] Train loss=0.27393171191215515
Test set avg_accuracy=85.22% avg_sensitivity=57.88%, avg_specificity=94.51% avg_auc=0.9019
Best model saved!! Metric=1.800271707850385!!
Fold[9] Epoch: 9 [9/100 (9%)] Train loss=0.326262 Test loss=0.353592 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29257386922836304
[5/23] Train loss=0.40366044640541077
[10/23] Train loss=0.3454740643501282
[15/23] Train loss=0.3110327422618866
[20/23] Train loss=0.2606695294380188
Test set avg_accuracy=86.05% avg_sensitivity=65.18%, avg_specificity=93.15% avg_auc=0.9109
Best model saved!! Metric=9.471034988539405!!
Fold[9] Epoch: 10 [10/100 (10%)] Train loss=0.318392 Test loss=0.326274 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.26151973009109497
[5/23] Train loss=0.38439270853996277
[10/23] Train loss=0.3312535881996155
[15/23] Train loss=0.2864115536212921
[20/23] Train loss=0.26054245233535767
Test set avg_accuracy=86.23% avg_sensitivity=65.36%, avg_specificity=93.33% avg_auc=0.9157
Best model saved!! Metric=10.488400605530408!!
Fold[9] Epoch: 11 [11/100 (11%)] Train loss=0.305989 Test loss=0.323435 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2584811747074127
[5/23] Train loss=0.3620092570781708
[10/23] Train loss=0.319572389125824
[15/23] Train loss=0.2891915738582611
[20/23] Train loss=0.25197526812553406
Test set avg_accuracy=86.43% avg_sensitivity=65.32%, avg_specificity=93.61% avg_auc=0.9175
Best model saved!! Metric=11.107260942020828!!
Fold[9] Epoch: 12 [12/100 (12%)] Train loss=0.301377 Test loss=0.320157 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2540987730026245
[5/23] Train loss=0.380260169506073
[10/23] Train loss=0.3249181807041168
[15/23] Train loss=0.27038708329200745
[20/23] Train loss=0.25130710005760193
Test set avg_accuracy=86.63% avg_sensitivity=65.55%, avg_specificity=93.80% avg_auc=0.9195
Best model saved!! Metric=11.933731054174222!!
Fold[9] Epoch: 13 [13/100 (13%)] Train loss=0.295638 Test loss=0.320910 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25952133536338806
[5/23] Train loss=0.3616562485694885
[10/23] Train loss=0.3171062767505646
[15/23] Train loss=0.27404797077178955
[20/23] Train loss=0.24467937648296356
Test set avg_accuracy=86.47% avg_sensitivity=65.41%, avg_specificity=93.63% avg_auc=0.9205
Fold[9] Epoch: 14 [14/100 (14%)] Train loss=0.290442 Test loss=0.319501 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25200971961021423
[5/23] Train loss=0.3737998306751251
[10/23] Train loss=0.29714399576187134
[15/23] Train loss=0.2660602927207947
[20/23] Train loss=0.2400590181350708
Test set avg_accuracy=86.64% avg_sensitivity=67.83%, avg_specificity=93.04% avg_auc=0.9220
Best model saved!! Metric=13.710184151896144!!
Fold[9] Epoch: 15 [15/100 (15%)] Train loss=0.290139 Test loss=0.312346 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24422875046730042
[5/23] Train loss=0.3683728277683258
[10/23] Train loss=0.309296578168869
[15/23] Train loss=0.2611837089061737
[20/23] Train loss=0.2351444661617279
Test set avg_accuracy=86.77% avg_sensitivity=69.69%, avg_specificity=92.58% avg_auc=0.9229
Best model saved!! Metric=15.337821067065052!!
Fold[9] Epoch: 16 [16/100 (16%)] Train loss=0.288872 Test loss=0.308762 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2357579618692398
[5/23] Train loss=0.36380642652511597
[10/23] Train loss=0.3127506375312805
[15/23] Train loss=0.2609393000602722
[20/23] Train loss=0.23448233306407928
Test set avg_accuracy=86.86% avg_sensitivity=70.06%, avg_specificity=92.57% avg_auc=0.9240
Best model saved!! Metric=15.881876546984872!!
Fold[9] Epoch: 17 [17/100 (17%)] Train loss=0.283957 Test loss=0.307465 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23895615339279175
[5/23] Train loss=0.35708150267601013
[10/23] Train loss=0.293376088142395
[15/23] Train loss=0.25629758834838867
[20/23] Train loss=0.2257601022720337
Test set avg_accuracy=86.96% avg_sensitivity=69.74%, avg_specificity=92.82% avg_auc=0.9250
Best model saved!! Metric=16.018998411437316!!
Fold[9] Epoch: 18 [18/100 (18%)] Train loss=0.279288 Test loss=0.307431 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23891852796077728
[5/23] Train loss=0.3593742549419403
[10/23] Train loss=0.3085588216781616
[15/23] Train loss=0.25712141394615173
[20/23] Train loss=0.2319556176662445
Test set avg_accuracy=87.04% avg_sensitivity=68.62%, avg_specificity=93.31% avg_auc=0.9243
Fold[9] Epoch: 19 [19/100 (19%)] Train loss=0.277295 Test loss=0.307240 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22738054394721985
[5/23] Train loss=0.36774012446403503
[10/23] Train loss=0.29825255274772644
[15/23] Train loss=0.2598406672477722
[20/23] Train loss=0.22239398956298828
Test set avg_accuracy=87.21% avg_sensitivity=70.71%, avg_specificity=92.82% avg_auc=0.9255
Best model saved!! Metric=17.29626321387233!!
Fold[9] Epoch: 20 [20/100 (20%)] Train loss=0.275078 Test loss=0.305487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22059708833694458
[5/23] Train loss=0.3652089834213257
[10/23] Train loss=0.28951412439346313
[15/23] Train loss=0.2529342770576477
[20/23] Train loss=0.2205173224210739
Test set avg_accuracy=87.14% avg_sensitivity=72.38%, avg_specificity=92.16% avg_auc=0.9267
Best model saved!! Metric=18.34546124899647!!
Fold[9] Epoch: 21 [21/100 (21%)] Train loss=0.271720 Test loss=0.302305 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.22651050984859467
[5/23] Train loss=0.35666269063949585
[10/23] Train loss=0.2918414771556854
[15/23] Train loss=0.250942587852478
[20/23] Train loss=0.21800778806209564
Test set avg_accuracy=87.06% avg_sensitivity=72.76%, avg_specificity=91.92% avg_auc=0.9264
Best model saved!! Metric=18.37281967979174!!
Fold[9] Epoch: 22 [22/100 (22%)] Train loss=0.270676 Test loss=0.300261 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23020242154598236
[5/23] Train loss=0.34565985202789307
[10/23] Train loss=0.28459447622299194
[15/23] Train loss=0.24659639596939087
[20/23] Train loss=0.21775048971176147
Test set avg_accuracy=87.34% avg_sensitivity=72.20%, avg_specificity=92.49% avg_auc=0.9278
Best model saved!! Metric=18.80381197740559!!
Fold[9] Epoch: 23 [23/100 (23%)] Train loss=0.266892 Test loss=0.300198 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21821598708629608
[5/23] Train loss=0.33517277240753174
[10/23] Train loss=0.30016788840293884
[15/23] Train loss=0.24187229573726654
[20/23] Train loss=0.21563902497291565
Test set avg_accuracy=87.61% avg_sensitivity=72.20%, avg_specificity=92.85% avg_auc=0.9288
Best model saved!! Metric=19.544413703266155!!
Fold[9] Epoch: 24 [24/100 (24%)] Train loss=0.264444 Test loss=0.298552 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21858811378479004
[5/23] Train loss=0.35889744758605957
[10/23] Train loss=0.2828739881515503
[15/23] Train loss=0.251346230506897
[20/23] Train loss=0.21526719629764557
Test set avg_accuracy=87.56% avg_sensitivity=72.62%, avg_specificity=92.65% avg_auc=0.9292
Best model saved!! Metric=19.751823087343872!!
Fold[9] Epoch: 25 [25/100 (25%)] Train loss=0.264389 Test loss=0.295992 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2202838957309723
[5/23] Train loss=0.33864882588386536
[10/23] Train loss=0.2778902053833008
[15/23] Train loss=0.24569618701934814
[20/23] Train loss=0.21037128567695618
Test set avg_accuracy=87.66% avg_sensitivity=72.57%, avg_specificity=92.79% avg_auc=0.9280
Best model saved!! Metric=19.82165379602156!!
Fold[9] Epoch: 26 [26/100 (26%)] Train loss=0.262154 Test loss=0.298487 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21558378636837006
[5/23] Train loss=0.36000707745552063
[10/23] Train loss=0.27620813250541687
[15/23] Train loss=0.24108439683914185
[20/23] Train loss=0.21994462609291077
Test set avg_accuracy=87.66% avg_sensitivity=72.38%, avg_specificity=92.85% avg_auc=0.9284
Fold[9] Epoch: 27 [27/100 (27%)] Train loss=0.260337 Test loss=0.296876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21915346384048462
[5/23] Train loss=0.33893412351608276
[10/23] Train loss=0.28560009598731995
[15/23] Train loss=0.2457522451877594
[20/23] Train loss=0.20960858464241028
Test set avg_accuracy=87.53% avg_sensitivity=71.83%, avg_specificity=92.87% avg_auc=0.9270
Fold[9] Epoch: 28 [28/100 (28%)] Train loss=0.259239 Test loss=0.299416 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20974266529083252
[5/23] Train loss=0.33384066820144653
[10/23] Train loss=0.2744661867618561
[15/23] Train loss=0.23597054183483124
[20/23] Train loss=0.20264393091201782
Test set avg_accuracy=87.56% avg_sensitivity=71.64%, avg_specificity=92.98% avg_auc=0.9277
Fold[9] Epoch: 29 [29/100 (29%)] Train loss=0.256671 Test loss=0.296332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2176128476858139
[5/23] Train loss=0.3453359305858612
[10/23] Train loss=0.28300344944000244
[15/23] Train loss=0.24545976519584656
[20/23] Train loss=0.20225343108177185
Test set avg_accuracy=87.67% avg_sensitivity=71.78%, avg_specificity=93.07% avg_auc=0.9284
Fold[9] Epoch: 30 [30/100 (30%)] Train loss=0.257534 Test loss=0.294528 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20646730065345764
[5/23] Train loss=0.32921963930130005
[10/23] Train loss=0.2761322855949402
[15/23] Train loss=0.23881414532661438
[20/23] Train loss=0.21206369996070862
Test set avg_accuracy=87.74% avg_sensitivity=71.55%, avg_specificity=93.25% avg_auc=0.9291
Fold[9] Epoch: 31 [31/100 (31%)] Train loss=0.256511 Test loss=0.293642 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21547232568264008
[5/23] Train loss=0.32779479026794434
[10/23] Train loss=0.2823239266872406
[15/23] Train loss=0.24317753314971924
[20/23] Train loss=0.20583444833755493
Test set avg_accuracy=87.85% avg_sensitivity=71.55%, avg_specificity=93.39% avg_auc=0.9285
Fold[9] Epoch: 32 [32/100 (32%)] Train loss=0.255183 Test loss=0.293836 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2053026407957077
[5/23] Train loss=0.3336361050605774
[10/23] Train loss=0.2733894884586334
[15/23] Train loss=0.24668556451797485
[20/23] Train loss=0.20519939064979553
Test set avg_accuracy=87.76% avg_sensitivity=72.76%, avg_specificity=92.87% avg_auc=0.9293
Best model saved!! Metric=20.320256765565848!!
Fold[9] Epoch: 33 [33/100 (33%)] Train loss=0.253508 Test loss=0.292268 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21171781420707703
[5/23] Train loss=0.3257700800895691
[10/23] Train loss=0.27395153045654297
[15/23] Train loss=0.24015232920646667
[20/23] Train loss=0.19276629388332367
Test set avg_accuracy=87.79% avg_sensitivity=74.80%, avg_specificity=92.20% avg_auc=0.9303
Best model saved!! Metric=21.825224591288602!!
Fold[9] Epoch: 34 [34/100 (34%)] Train loss=0.249068 Test loss=0.292075 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21231608092784882
[5/23] Train loss=0.3345548212528229
[10/23] Train loss=0.2721920609474182
[15/23] Train loss=0.2371658831834793
[20/23] Train loss=0.2056252658367157
Test set avg_accuracy=87.69% avg_sensitivity=72.15%, avg_specificity=92.98% avg_auc=0.9306
Fold[9] Epoch: 35 [35/100 (35%)] Train loss=0.251085 Test loss=0.289995 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21407848596572876
[5/23] Train loss=0.3283122181892395
[10/23] Train loss=0.2849341630935669
[15/23] Train loss=0.24383096396923065
[20/23] Train loss=0.20382829010486603
Test set avg_accuracy=87.67% avg_sensitivity=73.18%, avg_specificity=92.60% avg_auc=0.9313
Fold[9] Epoch: 36 [36/100 (36%)] Train loss=0.250551 Test loss=0.289332 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1982656568288803
[5/23] Train loss=0.3264833390712738
[10/23] Train loss=0.27034640312194824
[15/23] Train loss=0.24112370610237122
[20/23] Train loss=0.20327365398406982
Test set avg_accuracy=87.82% avg_sensitivity=75.22%, avg_specificity=92.11% avg_auc=0.9311
Best model saved!! Metric=22.26005165006129!!
Fold[9] Epoch: 37 [37/100 (37%)] Train loss=0.246668 Test loss=0.291857 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21354031562805176
[5/23] Train loss=0.3184809684753418
[10/23] Train loss=0.2713921368122101
[15/23] Train loss=0.23215772211551666
[20/23] Train loss=0.20196732878684998
Test set avg_accuracy=87.82% avg_sensitivity=73.27%, avg_specificity=92.77% avg_auc=0.9311
Fold[9] Epoch: 38 [38/100 (38%)] Train loss=0.246553 Test loss=0.288178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20152057707309723
[5/23] Train loss=0.3242899179458618
[10/23] Train loss=0.27300867438316345
[15/23] Train loss=0.24162302911281586
[20/23] Train loss=0.20079517364501953
Test set avg_accuracy=87.95% avg_sensitivity=74.06%, avg_specificity=92.68% avg_auc=0.9305
Fold[9] Epoch: 39 [39/100 (39%)] Train loss=0.247988 Test loss=0.289186 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20214149355888367
[5/23] Train loss=0.3330468535423279
[10/23] Train loss=0.26703080534935
[15/23] Train loss=0.23246286809444427
[20/23] Train loss=0.19613303244113922
Test set avg_accuracy=87.82% avg_sensitivity=74.34%, avg_specificity=92.41% avg_auc=0.9300
Fold[9] Epoch: 40 [40/100 (40%)] Train loss=0.244147 Test loss=0.290385 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20462898910045624
[5/23] Train loss=0.3357231616973877
[10/23] Train loss=0.253451943397522
[15/23] Train loss=0.23020577430725098
[20/23] Train loss=0.18505321443080902
Test set avg_accuracy=87.93% avg_sensitivity=73.83%, avg_specificity=92.73% avg_auc=0.9311
Fold[9] Epoch: 41 [41/100 (41%)] Train loss=0.241019 Test loss=0.289757 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19893328845500946
[5/23] Train loss=0.32622161507606506
[10/23] Train loss=0.26542723178863525
[15/23] Train loss=0.23113727569580078
[20/23] Train loss=0.194765105843544
Test set avg_accuracy=88.06% avg_sensitivity=73.78%, avg_specificity=92.92% avg_auc=0.9296
Fold[9] Epoch: 42 [42/100 (42%)] Train loss=0.242846 Test loss=0.289600 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20201951265335083
[5/23] Train loss=0.3156396746635437
[10/23] Train loss=0.27032291889190674
[15/23] Train loss=0.23553159832954407
[20/23] Train loss=0.19888760149478912
Test set avg_accuracy=87.87% avg_sensitivity=73.31%, avg_specificity=92.82% avg_auc=0.9282
Fold[9] Epoch: 43 [43/100 (43%)] Train loss=0.242277 Test loss=0.291333 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1971939653158188
[5/23] Train loss=0.3127298355102539
[10/23] Train loss=0.2632172703742981
[15/23] Train loss=0.23204003274440765
[20/23] Train loss=0.20272275805473328
Test set avg_accuracy=87.82% avg_sensitivity=73.92%, avg_specificity=92.55% avg_auc=0.9293
Fold[9] Epoch: 44 [44/100 (44%)] Train loss=0.239447 Test loss=0.290184 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19520145654678345
[5/23] Train loss=0.30802521109580994
[10/23] Train loss=0.25823280215263367
[15/23] Train loss=0.2325761765241623
[20/23] Train loss=0.18955418467521667
Test set avg_accuracy=87.93% avg_sensitivity=73.78%, avg_specificity=92.74% avg_auc=0.9303
Fold[9] Epoch: 45 [45/100 (45%)] Train loss=0.240790 Test loss=0.288389 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1921747475862503
[5/23] Train loss=0.32207509875297546
[10/23] Train loss=0.25726330280303955
[15/23] Train loss=0.2312491089105606
[20/23] Train loss=0.19301368296146393
Test set avg_accuracy=87.87% avg_sensitivity=73.55%, avg_specificity=92.74% avg_auc=0.9298
Fold[9] Epoch: 46 [46/100 (46%)] Train loss=0.238540 Test loss=0.288858 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19261233508586884
[5/23] Train loss=0.314866304397583
[10/23] Train loss=0.25900599360466003
[15/23] Train loss=0.22234225273132324
[20/23] Train loss=0.19630178809165955
Test set avg_accuracy=88.01% avg_sensitivity=73.50%, avg_specificity=92.95% avg_auc=0.9324
Fold[9] Epoch: 47 [47/100 (47%)] Train loss=0.236772 Test loss=0.284850 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1945861279964447
[5/23] Train loss=0.31708672642707825
[10/23] Train loss=0.26626911759376526
[15/23] Train loss=0.22517706453800201
[20/23] Train loss=0.18370550870895386
Test set avg_accuracy=87.89% avg_sensitivity=73.69%, avg_specificity=92.73% avg_auc=0.9318
Fold[9] Epoch: 48 [48/100 (48%)] Train loss=0.238131 Test loss=0.286286 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19971922039985657
[5/23] Train loss=0.3172130286693573
[10/23] Train loss=0.2554421126842499
[15/23] Train loss=0.2367905080318451
[20/23] Train loss=0.18554255366325378
Test set avg_accuracy=87.96% avg_sensitivity=73.59%, avg_specificity=92.85% avg_auc=0.9310
Fold[9] Epoch: 49 [49/100 (49%)] Train loss=0.237325 Test loss=0.287048 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19482611119747162
[5/23] Train loss=0.30838924646377563
[10/23] Train loss=0.2592180371284485
[15/23] Train loss=0.23475892841815948
[20/23] Train loss=0.18653683364391327
Test set avg_accuracy=88.18% avg_sensitivity=74.66%, avg_specificity=92.77% avg_auc=0.9315
Best model saved!! Metric=22.759679107825768!!
Fold[9] Epoch: 50 [50/100 (50%)] Train loss=0.232910 Test loss=0.286425 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19068260490894318
[5/23] Train loss=0.31903567910194397
[10/23] Train loss=0.24492770433425903
[15/23] Train loss=0.23454256355762482
[20/23] Train loss=0.18718868494033813
Test set avg_accuracy=88.15% avg_sensitivity=75.27%, avg_specificity=92.54% avg_auc=0.9309
Best model saved!! Metric=23.044477217720946!!
Fold[9] Epoch: 51 [51/100 (51%)] Train loss=0.231908 Test loss=0.287953 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19658702611923218
[5/23] Train loss=0.30731549859046936
[10/23] Train loss=0.2511000335216522
[15/23] Train loss=0.22334130108356476
[20/23] Train loss=0.1848936229944229
Test set avg_accuracy=88.02% avg_sensitivity=75.96%, avg_specificity=92.13% avg_auc=0.9315
Best model saved!! Metric=23.267354206768516!!
Fold[9] Epoch: 52 [52/100 (52%)] Train loss=0.230134 Test loss=0.289128 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18866504728794098
[5/23] Train loss=0.3105042278766632
[10/23] Train loss=0.2510446012020111
[15/23] Train loss=0.22866208851337433
[20/23] Train loss=0.17820028960704803
Test set avg_accuracy=88.07% avg_sensitivity=75.17%, avg_specificity=92.46% avg_auc=0.9319
Fold[9] Epoch: 53 [53/100 (53%)] Train loss=0.229954 Test loss=0.286890 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18940550088882446
[5/23] Train loss=0.3121671676635742
[10/23] Train loss=0.2549424171447754
[15/23] Train loss=0.2320239096879959
[20/23] Train loss=0.1860300451517105
Test set avg_accuracy=88.05% avg_sensitivity=74.80%, avg_specificity=92.55% avg_auc=0.9311
Fold[9] Epoch: 54 [54/100 (54%)] Train loss=0.229193 Test loss=0.287512 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1912798285484314
[5/23] Train loss=0.2961975336074829
[10/23] Train loss=0.262299507856369
[15/23] Train loss=0.22875455021858215
[20/23] Train loss=0.1779416799545288
Test set avg_accuracy=87.96% avg_sensitivity=72.99%, avg_specificity=93.06% avg_auc=0.9283
Fold[9] Epoch: 55 [55/100 (55%)] Train loss=0.228562 Test loss=0.290018 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18829309940338135
[5/23] Train loss=0.3061583936214447
[10/23] Train loss=0.25225183367729187
[15/23] Train loss=0.24290408194065094
[20/23] Train loss=0.18149112164974213
Test set avg_accuracy=87.89% avg_sensitivity=74.43%, avg_specificity=92.47% avg_auc=0.9303
Fold[9] Epoch: 56 [56/100 (56%)] Train loss=0.230001 Test loss=0.288736 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19033624231815338
[5/23] Train loss=0.30214038491249084
[10/23] Train loss=0.24202413856983185
[15/23] Train loss=0.22129473090171814
[20/23] Train loss=0.17937511205673218
Test set avg_accuracy=87.65% avg_sensitivity=74.85%, avg_specificity=92.00% avg_auc=0.9292
Fold[9] Epoch: 57 [57/100 (57%)] Train loss=0.226104 Test loss=0.292173 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18522796034812927
[5/23] Train loss=0.29714465141296387
[10/23] Train loss=0.23951296508312225
[15/23] Train loss=0.22035682201385498
[20/23] Train loss=0.18196196854114532
Test set avg_accuracy=87.75% avg_sensitivity=74.71%, avg_specificity=92.19% avg_auc=0.9270
Fold[9] Epoch: 58 [58/100 (58%)] Train loss=0.224993 Test loss=0.295402 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1902446299791336
[5/23] Train loss=0.2901139557361603
[10/23] Train loss=0.25684159994125366
[15/23] Train loss=0.2152724713087082
[20/23] Train loss=0.18069905042648315
Test set avg_accuracy=87.65% avg_sensitivity=74.20%, avg_specificity=92.22% avg_auc=0.9263
Fold[9] Epoch: 59 [59/100 (59%)] Train loss=0.226225 Test loss=0.296172 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1862187534570694
[5/23] Train loss=0.29970845580101013
[10/23] Train loss=0.2527020275592804
[15/23] Train loss=0.22545109689235687
[20/23] Train loss=0.17713633179664612
Test set avg_accuracy=87.87% avg_sensitivity=74.94%, avg_specificity=92.27% avg_auc=0.9283
Fold[9] Epoch: 60 [60/100 (60%)] Train loss=0.224304 Test loss=0.293179 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19047540426254272
[5/23] Train loss=0.30215057730674744
[10/23] Train loss=0.24384009838104248
[15/23] Train loss=0.2215675264596939
[20/23] Train loss=0.18148519098758698
Test set avg_accuracy=87.65% avg_sensitivity=74.71%, avg_specificity=92.05% avg_auc=0.9278
Fold[9] Epoch: 61 [61/100 (61%)] Train loss=0.223067 Test loss=0.294205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18063460290431976
[5/23] Train loss=0.30618995428085327
[10/23] Train loss=0.2412649542093277
[15/23] Train loss=0.2269449234008789
[20/23] Train loss=0.17044803500175476
Test set avg_accuracy=87.63% avg_sensitivity=75.55%, avg_specificity=91.75% avg_auc=0.9261
Fold[9] Epoch: 62 [62/100 (62%)] Train loss=0.221395 Test loss=0.299324 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1790345013141632
[5/23] Train loss=0.2958073616027832
[10/23] Train loss=0.23697778582572937
[15/23] Train loss=0.2347712218761444
[20/23] Train loss=0.17569464445114136
Test set avg_accuracy=87.59% avg_sensitivity=75.13%, avg_specificity=91.82% avg_auc=0.9262
Fold[9] Epoch: 63 [63/100 (63%)] Train loss=0.222020 Test loss=0.297890 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18408791720867157
[5/23] Train loss=0.2968306243419647
[10/23] Train loss=0.24026687443256378
[15/23] Train loss=0.23076297342777252
[20/23] Train loss=0.18267422914505005
Test set avg_accuracy=87.63% avg_sensitivity=75.17%, avg_specificity=91.87% avg_auc=0.9279
Fold[9] Epoch: 64 [64/100 (64%)] Train loss=0.221818 Test loss=0.294734 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18856707215309143
[5/23] Train loss=0.29496368765830994
[10/23] Train loss=0.23624220490455627
[15/23] Train loss=0.22064343094825745
[20/23] Train loss=0.17698487639427185
Test set avg_accuracy=87.91% avg_sensitivity=75.69%, avg_specificity=92.06% avg_auc=0.9289
Fold[9] Epoch: 65 [65/100 (65%)] Train loss=0.219695 Test loss=0.293450 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18507274985313416
[5/23] Train loss=0.29197606444358826
[10/23] Train loss=0.24596209824085236
[15/23] Train loss=0.21994009613990784
[20/23] Train loss=0.1730956733226776
Test set avg_accuracy=87.55% avg_sensitivity=75.69%, avg_specificity=91.59% avg_auc=0.9255
Fold[9] Epoch: 66 [66/100 (66%)] Train loss=0.220353 Test loss=0.299756 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1848321110010147
[5/23] Train loss=0.2827185392379761
[10/23] Train loss=0.24093754589557648
[15/23] Train loss=0.22307804226875305
[20/23] Train loss=0.17378905415534973
Test set avg_accuracy=87.60% avg_sensitivity=76.06%, avg_specificity=91.52% avg_auc=0.9274
Fold[9] Epoch: 67 [67/100 (67%)] Train loss=0.216810 Test loss=0.296374 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17897002398967743
[5/23] Train loss=0.2832055985927582
[10/23] Train loss=0.23469802737236023
[15/23] Train loss=0.21749140322208405
[20/23] Train loss=0.17668862640857697
Test set avg_accuracy=87.58% avg_sensitivity=75.41%, avg_specificity=91.71% avg_auc=0.9270
Fold[9] Epoch: 68 [68/100 (68%)] Train loss=0.218328 Test loss=0.296507 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18197697401046753
[5/23] Train loss=0.2784493565559387
[10/23] Train loss=0.23699386417865753
[15/23] Train loss=0.21535886824131012
[20/23] Train loss=0.17339639365673065
Test set avg_accuracy=87.72% avg_sensitivity=75.73%, avg_specificity=91.79% avg_auc=0.9278
Fold[9] Epoch: 69 [69/100 (69%)] Train loss=0.216444 Test loss=0.295013 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17583200335502625
[5/23] Train loss=0.30273371934890747
[10/23] Train loss=0.23990114033222198
[15/23] Train loss=0.22129637002944946
[20/23] Train loss=0.17076075077056885
Test set avg_accuracy=87.55% avg_sensitivity=75.87%, avg_specificity=91.52% avg_auc=0.9266
Fold[9] Epoch: 70 [70/100 (70%)] Train loss=0.215053 Test loss=0.298747 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18282757699489594
[5/23] Train loss=0.2835436165332794
[10/23] Train loss=0.2376161366701126
[15/23] Train loss=0.22162798047065735
[20/23] Train loss=0.16970568895339966
Test set avg_accuracy=87.61% avg_sensitivity=76.94%, avg_specificity=91.24% avg_auc=0.9270
Fold[9] Epoch: 71 [71/100 (71%)] Train loss=0.212641 Test loss=0.301608 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17433789372444153
[5/23] Train loss=0.28136900067329407
[10/23] Train loss=0.22617478668689728
[15/23] Train loss=0.21070228517055511
[20/23] Train loss=0.17701156437397003
Test set avg_accuracy=87.60% avg_sensitivity=77.55%, avg_specificity=91.02% avg_auc=0.9257
Fold[9] Epoch: 72 [72/100 (72%)] Train loss=0.212122 Test loss=0.304833 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17497950792312622
[5/23] Train loss=0.29376259446144104
[10/23] Train loss=0.23318126797676086
[15/23] Train loss=0.22009316086769104
[20/23] Train loss=0.16826389729976654
Test set avg_accuracy=87.50% avg_sensitivity=76.34%, avg_specificity=91.30% avg_auc=0.9262
Fold[9] Epoch: 73 [73/100 (73%)] Train loss=0.212731 Test loss=0.301301 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17715191841125488
[5/23] Train loss=0.283782422542572
[10/23] Train loss=0.22977937757968903
[15/23] Train loss=0.2129179686307907
[20/23] Train loss=0.16989096999168396
Test set avg_accuracy=87.59% avg_sensitivity=77.41%, avg_specificity=91.05% avg_auc=0.9263
Fold[9] Epoch: 74 [74/100 (74%)] Train loss=0.210140 Test loss=0.303228 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17710521817207336
[5/23] Train loss=0.28675377368927
[10/23] Train loss=0.2380523383617401
[15/23] Train loss=0.22173485159873962
[20/23] Train loss=0.16504375636577606
Test set avg_accuracy=87.75% avg_sensitivity=76.85%, avg_specificity=91.46% avg_auc=0.9262
Fold[9] Epoch: 75 [75/100 (75%)] Train loss=0.209638 Test loss=0.301364 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18272340297698975
[5/23] Train loss=0.2608596682548523
[10/23] Train loss=0.240609273314476
[15/23] Train loss=0.22044125199317932
[20/23] Train loss=0.17288291454315186
Test set avg_accuracy=87.61% avg_sensitivity=76.43%, avg_specificity=91.41% avg_auc=0.9258
Fold[9] Epoch: 76 [76/100 (76%)] Train loss=0.208016 Test loss=0.302717 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1762172132730484
[5/23] Train loss=0.2774824798107147
[10/23] Train loss=0.23682840168476105
[15/23] Train loss=0.2098153978586197
[20/23] Train loss=0.16482989490032196
Test set avg_accuracy=87.61% avg_sensitivity=75.50%, avg_specificity=91.73% avg_auc=0.9230
Fold[9] Epoch: 77 [77/100 (77%)] Train loss=0.209980 Test loss=0.304319 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17228104174137115
[5/23] Train loss=0.28223150968551636
[10/23] Train loss=0.2343672662973404
[15/23] Train loss=0.2066202312707901
[20/23] Train loss=0.17125430703163147
Test set avg_accuracy=87.79% avg_sensitivity=76.20%, avg_specificity=91.73% avg_auc=0.9245
Fold[9] Epoch: 78 [78/100 (78%)] Train loss=0.207399 Test loss=0.301579 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17877112329006195
[5/23] Train loss=0.2828184962272644
[10/23] Train loss=0.2435418665409088
[15/23] Train loss=0.21440894901752472
[20/23] Train loss=0.1554143726825714
Test set avg_accuracy=87.69% avg_sensitivity=76.57%, avg_specificity=91.48% avg_auc=0.9249
Fold[9] Epoch: 79 [79/100 (79%)] Train loss=0.207783 Test loss=0.302210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17198196053504944
[5/23] Train loss=0.27731433510780334
[10/23] Train loss=0.2426837533712387
[15/23] Train loss=0.218263640999794
[20/23] Train loss=0.16087934374809265
Test set avg_accuracy=87.98% avg_sensitivity=76.10%, avg_specificity=92.01% avg_auc=0.9264
Fold[9] Epoch: 80 [80/100 (80%)] Train loss=0.206080 Test loss=0.298442 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16793935000896454
[5/23] Train loss=0.26083219051361084
[10/23] Train loss=0.22598038613796234
[15/23] Train loss=0.2120317816734314
[20/23] Train loss=0.16655763983726501
Test set avg_accuracy=87.66% avg_sensitivity=76.99%, avg_specificity=91.29% avg_auc=0.9250
Fold[9] Epoch: 81 [81/100 (81%)] Train loss=0.202990 Test loss=0.303045 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16449381411075592
[5/23] Train loss=0.25770795345306396
[10/23] Train loss=0.21679502725601196
[15/23] Train loss=0.20675936341285706
[20/23] Train loss=0.15740449726581573
Test set avg_accuracy=87.66% avg_sensitivity=77.22%, avg_specificity=91.21% avg_auc=0.9245
Fold[9] Epoch: 82 [82/100 (82%)] Train loss=0.199733 Test loss=0.306945 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17377027869224548
[5/23] Train loss=0.26626649498939514
[10/23] Train loss=0.22973112761974335
[15/23] Train loss=0.20925647020339966
[20/23] Train loss=0.1518198400735855
Test set avg_accuracy=87.73% avg_sensitivity=76.15%, avg_specificity=91.67% avg_auc=0.9235
Fold[9] Epoch: 83 [83/100 (83%)] Train loss=0.201031 Test loss=0.304576 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16592328250408173
[5/23] Train loss=0.2741551101207733
[10/23] Train loss=0.21921798586845398
[15/23] Train loss=0.21184656023979187
[20/23] Train loss=0.1552014797925949
Test set avg_accuracy=87.85% avg_sensitivity=76.62%, avg_specificity=91.67% avg_auc=0.9249
Fold[9] Epoch: 84 [84/100 (84%)] Train loss=0.199545 Test loss=0.304021 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1678772270679474
[5/23] Train loss=0.2583347260951996
[10/23] Train loss=0.21761570870876312
[15/23] Train loss=0.2085886001586914
[20/23] Train loss=0.14745719730854034
Test set avg_accuracy=87.71% avg_sensitivity=76.15%, avg_specificity=91.64% avg_auc=0.9190
Fold[9] Epoch: 85 [85/100 (85%)] Train loss=0.198894 Test loss=0.313823 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1767902672290802
[5/23] Train loss=0.2659541368484497
[10/23] Train loss=0.22123339772224426
[15/23] Train loss=0.22416023910045624
[20/23] Train loss=0.1607333868741989
Test set avg_accuracy=87.46% avg_sensitivity=76.57%, avg_specificity=91.16% avg_auc=0.9231
Fold[9] Epoch: 86 [86/100 (86%)] Train loss=0.201602 Test loss=0.307859 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16393369436264038
[5/23] Train loss=0.27637097239494324
[10/23] Train loss=0.21704959869384766
[15/23] Train loss=0.20336748659610748
[20/23] Train loss=0.16128675639629364
Test set avg_accuracy=87.45% avg_sensitivity=77.92%, avg_specificity=90.69% avg_auc=0.9191
Fold[9] Epoch: 87 [87/100 (87%)] Train loss=0.198290 Test loss=0.318756 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1620458960533142
[5/23] Train loss=0.2667398750782013
[10/23] Train loss=0.22571948170661926
[15/23] Train loss=0.21170328557491302
[20/23] Train loss=0.16145433485507965
Test set avg_accuracy=87.66% avg_sensitivity=76.85%, avg_specificity=91.33% avg_auc=0.9213
Fold[9] Epoch: 88 [88/100 (88%)] Train loss=0.199668 Test loss=0.313090 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17025429010391235
[5/23] Train loss=0.2744462490081787
[10/23] Train loss=0.21968480944633484
[15/23] Train loss=0.21066337823867798
[20/23] Train loss=0.16192834079265594
Test set avg_accuracy=87.73% avg_sensitivity=76.71%, avg_specificity=91.48% avg_auc=0.9277
Fold[9] Epoch: 89 [89/100 (89%)] Train loss=0.199874 Test loss=0.301087 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17009510099887848
[5/23] Train loss=0.25674644112586975
[10/23] Train loss=0.21948476135730743
[15/23] Train loss=0.20192086696624756
[20/23] Train loss=0.15349453687667847
Test set avg_accuracy=87.46% avg_sensitivity=78.43%, avg_specificity=90.53% avg_auc=0.9237
Fold[9] Epoch: 90 [90/100 (90%)] Train loss=0.194759 Test loss=0.314100 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16729409992694855
[5/23] Train loss=0.254913866519928
[10/23] Train loss=0.2154320329427719
[15/23] Train loss=0.20070356130599976
[20/23] Train loss=0.15572692453861237
Test set avg_accuracy=86.95% avg_sensitivity=79.92%, avg_specificity=89.34% avg_auc=0.9219
Fold[9] Epoch: 91 [91/100 (91%)] Train loss=0.192132 Test loss=0.326050 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16732211410999298
[5/23] Train loss=0.24068620800971985
[10/23] Train loss=0.2199840396642685
[15/23] Train loss=0.2018403261899948
[20/23] Train loss=0.1560879349708557
Test set avg_accuracy=87.23% avg_sensitivity=78.06%, avg_specificity=90.35% avg_auc=0.9186
Fold[9] Epoch: 92 [92/100 (92%)] Train loss=0.192732 Test loss=0.321583 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16319765150547028
[5/23] Train loss=0.2621558606624603
[10/23] Train loss=0.21362923085689545
[15/23] Train loss=0.20457039773464203
[20/23] Train loss=0.15333634614944458
Test set avg_accuracy=87.69% avg_sensitivity=76.99%, avg_specificity=91.33% avg_auc=0.9257
Fold[9] Epoch: 93 [93/100 (93%)] Train loss=0.191731 Test loss=0.306181 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16295935213565826
[5/23] Train loss=0.26183903217315674
[10/23] Train loss=0.22228334844112396
[15/23] Train loss=0.21572016179561615
[20/23] Train loss=0.15439684689044952
Test set avg_accuracy=87.26% avg_sensitivity=75.69%, avg_specificity=91.19% avg_auc=0.9198
Fold[9] Epoch: 94 [94/100 (94%)] Train loss=0.194226 Test loss=0.314569 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15373679995536804
[5/23] Train loss=0.26388949155807495
[10/23] Train loss=0.22400619089603424
[15/23] Train loss=0.20521673560142517
[20/23] Train loss=0.1535249501466751
Test set avg_accuracy=87.36% avg_sensitivity=76.71%, avg_specificity=90.99% avg_auc=0.9194
Fold[9] Epoch: 95 [95/100 (95%)] Train loss=0.189528 Test loss=0.318060 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16949376463890076
[5/23] Train loss=0.2463523894548416
[10/23] Train loss=0.21836894750595093
[15/23] Train loss=0.20639252662658691
[20/23] Train loss=0.14302422106266022
Test set avg_accuracy=87.02% avg_sensitivity=78.61%, avg_specificity=89.88% avg_auc=0.9144
Fold[9] Epoch: 96 [96/100 (96%)] Train loss=0.188558 Test loss=0.334178 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16550029814243317
[5/23] Train loss=0.25317108631134033
[10/23] Train loss=0.21295875310897827
[15/23] Train loss=0.20634986460208893
[20/23] Train loss=0.14947885274887085
Test set avg_accuracy=86.62% avg_sensitivity=78.20%, avg_specificity=89.48% avg_auc=0.9158
Fold[9] Epoch: 97 [97/100 (97%)] Train loss=0.187739 Test loss=0.333429 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17188797891139984
[5/23] Train loss=0.2557052969932556
[10/23] Train loss=0.21394778788089752
[15/23] Train loss=0.18944360315799713
[20/23] Train loss=0.14579948782920837
Test set avg_accuracy=86.71% avg_sensitivity=77.59%, avg_specificity=89.82% avg_auc=0.9180
Fold[9] Epoch: 98 [98/100 (98%)] Train loss=0.186783 Test loss=0.328381 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16087935864925385
[5/23] Train loss=0.2456061840057373
[10/23] Train loss=0.2024170458316803
[15/23] Train loss=0.1961786299943924
[20/23] Train loss=0.14418745040893555
Test set avg_accuracy=87.16% avg_sensitivity=78.34%, avg_specificity=90.16% avg_auc=0.9185
Fold[9] Epoch: 99 [99/100 (99%)] Train loss=0.183656 Test loss=0.329164 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15386855602264404
[5/23] Train loss=0.24619229137897491
[10/23] Train loss=0.21647536754608154
[15/23] Train loss=0.19758203625679016
[20/23] Train loss=0.1454126238822937
Test set avg_accuracy=86.70% avg_sensitivity=78.52%, avg_specificity=89.48% avg_auc=0.9167
Fold[9] Epoch: 100 [100/100 (100%)] Train loss=0.182464 Test loss=0.334267 Current lr=[3.9999999999999996e-05]

Fold[9] Best Result: acc=88.02359882005901 sen=75.96466759646677, spe=92.12523719165085, auc=0.9315385059859189!
[0/23] Train loss=0.7139924764633179
[5/23] Train loss=0.6960575580596924
[10/23] Train loss=0.5550875663757324
[15/23] Train loss=0.5551259517669678
[20/23] Train loss=0.577392578125
Test set avg_accuracy=77.55% avg_sensitivity=0.00%, avg_specificity=100.00% avg_auc=0.6181
Best model saved!! Metric=-86.63200481485177!!
Fold[10] Epoch: 1 [1/100 (1%)] Train loss=0.577101 Test loss=0.559703 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.525987446308136
[5/23] Train loss=0.5372458100318909
[10/23] Train loss=0.49460533261299133
[15/23] Train loss=0.4544009268283844
[20/23] Train loss=0.5011856555938721
Test set avg_accuracy=78.22% avg_sensitivity=22.40%, avg_specificity=94.38% avg_auc=0.8051
Best model saved!! Metric=-50.48620247222197!!
Fold[10] Epoch: 2 [2/100 (2%)] Train loss=0.477972 Test loss=0.480534 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.41555526852607727
[5/23] Train loss=0.4378916025161743
[10/23] Train loss=0.44765505194664
[15/23] Train loss=0.38729944825172424
[20/23] Train loss=0.4751136302947998
Test set avg_accuracy=80.61% avg_sensitivity=39.62%, avg_specificity=92.47% avg_auc=0.8515
Best model saved!! Metric=-28.145635490908607!!
Fold[10] Epoch: 3 [3/100 (3%)] Train loss=0.410648 Test loss=0.457210 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3608626127243042
[5/23] Train loss=0.4432094991207123
[10/23] Train loss=0.43234512209892273
[15/23] Train loss=0.3743123710155487
[20/23] Train loss=0.438993901014328
Test set avg_accuracy=83.45% avg_sensitivity=50.51%, avg_specificity=92.98% avg_auc=0.8796
Best model saved!! Metric=-11.099402883330143!!
Fold[10] Epoch: 4 [4/100 (4%)] Train loss=0.387415 Test loss=0.382877 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3586674928665161
[5/23] Train loss=0.44166240096092224
[10/23] Train loss=0.3961011469364166
[15/23] Train loss=0.3512097895145416
[20/23] Train loss=0.4181104898452759
Test set avg_accuracy=86.15% avg_sensitivity=55.29%, avg_specificity=95.08% avg_auc=0.9036
Best model saved!! Metric=0.8761804189754283!!
Fold[10] Epoch: 5 [5/100 (5%)] Train loss=0.368016 Test loss=0.341076 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.32110121846199036
[5/23] Train loss=0.4092499017715454
[10/23] Train loss=0.38324466347694397
[15/23] Train loss=0.3449433743953705
[20/23] Train loss=0.4334934949874878
Test set avg_accuracy=87.30% avg_sensitivity=57.50%, avg_specificity=95.93% avg_auc=0.9223
Best model saved!! Metric=6.955461663710236!!
Fold[10] Epoch: 6 [6/100 (6%)] Train loss=0.350924 Test loss=0.308876 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.3050547242164612
[5/23] Train loss=0.3894539773464203
[10/23] Train loss=0.38249513506889343
[15/23] Train loss=0.3156272768974304
[20/23] Train loss=0.4128499925136566
Test set avg_accuracy=87.91% avg_sensitivity=60.64%, avg_specificity=95.81% avg_auc=0.9281
Best model saved!! Metric=11.164280894059063!!
Fold[10] Epoch: 7 [7/100 (7%)] Train loss=0.338796 Test loss=0.293000 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.29144206643104553
[5/23] Train loss=0.3934391438961029
[10/23] Train loss=0.3748091161251068
[15/23] Train loss=0.30964601039886475
[20/23] Train loss=0.39916306734085083
Test set avg_accuracy=88.37% avg_sensitivity=63.41%, avg_specificity=95.60% avg_auc=0.9312
Best model saved!! Metric=14.506496059760089!!
Fold[10] Epoch: 8 [8/100 (8%)] Train loss=0.329334 Test loss=0.282344 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.28101953864097595
[5/23] Train loss=0.3977964222431183
[10/23] Train loss=0.3483760356903076
[15/23] Train loss=0.29058197140693665
[20/23] Train loss=0.38911715149879456
Test set avg_accuracy=88.81% avg_sensitivity=68.14%, avg_specificity=94.79% avg_auc=0.9370
Best model saved!! Metric=19.442277121739203!!
Fold[10] Epoch: 9 [9/100 (9%)] Train loss=0.319851 Test loss=0.264428 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.27385449409484863
[5/23] Train loss=0.37148594856262207
[10/23] Train loss=0.33984750509262085
[15/23] Train loss=0.2908545434474945
[20/23] Train loss=0.39430901408195496
Test set avg_accuracy=89.24% avg_sensitivity=68.86%, avg_specificity=95.14% avg_auc=0.9393
Best model saved!! Metric=21.163061603325907!!
Fold[10] Epoch: 10 [10/100 (10%)] Train loss=0.311439 Test loss=0.260367 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2622949779033661
[5/23] Train loss=0.3736981153488159
[10/23] Train loss=0.3294789493083954
[15/23] Train loss=0.27535176277160645
[20/23] Train loss=0.38451844453811646
Test set avg_accuracy=89.48% avg_sensitivity=69.94%, avg_specificity=95.14% avg_auc=0.9422
Best model saved!! Metric=22.773027859863543!!
Fold[10] Epoch: 11 [11/100 (11%)] Train loss=0.304219 Test loss=0.252670 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2563047409057617
[5/23] Train loss=0.37457287311553955
[10/23] Train loss=0.3229142725467682
[15/23] Train loss=0.2838687300682068
[20/23] Train loss=0.380388081073761
Test set avg_accuracy=89.54% avg_sensitivity=70.09%, avg_specificity=95.17% avg_auc=0.9434
Best model saved!! Metric=23.13367307925668!!
Fold[10] Epoch: 12 [12/100 (12%)] Train loss=0.303648 Test loss=0.249850 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24955804646015167
[5/23] Train loss=0.3647518455982208
[10/23] Train loss=0.31695038080215454
[15/23] Train loss=0.27152571082115173
[20/23] Train loss=0.38469791412353516
Test set avg_accuracy=89.93% avg_sensitivity=72.10%, avg_specificity=95.09% avg_auc=0.9456
Best model saved!! Metric=25.676086451334978!!
Fold[10] Epoch: 13 [13/100 (13%)] Train loss=0.295781 Test loss=0.243422 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2481115162372589
[5/23] Train loss=0.3567506670951843
[10/23] Train loss=0.3168698251247406
[15/23] Train loss=0.27876225113868713
[20/23] Train loss=0.37483417987823486
Test set avg_accuracy=89.98% avg_sensitivity=71.99%, avg_specificity=95.18% avg_auc=0.9445
Fold[10] Epoch: 14 [14/100 (14%)] Train loss=0.292426 Test loss=0.245016 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.25206512212753296
[5/23] Train loss=0.37018656730651855
[10/23] Train loss=0.3186505138874054
[15/23] Train loss=0.2676524519920349
[20/23] Train loss=0.3707664906978607
Test set avg_accuracy=90.17% avg_sensitivity=72.92%, avg_specificity=95.17% avg_auc=0.9474
Best model saved!! Metric=26.99657408426181!!
Fold[10] Epoch: 15 [15/100 (15%)] Train loss=0.290872 Test loss=0.239491 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.24168352782726288
[5/23] Train loss=0.36444342136383057
[10/23] Train loss=0.3093380630016327
[15/23] Train loss=0.27249810099601746
[20/23] Train loss=0.3724028468132019
Test set avg_accuracy=90.20% avg_sensitivity=73.12%, avg_specificity=95.14% avg_auc=0.9483
Best model saved!! Metric=27.28948744683035!!
Fold[10] Epoch: 16 [16/100 (16%)] Train loss=0.290150 Test loss=0.236486 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23826494812965393
[5/23] Train loss=0.3691503703594208
[10/23] Train loss=0.2974892854690552
[15/23] Train loss=0.2511441111564636
[20/23] Train loss=0.3791540265083313
Test set avg_accuracy=90.31% avg_sensitivity=73.74%, avg_specificity=95.11% avg_auc=0.9472
Best model saved!! Metric=27.875859050904445!!
Fold[10] Epoch: 17 [17/100 (17%)] Train loss=0.284077 Test loss=0.236544 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.231096088886261
[5/23] Train loss=0.358871728181839
[10/23] Train loss=0.2955784499645233
[15/23] Train loss=0.26230230927467346
[20/23] Train loss=0.3572936952114105
Test set avg_accuracy=90.48% avg_sensitivity=74.15%, avg_specificity=95.21% avg_auc=0.9473
Best model saved!! Metric=28.579435035982613!!
Fold[10] Epoch: 18 [18/100 (18%)] Train loss=0.279737 Test loss=0.235693 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23076269030570984
[5/23] Train loss=0.34896910190582275
[10/23] Train loss=0.3013485074043274
[15/23] Train loss=0.2554728090763092
[20/23] Train loss=0.35208985209465027
Test set avg_accuracy=90.53% avg_sensitivity=73.59%, avg_specificity=95.43% avg_auc=0.9475
Fold[10] Epoch: 19 [19/100 (19%)] Train loss=0.275680 Test loss=0.235856 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2214714139699936
[5/23] Train loss=0.3615264296531677
[10/23] Train loss=0.30272260308265686
[15/23] Train loss=0.26910853385925293
[20/23] Train loss=0.3574836254119873
Test set avg_accuracy=90.50% avg_sensitivity=74.51%, avg_specificity=95.12% avg_auc=0.9489
Best model saved!! Metric=29.020448712106134!!
Fold[10] Epoch: 20 [20/100 (20%)] Train loss=0.279081 Test loss=0.231807 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.23210524022579193
[5/23] Train loss=0.3517187237739563
[10/23] Train loss=0.2848207354545593
[15/23] Train loss=0.257621169090271
[20/23] Train loss=0.3549094498157501
Test set avg_accuracy=90.53% avg_sensitivity=74.31%, avg_specificity=95.23% avg_auc=0.9473
Fold[10] Epoch: 21 [21/100 (21%)] Train loss=0.274174 Test loss=0.234353 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21467050909996033
[5/23] Train loss=0.34450089931488037
[10/23] Train loss=0.2819522023200989
[15/23] Train loss=0.2554694712162018
[20/23] Train loss=0.34093597531318665
Test set avg_accuracy=90.51% avg_sensitivity=75.13%, avg_specificity=94.96% avg_auc=0.9484
Best model saved!! Metric=29.431305499038903!!
Fold[10] Epoch: 22 [22/100 (22%)] Train loss=0.269519 Test loss=0.231235 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21406947076320648
[5/23] Train loss=0.34191158413887024
[10/23] Train loss=0.2942616045475006
[15/23] Train loss=0.2525330185890198
[20/23] Train loss=0.34403911232948303
Test set avg_accuracy=90.48% avg_sensitivity=75.64%, avg_specificity=94.78% avg_auc=0.9487
Best model saved!! Metric=29.77975717820086!!
Fold[10] Epoch: 23 [23/100 (23%)] Train loss=0.269752 Test loss=0.231943 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21426039934158325
[5/23] Train loss=0.34986287355422974
[10/23] Train loss=0.2818404734134674
[15/23] Train loss=0.24142728745937347
[20/23] Train loss=0.3456617295742035
Test set avg_accuracy=90.62% avg_sensitivity=75.69%, avg_specificity=94.94% avg_auc=0.9483
Best model saved!! Metric=30.086863701654337!!
Fold[10] Epoch: 24 [24/100 (24%)] Train loss=0.267512 Test loss=0.231681 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21431392431259155
[5/23] Train loss=0.3373095989227295
[10/23] Train loss=0.28546321392059326
[15/23] Train loss=0.24620074033737183
[20/23] Train loss=0.3436778485774994
Test set avg_accuracy=90.57% avg_sensitivity=74.77%, avg_specificity=95.14% avg_auc=0.9504
Fold[10] Epoch: 25 [25/100 (25%)] Train loss=0.267836 Test loss=0.227809 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21448445320129395
[5/23] Train loss=0.3452349901199341
[10/23] Train loss=0.28272172808647156
[15/23] Train loss=0.24475610256195068
[20/23] Train loss=0.34395715594291687
Test set avg_accuracy=90.48% avg_sensitivity=74.56%, avg_specificity=95.09% avg_auc=0.9499
Fold[10] Epoch: 26 [26/100 (26%)] Train loss=0.265768 Test loss=0.228099 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2150597870349884
[5/23] Train loss=0.33872780203819275
[10/23] Train loss=0.27808624505996704
[15/23] Train loss=0.24512936174869537
[20/23] Train loss=0.3352468013763428
Test set avg_accuracy=90.63% avg_sensitivity=75.80%, avg_specificity=94.93% avg_auc=0.9493
Best model saved!! Metric=30.289610440550085!!
Fold[10] Epoch: 27 [27/100 (27%)] Train loss=0.261001 Test loss=0.229649 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21487195789813995
[5/23] Train loss=0.3313087522983551
[10/23] Train loss=0.2708906829357147
[15/23] Train loss=0.24603450298309326
[20/23] Train loss=0.34377607703208923
Test set avg_accuracy=90.62% avg_sensitivity=76.00%, avg_specificity=94.85% avg_auc=0.9500
Best model saved!! Metric=30.477237219106218!!
Fold[10] Epoch: 28 [28/100 (28%)] Train loss=0.260645 Test loss=0.226882 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21226032078266144
[5/23] Train loss=0.3418635427951813
[10/23] Train loss=0.2712017893791199
[15/23] Train loss=0.24882470071315765
[20/23] Train loss=0.35147109627723694
Test set avg_accuracy=90.84% avg_sensitivity=75.64%, avg_specificity=95.24% avg_auc=0.9495
Best model saved!! Metric=30.67415197526399!!
Fold[10] Epoch: 29 [29/100 (29%)] Train loss=0.260138 Test loss=0.228728 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20708692073822021
[5/23] Train loss=0.33303001523017883
[10/23] Train loss=0.2758990228176117
[15/23] Train loss=0.2547720968723297
[20/23] Train loss=0.34013092517852783
Test set avg_accuracy=90.81% avg_sensitivity=75.90%, avg_specificity=95.12% avg_auc=0.9496
Best model saved!! Metric=30.79344479970573!!
Fold[10] Epoch: 30 [30/100 (30%)] Train loss=0.260826 Test loss=0.228046 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.2088538557291031
[5/23] Train loss=0.34514865279197693
[10/23] Train loss=0.2804137170314789
[15/23] Train loss=0.2457459270954132
[20/23] Train loss=0.3399026691913605
Test set avg_accuracy=90.91% avg_sensitivity=76.67%, avg_specificity=95.03% avg_auc=0.9505
Best model saved!! Metric=31.666809597251977!!
Fold[10] Epoch: 31 [31/100 (31%)] Train loss=0.259995 Test loss=0.226877 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.21174168586730957
[5/23] Train loss=0.3404017984867096
[10/23] Train loss=0.26083916425704956
[15/23] Train loss=0.23794633150100708
[20/23] Train loss=0.33680522441864014
Test set avg_accuracy=90.89% avg_sensitivity=77.49%, avg_specificity=94.77% avg_auc=0.9500
Best model saved!! Metric=32.141956894509406!!
Fold[10] Epoch: 32 [32/100 (32%)] Train loss=0.256278 Test loss=0.227417 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1989157497882843
[5/23] Train loss=0.3264738619327545
[10/23] Train loss=0.2724863290786743
[15/23] Train loss=0.24284319579601288
[20/23] Train loss=0.3354128897190094
Test set avg_accuracy=90.88% avg_sensitivity=76.31%, avg_specificity=95.09% avg_auc=0.9501
Fold[10] Epoch: 33 [33/100 (33%)] Train loss=0.253845 Test loss=0.227118 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20186075568199158
[5/23] Train loss=0.33957749605178833
[10/23] Train loss=0.26949867606163025
[15/23] Train loss=0.24418456852436066
[20/23] Train loss=0.3480483889579773
Test set avg_accuracy=90.85% avg_sensitivity=76.52%, avg_specificity=95.00% avg_auc=0.9496
Fold[10] Epoch: 34 [34/100 (34%)] Train loss=0.254754 Test loss=0.227748 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19296826422214508
[5/23] Train loss=0.3296130895614624
[10/23] Train loss=0.27060970664024353
[15/23] Train loss=0.24214574694633484
[20/23] Train loss=0.34079623222351074
Test set avg_accuracy=91.03% avg_sensitivity=76.05%, avg_specificity=95.36% avg_auc=0.9486
Fold[10] Epoch: 35 [35/100 (35%)] Train loss=0.251585 Test loss=0.229309 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19892500340938568
[5/23] Train loss=0.3420826494693756
[10/23] Train loss=0.26313838362693787
[15/23] Train loss=0.24169640243053436
[20/23] Train loss=0.3296569585800171
Test set avg_accuracy=90.92% avg_sensitivity=76.41%, avg_specificity=95.12% avg_auc=0.9499
Fold[10] Epoch: 36 [36/100 (36%)] Train loss=0.252049 Test loss=0.227251 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20028215646743774
[5/23] Train loss=0.31836196780204773
[10/23] Train loss=0.2697903513908386
[15/23] Train loss=0.24410322308540344
[20/23] Train loss=0.3239187002182007
Test set avg_accuracy=91.06% avg_sensitivity=77.49%, avg_specificity=94.99% avg_auc=0.9488
Best model saved!! Metric=32.42141818986575!!
Fold[10] Epoch: 37 [37/100 (37%)] Train loss=0.250340 Test loss=0.228782 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.20434525609016418
[5/23] Train loss=0.3193508982658386
[10/23] Train loss=0.26422151923179626
[15/23] Train loss=0.23172251880168915
[20/23] Train loss=0.3248898386955261
Test set avg_accuracy=91.03% avg_sensitivity=77.75%, avg_specificity=94.87% avg_auc=0.9488
Best model saved!! Metric=32.52754316836839!!
Fold[10] Epoch: 38 [38/100 (38%)] Train loss=0.247590 Test loss=0.228952 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1992781162261963
[5/23] Train loss=0.3178096115589142
[10/23] Train loss=0.26885437965393066
[15/23] Train loss=0.23360899090766907
[20/23] Train loss=0.3272787630558014
Test set avg_accuracy=91.13% avg_sensitivity=76.16%, avg_specificity=95.46% avg_auc=0.9501
Fold[10] Epoch: 39 [39/100 (39%)] Train loss=0.246096 Test loss=0.226493 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19555935263633728
[5/23] Train loss=0.3262186050415039
[10/23] Train loss=0.26669764518737793
[15/23] Train loss=0.25076308846473694
[20/23] Train loss=0.32412368059158325
Test set avg_accuracy=90.92% avg_sensitivity=75.33%, avg_specificity=95.43% avg_auc=0.9500
Fold[10] Epoch: 40 [40/100 (40%)] Train loss=0.246066 Test loss=0.227209 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19487547874450684
[5/23] Train loss=0.32975441217422485
[10/23] Train loss=0.2561756372451782
[15/23] Train loss=0.235735684633255
[20/23] Train loss=0.3131974935531616
Test set avg_accuracy=91.08% avg_sensitivity=76.41%, avg_specificity=95.33% avg_auc=0.9502
Fold[10] Epoch: 41 [41/100 (41%)] Train loss=0.247997 Test loss=0.225151 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1971822828054428
[5/23] Train loss=0.32168570160865784
[10/23] Train loss=0.25742748379707336
[15/23] Train loss=0.23242077231407166
[20/23] Train loss=0.3226182758808136
Test set avg_accuracy=91.00% avg_sensitivity=77.08%, avg_specificity=95.03% avg_auc=0.9494
Fold[10] Epoch: 42 [42/100 (42%)] Train loss=0.245408 Test loss=0.227758 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19916363060474396
[5/23] Train loss=0.3107742965221405
[10/23] Train loss=0.2571050822734833
[15/23] Train loss=0.22991140186786652
[20/23] Train loss=0.3258901536464691
Test set avg_accuracy=91.00% avg_sensitivity=77.18%, avg_specificity=95.00% avg_auc=0.9513
Fold[10] Epoch: 43 [43/100 (43%)] Train loss=0.242471 Test loss=0.224337 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19707314670085907
[5/23] Train loss=0.3077511787414551
[10/23] Train loss=0.25825396180152893
[15/23] Train loss=0.23499219119548798
[20/23] Train loss=0.317295104265213
Test set avg_accuracy=91.06% avg_sensitivity=76.41%, avg_specificity=95.30% avg_auc=0.9488
Fold[10] Epoch: 44 [44/100 (44%)] Train loss=0.240531 Test loss=0.228143 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19689054787158966
[5/23] Train loss=0.30456575751304626
[10/23] Train loss=0.26040583848953247
[15/23] Train loss=0.23450995981693268
[20/23] Train loss=0.31173646450042725
Test set avg_accuracy=91.03% avg_sensitivity=75.49%, avg_specificity=95.52% avg_auc=0.9492
Fold[10] Epoch: 45 [45/100 (45%)] Train loss=0.240452 Test loss=0.227278 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18899156153202057
[5/23] Train loss=0.3111627399921417
[10/23] Train loss=0.2578525245189667
[15/23] Train loss=0.23726420104503632
[20/23] Train loss=0.322847455739975
Test set avg_accuracy=91.01% avg_sensitivity=75.39%, avg_specificity=95.54% avg_auc=0.9493
Fold[10] Epoch: 46 [46/100 (46%)] Train loss=0.237827 Test loss=0.227148 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19743669033050537
[5/23] Train loss=0.3289458453655243
[10/23] Train loss=0.25090619921684265
[15/23] Train loss=0.22854554653167725
[20/23] Train loss=0.32500576972961426
Test set avg_accuracy=90.91% avg_sensitivity=77.39%, avg_specificity=94.82% avg_auc=0.9501
Fold[10] Epoch: 47 [47/100 (47%)] Train loss=0.240087 Test loss=0.226466 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1897609680891037
[5/23] Train loss=0.31285351514816284
[10/23] Train loss=0.24997511506080627
[15/23] Train loss=0.2384597361087799
[20/23] Train loss=0.3207618296146393
Test set avg_accuracy=91.06% avg_sensitivity=76.62%, avg_specificity=95.24% avg_auc=0.9489
Fold[10] Epoch: 48 [48/100 (48%)] Train loss=0.236658 Test loss=0.228171 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19150541722774506
[5/23] Train loss=0.3160686492919922
[10/23] Train loss=0.2566603124141693
[15/23] Train loss=0.23040242493152618
[20/23] Train loss=0.31788867712020874
Test set avg_accuracy=91.04% avg_sensitivity=76.36%, avg_specificity=95.29% avg_auc=0.9489
Fold[10] Epoch: 49 [49/100 (49%)] Train loss=0.235988 Test loss=0.228287 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18678681552410126
[5/23] Train loss=0.30542120337486267
[10/23] Train loss=0.24674582481384277
[15/23] Train loss=0.23665885627269745
[20/23] Train loss=0.31148314476013184
Test set avg_accuracy=91.10% avg_sensitivity=76.46%, avg_specificity=95.33% avg_auc=0.9490
Fold[10] Epoch: 50 [50/100 (50%)] Train loss=0.234327 Test loss=0.227948 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.186942458152771
[5/23] Train loss=0.3150031864643097
[10/23] Train loss=0.25620728731155396
[15/23] Train loss=0.22312340140342712
[20/23] Train loss=0.32172948122024536
Test set avg_accuracy=90.97% avg_sensitivity=76.21%, avg_specificity=95.24% avg_auc=0.9508
Fold[10] Epoch: 51 [51/100 (51%)] Train loss=0.234539 Test loss=0.225067 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18405307829380035
[5/23] Train loss=0.29793781042099
[10/23] Train loss=0.25213074684143066
[15/23] Train loss=0.23636949062347412
[20/23] Train loss=0.31499266624450684
Test set avg_accuracy=90.99% avg_sensitivity=76.67%, avg_specificity=95.14% avg_auc=0.9486
Fold[10] Epoch: 52 [52/100 (52%)] Train loss=0.233387 Test loss=0.228625 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.19050249457359314
[5/23] Train loss=0.30163609981536865
[10/23] Train loss=0.2576214671134949
[15/23] Train loss=0.23514656722545624
[20/23] Train loss=0.30843842029571533
Test set avg_accuracy=91.28% avg_sensitivity=76.98%, avg_specificity=95.42% avg_auc=0.9508
Best model saved!! Metric=32.75701183889117!!
Fold[10] Epoch: 53 [53/100 (53%)] Train loss=0.232276 Test loss=0.224659 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18282550573349
[5/23] Train loss=0.3133338391780853
[10/23] Train loss=0.25685936212539673
[15/23] Train loss=0.2290918380022049
[20/23] Train loss=0.3079983592033386
Test set avg_accuracy=91.08% avg_sensitivity=76.77%, avg_specificity=95.23% avg_auc=0.9483
Fold[10] Epoch: 54 [54/100 (54%)] Train loss=0.230076 Test loss=0.229478 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.184272900223732
[5/23] Train loss=0.3037129342556
[10/23] Train loss=0.2557470202445984
[15/23] Train loss=0.2221299260854721
[20/23] Train loss=0.29644903540611267
Test set avg_accuracy=90.99% avg_sensitivity=77.03%, avg_specificity=95.03% avg_auc=0.9492
Fold[10] Epoch: 55 [55/100 (55%)] Train loss=0.230200 Test loss=0.228588 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18292056024074554
[5/23] Train loss=0.29200810194015503
[10/23] Train loss=0.24665039777755737
[15/23] Train loss=0.2250068485736847
[20/23] Train loss=0.31411758065223694
Test set avg_accuracy=91.05% avg_sensitivity=76.57%, avg_specificity=95.24% avg_auc=0.9499
Fold[10] Epoch: 56 [56/100 (56%)] Train loss=0.227525 Test loss=0.227518 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17935025691986084
[5/23] Train loss=0.3010902404785156
[10/23] Train loss=0.2449006885290146
[15/23] Train loss=0.2202053666114807
[20/23] Train loss=0.30574092268943787
Test set avg_accuracy=90.99% avg_sensitivity=77.75%, avg_specificity=94.82% avg_auc=0.9495
Fold[10] Epoch: 57 [57/100 (57%)] Train loss=0.228525 Test loss=0.227796 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1876523494720459
[5/23] Train loss=0.3032902479171753
[10/23] Train loss=0.24228480458259583
[15/23] Train loss=0.22255758941173553
[20/23] Train loss=0.3090694546699524
Test set avg_accuracy=91.14% avg_sensitivity=76.67%, avg_specificity=95.33% avg_auc=0.9485
Fold[10] Epoch: 58 [58/100 (58%)] Train loss=0.227125 Test loss=0.229010 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1771102398633957
[5/23] Train loss=0.2995990514755249
[10/23] Train loss=0.24587011337280273
[15/23] Train loss=0.22902041673660278
[20/23] Train loss=0.29685837030410767
Test set avg_accuracy=91.05% avg_sensitivity=76.67%, avg_specificity=95.21% avg_auc=0.9499
Fold[10] Epoch: 59 [59/100 (59%)] Train loss=0.226488 Test loss=0.227610 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1853097379207611
[5/23] Train loss=0.2932116985321045
[10/23] Train loss=0.2374189794063568
[15/23] Train loss=0.21748867630958557
[20/23] Train loss=0.2972162961959839
Test set avg_accuracy=90.77% avg_sensitivity=78.11%, avg_specificity=94.44% avg_auc=0.9479
Fold[10] Epoch: 60 [60/100 (60%)] Train loss=0.223092 Test loss=0.232136 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17903129756450653
[5/23] Train loss=0.2989041805267334
[10/23] Train loss=0.24346314370632172
[15/23] Train loss=0.22269782423973083
[20/23] Train loss=0.29856136441230774
Test set avg_accuracy=90.91% avg_sensitivity=77.34%, avg_specificity=94.84% avg_auc=0.9483
Fold[10] Epoch: 61 [61/100 (61%)] Train loss=0.222498 Test loss=0.230919 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18367497622966766
[5/23] Train loss=0.29008951783180237
[10/23] Train loss=0.24027542769908905
[15/23] Train loss=0.22219468653202057
[20/23] Train loss=0.306851863861084
Test set avg_accuracy=90.99% avg_sensitivity=77.60%, avg_specificity=94.87% avg_auc=0.9479
Fold[10] Epoch: 62 [62/100 (62%)] Train loss=0.222244 Test loss=0.231920 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18757791817188263
[5/23] Train loss=0.29253146052360535
[10/23] Train loss=0.23533698916435242
[15/23] Train loss=0.22117619216442108
[20/23] Train loss=0.3015677332878113
Test set avg_accuracy=90.90% avg_sensitivity=78.01%, avg_specificity=94.63% avg_auc=0.9491
Fold[10] Epoch: 63 [63/100 (63%)] Train loss=0.222164 Test loss=0.230476 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18087127804756165
[5/23] Train loss=0.29125848412513733
[10/23] Train loss=0.23051059246063232
[15/23] Train loss=0.22009804844856262
[20/23] Train loss=0.304245263338089
Test set avg_accuracy=91.01% avg_sensitivity=78.83%, avg_specificity=94.54% avg_auc=0.9500
Best model saved!! Metric=33.38153326147388!!
Fold[10] Epoch: 64 [64/100 (64%)] Train loss=0.220594 Test loss=0.227313 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18292765319347382
[5/23] Train loss=0.2869541645050049
[10/23] Train loss=0.2288721203804016
[15/23] Train loss=0.22784313559532166
[20/23] Train loss=0.30492058396339417
Test set avg_accuracy=91.07% avg_sensitivity=77.75%, avg_specificity=94.93% avg_auc=0.9462
Fold[10] Epoch: 65 [65/100 (65%)] Train loss=0.219841 Test loss=0.236023 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18208175897598267
[5/23] Train loss=0.2911328673362732
[10/23] Train loss=0.23752553761005402
[15/23] Train loss=0.21820729970932007
[20/23] Train loss=0.28562813997268677
Test set avg_accuracy=91.19% avg_sensitivity=78.16%, avg_specificity=94.96% avg_auc=0.9493
Fold[10] Epoch: 66 [66/100 (66%)] Train loss=0.219496 Test loss=0.229508 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17987847328186035
[5/23] Train loss=0.2957232594490051
[10/23] Train loss=0.22929802536964417
[15/23] Train loss=0.21818068623542786
[20/23] Train loss=0.29100075364112854
Test set avg_accuracy=91.01% avg_sensitivity=77.49%, avg_specificity=94.93% avg_auc=0.9478
Fold[10] Epoch: 67 [67/100 (67%)] Train loss=0.219352 Test loss=0.232522 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17071470618247986
[5/23] Train loss=0.29360732436180115
[10/23] Train loss=0.23573389649391174
[15/23] Train loss=0.2113940715789795
[20/23] Train loss=0.28016310930252075
Test set avg_accuracy=90.95% avg_sensitivity=77.65%, avg_specificity=94.79% avg_auc=0.9479
Fold[10] Epoch: 68 [68/100 (68%)] Train loss=0.215716 Test loss=0.233022 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.18097633123397827
[5/23] Train loss=0.2861958146095276
[10/23] Train loss=0.2262772023677826
[15/23] Train loss=0.20967735350131989
[20/23] Train loss=0.2809961438179016
Test set avg_accuracy=91.12% avg_sensitivity=77.49%, avg_specificity=95.06% avg_auc=0.9491
Fold[10] Epoch: 69 [69/100 (69%)] Train loss=0.214955 Test loss=0.230276 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1766616553068161
[5/23] Train loss=0.2786933481693268
[10/23] Train loss=0.23487821221351624
[15/23] Train loss=0.21709753572940826
[20/23] Train loss=0.27745500206947327
Test set avg_accuracy=90.98% avg_sensitivity=77.39%, avg_specificity=94.91% avg_auc=0.9471
Fold[10] Epoch: 70 [70/100 (70%)] Train loss=0.212156 Test loss=0.235077 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17651063203811646
[5/23] Train loss=0.28586217761039734
[10/23] Train loss=0.22694216668605804
[15/23] Train loss=0.21489128470420837
[20/23] Train loss=0.2919055223464966
Test set avg_accuracy=90.96% avg_sensitivity=78.73%, avg_specificity=94.50% avg_auc=0.9484
Fold[10] Epoch: 71 [71/100 (71%)] Train loss=0.212930 Test loss=0.233185 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17684975266456604
[5/23] Train loss=0.2825530767440796
[10/23] Train loss=0.24279002845287323
[15/23] Train loss=0.21107779443264008
[20/23] Train loss=0.28895094990730286
Test set avg_accuracy=90.96% avg_sensitivity=78.21%, avg_specificity=94.65% avg_auc=0.9463
Fold[10] Epoch: 72 [72/100 (72%)] Train loss=0.211401 Test loss=0.236062 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17268234491348267
[5/23] Train loss=0.2808171212673187
[10/23] Train loss=0.23009434342384338
[15/23] Train loss=0.2148546576499939
[20/23] Train loss=0.28201398253440857
Test set avg_accuracy=90.89% avg_sensitivity=79.03%, avg_specificity=94.32% avg_auc=0.9454
Fold[10] Epoch: 73 [73/100 (73%)] Train loss=0.209238 Test loss=0.240888 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1745416820049286
[5/23] Train loss=0.2728307247161865
[10/23] Train loss=0.22423456609249115
[15/23] Train loss=0.21074220538139343
[20/23] Train loss=0.26641935110092163
Test set avg_accuracy=90.85% avg_sensitivity=79.09%, avg_specificity=94.26% avg_auc=0.9458
Fold[10] Epoch: 74 [74/100 (74%)] Train loss=0.207740 Test loss=0.239382 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16993403434753418
[5/23] Train loss=0.27049946784973145
[10/23] Train loss=0.23938381671905518
[15/23] Train loss=0.2199171781539917
[20/23] Train loss=0.2796887755393982
Test set avg_accuracy=90.68% avg_sensitivity=78.47%, avg_specificity=94.21% avg_auc=0.9464
Fold[10] Epoch: 75 [75/100 (75%)] Train loss=0.210752 Test loss=0.238681 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17008960247039795
[5/23] Train loss=0.2749593257904053
[10/23] Train loss=0.2242712527513504
[15/23] Train loss=0.2180657982826233
[20/23] Train loss=0.2729000747203827
Test set avg_accuracy=90.80% avg_sensitivity=79.34%, avg_specificity=94.11% avg_auc=0.9468
Fold[10] Epoch: 76 [76/100 (76%)] Train loss=0.205715 Test loss=0.239123 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16824984550476074
[5/23] Train loss=0.2785097360610962
[10/23] Train loss=0.22660158574581146
[15/23] Train loss=0.20521780848503113
[20/23] Train loss=0.2753603160381317
Test set avg_accuracy=90.90% avg_sensitivity=78.78%, avg_specificity=94.41% avg_auc=0.9467
Fold[10] Epoch: 77 [77/100 (77%)] Train loss=0.203520 Test loss=0.238019 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1762877106666565
[5/23] Train loss=0.2643691301345825
[10/23] Train loss=0.21337951719760895
[15/23] Train loss=0.20830386877059937
[20/23] Train loss=0.2869377136230469
Test set avg_accuracy=90.89% avg_sensitivity=78.93%, avg_specificity=94.35% avg_auc=0.9461
Fold[10] Epoch: 78 [78/100 (78%)] Train loss=0.204039 Test loss=0.238825 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17617781460285187
[5/23] Train loss=0.27730366587638855
[10/23] Train loss=0.22070741653442383
[15/23] Train loss=0.21117548644542694
[20/23] Train loss=0.2615712285041809
Test set avg_accuracy=90.83% avg_sensitivity=78.73%, avg_specificity=94.33% avg_auc=0.9455
Fold[10] Epoch: 79 [79/100 (79%)] Train loss=0.205433 Test loss=0.241149 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17357875406742096
[5/23] Train loss=0.27723419666290283
[10/23] Train loss=0.22167931497097015
[15/23] Train loss=0.2087661474943161
[20/23] Train loss=0.2626691162586212
Test set avg_accuracy=90.60% avg_sensitivity=78.52%, avg_specificity=94.10% avg_auc=0.9484
Fold[10] Epoch: 80 [80/100 (80%)] Train loss=0.203779 Test loss=0.236807 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1728498488664627
[5/23] Train loss=0.26691144704818726
[10/23] Train loss=0.22696776688098907
[15/23] Train loss=0.212632954120636
[20/23] Train loss=0.2630552351474762
Test set avg_accuracy=90.78% avg_sensitivity=78.37%, avg_specificity=94.38% avg_auc=0.9467
Fold[10] Epoch: 81 [81/100 (81%)] Train loss=0.198802 Test loss=0.239821 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16365540027618408
[5/23] Train loss=0.2743200361728668
[10/23] Train loss=0.21869410574436188
[15/23] Train loss=0.22078533470630646
[20/23] Train loss=0.2671644985675812
Test set avg_accuracy=90.81% avg_sensitivity=77.65%, avg_specificity=94.62% avg_auc=0.9451
Fold[10] Epoch: 82 [82/100 (82%)] Train loss=0.200365 Test loss=0.241810 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16831085085868835
[5/23] Train loss=0.27292877435684204
[10/23] Train loss=0.22291114926338196
[15/23] Train loss=0.20676293969154358
[20/23] Train loss=0.25830182433128357
Test set avg_accuracy=90.76% avg_sensitivity=77.95%, avg_specificity=94.47% avg_auc=0.9471
Fold[10] Epoch: 83 [83/100 (83%)] Train loss=0.200285 Test loss=0.237595 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.17194105684757233
[5/23] Train loss=0.26151683926582336
[10/23] Train loss=0.22340942919254303
[15/23] Train loss=0.2133876383304596
[20/23] Train loss=0.26785808801651
Test set avg_accuracy=90.78% avg_sensitivity=78.67%, avg_specificity=94.29% avg_auc=0.9464
Fold[10] Epoch: 84 [84/100 (84%)] Train loss=0.199673 Test loss=0.241616 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.158079594373703
[5/23] Train loss=0.2695789039134979
[10/23] Train loss=0.21112065017223358
[15/23] Train loss=0.21173599362373352
[20/23] Train loss=0.25969403982162476
Test set avg_accuracy=90.59% avg_sensitivity=78.67%, avg_specificity=94.04% avg_auc=0.9438
Fold[10] Epoch: 85 [85/100 (85%)] Train loss=0.196673 Test loss=0.247380 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16653533279895782
[5/23] Train loss=0.25401929020881653
[10/23] Train loss=0.22122469544410706
[15/23] Train loss=0.2058987021446228
[20/23] Train loss=0.25117671489715576
Test set avg_accuracy=90.65% avg_sensitivity=79.91%, avg_specificity=93.75% avg_auc=0.9452
Fold[10] Epoch: 86 [86/100 (86%)] Train loss=0.193995 Test loss=0.244428 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16533127427101135
[5/23] Train loss=0.26279735565185547
[10/23] Train loss=0.21476204693317413
[15/23] Train loss=0.20109759271144867
[20/23] Train loss=0.2580556571483612
Test set avg_accuracy=90.73% avg_sensitivity=77.95%, avg_specificity=94.42% avg_auc=0.9434
Fold[10] Epoch: 87 [87/100 (87%)] Train loss=0.196210 Test loss=0.247074 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16322791576385498
[5/23] Train loss=0.2584511339664459
[10/23] Train loss=0.21180042624473572
[15/23] Train loss=0.20688220858573914
[20/23] Train loss=0.25051605701446533
Test set avg_accuracy=90.84% avg_sensitivity=79.09%, avg_specificity=94.24% avg_auc=0.9460
Fold[10] Epoch: 88 [88/100 (88%)] Train loss=0.193769 Test loss=0.242338 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16527359187602997
[5/23] Train loss=0.2589865028858185
[10/23] Train loss=0.2177119106054306
[15/23] Train loss=0.20915833115577698
[20/23] Train loss=0.2597101330757141
Test set avg_accuracy=90.45% avg_sensitivity=79.34%, avg_specificity=93.66% avg_auc=0.9453
Fold[10] Epoch: 89 [89/100 (89%)] Train loss=0.191858 Test loss=0.245784 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16824796795845032
[5/23] Train loss=0.25418901443481445
[10/23] Train loss=0.22293588519096375
[15/23] Train loss=0.1988355964422226
[20/23] Train loss=0.2585641145706177
Test set avg_accuracy=90.48% avg_sensitivity=79.34%, avg_specificity=93.71% avg_auc=0.9437
Fold[10] Epoch: 90 [90/100 (90%)] Train loss=0.193477 Test loss=0.250181 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16157729923725128
[5/23] Train loss=0.2596960663795471
[10/23] Train loss=0.19946634769439697
[15/23] Train loss=0.1967722326517105
[20/23] Train loss=0.25298863649368286
Test set avg_accuracy=90.51% avg_sensitivity=79.86%, avg_specificity=93.59% avg_auc=0.9457
Fold[10] Epoch: 91 [91/100 (91%)] Train loss=0.190019 Test loss=0.246193 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15974578261375427
[5/23] Train loss=0.25536835193634033
[10/23] Train loss=0.21011126041412354
[15/23] Train loss=0.19410258531570435
[20/23] Train loss=0.25420546531677246
Test set avg_accuracy=90.27% avg_sensitivity=78.73%, avg_specificity=93.60% avg_auc=0.9425
Fold[10] Epoch: 92 [92/100 (92%)] Train loss=0.187401 Test loss=0.254292 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15843194723129272
[5/23] Train loss=0.2552439272403717
[10/23] Train loss=0.20426547527313232
[15/23] Train loss=0.19943015277385712
[20/23] Train loss=0.24647416174411774
Test set avg_accuracy=89.95% avg_sensitivity=80.88%, avg_specificity=92.58% avg_auc=0.9457
Fold[10] Epoch: 93 [93/100 (93%)] Train loss=0.187983 Test loss=0.251717 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1502038985490799
[5/23] Train loss=0.2600826919078827
[10/23] Train loss=0.2202085703611374
[15/23] Train loss=0.1965995579957962
[20/23] Train loss=0.23694027960300446
Test set avg_accuracy=90.45% avg_sensitivity=79.60%, avg_specificity=93.59% avg_auc=0.9441
Fold[10] Epoch: 94 [94/100 (94%)] Train loss=0.185221 Test loss=0.250979 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15320615470409393
[5/23] Train loss=0.24005407094955444
[10/23] Train loss=0.2159053236246109
[15/23] Train loss=0.1915522962808609
[20/23] Train loss=0.2553708851337433
Test set avg_accuracy=90.39% avg_sensitivity=79.70%, avg_specificity=93.49% avg_auc=0.9450
Fold[10] Epoch: 95 [95/100 (95%)] Train loss=0.184988 Test loss=0.249167 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.16095764935016632
[5/23] Train loss=0.22891190648078918
[10/23] Train loss=0.20560862123966217
[15/23] Train loss=0.19461901485919952
[20/23] Train loss=0.23594437539577484
Test set avg_accuracy=90.60% avg_sensitivity=78.52%, avg_specificity=94.10% avg_auc=0.9444
Fold[10] Epoch: 96 [96/100 (96%)] Train loss=0.183429 Test loss=0.248384 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1588554084300995
[5/23] Train loss=0.24906031787395477
[10/23] Train loss=0.19920256733894348
[15/23] Train loss=0.1970653384923935
[20/23] Train loss=0.24385474622249603
Test set avg_accuracy=90.44% avg_sensitivity=78.83%, avg_specificity=93.80% avg_auc=0.9457
Fold[10] Epoch: 97 [97/100 (97%)] Train loss=0.183671 Test loss=0.247727 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15440300107002258
[5/23] Train loss=0.23158109188079834
[10/23] Train loss=0.2073938101530075
[15/23] Train loss=0.18878640234470367
[20/23] Train loss=0.24155043065547943
Test set avg_accuracy=90.32% avg_sensitivity=79.55%, avg_specificity=93.44% avg_auc=0.9438
Fold[10] Epoch: 98 [98/100 (98%)] Train loss=0.181145 Test loss=0.254205 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.1505279690027237
[5/23] Train loss=0.24893978238105774
[10/23] Train loss=0.20355460047721863
[15/23] Train loss=0.19129414856433868
[20/23] Train loss=0.23464323580265045
Test set avg_accuracy=90.23% avg_sensitivity=79.24%, avg_specificity=93.41% avg_auc=0.9436
Fold[10] Epoch: 99 [99/100 (99%)] Train loss=0.179953 Test loss=0.255465 Current lr=[3.9999999999999996e-05]

[0/23] Train loss=0.15279237926006317
[5/23] Train loss=0.24461182951927185
[10/23] Train loss=0.20219475030899048
[15/23] Train loss=0.19145670533180237
[20/23] Train loss=0.2264086902141571
Test set avg_accuracy=89.99% avg_sensitivity=79.45%, avg_specificity=93.04% avg_auc=0.9444
Fold[10] Epoch: 100 [100/100 (100%)] Train loss=0.177934 Test loss=0.254997 Current lr=[3.9999999999999996e-05]

Fold[10] Best Result: acc=91.0149942329873 sen=78.82836587872559, spe=94.54193932183225, auc=0.9499623382792873!
Final Avg Result: avg_acc=88.992467% avg_sen=74.729100% avg_spe=93.774607% avg_auc=0.937502
