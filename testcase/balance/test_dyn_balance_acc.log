/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=1.4338245391845703
[5/24] Train loss=1.2948217391967773
[10/24] Train loss=1.3188235759735107
[15/24] Train loss=1.1176252365112305
[20/24] Train loss=1.035949468612671
Test set avg_accuracy=74.10% avg_sensitivity=20.26%, avg_specificity=92.17% avg_auc=78.90%
Best model saved!! Metric=78.89541788691146!!
Fold[1] Epoch: 1 [1/100 (1%)] Train loss=1.230410 Test loss=0.544387 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=1.0276931524276733
[5/24] Train loss=0.8889614343643188
[10/24] Train loss=1.055126428604126
[15/24] Train loss=0.8731071949005127
[20/24] Train loss=0.8505641222000122
Test set avg_accuracy=81.25% avg_sensitivity=60.41%, avg_specificity=88.24% avg_auc=87.11%
Best model saved!! Metric=87.10510475332282!!
Fold[1] Epoch: 2 [2/100 (2%)] Train loss=0.956368 Test loss=0.462972 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8430919647216797
[5/24] Train loss=0.8217414021492004
[10/24] Train loss=0.951882541179657
[15/24] Train loss=0.8110026121139526
[20/24] Train loss=0.7991466522216797
Test set avg_accuracy=82.84% avg_sensitivity=73.47%, avg_specificity=85.98% avg_auc=89.98%
Best model saved!! Metric=89.97862581662537!!
Fold[1] Epoch: 3 [3/100 (3%)] Train loss=0.865427 Test loss=0.399978 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.8086163997650146
[5/24] Train loss=0.749639093875885
[10/24] Train loss=0.9231333136558533
[15/24] Train loss=0.7685484290122986
[20/24] Train loss=0.767039954662323
Test set avg_accuracy=82.77% avg_sensitivity=83.99%, avg_specificity=82.37% avg_auc=91.57%
Best model saved!! Metric=91.568628069385!!
Fold[1] Epoch: 4 [4/100 (4%)] Train loss=0.816463 Test loss=0.431751 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.7716203331947327
[5/24] Train loss=0.7092359662055969
[10/24] Train loss=0.8429244160652161
[15/24] Train loss=0.7263046503067017
[20/24] Train loss=0.7590106725692749
Test set avg_accuracy=82.94% avg_sensitivity=85.60%, avg_specificity=82.05% avg_auc=92.29%
Best model saved!! Metric=92.28943455733274!!
Fold[1] Epoch: 5 [5/100 (5%)] Train loss=0.773904 Test loss=0.430187 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.7231982350349426
[5/24] Train loss=0.7006379961967468
[10/24] Train loss=0.8340576887130737
[15/24] Train loss=0.694908618927002
[20/24] Train loss=0.699192225933075
Test set avg_accuracy=83.19% avg_sensitivity=86.94%, avg_specificity=81.93% avg_auc=92.84%
Best model saved!! Metric=92.84009912142375!!
Fold[1] Epoch: 6 [6/100 (6%)] Train loss=0.745016 Test loss=0.422817 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.7134647965431213
[5/24] Train loss=0.6635740995407104
[10/24] Train loss=0.8190082311630249
[15/24] Train loss=0.7438775897026062
[20/24] Train loss=0.6476433873176575
Test set avg_accuracy=83.75% avg_sensitivity=87.15%, avg_specificity=82.61% avg_auc=93.18%
Best model saved!! Metric=93.18059923406173!!
Fold[1] Epoch: 7 [7/100 (7%)] Train loss=0.715392 Test loss=0.385795 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.7212892174720764
[5/24] Train loss=0.6455056667327881
[10/24] Train loss=0.7989570498466492
[15/24] Train loss=0.7603132128715515
[20/24] Train loss=0.6269639134407043
Test set avg_accuracy=85.17% avg_sensitivity=83.99%, avg_specificity=85.57% avg_auc=93.26%
Best model saved!! Metric=93.2586798828565!!
Fold[1] Epoch: 8 [8/100 (8%)] Train loss=0.694228 Test loss=0.348017 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.688267707824707
[5/24] Train loss=0.5779434442520142
[10/24] Train loss=0.7860785722732544
[15/24] Train loss=0.680364191532135
[20/24] Train loss=0.6230345964431763
Test set avg_accuracy=84.61% avg_sensitivity=84.87%, avg_specificity=84.52% avg_auc=93.59%
Best model saved!! Metric=93.58751971164676!!
Fold[1] Epoch: 9 [9/100 (9%)] Train loss=0.674035 Test loss=0.353940 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6476007103919983
[5/24] Train loss=0.6243890523910522
[10/24] Train loss=0.7233665585517883
[15/24] Train loss=0.6438019871711731
[20/24] Train loss=0.6070212125778198
Test set avg_accuracy=85.59% avg_sensitivity=83.06%, avg_specificity=86.43% avg_auc=93.61%
Best model saved!! Metric=93.61036719981978!!
Fold[1] Epoch: 10 [10/100 (10%)] Train loss=0.659425 Test loss=0.329517 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.6405743956565857
[5/24] Train loss=0.5970807671546936
[10/24] Train loss=0.704442024230957
[15/24] Train loss=0.6615431904792786
[20/24] Train loss=0.5630314946174622
Test set avg_accuracy=85.56% avg_sensitivity=84.72%, avg_specificity=85.84% avg_auc=93.74%
Best model saved!! Metric=93.74381617481414!!
Fold[1] Epoch: 11 [11/100 (11%)] Train loss=0.644904 Test loss=0.338318 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.5978781580924988
[5/24] Train loss=0.5654743909835815
[10/24] Train loss=0.7123702168464661
[15/24] Train loss=0.6403501033782959
[20/24] Train loss=0.5629299283027649
Test set avg_accuracy=84.18% avg_sensitivity=86.37%, avg_specificity=83.44% avg_auc=93.58%
Fold[1] Epoch: 12 [12/100 (12%)] Train loss=0.630573 Test loss=0.385853 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.6286490559577942
[5/24] Train loss=0.5707499384880066
[10/24] Train loss=0.6756897568702698
[15/24] Train loss=0.6278530359268188
[20/24] Train loss=0.5894942879676819
Test set avg_accuracy=86.67% avg_sensitivity=83.47%, avg_specificity=87.74% avg_auc=93.95%
Best model saved!! Metric=93.94842532101826!!
Fold[1] Epoch: 13 [13/100 (13%)] Train loss=0.631190 Test loss=0.335329 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.5970741510391235
[5/24] Train loss=0.5465143918991089
[10/24] Train loss=0.6820507645606995
[15/24] Train loss=0.6333158612251282
[20/24] Train loss=0.6048530340194702
Test set avg_accuracy=86.80% avg_sensitivity=81.50%, avg_specificity=88.57% avg_auc=93.99%
Best model saved!! Metric=93.98630322144628!!
Fold[1] Epoch: 14 [14/100 (14%)] Train loss=0.612381 Test loss=0.308283 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.60398930311203
[5/24] Train loss=0.51695317029953
[10/24] Train loss=0.6532140374183655
[15/24] Train loss=0.6059343218803406
[20/24] Train loss=0.5697387456893921
Test set avg_accuracy=87.92% avg_sensitivity=74.46%, avg_specificity=92.43% avg_auc=93.77%
Fold[1] Epoch: 15 [15/100 (15%)] Train loss=0.604833 Test loss=0.286026 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.6351569890975952
[5/24] Train loss=0.5037251114845276
[10/24] Train loss=0.6710130572319031
[15/24] Train loss=0.5795885920524597
[20/24] Train loss=0.556018054485321
Test set avg_accuracy=87.90% avg_sensitivity=63.83%, avg_specificity=95.98% avg_auc=93.61%
Fold[1] Epoch: 16 [16/100 (16%)] Train loss=0.592709 Test loss=0.288408 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.6157268285751343
[5/24] Train loss=0.5153645277023315
[10/24] Train loss=0.6543987989425659
[15/24] Train loss=0.6037768125534058
[20/24] Train loss=0.571242094039917
Test set avg_accuracy=88.01% avg_sensitivity=80.05%, avg_specificity=90.68% avg_auc=94.13%
Best model saved!! Metric=94.12649245325522!!
Fold[1] Epoch: 17 [17/100 (17%)] Train loss=0.590117 Test loss=0.282771 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5827001929283142
[5/24] Train loss=0.46784231066703796
[10/24] Train loss=0.6911611557006836
[15/24] Train loss=0.5533930659294128
[20/24] Train loss=0.5411711931228638
Test set avg_accuracy=88.45% avg_sensitivity=80.16%, avg_specificity=91.23% avg_auc=93.75%
Fold[1] Epoch: 18 [18/100 (18%)] Train loss=0.586147 Test loss=0.297372 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.6059081554412842
[5/24] Train loss=0.4946773052215576
[10/24] Train loss=0.6568058133125305
[15/24] Train loss=0.6103047728538513
[20/24] Train loss=0.5549458861351013
Test set avg_accuracy=87.98% avg_sensitivity=79.02%, avg_specificity=90.99% avg_auc=93.99%
Fold[1] Epoch: 19 [19/100 (19%)] Train loss=0.582913 Test loss=0.290028 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5690611004829407
[5/24] Train loss=0.49128592014312744
[10/24] Train loss=0.6153513789176941
[15/24] Train loss=0.5697802305221558
[20/24] Train loss=0.5561010837554932
Test set avg_accuracy=87.93% avg_sensitivity=73.21%, avg_specificity=92.87% avg_auc=93.45%
Fold[1] Epoch: 20 [20/100 (20%)] Train loss=0.580811 Test loss=0.286386 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5906274318695068
[5/24] Train loss=0.5214819312095642
[10/24] Train loss=0.6920781135559082
[15/24] Train loss=0.5340683460235596
[20/24] Train loss=0.5154346227645874
Test set avg_accuracy=87.70% avg_sensitivity=80.52%, avg_specificity=90.10% avg_auc=94.09%
Fold[1] Epoch: 21 [21/100 (21%)] Train loss=0.566019 Test loss=0.293391 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.5695503950119019
[5/24] Train loss=0.46683529019355774
[10/24] Train loss=0.661942720413208
[15/24] Train loss=0.5527611970901489
[20/24] Train loss=0.48740676045417786
Test set avg_accuracy=88.35% avg_sensitivity=74.51%, avg_specificity=92.99% avg_auc=93.97%
Fold[1] Epoch: 22 [22/100 (22%)] Train loss=0.563287 Test loss=0.273027 Current lr=[0.000842324016282456]

[0/24] Train loss=0.561373233795166
[5/24] Train loss=0.4810590445995331
[10/24] Train loss=0.6392678618431091
[15/24] Train loss=0.5625879168510437
[20/24] Train loss=0.49957993626594543
Test set avg_accuracy=88.95% avg_sensitivity=76.79%, avg_specificity=93.03% avg_auc=94.39%
Best model saved!! Metric=94.38586168055866!!
Fold[1] Epoch: 23 [23/100 (23%)] Train loss=0.546518 Test loss=0.268879 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5226182341575623
[5/24] Train loss=0.4810214638710022
[10/24] Train loss=0.5919466614723206
[15/24] Train loss=0.5239592790603638
[20/24] Train loss=0.45336776971817017
Test set avg_accuracy=88.82% avg_sensitivity=72.95%, avg_specificity=94.14% avg_auc=94.19%
Fold[1] Epoch: 24 [24/100 (24%)] Train loss=0.534602 Test loss=0.272590 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.5358818769454956
[5/24] Train loss=0.4865935444831848
[10/24] Train loss=0.601015031337738
[15/24] Train loss=0.5650679469108582
[20/24] Train loss=0.5093961954116821
Test set avg_accuracy=88.36% avg_sensitivity=74.51%, avg_specificity=93.01% avg_auc=93.56%
Fold[1] Epoch: 25 [25/100 (25%)] Train loss=0.536977 Test loss=0.287442 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.5424570441246033
[5/24] Train loss=0.4705788195133209
[10/24] Train loss=0.5712392330169678
[15/24] Train loss=0.4849362373352051
[20/24] Train loss=0.4690167307853699
Test set avg_accuracy=89.19% avg_sensitivity=78.81%, avg_specificity=92.68% avg_auc=93.95%
Fold[1] Epoch: 26 [26/100 (26%)] Train loss=0.515902 Test loss=0.284579 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.530221164226532
[5/24] Train loss=0.4234185516834259
[10/24] Train loss=0.5884899497032166
[15/24] Train loss=0.5401313304901123
[20/24] Train loss=0.42777687311172485
Test set avg_accuracy=87.68% avg_sensitivity=80.36%, avg_specificity=90.14% avg_auc=94.28%
Fold[1] Epoch: 27 [27/100 (27%)] Train loss=0.511044 Test loss=0.293824 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.5269753932952881
[5/24] Train loss=0.470384418964386
[10/24] Train loss=0.5281422138214111
[15/24] Train loss=0.48906567692756653
[20/24] Train loss=0.4343903660774231
Test set avg_accuracy=89.36% avg_sensitivity=76.84%, avg_specificity=93.57% avg_auc=94.18%
Fold[1] Epoch: 28 [28/100 (28%)] Train loss=0.487443 Test loss=0.286234 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.5140512585639954
[5/24] Train loss=0.4066326320171356
[10/24] Train loss=0.5952998399734497
[15/24] Train loss=0.4636259078979492
[20/24] Train loss=0.4238303601741791
Test set avg_accuracy=87.92% avg_sensitivity=76.01%, avg_specificity=91.91% avg_auc=93.85%
Fold[1] Epoch: 29 [29/100 (29%)] Train loss=0.492099 Test loss=0.283281 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.4825265109539032
[5/24] Train loss=0.4409140646457672
[10/24] Train loss=0.5948280692100525
[15/24] Train loss=0.4658820629119873
[20/24] Train loss=0.4494962692260742
Test set avg_accuracy=88.24% avg_sensitivity=77.41%, avg_specificity=91.88% avg_auc=93.76%
Fold[1] Epoch: 30 [30/100 (30%)] Train loss=0.491958 Test loss=0.312164 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.5423485040664673
[5/24] Train loss=0.4402106702327728
[10/24] Train loss=0.5674211978912354
[15/24] Train loss=0.5296374559402466
[20/24] Train loss=0.41614386439323425
Test set avg_accuracy=88.45% avg_sensitivity=76.53%, avg_specificity=92.45% avg_auc=93.79%
Fold[1] Epoch: 31 [31/100 (31%)] Train loss=0.487167 Test loss=0.293060 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.47635290026664734
[5/24] Train loss=0.40553978085517883
[10/24] Train loss=0.5403354167938232
[15/24] Train loss=0.418345183134079
[20/24] Train loss=0.4219800531864166
Test set avg_accuracy=88.96% avg_sensitivity=74.77%, avg_specificity=93.72% avg_auc=94.42%
Best model saved!! Metric=94.41742284298265!!
Fold[1] Epoch: 32 [32/100 (32%)] Train loss=0.465966 Test loss=0.295243 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.4522549510002136
[5/24] Train loss=0.3809305429458618
[10/24] Train loss=0.4715920686721802
[15/24] Train loss=0.3846784234046936
[20/24] Train loss=0.39341336488723755
Test set avg_accuracy=88.54% avg_sensitivity=66.94%, avg_specificity=95.79% avg_auc=93.41%
Fold[1] Epoch: 33 [33/100 (33%)] Train loss=0.431475 Test loss=0.325164 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.4548109471797943
[5/24] Train loss=0.364380419254303
[10/24] Train loss=0.48761188983917236
[15/24] Train loss=0.35526543855667114
[20/24] Train loss=0.36774757504463196
Test set avg_accuracy=88.71% avg_sensitivity=71.24%, avg_specificity=94.57% avg_auc=93.41%
Fold[1] Epoch: 34 [34/100 (34%)] Train loss=0.415148 Test loss=0.328177 Current lr=[0.000991797016730875]

[0/24] Train loss=0.41993874311447144
[5/24] Train loss=0.34249916672706604
[10/24] Train loss=0.43227049708366394
[15/24] Train loss=0.3565501570701599
[20/24] Train loss=0.35341769456863403
Test set avg_accuracy=88.72% avg_sensitivity=72.33%, avg_specificity=94.23% avg_auc=93.11%
Fold[1] Epoch: 35 [35/100 (35%)] Train loss=0.390626 Test loss=0.332121 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.39389827847480774
[5/24] Train loss=0.34093400835990906
[10/24] Train loss=0.42001956701278687
[15/24] Train loss=0.3143376111984253
[20/24] Train loss=0.34233275055885315
Test set avg_accuracy=88.79% avg_sensitivity=71.09%, avg_specificity=94.73% avg_auc=93.47%
Fold[1] Epoch: 36 [36/100 (36%)] Train loss=0.383286 Test loss=0.345840 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.37975215911865234
[5/24] Train loss=0.32590919733047485
[10/24] Train loss=0.3911989629268646
[15/24] Train loss=0.3077065944671631
[20/24] Train loss=0.3576679527759552
Test set avg_accuracy=88.76% avg_sensitivity=69.84%, avg_specificity=95.11% avg_auc=93.21%
Fold[1] Epoch: 37 [37/100 (37%)] Train loss=0.374055 Test loss=0.327596 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.3988226056098938
[5/24] Train loss=0.3298616409301758
[10/24] Train loss=0.38049209117889404
[15/24] Train loss=0.29256024956703186
[20/24] Train loss=0.3275299072265625
Test set avg_accuracy=87.60% avg_sensitivity=79.12%, avg_specificity=90.45% avg_auc=93.87%
Fold[1] Epoch: 38 [38/100 (38%)] Train loss=0.360255 Test loss=0.303850 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.3580684959888458
[5/24] Train loss=0.27783212065696716
[10/24] Train loss=0.4288977384567261
[15/24] Train loss=0.2964683175086975
[20/24] Train loss=0.3288966119289398
Test set avg_accuracy=88.49% avg_sensitivity=80.98%, avg_specificity=91.01% avg_auc=93.83%
Fold[1] Epoch: 39 [39/100 (39%)] Train loss=0.337193 Test loss=0.335394 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.35970550775527954
[5/24] Train loss=0.2903020977973938
[10/24] Train loss=0.35489076375961304
[15/24] Train loss=0.27053749561309814
[20/24] Train loss=0.3105664551258087
Test set avg_accuracy=86.00% avg_sensitivity=84.77%, avg_specificity=86.42% avg_auc=93.25%
Fold[1] Epoch: 40 [40/100 (40%)] Train loss=0.334717 Test loss=0.389365 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.3927253186702728
[5/24] Train loss=0.2767846882343292
[10/24] Train loss=0.3448430597782135
[15/24] Train loss=0.30334582924842834
[20/24] Train loss=0.33645105361938477
Test set avg_accuracy=85.87% avg_sensitivity=85.28%, avg_specificity=86.07% avg_auc=93.79%
Fold[1] Epoch: 41 [41/100 (41%)] Train loss=0.318644 Test loss=0.389299 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.3384716808795929
[5/24] Train loss=0.25505366921424866
[10/24] Train loss=0.31756842136383057
[15/24] Train loss=0.25388506054878235
[20/24] Train loss=0.2652374505996704
Test set avg_accuracy=87.29% avg_sensitivity=83.52%, avg_specificity=88.56% avg_auc=93.40%
Fold[1] Epoch: 42 [42/100 (42%)] Train loss=0.286889 Test loss=0.389114 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.33005863428115845
[5/24] Train loss=0.27682045102119446
[10/24] Train loss=0.29793378710746765
[15/24] Train loss=0.21221192181110382
[20/24] Train loss=0.21979746222496033
Test set avg_accuracy=88.91% avg_sensitivity=77.05%, avg_specificity=92.89% avg_auc=93.80%
Fold[1] Epoch: 43 [43/100 (43%)] Train loss=0.272565 Test loss=0.342637 Current lr=[0.000916771143003274]

[0/24] Train loss=0.29303786158561707
[5/24] Train loss=0.2207491397857666
[10/24] Train loss=0.28464236855506897
[15/24] Train loss=0.210656076669693
[20/24] Train loss=0.20013800263404846
Test set avg_accuracy=88.66% avg_sensitivity=80.67%, avg_specificity=91.34% avg_auc=93.80%
Fold[1] Epoch: 44 [44/100 (44%)] Train loss=0.249791 Test loss=0.361195 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.23503199219703674
[5/24] Train loss=0.20723095536231995
[10/24] Train loss=0.24345310032367706
[15/24] Train loss=0.18672361969947815
[20/24] Train loss=0.21460698544979095
Test set avg_accuracy=88.57% avg_sensitivity=78.65%, avg_specificity=91.90% avg_auc=93.38%
Fold[1] Epoch: 45 [45/100 (45%)] Train loss=0.222278 Test loss=0.419669 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.25059905648231506
[5/24] Train loss=0.19782912731170654
[10/24] Train loss=0.21004509925842285
[15/24] Train loss=0.18577750027179718
[20/24] Train loss=0.17939311265945435
Test set avg_accuracy=87.92% avg_sensitivity=77.93%, avg_specificity=91.27% avg_auc=93.15%
Fold[1] Epoch: 46 [46/100 (46%)] Train loss=0.200856 Test loss=0.465300 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.22301265597343445
[5/24] Train loss=0.19171293079853058
[10/24] Train loss=0.18649554252624512
[15/24] Train loss=0.1821279376745224
[20/24] Train loss=0.1942387968301773
Test set avg_accuracy=87.33% avg_sensitivity=80.00%, avg_specificity=89.79% avg_auc=93.65%
Fold[1] Epoch: 47 [47/100 (47%)] Train loss=0.199929 Test loss=0.405085 Current lr=[0.000860751215339601]

[0/24] Train loss=0.20677588880062103
[5/24] Train loss=0.16307485103607178
[10/24] Train loss=0.20901121199131012
[15/24] Train loss=0.1267290562391281
[20/24] Train loss=0.14800237119197845
Test set avg_accuracy=88.42% avg_sensitivity=78.60%, avg_specificity=91.72% avg_auc=93.54%
Fold[1] Epoch: 48 [48/100 (48%)] Train loss=0.177548 Test loss=0.384715 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.2099216878414154
[5/24] Train loss=0.16022415459156036
[10/24] Train loss=0.19686728715896606
[15/24] Train loss=0.1289500743150711
[20/24] Train loss=0.14761407673358917
Test set avg_accuracy=88.67% avg_sensitivity=78.19%, avg_specificity=92.19% avg_auc=93.29%
Fold[1] Epoch: 49 [49/100 (49%)] Train loss=0.172255 Test loss=0.416922 Current lr=[0.000828265354963756]

[0/24] Train loss=0.17271411418914795
[5/24] Train loss=0.1200043261051178
[10/24] Train loss=0.16470524668693542
[15/24] Train loss=0.13693584501743317
[20/24] Train loss=0.11469832062721252
Test set avg_accuracy=88.75% avg_sensitivity=75.70%, avg_specificity=93.13% avg_auc=93.25%
Fold[1] Epoch: 50 [50/100 (50%)] Train loss=0.147668 Test loss=0.462077 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.14437192678451538
[5/24] Train loss=0.1326095163822174
[10/24] Train loss=0.15303820371627808
[15/24] Train loss=0.10848192870616913
[20/24] Train loss=0.13595914840698242
Test set avg_accuracy=88.52% avg_sensitivity=72.18%, avg_specificity=94.00% avg_auc=93.07%
Fold[1] Epoch: 51 [51/100 (51%)] Train loss=0.138616 Test loss=0.470724 Current lr=[0.00079313651106947]

[0/24] Train loss=0.12976320087909698
[5/24] Train loss=0.14334861934185028
[10/24] Train loss=0.1529388129711151
[15/24] Train loss=0.10887514799833298
[20/24] Train loss=0.10306037962436676
Test set avg_accuracy=88.62% avg_sensitivity=69.12%, avg_specificity=95.17% avg_auc=92.61%
Fold[1] Epoch: 52 [52/100 (52%)] Train loss=0.134900 Test loss=0.568787 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.16084302961826324
[5/24] Train loss=0.14366692304611206
[10/24] Train loss=0.16208359599113464
[15/24] Train loss=0.11200783401727676
[20/24] Train loss=0.1146015003323555
Test set avg_accuracy=88.44% avg_sensitivity=70.78%, avg_specificity=94.37% avg_auc=92.82%
Fold[1] Epoch: 53 [53/100 (53%)] Train loss=0.137359 Test loss=0.588350 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.11407970637083054
[5/24] Train loss=0.12877553701400757
[10/24] Train loss=0.1381525993347168
[15/24] Train loss=0.11742059886455536
[20/24] Train loss=0.11646974086761475
Test set avg_accuracy=88.70% avg_sensitivity=71.30%, avg_specificity=94.54% avg_auc=92.56%
Fold[1] Epoch: 54 [54/100 (54%)] Train loss=0.128904 Test loss=0.511344 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.15004250407218933
[5/24] Train loss=0.10149949789047241
[10/24] Train loss=0.1316540688276291
[15/24] Train loss=0.10435228049755096
[20/24] Train loss=0.1041954904794693
Test set avg_accuracy=88.39% avg_sensitivity=69.02%, avg_specificity=94.89% avg_auc=92.63%
Fold[1] Epoch: 55 [55/100 (55%)] Train loss=0.119950 Test loss=0.515890 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.12049378454685211
[5/24] Train loss=0.09671974927186966
[10/24] Train loss=0.12909306585788727
[15/24] Train loss=0.1320023238658905
[20/24] Train loss=0.08853217959403992
Test set avg_accuracy=88.50% avg_sensitivity=73.47%, avg_specificity=93.55% avg_auc=93.16%
Fold[1] Epoch: 56 [56/100 (56%)] Train loss=0.115506 Test loss=0.554908 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.12634383141994476
[5/24] Train loss=0.09114326536655426
[10/24] Train loss=0.1348164677619934
[15/24] Train loss=0.08720598369836807
[20/24] Train loss=0.09373205155134201
Test set avg_accuracy=88.41% avg_sensitivity=76.99%, avg_specificity=92.24% avg_auc=93.41%
Fold[1] Epoch: 57 [57/100 (57%)] Train loss=0.108815 Test loss=0.597904 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.1169280856847763
[5/24] Train loss=0.08816004544496536
[10/24] Train loss=0.12348417192697525
[15/24] Train loss=0.07241227477788925
[20/24] Train loss=0.09277002513408661
Test set avg_accuracy=89.18% avg_sensitivity=72.80%, avg_specificity=94.68% avg_auc=93.38%
Fold[1] Epoch: 58 [58/100 (58%)] Train loss=0.098421 Test loss=0.605880 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.08007695525884628
[5/24] Train loss=0.07351349294185638
[10/24] Train loss=0.08348015695810318
[15/24] Train loss=0.0846385732293129
[20/24] Train loss=0.09250824898481369
Test set avg_accuracy=88.70% avg_sensitivity=70.67%, avg_specificity=94.75% avg_auc=93.30%
Fold[1] Epoch: 59 [59/100 (59%)] Train loss=0.079837 Test loss=0.572821 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.09632889926433563
[5/24] Train loss=0.07345210760831833
[10/24] Train loss=0.08185545355081558
[15/24] Train loss=0.08028596639633179
[20/24] Train loss=0.062258172780275345
Test set avg_accuracy=89.00% avg_sensitivity=71.45%, avg_specificity=94.89% avg_auc=93.72%
Fold[1] Epoch: 60 [60/100 (60%)] Train loss=0.072621 Test loss=0.619368 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.07063862681388855
[5/24] Train loss=0.05823144316673279
[10/24] Train loss=0.07444948703050613
[15/24] Train loss=0.06983140856027603
[20/24] Train loss=0.057141877710819244
Test set avg_accuracy=88.39% avg_sensitivity=71.97%, avg_specificity=93.90% avg_auc=93.50%
Fold[1] Epoch: 61 [61/100 (61%)] Train loss=0.068755 Test loss=0.616362 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.05657995492219925
[5/24] Train loss=0.05047101154923439
[10/24] Train loss=0.054209884256124496
[15/24] Train loss=0.05673866346478462
[20/24] Train loss=0.050255998969078064
Test set avg_accuracy=89.09% avg_sensitivity=74.35%, avg_specificity=94.03% avg_auc=93.76%
Fold[1] Epoch: 62 [62/100 (62%)] Train loss=0.055936 Test loss=0.594606 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.04800353944301605
[5/24] Train loss=0.04182681068778038
[10/24] Train loss=0.06865177303552628
[15/24] Train loss=0.04303549975156784
[20/24] Train loss=0.047677166759967804
Test set avg_accuracy=88.54% avg_sensitivity=73.94%, avg_specificity=93.44% avg_auc=93.79%
Fold[1] Epoch: 63 [63/100 (63%)] Train loss=0.052616 Test loss=0.627042 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.050302404910326004
[5/24] Train loss=0.042046912014484406
[10/24] Train loss=0.05075136199593544
[15/24] Train loss=0.040319863706827164
[20/24] Train loss=0.04273552820086479
Test set avg_accuracy=88.22% avg_sensitivity=75.49%, avg_specificity=92.49% avg_auc=93.78%
Fold[1] Epoch: 64 [64/100 (64%)] Train loss=0.046128 Test loss=0.643782 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.0622810423374176
[5/24] Train loss=0.02678688056766987
[10/24] Train loss=0.04803238809108734
[15/24] Train loss=0.034834615886211395
[20/24] Train loss=0.037763334810733795
Test set avg_accuracy=88.62% avg_sensitivity=76.74%, avg_specificity=92.61% avg_auc=93.88%
Fold[1] Epoch: 65 [65/100 (65%)] Train loss=0.043527 Test loss=0.733060 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.0408596433699131
[5/24] Train loss=0.039057787507772446
[10/24] Train loss=0.040580783039331436
[15/24] Train loss=0.03297826647758484
[20/24] Train loss=0.03640289604663849
Test set avg_accuracy=88.59% avg_sensitivity=75.60%, avg_specificity=92.96% avg_auc=93.82%
Fold[1] Epoch: 66 [66/100 (66%)] Train loss=0.038617 Test loss=0.644531 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.0417795367538929
[5/24] Train loss=0.029384786263108253
[10/24] Train loss=0.036717966198921204
[15/24] Train loss=0.032168906182050705
[20/24] Train loss=0.02837667241692543
Test set avg_accuracy=88.42% avg_sensitivity=74.97%, avg_specificity=92.94% avg_auc=93.90%
Fold[1] Epoch: 67 [67/100 (67%)] Train loss=0.034971 Test loss=0.639530 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.043967828154563904
[5/24] Train loss=0.022732585668563843
[10/24] Train loss=0.03687398135662079
[15/24] Train loss=0.025583382695913315
[20/24] Train loss=0.03743791952729225
Test set avg_accuracy=88.98% avg_sensitivity=74.72%, avg_specificity=93.77% avg_auc=93.87%
Fold[1] Epoch: 68 [68/100 (68%)] Train loss=0.031167 Test loss=0.708148 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.04113580659031868
[5/24] Train loss=0.026244230568408966
[10/24] Train loss=0.04462695121765137
[15/24] Train loss=0.02269839495420456
[20/24] Train loss=0.027985064312815666
Test set avg_accuracy=88.74% avg_sensitivity=73.42%, avg_specificity=93.88% avg_auc=93.94%
Fold[1] Epoch: 69 [69/100 (69%)] Train loss=0.030636 Test loss=0.680932 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.030873334035277367
[5/24] Train loss=0.02337757870554924
[10/24] Train loss=0.02674141339957714
[15/24] Train loss=0.031219173222780228
[20/24] Train loss=0.029079090803861618
Test set avg_accuracy=88.62% avg_sensitivity=72.69%, avg_specificity=93.97% avg_auc=93.85%
Fold[1] Epoch: 70 [70/100 (70%)] Train loss=0.027670 Test loss=0.759200 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.03042869083583355
[5/24] Train loss=0.021298687905073166
[10/24] Train loss=0.028931420296430588
[15/24] Train loss=0.021922007203102112
[20/24] Train loss=0.027136828750371933
Test set avg_accuracy=88.65% avg_sensitivity=73.99%, avg_specificity=93.57% avg_auc=93.87%
Fold[1] Epoch: 71 [71/100 (71%)] Train loss=0.024743 Test loss=0.745559 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.036169666796922684
[5/24] Train loss=0.017588334158062935
[10/24] Train loss=0.02144128642976284
[15/24] Train loss=0.024821044877171516
[20/24] Train loss=0.020972976461052895
Test set avg_accuracy=88.75% avg_sensitivity=73.58%, avg_specificity=93.84% avg_auc=93.79%
Fold[1] Epoch: 72 [72/100 (72%)] Train loss=0.024234 Test loss=0.761281 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.02918967232108116
[5/24] Train loss=0.022095466032624245
[10/24] Train loss=0.021588625386357307
[15/24] Train loss=0.018401242792606354
[20/24] Train loss=0.02055542729794979
Test set avg_accuracy=89.00% avg_sensitivity=75.23%, avg_specificity=93.62% avg_auc=93.91%
Fold[1] Epoch: 73 [73/100 (73%)] Train loss=0.022719 Test loss=0.763208 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.025302667170763016
[5/24] Train loss=0.014812088571488857
[10/24] Train loss=0.022863898426294327
[15/24] Train loss=0.013234457932412624
[20/24] Train loss=0.01465314719825983
Test set avg_accuracy=88.88% avg_sensitivity=73.11%, avg_specificity=94.17% avg_auc=93.79%
Fold[1] Epoch: 74 [74/100 (74%)] Train loss=0.021801 Test loss=0.770427 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.029731158167123795
[5/24] Train loss=0.023230481892824173
[10/24] Train loss=0.01927061565220356
[15/24] Train loss=0.020742757245898247
[20/24] Train loss=0.013759120367467403
Test set avg_accuracy=88.82% avg_sensitivity=73.58%, avg_specificity=93.93% avg_auc=93.87%
Fold[1] Epoch: 75 [75/100 (75%)] Train loss=0.021850 Test loss=0.768700 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.019734196364879608
[5/24] Train loss=0.015397190116345882
[10/24] Train loss=0.020267054438591003
[15/24] Train loss=0.01924259215593338
[20/24] Train loss=0.020740406587719917
Test set avg_accuracy=89.17% avg_sensitivity=73.83%, avg_specificity=94.31% avg_auc=93.81%
Fold[1] Epoch: 76 [76/100 (76%)] Train loss=0.020464 Test loss=0.751311 Current lr=[0.000262245679641298]

[0/24] Train loss=0.01953074149787426
[5/24] Train loss=0.013567587360739708
[10/24] Train loss=0.021530641242861748
[15/24] Train loss=0.018785646185278893
[20/24] Train loss=0.017796985805034637
Test set avg_accuracy=88.79% avg_sensitivity=73.47%, avg_specificity=93.93% avg_auc=93.76%
Fold[1] Epoch: 77 [77/100 (77%)] Train loss=0.020879 Test loss=0.784070 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.017420491203665733
[5/24] Train loss=0.013248398900032043
[10/24] Train loss=0.018018821254372597
[15/24] Train loss=0.01244500745087862
[20/24] Train loss=0.020176300778985023
Test set avg_accuracy=88.88% avg_sensitivity=73.63%, avg_specificity=94.00% avg_auc=93.86%
Fold[1] Epoch: 78 [78/100 (78%)] Train loss=0.018100 Test loss=0.796585 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.016205357387661934
[5/24] Train loss=0.012850652448832989
[10/24] Train loss=0.018215427175164223
[15/24] Train loss=0.018450818955898285
[20/24] Train loss=0.016216525807976723
Test set avg_accuracy=88.91% avg_sensitivity=72.95%, avg_specificity=94.26% avg_auc=93.83%
Fold[1] Epoch: 79 [79/100 (79%)] Train loss=0.018011 Test loss=0.780211 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.020369671285152435
[5/24] Train loss=0.013701586052775383
[10/24] Train loss=0.01740872487425804
[15/24] Train loss=0.012620865367352962
[20/24] Train loss=0.011327940039336681
Test set avg_accuracy=88.80% avg_sensitivity=72.90%, avg_specificity=94.14% avg_auc=93.86%
Fold[1] Epoch: 80 [80/100 (80%)] Train loss=0.017655 Test loss=0.775812 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.014062910340726376
[5/24] Train loss=0.014994236640632153
[10/24] Train loss=0.016112416982650757
[15/24] Train loss=0.01342262327671051
[20/24] Train loss=0.015807971358299255
Test set avg_accuracy=88.92% avg_sensitivity=72.18%, avg_specificity=94.54% avg_auc=93.87%
Fold[1] Epoch: 81 [81/100 (81%)] Train loss=0.016271 Test loss=0.763752 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.015244239941239357
[5/24] Train loss=0.008763191290199757
[10/24] Train loss=0.02108153887093067
[15/24] Train loss=0.010476493276655674
[20/24] Train loss=0.01384748611599207
Test set avg_accuracy=88.89% avg_sensitivity=73.01%, avg_specificity=94.23% avg_auc=93.92%
Fold[1] Epoch: 82 [82/100 (82%)] Train loss=0.015847 Test loss=0.776098 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.01599721983075142
[5/24] Train loss=0.013474281877279282
[10/24] Train loss=0.014873586595058441
[15/24] Train loss=0.012539400719106197
[20/24] Train loss=0.01603979803621769
Test set avg_accuracy=88.87% avg_sensitivity=73.78%, avg_specificity=93.93% avg_auc=93.94%
Fold[1] Epoch: 83 [83/100 (83%)] Train loss=0.015616 Test loss=0.779308 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.01692310906946659
[5/24] Train loss=0.012614949606359005
[10/24] Train loss=0.016125094145536423
[15/24] Train loss=0.009979349561035633
[20/24] Train loss=0.010454096831381321
Test set avg_accuracy=88.95% avg_sensitivity=73.32%, avg_specificity=94.19% avg_auc=93.88%
Fold[1] Epoch: 84 [84/100 (84%)] Train loss=0.015948 Test loss=0.782319 Current lr=[0.000122853263038123]

[0/24] Train loss=0.018406303599476814
[5/24] Train loss=0.008854644373059273
[10/24] Train loss=0.021082337945699692
[15/24] Train loss=0.014881869778037071
[20/24] Train loss=0.01721605286002159
Test set avg_accuracy=89.04% avg_sensitivity=73.32%, avg_specificity=94.31% avg_auc=93.91%
Fold[1] Epoch: 85 [85/100 (85%)] Train loss=0.015260 Test loss=0.784525 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.020533401519060135
[5/24] Train loss=0.014146276749670506
[10/24] Train loss=0.01424204558134079
[15/24] Train loss=0.016293643042445183
[20/24] Train loss=0.01478116400539875
Test set avg_accuracy=88.85% avg_sensitivity=73.21%, avg_specificity=94.10% avg_auc=93.86%
Fold[1] Epoch: 86 [86/100 (86%)] Train loss=0.015098 Test loss=0.777555 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.01395439449697733
[5/24] Train loss=0.01115081924945116
[10/24] Train loss=0.015660932287573814
[15/24] Train loss=0.011205457150936127
[20/24] Train loss=0.011240173131227493
Test set avg_accuracy=88.97% avg_sensitivity=72.75%, avg_specificity=94.42% avg_auc=93.82%
Fold[1] Epoch: 87 [87/100 (87%)] Train loss=0.013422 Test loss=0.782442 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.011547617614269257
[5/24] Train loss=0.014749418012797832
[10/24] Train loss=0.012639733962714672
[15/24] Train loss=0.017961328849196434
[20/24] Train loss=0.013521401211619377
Test set avg_accuracy=89.00% avg_sensitivity=73.26%, avg_specificity=94.28% avg_auc=93.85%
Fold[1] Epoch: 88 [88/100 (88%)] Train loss=0.015474 Test loss=0.787852 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.017184657976031303
[5/24] Train loss=0.010201279073953629
[10/24] Train loss=0.018431786447763443
[15/24] Train loss=0.011134432628750801
[20/24] Train loss=0.012169137597084045
Test set avg_accuracy=88.97% avg_sensitivity=73.42%, avg_specificity=94.19% avg_auc=93.89%
Fold[1] Epoch: 89 [89/100 (89%)] Train loss=0.014348 Test loss=0.788136 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.009751749224960804
[5/24] Train loss=0.009618906304240227
[10/24] Train loss=0.018486417829990387
[15/24] Train loss=0.016734864562749863
[20/24] Train loss=0.01198119018226862
Test set avg_accuracy=89.09% avg_sensitivity=73.16%, avg_specificity=94.43% avg_auc=93.89%
Fold[1] Epoch: 90 [90/100 (90%)] Train loss=0.013574 Test loss=0.789661 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.017333710566163063
[5/24] Train loss=0.009754501283168793
[10/24] Train loss=0.015863697975873947
[15/24] Train loss=0.01491254847496748
[20/24] Train loss=0.010880539193749428
Test set avg_accuracy=89.09% avg_sensitivity=73.21%, avg_specificity=94.42% avg_auc=93.88%
Fold[1] Epoch: 91 [91/100 (91%)] Train loss=0.014182 Test loss=0.787394 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.017460089176893234
[5/24] Train loss=0.014146620407700539
[10/24] Train loss=0.01333283819258213
[15/24] Train loss=0.017080871388316154
[20/24] Train loss=0.016010677441954613
Test set avg_accuracy=88.93% avg_sensitivity=73.52%, avg_specificity=94.10% avg_auc=93.90%
Fold[1] Epoch: 92 [92/100 (92%)] Train loss=0.013980 Test loss=0.785673 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.01905917003750801
[5/24] Train loss=0.010010870173573494
[10/24] Train loss=0.01403870526701212
[15/24] Train loss=0.014748903922736645
[20/24] Train loss=0.01201427448540926
Test set avg_accuracy=89.04% avg_sensitivity=73.52%, avg_specificity=94.24% avg_auc=93.91%
Fold[1] Epoch: 93 [93/100 (93%)] Train loss=0.014718 Test loss=0.786259 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.014918425120413303
[5/24] Train loss=0.012395712547004223
[10/24] Train loss=0.013401095755398273
[15/24] Train loss=0.010609385557472706
[20/24] Train loss=0.01697717234492302
Test set avg_accuracy=89.18% avg_sensitivity=73.52%, avg_specificity=94.43% avg_auc=93.92%
Fold[1] Epoch: 94 [94/100 (94%)] Train loss=0.013680 Test loss=0.785390 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.01567244902253151
[5/24] Train loss=0.009794037789106369
[10/24] Train loss=0.014917921274900436
[15/24] Train loss=0.011891670525074005
[20/24] Train loss=0.009136953391134739
Test set avg_accuracy=89.19% avg_sensitivity=73.52%, avg_specificity=94.45% avg_auc=93.92%
Fold[1] Epoch: 95 [95/100 (95%)] Train loss=0.013751 Test loss=0.786675 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.016092577949166298
[5/24] Train loss=0.010399479418992996
[10/24] Train loss=0.014464817941188812
[15/24] Train loss=0.013583335094153881
[20/24] Train loss=0.00952110718935728
Test set avg_accuracy=89.19% avg_sensitivity=73.52%, avg_specificity=94.45% avg_auc=93.92%
Fold[1] Epoch: 96 [96/100 (96%)] Train loss=0.013871 Test loss=0.787002 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.013183603063225746
[5/24] Train loss=0.010994510725140572
[10/24] Train loss=0.010226776823401451
[15/24] Train loss=0.01210802048444748
[20/24] Train loss=0.01625792495906353
Test set avg_accuracy=89.19% avg_sensitivity=73.47%, avg_specificity=94.47% avg_auc=93.91%
Fold[1] Epoch: 97 [97/100 (97%)] Train loss=0.013085 Test loss=0.787576 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.012039191089570522
[5/24] Train loss=0.01068654004484415
[10/24] Train loss=0.012554313987493515
[15/24] Train loss=0.013958909548819065
[20/24] Train loss=0.012520263902842999
Test set avg_accuracy=89.19% avg_sensitivity=73.52%, avg_specificity=94.45% avg_auc=93.91%
Fold[1] Epoch: 98 [98/100 (98%)] Train loss=0.012900 Test loss=0.788114 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.017320308834314346
[5/24] Train loss=0.010014766827225685
[10/24] Train loss=0.01209480594843626
[15/24] Train loss=0.010223176330327988
[20/24] Train loss=0.01135166734457016
Test set avg_accuracy=89.17% avg_sensitivity=73.42%, avg_specificity=94.45% avg_auc=93.92%
Fold[1] Epoch: 99 [99/100 (99%)] Train loss=0.013469 Test loss=0.787929 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.01849488914012909
[5/24] Train loss=0.013749854639172554
[10/24] Train loss=0.024180864915251732
[15/24] Train loss=0.012398832477629185
[20/24] Train loss=0.01124529168009758
Test set avg_accuracy=89.19% avg_sensitivity=73.47%, avg_specificity=94.47% avg_auc=93.92%
Fold[1] Epoch: 100 [100/100 (100%)] Train loss=0.014239 Test loss=0.787379 Current lr=[4.874217159761039e-09]

Fold[1] Result: acc=88.96% sen=74.77%, spe=93.72%, auc=94.42%!
Fold[1] Avg_overlap=0.70%(Â±0.2621260638020794)
[0/24] Train loss=1.396139144897461
[5/24] Train loss=1.2981016635894775
[10/24] Train loss=1.2608015537261963
[15/24] Train loss=1.039724588394165
[20/24] Train loss=1.0332691669464111
Test set avg_accuracy=73.74% avg_sensitivity=26.35%, avg_specificity=92.54% avg_auc=74.16%
Best model saved!! Metric=74.15770971128907!!
Fold[2] Epoch: 1 [1/100 (1%)] Train loss=1.210678 Test loss=0.676696 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=0.9303768277168274
[5/24] Train loss=0.9481559991836548
[10/24] Train loss=0.9255068898200989
[15/24] Train loss=0.8652173280715942
[20/24] Train loss=0.9010206460952759
Test set avg_accuracy=80.01% avg_sensitivity=55.13%, avg_specificity=89.89% avg_auc=83.99%
Best model saved!! Metric=83.99189572810243!!
Fold[2] Epoch: 2 [2/100 (2%)] Train loss=0.947991 Test loss=0.549621 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.7963279485702515
[5/24] Train loss=0.9122945666313171
[10/24] Train loss=0.8450176119804382
[15/24] Train loss=0.7671113610267639
[20/24] Train loss=0.7608919143676758
Test set avg_accuracy=83.28% avg_sensitivity=63.43%, avg_specificity=91.16% avg_auc=88.11%
Best model saved!! Metric=88.10500710365805!!
Fold[2] Epoch: 3 [3/100 (3%)] Train loss=0.849175 Test loss=0.424809 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.7505544424057007
[5/24] Train loss=0.8340917229652405
[10/24] Train loss=0.7949345707893372
[15/24] Train loss=0.6953632831573486
[20/24] Train loss=0.7548420429229736
Test set avg_accuracy=85.43% avg_sensitivity=75.99%, avg_specificity=89.18% avg_auc=91.23%
Best model saved!! Metric=91.23206288829635!!
Fold[2] Epoch: 4 [4/100 (4%)] Train loss=0.793743 Test loss=0.362350 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.6863464117050171
[5/24] Train loss=0.8156049251556396
[10/24] Train loss=0.7636763453483582
[15/24] Train loss=0.6880645751953125
[20/24] Train loss=0.7202277183532715
Test set avg_accuracy=85.53% avg_sensitivity=80.48%, avg_specificity=87.54% avg_auc=92.15%
Best model saved!! Metric=92.152729315118!!
Fold[2] Epoch: 5 [5/100 (5%)] Train loss=0.756408 Test loss=0.362046 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.7188581228256226
[5/24] Train loss=0.7925972938537598
[10/24] Train loss=0.7434417605400085
[15/24] Train loss=0.6748325824737549
[20/24] Train loss=0.6972275376319885
Test set avg_accuracy=86.41% avg_sensitivity=80.29%, avg_specificity=88.83% avg_auc=92.76%
Best model saved!! Metric=92.76338800310354!!
Fold[2] Epoch: 6 [6/100 (6%)] Train loss=0.740279 Test loss=0.343630 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.6451060771942139
[5/24] Train loss=0.7455095052719116
[10/24] Train loss=0.7015737295150757
[15/24] Train loss=0.6514472961425781
[20/24] Train loss=0.6841298937797546
Test set avg_accuracy=86.59% avg_sensitivity=81.16%, avg_specificity=88.74% avg_auc=92.85%
Best model saved!! Metric=92.85220040017886!!
Fold[2] Epoch: 7 [7/100 (7%)] Train loss=0.705556 Test loss=0.335372 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.6309622526168823
[5/24] Train loss=0.7472871541976929
[10/24] Train loss=0.717359721660614
[15/24] Train loss=0.6446840763092041
[20/24] Train loss=0.6659673452377319
Test set avg_accuracy=86.55% avg_sensitivity=80.66%, avg_specificity=88.89% avg_auc=92.86%
Best model saved!! Metric=92.86041520306192!!
Fold[2] Epoch: 8 [8/100 (8%)] Train loss=0.696814 Test loss=0.334950 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.6091741919517517
[5/24] Train loss=0.676555335521698
[10/24] Train loss=0.7079974412918091
[15/24] Train loss=0.6055967211723328
[20/24] Train loss=0.6404783129692078
Test set avg_accuracy=87.42% avg_sensitivity=78.32%, avg_specificity=91.03% avg_auc=93.20%
Best model saved!! Metric=93.19839328291697!!
Fold[2] Epoch: 9 [9/100 (9%)] Train loss=0.668223 Test loss=0.320694 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.5699030160903931
[5/24] Train loss=0.6636032462120056
[10/24] Train loss=0.6753705739974976
[15/24] Train loss=0.6043170094490051
[20/24] Train loss=0.6317588686943054
Test set avg_accuracy=87.63% avg_sensitivity=78.51%, avg_specificity=91.25% avg_auc=93.23%
Best model saved!! Metric=93.22992712290346!!
Fold[2] Epoch: 10 [10/100 (10%)] Train loss=0.656927 Test loss=0.314802 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.5532566905021667
[5/24] Train loss=0.6469557285308838
[10/24] Train loss=0.6462429165840149
[15/24] Train loss=0.582828938961029
[20/24] Train loss=0.6375705003738403
Test set avg_accuracy=87.11% avg_sensitivity=83.78%, avg_specificity=88.43% avg_auc=93.45%
Best model saved!! Metric=93.45256036775642!!
Fold[2] Epoch: 11 [11/100 (11%)] Train loss=0.642322 Test loss=0.330933 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.573813796043396
[5/24] Train loss=0.6276634335517883
[10/24] Train loss=0.659392237663269
[15/24] Train loss=0.6030514240264893
[20/24] Train loss=0.6086917519569397
Test set avg_accuracy=87.67% avg_sensitivity=81.39%, avg_specificity=90.16% avg_auc=93.27%
Fold[2] Epoch: 12 [12/100 (12%)] Train loss=0.640254 Test loss=0.318433 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.5570387840270996
[5/24] Train loss=0.6197651624679565
[10/24] Train loss=0.6391521692276001
[15/24] Train loss=0.5756709575653076
[20/24] Train loss=0.6004486680030823
Test set avg_accuracy=87.73% avg_sensitivity=80.34%, avg_specificity=90.67% avg_auc=93.50%
Best model saved!! Metric=93.50372054299221!!
Fold[2] Epoch: 13 [13/100 (13%)] Train loss=0.624180 Test loss=0.303470 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.5661227703094482
[5/24] Train loss=0.6071092486381531
[10/24] Train loss=0.6352113485336304
[15/24] Train loss=0.5698763132095337
[20/24] Train loss=0.5514410734176636
Test set avg_accuracy=88.62% avg_sensitivity=72.46%, avg_specificity=95.03% avg_auc=93.30%
Fold[2] Epoch: 14 [14/100 (14%)] Train loss=0.612139 Test loss=0.320140 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.5478625297546387
[5/24] Train loss=0.5930171012878418
[10/24] Train loss=0.6315344572067261
[15/24] Train loss=0.5582019090652466
[20/24] Train loss=0.5649932622909546
Test set avg_accuracy=87.75% avg_sensitivity=66.87%, avg_specificity=96.03% avg_auc=92.94%
Fold[2] Epoch: 15 [15/100 (15%)] Train loss=0.600682 Test loss=0.326505 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.5531333088874817
[5/24] Train loss=0.5830734968185425
[10/24] Train loss=0.627895176410675
[15/24] Train loss=0.568902313709259
[20/24] Train loss=0.6271994709968567
Test set avg_accuracy=88.82% avg_sensitivity=77.04%, avg_specificity=93.49% avg_auc=93.20%
Fold[2] Epoch: 16 [16/100 (16%)] Train loss=0.606286 Test loss=0.309052 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5554806590080261
[5/24] Train loss=0.5683007836341858
[10/24] Train loss=0.6091329455375671
[15/24] Train loss=0.5456370115280151
[20/24] Train loss=0.5745235085487366
Test set avg_accuracy=89.04% avg_sensitivity=80.48%, avg_specificity=92.43% avg_auc=93.92%
Best model saved!! Metric=93.9247927502343!!
Fold[2] Epoch: 17 [17/100 (17%)] Train loss=0.599551 Test loss=0.301449 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5363988876342773
[5/24] Train loss=0.5834306478500366
[10/24] Train loss=0.6491376757621765
[15/24] Train loss=0.5563640594482422
[20/24] Train loss=0.5461536049842834
Test set avg_accuracy=87.86% avg_sensitivity=70.81%, avg_specificity=94.63% avg_auc=93.42%
Fold[2] Epoch: 18 [18/100 (18%)] Train loss=0.588564 Test loss=0.317828 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.5273787379264832
[5/24] Train loss=0.5539932250976562
[10/24] Train loss=0.5920933485031128
[15/24] Train loss=0.5441470742225647
[20/24] Train loss=0.5629567503929138
Test set avg_accuracy=88.98% avg_sensitivity=74.84%, avg_specificity=94.60% avg_auc=93.93%
Best model saved!! Metric=93.92879803971714!!
Fold[2] Epoch: 19 [19/100 (19%)] Train loss=0.575892 Test loss=0.286544 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5030044913291931
[5/24] Train loss=0.599208652973175
[10/24] Train loss=0.6287859678268433
[15/24] Train loss=0.5689520835876465
[20/24] Train loss=0.5697957277297974
Test set avg_accuracy=88.44% avg_sensitivity=69.02%, avg_specificity=96.14% avg_auc=94.03%
Best model saved!! Metric=94.03016812379738!!
Fold[2] Epoch: 20 [20/100 (20%)] Train loss=0.584465 Test loss=0.280055 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5750272274017334
[5/24] Train loss=0.5273750424385071
[10/24] Train loss=0.6496433019638062
[15/24] Train loss=0.536935567855835
[20/24] Train loss=0.5096341371536255
Test set avg_accuracy=88.58% avg_sensitivity=73.24%, avg_specificity=94.67% avg_auc=93.56%
Fold[2] Epoch: 21 [21/100 (21%)] Train loss=0.563787 Test loss=0.296358 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.5180657505989075
[5/24] Train loss=0.5074622631072998
[10/24] Train loss=0.5920972228050232
[15/24] Train loss=0.48776566982269287
[20/24] Train loss=0.5185867547988892
Test set avg_accuracy=87.54% avg_sensitivity=68.79%, avg_specificity=94.98% avg_auc=93.37%
Fold[2] Epoch: 22 [22/100 (22%)] Train loss=0.556566 Test loss=0.312292 Current lr=[0.000842324016282456]

[0/24] Train loss=0.5032731890678406
[5/24] Train loss=0.5296979546546936
[10/24] Train loss=0.6097772121429443
[15/24] Train loss=0.5299779772758484
[20/24] Train loss=0.5919152498245239
Test set avg_accuracy=88.63% avg_sensitivity=78.37%, avg_specificity=92.71% avg_auc=94.22%
Best model saved!! Metric=94.21532419588291!!
Fold[2] Epoch: 23 [23/100 (23%)] Train loss=0.557988 Test loss=0.292383 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.48603683710098267
[5/24] Train loss=0.5191707611083984
[10/24] Train loss=0.6220380663871765
[15/24] Train loss=0.5051863789558411
[20/24] Train loss=0.4942450225353241
Test set avg_accuracy=88.71% avg_sensitivity=72.04%, avg_specificity=95.33% avg_auc=93.95%
Fold[2] Epoch: 24 [24/100 (24%)] Train loss=0.533773 Test loss=0.314956 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.46679237484931946
[5/24] Train loss=0.48853203654289246
[10/24] Train loss=0.5580779910087585
[15/24] Train loss=0.4881742298603058
[20/24] Train loss=0.4696703255176544
Test set avg_accuracy=89.10% avg_sensitivity=75.85%, avg_specificity=94.36% avg_auc=94.05%
Fold[2] Epoch: 25 [25/100 (25%)] Train loss=0.515889 Test loss=0.292961 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.45838332176208496
[5/24] Train loss=0.4918040335178375
[10/24] Train loss=0.5373587608337402
[15/24] Train loss=0.462968111038208
[20/24] Train loss=0.45617181062698364
Test set avg_accuracy=88.98% avg_sensitivity=72.04%, avg_specificity=95.71% avg_auc=94.36%
Best model saved!! Metric=94.3561845170596!!
Fold[2] Epoch: 26 [26/100 (26%)] Train loss=0.505869 Test loss=0.297212 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.44914814829826355
[5/24] Train loss=0.48386189341545105
[10/24] Train loss=0.4888993501663208
[15/24] Train loss=0.5033752918243408
[20/24] Train loss=0.4960572123527527
Test set avg_accuracy=88.82% avg_sensitivity=75.30%, avg_specificity=94.18% avg_auc=93.65%
Fold[2] Epoch: 27 [27/100 (27%)] Train loss=0.490192 Test loss=0.299365 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.4530327022075653
[5/24] Train loss=0.43654704093933105
[10/24] Train loss=0.5357331037521362
[15/24] Train loss=0.4343727231025696
[20/24] Train loss=0.4268782436847687
Test set avg_accuracy=88.28% avg_sensitivity=71.77%, avg_specificity=94.83% avg_auc=94.02%
Fold[2] Epoch: 28 [28/100 (28%)] Train loss=0.486835 Test loss=0.315352 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.45380571484565735
[5/24] Train loss=0.4248015582561493
[10/24] Train loss=0.48344963788986206
[15/24] Train loss=0.4307432770729065
[20/24] Train loss=0.4157801568508148
Test set avg_accuracy=89.11% avg_sensitivity=77.86%, avg_specificity=93.58% avg_auc=94.39%
Best model saved!! Metric=94.38992314178742!!
Fold[2] Epoch: 29 [29/100 (29%)] Train loss=0.460950 Test loss=0.300317 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.4171830117702484
[5/24] Train loss=0.450490266084671
[10/24] Train loss=0.4869786202907562
[15/24] Train loss=0.39723899960517883
[20/24] Train loss=0.39045318961143494
Test set avg_accuracy=88.80% avg_sensitivity=75.21%, avg_specificity=94.20% avg_auc=93.93%
Fold[2] Epoch: 30 [30/100 (30%)] Train loss=0.452572 Test loss=0.311696 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.417765736579895
[5/24] Train loss=0.39951571822166443
[10/24] Train loss=0.4630095958709717
[15/24] Train loss=0.3851451575756073
[20/24] Train loss=0.4248576760292053
Test set avg_accuracy=87.66% avg_sensitivity=66.36%, avg_specificity=96.11% avg_auc=92.90%
Fold[2] Epoch: 31 [31/100 (31%)] Train loss=0.428630 Test loss=0.354418 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.4413588345050812
[5/24] Train loss=0.4231737554073334
[10/24] Train loss=0.45326927304267883
[15/24] Train loss=0.39460036158561707
[20/24] Train loss=0.3750593662261963
Test set avg_accuracy=88.20% avg_sensitivity=73.01%, avg_specificity=94.23% avg_auc=93.92%
Fold[2] Epoch: 32 [32/100 (32%)] Train loss=0.432160 Test loss=0.311562 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.4001314640045166
[5/24] Train loss=0.3858211040496826
[10/24] Train loss=0.4399547278881073
[15/24] Train loss=0.3865414559841156
[20/24] Train loss=0.40155407786369324
Test set avg_accuracy=88.75% avg_sensitivity=75.30%, avg_specificity=94.09% avg_auc=94.30%
Fold[2] Epoch: 33 [33/100 (33%)] Train loss=0.417326 Test loss=0.305941 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.377448171377182
[5/24] Train loss=0.39332327246665955
[10/24] Train loss=0.4871616065502167
[15/24] Train loss=0.34898191690444946
[20/24] Train loss=0.37045133113861084
Test set avg_accuracy=87.63% avg_sensitivity=64.80%, avg_specificity=96.69% avg_auc=92.80%
Fold[2] Epoch: 34 [34/100 (34%)] Train loss=0.402433 Test loss=0.386701 Current lr=[0.000991797016730875]

[0/24] Train loss=0.3425438404083252
[5/24] Train loss=0.3754490613937378
[10/24] Train loss=0.38423803448677063
[15/24] Train loss=0.36022403836250305
[20/24] Train loss=0.3894503712654114
Test set avg_accuracy=88.50% avg_sensitivity=71.59%, avg_specificity=95.22% avg_auc=93.79%
Fold[2] Epoch: 35 [35/100 (35%)] Train loss=0.385167 Test loss=0.326976 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.3418554365634918
[5/24] Train loss=0.36219295859336853
[10/24] Train loss=0.3707161545753479
[15/24] Train loss=0.31140920519828796
[20/24] Train loss=0.3100391626358032
Test set avg_accuracy=88.33% avg_sensitivity=74.34%, avg_specificity=93.89% avg_auc=93.74%
Fold[2] Epoch: 36 [36/100 (36%)] Train loss=0.360863 Test loss=0.319223 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.33677083253860474
[5/24] Train loss=0.3484579920768738
[10/24] Train loss=0.41132915019989014
[15/24] Train loss=0.28011977672576904
[20/24] Train loss=0.3007293939590454
Test set avg_accuracy=88.57% avg_sensitivity=78.51%, avg_specificity=92.56% avg_auc=93.95%
Fold[2] Epoch: 37 [37/100 (37%)] Train loss=0.344752 Test loss=0.343368 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.29563701152801514
[5/24] Train loss=0.29385650157928467
[10/24] Train loss=0.3475532531738281
[15/24] Train loss=0.3130229413509369
[20/24] Train loss=0.2926822304725647
Test set avg_accuracy=87.64% avg_sensitivity=65.22%, avg_specificity=96.54% avg_auc=92.65%
Fold[2] Epoch: 38 [38/100 (38%)] Train loss=0.319384 Test loss=0.471990 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.30407315492630005
[5/24] Train loss=0.3031689524650574
[10/24] Train loss=0.3013099133968353
[15/24] Train loss=0.28985077142715454
[20/24] Train loss=0.2772221267223358
Test set avg_accuracy=88.19% avg_sensitivity=69.20%, avg_specificity=95.73% avg_auc=92.86%
Fold[2] Epoch: 39 [39/100 (39%)] Train loss=0.303106 Test loss=0.449835 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.27261534333229065
[5/24] Train loss=0.2779979109764099
[10/24] Train loss=0.310346394777298
[15/24] Train loss=0.2421906590461731
[20/24] Train loss=0.25225508213043213
Test set avg_accuracy=88.09% avg_sensitivity=74.79%, avg_specificity=93.36% avg_auc=93.44%
Fold[2] Epoch: 40 [40/100 (40%)] Train loss=0.278977 Test loss=0.384175 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.24752803146839142
[5/24] Train loss=0.27759379148483276
[10/24] Train loss=0.2718106210231781
[15/24] Train loss=0.24218589067459106
[20/24] Train loss=0.24655812978744507
Test set avg_accuracy=88.70% avg_sensitivity=76.95%, avg_specificity=93.36% avg_auc=93.74%
Fold[2] Epoch: 41 [41/100 (41%)] Train loss=0.262062 Test loss=0.398181 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.2500574588775635
[5/24] Train loss=0.22175131738185883
[10/24] Train loss=0.2702096402645111
[15/24] Train loss=0.20873750746250153
[20/24] Train loss=0.23144780099391937
Test set avg_accuracy=88.79% avg_sensitivity=73.51%, avg_specificity=94.85% avg_auc=93.55%
Fold[2] Epoch: 42 [42/100 (42%)] Train loss=0.247956 Test loss=0.390237 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.2117646485567093
[5/24] Train loss=0.230063334107399
[10/24] Train loss=0.25925424695014954
[15/24] Train loss=0.17817240953445435
[20/24] Train loss=0.2347683608531952
Test set avg_accuracy=87.53% avg_sensitivity=78.64%, avg_specificity=91.05% avg_auc=93.28%
Fold[2] Epoch: 43 [43/100 (43%)] Train loss=0.231274 Test loss=0.434675 Current lr=[0.000916771143003274]

[0/24] Train loss=0.2214479297399521
[5/24] Train loss=0.18745499849319458
[10/24] Train loss=0.2605329751968384
[15/24] Train loss=0.1770196110010147
[20/24] Train loss=0.18814466893672943
Test set avg_accuracy=87.86% avg_sensitivity=77.96%, avg_specificity=91.80% avg_auc=92.93%
Fold[2] Epoch: 44 [44/100 (44%)] Train loss=0.215103 Test loss=0.397949 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.22328215837478638
[5/24] Train loss=0.21452751755714417
[10/24] Train loss=0.25101229548454285
[15/24] Train loss=0.20863978564739227
[20/24] Train loss=0.1947726011276245
Test set avg_accuracy=87.77% avg_sensitivity=75.57%, avg_specificity=92.62% avg_auc=93.40%
Fold[2] Epoch: 45 [45/100 (45%)] Train loss=0.220511 Test loss=0.387565 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.21355293691158295
[5/24] Train loss=0.14388889074325562
[10/24] Train loss=0.19177640974521637
[15/24] Train loss=0.18547622859477997
[20/24] Train loss=0.17649158835411072
Test set avg_accuracy=87.73% avg_sensitivity=73.60%, avg_specificity=93.34% avg_auc=93.49%
Fold[2] Epoch: 46 [46/100 (46%)] Train loss=0.196490 Test loss=0.418984 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.1813327521085739
[5/24] Train loss=0.14544054865837097
[10/24] Train loss=0.18922047317028046
[15/24] Train loss=0.17949643731117249
[20/24] Train loss=0.1562367081642151
Test set avg_accuracy=87.80% avg_sensitivity=79.06%, avg_specificity=91.27% avg_auc=93.13%
Fold[2] Epoch: 47 [47/100 (47%)] Train loss=0.181781 Test loss=0.526352 Current lr=[0.000860751215339601]

[0/24] Train loss=0.1945449560880661
[5/24] Train loss=0.13577643036842346
[10/24] Train loss=0.17095808684825897
[15/24] Train loss=0.1732572466135025
[20/24] Train loss=0.13282327353954315
Test set avg_accuracy=87.97% avg_sensitivity=74.93%, avg_specificity=93.14% avg_auc=93.26%
Fold[2] Epoch: 48 [48/100 (48%)] Train loss=0.162705 Test loss=0.583317 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.1548391729593277
[5/24] Train loss=0.13321441411972046
[10/24] Train loss=0.15014579892158508
[15/24] Train loss=0.12611103057861328
[20/24] Train loss=0.11209448426961899
Test set avg_accuracy=87.72% avg_sensitivity=75.30%, avg_specificity=92.65% avg_auc=93.29%
Fold[2] Epoch: 49 [49/100 (49%)] Train loss=0.146208 Test loss=0.507051 Current lr=[0.000828265354963756]

[0/24] Train loss=0.11950239539146423
[5/24] Train loss=0.1395520567893982
[10/24] Train loss=0.12597410380840302
[15/24] Train loss=0.13331979513168335
[20/24] Train loss=0.13389462232589722
Test set avg_accuracy=87.98% avg_sensitivity=72.59%, avg_specificity=94.09% avg_auc=93.71%
Fold[2] Epoch: 50 [50/100 (50%)] Train loss=0.135299 Test loss=0.522919 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.12088417261838913
[5/24] Train loss=0.11584620177745819
[10/24] Train loss=0.157027468085289
[15/24] Train loss=0.11972275376319885
[20/24] Train loss=0.11061499267816544
Test set avg_accuracy=87.54% avg_sensitivity=71.59%, avg_specificity=93.87% avg_auc=93.41%
Fold[2] Epoch: 51 [51/100 (51%)] Train loss=0.128474 Test loss=0.537965 Current lr=[0.00079313651106947]

[0/24] Train loss=0.0892820656299591
[5/24] Train loss=0.11559916287660599
[10/24] Train loss=0.13562756776809692
[15/24] Train loss=0.09789936989545822
[20/24] Train loss=0.1036602109670639
Test set avg_accuracy=88.12% avg_sensitivity=69.52%, avg_specificity=95.51% avg_auc=93.42%
Fold[2] Epoch: 52 [52/100 (52%)] Train loss=0.116107 Test loss=0.584076 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.12093710154294968
[5/24] Train loss=0.10624485462903976
[10/24] Train loss=0.13094818592071533
[15/24] Train loss=0.10607942938804626
[20/24] Train loss=0.09602529555559158
Test set avg_accuracy=87.85% avg_sensitivity=65.72%, avg_specificity=96.64% avg_auc=93.30%
Fold[2] Epoch: 53 [53/100 (53%)] Train loss=0.111031 Test loss=0.630084 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.09897416085004807
[5/24] Train loss=0.0911237969994545
[10/24] Train loss=0.11825726181268692
[15/24] Train loss=0.09107963740825653
[20/24] Train loss=0.08095544576644897
Test set avg_accuracy=88.18% avg_sensitivity=68.38%, avg_specificity=96.03% avg_auc=93.66%
Fold[2] Epoch: 54 [54/100 (54%)] Train loss=0.110739 Test loss=0.641790 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.12431423366069794
[5/24] Train loss=0.09312064200639725
[10/24] Train loss=0.1102491095662117
[15/24] Train loss=0.08604611456394196
[20/24] Train loss=0.0996411070227623
Test set avg_accuracy=88.12% avg_sensitivity=70.16%, avg_specificity=95.25% avg_auc=93.79%
Fold[2] Epoch: 55 [55/100 (55%)] Train loss=0.101323 Test loss=0.588852 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.0742514431476593
[5/24] Train loss=0.07173887640237808
[10/24] Train loss=0.11128850281238556
[15/24] Train loss=0.07675836235284805
[20/24] Train loss=0.07715502381324768
Test set avg_accuracy=88.39% avg_sensitivity=71.45%, avg_specificity=95.11% avg_auc=93.53%
Fold[2] Epoch: 56 [56/100 (56%)] Train loss=0.087225 Test loss=0.625985 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.07479528337717056
[5/24] Train loss=0.0670805424451828
[10/24] Train loss=0.07851337641477585
[15/24] Train loss=0.06327774375677109
[20/24] Train loss=0.0622720867395401
Test set avg_accuracy=88.42% avg_sensitivity=71.86%, avg_specificity=95.00% avg_auc=93.60%
Fold[2] Epoch: 57 [57/100 (57%)] Train loss=0.072612 Test loss=0.647453 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.04955913871526718
[5/24] Train loss=0.06164504215121269
[10/24] Train loss=0.0707840844988823
[15/24] Train loss=0.05616839602589607
[20/24] Train loss=0.05354180559515953
Test set avg_accuracy=87.86% avg_sensitivity=71.04%, avg_specificity=94.54% avg_auc=93.66%
Fold[2] Epoch: 58 [58/100 (58%)] Train loss=0.065652 Test loss=0.629036 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.05836009234189987
[5/24] Train loss=0.052596986293792725
[10/24] Train loss=0.07536516338586807
[15/24] Train loss=0.054436471313238144
[20/24] Train loss=0.061383504420518875
Test set avg_accuracy=87.88% avg_sensitivity=71.86%, avg_specificity=94.23% avg_auc=93.30%
Fold[2] Epoch: 59 [59/100 (59%)] Train loss=0.058520 Test loss=0.613562 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.05649707466363907
[5/24] Train loss=0.043292172253131866
[10/24] Train loss=0.05031988024711609
[15/24] Train loss=0.04965246096253395
[20/24] Train loss=0.05136946216225624
Test set avg_accuracy=88.35% avg_sensitivity=70.76%, avg_specificity=95.33% avg_auc=93.09%
Fold[2] Epoch: 60 [60/100 (60%)] Train loss=0.051300 Test loss=0.672828 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.05591383948922157
[5/24] Train loss=0.04041944444179535
[10/24] Train loss=0.04517471790313721
[15/24] Train loss=0.054250482469797134
[20/24] Train loss=0.041474729776382446
Test set avg_accuracy=88.32% avg_sensitivity=71.49%, avg_specificity=95.00% avg_auc=93.33%
Fold[2] Epoch: 61 [61/100 (61%)] Train loss=0.049092 Test loss=0.699792 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.039000459015369415
[5/24] Train loss=0.04317953810095787
[10/24] Train loss=0.040210891515016556
[15/24] Train loss=0.03350510820746422
[20/24] Train loss=0.055436551570892334
Test set avg_accuracy=88.24% avg_sensitivity=72.73%, avg_specificity=94.40% avg_auc=93.60%
Fold[2] Epoch: 62 [62/100 (62%)] Train loss=0.045510 Test loss=0.663348 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.027588993310928345
[5/24] Train loss=0.04340934008359909
[10/24] Train loss=0.053611695766448975
[15/24] Train loss=0.030864227563142776
[20/24] Train loss=0.04303280636668205
Test set avg_accuracy=88.03% avg_sensitivity=74.29%, avg_specificity=93.49% avg_auc=93.72%
Fold[2] Epoch: 63 [63/100 (63%)] Train loss=0.045803 Test loss=0.723395 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.03911976143717766
[5/24] Train loss=0.026566699147224426
[10/24] Train loss=0.05342141538858414
[15/24] Train loss=0.03376207500696182
[20/24] Train loss=0.03252117708325386
Test set avg_accuracy=88.16% avg_sensitivity=73.56%, avg_specificity=93.96% avg_auc=93.52%
Fold[2] Epoch: 64 [64/100 (64%)] Train loss=0.040809 Test loss=0.778270 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.06117354705929756
[5/24] Train loss=0.029467234387993813
[10/24] Train loss=0.04520496353507042
[15/24] Train loss=0.032193005084991455
[20/24] Train loss=0.03242824599146843
Test set avg_accuracy=87.77% avg_sensitivity=76.99%, avg_specificity=92.05% avg_auc=93.73%
Fold[2] Epoch: 65 [65/100 (65%)] Train loss=0.040706 Test loss=0.735401 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.031121553853154182
[5/24] Train loss=0.031514618545770645
[10/24] Train loss=0.028334137052297592
[15/24] Train loss=0.039531391113996506
[20/24] Train loss=0.038939882069826126
Test set avg_accuracy=88.03% avg_sensitivity=74.79%, avg_specificity=93.29% avg_auc=93.66%
Fold[2] Epoch: 66 [66/100 (66%)] Train loss=0.036383 Test loss=0.750359 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.03310643136501312
[5/24] Train loss=0.029347185045480728
[10/24] Train loss=0.03772194683551788
[15/24] Train loss=0.028538811951875687
[20/24] Train loss=0.039001673460006714
Test set avg_accuracy=88.16% avg_sensitivity=73.05%, avg_specificity=94.16% avg_auc=93.82%
Fold[2] Epoch: 67 [67/100 (67%)] Train loss=0.033116 Test loss=0.728270 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.0234786719083786
[5/24] Train loss=0.029211625456809998
[10/24] Train loss=0.03487449511885643
[15/24] Train loss=0.026650935411453247
[20/24] Train loss=0.024167070165276527
Test set avg_accuracy=87.80% avg_sensitivity=70.62%, avg_specificity=94.62% avg_auc=93.59%
Fold[2] Epoch: 68 [68/100 (68%)] Train loss=0.028413 Test loss=0.771692 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.021949542686343193
[5/24] Train loss=0.03575711324810982
[10/24] Train loss=0.032959263771772385
[15/24] Train loss=0.019694354385137558
[20/24] Train loss=0.024553777649998665
Test set avg_accuracy=87.80% avg_sensitivity=67.64%, avg_specificity=95.80% avg_auc=93.56%
Fold[2] Epoch: 69 [69/100 (69%)] Train loss=0.028969 Test loss=0.820139 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.02200631983578205
[5/24] Train loss=0.021348344162106514
[10/24] Train loss=0.026103025302290916
[15/24] Train loss=0.023648442700505257
[20/24] Train loss=0.02216152474284172
Test set avg_accuracy=87.57% avg_sensitivity=68.74%, avg_specificity=95.03% avg_auc=93.61%
Fold[2] Epoch: 70 [70/100 (70%)] Train loss=0.025244 Test loss=0.835711 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.024561217054724693
[5/24] Train loss=0.02372589521110058
[10/24] Train loss=0.01811748370528221
[15/24] Train loss=0.02104400470852852
[20/24] Train loss=0.013215802609920502
Test set avg_accuracy=87.92% avg_sensitivity=69.75%, avg_specificity=95.13% avg_auc=93.66%
Fold[2] Epoch: 71 [71/100 (71%)] Train loss=0.024431 Test loss=0.804218 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.0253579244017601
[5/24] Train loss=0.014101527631282806
[10/24] Train loss=0.018985623493790627
[15/24] Train loss=0.023150766268372536
[20/24] Train loss=0.01761556975543499
Test set avg_accuracy=87.80% avg_sensitivity=71.13%, avg_specificity=94.42% avg_auc=93.77%
Fold[2] Epoch: 72 [72/100 (72%)] Train loss=0.020844 Test loss=0.839462 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.02189210057258606
[5/24] Train loss=0.015584219247102737
[10/24] Train loss=0.020344913005828857
[15/24] Train loss=0.017796700820326805
[20/24] Train loss=0.019114207476377487
Test set avg_accuracy=87.50% avg_sensitivity=69.20%, avg_specificity=94.76% avg_auc=93.61%
Fold[2] Epoch: 73 [73/100 (73%)] Train loss=0.021123 Test loss=0.830323 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.0168493390083313
[5/24] Train loss=0.01497876737266779
[10/24] Train loss=0.020504305139183998
[15/24] Train loss=0.017250951379537582
[20/24] Train loss=0.02587728761136532
Test set avg_accuracy=87.84% avg_sensitivity=71.04%, avg_specificity=94.51% avg_auc=93.77%
Fold[2] Epoch: 74 [74/100 (74%)] Train loss=0.019682 Test loss=0.823617 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.015312010422348976
[5/24] Train loss=0.013266736641526222
[10/24] Train loss=0.01777070201933384
[15/24] Train loss=0.012385101057589054
[20/24] Train loss=0.020852042362093925
Test set avg_accuracy=87.92% avg_sensitivity=71.17%, avg_specificity=94.56% avg_auc=93.71%
Fold[2] Epoch: 75 [75/100 (75%)] Train loss=0.017798 Test loss=0.835100 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.01563495397567749
[5/24] Train loss=0.017347289249300957
[10/24] Train loss=0.014245065860450268
[15/24] Train loss=0.022741883993148804
[20/24] Train loss=0.018462596461176872
Test set avg_accuracy=87.80% avg_sensitivity=70.90%, avg_specificity=94.51% avg_auc=93.68%
Fold[2] Epoch: 76 [76/100 (76%)] Train loss=0.018925 Test loss=0.832404 Current lr=[0.000262245679641298]

[0/24] Train loss=0.01726885512471199
[5/24] Train loss=0.011785359121859074
[10/24] Train loss=0.01491512730717659
[15/24] Train loss=0.01769937202334404
[20/24] Train loss=0.01102293748408556
Test set avg_accuracy=87.96% avg_sensitivity=70.07%, avg_specificity=95.05% avg_auc=93.62%
Fold[2] Epoch: 77 [77/100 (77%)] Train loss=0.016767 Test loss=0.869315 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.017813652753829956
[5/24] Train loss=0.01259527076035738
[10/24] Train loss=0.01748725213110447
[15/24] Train loss=0.01402233075350523
[20/24] Train loss=0.020025501027703285
Test set avg_accuracy=87.99% avg_sensitivity=70.35%, avg_specificity=95.00% avg_auc=93.67%
Fold[2] Epoch: 78 [78/100 (78%)] Train loss=0.017847 Test loss=0.854760 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.01342802494764328
[5/24] Train loss=0.01273905485868454
[10/24] Train loss=0.019610755145549774
[15/24] Train loss=0.010970656760036945
[20/24] Train loss=0.011777088977396488
Test set avg_accuracy=87.86% avg_sensitivity=70.39%, avg_specificity=94.80% avg_auc=93.71%
Fold[2] Epoch: 79 [79/100 (79%)] Train loss=0.017412 Test loss=0.862176 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.013431997038424015
[5/24] Train loss=0.013439350761473179
[10/24] Train loss=0.011624908074736595
[15/24] Train loss=0.011747376061975956
[20/24] Train loss=0.01086443942040205
Test set avg_accuracy=87.99% avg_sensitivity=71.45%, avg_specificity=94.56% avg_auc=93.76%
Fold[2] Epoch: 80 [80/100 (80%)] Train loss=0.016211 Test loss=0.851233 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.01731107383966446
[5/24] Train loss=0.011122642084956169
[10/24] Train loss=0.01269019115716219
[15/24] Train loss=0.013131215237081051
[20/24] Train loss=0.010867949575185776
Test set avg_accuracy=87.80% avg_sensitivity=70.58%, avg_specificity=94.63% avg_auc=93.72%
Fold[2] Epoch: 81 [81/100 (81%)] Train loss=0.015752 Test loss=0.862479 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.009860153310000896
[5/24] Train loss=0.011999061331152916
[10/24] Train loss=0.01570291817188263
[15/24] Train loss=0.012251261621713638
[20/24] Train loss=0.018061969429254532
Test set avg_accuracy=87.75% avg_sensitivity=71.04%, avg_specificity=94.38% avg_auc=93.80%
Fold[2] Epoch: 82 [82/100 (82%)] Train loss=0.015867 Test loss=0.841851 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.010674838908016682
[5/24] Train loss=0.013401336036622524
[10/24] Train loss=0.012241185642778873
[15/24] Train loss=0.0075890799053013325
[20/24] Train loss=0.013594450429081917
Test set avg_accuracy=87.97% avg_sensitivity=71.59%, avg_specificity=94.47% avg_auc=93.82%
Fold[2] Epoch: 83 [83/100 (83%)] Train loss=0.013965 Test loss=0.839088 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.014951375313103199
[5/24] Train loss=0.011524517089128494
[10/24] Train loss=0.011715236119925976
[15/24] Train loss=0.013026408851146698
[20/24] Train loss=0.016499899327754974
Test set avg_accuracy=88.15% avg_sensitivity=70.76%, avg_specificity=95.05% avg_auc=93.81%
Fold[2] Epoch: 84 [84/100 (84%)] Train loss=0.014535 Test loss=0.884862 Current lr=[0.000122853263038123]

[0/24] Train loss=0.008461873047053814
[5/24] Train loss=0.010850487276911736
[10/24] Train loss=0.016180768609046936
[15/24] Train loss=0.011576582677662373
[20/24] Train loss=0.01358755398541689
Test set avg_accuracy=87.88% avg_sensitivity=70.94%, avg_specificity=94.60% avg_auc=93.80%
Fold[2] Epoch: 85 [85/100 (85%)] Train loss=0.013884 Test loss=0.871796 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.012159961275756359
[5/24] Train loss=0.008111980743706226
[10/24] Train loss=0.015448614954948425
[15/24] Train loss=0.013718394562602043
[20/24] Train loss=0.011605191975831985
Test set avg_accuracy=87.98% avg_sensitivity=70.62%, avg_specificity=94.87% avg_auc=93.79%
Fold[2] Epoch: 86 [86/100 (86%)] Train loss=0.013656 Test loss=0.862873 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.01296820119023323
[5/24] Train loss=0.010248925536870956
[10/24] Train loss=0.01670808531343937
[15/24] Train loss=0.009588109329342842
[20/24] Train loss=0.012444647960364819
Test set avg_accuracy=87.81% avg_sensitivity=70.90%, avg_specificity=94.53% avg_auc=93.81%
Fold[2] Epoch: 87 [87/100 (87%)] Train loss=0.014997 Test loss=0.861521 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.010238222777843475
[5/24] Train loss=0.009057516232132912
[10/24] Train loss=0.012503479607403278
[15/24] Train loss=0.01295010931789875
[20/24] Train loss=0.012196650728583336
Test set avg_accuracy=87.93% avg_sensitivity=70.85%, avg_specificity=94.71% avg_auc=93.78%
Fold[2] Epoch: 88 [88/100 (88%)] Train loss=0.013399 Test loss=0.845543 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.012632166966795921
[5/24] Train loss=0.012410848401486874
[10/24] Train loss=0.013336987234652042
[15/24] Train loss=0.009672632440924644
[20/24] Train loss=0.011975684203207493
Test set avg_accuracy=87.97% avg_sensitivity=70.67%, avg_specificity=94.83% avg_auc=93.78%
Fold[2] Epoch: 89 [89/100 (89%)] Train loss=0.013841 Test loss=0.862569 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.0130289476364851
[5/24] Train loss=0.00724694412201643
[10/24] Train loss=0.01163049042224884
[15/24] Train loss=0.009048053994774818
[20/24] Train loss=0.013129700906574726
Test set avg_accuracy=87.83% avg_sensitivity=71.08%, avg_specificity=94.47% avg_auc=93.80%
Fold[2] Epoch: 90 [90/100 (90%)] Train loss=0.013108 Test loss=0.871521 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.011187581345438957
[5/24] Train loss=0.014295654371380806
[10/24] Train loss=0.01141656469553709
[15/24] Train loss=0.011234370060265064
[20/24] Train loss=0.012634098529815674
Test set avg_accuracy=87.97% avg_sensitivity=71.31%, avg_specificity=94.58% avg_auc=93.79%
Fold[2] Epoch: 91 [91/100 (91%)] Train loss=0.012702 Test loss=0.875052 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.009602127596735954
[5/24] Train loss=0.007016460411250591
[10/24] Train loss=0.012004702351987362
[15/24] Train loss=0.008488709107041359
[20/24] Train loss=0.009793317876756191
Test set avg_accuracy=87.93% avg_sensitivity=71.36%, avg_specificity=94.51% avg_auc=93.80%
Fold[2] Epoch: 92 [92/100 (92%)] Train loss=0.012922 Test loss=0.876723 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.01160047110170126
[5/24] Train loss=0.0076139746233820915
[10/24] Train loss=0.010695558972656727
[15/24] Train loss=0.010694571770727634
[20/24] Train loss=0.018396960571408272
Test set avg_accuracy=87.92% avg_sensitivity=71.08%, avg_specificity=94.60% avg_auc=93.81%
Fold[2] Epoch: 93 [93/100 (93%)] Train loss=0.013013 Test loss=0.879114 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.01158593874424696
[5/24] Train loss=0.008198641240596771
[10/24] Train loss=0.011234977282583714
[15/24] Train loss=0.007468129973858595
[20/24] Train loss=0.012587381526827812
Test set avg_accuracy=87.89% avg_sensitivity=70.85%, avg_specificity=94.65% avg_auc=93.81%
Fold[2] Epoch: 94 [94/100 (94%)] Train loss=0.011578 Test loss=0.880251 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.009974752552807331
[5/24] Train loss=0.008432363159954548
[10/24] Train loss=0.008159760385751724
[15/24] Train loss=0.013307281769812107
[20/24] Train loss=0.013204550370573997
Test set avg_accuracy=87.88% avg_sensitivity=70.81%, avg_specificity=94.65% avg_auc=93.80%
Fold[2] Epoch: 95 [95/100 (95%)] Train loss=0.012065 Test loss=0.882602 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.01036594808101654
[5/24] Train loss=0.010458243079483509
[10/24] Train loss=0.01418994925916195
[15/24] Train loss=0.00867749098688364
[20/24] Train loss=0.012138115242123604
Test set avg_accuracy=87.88% avg_sensitivity=70.81%, avg_specificity=94.65% avg_auc=93.81%
Fold[2] Epoch: 96 [96/100 (96%)] Train loss=0.012525 Test loss=0.883231 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.006336551159620285
[5/24] Train loss=0.011268923990428448
[10/24] Train loss=0.010931569151580334
[15/24] Train loss=0.012042849324643612
[20/24] Train loss=0.008307385258376598
Test set avg_accuracy=87.88% avg_sensitivity=70.81%, avg_specificity=94.65% avg_auc=93.80%
Fold[2] Epoch: 97 [97/100 (97%)] Train loss=0.011999 Test loss=0.883888 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.01179798785597086
[5/24] Train loss=0.010389899834990501
[10/24] Train loss=0.014214959926903248
[15/24] Train loss=0.008468611165881157
[20/24] Train loss=0.01107263844460249
Test set avg_accuracy=87.88% avg_sensitivity=70.81%, avg_specificity=94.65% avg_auc=93.81%
Fold[2] Epoch: 98 [98/100 (98%)] Train loss=0.012430 Test loss=0.882458 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.008798058144748211
[5/24] Train loss=0.009245200082659721
[10/24] Train loss=0.008580915629863739
[15/24] Train loss=0.011067640036344528
[20/24] Train loss=0.013848060742020607
Test set avg_accuracy=87.88% avg_sensitivity=70.81%, avg_specificity=94.65% avg_auc=93.81%
Fold[2] Epoch: 99 [99/100 (99%)] Train loss=0.011748 Test loss=0.882595 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.012289348058402538
[5/24] Train loss=0.008346496149897575
[10/24] Train loss=0.012221025303006172
[15/24] Train loss=0.00726328557357192
[20/24] Train loss=0.014913279563188553
Test set avg_accuracy=87.86% avg_sensitivity=70.81%, avg_specificity=94.63% avg_auc=93.81%
Fold[2] Epoch: 100 [100/100 (100%)] Train loss=0.012186 Test loss=0.882740 Current lr=[4.874217159761039e-09]

Fold[2] Result: acc=89.11% sen=77.86%, spe=93.58%, auc=94.39%!
Fold[2] Avg_overlap=0.71%(Â±0.2562297111393338)
[0/24] Train loss=1.4050443172454834
[5/24] Train loss=1.3606481552124023
[10/24] Train loss=1.2602852582931519
[15/24] Train loss=1.1021373271942139
[20/24] Train loss=1.0183027982711792
Test set avg_accuracy=76.98% avg_sensitivity=10.49%, avg_specificity=97.36% avg_auc=74.05%
Best model saved!! Metric=74.05217596870742!!
Fold[3] Epoch: 1 [1/100 (1%)] Train loss=1.231118 Test loss=0.603682 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=0.9754858016967773
[5/24] Train loss=1.0037579536437988
[10/24] Train loss=0.959433913230896
[15/24] Train loss=0.81430983543396
[20/24] Train loss=0.8275203108787537
Test set avg_accuracy=80.66% avg_sensitivity=50.22%, avg_specificity=90.00% avg_auc=85.02%
Best model saved!! Metric=85.01829561422622!!
Fold[3] Epoch: 2 [2/100 (2%)] Train loss=0.963405 Test loss=0.485103 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8647490739822388
[5/24] Train loss=0.9116002917289734
[10/24] Train loss=0.8653527498245239
[15/24] Train loss=0.7863818407058716
[20/24] Train loss=0.7733378410339355
Test set avg_accuracy=84.44% avg_sensitivity=69.53%, avg_specificity=89.01% avg_auc=89.54%
Best model saved!! Metric=89.54182698970823!!
Fold[3] Epoch: 3 [3/100 (3%)] Train loss=0.884834 Test loss=0.366035 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.789976179599762
[5/24] Train loss=0.8846839666366577
[10/24] Train loss=0.8225451707839966
[15/24] Train loss=0.7451027035713196
[20/24] Train loss=0.7249191403388977
Test set avg_accuracy=85.56% avg_sensitivity=82.41%, avg_specificity=86.53% avg_auc=91.82%
Best model saved!! Metric=91.81611373548502!!
Fold[3] Epoch: 4 [4/100 (4%)] Train loss=0.824482 Test loss=0.370422 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.767365038394928
[5/24] Train loss=0.8252866268157959
[10/24] Train loss=0.7774898409843445
[15/24] Train loss=0.681838870048523
[20/24] Train loss=0.697455883026123
Test set avg_accuracy=86.04% avg_sensitivity=87.40%, avg_specificity=85.62% avg_auc=92.80%
Best model saved!! Metric=92.80008715883716!!
Fold[3] Epoch: 5 [5/100 (5%)] Train loss=0.776999 Test loss=0.366440 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.7273545861244202
[5/24] Train loss=0.7539998888969421
[10/24] Train loss=0.7360708117485046
[15/24] Train loss=0.6249961256980896
[20/24] Train loss=0.6423589587211609
Test set avg_accuracy=85.07% avg_sensitivity=90.90%, avg_specificity=83.28% avg_auc=93.11%
Best model saved!! Metric=93.11351721028278!!
Fold[3] Epoch: 6 [6/100 (6%)] Train loss=0.738980 Test loss=0.409506 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.7066255211830139
[5/24] Train loss=0.7568950057029724
[10/24] Train loss=0.7483527064323425
[15/24] Train loss=0.6105330586433411
[20/24] Train loss=0.6336705088615417
Test set avg_accuracy=85.79% avg_sensitivity=91.56%, avg_specificity=84.03% avg_auc=93.67%
Best model saved!! Metric=93.66818237948914!!
Fold[3] Epoch: 7 [7/100 (7%)] Train loss=0.724494 Test loss=0.400269 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.7064098715782166
[5/24] Train loss=0.7190502285957336
[10/24] Train loss=0.7506020069122314
[15/24] Train loss=0.6007081866264343
[20/24] Train loss=0.6027644276618958
Test set avg_accuracy=86.45% avg_sensitivity=90.40%, avg_specificity=85.23% avg_auc=93.85%
Best model saved!! Metric=93.84807021346741!!
Fold[3] Epoch: 8 [8/100 (8%)] Train loss=0.702989 Test loss=0.355548 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.671985387802124
[5/24] Train loss=0.7338258624076843
[10/24] Train loss=0.7304709553718567
[15/24] Train loss=0.6105368733406067
[20/24] Train loss=0.5690456032752991
Test set avg_accuracy=86.60% avg_sensitivity=90.12%, avg_specificity=85.52% avg_auc=94.04%
Best model saved!! Metric=94.03825812233127!!
Fold[3] Epoch: 9 [9/100 (9%)] Train loss=0.692599 Test loss=0.362386 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6588491201400757
[5/24] Train loss=0.6954454183578491
[10/24] Train loss=0.7228681445121765
[15/24] Train loss=0.5931352972984314
[20/24] Train loss=0.5680474042892456
Test set avg_accuracy=88.37% avg_sensitivity=87.18%, avg_specificity=88.74% avg_auc=94.47%
Best model saved!! Metric=94.4734622488566!!
Fold[3] Epoch: 10 [10/100 (10%)] Train loss=0.671892 Test loss=0.324046 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.6341243982315063
[5/24] Train loss=0.6566796898841858
[10/24] Train loss=0.7244393229484558
[15/24] Train loss=0.5697836875915527
[20/24] Train loss=0.5466495752334595
Test set avg_accuracy=86.90% avg_sensitivity=90.40%, avg_specificity=85.83% avg_auc=94.60%
Best model saved!! Metric=94.59664774574694!!
Fold[3] Epoch: 11 [11/100 (11%)] Train loss=0.660618 Test loss=0.355151 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.6232807040214539
[5/24] Train loss=0.6571551561355591
[10/24] Train loss=0.7165914177894592
[15/24] Train loss=0.5340702533721924
[20/24] Train loss=0.5318247675895691
Test set avg_accuracy=88.07% avg_sensitivity=86.40%, avg_specificity=88.58% avg_auc=94.53%
Fold[3] Epoch: 12 [12/100 (12%)] Train loss=0.650464 Test loss=0.320742 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.6313820481300354
[5/24] Train loss=0.634658694267273
[10/24] Train loss=0.6770275831222534
[15/24] Train loss=0.5811643004417419
[20/24] Train loss=0.5235652923583984
Test set avg_accuracy=88.71% avg_sensitivity=85.35%, avg_specificity=89.74% avg_auc=94.56%
Fold[3] Epoch: 13 [13/100 (13%)] Train loss=0.635410 Test loss=0.290043 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.593694806098938
[5/24] Train loss=0.6273372769355774
[10/24] Train loss=0.6482226848602295
[15/24] Train loss=0.5384905934333801
[20/24] Train loss=0.5115405321121216
Test set avg_accuracy=89.40% avg_sensitivity=83.30%, avg_specificity=91.27% avg_auc=94.49%
Fold[3] Epoch: 14 [14/100 (14%)] Train loss=0.618906 Test loss=0.272560 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.6140778064727783
[5/24] Train loss=0.6265348196029663
[10/24] Train loss=0.6277619004249573
[15/24] Train loss=0.5145750641822815
[20/24] Train loss=0.4938927888870239
Test set avg_accuracy=90.23% avg_sensitivity=76.36%, avg_specificity=94.49% avg_auc=94.90%
Best model saved!! Metric=94.90209547517993!!
Fold[3] Epoch: 15 [15/100 (15%)] Train loss=0.612992 Test loss=0.254104 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.5801320672035217
[5/24] Train loss=0.6001511216163635
[10/24] Train loss=0.6221859455108643
[15/24] Train loss=0.5084602236747742
[20/24] Train loss=0.5290959477424622
Test set avg_accuracy=90.17% avg_sensitivity=74.58%, avg_specificity=94.95% avg_auc=94.93%
Best model saved!! Metric=94.92819969796517!!
Fold[3] Epoch: 16 [16/100 (16%)] Train loss=0.595920 Test loss=0.247791 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5791094303131104
[5/24] Train loss=0.5812111496925354
[10/24] Train loss=0.6676602959632874
[15/24] Train loss=0.5004839897155762
[20/24] Train loss=0.5615096688270569
Test set avg_accuracy=90.51% avg_sensitivity=79.30%, avg_specificity=93.94% avg_auc=95.04%
Best model saved!! Metric=95.04463491663076!!
Fold[3] Epoch: 17 [17/100 (17%)] Train loss=0.598615 Test loss=0.245549 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5678679347038269
[5/24] Train loss=0.599378228187561
[10/24] Train loss=0.6559194326400757
[15/24] Train loss=0.5067256689071655
[20/24] Train loss=0.5414398312568665
Test set avg_accuracy=90.22% avg_sensitivity=82.46%, avg_specificity=92.60% avg_auc=95.28%
Best model saved!! Metric=95.27797740139022!!
Fold[3] Epoch: 18 [18/100 (18%)] Train loss=0.594334 Test loss=0.245893 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.558756947517395
[5/24] Train loss=0.5815247297286987
[10/24] Train loss=0.6018741726875305
[15/24] Train loss=0.5093821883201599
[20/24] Train loss=0.4890735149383545
Test set avg_accuracy=89.92% avg_sensitivity=76.30%, avg_specificity=94.10% avg_auc=94.94%
Fold[3] Epoch: 19 [19/100 (19%)] Train loss=0.570591 Test loss=0.252369 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5818458795547485
[5/24] Train loss=0.5563173294067383
[10/24] Train loss=0.6271440982818604
[15/24] Train loss=0.4908258616924286
[20/24] Train loss=0.4582466185092926
Test set avg_accuracy=89.82% avg_sensitivity=82.08%, avg_specificity=92.19% avg_auc=95.16%
Fold[3] Epoch: 20 [20/100 (20%)] Train loss=0.572410 Test loss=0.249640 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5510708093643188
[5/24] Train loss=0.5581454634666443
[10/24] Train loss=0.590327799320221
[15/24] Train loss=0.4823415279388428
[20/24] Train loss=0.48055535554885864
Test set avg_accuracy=89.92% avg_sensitivity=71.53%, avg_specificity=95.56% avg_auc=94.93%
Fold[3] Epoch: 21 [21/100 (21%)] Train loss=0.557973 Test loss=0.251265 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.52332603931427
[5/24] Train loss=0.5589907765388489
[10/24] Train loss=0.6190354824066162
[15/24] Train loss=0.47572416067123413
[20/24] Train loss=0.4708074927330017
Test set avg_accuracy=90.38% avg_sensitivity=75.42%, avg_specificity=94.96% avg_auc=95.09%
Fold[3] Epoch: 22 [22/100 (22%)] Train loss=0.555918 Test loss=0.244088 Current lr=[0.000842324016282456]

[0/24] Train loss=0.5541386008262634
[5/24] Train loss=0.5579230189323425
[10/24] Train loss=0.572800874710083
[15/24] Train loss=0.45206016302108765
[20/24] Train loss=0.4494512677192688
Test set avg_accuracy=90.10% avg_sensitivity=69.70%, avg_specificity=96.36% avg_auc=95.21%
Fold[3] Epoch: 23 [23/100 (23%)] Train loss=0.534654 Test loss=0.253395 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5078403949737549
[5/24] Train loss=0.4920424520969391
[10/24] Train loss=0.5544579029083252
[15/24] Train loss=0.46085241436958313
[20/24] Train loss=0.4328519403934479
Test set avg_accuracy=90.44% avg_sensitivity=77.52%, avg_specificity=94.40% avg_auc=95.25%
Fold[3] Epoch: 24 [24/100 (24%)] Train loss=0.521658 Test loss=0.246214 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.5219722390174866
[5/24] Train loss=0.49205413460731506
[10/24] Train loss=0.5853110551834106
[15/24] Train loss=0.44525599479675293
[20/24] Train loss=0.4478803873062134
Test set avg_accuracy=90.16% avg_sensitivity=78.58%, avg_specificity=93.71% avg_auc=94.77%
Fold[3] Epoch: 25 [25/100 (25%)] Train loss=0.520530 Test loss=0.252761 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.5038972496986389
[5/24] Train loss=0.4829349219799042
[10/24] Train loss=0.5564484000205994
[15/24] Train loss=0.44033339619636536
[20/24] Train loss=0.42215317487716675
Test set avg_accuracy=89.80% avg_sensitivity=77.19%, avg_specificity=93.67% avg_auc=95.15%
Fold[3] Epoch: 26 [26/100 (26%)] Train loss=0.505645 Test loss=0.250508 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.5084855556488037
[5/24] Train loss=0.4773326516151428
[10/24] Train loss=0.5191525816917419
[15/24] Train loss=0.40631112456321716
[20/24] Train loss=0.4281488358974457
Test set avg_accuracy=90.36% avg_sensitivity=77.80%, avg_specificity=94.22% avg_auc=95.11%
Fold[3] Epoch: 27 [27/100 (27%)] Train loss=0.487209 Test loss=0.252094 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.4516927897930145
[5/24] Train loss=0.4541029632091522
[10/24] Train loss=0.4784758388996124
[15/24] Train loss=0.4264032542705536
[20/24] Train loss=0.4260866343975067
Test set avg_accuracy=90.22% avg_sensitivity=80.63%, avg_specificity=93.16% avg_auc=94.52%
Fold[3] Epoch: 28 [28/100 (28%)] Train loss=0.476970 Test loss=0.267871 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.49127137660980225
[5/24] Train loss=0.435205340385437
[10/24] Train loss=0.4499827027320862
[15/24] Train loss=0.3971460461616516
[20/24] Train loss=0.4176774024963379
Test set avg_accuracy=89.73% avg_sensitivity=82.13%, avg_specificity=92.06% avg_auc=94.86%
Fold[3] Epoch: 29 [29/100 (29%)] Train loss=0.462192 Test loss=0.282418 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.44942060112953186
[5/24] Train loss=0.4172374904155731
[10/24] Train loss=0.464821457862854
[15/24] Train loss=0.3978818953037262
[20/24] Train loss=0.3927943706512451
Test set avg_accuracy=89.92% avg_sensitivity=76.25%, avg_specificity=94.11% avg_auc=94.67%
Fold[3] Epoch: 30 [30/100 (30%)] Train loss=0.432407 Test loss=0.284296 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.453510046005249
[5/24] Train loss=0.40953463315963745
[10/24] Train loss=0.3943256437778473
[15/24] Train loss=0.36175575852394104
[20/24] Train loss=0.35155075788497925
Test set avg_accuracy=89.24% avg_sensitivity=79.80%, avg_specificity=92.14% avg_auc=94.67%
Fold[3] Epoch: 31 [31/100 (31%)] Train loss=0.422377 Test loss=0.279568 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.4285200834274292
[5/24] Train loss=0.38522306084632874
[10/24] Train loss=0.41012415289878845
[15/24] Train loss=0.3675270974636078
[20/24] Train loss=0.35280323028564453
Test set avg_accuracy=89.70% avg_sensitivity=77.36%, avg_specificity=93.48% avg_auc=94.78%
Fold[3] Epoch: 32 [32/100 (32%)] Train loss=0.414255 Test loss=0.276451 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.4429174065589905
[5/24] Train loss=0.3706577718257904
[10/24] Train loss=0.3997707962989807
[15/24] Train loss=0.309296190738678
[20/24] Train loss=0.3550790846347809
Test set avg_accuracy=89.95% avg_sensitivity=71.42%, avg_specificity=95.63% avg_auc=94.35%
Fold[3] Epoch: 33 [33/100 (33%)] Train loss=0.388558 Test loss=0.304321 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.41813191771507263
[5/24] Train loss=0.33119693398475647
[10/24] Train loss=0.38191041350364685
[15/24] Train loss=0.3156742751598358
[20/24] Train loss=0.2934750020503998
Test set avg_accuracy=88.72% avg_sensitivity=68.98%, avg_specificity=94.78% avg_auc=93.70%
Fold[3] Epoch: 34 [34/100 (34%)] Train loss=0.368717 Test loss=0.322990 Current lr=[0.000991797016730875]

[0/24] Train loss=0.36225488781929016
[5/24] Train loss=0.34734904766082764
[10/24] Train loss=0.36071354150772095
[15/24] Train loss=0.29290732741355896
[20/24] Train loss=0.3012637197971344
Test set avg_accuracy=89.77% avg_sensitivity=72.70%, avg_specificity=95.00% avg_auc=93.93%
Fold[3] Epoch: 35 [35/100 (35%)] Train loss=0.346778 Test loss=0.311698 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.3541422188282013
[5/24] Train loss=0.29585739970207214
[10/24] Train loss=0.28744909167289734
[15/24] Train loss=0.2644602656364441
[20/24] Train loss=0.2779967784881592
Test set avg_accuracy=89.36% avg_sensitivity=72.97%, avg_specificity=94.39% avg_auc=93.72%
Fold[3] Epoch: 36 [36/100 (36%)] Train loss=0.324503 Test loss=0.342878 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.31918445229530334
[5/24] Train loss=0.33007535338401794
[10/24] Train loss=0.3094022870063782
[15/24] Train loss=0.265165776014328
[20/24] Train loss=0.28044745326042175
Test set avg_accuracy=90.27% avg_sensitivity=72.09%, avg_specificity=95.85% avg_auc=93.81%
Fold[3] Epoch: 37 [37/100 (37%)] Train loss=0.316807 Test loss=0.357450 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.32955917716026306
[5/24] Train loss=0.3004346489906311
[10/24] Train loss=0.3080662488937378
[15/24] Train loss=0.2828562557697296
[20/24] Train loss=0.24487844109535217
Test set avg_accuracy=89.69% avg_sensitivity=76.08%, avg_specificity=93.86% avg_auc=94.18%
Fold[3] Epoch: 38 [38/100 (38%)] Train loss=0.302032 Test loss=0.337651 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.2908702492713928
[5/24] Train loss=0.2811933159828186
[10/24] Train loss=0.26643913984298706
[15/24] Train loss=0.3432392179965973
[20/24] Train loss=0.25224459171295166
Test set avg_accuracy=90.10% avg_sensitivity=77.41%, avg_specificity=93.99% avg_auc=93.73%
Fold[3] Epoch: 39 [39/100 (39%)] Train loss=0.291099 Test loss=0.355562 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.2570725679397583
[5/24] Train loss=0.2533419728279114
[10/24] Train loss=0.256613552570343
[15/24] Train loss=0.21344858407974243
[20/24] Train loss=0.2700170874595642
Test set avg_accuracy=89.90% avg_sensitivity=75.25%, avg_specificity=94.39% avg_auc=94.07%
Fold[3] Epoch: 40 [40/100 (40%)] Train loss=0.265668 Test loss=0.364276 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.2520812451839447
[5/24] Train loss=0.26404181122779846
[10/24] Train loss=0.23295772075653076
[15/24] Train loss=0.2093137502670288
[20/24] Train loss=0.3091920018196106
Test set avg_accuracy=89.36% avg_sensitivity=69.87%, avg_specificity=95.34% avg_auc=93.79%
Fold[3] Epoch: 41 [41/100 (41%)] Train loss=0.257784 Test loss=0.398663 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.27700483798980713
[5/24] Train loss=0.2288064807653427
[10/24] Train loss=0.2318173199892044
[15/24] Train loss=0.22940345108509064
[20/24] Train loss=0.21856006979942322
Test set avg_accuracy=89.82% avg_sensitivity=70.64%, avg_specificity=95.70% avg_auc=94.16%
Fold[3] Epoch: 42 [42/100 (42%)] Train loss=0.245561 Test loss=0.381050 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.25938844680786133
[5/24] Train loss=0.21806073188781738
[10/24] Train loss=0.21381688117980957
[15/24] Train loss=0.15631523728370667
[20/24] Train loss=0.23152409493923187
Test set avg_accuracy=88.84% avg_sensitivity=76.69%, avg_specificity=92.57% avg_auc=93.25%
Fold[3] Epoch: 43 [43/100 (43%)] Train loss=0.228080 Test loss=0.378370 Current lr=[0.000916771143003274]

[0/24] Train loss=0.2498985081911087
[5/24] Train loss=0.20498692989349365
[10/24] Train loss=0.22062617540359497
[15/24] Train loss=0.18915359675884247
[20/24] Train loss=0.1773727983236313
Test set avg_accuracy=87.63% avg_sensitivity=83.57%, avg_specificity=88.87% avg_auc=93.34%
Fold[3] Epoch: 44 [44/100 (44%)] Train loss=0.225401 Test loss=0.427931 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.2457321584224701
[5/24] Train loss=0.19141842424869537
[10/24] Train loss=0.2051803320646286
[15/24] Train loss=0.18731828033924103
[20/24] Train loss=0.21397635340690613
Test set avg_accuracy=87.27% avg_sensitivity=82.85%, avg_specificity=88.62% avg_auc=93.04%
Fold[3] Epoch: 45 [45/100 (45%)] Train loss=0.219188 Test loss=0.458493 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.2544110417366028
[5/24] Train loss=0.21688416600227356
[10/24] Train loss=0.23218874633312225
[15/24] Train loss=0.1615222990512848
[20/24] Train loss=0.18717113137245178
Test set avg_accuracy=88.98% avg_sensitivity=81.08%, avg_specificity=91.41% avg_auc=93.59%
Fold[3] Epoch: 46 [46/100 (46%)] Train loss=0.217116 Test loss=0.397814 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.22058451175689697
[5/24] Train loss=0.22095820307731628
[10/24] Train loss=0.1875758320093155
[15/24] Train loss=0.13869445025920868
[20/24] Train loss=0.16112199425697327
Test set avg_accuracy=89.51% avg_sensitivity=78.58%, avg_specificity=92.85% avg_auc=93.59%
Fold[3] Epoch: 47 [47/100 (47%)] Train loss=0.190193 Test loss=0.398908 Current lr=[0.000860751215339601]

[0/24] Train loss=0.17559576034545898
[5/24] Train loss=0.1695021092891693
[10/24] Train loss=0.18862107396125793
[15/24] Train loss=0.17269307374954224
[20/24] Train loss=0.13273048400878906
Test set avg_accuracy=89.67% avg_sensitivity=73.86%, avg_specificity=94.52% avg_auc=93.57%
Fold[3] Epoch: 48 [48/100 (48%)] Train loss=0.190261 Test loss=0.425407 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.18499058485031128
[5/24] Train loss=0.1951105147600174
[10/24] Train loss=0.14285998046398163
[15/24] Train loss=0.16520395874977112
[20/24] Train loss=0.13167712092399597
Test set avg_accuracy=90.00% avg_sensitivity=76.75%, avg_specificity=94.06% avg_auc=93.89%
Fold[3] Epoch: 49 [49/100 (49%)] Train loss=0.171736 Test loss=0.437493 Current lr=[0.000828265354963756]

[0/24] Train loss=0.19891996681690216
[5/24] Train loss=0.1628008335828781
[10/24] Train loss=0.1381184309720993
[15/24] Train loss=0.13621138036251068
[20/24] Train loss=0.13655813038349152
Test set avg_accuracy=89.73% avg_sensitivity=79.19%, avg_specificity=92.96% avg_auc=94.28%
Fold[3] Epoch: 50 [50/100 (50%)] Train loss=0.151799 Test loss=0.452631 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.15841564536094666
[5/24] Train loss=0.12169995903968811
[10/24] Train loss=0.1251971423625946
[15/24] Train loss=0.11780789494514465
[20/24] Train loss=0.10586314648389816
Test set avg_accuracy=89.64% avg_sensitivity=74.47%, avg_specificity=94.28% avg_auc=94.46%
Fold[3] Epoch: 51 [51/100 (51%)] Train loss=0.135402 Test loss=0.476716 Current lr=[0.00079313651106947]

[0/24] Train loss=0.1564938873052597
[5/24] Train loss=0.12264671176671982
[10/24] Train loss=0.11073370277881622
[15/24] Train loss=0.1480879932641983
[20/24] Train loss=0.11705224215984344
Test set avg_accuracy=89.70% avg_sensitivity=76.47%, avg_specificity=93.76% avg_auc=94.35%
Fold[3] Epoch: 52 [52/100 (52%)] Train loss=0.130824 Test loss=0.450930 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.10187926888465881
[5/24] Train loss=0.13549940288066864
[10/24] Train loss=0.13719654083251953
[15/24] Train loss=0.10590625554323196
[20/24] Train loss=0.10266663879156113
Test set avg_accuracy=89.40% avg_sensitivity=71.31%, avg_specificity=94.95% avg_auc=94.11%
Fold[3] Epoch: 53 [53/100 (53%)] Train loss=0.120783 Test loss=0.456693 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.0890892744064331
[5/24] Train loss=0.128679096698761
[10/24] Train loss=0.07733354717493057
[15/24] Train loss=0.09327712655067444
[20/24] Train loss=0.08789888024330139
Test set avg_accuracy=89.60% avg_sensitivity=70.87%, avg_specificity=95.34% avg_auc=94.52%
Fold[3] Epoch: 54 [54/100 (54%)] Train loss=0.102768 Test loss=0.511932 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.08839496225118637
[5/24] Train loss=0.09700193256139755
[10/24] Train loss=0.08992228657007217
[15/24] Train loss=0.07828110456466675
[20/24] Train loss=0.06326562166213989
Test set avg_accuracy=89.91% avg_sensitivity=74.75%, avg_specificity=94.56% avg_auc=94.45%
Fold[3] Epoch: 55 [55/100 (55%)] Train loss=0.088002 Test loss=0.507712 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.09657779335975647
[5/24] Train loss=0.09651977568864822
[10/24] Train loss=0.0640205666422844
[15/24] Train loss=0.06615762412548065
[20/24] Train loss=0.05414314568042755
Test set avg_accuracy=89.35% avg_sensitivity=71.59%, avg_specificity=94.79% avg_auc=93.90%
Fold[3] Epoch: 56 [56/100 (56%)] Train loss=0.075194 Test loss=0.540916 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.09396012872457504
[5/24] Train loss=0.05917501077055931
[10/24] Train loss=0.06737212091684341
[15/24] Train loss=0.06635420769453049
[20/24] Train loss=0.047839730978012085
Test set avg_accuracy=89.93% avg_sensitivity=73.86%, avg_specificity=94.86% avg_auc=94.35%
Fold[3] Epoch: 57 [57/100 (57%)] Train loss=0.066155 Test loss=0.536277 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.057583216577768326
[5/24] Train loss=0.05651143938302994
[10/24] Train loss=0.04812595248222351
[15/24] Train loss=0.05987333133816719
[20/24] Train loss=0.049211449921131134
Test set avg_accuracy=89.61% avg_sensitivity=73.70%, avg_specificity=94.49% avg_auc=94.33%
Fold[3] Epoch: 58 [58/100 (58%)] Train loss=0.061275 Test loss=0.537200 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.04521369934082031
[5/24] Train loss=0.04509923234581947
[10/24] Train loss=0.045557111501693726
[15/24] Train loss=0.044762399047613144
[20/24] Train loss=0.061750661581754684
Test set avg_accuracy=90.05% avg_sensitivity=76.86%, avg_specificity=94.10% avg_auc=94.31%
Fold[3] Epoch: 59 [59/100 (59%)] Train loss=0.053933 Test loss=0.511409 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.04565351828932762
[5/24] Train loss=0.055880721658468246
[10/24] Train loss=0.051247671246528625
[15/24] Train loss=0.04729185253381729
[20/24] Train loss=0.042965084314346313
Test set avg_accuracy=89.93% avg_sensitivity=76.69%, avg_specificity=93.99% avg_auc=94.34%
Fold[3] Epoch: 60 [60/100 (60%)] Train loss=0.051570 Test loss=0.547365 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.04871141538023949
[5/24] Train loss=0.035218317061662674
[10/24] Train loss=0.04023125395178795
[15/24] Train loss=0.03295827656984329
[20/24] Train loss=0.04720107093453407
Test set avg_accuracy=89.93% avg_sensitivity=77.80%, avg_specificity=93.65% avg_auc=94.42%
Fold[3] Epoch: 61 [61/100 (61%)] Train loss=0.044809 Test loss=0.593460 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.05731187015771866
[5/24] Train loss=0.03578491881489754
[10/24] Train loss=0.04104749858379364
[15/24] Train loss=0.033206671476364136
[20/24] Train loss=0.032376278191804886
Test set avg_accuracy=90.04% avg_sensitivity=80.02%, avg_specificity=93.11% avg_auc=94.40%
Fold[3] Epoch: 62 [62/100 (62%)] Train loss=0.041411 Test loss=0.628007 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.041923437267541885
[5/24] Train loss=0.037427037954330444
[10/24] Train loss=0.037221577018499374
[15/24] Train loss=0.02842825837433338
[20/24] Train loss=0.03578987717628479
Test set avg_accuracy=89.95% avg_sensitivity=79.80%, avg_specificity=93.06% avg_auc=94.07%
Fold[3] Epoch: 63 [63/100 (63%)] Train loss=0.037326 Test loss=0.715580 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.03328283131122589
[5/24] Train loss=0.04241446033120155
[10/24] Train loss=0.02668856829404831
[15/24] Train loss=0.030177181586623192
[20/24] Train loss=0.032284170389175415
Test set avg_accuracy=90.17% avg_sensitivity=76.30%, avg_specificity=94.42% avg_auc=94.58%
Fold[3] Epoch: 64 [64/100 (64%)] Train loss=0.036655 Test loss=0.576152 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.03221844881772995
[5/24] Train loss=0.054340165108442307
[10/24] Train loss=0.023499496281147003
[15/24] Train loss=0.02935349941253662
[20/24] Train loss=0.030293410643935204
Test set avg_accuracy=89.71% avg_sensitivity=75.69%, avg_specificity=94.01% avg_auc=94.39%
Fold[3] Epoch: 65 [65/100 (65%)] Train loss=0.034071 Test loss=0.609013 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.033683788031339645
[5/24] Train loss=0.030013788491487503
[10/24] Train loss=0.03307066112756729
[15/24] Train loss=0.02526199445128441
[20/24] Train loss=0.027689706534147263
Test set avg_accuracy=90.10% avg_sensitivity=72.75%, avg_specificity=95.42% avg_auc=94.43%
Fold[3] Epoch: 66 [66/100 (66%)] Train loss=0.032180 Test loss=0.628307 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.031222600489854813
[5/24] Train loss=0.037022341042757034
[10/24] Train loss=0.025143593549728394
[15/24] Train loss=0.02294115722179413
[20/24] Train loss=0.017799410969018936
Test set avg_accuracy=90.05% avg_sensitivity=72.20%, avg_specificity=95.53% avg_auc=94.52%
Fold[3] Epoch: 67 [67/100 (67%)] Train loss=0.026725 Test loss=0.650277 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.028125744313001633
[5/24] Train loss=0.0278155580163002
[10/24] Train loss=0.019863232970237732
[15/24] Train loss=0.029354315251111984
[20/24] Train loss=0.016601305454969406
Test set avg_accuracy=90.05% avg_sensitivity=73.42%, avg_specificity=95.15% avg_auc=94.50%
Fold[3] Epoch: 68 [68/100 (68%)] Train loss=0.025397 Test loss=0.640343 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.024561628699302673
[5/24] Train loss=0.01979793980717659
[10/24] Train loss=0.015041324310004711
[15/24] Train loss=0.024598730728030205
[20/24] Train loss=0.022249551489949226
Test set avg_accuracy=90.07% avg_sensitivity=74.92%, avg_specificity=94.71% avg_auc=94.61%
Fold[3] Epoch: 69 [69/100 (69%)] Train loss=0.021663 Test loss=0.645167 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.02438206411898136
[5/24] Train loss=0.02676263451576233
[10/24] Train loss=0.015002124942839146
[15/24] Train loss=0.017861519008874893
[20/24] Train loss=0.020773494616150856
Test set avg_accuracy=89.99% avg_sensitivity=74.14%, avg_specificity=94.85% avg_auc=94.66%
Fold[3] Epoch: 70 [70/100 (70%)] Train loss=0.019959 Test loss=0.650249 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.022874226793646812
[5/24] Train loss=0.026723921298980713
[10/24] Train loss=0.014721761457622051
[15/24] Train loss=0.011419444344937801
[20/24] Train loss=0.015137986280024052
Test set avg_accuracy=90.00% avg_sensitivity=73.42%, avg_specificity=95.08% avg_auc=94.49%
Fold[3] Epoch: 71 [71/100 (71%)] Train loss=0.019107 Test loss=0.655829 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.016553713008761406
[5/24] Train loss=0.01945771835744381
[10/24] Train loss=0.017287516966462135
[15/24] Train loss=0.016496630385518074
[20/24] Train loss=0.01637805439531803
Test set avg_accuracy=89.83% avg_sensitivity=74.36%, avg_specificity=94.57% avg_auc=94.61%
Fold[3] Epoch: 72 [72/100 (72%)] Train loss=0.017655 Test loss=0.676592 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.013886521570384502
[5/24] Train loss=0.020863518118858337
[10/24] Train loss=0.014820710755884647
[15/24] Train loss=0.010710806585848331
[20/24] Train loss=0.016439149156212807
Test set avg_accuracy=89.92% avg_sensitivity=75.03%, avg_specificity=94.49% avg_auc=94.56%
Fold[3] Epoch: 73 [73/100 (73%)] Train loss=0.017153 Test loss=0.700878 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.02772841602563858
[5/24] Train loss=0.012919120490550995
[10/24] Train loss=0.019085552543401718
[15/24] Train loss=0.013499383814632893
[20/24] Train loss=0.01515035331249237
Test set avg_accuracy=90.05% avg_sensitivity=74.69%, avg_specificity=94.76% avg_auc=94.66%
Fold[3] Epoch: 74 [74/100 (74%)] Train loss=0.016339 Test loss=0.687485 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.023723192512989044
[5/24] Train loss=0.015666015446186066
[10/24] Train loss=0.01564732939004898
[15/24] Train loss=0.01497021783143282
[20/24] Train loss=0.016560642048716545
Test set avg_accuracy=89.86% avg_sensitivity=73.42%, avg_specificity=94.90% avg_auc=94.65%
Fold[3] Epoch: 75 [75/100 (75%)] Train loss=0.017223 Test loss=0.685266 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.01370058860629797
[5/24] Train loss=0.014665771275758743
[10/24] Train loss=0.014706519432365894
[15/24] Train loss=0.009559187106788158
[20/24] Train loss=0.011156016029417515
Test set avg_accuracy=90.03% avg_sensitivity=74.69%, avg_specificity=94.73% avg_auc=94.65%
Fold[3] Epoch: 76 [76/100 (76%)] Train loss=0.015826 Test loss=0.679270 Current lr=[0.000262245679641298]

[0/24] Train loss=0.01492871344089508
[5/24] Train loss=0.014180931262671947
[10/24] Train loss=0.012174772098660469
[15/24] Train loss=0.01223037764430046
[20/24] Train loss=0.013303509913384914
Test set avg_accuracy=89.90% avg_sensitivity=73.97%, avg_specificity=94.78% avg_auc=94.61%
Fold[3] Epoch: 77 [77/100 (77%)] Train loss=0.015089 Test loss=0.702633 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.015092430636286736
[5/24] Train loss=0.015017358586192131
[10/24] Train loss=0.01728161610662937
[15/24] Train loss=0.013336262665688992
[20/24] Train loss=0.02366899698972702
Test set avg_accuracy=90.03% avg_sensitivity=74.36%, avg_specificity=94.83% avg_auc=94.64%
Fold[3] Epoch: 78 [78/100 (78%)] Train loss=0.016161 Test loss=0.673148 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.015156259760260582
[5/24] Train loss=0.008653244003653526
[10/24] Train loss=0.009067500941455364
[15/24] Train loss=0.01673521287739277
[20/24] Train loss=0.019194548949599266
Test set avg_accuracy=90.03% avg_sensitivity=73.70%, avg_specificity=95.03% avg_auc=94.65%
Fold[3] Epoch: 79 [79/100 (79%)] Train loss=0.013925 Test loss=0.711303 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.009960842318832874
[5/24] Train loss=0.01523342914879322
[10/24] Train loss=0.012204781174659729
[15/24] Train loss=0.014556258916854858
[20/24] Train loss=0.014411691576242447
Test set avg_accuracy=90.07% avg_sensitivity=75.14%, avg_specificity=94.64% avg_auc=94.68%
Fold[3] Epoch: 80 [80/100 (80%)] Train loss=0.014482 Test loss=0.713196 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.014052525162696838
[5/24] Train loss=0.009002161212265491
[10/24] Train loss=0.013006257824599743
[15/24] Train loss=0.015275735408067703
[20/24] Train loss=0.010894195176661015
Test set avg_accuracy=90.08% avg_sensitivity=74.47%, avg_specificity=94.86% avg_auc=94.64%
Fold[3] Epoch: 81 [81/100 (81%)] Train loss=0.013160 Test loss=0.733535 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.0157292652875185
[5/24] Train loss=0.01629306934773922
[10/24] Train loss=0.011760132387280464
[15/24] Train loss=0.009477510116994381
[20/24] Train loss=0.009820454753935337
Test set avg_accuracy=90.18% avg_sensitivity=75.08%, avg_specificity=94.81% avg_auc=94.60%
Fold[3] Epoch: 82 [82/100 (82%)] Train loss=0.012626 Test loss=0.734830 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.012570920400321484
[5/24] Train loss=0.0126674585044384
[10/24] Train loss=0.00894971564412117
[15/24] Train loss=0.011771061457693577
[20/24] Train loss=0.011751607991755009
Test set avg_accuracy=90.09% avg_sensitivity=74.64%, avg_specificity=94.83% avg_auc=94.56%
Fold[3] Epoch: 83 [83/100 (83%)] Train loss=0.012822 Test loss=0.735061 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.01426162850111723
[5/24] Train loss=0.01781093329191208
[10/24] Train loss=0.00988389365375042
[15/24] Train loss=0.007891341112554073
[20/24] Train loss=0.010221894830465317
Test set avg_accuracy=90.23% avg_sensitivity=75.19%, avg_specificity=94.85% avg_auc=94.58%
Fold[3] Epoch: 84 [84/100 (84%)] Train loss=0.012627 Test loss=0.765132 Current lr=[0.000122853263038123]

[0/24] Train loss=0.015781652182340622
[5/24] Train loss=0.012905312702059746
[10/24] Train loss=0.010536754503846169
[15/24] Train loss=0.01089443638920784
[20/24] Train loss=0.00750670675188303
Test set avg_accuracy=90.16% avg_sensitivity=74.75%, avg_specificity=94.88% avg_auc=94.57%
Fold[3] Epoch: 85 [85/100 (85%)] Train loss=0.011538 Test loss=0.779214 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.015004479326307774
[5/24] Train loss=0.007500029634684324
[10/24] Train loss=0.01258841622620821
[15/24] Train loss=0.00936039350926876
[20/24] Train loss=0.01686990074813366
Test set avg_accuracy=90.05% avg_sensitivity=74.42%, avg_specificity=94.85% avg_auc=94.56%
Fold[3] Epoch: 86 [86/100 (86%)] Train loss=0.011200 Test loss=0.787115 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.01327778585255146
[5/24] Train loss=0.012172959744930267
[10/24] Train loss=0.013088586740195751
[15/24] Train loss=0.007851053960621357
[20/24] Train loss=0.008035874925553799
Test set avg_accuracy=90.07% avg_sensitivity=74.42%, avg_specificity=94.86% avg_auc=94.54%
Fold[3] Epoch: 87 [87/100 (87%)] Train loss=0.011632 Test loss=0.792799 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.009330562315881252
[5/24] Train loss=0.008862697519361973
[10/24] Train loss=0.009481208398938179
[15/24] Train loss=0.006947830785065889
[20/24] Train loss=0.006754305213689804
Test set avg_accuracy=90.04% avg_sensitivity=74.53%, avg_specificity=94.79% avg_auc=94.53%
Fold[3] Epoch: 88 [88/100 (88%)] Train loss=0.011098 Test loss=0.802405 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.009624077938497066
[5/24] Train loss=0.012426375411450863
[10/24] Train loss=0.008082803338766098
[15/24] Train loss=0.007753916550427675
[20/24] Train loss=0.008206881582736969
Test set avg_accuracy=90.09% avg_sensitivity=74.86%, avg_specificity=94.76% avg_auc=94.54%
Fold[3] Epoch: 89 [89/100 (89%)] Train loss=0.010665 Test loss=0.799958 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.012715930119156837
[5/24] Train loss=0.008345654234290123
[10/24] Train loss=0.01440795324742794
[15/24] Train loss=0.012040023691952229
[20/24] Train loss=0.011611036956310272
Test set avg_accuracy=89.99% avg_sensitivity=74.69%, avg_specificity=94.68% avg_auc=94.55%
Fold[3] Epoch: 90 [90/100 (90%)] Train loss=0.012133 Test loss=0.785028 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.010682480409741402
[5/24] Train loss=0.010727840475738049
[10/24] Train loss=0.009980780072510242
[15/24] Train loss=0.012146749533712864
[20/24] Train loss=0.014461912214756012
Test set avg_accuracy=90.01% avg_sensitivity=74.31%, avg_specificity=94.83% avg_auc=94.56%
Fold[3] Epoch: 91 [91/100 (91%)] Train loss=0.010937 Test loss=0.784483 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.01448888797312975
[5/24] Train loss=0.01050624717026949
[10/24] Train loss=0.01115912664681673
[15/24] Train loss=0.00846178736537695
[20/24] Train loss=0.010752740316092968
Test set avg_accuracy=90.05% avg_sensitivity=74.36%, avg_specificity=94.86% avg_auc=94.56%
Fold[3] Epoch: 92 [92/100 (92%)] Train loss=0.011884 Test loss=0.784421 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.016890989616513252
[5/24] Train loss=0.01833839900791645
[10/24] Train loss=0.01333400048315525
[15/24] Train loss=0.01512537058442831
[20/24] Train loss=0.007895689457654953
Test set avg_accuracy=90.05% avg_sensitivity=74.36%, avg_specificity=94.86% avg_auc=94.58%
Fold[3] Epoch: 93 [93/100 (93%)] Train loss=0.011757 Test loss=0.772722 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.01016485970467329
[5/24] Train loss=0.013510126620531082
[10/24] Train loss=0.011682698503136635
[15/24] Train loss=0.008084915578365326
[20/24] Train loss=0.009071670472621918
Test set avg_accuracy=90.05% avg_sensitivity=74.31%, avg_specificity=94.88% avg_auc=94.58%
Fold[3] Epoch: 94 [94/100 (94%)] Train loss=0.010193 Test loss=0.773357 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.013145817443728447
[5/24] Train loss=0.010018164291977882
[10/24] Train loss=0.0080325398594141
[15/24] Train loss=0.008884038776159286
[20/24] Train loss=0.011372264474630356
Test set avg_accuracy=90.05% avg_sensitivity=74.31%, avg_specificity=94.88% avg_auc=94.58%
Fold[3] Epoch: 95 [95/100 (95%)] Train loss=0.009603 Test loss=0.775112 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.016027821227908134
[5/24] Train loss=0.008786165155470371
[10/24] Train loss=0.010591692291200161
[15/24] Train loss=0.00825375784188509
[20/24] Train loss=0.010419818572700024
Test set avg_accuracy=90.09% avg_sensitivity=74.47%, avg_specificity=94.88% avg_auc=94.58%
Fold[3] Epoch: 96 [96/100 (96%)] Train loss=0.010499 Test loss=0.775837 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.007763545028865337
[5/24] Train loss=0.010940337553620338
[10/24] Train loss=0.009336591698229313
[15/24] Train loss=0.007652866188436747
[20/24] Train loss=0.009808269329369068
Test set avg_accuracy=90.09% avg_sensitivity=74.47%, avg_specificity=94.88% avg_auc=94.59%
Fold[3] Epoch: 97 [97/100 (97%)] Train loss=0.011077 Test loss=0.775926 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.014250688254833221
[5/24] Train loss=0.01096341386437416
[10/24] Train loss=0.0070952242240309715
[15/24] Train loss=0.00853257067501545
[20/24] Train loss=0.008578297682106495
Test set avg_accuracy=90.08% avg_sensitivity=74.47%, avg_specificity=94.86% avg_auc=94.59%
Fold[3] Epoch: 98 [98/100 (98%)] Train loss=0.011119 Test loss=0.775955 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.006755170412361622
[5/24] Train loss=0.012685596942901611
[10/24] Train loss=0.00970475934445858
[15/24] Train loss=0.00929795391857624
[20/24] Train loss=0.008404653519392014
Test set avg_accuracy=90.08% avg_sensitivity=74.47%, avg_specificity=94.86% avg_auc=94.59%
Fold[3] Epoch: 99 [99/100 (99%)] Train loss=0.010862 Test loss=0.776108 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.010967548005282879
[5/24] Train loss=0.009004587307572365
[10/24] Train loss=0.007100545801222324
[15/24] Train loss=0.006866768002510071
[20/24] Train loss=0.012359189800918102
Test set avg_accuracy=90.08% avg_sensitivity=74.47%, avg_specificity=94.86% avg_auc=94.58%
Fold[3] Epoch: 100 [100/100 (100%)] Train loss=0.011249 Test loss=0.787026 Current lr=[4.874217159761039e-09]

Fold[3] Result: acc=90.22% sen=82.46%, spe=92.60%, auc=95.28%!
Fold[3] Avg_overlap=0.70%(Â±0.2318271798791912)
[0/24] Train loss=1.4020410776138306
[5/24] Train loss=1.3239428997039795
[10/24] Train loss=1.3107396364212036
[15/24] Train loss=1.1172380447387695
[20/24] Train loss=1.0180130004882812
Test set avg_accuracy=74.93% avg_sensitivity=12.79%, avg_specificity=95.04% avg_auc=69.40%
Best model saved!! Metric=69.40182410747624!!
Fold[4] Epoch: 1 [1/100 (1%)] Train loss=1.231478 Test loss=0.669874 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=0.9619622826576233
[5/24] Train loss=0.8906329274177551
[10/24] Train loss=1.008226752281189
[15/24] Train loss=0.9016391038894653
[20/24] Train loss=0.8234924674034119
Test set avg_accuracy=80.77% avg_sensitivity=49.65%, avg_specificity=90.83% avg_auc=83.30%
Best model saved!! Metric=83.3008499360691!!
Fold[4] Epoch: 2 [2/100 (2%)] Train loss=0.964990 Test loss=0.506615 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8611836433410645
[5/24] Train loss=0.8396539688110352
[10/24] Train loss=0.9560593366622925
[15/24] Train loss=0.8261503577232361
[20/24] Train loss=0.7904849648475647
Test set avg_accuracy=84.41% avg_sensitivity=61.27%, avg_specificity=91.90% avg_auc=87.66%
Best model saved!! Metric=87.65536188132623!!
Fold[4] Epoch: 3 [3/100 (3%)] Train loss=0.879625 Test loss=0.387803 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.7972686290740967
[5/24] Train loss=0.7174253463745117
[10/24] Train loss=0.8928737640380859
[15/24] Train loss=0.7725067734718323
[20/24] Train loss=0.7102376818656921
Test set avg_accuracy=87.42% avg_sensitivity=75.01%, avg_specificity=91.44% avg_auc=91.78%
Best model saved!! Metric=91.77640466861197!!
Fold[4] Epoch: 4 [4/100 (4%)] Train loss=0.802659 Test loss=0.324053 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.7349844574928284
[5/24] Train loss=0.6700865626335144
[10/24] Train loss=0.8217822909355164
[15/24] Train loss=0.7556630969047546
[20/24] Train loss=0.6815166473388672
Test set avg_accuracy=88.16% avg_sensitivity=82.42%, avg_specificity=90.02% avg_auc=93.47%
Best model saved!! Metric=93.4674631854576!!
Fold[4] Epoch: 5 [5/100 (5%)] Train loss=0.767121 Test loss=0.306907 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.735905647277832
[5/24] Train loss=0.6396762728691101
[10/24] Train loss=0.8310984969139099
[15/24] Train loss=0.7158205509185791
[20/24] Train loss=0.6071312427520752
Test set avg_accuracy=86.00% avg_sensitivity=88.65%, avg_specificity=85.15% avg_auc=93.63%
Best model saved!! Metric=93.63440786373332!!
Fold[4] Epoch: 6 [6/100 (6%)] Train loss=0.743479 Test loss=0.377985 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.7324444055557251
[5/24] Train loss=0.635500967502594
[10/24] Train loss=0.8437232375144958
[15/24] Train loss=0.7074934840202332
[20/24] Train loss=0.6305826902389526
Test set avg_accuracy=85.14% avg_sensitivity=89.93%, avg_specificity=83.59% avg_auc=93.73%
Best model saved!! Metric=93.72975104916523!!
Fold[4] Epoch: 7 [7/100 (7%)] Train loss=0.729872 Test loss=0.384105 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.6952999234199524
[5/24] Train loss=0.6634769439697266
[10/24] Train loss=0.825697124004364
[15/24] Train loss=0.7099319696426392
[20/24] Train loss=0.5880032777786255
Test set avg_accuracy=85.31% avg_sensitivity=90.20%, avg_specificity=83.73% avg_auc=93.95%
Best model saved!! Metric=93.95130345656459!!
Fold[4] Epoch: 8 [8/100 (8%)] Train loss=0.713155 Test loss=0.388192 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.6878445744514465
[5/24] Train loss=0.6067931652069092
[10/24] Train loss=0.8247429132461548
[15/24] Train loss=0.6951111555099487
[20/24] Train loss=0.5857366919517517
Test set avg_accuracy=86.48% avg_sensitivity=89.66%, avg_specificity=85.46% avg_auc=94.28%
Best model saved!! Metric=94.28359993466904!!
Fold[4] Epoch: 9 [9/100 (9%)] Train loss=0.695377 Test loss=0.346470 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6386452913284302
[5/24] Train loss=0.5700357556343079
[10/24] Train loss=0.7845668196678162
[15/24] Train loss=0.6715775728225708
[20/24] Train loss=0.5505110621452332
Test set avg_accuracy=88.01% avg_sensitivity=89.08%, avg_specificity=87.66% avg_auc=94.42%
Best model saved!! Metric=94.424094567954!!
Fold[4] Epoch: 10 [10/100 (10%)] Train loss=0.663665 Test loss=0.323596 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.6136083006858826
[5/24] Train loss=0.5680782198905945
[10/24] Train loss=0.7684354782104492
[15/24] Train loss=0.6612297296524048
[20/24] Train loss=0.5892654657363892
Test set avg_accuracy=88.35% avg_sensitivity=88.17%, avg_specificity=88.40% avg_auc=94.65%
Best model saved!! Metric=94.65073775978492!!
Fold[4] Epoch: 11 [11/100 (11%)] Train loss=0.652595 Test loss=0.316609 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.6248980760574341
[5/24] Train loss=0.5699841976165771
[10/24] Train loss=0.7711883783340454
[15/24] Train loss=0.6585630178451538
[20/24] Train loss=0.5156718492507935
Test set avg_accuracy=89.47% avg_sensitivity=86.63%, avg_specificity=90.38% avg_auc=94.75%
Best model saved!! Metric=94.74814663772739!!
Fold[4] Epoch: 12 [12/100 (12%)] Train loss=0.647287 Test loss=0.289373 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.6126017570495605
[5/24] Train loss=0.5662116408348083
[10/24] Train loss=0.7421666979789734
[15/24] Train loss=0.6318085193634033
[20/24] Train loss=0.542962908744812
Test set avg_accuracy=88.95% avg_sensitivity=86.68%, avg_specificity=89.68% avg_auc=94.96%
Best model saved!! Metric=94.95709373038453!!
Fold[4] Epoch: 13 [13/100 (13%)] Train loss=0.644009 Test loss=0.278872 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.620243489742279
[5/24] Train loss=0.5310973525047302
[10/24] Train loss=0.7542338967323303
[15/24] Train loss=0.6244246959686279
[20/24] Train loss=0.5241486430168152
Test set avg_accuracy=90.60% avg_sensitivity=81.94%, avg_specificity=93.40% avg_auc=94.88%
Fold[4] Epoch: 14 [14/100 (14%)] Train loss=0.620758 Test loss=0.252026 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.5880045294761658
[5/24] Train loss=0.5290275812149048
[10/24] Train loss=0.7264034748077393
[15/24] Train loss=0.6716506481170654
[20/24] Train loss=0.5415721535682678
Test set avg_accuracy=88.49% avg_sensitivity=87.59%, avg_specificity=88.78% avg_auc=95.00%
Best model saved!! Metric=95.00022998043283!!
Fold[4] Epoch: 15 [15/100 (15%)] Train loss=0.622115 Test loss=0.293849 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.5991722345352173
[5/24] Train loss=0.5238456726074219
[10/24] Train loss=0.7295101284980774
[15/24] Train loss=0.6147652864456177
[20/24] Train loss=0.517943799495697
Test set avg_accuracy=89.74% avg_sensitivity=85.46%, avg_specificity=91.13% avg_auc=95.20%
Best model saved!! Metric=95.20464632085015!!
Fold[4] Epoch: 16 [16/100 (16%)] Train loss=0.611697 Test loss=0.262083 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.6054469347000122
[5/24] Train loss=0.5235751867294312
[10/24] Train loss=0.6854205131530762
[15/24] Train loss=0.6269564628601074
[20/24] Train loss=0.4918442666530609
Test set avg_accuracy=90.61% avg_sensitivity=82.42%, avg_specificity=93.26% avg_auc=95.35%
Best model saved!! Metric=95.34920807316702!!
Fold[4] Epoch: 17 [17/100 (17%)] Train loss=0.603929 Test loss=0.240874 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5647520422935486
[5/24] Train loss=0.5361391305923462
[10/24] Train loss=0.6717104911804199
[15/24] Train loss=0.5892776846885681
[20/24] Train loss=0.4925306439399719
Test set avg_accuracy=90.81% avg_sensitivity=80.71%, avg_specificity=94.07% avg_auc=95.26%
Fold[4] Epoch: 18 [18/100 (18%)] Train loss=0.594599 Test loss=0.237353 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.5840254426002502
[5/24] Train loss=0.4940575659275055
[10/24] Train loss=0.7110181450843811
[15/24] Train loss=0.595934271812439
[20/24] Train loss=0.4823417365550995
Test set avg_accuracy=91.20% avg_sensitivity=73.36%, avg_specificity=96.97% avg_auc=95.32%
Fold[4] Epoch: 19 [19/100 (19%)] Train loss=0.579091 Test loss=0.240593 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5448483228683472
[5/24] Train loss=0.4778082072734833
[10/24] Train loss=0.6409430503845215
[15/24] Train loss=0.5307763814926147
[20/24] Train loss=0.45627304911613464
Test set avg_accuracy=90.61% avg_sensitivity=70.22%, avg_specificity=97.21% avg_auc=95.22%
Fold[4] Epoch: 20 [20/100 (20%)] Train loss=0.564262 Test loss=0.250452 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5638790130615234
[5/24] Train loss=0.5029098987579346
[10/24] Train loss=0.6678694486618042
[15/24] Train loss=0.5865268111228943
[20/24] Train loss=0.45595577359199524
Test set avg_accuracy=90.46% avg_sensitivity=70.64%, avg_specificity=96.86% avg_auc=95.30%
Fold[4] Epoch: 21 [21/100 (21%)] Train loss=0.566439 Test loss=0.252579 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.5483500361442566
[5/24] Train loss=0.4397234320640564
[10/24] Train loss=0.6667015552520752
[15/24] Train loss=0.5465554594993591
[20/24] Train loss=0.4723220467567444
Test set avg_accuracy=91.46% avg_sensitivity=75.60%, avg_specificity=96.59% avg_auc=95.68%
Best model saved!! Metric=95.68053597100538!!
Fold[4] Epoch: 22 [22/100 (22%)] Train loss=0.556446 Test loss=0.229395 Current lr=[0.000842324016282456]

[0/24] Train loss=0.5198516845703125
[5/24] Train loss=0.4712655246257782
[10/24] Train loss=0.6375617384910583
[15/24] Train loss=0.5201282501220703
[20/24] Train loss=0.42681023478507996
Test set avg_accuracy=90.00% avg_sensitivity=67.39%, avg_specificity=97.31% avg_auc=95.30%
Fold[4] Epoch: 23 [23/100 (23%)] Train loss=0.536324 Test loss=0.248209 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5492050647735596
[5/24] Train loss=0.4341447353363037
[10/24] Train loss=0.6442466378211975
[15/24] Train loss=0.5399117469787598
[20/24] Train loss=0.47344839572906494
Test set avg_accuracy=89.66% avg_sensitivity=63.72%, avg_specificity=98.05% avg_auc=95.02%
Fold[4] Epoch: 24 [24/100 (24%)] Train loss=0.534456 Test loss=0.264995 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.5462697148323059
[5/24] Train loss=0.439470112323761
[10/24] Train loss=0.60267573595047
[15/24] Train loss=0.49027299880981445
[20/24] Train loss=0.41289642453193665
Test set avg_accuracy=88.39% avg_sensitivity=56.53%, avg_specificity=98.69% avg_auc=94.42%
Fold[4] Epoch: 25 [25/100 (25%)] Train loss=0.517059 Test loss=0.317963 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.5176334977149963
[5/24] Train loss=0.43272924423217773
[10/24] Train loss=0.5753845572471619
[15/24] Train loss=0.5064347386360168
[20/24] Train loss=0.4292623996734619
Test set avg_accuracy=89.43% avg_sensitivity=62.97%, avg_specificity=97.98% avg_auc=94.97%
Fold[4] Epoch: 26 [26/100 (26%)] Train loss=0.507298 Test loss=0.287925 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.5386205315589905
[5/24] Train loss=0.41487371921539307
[10/24] Train loss=0.603445827960968
[15/24] Train loss=0.46210965514183044
[20/24] Train loss=0.4135090708732605
Test set avg_accuracy=90.10% avg_sensitivity=66.06%, avg_specificity=97.88% avg_auc=95.12%
Fold[4] Epoch: 27 [27/100 (27%)] Train loss=0.508028 Test loss=0.274351 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.4955008327960968
[5/24] Train loss=0.4131386876106262
[10/24] Train loss=0.5776785612106323
[15/24] Train loss=0.48488685488700867
[20/24] Train loss=0.39989739656448364
Test set avg_accuracy=90.10% avg_sensitivity=64.89%, avg_specificity=98.26% avg_auc=95.42%
Fold[4] Epoch: 28 [28/100 (28%)] Train loss=0.494523 Test loss=0.272136 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.4485689103603363
[5/24] Train loss=0.4143076241016388
[10/24] Train loss=0.5804685354232788
[15/24] Train loss=0.47825485467910767
[20/24] Train loss=0.3885078728199005
Test set avg_accuracy=90.56% avg_sensitivity=72.24%, avg_specificity=96.48% avg_auc=95.29%
Fold[4] Epoch: 29 [29/100 (29%)] Train loss=0.482342 Test loss=0.248712 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.4501519799232483
[5/24] Train loss=0.39431795477867126
[10/24] Train loss=0.5213718414306641
[15/24] Train loss=0.44496017694473267
[20/24] Train loss=0.3969508707523346
Test set avg_accuracy=90.86% avg_sensitivity=71.76%, avg_specificity=97.04% avg_auc=95.44%
Fold[4] Epoch: 30 [30/100 (30%)] Train loss=0.467934 Test loss=0.247890 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.45659393072128296
[5/24] Train loss=0.4082601070404053
[10/24] Train loss=0.48791053891181946
[15/24] Train loss=0.4468178153038025
[20/24] Train loss=0.3867471218109131
Test set avg_accuracy=91.11% avg_sensitivity=72.30%, avg_specificity=97.19% avg_auc=95.44%
Fold[4] Epoch: 31 [31/100 (31%)] Train loss=0.457976 Test loss=0.263865 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.43124502897262573
[5/24] Train loss=0.3939626216888428
[10/24] Train loss=0.5016729235649109
[15/24] Train loss=0.4116707146167755
[20/24] Train loss=0.3808528184890747
Test set avg_accuracy=91.12% avg_sensitivity=70.96%, avg_specificity=97.64% avg_auc=95.56%
Fold[4] Epoch: 32 [32/100 (32%)] Train loss=0.435665 Test loss=0.256947 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.423354834318161
[5/24] Train loss=0.3909045159816742
[10/24] Train loss=0.47657129168510437
[15/24] Train loss=0.4465686082839966
[20/24] Train loss=0.3433819115161896
Test set avg_accuracy=90.77% avg_sensitivity=74.59%, avg_specificity=96.00% avg_auc=95.22%
Fold[4] Epoch: 33 [33/100 (33%)] Train loss=0.425813 Test loss=0.265344 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.41924983263015747
[5/24] Train loss=0.38762354850769043
[10/24] Train loss=0.48216745257377625
[15/24] Train loss=0.4086046516895294
[20/24] Train loss=0.33471858501434326
Test set avg_accuracy=90.29% avg_sensitivity=73.52%, avg_specificity=95.71% avg_auc=94.92%
Fold[4] Epoch: 34 [34/100 (34%)] Train loss=0.416765 Test loss=0.267098 Current lr=[0.000991797016730875]

[0/24] Train loss=0.38924238085746765
[5/24] Train loss=0.3499538004398346
[10/24] Train loss=0.4697047770023346
[15/24] Train loss=0.4021233022212982
[20/24] Train loss=0.31495025753974915
Test set avg_accuracy=88.83% avg_sensitivity=60.63%, avg_specificity=97.95% avg_auc=94.44%
Fold[4] Epoch: 35 [35/100 (35%)] Train loss=0.402335 Test loss=0.308784 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.4149944484233856
[5/24] Train loss=0.3169034421443939
[10/24] Train loss=0.4031464457511902
[15/24] Train loss=0.3398140072822571
[20/24] Train loss=0.28148341178894043
Test set avg_accuracy=89.61% avg_sensitivity=63.61%, avg_specificity=98.02% avg_auc=94.52%
Fold[4] Epoch: 36 [36/100 (36%)] Train loss=0.379616 Test loss=0.302555 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.3826014995574951
[5/24] Train loss=0.2980278432369232
[10/24] Train loss=0.37801864743232727
[15/24] Train loss=0.3749249577522278
[20/24] Train loss=0.3243561089038849
Test set avg_accuracy=91.16% avg_sensitivity=77.25%, avg_specificity=95.66% avg_auc=95.27%
Fold[4] Epoch: 37 [37/100 (37%)] Train loss=0.362207 Test loss=0.264167 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.3491680920124054
[5/24] Train loss=0.3098005950450897
[10/24] Train loss=0.36286818981170654
[15/24] Train loss=0.323772668838501
[20/24] Train loss=0.2881687879562378
Test set avg_accuracy=90.51% avg_sensitivity=73.84%, avg_specificity=95.90% avg_auc=94.74%
Fold[4] Epoch: 38 [38/100 (38%)] Train loss=0.347698 Test loss=0.288307 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.33412209153175354
[5/24] Train loss=0.24311886727809906
[10/24] Train loss=0.40208494663238525
[15/24] Train loss=0.30760109424591064
[20/24] Train loss=0.2788868546485901
Test set avg_accuracy=89.78% avg_sensitivity=68.19%, avg_specificity=96.76% avg_auc=94.55%
Fold[4] Epoch: 39 [39/100 (39%)] Train loss=0.347973 Test loss=0.289481 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.34848883748054504
[5/24] Train loss=0.2678435146808624
[10/24] Train loss=0.33846741914749146
[15/24] Train loss=0.3359133005142212
[20/24] Train loss=0.29299405217170715
Test set avg_accuracy=90.40% avg_sensitivity=81.51%, avg_specificity=93.28% avg_auc=94.87%
Fold[4] Epoch: 40 [40/100 (40%)] Train loss=0.324230 Test loss=0.290891 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.31627777218818665
[5/24] Train loss=0.2811349332332611
[10/24] Train loss=0.32496631145477295
[15/24] Train loss=0.2966311573982239
[20/24] Train loss=0.24611254036426544
Test set avg_accuracy=89.64% avg_sensitivity=80.39%, avg_specificity=92.62% avg_auc=94.28%
Fold[4] Epoch: 41 [41/100 (41%)] Train loss=0.310828 Test loss=0.317062 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.3453151285648346
[5/24] Train loss=0.2702130377292633
[10/24] Train loss=0.3120143711566925
[15/24] Train loss=0.32086730003356934
[20/24] Train loss=0.2434162199497223
Test set avg_accuracy=89.95% avg_sensitivity=80.02%, avg_specificity=93.16% avg_auc=94.72%
Fold[4] Epoch: 42 [42/100 (42%)] Train loss=0.308979 Test loss=0.286965 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.3212309777736664
[5/24] Train loss=0.24102428555488586
[10/24] Train loss=0.3016388416290283
[15/24] Train loss=0.2655397653579712
[20/24] Train loss=0.21425795555114746
Test set avg_accuracy=90.27% avg_sensitivity=74.91%, avg_specificity=95.24% avg_auc=95.01%
Fold[4] Epoch: 43 [43/100 (43%)] Train loss=0.275417 Test loss=0.320810 Current lr=[0.000916771143003274]

[0/24] Train loss=0.25986215472221375
[5/24] Train loss=0.1964745968580246
[10/24] Train loss=0.28118857741355896
[15/24] Train loss=0.24196864664554596
[20/24] Train loss=0.18977677822113037
Test set avg_accuracy=90.57% avg_sensitivity=77.25%, avg_specificity=94.88% avg_auc=95.44%
Fold[4] Epoch: 44 [44/100 (44%)] Train loss=0.245413 Test loss=0.302879 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.24011212587356567
[5/24] Train loss=0.16121219098567963
[10/24] Train loss=0.2154354304075241
[15/24] Train loss=0.19532360136508942
[20/24] Train loss=0.17251020669937134
Test set avg_accuracy=90.18% avg_sensitivity=76.88%, avg_specificity=94.49% avg_auc=95.08%
Fold[4] Epoch: 45 [45/100 (45%)] Train loss=0.214522 Test loss=0.346483 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.2132430374622345
[5/24] Train loss=0.1757008582353592
[10/24] Train loss=0.19661957025527954
[15/24] Train loss=0.188590407371521
[20/24] Train loss=0.15521082282066345
Test set avg_accuracy=90.89% avg_sensitivity=80.23%, avg_specificity=94.33% avg_auc=95.30%
Fold[4] Epoch: 46 [46/100 (46%)] Train loss=0.196953 Test loss=0.332803 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.21493205428123474
[5/24] Train loss=0.14750255644321442
[10/24] Train loss=0.18028908967971802
[15/24] Train loss=0.19045130908489227
[20/24] Train loss=0.14158229529857635
Test set avg_accuracy=90.61% avg_sensitivity=78.00%, avg_specificity=94.69% avg_auc=94.98%
Fold[4] Epoch: 47 [47/100 (47%)] Train loss=0.184654 Test loss=0.382117 Current lr=[0.000860751215339601]

[0/24] Train loss=0.19582177698612213
[5/24] Train loss=0.14736351370811462
[10/24] Train loss=0.18215125799179077
[15/24] Train loss=0.1533038169145584
[20/24] Train loss=0.17766161262989044
Test set avg_accuracy=90.72% avg_sensitivity=80.66%, avg_specificity=93.97% avg_auc=95.03%
Fold[4] Epoch: 48 [48/100 (48%)] Train loss=0.166637 Test loss=0.375916 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.15756191313266754
[5/24] Train loss=0.13872656226158142
[10/24] Train loss=0.16557306051254272
[15/24] Train loss=0.1381571888923645
[20/24] Train loss=0.13435186445713043
Test set avg_accuracy=90.65% avg_sensitivity=75.71%, avg_specificity=95.49% avg_auc=95.04%
Fold[4] Epoch: 49 [49/100 (49%)] Train loss=0.159173 Test loss=0.413674 Current lr=[0.000828265354963756]

[0/24] Train loss=0.1444607824087143
[5/24] Train loss=0.11909447610378265
[10/24] Train loss=0.1604049801826477
[15/24] Train loss=0.14557865262031555
[20/24] Train loss=0.13020861148834229
Test set avg_accuracy=90.10% avg_sensitivity=71.71%, avg_specificity=96.05% avg_auc=94.64%
Fold[4] Epoch: 50 [50/100 (50%)] Train loss=0.146664 Test loss=0.420542 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.14725364744663239
[5/24] Train loss=0.10707239806652069
[10/24] Train loss=0.130670964717865
[15/24] Train loss=0.1550678312778473
[20/24] Train loss=0.10974437743425369
Test set avg_accuracy=90.43% avg_sensitivity=78.80%, avg_specificity=94.19% avg_auc=94.70%
Fold[4] Epoch: 51 [51/100 (51%)] Train loss=0.134721 Test loss=0.382599 Current lr=[0.00079313651106947]

[0/24] Train loss=0.12507779896259308
[5/24] Train loss=0.10731431841850281
[10/24] Train loss=0.13312408328056335
[15/24] Train loss=0.10329072177410126
[20/24] Train loss=0.11086871474981308
Test set avg_accuracy=90.08% avg_sensitivity=72.83%, avg_specificity=95.66% avg_auc=94.62%
Fold[4] Epoch: 52 [52/100 (52%)] Train loss=0.126659 Test loss=0.406446 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.13470911979675293
[5/24] Train loss=0.10056979954242706
[10/24] Train loss=0.13207344710826874
[15/24] Train loss=0.10741250216960907
[20/24] Train loss=0.08613605797290802
Test set avg_accuracy=90.66% avg_sensitivity=78.48%, avg_specificity=94.61% avg_auc=94.80%
Fold[4] Epoch: 53 [53/100 (53%)] Train loss=0.115735 Test loss=0.520728 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.10910176485776901
[5/24] Train loss=0.08592401444911957
[10/24] Train loss=0.10397683084011078
[15/24] Train loss=0.09500887244939804
[20/24] Train loss=0.08392229676246643
Test set avg_accuracy=90.16% avg_sensitivity=77.57%, avg_specificity=94.23% avg_auc=94.94%
Fold[4] Epoch: 54 [54/100 (54%)] Train loss=0.107099 Test loss=0.536690 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.1011262759566307
[5/24] Train loss=0.09428758174180984
[10/24] Train loss=0.10789866745471954
[15/24] Train loss=0.09879478812217712
[20/24] Train loss=0.06987340748310089
Test set avg_accuracy=89.96% avg_sensitivity=72.51%, avg_specificity=95.61% avg_auc=94.74%
Fold[4] Epoch: 55 [55/100 (55%)] Train loss=0.097651 Test loss=0.496071 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.10610027611255646
[5/24] Train loss=0.07658246904611588
[10/24] Train loss=0.1174589991569519
[15/24] Train loss=0.09233947098255157
[20/24] Train loss=0.07106062769889832
Test set avg_accuracy=89.61% avg_sensitivity=72.67%, avg_specificity=95.09% avg_auc=95.06%
Fold[4] Epoch: 56 [56/100 (56%)] Train loss=0.091435 Test loss=0.514408 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.08801627904176712
[5/24] Train loss=0.06116617098450661
[10/24] Train loss=0.09931062906980515
[15/24] Train loss=0.07351706922054291
[20/24] Train loss=0.06228169798851013
Test set avg_accuracy=90.30% avg_sensitivity=69.74%, avg_specificity=96.95% avg_auc=95.14%
Fold[4] Epoch: 57 [57/100 (57%)] Train loss=0.087490 Test loss=0.536312 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.10009433329105377
[5/24] Train loss=0.05581040680408478
[10/24] Train loss=0.07497850060462952
[15/24] Train loss=0.08181624859571457
[20/24] Train loss=0.07792619615793228
Test set avg_accuracy=90.12% avg_sensitivity=71.87%, avg_specificity=96.02% avg_auc=94.95%
Fold[4] Epoch: 58 [58/100 (58%)] Train loss=0.081064 Test loss=0.485490 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.07388350367546082
[5/24] Train loss=0.05705893039703369
[10/24] Train loss=0.08821931481361389
[15/24] Train loss=0.07599756121635437
[20/24] Train loss=0.056770168244838715
Test set avg_accuracy=90.14% avg_sensitivity=72.56%, avg_specificity=95.83% avg_auc=94.81%
Fold[4] Epoch: 59 [59/100 (59%)] Train loss=0.075455 Test loss=0.461498 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.07425059378147125
[5/24] Train loss=0.057740677148103714
[10/24] Train loss=0.08709392696619034
[15/24] Train loss=0.05682377889752388
[20/24] Train loss=0.048036158084869385
Test set avg_accuracy=90.20% avg_sensitivity=72.99%, avg_specificity=95.76% avg_auc=94.82%
Fold[4] Epoch: 60 [60/100 (60%)] Train loss=0.065771 Test loss=0.471782 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.06207035854458809
[5/24] Train loss=0.05286410078406334
[10/24] Train loss=0.0543709322810173
[15/24] Train loss=0.04606267809867859
[20/24] Train loss=0.05381438881158829
Test set avg_accuracy=90.52% avg_sensitivity=74.16%, avg_specificity=95.81% avg_auc=95.11%
Fold[4] Epoch: 61 [61/100 (61%)] Train loss=0.058741 Test loss=0.460641 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.06289194524288177
[5/24] Train loss=0.04300430044531822
[10/24] Train loss=0.06161554902791977
[15/24] Train loss=0.04152435064315796
[20/24] Train loss=0.048379357904195786
Test set avg_accuracy=90.47% avg_sensitivity=76.29%, avg_specificity=95.05% avg_auc=95.04%
Fold[4] Epoch: 62 [62/100 (62%)] Train loss=0.056300 Test loss=0.459584 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.049149494618177414
[5/24] Train loss=0.034931398928165436
[10/24] Train loss=0.05890556424856186
[15/24] Train loss=0.034840986132621765
[20/24] Train loss=0.04024431109428406
Test set avg_accuracy=90.60% avg_sensitivity=80.71%, avg_specificity=93.80% avg_auc=95.13%
Fold[4] Epoch: 63 [63/100 (63%)] Train loss=0.050718 Test loss=0.512163 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.04587842896580696
[5/24] Train loss=0.03124811127781868
[10/24] Train loss=0.052053529769182205
[15/24] Train loss=0.03706403821706772
[20/24] Train loss=0.04111112281680107
Test set avg_accuracy=90.18% avg_sensitivity=80.02%, avg_specificity=93.47% avg_auc=95.20%
Fold[4] Epoch: 64 [64/100 (64%)] Train loss=0.044783 Test loss=0.583761 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.04929613694548607
[5/24] Train loss=0.02650691568851471
[10/24] Train loss=0.04766172915697098
[15/24] Train loss=0.04433996230363846
[20/24] Train loss=0.03559235855937004
Test set avg_accuracy=90.59% avg_sensitivity=80.23%, avg_specificity=93.93% avg_auc=95.22%
Fold[4] Epoch: 65 [65/100 (65%)] Train loss=0.043209 Test loss=0.580898 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.04236099123954773
[5/24] Train loss=0.030903086066246033
[10/24] Train loss=0.03246420621871948
[15/24] Train loss=0.027366507798433304
[20/24] Train loss=0.01949394680559635
Test set avg_accuracy=90.51% avg_sensitivity=78.10%, avg_specificity=94.52% avg_auc=95.20%
Fold[4] Epoch: 66 [66/100 (66%)] Train loss=0.036238 Test loss=0.543718 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.04242945462465286
[5/24] Train loss=0.02904338948428631
[10/24] Train loss=0.029003648087382317
[15/24] Train loss=0.04073001816868782
[20/24] Train loss=0.02641032077372074
Test set avg_accuracy=90.47% avg_sensitivity=79.97%, avg_specificity=93.87% avg_auc=94.99%
Fold[4] Epoch: 67 [67/100 (67%)] Train loss=0.035712 Test loss=0.533949 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.03895905986428261
[5/24] Train loss=0.029992401599884033
[10/24] Train loss=0.028326895087957382
[15/24] Train loss=0.03061368688941002
[20/24] Train loss=0.01884339191019535
Test set avg_accuracy=90.14% avg_sensitivity=78.74%, avg_specificity=93.83% avg_auc=95.14%
Fold[4] Epoch: 68 [68/100 (68%)] Train loss=0.033570 Test loss=0.610815 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.034820813685655594
[5/24] Train loss=0.032769765704870224
[10/24] Train loss=0.026897383853793144
[15/24] Train loss=0.029419107362627983
[20/24] Train loss=0.021573347970843315
Test set avg_accuracy=90.34% avg_sensitivity=77.89%, avg_specificity=94.36% avg_auc=95.23%
Fold[4] Epoch: 69 [69/100 (69%)] Train loss=0.030673 Test loss=0.559896 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.02829318679869175
[5/24] Train loss=0.016185136511921883
[10/24] Train loss=0.03392837569117546
[15/24] Train loss=0.026225825771689415
[20/24] Train loss=0.019582612439990044
Test set avg_accuracy=90.74% avg_sensitivity=77.62%, avg_specificity=94.99% avg_auc=95.21%
Fold[4] Epoch: 70 [70/100 (70%)] Train loss=0.027425 Test loss=0.652739 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.03201508894562721
[5/24] Train loss=0.023067856207489967
[10/24] Train loss=0.021316150203347206
[15/24] Train loss=0.02258020080626011
[20/24] Train loss=0.01944544166326523
Test set avg_accuracy=90.62% avg_sensitivity=74.96%, avg_specificity=95.69% avg_auc=95.29%
Fold[4] Epoch: 71 [71/100 (71%)] Train loss=0.023431 Test loss=0.561959 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.022157208994030952
[5/24] Train loss=0.01589474081993103
[10/24] Train loss=0.027142854407429695
[15/24] Train loss=0.01704852283000946
[20/24] Train loss=0.01976911537349224
Test set avg_accuracy=90.62% avg_sensitivity=76.56%, avg_specificity=95.17% avg_auc=95.26%
Fold[4] Epoch: 72 [72/100 (72%)] Train loss=0.024171 Test loss=0.551095 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.03309588134288788
[5/24] Train loss=0.01556125283241272
[10/24] Train loss=0.017465850338339806
[15/24] Train loss=0.013328833505511284
[20/24] Train loss=0.017814699560403824
Test set avg_accuracy=90.49% avg_sensitivity=77.30%, avg_specificity=94.76% avg_auc=95.25%
Fold[4] Epoch: 73 [73/100 (73%)] Train loss=0.022345 Test loss=0.595498 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.021896012127399445
[5/24] Train loss=0.012355047278106213
[10/24] Train loss=0.019697459414601326
[15/24] Train loss=0.012741362676024437
[20/24] Train loss=0.01741640269756317
Test set avg_accuracy=90.89% avg_sensitivity=76.88%, avg_specificity=95.42% avg_auc=95.21%
Fold[4] Epoch: 74 [74/100 (74%)] Train loss=0.020695 Test loss=0.621936 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.018035443499684334
[5/24] Train loss=0.009240292944014072
[10/24] Train loss=0.015234546735882759
[15/24] Train loss=0.02180049940943718
[20/24] Train loss=0.011734116822481155
Test set avg_accuracy=90.69% avg_sensitivity=78.16%, avg_specificity=94.74% avg_auc=95.29%
Fold[4] Epoch: 75 [75/100 (75%)] Train loss=0.018226 Test loss=0.688230 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.02184448391199112
[5/24] Train loss=0.01959899254143238
[10/24] Train loss=0.018518637865781784
[15/24] Train loss=0.01071255560964346
[20/24] Train loss=0.02329714596271515
Test set avg_accuracy=90.91% avg_sensitivity=77.04%, avg_specificity=95.40% avg_auc=95.29%
Fold[4] Epoch: 76 [76/100 (76%)] Train loss=0.020131 Test loss=0.610519 Current lr=[0.000262245679641298]

[0/24] Train loss=0.015811484307050705
[5/24] Train loss=0.008374413475394249
[10/24] Train loss=0.016569068655371666
[15/24] Train loss=0.01895030029118061
[20/24] Train loss=0.017582690343260765
Test set avg_accuracy=90.57% avg_sensitivity=77.78%, avg_specificity=94.71% avg_auc=95.29%
Fold[4] Epoch: 77 [77/100 (77%)] Train loss=0.017877 Test loss=0.633557 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.017538417130708694
[5/24] Train loss=0.011715158820152283
[10/24] Train loss=0.019988251850008965
[15/24] Train loss=0.013417990878224373
[20/24] Train loss=0.01170794665813446
Test set avg_accuracy=90.68% avg_sensitivity=77.73%, avg_specificity=94.86% avg_auc=95.32%
Fold[4] Epoch: 78 [78/100 (78%)] Train loss=0.017207 Test loss=0.677797 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.01973007246851921
[5/24] Train loss=0.01728038862347603
[10/24] Train loss=0.014435199089348316
[15/24] Train loss=0.013594883494079113
[20/24] Train loss=0.013433355838060379
Test set avg_accuracy=90.47% avg_sensitivity=77.46%, avg_specificity=94.68% avg_auc=95.28%
Fold[4] Epoch: 79 [79/100 (79%)] Train loss=0.016877 Test loss=0.675495 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.013507265597581863
[5/24] Train loss=0.013088003732264042
[10/24] Train loss=0.01293107122182846
[15/24] Train loss=0.014501906000077724
[20/24] Train loss=0.011753580532968044
Test set avg_accuracy=90.69% avg_sensitivity=77.14%, avg_specificity=95.07% avg_auc=95.33%
Fold[4] Epoch: 80 [80/100 (80%)] Train loss=0.015472 Test loss=0.690501 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.013797168619930744
[5/24] Train loss=0.014713226817548275
[10/24] Train loss=0.014797025360167027
[15/24] Train loss=0.011395836248993874
[20/24] Train loss=0.01124583464115858
Test set avg_accuracy=90.60% avg_sensitivity=77.84%, avg_specificity=94.73% avg_auc=95.32%
Fold[4] Epoch: 81 [81/100 (81%)] Train loss=0.014896 Test loss=0.701838 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.016352355480194092
[5/24] Train loss=0.009132125414907932
[10/24] Train loss=0.02183513715863228
[15/24] Train loss=0.011164502240717411
[20/24] Train loss=0.011436419561505318
Test set avg_accuracy=90.49% avg_sensitivity=77.14%, avg_specificity=94.81% avg_auc=95.34%
Fold[4] Epoch: 82 [82/100 (82%)] Train loss=0.014672 Test loss=0.689435 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.01769435405731201
[5/24] Train loss=0.011229179799556732
[10/24] Train loss=0.015515387989580631
[15/24] Train loss=0.01035215798765421
[20/24] Train loss=0.010924557223916054
Test set avg_accuracy=90.42% avg_sensitivity=77.84%, avg_specificity=94.49% avg_auc=95.30%
Fold[4] Epoch: 83 [83/100 (83%)] Train loss=0.014874 Test loss=0.712473 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.019057314842939377
[5/24] Train loss=0.009635183028876781
[10/24] Train loss=0.009989582933485508
[15/24] Train loss=0.00875183381140232
[20/24] Train loss=0.011057166382670403
Test set avg_accuracy=90.55% avg_sensitivity=77.20%, avg_specificity=94.86% avg_auc=95.28%
Fold[4] Epoch: 84 [84/100 (84%)] Train loss=0.013501 Test loss=0.715135 Current lr=[0.000122853263038123]

[0/24] Train loss=0.017651837319135666
[5/24] Train loss=0.013109231367707253
[10/24] Train loss=0.018140336498618126
[15/24] Train loss=0.01447143591940403
[20/24] Train loss=0.011545834131538868
Test set avg_accuracy=90.51% avg_sensitivity=77.09%, avg_specificity=94.85% avg_auc=95.29%
Fold[4] Epoch: 85 [85/100 (85%)] Train loss=0.013927 Test loss=0.682946 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.01647920161485672
[5/24] Train loss=0.012309557758271694
[10/24] Train loss=0.015927765518426895
[15/24] Train loss=0.015572985634207726
[20/24] Train loss=0.01397412084043026
Test set avg_accuracy=90.40% avg_sensitivity=77.20%, avg_specificity=94.68% avg_auc=95.33%
Fold[4] Epoch: 86 [86/100 (86%)] Train loss=0.014152 Test loss=0.705451 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.018077578395605087
[5/24] Train loss=0.011206481605768204
[10/24] Train loss=0.016184909269213676
[15/24] Train loss=0.009288568049669266
[20/24] Train loss=0.005536424461752176
Test set avg_accuracy=90.49% avg_sensitivity=76.82%, avg_specificity=94.92% avg_auc=95.31%
Fold[4] Epoch: 87 [87/100 (87%)] Train loss=0.012931 Test loss=0.696829 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.01677655428647995
[5/24] Train loss=0.008648330345749855
[10/24] Train loss=0.014223949983716011
[15/24] Train loss=0.012643858790397644
[20/24] Train loss=0.01141449436545372
Test set avg_accuracy=90.31% avg_sensitivity=77.09%, avg_specificity=94.59% avg_auc=95.28%
Fold[4] Epoch: 88 [88/100 (88%)] Train loss=0.013348 Test loss=0.710750 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.01584644615650177
[5/24] Train loss=0.010437042452394962
[10/24] Train loss=0.01830280013382435
[15/24] Train loss=0.021371519193053246
[20/24] Train loss=0.0112248370423913
Test set avg_accuracy=90.46% avg_sensitivity=77.94%, avg_specificity=94.50% avg_auc=95.26%
Fold[4] Epoch: 89 [89/100 (89%)] Train loss=0.013412 Test loss=0.714766 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.01193966157734394
[5/24] Train loss=0.006139242090284824
[10/24] Train loss=0.011420010589063168
[15/24] Train loss=0.009618569165468216
[20/24] Train loss=0.012424551881849766
Test set avg_accuracy=90.36% avg_sensitivity=77.36%, avg_specificity=94.57% avg_auc=95.27%
Fold[4] Epoch: 90 [90/100 (90%)] Train loss=0.012573 Test loss=0.727621 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.01442152913659811
[5/24] Train loss=0.00961267203092575
[10/24] Train loss=0.013429034501314163
[15/24] Train loss=0.008488885127007961
[20/24] Train loss=0.010878097265958786
Test set avg_accuracy=90.44% avg_sensitivity=77.30%, avg_specificity=94.69% avg_auc=95.28%
Fold[4] Epoch: 91 [91/100 (91%)] Train loss=0.012293 Test loss=0.729001 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.012426563538610935
[5/24] Train loss=0.013037239201366901
[10/24] Train loss=0.014973276294767857
[15/24] Train loss=0.00913170725107193
[20/24] Train loss=0.012610320001840591
Test set avg_accuracy=90.55% avg_sensitivity=77.41%, avg_specificity=94.80% avg_auc=95.29%
Fold[4] Epoch: 92 [92/100 (92%)] Train loss=0.013100 Test loss=0.725995 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.011872278526425362
[5/24] Train loss=0.01056674774736166
[10/24] Train loss=0.01380973495543003
[15/24] Train loss=0.011045336723327637
[20/24] Train loss=0.011998781003057957
Test set avg_accuracy=90.68% avg_sensitivity=77.52%, avg_specificity=94.93% avg_auc=95.29%
Fold[4] Epoch: 93 [93/100 (93%)] Train loss=0.012310 Test loss=0.723692 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.014301413670182228
[5/24] Train loss=0.01101686991751194
[10/24] Train loss=0.011724021285772324
[15/24] Train loss=0.010245210491120815
[20/24] Train loss=0.008709834888577461
Test set avg_accuracy=90.49% avg_sensitivity=77.36%, avg_specificity=94.74% avg_auc=95.30%
Fold[4] Epoch: 94 [94/100 (94%)] Train loss=0.012580 Test loss=0.712735 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.014028496108949184
[5/24] Train loss=0.008054390549659729
[10/24] Train loss=0.014492721296846867
[15/24] Train loss=0.00809253565967083
[20/24] Train loss=0.008268146775662899
Test set avg_accuracy=90.42% avg_sensitivity=77.14%, avg_specificity=94.71% avg_auc=95.30%
Fold[4] Epoch: 95 [95/100 (95%)] Train loss=0.011842 Test loss=0.724784 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.01582322269678116
[5/24] Train loss=0.008172113448381424
[10/24] Train loss=0.017306867986917496
[15/24] Train loss=0.010852385312318802
[20/24] Train loss=0.006783402990549803
Test set avg_accuracy=90.42% avg_sensitivity=77.14%, avg_specificity=94.71% avg_auc=95.30%
Fold[4] Epoch: 96 [96/100 (96%)] Train loss=0.013003 Test loss=0.724897 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.016596440225839615
[5/24] Train loss=0.007017261348664761
[10/24] Train loss=0.01399196870625019
[15/24] Train loss=0.008161637000739574
[20/24] Train loss=0.0129318218678236
Test set avg_accuracy=90.47% avg_sensitivity=77.36%, avg_specificity=94.71% avg_auc=95.30%
Fold[4] Epoch: 97 [97/100 (97%)] Train loss=0.012550 Test loss=0.725322 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.013006100431084633
[5/24] Train loss=0.01077181939035654
[10/24] Train loss=0.011393927037715912
[15/24] Train loss=0.013125063851475716
[20/24] Train loss=0.011119918897747993
Test set avg_accuracy=90.43% avg_sensitivity=77.20%, avg_specificity=94.71% avg_auc=95.30%
Fold[4] Epoch: 98 [98/100 (98%)] Train loss=0.012018 Test loss=0.725087 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.01254751905798912
[5/24] Train loss=0.011186127550899982
[10/24] Train loss=0.011422056704759598
[15/24] Train loss=0.011200753971934319
[20/24] Train loss=0.008330250158905983
Test set avg_accuracy=90.43% avg_sensitivity=77.20%, avg_specificity=94.71% avg_auc=95.30%
Fold[4] Epoch: 99 [99/100 (99%)] Train loss=0.012269 Test loss=0.725134 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.009409744292497635
[5/24] Train loss=0.008847532793879509
[10/24] Train loss=0.012248480692505836
[15/24] Train loss=0.01173742301762104
[20/24] Train loss=0.011020722799003124
Test set avg_accuracy=90.43% avg_sensitivity=77.20%, avg_specificity=94.71% avg_auc=95.30%
Fold[4] Epoch: 100 [100/100 (100%)] Train loss=0.013227 Test loss=0.725084 Current lr=[4.874217159761039e-09]

Fold[4] Result: acc=91.46% sen=75.60%, spe=96.59%, auc=95.68%!
Fold[4] Avg_overlap=0.75%(Â±0.20698135385146518)
[0/24] Train loss=1.4474828243255615
[5/24] Train loss=1.3437435626983643
[10/24] Train loss=1.2850583791732788
[15/24] Train loss=1.103493094444275
[20/24] Train loss=1.047214150428772
Test set avg_accuracy=78.36% avg_sensitivity=38.11%, avg_specificity=90.45% avg_auc=79.13%
Best model saved!! Metric=79.12770285773625!!
Fold[5] Epoch: 1 [1/100 (1%)] Train loss=1.232589 Test loss=0.506056 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=1.0211516618728638
[5/24] Train loss=0.9462271928787231
[10/24] Train loss=1.0099376440048218
[15/24] Train loss=0.8229071497917175
[20/24] Train loss=0.9135486483573914
Test set avg_accuracy=81.51% avg_sensitivity=74.18%, avg_specificity=83.71% avg_auc=86.59%
Best model saved!! Metric=86.5940986007389!!
Fold[5] Epoch: 2 [2/100 (2%)] Train loss=0.958774 Test loss=0.516057 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8436237573623657
[5/24] Train loss=0.8372430205345154
[10/24] Train loss=0.9592475295066833
[15/24] Train loss=0.7601245045661926
[20/24] Train loss=0.8418171405792236
Test set avg_accuracy=83.09% avg_sensitivity=81.68%, avg_specificity=83.51% avg_auc=89.47%
Best model saved!! Metric=89.46913424942666!!
Fold[5] Epoch: 3 [3/100 (3%)] Train loss=0.871939 Test loss=0.462625 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.7669058442115784
[5/24] Train loss=0.7904138565063477
[10/24] Train loss=0.8902626633644104
[15/24] Train loss=0.7073744535446167
[20/24] Train loss=0.8047066330909729
Test set avg_accuracy=82.10% avg_sensitivity=89.18%, avg_specificity=79.97% avg_auc=91.37%
Best model saved!! Metric=91.36924271306461!!
Fold[5] Epoch: 4 [4/100 (4%)] Train loss=0.812065 Test loss=0.491484 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.7291372418403625
[5/24] Train loss=0.7441437244415283
[10/24] Train loss=0.833915650844574
[15/24] Train loss=0.6837379932403564
[20/24] Train loss=0.7457349300384521
Test set avg_accuracy=82.25% avg_sensitivity=89.63%, avg_specificity=80.04% avg_auc=92.53%
Best model saved!! Metric=92.53146151793352!!
Fold[5] Epoch: 5 [5/100 (5%)] Train loss=0.773718 Test loss=0.468808 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.705691933631897
[5/24] Train loss=0.730577290058136
[10/24] Train loss=0.8322765827178955
[15/24] Train loss=0.6314476728439331
[20/24] Train loss=0.7092214822769165
Test set avg_accuracy=82.50% avg_sensitivity=91.66%, avg_specificity=79.75% avg_auc=93.13%
Best model saved!! Metric=93.13245448898584!!
Fold[5] Epoch: 6 [6/100 (6%)] Train loss=0.748610 Test loss=0.474948 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.7033138871192932
[5/24] Train loss=0.6846297383308411
[10/24] Train loss=0.8154112696647644
[15/24] Train loss=0.6171936392784119
[20/24] Train loss=0.696414589881897
Test set avg_accuracy=85.39% avg_sensitivity=90.53%, avg_specificity=83.85% avg_auc=93.97%
Best model saved!! Metric=93.97471319747825!!
Fold[5] Epoch: 7 [7/100 (7%)] Train loss=0.719054 Test loss=0.391882 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.680553674697876
[5/24] Train loss=0.6638791561126709
[10/24] Train loss=0.8260806202888489
[15/24] Train loss=0.571948766708374
[20/24] Train loss=0.6922450661659241
Test set avg_accuracy=86.38% avg_sensitivity=90.19%, avg_specificity=85.24% avg_auc=94.15%
Best model saved!! Metric=94.15301390327457!!
Fold[5] Epoch: 8 [8/100 (8%)] Train loss=0.700541 Test loss=0.383888 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.6466355919837952
[5/24] Train loss=0.6390668749809265
[10/24] Train loss=0.7882252931594849
[15/24] Train loss=0.5449680685997009
[20/24] Train loss=0.6573903560638428
Test set avg_accuracy=87.06% avg_sensitivity=90.02%, avg_specificity=86.17% avg_auc=94.55%
Best model saved!! Metric=94.546399797504!!
Fold[5] Epoch: 9 [9/100 (9%)] Train loss=0.678041 Test loss=0.362497 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6523386836051941
[5/24] Train loss=0.6123579144477844
[10/24] Train loss=0.7815653085708618
[15/24] Train loss=0.5707754492759705
[20/24] Train loss=0.6401751637458801
Test set avg_accuracy=87.94% avg_sensitivity=89.29%, avg_specificity=87.54% avg_auc=94.54%
Fold[5] Epoch: 10 [10/100 (10%)] Train loss=0.663452 Test loss=0.355976 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.6107163429260254
[5/24] Train loss=0.6415042281150818
[10/24] Train loss=0.7649284601211548
[15/24] Train loss=0.5393412113189697
[20/24] Train loss=0.5922863483428955
Test set avg_accuracy=89.56% avg_sensitivity=85.91%, avg_specificity=90.65% avg_auc=95.00%
Best model saved!! Metric=94.99939583348446!!
Fold[5] Epoch: 11 [11/100 (11%)] Train loss=0.651003 Test loss=0.285125 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.6264522671699524
[5/24] Train loss=0.5989395976066589
[10/24] Train loss=0.7675153613090515
[15/24] Train loss=0.5299848318099976
[20/24] Train loss=0.6143490076065063
Test set avg_accuracy=88.28% avg_sensitivity=91.04%, avg_specificity=87.45% avg_auc=95.24%
Best model saved!! Metric=95.23651926021766!!
Fold[5] Epoch: 12 [12/100 (12%)] Train loss=0.640311 Test loss=0.321885 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.6195580363273621
[5/24] Train loss=0.5934809446334839
[10/24] Train loss=0.7324116826057434
[15/24] Train loss=0.5502299070358276
[20/24] Train loss=0.575840413570404
Test set avg_accuracy=88.97% avg_sensitivity=87.94%, avg_specificity=89.28% avg_auc=94.99%
Fold[5] Epoch: 13 [13/100 (13%)] Train loss=0.633324 Test loss=0.298656 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.5884628891944885
[5/24] Train loss=0.6078332662582397
[10/24] Train loss=0.740576982498169
[15/24] Train loss=0.534734845161438
[20/24] Train loss=0.5585609674453735
Test set avg_accuracy=90.12% avg_sensitivity=85.06%, avg_specificity=91.64% avg_auc=95.33%
Best model saved!! Metric=95.32552644569509!!
Fold[5] Epoch: 14 [14/100 (14%)] Train loss=0.623351 Test loss=0.270691 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.6030716300010681
[5/24] Train loss=0.5971559286117554
[10/24] Train loss=0.7340914607048035
[15/24] Train loss=0.5101858973503113
[20/24] Train loss=0.5536832213401794
Test set avg_accuracy=90.27% avg_sensitivity=77.17%, avg_specificity=94.21% avg_auc=94.51%
Fold[5] Epoch: 15 [15/100 (15%)] Train loss=0.607402 Test loss=0.260411 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.6175366640090942
[5/24] Train loss=0.5957483053207397
[10/24] Train loss=0.7104552984237671
[15/24] Train loss=0.5097839832305908
[20/24] Train loss=0.5809502005577087
Test set avg_accuracy=90.56% avg_sensitivity=78.97%, avg_specificity=94.04% avg_auc=95.25%
Fold[5] Epoch: 16 [16/100 (16%)] Train loss=0.612787 Test loss=0.243509 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5882381796836853
[5/24] Train loss=0.588387131690979
[10/24] Train loss=0.6742249131202698
[15/24] Train loss=0.48779430985450745
[20/24] Train loss=0.5434063076972961
Test set avg_accuracy=90.35% avg_sensitivity=76.72%, avg_specificity=94.45% avg_auc=94.95%
Fold[5] Epoch: 17 [17/100 (17%)] Train loss=0.592515 Test loss=0.242745 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5954366326332092
[5/24] Train loss=0.5563380718231201
[10/24] Train loss=0.6994423866271973
[15/24] Train loss=0.48836004734039307
[20/24] Train loss=0.5403730273246765
Test set avg_accuracy=90.59% avg_sensitivity=80.61%, avg_specificity=93.58% avg_auc=95.23%
Fold[5] Epoch: 18 [18/100 (18%)] Train loss=0.586106 Test loss=0.242903 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.6061827540397644
[5/24] Train loss=0.5609199404716492
[10/24] Train loss=0.7179262042045593
[15/24] Train loss=0.49513736367225647
[20/24] Train loss=0.5267714262008667
Test set avg_accuracy=90.46% avg_sensitivity=77.96%, avg_specificity=94.21% avg_auc=95.04%
Fold[5] Epoch: 19 [19/100 (19%)] Train loss=0.594331 Test loss=0.243838 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5788010954856873
[5/24] Train loss=0.5482232570648193
[10/24] Train loss=0.6857884526252747
[15/24] Train loss=0.47057220339775085
[20/24] Train loss=0.5101763010025024
Test set avg_accuracy=90.29% avg_sensitivity=77.23%, avg_specificity=94.21% avg_auc=94.75%
Fold[5] Epoch: 20 [20/100 (20%)] Train loss=0.568066 Test loss=0.247482 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.6084521412849426
[5/24] Train loss=0.5294844508171082
[10/24] Train loss=0.7073144912719727
[15/24] Train loss=0.5162292122840881
[20/24] Train loss=0.5540837645530701
Test set avg_accuracy=90.85% avg_sensitivity=83.99%, avg_specificity=92.91% avg_auc=95.28%
Fold[5] Epoch: 21 [21/100 (21%)] Train loss=0.577660 Test loss=0.251581 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.6107887625694275
[5/24] Train loss=0.5221671462059021
[10/24] Train loss=0.6686437129974365
[15/24] Train loss=0.4530656337738037
[20/24] Train loss=0.48735037446022034
Test set avg_accuracy=89.01% avg_sensitivity=84.95%, avg_specificity=90.23% avg_auc=94.86%
Fold[5] Epoch: 22 [22/100 (22%)] Train loss=0.564719 Test loss=0.293778 Current lr=[0.000842324016282456]

[0/24] Train loss=0.562109649181366
[5/24] Train loss=0.5349546074867249
[10/24] Train loss=0.667131781578064
[15/24] Train loss=0.4279443323612213
[20/24] Train loss=0.46357089281082153
Test set avg_accuracy=89.91% avg_sensitivity=86.08%, avg_specificity=91.06% avg_auc=95.60%
Best model saved!! Metric=95.59784042444748!!
Fold[5] Epoch: 23 [23/100 (23%)] Train loss=0.547657 Test loss=0.263177 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5747679471969604
[5/24] Train loss=0.49050062894821167
[10/24] Train loss=0.6732028722763062
[15/24] Train loss=0.44027063250541687
[20/24] Train loss=0.4558861553668976
Test set avg_accuracy=90.82% avg_sensitivity=82.30%, avg_specificity=93.38% avg_auc=95.49%
Fold[5] Epoch: 24 [24/100 (24%)] Train loss=0.535590 Test loss=0.240408 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.5108885765075684
[5/24] Train loss=0.49817588925361633
[10/24] Train loss=0.5500181913375854
[15/24] Train loss=0.4193582236766815
[20/24] Train loss=0.4779475927352905
Test set avg_accuracy=90.61% avg_sensitivity=73.28%, avg_specificity=95.82% avg_auc=95.42%
Fold[5] Epoch: 25 [25/100 (25%)] Train loss=0.509372 Test loss=0.232037 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.5196377635002136
[5/24] Train loss=0.49229153990745544
[10/24] Train loss=0.6230363249778748
[15/24] Train loss=0.4077373147010803
[20/24] Train loss=0.47549545764923096
Test set avg_accuracy=89.64% avg_sensitivity=66.80%, avg_specificity=96.50% avg_auc=95.54%
Fold[5] Epoch: 26 [26/100 (26%)] Train loss=0.516094 Test loss=0.241249 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.5252315998077393
[5/24] Train loss=0.4682924449443817
[10/24] Train loss=0.5277963280677795
[15/24] Train loss=0.40746229887008667
[20/24] Train loss=0.4453650414943695
Test set avg_accuracy=90.43% avg_sensitivity=72.32%, avg_specificity=95.87% avg_auc=95.05%
Fold[5] Epoch: 27 [27/100 (27%)] Train loss=0.493643 Test loss=0.249080 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.5402280688285828
[5/24] Train loss=0.45801258087158203
[10/24] Train loss=0.5493306517601013
[15/24] Train loss=0.39541563391685486
[20/24] Train loss=0.4431625008583069
Test set avg_accuracy=89.15% avg_sensitivity=63.42%, avg_specificity=96.88% avg_auc=94.94%
Fold[5] Epoch: 28 [28/100 (28%)] Train loss=0.482786 Test loss=0.270986 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.4941595196723938
[5/24] Train loss=0.4347124695777893
[10/24] Train loss=0.4944846034049988
[15/24] Train loss=0.4053783416748047
[20/24] Train loss=0.4145582318305969
Test set avg_accuracy=89.64% avg_sensitivity=65.78%, avg_specificity=96.80% avg_auc=94.80%
Fold[5] Epoch: 29 [29/100 (29%)] Train loss=0.474790 Test loss=0.267478 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.5056113004684448
[5/24] Train loss=0.41281306743621826
[10/24] Train loss=0.5375950336456299
[15/24] Train loss=0.3761412799358368
[20/24] Train loss=0.4292024075984955
Test set avg_accuracy=89.97% avg_sensitivity=74.86%, avg_specificity=94.51% avg_auc=94.68%
Fold[5] Epoch: 30 [30/100 (30%)] Train loss=0.444811 Test loss=0.257914 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.445696085691452
[5/24] Train loss=0.4140585660934448
[10/24] Train loss=0.4381507337093353
[15/24] Train loss=0.35907498002052307
[20/24] Train loss=0.3884996175765991
Test set avg_accuracy=90.34% avg_sensitivity=72.15%, avg_specificity=95.80% avg_auc=94.89%
Fold[5] Epoch: 31 [31/100 (31%)] Train loss=0.428442 Test loss=0.260499 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.4577103555202484
[5/24] Train loss=0.3779151439666748
[10/24] Train loss=0.4627684950828552
[15/24] Train loss=0.3427777886390686
[20/24] Train loss=0.40510305762290955
Test set avg_accuracy=90.00% avg_sensitivity=71.14%, avg_specificity=95.67% avg_auc=94.83%
Fold[5] Epoch: 32 [32/100 (32%)] Train loss=0.405959 Test loss=0.252372 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.42844194173812866
[5/24] Train loss=0.36317622661590576
[10/24] Train loss=0.4156232476234436
[15/24] Train loss=0.30002105236053467
[20/24] Train loss=0.3405943810939789
Test set avg_accuracy=89.67% avg_sensitivity=79.14%, avg_specificity=92.84% avg_auc=94.84%
Fold[5] Epoch: 33 [33/100 (33%)] Train loss=0.385700 Test loss=0.259078 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.42586851119995117
[5/24] Train loss=0.3360580503940582
[10/24] Train loss=0.40586867928504944
[15/24] Train loss=0.3566622734069824
[20/24] Train loss=0.3917731046676636
Test set avg_accuracy=89.58% avg_sensitivity=81.12%, avg_specificity=92.13% avg_auc=94.74%
Fold[5] Epoch: 34 [34/100 (34%)] Train loss=0.391430 Test loss=0.269523 Current lr=[0.000991797016730875]

[0/24] Train loss=0.3819694221019745
[5/24] Train loss=0.3494597375392914
[10/24] Train loss=0.39954060316085815
[15/24] Train loss=0.33396467566490173
[20/24] Train loss=0.3201046884059906
Test set avg_accuracy=90.16% avg_sensitivity=78.30%, avg_specificity=93.72% avg_auc=95.03%
Fold[5] Epoch: 35 [35/100 (35%)] Train loss=0.379052 Test loss=0.252130 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.41476187109947205
[5/24] Train loss=0.30866897106170654
[10/24] Train loss=0.3950698971748352
[15/24] Train loss=0.28798338770866394
[20/24] Train loss=0.33370092511177063
Test set avg_accuracy=89.74% avg_sensitivity=73.17%, avg_specificity=94.72% avg_auc=94.74%
Fold[5] Epoch: 36 [36/100 (36%)] Train loss=0.356763 Test loss=0.271492 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.39500218629837036
[5/24] Train loss=0.2895709276199341
[10/24] Train loss=0.37407368421554565
[15/24] Train loss=0.25071895122528076
[20/24] Train loss=0.29689452052116394
Test set avg_accuracy=90.89% avg_sensitivity=74.80%, avg_specificity=95.72% avg_auc=95.38%
Fold[5] Epoch: 37 [37/100 (37%)] Train loss=0.336344 Test loss=0.274858 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.3774496912956238
[5/24] Train loss=0.31422972679138184
[10/24] Train loss=0.33114728331565857
[15/24] Train loss=0.3069908320903778
[20/24] Train loss=0.3068941533565521
Test set avg_accuracy=90.03% avg_sensitivity=68.71%, avg_specificity=96.43% avg_auc=94.93%
Fold[5] Epoch: 38 [38/100 (38%)] Train loss=0.321119 Test loss=0.295570 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.3271690607070923
[5/24] Train loss=0.26755109429359436
[10/24] Train loss=0.28430095314979553
[15/24] Train loss=0.2753843367099762
[20/24] Train loss=0.237130269408226
Test set avg_accuracy=90.26% avg_sensitivity=78.24%, avg_specificity=93.87% avg_auc=94.70%
Fold[5] Epoch: 39 [39/100 (39%)] Train loss=0.301221 Test loss=0.276380 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.28394126892089844
[5/24] Train loss=0.26141873002052307
[10/24] Train loss=0.2647757828235626
[15/24] Train loss=0.22609969973564148
[20/24] Train loss=0.23279818892478943
Test set avg_accuracy=90.38% avg_sensitivity=82.92%, avg_specificity=92.62% avg_auc=95.08%
Fold[5] Epoch: 40 [40/100 (40%)] Train loss=0.283345 Test loss=0.268019 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.340716689825058
[5/24] Train loss=0.2532030940055847
[10/24] Train loss=0.2952571511268616
[15/24] Train loss=0.22116421163082123
[20/24] Train loss=0.23147495090961456
Test set avg_accuracy=90.39% avg_sensitivity=82.64%, avg_specificity=92.72% avg_auc=95.28%
Fold[5] Epoch: 41 [41/100 (41%)] Train loss=0.276438 Test loss=0.290784 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.2642025053501129
[5/24] Train loss=0.25684982538223267
[10/24] Train loss=0.24795009195804596
[15/24] Train loss=0.2266562581062317
[20/24] Train loss=0.23897963762283325
Test set avg_accuracy=90.26% avg_sensitivity=78.02%, avg_specificity=93.94% avg_auc=95.26%
Fold[5] Epoch: 42 [42/100 (42%)] Train loss=0.257536 Test loss=0.280142 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.27766939997673035
[5/24] Train loss=0.17572470009326935
[10/24] Train loss=0.25661855936050415
[15/24] Train loss=0.1919793039560318
[20/24] Train loss=0.1882622241973877
Test set avg_accuracy=90.43% avg_sensitivity=81.29%, avg_specificity=93.18% avg_auc=95.20%
Fold[5] Epoch: 43 [43/100 (43%)] Train loss=0.228628 Test loss=0.277770 Current lr=[0.000916771143003274]

[0/24] Train loss=0.25685691833496094
[5/24] Train loss=0.18727050721645355
[10/24] Train loss=0.24482683837413788
[15/24] Train loss=0.16327232122421265
[20/24] Train loss=0.19419439136981964
Test set avg_accuracy=90.27% avg_sensitivity=76.32%, avg_specificity=94.46% avg_auc=94.70%
Fold[5] Epoch: 44 [44/100 (44%)] Train loss=0.218585 Test loss=0.303504 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.20954743027687073
[5/24] Train loss=0.1846855729818344
[10/24] Train loss=0.2333887666463852
[15/24] Train loss=0.15735802054405212
[20/24] Train loss=0.1681627780199051
Test set avg_accuracy=89.64% avg_sensitivity=76.72%, avg_specificity=93.52% avg_auc=94.57%
Fold[5] Epoch: 45 [45/100 (45%)] Train loss=0.200305 Test loss=0.318541 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.21693119406700134
[5/24] Train loss=0.17552797496318817
[10/24] Train loss=0.19876345992088318
[15/24] Train loss=0.16674590110778809
[20/24] Train loss=0.15444569289684296
Test set avg_accuracy=89.86% avg_sensitivity=76.72%, avg_specificity=93.80% avg_auc=94.60%
Fold[5] Epoch: 46 [46/100 (46%)] Train loss=0.186095 Test loss=0.366161 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.1896749883890152
[5/24] Train loss=0.1642734557390213
[10/24] Train loss=0.19478920102119446
[15/24] Train loss=0.14170491695404053
[20/24] Train loss=0.15137842297554016
Test set avg_accuracy=89.90% avg_sensitivity=75.03%, avg_specificity=94.36% avg_auc=94.64%
Fold[5] Epoch: 47 [47/100 (47%)] Train loss=0.178388 Test loss=0.376911 Current lr=[0.000860751215339601]

[0/24] Train loss=0.1722167581319809
[5/24] Train loss=0.1498887836933136
[10/24] Train loss=0.16448965668678284
[15/24] Train loss=0.14635030925273895
[20/24] Train loss=0.15209123492240906
Test set avg_accuracy=89.90% avg_sensitivity=77.11%, avg_specificity=93.74% avg_auc=94.82%
Fold[5] Epoch: 48 [48/100 (48%)] Train loss=0.160433 Test loss=0.408974 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.18628668785095215
[5/24] Train loss=0.13353238999843597
[10/24] Train loss=0.14224447309970856
[15/24] Train loss=0.11883791536092758
[20/24] Train loss=0.13743652403354645
Test set avg_accuracy=89.39% avg_sensitivity=76.27%, avg_specificity=93.33% avg_auc=94.39%
Fold[5] Epoch: 49 [49/100 (49%)] Train loss=0.146276 Test loss=0.406637 Current lr=[0.000828265354963756]

[0/24] Train loss=0.14588291943073273
[5/24] Train loss=0.1121356412768364
[10/24] Train loss=0.13667479157447815
[15/24] Train loss=0.11100494861602783
[20/24] Train loss=0.12787559628486633
Test set avg_accuracy=89.35% avg_sensitivity=72.44%, avg_specificity=94.43% avg_auc=94.15%
Fold[5] Epoch: 50 [50/100 (50%)] Train loss=0.134589 Test loss=0.411604 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.16021287441253662
[5/24] Train loss=0.11598765850067139
[10/24] Train loss=0.1533154845237732
[15/24] Train loss=0.12235431373119354
[20/24] Train loss=0.1001584455370903
Test set avg_accuracy=89.08% avg_sensitivity=73.06%, avg_specificity=93.89% avg_auc=94.24%
Fold[5] Epoch: 51 [51/100 (51%)] Train loss=0.127746 Test loss=0.397246 Current lr=[0.00079313651106947]

[0/24] Train loss=0.11052095890045166
[5/24] Train loss=0.09034325182437897
[10/24] Train loss=0.1249605193734169
[15/24] Train loss=0.08278316259384155
[20/24] Train loss=0.10039529204368591
Test set avg_accuracy=89.69% avg_sensitivity=74.52%, avg_specificity=94.24% avg_auc=94.58%
Fold[5] Epoch: 52 [52/100 (52%)] Train loss=0.112198 Test loss=0.373908 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.11994063854217529
[5/24] Train loss=0.09966928511857986
[10/24] Train loss=0.09915568679571152
[15/24] Train loss=0.0978742316365242
[20/24] Train loss=0.08215203881263733
Test set avg_accuracy=89.04% avg_sensitivity=66.46%, avg_specificity=95.82% avg_auc=94.11%
Fold[5] Epoch: 53 [53/100 (53%)] Train loss=0.102220 Test loss=0.463496 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.14615046977996826
[5/24] Train loss=0.10481268912553787
[10/24] Train loss=0.10085806250572205
[15/24] Train loss=0.09683097153902054
[20/24] Train loss=0.09605922549962997
Test set avg_accuracy=88.98% avg_sensitivity=69.62%, avg_specificity=94.80% avg_auc=94.23%
Fold[5] Epoch: 54 [54/100 (54%)] Train loss=0.105459 Test loss=0.438040 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.10201818495988846
[5/24] Train loss=0.07916620373725891
[10/24] Train loss=0.09558828920125961
[15/24] Train loss=0.10233322530984879
[20/24] Train loss=0.08516953140497208
Test set avg_accuracy=89.65% avg_sensitivity=68.32%, avg_specificity=96.05% avg_auc=94.67%
Fold[5] Epoch: 55 [55/100 (55%)] Train loss=0.097363 Test loss=0.420144 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.08383192867040634
[5/24] Train loss=0.11638373136520386
[10/24] Train loss=0.09219556301832199
[15/24] Train loss=0.06955880671739578
[20/24] Train loss=0.06404231488704681
Test set avg_accuracy=89.44% avg_sensitivity=73.79%, avg_specificity=94.14% avg_auc=94.77%
Fold[5] Epoch: 56 [56/100 (56%)] Train loss=0.084741 Test loss=0.471212 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.08811180293560028
[5/24] Train loss=0.07144106179475784
[10/24] Train loss=0.08121798932552338
[15/24] Train loss=0.04972095042467117
[20/24] Train loss=0.07564087957143784
Test set avg_accuracy=89.97% avg_sensitivity=74.80%, avg_specificity=94.53% avg_auc=94.72%
Fold[5] Epoch: 57 [57/100 (57%)] Train loss=0.074953 Test loss=0.474489 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.08359993994235992
[5/24] Train loss=0.049442537128925323
[10/24] Train loss=0.06479493528604507
[15/24] Train loss=0.05457036942243576
[20/24] Train loss=0.05608322098851204
Test set avg_accuracy=89.47% avg_sensitivity=75.14%, avg_specificity=93.77% avg_auc=94.50%
Fold[5] Epoch: 58 [58/100 (58%)] Train loss=0.063104 Test loss=0.549854 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.06578996032476425
[5/24] Train loss=0.04943932220339775
[10/24] Train loss=0.06945933401584625
[15/24] Train loss=0.04196338728070259
[20/24] Train loss=0.040375225245952606
Test set avg_accuracy=89.28% avg_sensitivity=76.21%, avg_specificity=93.21% avg_auc=94.04%
Fold[5] Epoch: 59 [59/100 (59%)] Train loss=0.055309 Test loss=0.564865 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.06355263292789459
[5/24] Train loss=0.041593801230192184
[10/24] Train loss=0.055127475410699844
[15/24] Train loss=0.047675181180238724
[20/24] Train loss=0.035445790737867355
Test set avg_accuracy=89.35% avg_sensitivity=73.51%, avg_specificity=94.11% avg_auc=94.21%
Fold[5] Epoch: 60 [60/100 (60%)] Train loss=0.049176 Test loss=0.552533 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.042794305831193924
[5/24] Train loss=0.05212870612740517
[10/24] Train loss=0.04162419214844704
[15/24] Train loss=0.045993365347385406
[20/24] Train loss=0.052150435745716095
Test set avg_accuracy=89.71% avg_sensitivity=74.41%, avg_specificity=94.31% avg_auc=94.51%
Fold[5] Epoch: 61 [61/100 (61%)] Train loss=0.049276 Test loss=0.551667 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.05558343604207039
[5/24] Train loss=0.05068701133131981
[10/24] Train loss=0.039199139922857285
[15/24] Train loss=0.0392402745783329
[20/24] Train loss=0.042098771780729294
Test set avg_accuracy=89.51% avg_sensitivity=76.16%, avg_specificity=93.52% avg_auc=94.40%
Fold[5] Epoch: 62 [62/100 (62%)] Train loss=0.043175 Test loss=0.554018 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.03446387127041817
[5/24] Train loss=0.030453337356448174
[10/24] Train loss=0.04349898546934128
[15/24] Train loss=0.029569024220108986
[20/24] Train loss=0.033901508897542953
Test set avg_accuracy=89.93% avg_sensitivity=74.69%, avg_specificity=94.51% avg_auc=94.64%
Fold[5] Epoch: 63 [63/100 (63%)] Train loss=0.041056 Test loss=0.519766 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.04220597818493843
[5/24] Train loss=0.025215284898877144
[10/24] Train loss=0.029039917513728142
[15/24] Train loss=0.027997156605124474
[20/24] Train loss=0.028042327612638474
Test set avg_accuracy=89.65% avg_sensitivity=76.04%, avg_specificity=93.74% avg_auc=94.46%
Fold[5] Epoch: 64 [64/100 (64%)] Train loss=0.035648 Test loss=0.512874 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.034394651651382446
[5/24] Train loss=0.030514035373926163
[10/24] Train loss=0.031479474157094955
[15/24] Train loss=0.03345384821295738
[20/24] Train loss=0.027650106698274612
Test set avg_accuracy=89.88% avg_sensitivity=76.38%, avg_specificity=93.94% avg_auc=94.45%
Fold[5] Epoch: 65 [65/100 (65%)] Train loss=0.033867 Test loss=0.514732 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.028909290209412575
[5/24] Train loss=0.022204356268048286
[10/24] Train loss=0.031305693089962006
[15/24] Train loss=0.028255758807063103
[20/24] Train loss=0.02457304857671261
Test set avg_accuracy=89.84% avg_sensitivity=78.02%, avg_specificity=93.40% avg_auc=94.38%
Fold[5] Epoch: 66 [66/100 (66%)] Train loss=0.031746 Test loss=0.561767 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.032978758215904236
[5/24] Train loss=0.02598707377910614
[10/24] Train loss=0.024785103276371956
[15/24] Train loss=0.0236975010484457
[20/24] Train loss=0.021108269691467285
Test set avg_accuracy=89.53% avg_sensitivity=77.17%, avg_specificity=93.24% avg_auc=94.55%
Fold[5] Epoch: 67 [67/100 (67%)] Train loss=0.028690 Test loss=0.566868 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.028800485655665398
[5/24] Train loss=0.02613581344485283
[10/24] Train loss=0.061286747455596924
[15/24] Train loss=0.024405958130955696
[20/24] Train loss=0.025191687047481537
Test set avg_accuracy=89.60% avg_sensitivity=76.21%, avg_specificity=93.62% avg_auc=94.53%
Fold[5] Epoch: 68 [68/100 (68%)] Train loss=0.028416 Test loss=0.548159 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.027410639449954033
[5/24] Train loss=0.026350976899266243
[10/24] Train loss=0.031334735453128815
[15/24] Train loss=0.02504442259669304
[20/24] Train loss=0.02341662161052227
Test set avg_accuracy=89.91% avg_sensitivity=77.11%, avg_specificity=93.75% avg_auc=94.68%
Fold[5] Epoch: 69 [69/100 (69%)] Train loss=0.026484 Test loss=0.565386 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.028528960421681404
[5/24] Train loss=0.02103838510811329
[10/24] Train loss=0.022518448531627655
[15/24] Train loss=0.014378512278199196
[20/24] Train loss=0.021609270945191383
Test set avg_accuracy=89.61% avg_sensitivity=76.55%, avg_specificity=93.53% avg_auc=94.55%
Fold[5] Epoch: 70 [70/100 (70%)] Train loss=0.022295 Test loss=0.583774 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.01824701391160488
[5/24] Train loss=0.03716013953089714
[10/24] Train loss=0.01747829280793667
[15/24] Train loss=0.021054254844784737
[20/24] Train loss=0.023695597425103188
Test set avg_accuracy=89.62% avg_sensitivity=77.34%, avg_specificity=93.31% avg_auc=94.66%
Fold[5] Epoch: 71 [71/100 (71%)] Train loss=0.023197 Test loss=0.580022 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.018505673855543137
[5/24] Train loss=0.01773645170032978
[10/24] Train loss=0.02826884388923645
[15/24] Train loss=0.022368689998984337
[20/24] Train loss=0.017416855320334435
Test set avg_accuracy=89.66% avg_sensitivity=75.65%, avg_specificity=93.87% avg_auc=94.75%
Fold[5] Epoch: 72 [72/100 (72%)] Train loss=0.019838 Test loss=0.577885 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.02903451956808567
[5/24] Train loss=0.020236585289239883
[10/24] Train loss=0.017019253224134445
[15/24] Train loss=0.01434063259512186
[20/24] Train loss=0.01823723502457142
Test set avg_accuracy=89.79% avg_sensitivity=76.32%, avg_specificity=93.84% avg_auc=94.76%
Fold[5] Epoch: 73 [73/100 (73%)] Train loss=0.019807 Test loss=0.619540 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.018892792984843254
[5/24] Train loss=0.015534091740846634
[10/24] Train loss=0.018887188285589218
[15/24] Train loss=0.0209646038711071
[20/24] Train loss=0.01891787350177765
Test set avg_accuracy=89.78% avg_sensitivity=76.44%, avg_specificity=93.79% avg_auc=94.73%
Fold[5] Epoch: 74 [74/100 (74%)] Train loss=0.018500 Test loss=0.589254 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.01917881891131401
[5/24] Train loss=0.012589935213327408
[10/24] Train loss=0.017995286732912064
[15/24] Train loss=0.016034787520766258
[20/24] Train loss=0.01435947511345148
Test set avg_accuracy=89.97% avg_sensitivity=75.82%, avg_specificity=94.23% avg_auc=94.63%
Fold[5] Epoch: 75 [75/100 (75%)] Train loss=0.017525 Test loss=0.642630 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.019068773835897446
[5/24] Train loss=0.021986020728945732
[10/24] Train loss=0.014163886196911335
[15/24] Train loss=0.01130032166838646
[20/24] Train loss=0.01570816896855831
Test set avg_accuracy=89.97% avg_sensitivity=76.38%, avg_specificity=94.06% avg_auc=94.61%
Fold[5] Epoch: 76 [76/100 (76%)] Train loss=0.015715 Test loss=0.624427 Current lr=[0.000262245679641298]

[0/24] Train loss=0.015668487176299095
[5/24] Train loss=0.013758811168372631
[10/24] Train loss=0.016402196139097214
[15/24] Train loss=0.011050594039261341
[20/24] Train loss=0.01661616563796997
Test set avg_accuracy=89.99% avg_sensitivity=75.99%, avg_specificity=94.19% avg_auc=94.71%
Fold[5] Epoch: 77 [77/100 (77%)] Train loss=0.016039 Test loss=0.623559 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.013560338877141476
[5/24] Train loss=0.019008543342351913
[10/24] Train loss=0.014478251338005066
[15/24] Train loss=0.010540398769080639
[20/24] Train loss=0.01566743105649948
Test set avg_accuracy=89.87% avg_sensitivity=76.16%, avg_specificity=93.99% avg_auc=94.75%
Fold[5] Epoch: 78 [78/100 (78%)] Train loss=0.015147 Test loss=0.643795 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.014456085860729218
[5/24] Train loss=0.012097143568098545
[10/24] Train loss=0.015816116705536842
[15/24] Train loss=0.017036177217960358
[20/24] Train loss=0.018224062398076057
Test set avg_accuracy=90.01% avg_sensitivity=76.27%, avg_specificity=94.14% avg_auc=94.67%
Fold[5] Epoch: 79 [79/100 (79%)] Train loss=0.015803 Test loss=0.620426 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.01358597632497549
[5/24] Train loss=0.016546184197068214
[10/24] Train loss=0.013261206448078156
[15/24] Train loss=0.009776918217539787
[20/24] Train loss=0.011504118330776691
Test set avg_accuracy=89.77% avg_sensitivity=74.92%, avg_specificity=94.23% avg_auc=94.67%
Fold[5] Epoch: 80 [80/100 (80%)] Train loss=0.014984 Test loss=0.624839 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.015778956934809685
[5/24] Train loss=0.013420894742012024
[10/24] Train loss=0.013768297620117664
[15/24] Train loss=0.013145547360181808
[20/24] Train loss=0.016261298209428787
Test set avg_accuracy=89.65% avg_sensitivity=75.54%, avg_specificity=93.89% avg_auc=94.69%
Fold[5] Epoch: 81 [81/100 (81%)] Train loss=0.013512 Test loss=0.652489 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.015853963792324066
[5/24] Train loss=0.0103770662099123
[10/24] Train loss=0.014742230996489525
[15/24] Train loss=0.010294467210769653
[20/24] Train loss=0.011336162686347961
Test set avg_accuracy=89.67% avg_sensitivity=75.70%, avg_specificity=93.87% avg_auc=94.67%
Fold[5] Epoch: 82 [82/100 (82%)] Train loss=0.014728 Test loss=0.652184 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.010219038464128971
[5/24] Train loss=0.015892451629042625
[10/24] Train loss=0.011351934634149075
[15/24] Train loss=0.009580694139003754
[20/24] Train loss=0.011580442078411579
Test set avg_accuracy=90.03% avg_sensitivity=75.82%, avg_specificity=94.29% avg_auc=94.67%
Fold[5] Epoch: 83 [83/100 (83%)] Train loss=0.013259 Test loss=0.667531 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.017837367951869965
[5/24] Train loss=0.017184777185320854
[10/24] Train loss=0.011750911362469196
[15/24] Train loss=0.008565503172576427
[20/24] Train loss=0.00938654225319624
Test set avg_accuracy=89.90% avg_sensitivity=75.76%, avg_specificity=94.14% avg_auc=94.67%
Fold[5] Epoch: 84 [84/100 (84%)] Train loss=0.013544 Test loss=0.671680 Current lr=[0.000122853263038123]

[0/24] Train loss=0.015989333391189575
[5/24] Train loss=0.011444386094808578
[10/24] Train loss=0.01544875092804432
[15/24] Train loss=0.009582661092281342
[20/24] Train loss=0.013229156844317913
Test set avg_accuracy=89.79% avg_sensitivity=75.65%, avg_specificity=94.04% avg_auc=94.64%
Fold[5] Epoch: 85 [85/100 (85%)] Train loss=0.013350 Test loss=0.670113 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.013956477865576744
[5/24] Train loss=0.008232722990214825
[10/24] Train loss=0.01991836354136467
[15/24] Train loss=0.009831731207668781
[20/24] Train loss=0.009209935553371906
Test set avg_accuracy=89.83% avg_sensitivity=75.99%, avg_specificity=93.99% avg_auc=94.63%
Fold[5] Epoch: 86 [86/100 (86%)] Train loss=0.012719 Test loss=0.659462 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.02175440452992916
[5/24] Train loss=0.012160043232142925
[10/24] Train loss=0.009984674863517284
[15/24] Train loss=0.01235865242779255
[20/24] Train loss=0.00776694156229496
Test set avg_accuracy=89.92% avg_sensitivity=76.32%, avg_specificity=94.01% avg_auc=94.65%
Fold[5] Epoch: 87 [87/100 (87%)] Train loss=0.013028 Test loss=0.661048 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.014830687083303928
[5/24] Train loss=0.009821103885769844
[10/24] Train loss=0.009897401556372643
[15/24] Train loss=0.015225564129650593
[20/24] Train loss=0.009615803137421608
Test set avg_accuracy=90.10% avg_sensitivity=76.16%, avg_specificity=94.29% avg_auc=94.66%
Fold[5] Epoch: 88 [88/100 (88%)] Train loss=0.012064 Test loss=0.665804 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.01362159475684166
[5/24] Train loss=0.011770171113312244
[10/24] Train loss=0.012690911069512367
[15/24] Train loss=0.012488973326981068
[20/24] Train loss=0.010652797296643257
Test set avg_accuracy=90.12% avg_sensitivity=75.59%, avg_specificity=94.48% avg_auc=94.66%
Fold[5] Epoch: 89 [89/100 (89%)] Train loss=0.012015 Test loss=0.668769 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.015178987756371498
[5/24] Train loss=0.011502626352012157
[10/24] Train loss=0.010981650091707706
[15/24] Train loss=0.009188846684992313
[20/24] Train loss=0.012988170608878136
Test set avg_accuracy=90.08% avg_sensitivity=75.93%, avg_specificity=94.33% avg_auc=94.65%
Fold[5] Epoch: 90 [90/100 (90%)] Train loss=0.012355 Test loss=0.670046 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.009631373919546604
[5/24] Train loss=0.009397788904607296
[10/24] Train loss=0.009148738346993923
[15/24] Train loss=0.008164143189787865
[20/24] Train loss=0.008566130883991718
Test set avg_accuracy=90.03% avg_sensitivity=75.87%, avg_specificity=94.28% avg_auc=94.63%
Fold[5] Epoch: 91 [91/100 (91%)] Train loss=0.011479 Test loss=0.670774 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.01080251857638359
[5/24] Train loss=0.008564049378037453
[10/24] Train loss=0.009380941279232502
[15/24] Train loss=0.009919699281454086
[20/24] Train loss=0.0090990224853158
Test set avg_accuracy=90.08% avg_sensitivity=75.93%, avg_specificity=94.33% avg_auc=94.63%
Fold[5] Epoch: 92 [92/100 (92%)] Train loss=0.010922 Test loss=0.671473 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.01133284904062748
[5/24] Train loss=0.014019360765814781
[10/24] Train loss=0.012150350958108902
[15/24] Train loss=0.01497281901538372
[20/24] Train loss=0.012068578973412514
Test set avg_accuracy=90.16% avg_sensitivity=75.87%, avg_specificity=94.45% avg_auc=94.64%
Fold[5] Epoch: 93 [93/100 (93%)] Train loss=0.011779 Test loss=0.672356 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.012997428886592388
[5/24] Train loss=0.011920024640858173
[10/24] Train loss=0.007689696736633778
[15/24] Train loss=0.008874249644577503
[20/24] Train loss=0.011775331571698189
Test set avg_accuracy=90.13% avg_sensitivity=75.87%, avg_specificity=94.41% avg_auc=94.64%
Fold[5] Epoch: 94 [94/100 (94%)] Train loss=0.011876 Test loss=0.673257 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.00876172911375761
[5/24] Train loss=0.010158337652683258
[10/24] Train loss=0.01586017943918705
[15/24] Train loss=0.00685160281136632
[20/24] Train loss=0.009120115078985691
Test set avg_accuracy=90.13% avg_sensitivity=75.87%, avg_specificity=94.41% avg_auc=94.63%
Fold[5] Epoch: 95 [95/100 (95%)] Train loss=0.010970 Test loss=0.674730 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.007019895128905773
[5/24] Train loss=0.006108766887336969
[10/24] Train loss=0.021102389320731163
[15/24] Train loss=0.01207891944795847
[20/24] Train loss=0.009255973622202873
Test set avg_accuracy=90.13% avg_sensitivity=75.87%, avg_specificity=94.41% avg_auc=94.64%
Fold[5] Epoch: 96 [96/100 (96%)] Train loss=0.011164 Test loss=0.674169 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.009735806845128536
[5/24] Train loss=0.008313757367432117
[10/24] Train loss=0.014079930260777473
[15/24] Train loss=0.008654028177261353
[20/24] Train loss=0.007788656745105982
Test set avg_accuracy=90.13% avg_sensitivity=75.87%, avg_specificity=94.41% avg_auc=94.64%
Fold[5] Epoch: 97 [97/100 (97%)] Train loss=0.010989 Test loss=0.673556 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.009588631801307201
[5/24] Train loss=0.011022910475730896
[10/24] Train loss=0.011615071445703506
[15/24] Train loss=0.008714219555258751
[20/24] Train loss=0.006463837809860706
Test set avg_accuracy=90.14% avg_sensitivity=75.87%, avg_specificity=94.43% avg_auc=94.64%
Fold[5] Epoch: 98 [98/100 (98%)] Train loss=0.010684 Test loss=0.673313 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.01223161444067955
[5/24] Train loss=0.008324661292135715
[10/24] Train loss=0.016752200201153755
[15/24] Train loss=0.010401984676718712
[20/24] Train loss=0.009428855963051319
Test set avg_accuracy=90.13% avg_sensitivity=75.87%, avg_specificity=94.41% avg_auc=94.64%
Fold[5] Epoch: 99 [99/100 (99%)] Train loss=0.011673 Test loss=0.673346 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.015925711020827293
[5/24] Train loss=0.008083506487309933
[10/24] Train loss=0.01312731858342886
[15/24] Train loss=0.006011889781802893
[20/24] Train loss=0.014087109826505184
Test set avg_accuracy=90.13% avg_sensitivity=75.87%, avg_specificity=94.41% avg_auc=94.64%
Fold[5] Epoch: 100 [100/100 (100%)] Train loss=0.011641 Test loss=0.673263 Current lr=[4.874217159761039e-09]

Fold[5] Result: acc=89.91% sen=86.08%, spe=91.06%, auc=95.60%!
Fold[5] Avg_overlap=0.67%(Â±0.22671534704737714)
[0/24] Train loss=1.3974332809448242
[5/24] Train loss=1.33108651638031
[10/24] Train loss=1.2900540828704834
[15/24] Train loss=1.1714333295822144
[20/24] Train loss=1.0816236734390259
Test set avg_accuracy=69.97% avg_sensitivity=11.08%, avg_specificity=90.88% avg_auc=70.35%
Best model saved!! Metric=70.34693304534122!!
Fold[6] Epoch: 1 [1/100 (1%)] Train loss=1.234485 Test loss=0.724510 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=1.0047860145568848
[5/24] Train loss=1.0082834959030151
[10/24] Train loss=1.0308550596237183
[15/24] Train loss=0.9623775482177734
[20/24] Train loss=0.9308176636695862
Test set avg_accuracy=77.16% avg_sensitivity=52.14%, avg_specificity=86.04% avg_auc=81.19%
Best model saved!! Metric=81.18960022504352!!
Fold[6] Epoch: 2 [2/100 (2%)] Train loss=0.993957 Test loss=0.630271 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8918306827545166
[5/24] Train loss=0.9186423420906067
[10/24] Train loss=0.9589428305625916
[15/24] Train loss=0.8784782886505127
[20/24] Train loss=0.8584815263748169
Test set avg_accuracy=78.45% avg_sensitivity=55.37%, avg_specificity=86.64% avg_auc=83.83%
Best model saved!! Metric=83.82532083434468!!
Fold[6] Epoch: 3 [3/100 (3%)] Train loss=0.908018 Test loss=0.528791 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.794293999671936
[5/24] Train loss=0.8514449000358582
[10/24] Train loss=0.8703813552856445
[15/24] Train loss=0.8373661637306213
[20/24] Train loss=0.7814675569534302
Test set avg_accuracy=81.45% avg_sensitivity=75.84%, avg_specificity=83.43% avg_auc=88.08%
Best model saved!! Metric=88.07883994550691!!
Fold[6] Epoch: 4 [4/100 (4%)] Train loss=0.833459 Test loss=0.472233 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.7396184206008911
[5/24] Train loss=0.8534841537475586
[10/24] Train loss=0.8240074515342712
[15/24] Train loss=0.8161921501159668
[20/24] Train loss=0.7538653612136841
Test set avg_accuracy=80.09% avg_sensitivity=86.98%, avg_specificity=77.65% avg_auc=90.61%
Best model saved!! Metric=90.60648459279608!!
Fold[6] Epoch: 5 [5/100 (5%)] Train loss=0.799988 Test loss=0.503502 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.7371474504470825
[5/24] Train loss=0.8117655515670776
[10/24] Train loss=0.826239287853241
[15/24] Train loss=0.7641296982765198
[20/24] Train loss=0.7223637104034424
Test set avg_accuracy=83.19% avg_sensitivity=86.83%, avg_specificity=81.90% avg_auc=91.78%
Best model saved!! Metric=91.77786141303204!!
Fold[6] Epoch: 6 [6/100 (6%)] Train loss=0.768235 Test loss=0.429406 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.6951294541358948
[5/24] Train loss=0.7180231809616089
[10/24] Train loss=0.7603910565376282
[15/24] Train loss=0.7641119360923767
[20/24] Train loss=0.7250680923461914
Test set avg_accuracy=84.77% avg_sensitivity=85.59%, avg_specificity=84.47% avg_auc=92.31%
Best model saved!! Metric=92.3096039149717!!
Fold[6] Epoch: 7 [7/100 (7%)] Train loss=0.729390 Test loss=0.389638 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.6440846920013428
[5/24] Train loss=0.7036619186401367
[10/24] Train loss=0.7286810278892517
[15/24] Train loss=0.73744136095047
[20/24] Train loss=0.6624842882156372
Test set avg_accuracy=83.59% avg_sensitivity=89.31%, avg_specificity=81.56% avg_auc=92.98%
Best model saved!! Metric=92.9777106591222!!
Fold[6] Epoch: 8 [8/100 (8%)] Train loss=0.701811 Test loss=0.410573 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.6421597599983215
[5/24] Train loss=0.6930209398269653
[10/24] Train loss=0.751835286617279
[15/24] Train loss=0.759888768196106
[20/24] Train loss=0.6575092077255249
Test set avg_accuracy=83.42% avg_sensitivity=88.67%, avg_specificity=81.56% avg_auc=93.00%
Best model saved!! Metric=93.00457838712258!!
Fold[6] Epoch: 9 [9/100 (9%)] Train loss=0.688216 Test loss=0.420100 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6235688924789429
[5/24] Train loss=0.7007834315299988
[10/24] Train loss=0.7493347525596619
[15/24] Train loss=0.747113823890686
[20/24] Train loss=0.6095296144485474
Test set avg_accuracy=84.69% avg_sensitivity=89.96%, avg_specificity=82.82% avg_auc=93.79%
Best model saved!! Metric=93.79475616309202!!
Fold[6] Epoch: 10 [10/100 (10%)] Train loss=0.680188 Test loss=0.386480 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.620048463344574
[5/24] Train loss=0.6439000368118286
[10/24] Train loss=0.7248106598854065
[15/24] Train loss=0.8105700016021729
[20/24] Train loss=0.6098212003707886
Test set avg_accuracy=86.85% avg_sensitivity=85.98%, avg_specificity=87.16% avg_auc=93.11%
Fold[6] Epoch: 11 [11/100 (11%)] Train loss=0.666067 Test loss=0.338214 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.5635178089141846
[5/24] Train loss=0.607067346572876
[10/24] Train loss=0.7071921229362488
[15/24] Train loss=0.6633810997009277
[20/24] Train loss=0.6032456755638123
Test set avg_accuracy=86.65% avg_sensitivity=88.97%, avg_specificity=85.83% avg_auc=93.95%
Best model saved!! Metric=93.9501005610655!!
Fold[6] Epoch: 12 [12/100 (12%)] Train loss=0.639276 Test loss=0.350832 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.5839800834655762
[5/24] Train loss=0.5687040090560913
[10/24] Train loss=0.6772036552429199
[15/24] Train loss=0.6590046882629395
[20/24] Train loss=0.5970636606216431
Test set avg_accuracy=86.54% avg_sensitivity=87.62%, avg_specificity=86.15% avg_auc=93.71%
Fold[6] Epoch: 13 [13/100 (13%)] Train loss=0.632916 Test loss=0.349112 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.5693442225456238
[5/24] Train loss=0.5676649808883667
[10/24] Train loss=0.7153536081314087
[15/24] Train loss=0.7040701508522034
[20/24] Train loss=0.5612384676933289
Test set avg_accuracy=88.20% avg_sensitivity=87.28%, avg_specificity=88.53% avg_auc=94.25%
Best model saved!! Metric=94.24528166217937!!
Fold[6] Epoch: 14 [14/100 (14%)] Train loss=0.623196 Test loss=0.316233 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.542795717716217
[5/24] Train loss=0.6064114570617676
[10/24] Train loss=0.7038503289222717
[15/24] Train loss=0.6514910459518433
[20/24] Train loss=0.5536624193191528
Test set avg_accuracy=87.16% avg_sensitivity=87.48%, avg_specificity=87.05% avg_auc=93.77%
Fold[6] Epoch: 15 [15/100 (15%)] Train loss=0.618293 Test loss=0.337960 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.5665361285209656
[5/24] Train loss=0.5594154000282288
[10/24] Train loss=0.6927379369735718
[15/24] Train loss=0.6723292469978333
[20/24] Train loss=0.5254456400871277
Test set avg_accuracy=89.34% avg_sensitivity=85.44%, avg_specificity=90.72% avg_auc=94.68%
Best model saved!! Metric=94.67628772179907!!
Fold[6] Epoch: 16 [16/100 (16%)] Train loss=0.611873 Test loss=0.289285 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5538302659988403
[5/24] Train loss=0.5860258936882019
[10/24] Train loss=0.6590195298194885
[15/24] Train loss=0.661758542060852
[20/24] Train loss=0.5720556378364563
Test set avg_accuracy=89.32% avg_sensitivity=81.76%, avg_specificity=92.01% avg_auc=93.81%
Fold[6] Epoch: 17 [17/100 (17%)] Train loss=0.606260 Test loss=0.289358 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5882119536399841
[5/24] Train loss=0.5541782379150391
[10/24] Train loss=0.6710191369056702
[15/24] Train loss=0.6650725603103638
[20/24] Train loss=0.5489967465400696
Test set avg_accuracy=86.76% avg_sensitivity=89.66%, avg_specificity=85.73% avg_auc=94.58%
Fold[6] Epoch: 18 [18/100 (18%)] Train loss=0.604635 Test loss=0.344148 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.5507270097732544
[5/24] Train loss=0.5570197701454163
[10/24] Train loss=0.615078866481781
[15/24] Train loss=0.6245155930519104
[20/24] Train loss=0.5411795377731323
Test set avg_accuracy=88.65% avg_sensitivity=82.36%, avg_specificity=90.88% avg_auc=93.92%
Fold[6] Epoch: 19 [19/100 (19%)] Train loss=0.584438 Test loss=0.289421 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.531149685382843
[5/24] Train loss=0.5350251793861389
[10/24] Train loss=0.6365677714347839
[15/24] Train loss=0.6142879724502563
[20/24] Train loss=0.5197165012359619
Test set avg_accuracy=87.96% avg_sensitivity=68.44%, avg_specificity=94.88% avg_auc=93.28%
Fold[6] Epoch: 20 [20/100 (20%)] Train loss=0.575126 Test loss=0.292222 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5839924216270447
[5/24] Train loss=0.5742384791374207
[10/24] Train loss=0.6575460433959961
[15/24] Train loss=0.6416503190994263
[20/24] Train loss=0.5216215252876282
Test set avg_accuracy=87.23% avg_sensitivity=89.12%, avg_specificity=86.56% avg_auc=94.39%
Fold[6] Epoch: 21 [21/100 (21%)] Train loss=0.590993 Test loss=0.322702 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.5691050887107849
[5/24] Train loss=0.5089126825332642
[10/24] Train loss=0.6184884309768677
[15/24] Train loss=0.5852749347686768
[20/24] Train loss=0.5254478454589844
Test set avg_accuracy=88.98% avg_sensitivity=77.78%, avg_specificity=92.96% avg_auc=94.11%
Fold[6] Epoch: 22 [22/100 (22%)] Train loss=0.567990 Test loss=0.281321 Current lr=[0.000842324016282456]

[0/24] Train loss=0.5157809257507324
[5/24] Train loss=0.49978333711624146
[10/24] Train loss=0.639921247959137
[15/24] Train loss=0.6456085443496704
[20/24] Train loss=0.5453876852989197
Test set avg_accuracy=89.52% avg_sensitivity=72.66%, avg_specificity=95.50% avg_auc=94.00%
Fold[6] Epoch: 23 [23/100 (23%)] Train loss=0.567615 Test loss=0.275352 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5305551886558533
[5/24] Train loss=0.48492899537086487
[10/24] Train loss=0.5805307030677795
[15/24] Train loss=0.6235138773918152
[20/24] Train loss=0.48739880323410034
Test set avg_accuracy=89.22% avg_sensitivity=69.83%, avg_specificity=96.10% avg_auc=93.67%
Fold[6] Epoch: 24 [24/100 (24%)] Train loss=0.554835 Test loss=0.291630 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.4966760277748108
[5/24] Train loss=0.4787518382072449
[10/24] Train loss=0.5946875214576721
[15/24] Train loss=0.5718353390693665
[20/24] Train loss=0.4566662013530731
Test set avg_accuracy=88.78% avg_sensitivity=74.85%, avg_specificity=93.72% avg_auc=93.75%
Fold[6] Epoch: 25 [25/100 (25%)] Train loss=0.543157 Test loss=0.286803 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.4735947549343109
[5/24] Train loss=0.5149455070495605
[10/24] Train loss=0.6399142146110535
[15/24] Train loss=0.5933241844177246
[20/24] Train loss=0.49972179532051086
Test set avg_accuracy=89.67% avg_sensitivity=76.99%, avg_specificity=94.18% avg_auc=94.21%
Fold[6] Epoch: 26 [26/100 (26%)] Train loss=0.534767 Test loss=0.272511 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.5108134150505066
[5/24] Train loss=0.5109009742736816
[10/24] Train loss=0.6287795901298523
[15/24] Train loss=0.5722098350524902
[20/24] Train loss=0.46297329664230347
Test set avg_accuracy=89.06% avg_sensitivity=71.82%, avg_specificity=95.18% avg_auc=94.02%
Fold[6] Epoch: 27 [27/100 (27%)] Train loss=0.524937 Test loss=0.291472 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.4799115061759949
[5/24] Train loss=0.4981633722782135
[10/24] Train loss=0.5483299493789673
[15/24] Train loss=0.5593732595443726
[20/24] Train loss=0.47353044152259827
Test set avg_accuracy=88.19% avg_sensitivity=65.81%, avg_specificity=96.14% avg_auc=93.18%
Fold[6] Epoch: 28 [28/100 (28%)] Train loss=0.518341 Test loss=0.310228 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.4894711673259735
[5/24] Train loss=0.5410674214363098
[10/24] Train loss=0.5585564970970154
[15/24] Train loss=0.5622705221176147
[20/24] Train loss=0.4464670419692993
Test set avg_accuracy=89.45% avg_sensitivity=69.93%, avg_specificity=96.38% avg_auc=93.70%
Fold[6] Epoch: 29 [29/100 (29%)] Train loss=0.519067 Test loss=0.308520 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.4979304373264313
[5/24] Train loss=0.5102559924125671
[10/24] Train loss=0.5558632016181946
[15/24] Train loss=0.5468705892562866
[20/24] Train loss=0.42901864647865295
Test set avg_accuracy=88.74% avg_sensitivity=76.39%, avg_specificity=93.12% avg_auc=93.73%
Fold[6] Epoch: 30 [30/100 (30%)] Train loss=0.516990 Test loss=0.295349 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.49227041006088257
[5/24] Train loss=0.451330304145813
[10/24] Train loss=0.5090277791023254
[15/24] Train loss=0.49084609746932983
[20/24] Train loss=0.4508231580257416
Test set avg_accuracy=88.85% avg_sensitivity=72.96%, avg_specificity=94.50% avg_auc=93.90%
Fold[6] Epoch: 31 [31/100 (31%)] Train loss=0.482455 Test loss=0.285781 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.44444727897644043
[5/24] Train loss=0.4503883421421051
[10/24] Train loss=0.5276723504066467
[15/24] Train loss=0.4910275936126709
[20/24] Train loss=0.4167640805244446
Test set avg_accuracy=88.84% avg_sensitivity=79.17%, avg_specificity=92.27% avg_auc=94.10%
Fold[6] Epoch: 32 [32/100 (32%)] Train loss=0.477706 Test loss=0.296431 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.4268570840358734
[5/24] Train loss=0.43653059005737305
[10/24] Train loss=0.5222222208976746
[15/24] Train loss=0.4337097704410553
[20/24] Train loss=0.41532835364341736
Test set avg_accuracy=89.10% avg_sensitivity=76.19%, avg_specificity=93.68% avg_auc=94.35%
Fold[6] Epoch: 33 [33/100 (33%)] Train loss=0.466211 Test loss=0.280816 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.40967822074890137
[5/24] Train loss=0.39569225907325745
[10/24] Train loss=0.51279217004776
[15/24] Train loss=0.3900837004184723
[20/24] Train loss=0.39469829201698303
Test set avg_accuracy=89.84% avg_sensitivity=76.69%, avg_specificity=94.51% avg_auc=94.85%
Best model saved!! Metric=94.85013875813574!!
Fold[6] Epoch: 34 [34/100 (34%)] Train loss=0.450961 Test loss=0.258300 Current lr=[0.000991797016730875]

[0/24] Train loss=0.425454318523407
[5/24] Train loss=0.42590975761413574
[10/24] Train loss=0.4826027750968933
[15/24] Train loss=0.3990636467933655
[20/24] Train loss=0.3786684274673462
Test set avg_accuracy=89.66% avg_sensitivity=77.53%, avg_specificity=93.97% avg_auc=94.43%
Fold[6] Epoch: 35 [35/100 (35%)] Train loss=0.447745 Test loss=0.279058 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.40975961089134216
[5/24] Train loss=0.4034745693206787
[10/24] Train loss=0.4898224472999573
[15/24] Train loss=0.3654411733150482
[20/24] Train loss=0.37726613879203796
Test set avg_accuracy=89.04% avg_sensitivity=79.47%, avg_specificity=92.43% avg_auc=94.31%
Fold[6] Epoch: 36 [36/100 (36%)] Train loss=0.424817 Test loss=0.279515 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.401237428188324
[5/24] Train loss=0.36117374897003174
[10/24] Train loss=0.4689312279224396
[15/24] Train loss=0.3957814872264862
[20/24] Train loss=0.35485920310020447
Test set avg_accuracy=89.24% avg_sensitivity=84.99%, avg_specificity=90.76% avg_auc=94.17%
Fold[6] Epoch: 37 [37/100 (37%)] Train loss=0.419045 Test loss=0.300158 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.382737934589386
[5/24] Train loss=0.3665718138217926
[10/24] Train loss=0.4650631844997406
[15/24] Train loss=0.34791022539138794
[20/24] Train loss=0.3598472774028778
Test set avg_accuracy=87.66% avg_sensitivity=83.40%, avg_specificity=89.17% avg_auc=93.94%
Fold[6] Epoch: 38 [38/100 (38%)] Train loss=0.400032 Test loss=0.317695 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.381014883518219
[5/24] Train loss=0.32500314712524414
[10/24] Train loss=0.39056631922721863
[15/24] Train loss=0.35315388441085815
[20/24] Train loss=0.3235587477684021
Test set avg_accuracy=88.36% avg_sensitivity=84.79%, avg_specificity=89.63% avg_auc=93.80%
Fold[6] Epoch: 39 [39/100 (39%)] Train loss=0.384696 Test loss=0.319878 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.37009429931640625
[5/24] Train loss=0.3320592939853668
[10/24] Train loss=0.4231127202510834
[15/24] Train loss=0.3730789124965668
[20/24] Train loss=0.3654092252254486
Test set avg_accuracy=86.93% avg_sensitivity=83.00%, avg_specificity=88.32% avg_auc=92.95%
Fold[6] Epoch: 40 [40/100 (40%)] Train loss=0.369668 Test loss=0.332389 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.4129911959171295
[5/24] Train loss=0.28127941489219666
[10/24] Train loss=0.4038170576095581
[15/24] Train loss=0.3367411494255066
[20/24] Train loss=0.28334271907806396
Test set avg_accuracy=87.15% avg_sensitivity=86.58%, avg_specificity=87.35% avg_auc=94.19%
Fold[6] Epoch: 41 [41/100 (41%)] Train loss=0.363520 Test loss=0.338463 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.36004289984703064
[5/24] Train loss=0.29292234778404236
[10/24] Train loss=0.36042988300323486
[15/24] Train loss=0.3366588056087494
[20/24] Train loss=0.3428027033805847
Test set avg_accuracy=87.53% avg_sensitivity=85.19%, avg_specificity=88.36% avg_auc=93.28%
Fold[6] Epoch: 42 [42/100 (42%)] Train loss=0.348932 Test loss=0.368606 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.378424733877182
[5/24] Train loss=0.33571672439575195
[10/24] Train loss=0.3755917549133301
[15/24] Train loss=0.34543952345848083
[20/24] Train loss=0.303055077791214
Test set avg_accuracy=88.67% avg_sensitivity=84.54%, avg_specificity=90.14% avg_auc=93.66%
Fold[6] Epoch: 43 [43/100 (43%)] Train loss=0.358892 Test loss=0.370716 Current lr=[0.000916771143003274]

[0/24] Train loss=0.3783913552761078
[5/24] Train loss=0.3414641320705414
[10/24] Train loss=0.4189600348472595
[15/24] Train loss=0.3336496651172638
[20/24] Train loss=0.27994489669799805
Test set avg_accuracy=89.00% avg_sensitivity=83.85%, avg_specificity=90.83% avg_auc=93.51%
Fold[6] Epoch: 44 [44/100 (44%)] Train loss=0.351335 Test loss=0.382718 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.37869635224342346
[5/24] Train loss=0.3393450081348419
[10/24] Train loss=0.3471134305000305
[15/24] Train loss=0.3091777265071869
[20/24] Train loss=0.2791404724121094
Test set avg_accuracy=89.17% avg_sensitivity=79.77%, avg_specificity=92.50% avg_auc=93.29%
Fold[6] Epoch: 45 [45/100 (45%)] Train loss=0.334863 Test loss=0.363929 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.3432135581970215
[5/24] Train loss=0.26321473717689514
[10/24] Train loss=0.3965928554534912
[15/24] Train loss=0.34221580624580383
[20/24] Train loss=0.24836646020412445
Test set avg_accuracy=88.40% avg_sensitivity=75.05%, avg_specificity=93.14% avg_auc=92.85%
Fold[6] Epoch: 46 [46/100 (46%)] Train loss=0.315171 Test loss=0.415869 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.30775922536849976
[5/24] Train loss=0.2518969178199768
[10/24] Train loss=0.3327037990093231
[15/24] Train loss=0.26446691155433655
[20/24] Train loss=0.21830002963542938
Test set avg_accuracy=88.54% avg_sensitivity=77.53%, avg_specificity=92.45% avg_auc=93.42%
Fold[6] Epoch: 47 [47/100 (47%)] Train loss=0.285300 Test loss=0.389843 Current lr=[0.000860751215339601]

[0/24] Train loss=0.24417978525161743
[5/24] Train loss=0.26490530371665955
[10/24] Train loss=0.31215164065361023
[15/24] Train loss=0.2689858675003052
[20/24] Train loss=0.25410908460617065
Test set avg_accuracy=88.72% avg_sensitivity=81.86%, avg_specificity=91.16% avg_auc=93.83%
Fold[6] Epoch: 48 [48/100 (48%)] Train loss=0.270401 Test loss=0.401919 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.23889784514904022
[5/24] Train loss=0.2555959224700928
[10/24] Train loss=0.24931085109710693
[15/24] Train loss=0.23613521456718445
[20/24] Train loss=0.20837071537971497
Test set avg_accuracy=87.97% avg_sensitivity=76.49%, avg_specificity=92.04% avg_auc=93.41%
Fold[6] Epoch: 49 [49/100 (49%)] Train loss=0.250885 Test loss=0.427193 Current lr=[0.000828265354963756]

[0/24] Train loss=0.23355701565742493
[5/24] Train loss=0.1985696405172348
[10/24] Train loss=0.26951053738594055
[15/24] Train loss=0.24547065794467926
[20/24] Train loss=0.18073995411396027
Test set avg_accuracy=88.26% avg_sensitivity=78.93%, avg_specificity=91.57% avg_auc=93.94%
Fold[6] Epoch: 50 [50/100 (50%)] Train loss=0.228852 Test loss=0.386549 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.20268093049526215
[5/24] Train loss=0.18616555631160736
[10/24] Train loss=0.22559712827205658
[15/24] Train loss=0.19525952637195587
[20/24] Train loss=0.16179612278938293
Test set avg_accuracy=88.72% avg_sensitivity=75.05%, avg_specificity=93.58% avg_auc=93.58%
Fold[6] Epoch: 51 [51/100 (51%)] Train loss=0.199857 Test loss=0.422263 Current lr=[0.00079313651106947]

[0/24] Train loss=0.18407371640205383
[5/24] Train loss=0.16005830466747284
[10/24] Train loss=0.20290303230285645
[15/24] Train loss=0.17956006526947021
[20/24] Train loss=0.1830807477235794
Test set avg_accuracy=88.89% avg_sensitivity=75.65%, avg_specificity=93.60% avg_auc=93.45%
Fold[6] Epoch: 52 [52/100 (52%)] Train loss=0.190928 Test loss=0.470167 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.1897519826889038
[5/24] Train loss=0.1636405736207962
[10/24] Train loss=0.19140402972698212
[15/24] Train loss=0.1529783010482788
[20/24] Train loss=0.19223855435848236
Test set avg_accuracy=88.93% avg_sensitivity=78.88%, avg_specificity=92.50% avg_auc=93.39%
Fold[6] Epoch: 53 [53/100 (53%)] Train loss=0.182296 Test loss=0.462960 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.17786861956119537
[5/24] Train loss=0.15023840963840485
[10/24] Train loss=0.17505496740341187
[15/24] Train loss=0.1459183394908905
[20/24] Train loss=0.17065604031085968
Test set avg_accuracy=89.19% avg_sensitivity=77.78%, avg_specificity=93.24% avg_auc=93.77%
Fold[6] Epoch: 54 [54/100 (54%)] Train loss=0.172227 Test loss=0.502268 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.1677381992340088
[5/24] Train loss=0.13894230127334595
[10/24] Train loss=0.18264225125312805
[15/24] Train loss=0.13948307931423187
[20/24] Train loss=0.13202384114265442
Test set avg_accuracy=88.85% avg_sensitivity=77.29%, avg_specificity=92.96% avg_auc=93.22%
Fold[6] Epoch: 55 [55/100 (55%)] Train loss=0.166221 Test loss=0.565015 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.1479223370552063
[5/24] Train loss=0.12972676753997803
[10/24] Train loss=0.17356519401073456
[15/24] Train loss=0.14982272684574127
[20/24] Train loss=0.12546198070049286
Test set avg_accuracy=88.61% avg_sensitivity=70.97%, avg_specificity=94.87% avg_auc=92.84%
Fold[6] Epoch: 56 [56/100 (56%)] Train loss=0.150295 Test loss=0.555715 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.15112794935703278
[5/24] Train loss=0.11268569529056549
[10/24] Train loss=0.16350474953651428
[15/24] Train loss=0.1213119700551033
[20/24] Train loss=0.10025130212306976
Test set avg_accuracy=89.36% avg_sensitivity=70.63%, avg_specificity=96.01% avg_auc=93.36%
Fold[6] Epoch: 57 [57/100 (57%)] Train loss=0.138771 Test loss=0.628884 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.1299731582403183
[5/24] Train loss=0.11960721015930176
[10/24] Train loss=0.15712839365005493
[15/24] Train loss=0.11731577664613724
[20/24] Train loss=0.11298120766878128
Test set avg_accuracy=88.93% avg_sensitivity=72.17%, avg_specificity=94.88% avg_auc=93.31%
Fold[6] Epoch: 58 [58/100 (58%)] Train loss=0.134347 Test loss=0.588049 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.12809255719184875
[5/24] Train loss=0.10115703195333481
[10/24] Train loss=0.12843529880046844
[15/24] Train loss=0.11973750591278076
[20/24] Train loss=0.09478684514760971
Test set avg_accuracy=88.98% avg_sensitivity=75.84%, avg_specificity=93.65% avg_auc=93.67%
Fold[6] Epoch: 59 [59/100 (59%)] Train loss=0.116457 Test loss=0.623456 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.08887650072574615
[5/24] Train loss=0.10870933532714844
[10/24] Train loss=0.11149939149618149
[15/24] Train loss=0.11296500265598297
[20/24] Train loss=0.09637575596570969
Test set avg_accuracy=88.45% avg_sensitivity=72.96%, avg_specificity=93.95% avg_auc=93.68%
Fold[6] Epoch: 60 [60/100 (60%)] Train loss=0.106261 Test loss=0.612001 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.09051410108804703
[5/24] Train loss=0.08310474455356598
[10/24] Train loss=0.10316779464483261
[15/24] Train loss=0.11035304516553879
[20/24] Train loss=0.08377581834793091
Test set avg_accuracy=88.32% avg_sensitivity=74.20%, avg_specificity=93.33% avg_auc=93.31%
Fold[6] Epoch: 61 [61/100 (61%)] Train loss=0.097582 Test loss=0.604024 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.08907666057348251
[5/24] Train loss=0.07604032009840012
[10/24] Train loss=0.10100101679563522
[15/24] Train loss=0.08972898870706558
[20/24] Train loss=0.08185816556215286
Test set avg_accuracy=88.26% avg_sensitivity=74.90%, avg_specificity=93.00% avg_auc=93.29%
Fold[6] Epoch: 62 [62/100 (62%)] Train loss=0.087854 Test loss=0.600319 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.08055878430604935
[5/24] Train loss=0.0767485648393631
[10/24] Train loss=0.09325207769870758
[15/24] Train loss=0.06580039858818054
[20/24] Train loss=0.07432008534669876
Test set avg_accuracy=88.63% avg_sensitivity=74.11%, avg_specificity=93.79% avg_auc=93.50%
Fold[6] Epoch: 63 [63/100 (63%)] Train loss=0.082000 Test loss=0.638456 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.07109475135803223
[5/24] Train loss=0.07523401081562042
[10/24] Train loss=0.07806948572397232
[15/24] Train loss=0.07515999674797058
[20/24] Train loss=0.07861156761646271
Test set avg_accuracy=88.33% avg_sensitivity=75.50%, avg_specificity=92.89% avg_auc=93.58%
Fold[6] Epoch: 64 [64/100 (64%)] Train loss=0.077365 Test loss=0.621334 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.07362329214811325
[5/24] Train loss=0.06665606051683426
[10/24] Train loss=0.08535783737897873
[15/24] Train loss=0.054041825234889984
[20/24] Train loss=0.07253137230873108
Test set avg_accuracy=89.26% avg_sensitivity=78.58%, avg_specificity=93.05% avg_auc=94.04%
Fold[6] Epoch: 65 [65/100 (65%)] Train loss=0.072998 Test loss=0.590606 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.06416063010692596
[5/24] Train loss=0.04886149987578392
[10/24] Train loss=0.06972415000200272
[15/24] Train loss=0.0558217391371727
[20/24] Train loss=0.062037914991378784
Test set avg_accuracy=88.79% avg_sensitivity=76.59%, avg_specificity=93.12% avg_auc=93.71%
Fold[6] Epoch: 66 [66/100 (66%)] Train loss=0.067396 Test loss=0.636891 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.06225569546222687
[5/24] Train loss=0.047528017312288284
[10/24] Train loss=0.07897020131349564
[15/24] Train loss=0.06912778317928314
[20/24] Train loss=0.04177962243556976
Test set avg_accuracy=88.96% avg_sensitivity=79.13%, avg_specificity=92.45% avg_auc=93.73%
Fold[6] Epoch: 67 [67/100 (67%)] Train loss=0.064118 Test loss=0.669874 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.06609276682138443
[5/24] Train loss=0.05189172551035881
[10/24] Train loss=0.0626038983464241
[15/24] Train loss=0.0620359405875206
[20/24] Train loss=0.052411869168281555
Test set avg_accuracy=89.19% avg_sensitivity=82.16%, avg_specificity=91.69% avg_auc=93.94%
Fold[6] Epoch: 68 [68/100 (68%)] Train loss=0.060750 Test loss=0.642709 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.06229536607861519
[5/24] Train loss=0.05667576938867569
[10/24] Train loss=0.06246812641620636
[15/24] Train loss=0.048048973083496094
[20/24] Train loss=0.0572713166475296
Test set avg_accuracy=89.04% avg_sensitivity=81.21%, avg_specificity=91.81% avg_auc=94.03%
Fold[6] Epoch: 69 [69/100 (69%)] Train loss=0.057960 Test loss=0.697721 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.059992704540491104
[5/24] Train loss=0.06402653455734253
[10/24] Train loss=0.04417978972196579
[15/24] Train loss=0.051841866225004196
[20/24] Train loss=0.042278677225112915
Test set avg_accuracy=88.75% avg_sensitivity=81.61%, avg_specificity=91.28% avg_auc=93.72%
Fold[6] Epoch: 70 [70/100 (70%)] Train loss=0.055199 Test loss=0.775645 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.0685616061091423
[5/24] Train loss=0.04719439521431923
[10/24] Train loss=0.06459703296422958
[15/24] Train loss=0.05731045827269554
[20/24] Train loss=0.046432651579380035
Test set avg_accuracy=88.42% avg_sensitivity=77.93%, avg_specificity=92.15% avg_auc=93.55%
Fold[6] Epoch: 71 [71/100 (71%)] Train loss=0.051961 Test loss=0.762669 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.05944142863154411
[5/24] Train loss=0.05209210142493248
[10/24] Train loss=0.048180773854255676
[15/24] Train loss=0.04303125664591789
[20/24] Train loss=0.03764703869819641
Test set avg_accuracy=88.65% avg_sensitivity=74.75%, avg_specificity=93.58% avg_auc=93.53%
Fold[6] Epoch: 72 [72/100 (72%)] Train loss=0.045297 Test loss=0.757787 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.04189525544643402
[5/24] Train loss=0.03709588572382927
[10/24] Train loss=0.04658825695514679
[15/24] Train loss=0.029233109205961227
[20/24] Train loss=0.03242378681898117
Test set avg_accuracy=88.92% avg_sensitivity=73.81%, avg_specificity=94.28% avg_auc=93.63%
Fold[6] Epoch: 73 [73/100 (73%)] Train loss=0.040795 Test loss=0.747616 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.03595731407403946
[5/24] Train loss=0.03159385174512863
[10/24] Train loss=0.03573353961110115
[15/24] Train loss=0.025211190804839134
[20/24] Train loss=0.032488301396369934
Test set avg_accuracy=88.55% avg_sensitivity=75.00%, avg_specificity=93.37% avg_auc=93.76%
Fold[6] Epoch: 74 [74/100 (74%)] Train loss=0.036539 Test loss=0.812235 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.03454364463686943
[5/24] Train loss=0.03606010973453522
[10/24] Train loss=0.028253847733139992
[15/24] Train loss=0.03497854992747307
[20/24] Train loss=0.029382508248090744
Test set avg_accuracy=88.29% avg_sensitivity=75.60%, avg_specificity=92.80% avg_auc=93.71%
Fold[6] Epoch: 75 [75/100 (75%)] Train loss=0.034211 Test loss=0.777919 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.02685260958969593
[5/24] Train loss=0.02523759938776493
[10/24] Train loss=0.03509937599301338
[15/24] Train loss=0.03442847356200218
[20/24] Train loss=0.027415797114372253
Test set avg_accuracy=88.42% avg_sensitivity=75.35%, avg_specificity=93.07% avg_auc=93.72%
Fold[6] Epoch: 76 [76/100 (76%)] Train loss=0.032393 Test loss=0.766051 Current lr=[0.000262245679641298]

[0/24] Train loss=0.038070205599069595
[5/24] Train loss=0.025680571794509888
[10/24] Train loss=0.02751193568110466
[15/24] Train loss=0.029455875977873802
[20/24] Train loss=0.03284505009651184
Test set avg_accuracy=88.54% avg_sensitivity=75.40%, avg_specificity=93.21% avg_auc=93.76%
Fold[6] Epoch: 77 [77/100 (77%)] Train loss=0.031611 Test loss=0.780198 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.02949792891740799
[5/24] Train loss=0.022325702011585236
[10/24] Train loss=0.030110089108347893
[15/24] Train loss=0.021736616268754005
[20/24] Train loss=0.02222074382007122
Test set avg_accuracy=88.76% avg_sensitivity=76.09%, avg_specificity=93.26% avg_auc=93.61%
Fold[6] Epoch: 78 [78/100 (78%)] Train loss=0.030509 Test loss=0.783036 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.030702019110322
[5/24] Train loss=0.030153978615999222
[10/24] Train loss=0.03227386996150017
[15/24] Train loss=0.03158021718263626
[20/24] Train loss=0.02845274843275547
Test set avg_accuracy=88.70% avg_sensitivity=75.30%, avg_specificity=93.45% avg_auc=93.71%
Fold[6] Epoch: 79 [79/100 (79%)] Train loss=0.028805 Test loss=0.810989 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.025687308982014656
[5/24] Train loss=0.02632342278957367
[10/24] Train loss=0.023414887487888336
[15/24] Train loss=0.025591200217604637
[20/24] Train loss=0.021739069372415543
Test set avg_accuracy=88.66% avg_sensitivity=75.15%, avg_specificity=93.45% avg_auc=93.69%
Fold[6] Epoch: 80 [80/100 (80%)] Train loss=0.027154 Test loss=0.800108 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.035781558603048325
[5/24] Train loss=0.020243097096681595
[10/24] Train loss=0.024420810863375664
[15/24] Train loss=0.017826760187745094
[20/24] Train loss=0.029348542913794518
Test set avg_accuracy=88.46% avg_sensitivity=75.55%, avg_specificity=93.05% avg_auc=93.67%
Fold[6] Epoch: 81 [81/100 (81%)] Train loss=0.025974 Test loss=0.811800 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.023825908079743385
[5/24] Train loss=0.024485604837536812
[10/24] Train loss=0.029770173132419586
[15/24] Train loss=0.025406844913959503
[20/24] Train loss=0.016986170783638954
Test set avg_accuracy=88.40% avg_sensitivity=74.80%, avg_specificity=93.23% avg_auc=93.61%
Fold[6] Epoch: 82 [82/100 (82%)] Train loss=0.024641 Test loss=0.839181 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.023551717400550842
[5/24] Train loss=0.023141706362366676
[10/24] Train loss=0.0242256261408329
[15/24] Train loss=0.02658635936677456
[20/24] Train loss=0.022961899638175964
Test set avg_accuracy=88.44% avg_sensitivity=75.35%, avg_specificity=93.08% avg_auc=93.73%
Fold[6] Epoch: 83 [83/100 (83%)] Train loss=0.024095 Test loss=0.806658 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.02112695947289467
[5/24] Train loss=0.026283903047442436
[10/24] Train loss=0.029215026646852493
[15/24] Train loss=0.019278282299637794
[20/24] Train loss=0.02022399567067623
Test set avg_accuracy=88.55% avg_sensitivity=75.60%, avg_specificity=93.15% avg_auc=93.66%
Fold[6] Epoch: 84 [84/100 (84%)] Train loss=0.025136 Test loss=0.815358 Current lr=[0.000122853263038123]

[0/24] Train loss=0.019802751019597054
[5/24] Train loss=0.015849456191062927
[10/24] Train loss=0.02622734010219574
[15/24] Train loss=0.022338729351758957
[20/24] Train loss=0.015225036069750786
Test set avg_accuracy=88.62% avg_sensitivity=76.19%, avg_specificity=93.03% avg_auc=93.73%
Fold[6] Epoch: 85 [85/100 (85%)] Train loss=0.022546 Test loss=0.804795 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.0296965129673481
[5/24] Train loss=0.01769411563873291
[10/24] Train loss=0.024870513007044792
[15/24] Train loss=0.019686438143253326
[20/24] Train loss=0.02123478800058365
Test set avg_accuracy=88.48% avg_sensitivity=75.20%, avg_specificity=93.19% avg_auc=93.71%
Fold[6] Epoch: 86 [86/100 (86%)] Train loss=0.024001 Test loss=0.831429 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.021135952323675156
[5/24] Train loss=0.021885789930820465
[10/24] Train loss=0.030818596482276917
[15/24] Train loss=0.01994517259299755
[20/24] Train loss=0.015420923009514809
Test set avg_accuracy=88.44% avg_sensitivity=75.45%, avg_specificity=93.05% avg_auc=93.70%
Fold[6] Epoch: 87 [87/100 (87%)] Train loss=0.022704 Test loss=0.804714 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.024132562801241875
[5/24] Train loss=0.018515052273869514
[10/24] Train loss=0.02010413631796837
[15/24] Train loss=0.026568351313471794
[20/24] Train loss=0.01832554116845131
Test set avg_accuracy=88.42% avg_sensitivity=75.70%, avg_specificity=92.94% avg_auc=93.72%
Fold[6] Epoch: 88 [88/100 (88%)] Train loss=0.022270 Test loss=0.815117 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.024953393265604973
[5/24] Train loss=0.023739291355013847
[10/24] Train loss=0.021129142493009567
[15/24] Train loss=0.019081782549619675
[20/24] Train loss=0.015714220702648163
Test set avg_accuracy=88.52% avg_sensitivity=75.84%, avg_specificity=93.01% avg_auc=93.72%
Fold[6] Epoch: 89 [89/100 (89%)] Train loss=0.020832 Test loss=0.815694 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.016008203849196434
[5/24] Train loss=0.021001508459448814
[10/24] Train loss=0.027893293648958206
[15/24] Train loss=0.015000395476818085
[20/24] Train loss=0.018717629835009575
Test set avg_accuracy=88.54% avg_sensitivity=75.70%, avg_specificity=93.10% avg_auc=93.72%
Fold[6] Epoch: 90 [90/100 (90%)] Train loss=0.021487 Test loss=0.819304 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.01957527920603752
[5/24] Train loss=0.02176530286669731
[10/24] Train loss=0.023120613768696785
[15/24] Train loss=0.01591922529041767
[20/24] Train loss=0.019082730636000633
Test set avg_accuracy=88.50% avg_sensitivity=75.65%, avg_specificity=93.07% avg_auc=93.72%
Fold[6] Epoch: 91 [91/100 (91%)] Train loss=0.021025 Test loss=0.821216 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.02024088054895401
[5/24] Train loss=0.022255176678299904
[10/24] Train loss=0.026557553559541702
[15/24] Train loss=0.017983727157115936
[20/24] Train loss=0.013120993971824646
Test set avg_accuracy=88.59% avg_sensitivity=75.84%, avg_specificity=93.12% avg_auc=93.74%
Fold[6] Epoch: 92 [92/100 (92%)] Train loss=0.020705 Test loss=0.822411 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.014461933635175228
[5/24] Train loss=0.01977887563407421
[10/24] Train loss=0.019752901047468185
[15/24] Train loss=0.021484360098838806
[20/24] Train loss=0.01429713238030672
Test set avg_accuracy=88.53% avg_sensitivity=75.70%, avg_specificity=93.08% avg_auc=93.75%
Fold[6] Epoch: 93 [93/100 (93%)] Train loss=0.020466 Test loss=0.822750 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.01674477383494377
[5/24] Train loss=0.020759034901857376
[10/24] Train loss=0.020755087956786156
[15/24] Train loss=0.015516282990574837
[20/24] Train loss=0.017650747671723366
Test set avg_accuracy=88.58% avg_sensitivity=75.89%, avg_specificity=93.08% avg_auc=93.76%
Fold[6] Epoch: 94 [94/100 (94%)] Train loss=0.020493 Test loss=0.822508 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.021306432783603668
[5/24] Train loss=0.027201903983950615
[10/24] Train loss=0.03006328083574772
[15/24] Train loss=0.02493736520409584
[20/24] Train loss=0.015670811757445335
Test set avg_accuracy=88.53% avg_sensitivity=75.70%, avg_specificity=93.08% avg_auc=93.76%
Fold[6] Epoch: 95 [95/100 (95%)] Train loss=0.020870 Test loss=0.821245 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.021352702751755714
[5/24] Train loss=0.023001108318567276
[10/24] Train loss=0.02226210944354534
[15/24] Train loss=0.01332905888557434
[20/24] Train loss=0.016332633793354034
Test set avg_accuracy=88.48% avg_sensitivity=75.50%, avg_specificity=93.08% avg_auc=93.76%
Fold[6] Epoch: 96 [96/100 (96%)] Train loss=0.020480 Test loss=0.820967 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.019650153815746307
[5/24] Train loss=0.016168832778930664
[10/24] Train loss=0.016828371211886406
[15/24] Train loss=0.01837071403861046
[20/24] Train loss=0.02193625457584858
Test set avg_accuracy=88.50% avg_sensitivity=75.60%, avg_specificity=93.08% avg_auc=93.75%
Fold[6] Epoch: 97 [97/100 (97%)] Train loss=0.019754 Test loss=0.822262 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.021336644887924194
[5/24] Train loss=0.012735186144709587
[10/24] Train loss=0.013409222476184368
[15/24] Train loss=0.02289568819105625
[20/24] Train loss=0.024933824315667152
Test set avg_accuracy=88.52% avg_sensitivity=75.60%, avg_specificity=93.10% avg_auc=93.75%
Fold[6] Epoch: 98 [98/100 (98%)] Train loss=0.020912 Test loss=0.822057 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.02226390317082405
[5/24] Train loss=0.018411150202155113
[10/24] Train loss=0.01818174682557583
[15/24] Train loss=0.014164064079523087
[20/24] Train loss=0.02318967692553997
Test set avg_accuracy=88.52% avg_sensitivity=75.60%, avg_specificity=93.10% avg_auc=93.75%
Fold[6] Epoch: 99 [99/100 (99%)] Train loss=0.020588 Test loss=0.822415 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.016532963141798973
[5/24] Train loss=0.01941106468439102
[10/24] Train loss=0.014971503987908363
[15/24] Train loss=0.020803477615118027
[20/24] Train loss=0.012836767360568047
Test set avg_accuracy=88.52% avg_sensitivity=75.60%, avg_specificity=93.10% avg_auc=93.75%
Fold[6] Epoch: 100 [100/100 (100%)] Train loss=0.020405 Test loss=0.822095 Current lr=[4.874217159761039e-09]

Fold[6] Result: acc=89.84% sen=76.69%, spe=94.51%, auc=94.85%!
Fold[6] Avg_overlap=0.73%(Â±0.20586705464501567)
[0/24] Train loss=1.4156787395477295
[5/24] Train loss=1.2817555665969849
[10/24] Train loss=1.2752774953842163
[15/24] Train loss=1.0752567052841187
[20/24] Train loss=1.0341383218765259
Test set avg_accuracy=75.92% avg_sensitivity=28.23%, avg_specificity=93.84% avg_auc=79.83%
Best model saved!! Metric=79.83428387371535!!
Fold[7] Epoch: 1 [1/100 (1%)] Train loss=1.208698 Test loss=0.573076 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=0.9856777787208557
[5/24] Train loss=0.8920606374740601
[10/24] Train loss=0.9983912110328674
[15/24] Train loss=0.8747275471687317
[20/24] Train loss=0.8836638331413269
Test set avg_accuracy=81.97% avg_sensitivity=62.33%, avg_specificity=89.34% avg_auc=86.72%
Best model saved!! Metric=86.72189427148342!!
Fold[7] Epoch: 2 [2/100 (2%)] Train loss=0.946140 Test loss=0.482187 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8560180068016052
[5/24] Train loss=0.8487101793289185
[10/24] Train loss=0.9088366031646729
[15/24] Train loss=0.8171547651290894
[20/24] Train loss=0.8001289367675781
Test set avg_accuracy=84.82% avg_sensitivity=69.62%, avg_specificity=90.52% avg_auc=88.65%
Best model saved!! Metric=88.64538792100927!!
Fold[7] Epoch: 3 [3/100 (3%)] Train loss=0.858169 Test loss=0.417015 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.8250452876091003
[5/24] Train loss=0.7617256045341492
[10/24] Train loss=0.8145869374275208
[15/24] Train loss=0.7804164290428162
[20/24] Train loss=0.7328969240188599
Test set avg_accuracy=86.28% avg_sensitivity=76.73%, avg_specificity=89.86% avg_auc=91.31%
Best model saved!! Metric=91.31005280267411!!
Fold[7] Epoch: 4 [4/100 (4%)] Train loss=0.805425 Test loss=0.365129 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.8157060146331787
[5/24] Train loss=0.7586517930030823
[10/24] Train loss=0.8125610947608948
[15/24] Train loss=0.771864116191864
[20/24] Train loss=0.7076871991157532
Test set avg_accuracy=84.71% avg_sensitivity=85.07%, avg_specificity=84.58% avg_auc=92.72%
Best model saved!! Metric=92.71554315671996!!
Fold[7] Epoch: 5 [5/100 (5%)] Train loss=0.774340 Test loss=0.390507 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.7551266551017761
[5/24] Train loss=0.710790753364563
[10/24] Train loss=0.7737025618553162
[15/24] Train loss=0.7656367421150208
[20/24] Train loss=0.6788095831871033
Test set avg_accuracy=86.67% avg_sensitivity=81.83%, avg_specificity=88.48% avg_auc=93.18%
Best model saved!! Metric=93.18315162581825!!
Fold[7] Epoch: 6 [6/100 (6%)] Train loss=0.731346 Test loss=0.341943 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.7148199081420898
[5/24] Train loss=0.6701224446296692
[10/24] Train loss=0.7560641765594482
[15/24] Train loss=0.7449371814727783
[20/24] Train loss=0.6397836208343506
Test set avg_accuracy=86.78% avg_sensitivity=81.40%, avg_specificity=88.81% avg_auc=93.48%
Best model saved!! Metric=93.47595410859198!!
Fold[7] Epoch: 7 [7/100 (7%)] Train loss=0.704948 Test loss=0.331845 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.6882755756378174
[5/24] Train loss=0.6527725458145142
[10/24] Train loss=0.7531129717826843
[15/24] Train loss=0.7565990686416626
[20/24] Train loss=0.634933352470398
Test set avg_accuracy=87.96% avg_sensitivity=76.49%, avg_specificity=92.26% avg_auc=93.53%
Best model saved!! Metric=93.53339566917111!!
Fold[7] Epoch: 8 [8/100 (8%)] Train loss=0.688745 Test loss=0.304961 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.6886399984359741
[5/24] Train loss=0.6261271238327026
[10/24] Train loss=0.7752037644386292
[15/24] Train loss=0.698197603225708
[20/24] Train loss=0.6478849053382874
Test set avg_accuracy=88.14% avg_sensitivity=77.40%, avg_specificity=92.17% avg_auc=93.39%
Fold[7] Epoch: 9 [9/100 (9%)] Train loss=0.679217 Test loss=0.306813 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6637089252471924
[5/24] Train loss=0.6210511922836304
[10/24] Train loss=0.732801616191864
[15/24] Train loss=0.6886439323425293
[20/24] Train loss=0.6138423085212708
Test set avg_accuracy=87.38% avg_sensitivity=82.21%, avg_specificity=89.32% avg_auc=93.79%
Best model saved!! Metric=93.78885473144639!!
Fold[7] Epoch: 10 [10/100 (10%)] Train loss=0.659645 Test loss=0.319218 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.6488406658172607
[5/24] Train loss=0.5994499325752258
[10/24] Train loss=0.69676274061203
[15/24] Train loss=0.692380964756012
[20/24] Train loss=0.6314276456832886
Test set avg_accuracy=87.96% avg_sensitivity=83.60%, avg_specificity=89.59% avg_auc=94.19%
Best model saved!! Metric=94.19254291525186!!
Fold[7] Epoch: 11 [11/100 (11%)] Train loss=0.646211 Test loss=0.313013 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.6028996109962463
[5/24] Train loss=0.568372368812561
[10/24] Train loss=0.682591438293457
[15/24] Train loss=0.6470171213150024
[20/24] Train loss=0.5889254808425903
Test set avg_accuracy=88.66% avg_sensitivity=83.36%, avg_specificity=90.65% avg_auc=94.64%
Best model saved!! Metric=94.64332890798427!!
Fold[7] Epoch: 12 [12/100 (12%)] Train loss=0.636029 Test loss=0.283698 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.6128458976745605
[5/24] Train loss=0.5479414463043213
[10/24] Train loss=0.6759997010231018
[15/24] Train loss=0.60628342628479
[20/24] Train loss=0.5947060585021973
Test set avg_accuracy=89.53% avg_sensitivity=82.16%, avg_specificity=92.30% avg_auc=94.90%
Best model saved!! Metric=94.90003502867508!!
Fold[7] Epoch: 13 [13/100 (13%)] Train loss=0.618881 Test loss=0.265858 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.6047061681747437
[5/24] Train loss=0.566991925239563
[10/24] Train loss=0.7309194207191467
[15/24] Train loss=0.6165951490402222
[20/24] Train loss=0.5594993829727173
Test set avg_accuracy=89.87% avg_sensitivity=74.49%, avg_specificity=95.65% avg_auc=94.83%
Fold[7] Epoch: 14 [14/100 (14%)] Train loss=0.615302 Test loss=0.257610 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.5867562294006348
[5/24] Train loss=0.5545783042907715
[10/24] Train loss=0.6888955235481262
[15/24] Train loss=0.621042013168335
[20/24] Train loss=0.5361682176589966
Test set avg_accuracy=89.26% avg_sensitivity=67.81%, avg_specificity=97.31% avg_auc=94.81%
Fold[7] Epoch: 15 [15/100 (15%)] Train loss=0.608898 Test loss=0.272934 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.6329487562179565
[5/24] Train loss=0.5809208154678345
[10/24] Train loss=0.62189781665802
[15/24] Train loss=0.6350980401039124
[20/24] Train loss=0.5564384460449219
Test set avg_accuracy=89.67% avg_sensitivity=72.77%, avg_specificity=96.02% avg_auc=95.16%
Best model saved!! Metric=95.16491536103496!!
Fold[7] Epoch: 16 [16/100 (16%)] Train loss=0.605661 Test loss=0.250739 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5846030116081238
[5/24] Train loss=0.5560571551322937
[10/24] Train loss=0.6318908929824829
[15/24] Train loss=0.625027596950531
[20/24] Train loss=0.5430994033813477
Test set avg_accuracy=90.07% avg_sensitivity=80.69%, avg_specificity=93.59% avg_auc=95.18%
Best model saved!! Metric=95.1768222064546!!
Fold[7] Epoch: 17 [17/100 (17%)] Train loss=0.598256 Test loss=0.252859 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.6071755886077881
[5/24] Train loss=0.5367093682289124
[10/24] Train loss=0.6575136780738831
[15/24] Train loss=0.6357553005218506
[20/24] Train loss=0.5786182880401611
Test set avg_accuracy=89.18% avg_sensitivity=83.74%, avg_specificity=91.22% avg_auc=94.98%
Fold[7] Epoch: 18 [18/100 (18%)] Train loss=0.600885 Test loss=0.269116 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.5785636305809021
[5/24] Train loss=0.5678980946540833
[10/24] Train loss=0.6545695066452026
[15/24] Train loss=0.6057328581809998
[20/24] Train loss=0.5391817092895508
Test set avg_accuracy=90.30% avg_sensitivity=76.01%, avg_specificity=95.67% avg_auc=95.18%
Best model saved!! Metric=95.1779582254222!!
Fold[7] Epoch: 19 [19/100 (19%)] Train loss=0.589437 Test loss=0.248038 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5658662915229797
[5/24] Train loss=0.5634915828704834
[10/24] Train loss=0.597352147102356
[15/24] Train loss=0.6008448600769043
[20/24] Train loss=0.5329846739768982
Test set avg_accuracy=90.22% avg_sensitivity=75.54%, avg_specificity=95.74% avg_auc=95.10%
Fold[7] Epoch: 20 [20/100 (20%)] Train loss=0.573926 Test loss=0.246191 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5603823661804199
[5/24] Train loss=0.522004246711731
[10/24] Train loss=0.6310204863548279
[15/24] Train loss=0.5614733695983887
[20/24] Train loss=0.5442456007003784
Test set avg_accuracy=89.93% avg_sensitivity=80.02%, avg_specificity=93.66% avg_auc=94.89%
Fold[7] Epoch: 21 [21/100 (21%)] Train loss=0.563733 Test loss=0.255321 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.5530168414115906
[5/24] Train loss=0.5699337124824524
[10/24] Train loss=0.627043604850769
[15/24] Train loss=0.571435272693634
[20/24] Train loss=0.5421923398971558
Test set avg_accuracy=89.79% avg_sensitivity=76.39%, avg_specificity=94.82% avg_auc=95.15%
Fold[7] Epoch: 22 [22/100 (22%)] Train loss=0.559164 Test loss=0.249004 Current lr=[0.000842324016282456]

[0/24] Train loss=0.5343947410583496
[5/24] Train loss=0.5279417634010315
[10/24] Train loss=0.627187967300415
[15/24] Train loss=0.5624777674674988
[20/24] Train loss=0.51753830909729
Test set avg_accuracy=89.30% avg_sensitivity=77.73%, avg_specificity=93.64% avg_auc=95.04%
Fold[7] Epoch: 23 [23/100 (23%)] Train loss=0.552663 Test loss=0.251067 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5026184320449829
[5/24] Train loss=0.5177187323570251
[10/24] Train loss=0.572494387626648
[15/24] Train loss=0.5507760643959045
[20/24] Train loss=0.5155324339866638
Test set avg_accuracy=90.40% avg_sensitivity=78.54%, avg_specificity=94.86% avg_auc=95.27%
Best model saved!! Metric=95.26514127506258!!
Fold[7] Epoch: 24 [24/100 (24%)] Train loss=0.543570 Test loss=0.244971 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.5241833925247192
[5/24] Train loss=0.4997903108596802
[10/24] Train loss=0.5525610446929932
[15/24] Train loss=0.600917637348175
[20/24] Train loss=0.4779938757419586
Test set avg_accuracy=89.58% avg_sensitivity=72.44%, avg_specificity=96.02% avg_auc=95.14%
Fold[7] Epoch: 25 [25/100 (25%)] Train loss=0.530313 Test loss=0.258873 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.5203248262405396
[5/24] Train loss=0.4893016815185547
[10/24] Train loss=0.5632899403572083
[15/24] Train loss=0.5505977869033813
[20/24] Train loss=0.4936859607696533
Test set avg_accuracy=90.31% avg_sensitivity=77.44%, avg_specificity=95.15% avg_auc=95.30%
Best model saved!! Metric=95.30248469556099!!
Fold[7] Epoch: 26 [26/100 (26%)] Train loss=0.515648 Test loss=0.246800 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.4949398934841156
[5/24] Train loss=0.46570175886154175
[10/24] Train loss=0.5373542904853821
[15/24] Train loss=0.531005322933197
[20/24] Train loss=0.46975812315940857
Test set avg_accuracy=89.92% avg_sensitivity=75.39%, avg_specificity=95.38% avg_auc=95.06%
Fold[7] Epoch: 27 [27/100 (27%)] Train loss=0.505435 Test loss=0.254066 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.5158879160881042
[5/24] Train loss=0.46701812744140625
[10/24] Train loss=0.49321067333221436
[15/24] Train loss=0.4811350107192993
[20/24] Train loss=0.4370987117290497
Test set avg_accuracy=89.36% avg_sensitivity=68.91%, avg_specificity=97.04% avg_auc=94.71%
Fold[7] Epoch: 28 [28/100 (28%)] Train loss=0.487768 Test loss=0.278058 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.5082084536552429
[5/24] Train loss=0.45037195086479187
[10/24] Train loss=0.5000708699226379
[15/24] Train loss=0.4968084394931793
[20/24] Train loss=0.41092807054519653
Test set avg_accuracy=88.98% avg_sensitivity=70.24%, avg_specificity=96.02% avg_auc=94.53%
Fold[7] Epoch: 29 [29/100 (29%)] Train loss=0.474894 Test loss=0.275378 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.4927103817462921
[5/24] Train loss=0.44492095708847046
[10/24] Train loss=0.4782085716724396
[15/24] Train loss=0.4506428837776184
[20/24] Train loss=0.4234635829925537
Test set avg_accuracy=88.82% avg_sensitivity=67.86%, avg_specificity=96.69% avg_auc=94.06%
Fold[7] Epoch: 30 [30/100 (30%)] Train loss=0.463889 Test loss=0.299070 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.47968557476997375
[5/24] Train loss=0.44197455048561096
[10/24] Train loss=0.5400813221931458
[15/24] Train loss=0.46726447343826294
[20/24] Train loss=0.4287138879299164
Test set avg_accuracy=89.23% avg_sensitivity=70.96%, avg_specificity=96.10% avg_auc=94.91%
Fold[7] Epoch: 31 [31/100 (31%)] Train loss=0.489686 Test loss=0.269951 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.49503588676452637
[5/24] Train loss=0.41569045186042786
[10/24] Train loss=0.44180265069007874
[15/24] Train loss=0.4518772065639496
[20/24] Train loss=0.4069296419620514
Test set avg_accuracy=88.74% avg_sensitivity=70.67%, avg_specificity=95.52% avg_auc=94.34%
Fold[7] Epoch: 32 [32/100 (32%)] Train loss=0.458007 Test loss=0.296243 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.47152870893478394
[5/24] Train loss=0.46958568692207336
[10/24] Train loss=0.4399666488170624
[15/24] Train loss=0.42985281348228455
[20/24] Train loss=0.3903554081916809
Test set avg_accuracy=89.04% avg_sensitivity=74.20%, avg_specificity=94.61% avg_auc=94.45%
Fold[7] Epoch: 33 [33/100 (33%)] Train loss=0.438120 Test loss=0.285788 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.43204444646835327
[5/24] Train loss=0.39163637161254883
[10/24] Train loss=0.4481140077114105
[15/24] Train loss=0.40051010251045227
[20/24] Train loss=0.3436676859855652
Test set avg_accuracy=89.74% avg_sensitivity=72.06%, avg_specificity=96.38% avg_auc=94.78%
Fold[7] Epoch: 34 [34/100 (34%)] Train loss=0.415776 Test loss=0.277177 Current lr=[0.000991797016730875]

[0/24] Train loss=0.4025607705116272
[5/24] Train loss=0.34554705023765564
[10/24] Train loss=0.3936159908771515
[15/24] Train loss=0.36833855509757996
[20/24] Train loss=0.3745066523551941
Test set avg_accuracy=89.36% avg_sensitivity=71.29%, avg_specificity=96.15% avg_auc=94.83%
Fold[7] Epoch: 35 [35/100 (35%)] Train loss=0.397850 Test loss=0.272948 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.3885522484779358
[5/24] Train loss=0.35595443844795227
[10/24] Train loss=0.3496705889701843
[15/24] Train loss=0.3562757670879364
[20/24] Train loss=0.3320915400981903
Test set avg_accuracy=88.02% avg_sensitivity=62.47%, avg_specificity=97.62% avg_auc=93.35%
Fold[7] Epoch: 36 [36/100 (36%)] Train loss=0.377330 Test loss=0.358824 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.4363720118999481
[5/24] Train loss=0.33083033561706543
[10/24] Train loss=0.3596867322921753
[15/24] Train loss=0.3513885736465454
[20/24] Train loss=0.3126077950000763
Test set avg_accuracy=88.84% avg_sensitivity=69.43%, avg_specificity=96.13% avg_auc=94.34%
Fold[7] Epoch: 37 [37/100 (37%)] Train loss=0.371231 Test loss=0.301729 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.33741623163223267
[5/24] Train loss=0.3276205062866211
[10/24] Train loss=0.37588268518447876
[15/24] Train loss=0.32024407386779785
[20/24] Train loss=0.32243427634239197
Test set avg_accuracy=88.33% avg_sensitivity=67.05%, avg_specificity=96.33% avg_auc=93.60%
Fold[7] Epoch: 38 [38/100 (38%)] Train loss=0.349359 Test loss=0.358022 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.3508458137512207
[5/24] Train loss=0.3569563627243042
[10/24] Train loss=0.31241196393966675
[15/24] Train loss=0.30681750178337097
[20/24] Train loss=0.2947196364402771
Test set avg_accuracy=88.44% avg_sensitivity=69.34%, avg_specificity=95.61% avg_auc=94.13%
Fold[7] Epoch: 39 [39/100 (39%)] Train loss=0.332620 Test loss=0.327163 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.3050854504108429
[5/24] Train loss=0.33110955357551575
[10/24] Train loss=0.3715708553791046
[15/24] Train loss=0.3223698139190674
[20/24] Train loss=0.341482013463974
Test set avg_accuracy=88.92% avg_sensitivity=78.06%, avg_specificity=93.00% avg_auc=94.06%
Fold[7] Epoch: 40 [40/100 (40%)] Train loss=0.340106 Test loss=0.313032 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.3457072973251343
[5/24] Train loss=0.2998044490814209
[10/24] Train loss=0.3965287208557129
[15/24] Train loss=0.29688048362731934
[20/24] Train loss=0.32048994302749634
Test set avg_accuracy=88.46% avg_sensitivity=72.39%, avg_specificity=94.50% avg_auc=94.11%
Fold[7] Epoch: 41 [41/100 (41%)] Train loss=0.347925 Test loss=0.344588 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.3314640522003174
[5/24] Train loss=0.2754512429237366
[10/24] Train loss=0.3082830011844635
[15/24] Train loss=0.3132801353931427
[20/24] Train loss=0.3332131803035736
Test set avg_accuracy=88.84% avg_sensitivity=78.73%, avg_specificity=92.64% avg_auc=94.05%
Fold[7] Epoch: 42 [42/100 (42%)] Train loss=0.328742 Test loss=0.320167 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.30478549003601074
[5/24] Train loss=0.24766990542411804
[10/24] Train loss=0.39210042357444763
[15/24] Train loss=0.3065515458583832
[20/24] Train loss=0.2730027139186859
Test set avg_accuracy=88.80% avg_sensitivity=81.69%, avg_specificity=91.47% avg_auc=94.42%
Fold[7] Epoch: 43 [43/100 (43%)] Train loss=0.314739 Test loss=0.294874 Current lr=[0.000916771143003274]

[0/24] Train loss=0.298048734664917
[5/24] Train loss=0.25441211462020874
[10/24] Train loss=0.29749611020088196
[15/24] Train loss=0.2434375137090683
[20/24] Train loss=0.3687068223953247
Test set avg_accuracy=88.58% avg_sensitivity=81.12%, avg_specificity=91.38% avg_auc=93.82%
Fold[7] Epoch: 44 [44/100 (44%)] Train loss=0.293541 Test loss=0.324543 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.3447350263595581
[5/24] Train loss=0.26124632358551025
[10/24] Train loss=0.28843995928764343
[15/24] Train loss=0.27822643518447876
[20/24] Train loss=0.2579633295536041
Test set avg_accuracy=87.40% avg_sensitivity=73.96%, avg_specificity=92.44% avg_auc=93.28%
Fold[7] Epoch: 45 [45/100 (45%)] Train loss=0.284792 Test loss=0.365176 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.25606459379196167
[5/24] Train loss=0.2136019915342331
[10/24] Train loss=0.2670442759990692
[15/24] Train loss=0.24502958357334137
[20/24] Train loss=0.2013324797153473
Test set avg_accuracy=88.52% avg_sensitivity=74.15%, avg_specificity=93.91% avg_auc=93.54%
Fold[7] Epoch: 46 [46/100 (46%)] Train loss=0.263156 Test loss=0.340983 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.24502789974212646
[5/24] Train loss=0.2247319370508194
[10/24] Train loss=0.2506348490715027
[15/24] Train loss=0.20493391156196594
[20/24] Train loss=0.19287602603435516
Test set avg_accuracy=88.05% avg_sensitivity=81.93%, avg_specificity=90.35% avg_auc=93.71%
Fold[7] Epoch: 47 [47/100 (47%)] Train loss=0.236954 Test loss=0.355946 Current lr=[0.000860751215339601]

[0/24] Train loss=0.24927303194999695
[5/24] Train loss=0.16181017458438873
[10/24] Train loss=0.20161591470241547
[15/24] Train loss=0.17876338958740234
[20/24] Train loss=0.204294815659523
Test set avg_accuracy=88.72% avg_sensitivity=84.07%, avg_specificity=90.47% avg_auc=94.19%
Fold[7] Epoch: 48 [48/100 (48%)] Train loss=0.208316 Test loss=0.381784 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.21045365929603577
[5/24] Train loss=0.17449869215488434
[10/24] Train loss=0.18549878895282745
[15/24] Train loss=0.17678189277648926
[20/24] Train loss=0.15842145681381226
Test set avg_accuracy=88.74% avg_sensitivity=85.74%, avg_specificity=89.86% avg_auc=94.21%
Fold[7] Epoch: 49 [49/100 (49%)] Train loss=0.189314 Test loss=0.396326 Current lr=[0.000828265354963756]

[0/24] Train loss=0.16851982474327087
[5/24] Train loss=0.1546293944120407
[10/24] Train loss=0.19941404461860657
[15/24] Train loss=0.15097402036190033
[20/24] Train loss=0.19100038707256317
Test set avg_accuracy=89.24% avg_sensitivity=83.45%, avg_specificity=91.42% avg_auc=94.09%
Fold[7] Epoch: 50 [50/100 (50%)] Train loss=0.181624 Test loss=0.375085 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.16043685376644135
[5/24] Train loss=0.15589815378189087
[10/24] Train loss=0.1775728017091751
[15/24] Train loss=0.15003465116024017
[20/24] Train loss=0.1490512490272522
Test set avg_accuracy=89.11% avg_sensitivity=87.22%, avg_specificity=89.83% avg_auc=94.30%
Fold[7] Epoch: 51 [51/100 (51%)] Train loss=0.161512 Test loss=0.424355 Current lr=[0.00079313651106947]

[0/24] Train loss=0.16390705108642578
[5/24] Train loss=0.11488782614469528
[10/24] Train loss=0.13565760850906372
[15/24] Train loss=0.1763274222612381
[20/24] Train loss=0.14725914597511292
Test set avg_accuracy=88.79% avg_sensitivity=81.64%, avg_specificity=91.47% avg_auc=94.11%
Fold[7] Epoch: 52 [52/100 (52%)] Train loss=0.157073 Test loss=0.381422 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.13644228875637054
[5/24] Train loss=0.12080471962690353
[10/24] Train loss=0.13984952867031097
[15/24] Train loss=0.15629842877388
[20/24] Train loss=0.12186401337385178
Test set avg_accuracy=88.88% avg_sensitivity=73.44%, avg_specificity=94.68% avg_auc=93.69%
Fold[7] Epoch: 53 [53/100 (53%)] Train loss=0.140434 Test loss=0.420101 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.13546016812324524
[5/24] Train loss=0.11119701713323593
[10/24] Train loss=0.1254401057958603
[15/24] Train loss=0.09690111875534058
[20/24] Train loss=0.10598202794790268
Test set avg_accuracy=88.80% avg_sensitivity=72.77%, avg_specificity=94.82% avg_auc=93.76%
Fold[7] Epoch: 54 [54/100 (54%)] Train loss=0.127833 Test loss=0.481665 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.1608404815196991
[5/24] Train loss=0.1272924244403839
[10/24] Train loss=0.12796719372272491
[15/24] Train loss=0.0986444503068924
[20/24] Train loss=0.10319139808416367
Test set avg_accuracy=88.68% avg_sensitivity=76.35%, avg_specificity=93.32% avg_auc=93.65%
Fold[7] Epoch: 55 [55/100 (55%)] Train loss=0.117647 Test loss=0.466726 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.12041245400905609
[5/24] Train loss=0.09290941804647446
[10/24] Train loss=0.09719055891036987
[15/24] Train loss=0.11176513880491257
[20/24] Train loss=0.11148888617753983
Test set avg_accuracy=89.00% avg_sensitivity=78.83%, avg_specificity=92.82% avg_auc=93.62%
Fold[7] Epoch: 56 [56/100 (56%)] Train loss=0.106085 Test loss=0.475241 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.11119891703128815
[5/24] Train loss=0.08971306681632996
[10/24] Train loss=0.10388261824846268
[15/24] Train loss=0.08405838161706924
[20/24] Train loss=0.08638866245746613
Test set avg_accuracy=89.11% avg_sensitivity=78.64%, avg_specificity=93.05% avg_auc=93.65%
Fold[7] Epoch: 57 [57/100 (57%)] Train loss=0.096232 Test loss=0.490388 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.08821859955787659
[5/24] Train loss=0.06217873468995094
[10/24] Train loss=0.1074175089597702
[15/24] Train loss=0.07505322247743607
[20/24] Train loss=0.09602285176515579
Test set avg_accuracy=89.01% avg_sensitivity=76.92%, avg_specificity=93.55% avg_auc=93.83%
Fold[7] Epoch: 58 [58/100 (58%)] Train loss=0.088611 Test loss=0.498662 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.08535947650671005
[5/24] Train loss=0.0767836645245552
[10/24] Train loss=0.08848617970943451
[15/24] Train loss=0.08770063519477844
[20/24] Train loss=0.07985612004995346
Test set avg_accuracy=89.00% avg_sensitivity=74.11%, avg_specificity=94.59% avg_auc=93.85%
Fold[7] Epoch: 59 [59/100 (59%)] Train loss=0.084233 Test loss=0.525613 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.0902579054236412
[5/24] Train loss=0.0518607422709465
[10/24] Train loss=0.0720210149884224
[15/24] Train loss=0.0763302892446518
[20/24] Train loss=0.07440230995416641
Test set avg_accuracy=89.21% avg_sensitivity=73.92%, avg_specificity=94.95% avg_auc=94.13%
Fold[7] Epoch: 60 [60/100 (60%)] Train loss=0.077602 Test loss=0.508470 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.06882166117429733
[5/24] Train loss=0.0642416849732399
[10/24] Train loss=0.07361124455928802
[15/24] Train loss=0.06281926482915878
[20/24] Train loss=0.06306587159633636
Test set avg_accuracy=89.04% avg_sensitivity=76.35%, avg_specificity=93.80% avg_auc=94.25%
Fold[7] Epoch: 61 [61/100 (61%)] Train loss=0.068579 Test loss=0.499026 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.06137891858816147
[5/24] Train loss=0.06369154900312424
[10/24] Train loss=0.06040056049823761
[15/24] Train loss=0.0529792346060276
[20/24] Train loss=0.0736197754740715
Test set avg_accuracy=89.38% avg_sensitivity=76.25%, avg_specificity=94.30% avg_auc=94.11%
Fold[7] Epoch: 62 [62/100 (62%)] Train loss=0.063659 Test loss=0.518827 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.06403150409460068
[5/24] Train loss=0.04828951507806778
[10/24] Train loss=0.047490086406469345
[15/24] Train loss=0.0706801638007164
[20/24] Train loss=0.05956193059682846
Test set avg_accuracy=89.02% avg_sensitivity=76.35%, avg_specificity=93.78% avg_auc=94.18%
Fold[7] Epoch: 63 [63/100 (63%)] Train loss=0.059780 Test loss=0.495841 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.06006573885679245
[5/24] Train loss=0.046202678233385086
[10/24] Train loss=0.05286233127117157
[15/24] Train loss=0.04525795951485634
[20/24] Train loss=0.05512818694114685
Test set avg_accuracy=89.75% avg_sensitivity=80.02%, avg_specificity=93.41% avg_auc=94.39%
Fold[7] Epoch: 64 [64/100 (64%)] Train loss=0.053203 Test loss=0.532343 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.059437599033117294
[5/24] Train loss=0.05401036888360977
[10/24] Train loss=0.046736329793930054
[15/24] Train loss=0.048145994544029236
[20/24] Train loss=0.05440927669405937
Test set avg_accuracy=89.23% avg_sensitivity=79.07%, avg_specificity=93.05% avg_auc=94.38%
Fold[7] Epoch: 65 [65/100 (65%)] Train loss=0.050259 Test loss=0.565742 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.05436214804649353
[5/24] Train loss=0.04549587145447731
[10/24] Train loss=0.04970331862568855
[15/24] Train loss=0.04009072482585907
[20/24] Train loss=0.04852217063307762
Test set avg_accuracy=89.60% avg_sensitivity=79.40%, avg_specificity=93.43% avg_auc=94.43%
Fold[7] Epoch: 66 [66/100 (66%)] Train loss=0.046844 Test loss=0.546856 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.04905814304947853
[5/24] Train loss=0.054108183830976486
[10/24] Train loss=0.03762953728437424
[15/24] Train loss=0.0336972177028656
[20/24] Train loss=0.04070607200264931
Test set avg_accuracy=89.91% avg_sensitivity=79.35%, avg_specificity=93.87% avg_auc=94.49%
Fold[7] Epoch: 67 [67/100 (67%)] Train loss=0.043354 Test loss=0.607015 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.04144885763525963
[5/24] Train loss=0.02879350259900093
[10/24] Train loss=0.05174436420202255
[15/24] Train loss=0.02402578666806221
[20/24] Train loss=0.039943013340234756
Test set avg_accuracy=89.80% avg_sensitivity=75.82%, avg_specificity=95.06% avg_auc=94.47%
Fold[7] Epoch: 68 [68/100 (68%)] Train loss=0.038993 Test loss=0.560680 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.03730865195393562
[5/24] Train loss=0.031075559556484222
[10/24] Train loss=0.03448251262307167
[15/24] Train loss=0.037536513060331345
[20/24] Train loss=0.02755538374185562
Test set avg_accuracy=89.34% avg_sensitivity=74.82%, avg_specificity=94.79% avg_auc=94.25%
Fold[7] Epoch: 69 [69/100 (69%)] Train loss=0.034571 Test loss=0.585786 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.03193715959787369
[5/24] Train loss=0.03247907757759094
[10/24] Train loss=0.03556768223643303
[15/24] Train loss=0.03325839340686798
[20/24] Train loss=0.02815949358046055
Test set avg_accuracy=89.44% avg_sensitivity=73.92%, avg_specificity=95.27% avg_auc=94.40%
Fold[7] Epoch: 70 [70/100 (70%)] Train loss=0.032445 Test loss=0.593723 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.029950181022286415
[5/24] Train loss=0.028300398960709572
[10/24] Train loss=0.02018626593053341
[15/24] Train loss=0.024212144315242767
[20/24] Train loss=0.02980099990963936
Test set avg_accuracy=89.73% avg_sensitivity=76.39%, avg_specificity=94.73% avg_auc=94.39%
Fold[7] Epoch: 71 [71/100 (71%)] Train loss=0.028448 Test loss=0.604669 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.031155511736869812
[5/24] Train loss=0.027339555323123932
[10/24] Train loss=0.025412915274500847
[15/24] Train loss=0.03188571333885193
[20/24] Train loss=0.026842262595891953
Test set avg_accuracy=89.35% avg_sensitivity=75.97%, avg_specificity=94.38% avg_auc=94.36%
Fold[7] Epoch: 72 [72/100 (72%)] Train loss=0.028555 Test loss=0.595205 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.03267877176403999
[5/24] Train loss=0.02360834926366806
[10/24] Train loss=0.028550738468766212
[15/24] Train loss=0.023821521550416946
[20/24] Train loss=0.030748292803764343
Test set avg_accuracy=89.44% avg_sensitivity=75.82%, avg_specificity=94.55% avg_auc=94.41%
Fold[7] Epoch: 73 [73/100 (73%)] Train loss=0.027822 Test loss=0.591533 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.023550186306238174
[5/24] Train loss=0.030505556613206863
[10/24] Train loss=0.021578002721071243
[15/24] Train loss=0.025137629359960556
[20/24] Train loss=0.027262317016720772
Test set avg_accuracy=89.39% avg_sensitivity=75.06%, avg_specificity=94.77% avg_auc=94.37%
Fold[7] Epoch: 74 [74/100 (74%)] Train loss=0.026106 Test loss=0.608284 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.021155783906579018
[5/24] Train loss=0.025731703266501427
[10/24] Train loss=0.0191761814057827
[15/24] Train loss=0.016844678670167923
[20/24] Train loss=0.022270649671554565
Test set avg_accuracy=89.48% avg_sensitivity=75.39%, avg_specificity=94.77% avg_auc=94.38%
Fold[7] Epoch: 75 [75/100 (75%)] Train loss=0.023593 Test loss=0.672386 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.025502638891339302
[5/24] Train loss=0.02083774283528328
[10/24] Train loss=0.01817896030843258
[15/24] Train loss=0.01634618639945984
[20/24] Train loss=0.03169141337275505
Test set avg_accuracy=89.47% avg_sensitivity=75.77%, avg_specificity=94.61% avg_auc=94.41%
Fold[7] Epoch: 76 [76/100 (76%)] Train loss=0.023438 Test loss=0.677725 Current lr=[0.000262245679641298]

[0/24] Train loss=0.021901315078139305
[5/24] Train loss=0.018405470997095108
[10/24] Train loss=0.02255212515592575
[15/24] Train loss=0.021423766389489174
[20/24] Train loss=0.025627857074141502
Test set avg_accuracy=89.31% avg_sensitivity=75.54%, avg_specificity=94.48% avg_auc=94.41%
Fold[7] Epoch: 77 [77/100 (77%)] Train loss=0.022653 Test loss=0.639110 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.022041598334908485
[5/24] Train loss=0.01480781752616167
[10/24] Train loss=0.017057128250598907
[15/24] Train loss=0.019855057820677757
[20/24] Train loss=0.02600696310400963
Test set avg_accuracy=89.30% avg_sensitivity=75.06%, avg_specificity=94.64% avg_auc=94.43%
Fold[7] Epoch: 78 [78/100 (78%)] Train loss=0.021926 Test loss=0.636726 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.020166831091046333
[5/24] Train loss=0.011404469609260559
[10/24] Train loss=0.016174601390957832
[15/24] Train loss=0.016021639108657837
[20/24] Train loss=0.019230259582400322
Test set avg_accuracy=89.65% avg_sensitivity=77.21%, avg_specificity=94.32% avg_auc=94.50%
Fold[7] Epoch: 79 [79/100 (79%)] Train loss=0.020126 Test loss=0.684092 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.017642924562096596
[5/24] Train loss=0.015215144492685795
[10/24] Train loss=0.022312205284833908
[15/24] Train loss=0.015901586040854454
[20/24] Train loss=0.02186579443514347
Test set avg_accuracy=89.43% avg_sensitivity=75.58%, avg_specificity=94.63% avg_auc=94.51%
Fold[7] Epoch: 80 [80/100 (80%)] Train loss=0.021219 Test loss=0.617754 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.01942293904721737
[5/24] Train loss=0.018930934369564056
[10/24] Train loss=0.026722239330410957
[15/24] Train loss=0.012023050338029861
[20/24] Train loss=0.02255179174244404
Test set avg_accuracy=89.35% avg_sensitivity=76.11%, avg_specificity=94.32% avg_auc=94.54%
Fold[7] Epoch: 81 [81/100 (81%)] Train loss=0.019071 Test loss=0.634286 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.019202105700969696
[5/24] Train loss=0.014875398948788643
[10/24] Train loss=0.01940457709133625
[15/24] Train loss=0.013901995494961739
[20/24] Train loss=0.015488112345337868
Test set avg_accuracy=89.24% avg_sensitivity=76.30%, avg_specificity=94.11% avg_auc=94.51%
Fold[7] Epoch: 82 [82/100 (82%)] Train loss=0.017311 Test loss=0.653267 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.01434202678501606
[5/24] Train loss=0.016511643305420876
[10/24] Train loss=0.016882678493857384
[15/24] Train loss=0.011001314967870712
[20/24] Train loss=0.014233916066586971
Test set avg_accuracy=89.35% avg_sensitivity=76.82%, avg_specificity=94.05% avg_auc=94.51%
Fold[7] Epoch: 83 [83/100 (83%)] Train loss=0.018432 Test loss=0.666804 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.021819517016410828
[5/24] Train loss=0.012341958470642567
[10/24] Train loss=0.014599226415157318
[15/24] Train loss=0.015130950137972832
[20/24] Train loss=0.017135940492153168
Test set avg_accuracy=89.36% avg_sensitivity=76.59%, avg_specificity=94.16% avg_auc=94.52%
Fold[7] Epoch: 84 [84/100 (84%)] Train loss=0.016917 Test loss=0.652952 Current lr=[0.000122853263038123]

[0/24] Train loss=0.01554626040160656
[5/24] Train loss=0.01580023765563965
[10/24] Train loss=0.021416759118437767
[15/24] Train loss=0.011309741996228695
[20/24] Train loss=0.017187366262078285
Test set avg_accuracy=89.54% avg_sensitivity=76.73%, avg_specificity=94.36% avg_auc=94.55%
Fold[7] Epoch: 85 [85/100 (85%)] Train loss=0.018690 Test loss=0.675781 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.021639259532094002
[5/24] Train loss=0.016652986407279968
[10/24] Train loss=0.015080014243721962
[15/24] Train loss=0.011873504146933556
[20/24] Train loss=0.013527548871934414
Test set avg_accuracy=89.54% avg_sensitivity=76.63%, avg_specificity=94.39% avg_auc=94.54%
Fold[7] Epoch: 86 [86/100 (86%)] Train loss=0.018239 Test loss=0.656914 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.013665438629686832
[5/24] Train loss=0.014498072676360607
[10/24] Train loss=0.01604335755109787
[15/24] Train loss=0.011366640217602253
[20/24] Train loss=0.017697464674711227
Test set avg_accuracy=89.41% avg_sensitivity=75.25%, avg_specificity=94.73% avg_auc=94.53%
Fold[7] Epoch: 87 [87/100 (87%)] Train loss=0.016373 Test loss=0.663612 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.01680808886885643
[5/24] Train loss=0.012724044732749462
[10/24] Train loss=0.014713174663484097
[15/24] Train loss=0.017091993242502213
[20/24] Train loss=0.016460631042718887
Test set avg_accuracy=89.41% avg_sensitivity=75.77%, avg_specificity=94.54% avg_auc=94.53%
Fold[7] Epoch: 88 [88/100 (88%)] Train loss=0.016260 Test loss=0.678704 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.014480162411928177
[5/24] Train loss=0.010532401502132416
[10/24] Train loss=0.01437730435281992
[15/24] Train loss=0.021765006706118584
[20/24] Train loss=0.014135046862065792
Test set avg_accuracy=89.62% avg_sensitivity=76.30%, avg_specificity=94.63% avg_auc=94.54%
Fold[7] Epoch: 89 [89/100 (89%)] Train loss=0.015051 Test loss=0.670812 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.017040535807609558
[5/24] Train loss=0.014428991824388504
[10/24] Train loss=0.013102129101753235
[15/24] Train loss=0.01756240241229534
[20/24] Train loss=0.016899168491363525
Test set avg_accuracy=89.54% avg_sensitivity=75.68%, avg_specificity=94.75% avg_auc=94.52%
Fold[7] Epoch: 90 [90/100 (90%)] Train loss=0.015100 Test loss=0.671934 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.013138270936906338
[5/24] Train loss=0.013568873517215252
[10/24] Train loss=0.010012289509177208
[15/24] Train loss=0.01617727242410183
[20/24] Train loss=0.015386492013931274
Test set avg_accuracy=89.52% avg_sensitivity=75.54%, avg_specificity=94.77% avg_auc=94.50%
Fold[7] Epoch: 91 [91/100 (91%)] Train loss=0.016100 Test loss=0.670831 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.01972774788737297
[5/24] Train loss=0.017341529950499535
[10/24] Train loss=0.013530480675399303
[15/24] Train loss=0.012136650271713734
[20/24] Train loss=0.013863950036466122
Test set avg_accuracy=89.65% avg_sensitivity=76.11%, avg_specificity=94.73% avg_auc=94.50%
Fold[7] Epoch: 92 [92/100 (92%)] Train loss=0.015476 Test loss=0.677213 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.013676544651389122
[5/24] Train loss=0.01566888578236103
[10/24] Train loss=0.016960343345999718
[15/24] Train loss=0.015681490302085876
[20/24] Train loss=0.020916664972901344
Test set avg_accuracy=89.65% avg_sensitivity=76.35%, avg_specificity=94.64% avg_auc=94.51%
Fold[7] Epoch: 93 [93/100 (93%)] Train loss=0.015046 Test loss=0.679349 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.018359551206231117
[5/24] Train loss=0.011900058947503567
[10/24] Train loss=0.011506634764373302
[15/24] Train loss=0.012843852862715721
[20/24] Train loss=0.01215419638901949
Test set avg_accuracy=89.65% avg_sensitivity=76.35%, avg_specificity=94.64% avg_auc=94.51%
Fold[7] Epoch: 94 [94/100 (94%)] Train loss=0.014360 Test loss=0.670812 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.011564251966774464
[5/24] Train loss=0.017451785504817963
[10/24] Train loss=0.01464436948299408
[15/24] Train loss=0.014920031651854515
[20/24] Train loss=0.012456104159355164
Test set avg_accuracy=89.70% avg_sensitivity=76.39%, avg_specificity=94.70% avg_auc=94.51%
Fold[7] Epoch: 95 [95/100 (95%)] Train loss=0.014976 Test loss=0.682497 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.012026157230138779
[5/24] Train loss=0.011485259979963303
[10/24] Train loss=0.019956855103373528
[15/24] Train loss=0.013007468543946743
[20/24] Train loss=0.011978122405707836
Test set avg_accuracy=89.64% avg_sensitivity=76.49%, avg_specificity=94.57% avg_auc=94.51%
Fold[7] Epoch: 96 [96/100 (96%)] Train loss=0.015057 Test loss=0.682377 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.014205021783709526
[5/24] Train loss=0.01112342905253172
[10/24] Train loss=0.012303564697504044
[15/24] Train loss=0.012871017679572105
[20/24] Train loss=0.016729483380913734
Test set avg_accuracy=89.70% avg_sensitivity=76.44%, avg_specificity=94.68% avg_auc=94.51%
Fold[7] Epoch: 97 [97/100 (97%)] Train loss=0.014673 Test loss=0.683465 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.01017909124493599
[5/24] Train loss=0.011249825358390808
[10/24] Train loss=0.01901492290198803
[15/24] Train loss=0.020373933017253876
[20/24] Train loss=0.01856001280248165
Test set avg_accuracy=89.61% avg_sensitivity=76.44%, avg_specificity=94.55% avg_auc=94.51%
Fold[7] Epoch: 98 [98/100 (98%)] Train loss=0.014955 Test loss=0.683451 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.017809832468628883
[5/24] Train loss=0.011579357087612152
[10/24] Train loss=0.01739860512316227
[15/24] Train loss=0.012744755484163761
[20/24] Train loss=0.016292063519358635
Test set avg_accuracy=89.61% avg_sensitivity=76.44%, avg_specificity=94.55% avg_auc=94.51%
Fold[7] Epoch: 99 [99/100 (99%)] Train loss=0.015197 Test loss=0.683543 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.026133235543966293
[5/24] Train loss=0.013907329179346561
[10/24] Train loss=0.015839621424674988
[15/24] Train loss=0.01189256552606821
[20/24] Train loss=0.01329839788377285
Test set avg_accuracy=89.64% avg_sensitivity=76.44%, avg_specificity=94.59% avg_auc=94.51%
Fold[7] Epoch: 100 [100/100 (100%)] Train loss=0.015008 Test loss=0.683337 Current lr=[4.874217159761039e-09]

Fold[7] Result: acc=90.31% sen=77.44%, spe=95.15%, auc=95.30%!
Fold[7] Avg_overlap=0.73%(Â±0.22922353913288848)
[0/24] Train loss=1.4196900129318237
[5/24] Train loss=1.3062785863876343
[10/24] Train loss=1.3087573051452637
[15/24] Train loss=1.1146115064620972
[20/24] Train loss=1.0667966604232788
Test set avg_accuracy=75.49% avg_sensitivity=10.16%, avg_specificity=96.96% avg_auc=70.76%
Best model saved!! Metric=70.75992253317712!!
Fold[8] Epoch: 1 [1/100 (1%)] Train loss=1.240746 Test loss=0.664838 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=1.0490891933441162
[5/24] Train loss=0.9291141629219055
[10/24] Train loss=1.0157572031021118
[15/24] Train loss=0.8761292099952698
[20/24] Train loss=0.874897837638855
Test set avg_accuracy=79.44% avg_sensitivity=41.76%, avg_specificity=91.82% avg_auc=81.91%
Best model saved!! Metric=81.90900463002814!!
Fold[8] Epoch: 2 [2/100 (2%)] Train loss=0.986958 Test loss=0.574502 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8971462845802307
[5/24] Train loss=0.8220007419586182
[10/24] Train loss=0.9576765298843384
[15/24] Train loss=0.7931203842163086
[20/24] Train loss=0.8020482659339905
Test set avg_accuracy=82.73% avg_sensitivity=60.82%, avg_specificity=89.93% avg_auc=86.79%
Best model saved!! Metric=86.79237308322125!!
Fold[8] Epoch: 3 [3/100 (3%)] Train loss=0.892498 Test loss=0.434390 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.8033651113510132
[5/24] Train loss=0.8079531788825989
[10/24] Train loss=0.8757678270339966
[15/24] Train loss=0.7318324446678162
[20/24] Train loss=0.7799866199493408
Test set avg_accuracy=83.78% avg_sensitivity=75.25%, avg_specificity=86.58% avg_auc=89.17%
Best model saved!! Metric=89.17409257451116!!
Fold[8] Epoch: 4 [4/100 (4%)] Train loss=0.828226 Test loss=0.435176 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.7555589079856873
[5/24] Train loss=0.7371621131896973
[10/24] Train loss=0.8094342947006226
[15/24] Train loss=0.6671227216720581
[20/24] Train loss=0.6737062931060791
Test set avg_accuracy=82.76% avg_sensitivity=82.46%, avg_specificity=82.86% avg_auc=90.33%
Best model saved!! Metric=90.3293132457391!!
Fold[8] Epoch: 5 [5/100 (5%)] Train loss=0.774430 Test loss=0.471447 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.7387217879295349
[5/24] Train loss=0.7068010568618774
[10/24] Train loss=0.762772798538208
[15/24] Train loss=0.6685397028923035
[20/24] Train loss=0.6640647649765015
Test set avg_accuracy=82.23% avg_sensitivity=84.36%, avg_specificity=81.53% avg_auc=90.93%
Best model saved!! Metric=90.93480404065578!!
Fold[8] Epoch: 6 [6/100 (6%)] Train loss=0.741316 Test loss=0.481270 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.6919225454330444
[5/24] Train loss=0.6796248555183411
[10/24] Train loss=0.7420182824134827
[15/24] Train loss=0.6076738238334656
[20/24] Train loss=0.6158130168914795
Test set avg_accuracy=81.05% avg_sensitivity=86.15%, avg_specificity=79.38% avg_auc=91.36%
Best model saved!! Metric=91.36396681435134!!
Fold[8] Epoch: 7 [7/100 (7%)] Train loss=0.715457 Test loss=0.489180 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.6658848524093628
[5/24] Train loss=0.6649719476699829
[10/24] Train loss=0.7271438837051392
[15/24] Train loss=0.6202229857444763
[20/24] Train loss=0.6336133480072021
Test set avg_accuracy=82.08% avg_sensitivity=86.84%, avg_specificity=80.52% avg_auc=91.47%
Best model saved!! Metric=91.46962699165493!!
Fold[8] Epoch: 8 [8/100 (8%)] Train loss=0.696368 Test loss=0.464163 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.6580420136451721
[5/24] Train loss=0.6148975491523743
[10/24] Train loss=0.7100053429603577
[15/24] Train loss=0.5942085981369019
[20/24] Train loss=0.5893421769142151
Test set avg_accuracy=82.46% avg_sensitivity=86.89%, avg_specificity=81.01% avg_auc=91.72%
Best model saved!! Metric=91.72160549544051!!
Fold[8] Epoch: 9 [9/100 (9%)] Train loss=0.672592 Test loss=0.457141 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6261895298957825
[5/24] Train loss=0.6178407073020935
[10/24] Train loss=0.6695564389228821
[15/24] Train loss=0.595639169216156
[20/24] Train loss=0.5791764855384827
Test set avg_accuracy=87.01% avg_sensitivity=83.41%, avg_specificity=88.19% avg_auc=91.88%
Best model saved!! Metric=91.87860415796185!!
Fold[8] Epoch: 10 [10/100 (10%)] Train loss=0.653373 Test loss=0.368306 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.6272881031036377
[5/24] Train loss=0.6107305288314819
[10/24] Train loss=0.6620575189590454
[15/24] Train loss=0.5966193675994873
[20/24] Train loss=0.5503166913986206
Test set avg_accuracy=87.66% avg_sensitivity=82.25%, avg_specificity=89.43% avg_auc=92.06%
Best model saved!! Metric=92.06282059795493!!
Fold[8] Epoch: 11 [11/100 (11%)] Train loss=0.641746 Test loss=0.352150 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.6275184750556946
[5/24] Train loss=0.556853175163269
[10/24] Train loss=0.6669151782989502
[15/24] Train loss=0.5629668831825256
[20/24] Train loss=0.5555103421211243
Test set avg_accuracy=85.79% avg_sensitivity=85.10%, avg_specificity=86.02% avg_auc=91.68%
Fold[8] Epoch: 12 [12/100 (12%)] Train loss=0.627063 Test loss=0.401656 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.6150205135345459
[5/24] Train loss=0.5644996762275696
[10/24] Train loss=0.653512716293335
[15/24] Train loss=0.5475265979766846
[20/24] Train loss=0.5075755715370178
Test set avg_accuracy=88.93% avg_sensitivity=78.88%, avg_specificity=92.23% avg_auc=91.60%
Fold[8] Epoch: 13 [13/100 (13%)] Train loss=0.621300 Test loss=0.343823 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.6223143339157104
[5/24] Train loss=0.540427565574646
[10/24] Train loss=0.6344780325889587
[15/24] Train loss=0.5496213436126709
[20/24] Train loss=0.512124240398407
Test set avg_accuracy=87.93% avg_sensitivity=79.99%, avg_specificity=90.54% avg_auc=92.17%
Best model saved!! Metric=92.17204695995733!!
Fold[8] Epoch: 14 [14/100 (14%)] Train loss=0.614029 Test loss=0.333233 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.6252036690711975
[5/24] Train loss=0.5489888787269592
[10/24] Train loss=0.6629324555397034
[15/24] Train loss=0.553534984588623
[20/24] Train loss=0.510792076587677
Test set avg_accuracy=87.93% avg_sensitivity=77.99%, avg_specificity=91.20% avg_auc=91.64%
Fold[8] Epoch: 15 [15/100 (15%)] Train loss=0.602762 Test loss=0.346891 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.5858086943626404
[5/24] Train loss=0.5516306757926941
[10/24] Train loss=0.6096789240837097
[15/24] Train loss=0.5315370559692383
[20/24] Train loss=0.5331497192382812
Test set avg_accuracy=87.29% avg_sensitivity=82.78%, avg_specificity=88.77% avg_auc=92.21%
Best model saved!! Metric=92.2132015511947!!
Fold[8] Epoch: 16 [16/100 (16%)] Train loss=0.596468 Test loss=0.361479 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5787996053695679
[5/24] Train loss=0.5450122952461243
[10/24] Train loss=0.6167771220207214
[15/24] Train loss=0.519381046295166
[20/24] Train loss=0.5120028853416443
Test set avg_accuracy=88.66% avg_sensitivity=78.09%, avg_specificity=92.13% avg_auc=92.18%
Fold[8] Epoch: 17 [17/100 (17%)] Train loss=0.592762 Test loss=0.331625 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.6073726415634155
[5/24] Train loss=0.5293656587600708
[10/24] Train loss=0.6362669467926025
[15/24] Train loss=0.552222728729248
[20/24] Train loss=0.4878794252872467
Test set avg_accuracy=88.15% avg_sensitivity=79.62%, avg_specificity=90.95% avg_auc=92.05%
Fold[8] Epoch: 18 [18/100 (18%)] Train loss=0.591514 Test loss=0.318575 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.5813542604446411
[5/24] Train loss=0.5218107104301453
[10/24] Train loss=0.6027791500091553
[15/24] Train loss=0.5319079160690308
[20/24] Train loss=0.4984627068042755
Test set avg_accuracy=86.68% avg_sensitivity=84.73%, avg_specificity=87.32% avg_auc=92.52%
Best model saved!! Metric=92.51991165335336!!
Fold[8] Epoch: 19 [19/100 (19%)] Train loss=0.580653 Test loss=0.361342 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5802470445632935
[5/24] Train loss=0.49507278203964233
[10/24] Train loss=0.553156852722168
[15/24] Train loss=0.5332217216491699
[20/24] Train loss=0.4859287738800049
Test set avg_accuracy=88.83% avg_sensitivity=76.51%, avg_specificity=92.87% avg_auc=92.29%
Fold[8] Epoch: 20 [20/100 (20%)] Train loss=0.564467 Test loss=0.319360 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5843736529350281
[5/24] Train loss=0.4924248456954956
[10/24] Train loss=0.5952527523040771
[15/24] Train loss=0.5186544060707092
[20/24] Train loss=0.4613332450389862
Test set avg_accuracy=89.51% avg_sensitivity=71.20%, avg_specificity=95.52% avg_auc=91.93%
Fold[8] Epoch: 21 [21/100 (21%)] Train loss=0.557150 Test loss=0.324128 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.5670648813247681
[5/24] Train loss=0.5181753039360046
[10/24] Train loss=0.5520853996276855
[15/24] Train loss=0.49256426095962524
[20/24] Train loss=0.46408313512802124
Test set avg_accuracy=89.45% avg_sensitivity=70.25%, avg_specificity=95.76% avg_auc=92.11%
Fold[8] Epoch: 22 [22/100 (22%)] Train loss=0.554177 Test loss=0.346369 Current lr=[0.000842324016282456]

[0/24] Train loss=0.5783076286315918
[5/24] Train loss=0.4937199652194977
[10/24] Train loss=0.5525463223457336
[15/24] Train loss=0.4992128610610962
[20/24] Train loss=0.4776419997215271
Test set avg_accuracy=88.42% avg_sensitivity=72.09%, avg_specificity=93.79% avg_auc=91.44%
Fold[8] Epoch: 23 [23/100 (23%)] Train loss=0.546429 Test loss=0.344869 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5710560083389282
[5/24] Train loss=0.5133532881736755
[10/24] Train loss=0.5435405969619751
[15/24] Train loss=0.4734678268432617
[20/24] Train loss=0.4638155400753021
Test set avg_accuracy=87.76% avg_sensitivity=61.14%, avg_specificity=96.51% avg_auc=91.06%
Fold[8] Epoch: 24 [24/100 (24%)] Train loss=0.539975 Test loss=0.363185 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.5540823936462402
[5/24] Train loss=0.4404575526714325
[10/24] Train loss=0.6035076975822449
[15/24] Train loss=0.4754036068916321
[20/24] Train loss=0.4465309977531433
Test set avg_accuracy=89.35% avg_sensitivity=75.88%, avg_specificity=93.77% avg_auc=92.04%
Fold[8] Epoch: 25 [25/100 (25%)] Train loss=0.532935 Test loss=0.314585 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.544132649898529
[5/24] Train loss=0.44282978773117065
[10/24] Train loss=0.5765621662139893
[15/24] Train loss=0.49825677275657654
[20/24] Train loss=0.41718587279319763
Test set avg_accuracy=89.91% avg_sensitivity=74.30%, avg_specificity=95.04% avg_auc=92.11%
Fold[8] Epoch: 26 [26/100 (26%)] Train loss=0.525567 Test loss=0.317170 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.5363141894340515
[5/24] Train loss=0.4310367703437805
[10/24] Train loss=0.5403488874435425
[15/24] Train loss=0.47040197253227234
[20/24] Train loss=0.41133731603622437
Test set avg_accuracy=89.67% avg_sensitivity=69.14%, avg_specificity=96.42% avg_auc=91.91%
Fold[8] Epoch: 27 [27/100 (27%)] Train loss=0.514821 Test loss=0.342560 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.5126816630363464
[5/24] Train loss=0.4486751854419708
[10/24] Train loss=0.5542889833450317
[15/24] Train loss=0.45796647667884827
[20/24] Train loss=0.4278689920902252
Test set avg_accuracy=89.34% avg_sensitivity=77.94%, avg_specificity=93.08% avg_auc=92.77%
Best model saved!! Metric=92.77066499279158!!
Fold[8] Epoch: 28 [28/100 (28%)] Train loss=0.511839 Test loss=0.299801 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.4948025047779083
[5/24] Train loss=0.4278601109981537
[10/24] Train loss=0.545271098613739
[15/24] Train loss=0.49795767664909363
[20/24] Train loss=0.44548559188842773
Test set avg_accuracy=89.31% avg_sensitivity=78.20%, avg_specificity=92.96% avg_auc=92.43%
Fold[8] Epoch: 29 [29/100 (29%)] Train loss=0.505830 Test loss=0.317716 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.5067959427833557
[5/24] Train loss=0.4698764979839325
[10/24] Train loss=0.5293869376182556
[15/24] Train loss=0.4541049897670746
[20/24] Train loss=0.39823856949806213
Test set avg_accuracy=88.71% avg_sensitivity=78.78%, avg_specificity=91.97% avg_auc=92.84%
Best model saved!! Metric=92.84275839968578!!
Fold[8] Epoch: 30 [30/100 (30%)] Train loss=0.484750 Test loss=0.326775 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.464170902967453
[5/24] Train loss=0.4231589138507843
[10/24] Train loss=0.48825082182884216
[15/24] Train loss=0.4137020409107208
[20/24] Train loss=0.3816938102245331
Test set avg_accuracy=88.58% avg_sensitivity=79.09%, avg_specificity=91.70% avg_auc=92.79%
Fold[8] Epoch: 31 [31/100 (31%)] Train loss=0.468542 Test loss=0.322778 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.45114293694496155
[5/24] Train loss=0.3684847354888916
[10/24] Train loss=0.47252002358436584
[15/24] Train loss=0.38033393025398254
[20/24] Train loss=0.37521669268608093
Test set avg_accuracy=88.16% avg_sensitivity=69.93%, avg_specificity=94.15% avg_auc=91.79%
Fold[8] Epoch: 32 [32/100 (32%)] Train loss=0.445987 Test loss=0.342742 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.44386419653892517
[5/24] Train loss=0.39308035373687744
[10/24] Train loss=0.42993566393852234
[15/24] Train loss=0.3397257924079895
[20/24] Train loss=0.3844239115715027
Test set avg_accuracy=88.67% avg_sensitivity=72.41%, avg_specificity=94.01% avg_auc=92.23%
Fold[8] Epoch: 33 [33/100 (33%)] Train loss=0.423010 Test loss=0.337772 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.4499812722206116
[5/24] Train loss=0.3495158553123474
[10/24] Train loss=0.4344218373298645
[15/24] Train loss=0.3678004741668701
[20/24] Train loss=0.3938261568546295
Test set avg_accuracy=88.66% avg_sensitivity=74.99%, avg_specificity=93.15% avg_auc=92.31%
Fold[8] Epoch: 34 [34/100 (34%)] Train loss=0.419733 Test loss=0.338115 Current lr=[0.000991797016730875]

[0/24] Train loss=0.4033101499080658
[5/24] Train loss=0.3467192053794861
[10/24] Train loss=0.3954952359199524
[15/24] Train loss=0.3906395137310028
[20/24] Train loss=0.33212149143218994
Test set avg_accuracy=88.72% avg_sensitivity=70.09%, avg_specificity=94.85% avg_auc=91.39%
Fold[8] Epoch: 35 [35/100 (35%)] Train loss=0.399478 Test loss=0.391729 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.37857115268707275
[5/24] Train loss=0.3477857708930969
[10/24] Train loss=0.41454607248306274
[15/24] Train loss=0.3556062877178192
[20/24] Train loss=0.34838828444480896
Test set avg_accuracy=89.36% avg_sensitivity=68.62%, avg_specificity=96.18% avg_auc=91.51%
Fold[8] Epoch: 36 [36/100 (36%)] Train loss=0.386187 Test loss=0.397743 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.37376436591148376
[5/24] Train loss=0.33977052569389343
[10/24] Train loss=0.385709285736084
[15/24] Train loss=0.3670622408390045
[20/24] Train loss=0.3385671079158783
Test set avg_accuracy=87.73% avg_sensitivity=78.67%, avg_specificity=90.71% avg_auc=92.32%
Fold[8] Epoch: 37 [37/100 (37%)] Train loss=0.383859 Test loss=0.362244 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.3904325067996979
[5/24] Train loss=0.3365652859210968
[10/24] Train loss=0.3582650125026703
[15/24] Train loss=0.3330097496509552
[20/24] Train loss=0.34736600518226624
Test set avg_accuracy=87.23% avg_sensitivity=83.94%, avg_specificity=88.31% avg_auc=92.55%
Fold[8] Epoch: 38 [38/100 (38%)] Train loss=0.365443 Test loss=0.381127 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.35435548424720764
[5/24] Train loss=0.29505059123039246
[10/24] Train loss=0.38029056787490845
[15/24] Train loss=0.2803526520729065
[20/24] Train loss=0.279305100440979
Test set avg_accuracy=87.97% avg_sensitivity=78.52%, avg_specificity=91.07% avg_auc=91.83%
Fold[8] Epoch: 39 [39/100 (39%)] Train loss=0.349287 Test loss=0.377702 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.3721380829811096
[5/24] Train loss=0.2826487421989441
[10/24] Train loss=0.3359176814556122
[15/24] Train loss=0.30169031023979187
[20/24] Train loss=0.2867560088634491
Test set avg_accuracy=87.64% avg_sensitivity=76.51%, avg_specificity=91.30% avg_auc=91.72%
Fold[8] Epoch: 40 [40/100 (40%)] Train loss=0.331235 Test loss=0.370188 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.3260613977909088
[5/24] Train loss=0.2737642526626587
[10/24] Train loss=0.37528321146965027
[15/24] Train loss=0.26975440979003906
[20/24] Train loss=0.2771286070346832
Test set avg_accuracy=87.96% avg_sensitivity=81.73%, avg_specificity=90.00% avg_auc=91.93%
Fold[8] Epoch: 41 [41/100 (41%)] Train loss=0.324218 Test loss=0.380634 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.35114917159080505
[5/24] Train loss=0.27744433283805847
[10/24] Train loss=0.34502655267715454
[15/24] Train loss=0.2951679825782776
[20/24] Train loss=0.2766384780406952
Test set avg_accuracy=88.84% avg_sensitivity=80.04%, avg_specificity=91.73% avg_auc=91.98%
Fold[8] Epoch: 42 [42/100 (42%)] Train loss=0.320718 Test loss=0.370211 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.3336389660835266
[5/24] Train loss=0.22074070572853088
[10/24] Train loss=0.4310809075832367
[15/24] Train loss=0.28339189291000366
[20/24] Train loss=0.25845393538475037
Test set avg_accuracy=87.77% avg_sensitivity=77.36%, avg_specificity=91.20% avg_auc=91.35%
Fold[8] Epoch: 43 [43/100 (43%)] Train loss=0.308938 Test loss=0.397648 Current lr=[0.000916771143003274]

[0/24] Train loss=0.3008480966091156
[5/24] Train loss=0.23890894651412964
[10/24] Train loss=0.3138660490512848
[15/24] Train loss=0.24858517944812775
[20/24] Train loss=0.2829906642436981
Test set avg_accuracy=88.52% avg_sensitivity=72.25%, avg_specificity=93.86% avg_auc=91.05%
Fold[8] Epoch: 44 [44/100 (44%)] Train loss=0.291976 Test loss=0.421034 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.29621487855911255
[5/24] Train loss=0.22998611629009247
[10/24] Train loss=0.3245716989040375
[15/24] Train loss=0.25231921672821045
[20/24] Train loss=0.2357264906167984
Test set avg_accuracy=87.77% avg_sensitivity=80.83%, avg_specificity=90.05% avg_auc=91.67%
Fold[8] Epoch: 45 [45/100 (45%)] Train loss=0.286792 Test loss=0.406616 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.29835715889930725
[5/24] Train loss=0.2206362783908844
[10/24] Train loss=0.2970161736011505
[15/24] Train loss=0.1878388524055481
[20/24] Train loss=0.201027050614357
Test set avg_accuracy=88.78% avg_sensitivity=75.46%, avg_specificity=93.15% avg_auc=91.35%
Fold[8] Epoch: 46 [46/100 (46%)] Train loss=0.247950 Test loss=0.438566 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.24809037148952484
[5/24] Train loss=0.1890266239643097
[10/24] Train loss=0.24950219690799713
[15/24] Train loss=0.21599504351615906
[20/24] Train loss=0.1926586925983429
Test set avg_accuracy=87.75% avg_sensitivity=78.83%, avg_specificity=90.68% avg_auc=91.88%
Fold[8] Epoch: 47 [47/100 (47%)] Train loss=0.222578 Test loss=0.494480 Current lr=[0.000860751215339601]

[0/24] Train loss=0.21235649287700653
[5/24] Train loss=0.16910549998283386
[10/24] Train loss=0.19124332070350647
[15/24] Train loss=0.1669229418039322
[20/24] Train loss=0.15532420575618744
Test set avg_accuracy=88.22% avg_sensitivity=75.25%, avg_specificity=92.48% avg_auc=91.80%
Fold[8] Epoch: 48 [48/100 (48%)] Train loss=0.191148 Test loss=0.490315 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.18035466969013214
[5/24] Train loss=0.13390624523162842
[10/24] Train loss=0.19406349956989288
[15/24] Train loss=0.1533401906490326
[20/24] Train loss=0.13562096655368805
Test set avg_accuracy=88.49% avg_sensitivity=75.78%, avg_specificity=92.67% avg_auc=91.10%
Fold[8] Epoch: 49 [49/100 (49%)] Train loss=0.178388 Test loss=0.481974 Current lr=[0.000828265354963756]

[0/24] Train loss=0.1814875453710556
[5/24] Train loss=0.12046085298061371
[10/24] Train loss=0.19002015888690948
[15/24] Train loss=0.14149746298789978
[20/24] Train loss=0.15064255893230438
Test set avg_accuracy=88.26% avg_sensitivity=79.62%, avg_specificity=91.09% avg_auc=91.55%
Fold[8] Epoch: 50 [50/100 (50%)] Train loss=0.160828 Test loss=0.515538 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.17323000729084015
[5/24] Train loss=0.13567505776882172
[10/24] Train loss=0.16670094430446625
[15/24] Train loss=0.14147740602493286
[20/24] Train loss=0.10297711938619614
Test set avg_accuracy=89.06% avg_sensitivity=77.09%, avg_specificity=92.99% avg_auc=92.05%
Fold[8] Epoch: 51 [51/100 (51%)] Train loss=0.152294 Test loss=0.500552 Current lr=[0.00079313651106947]

[0/24] Train loss=0.13233773410320282
[5/24] Train loss=0.13437595963478088
[10/24] Train loss=0.16703635454177856
[15/24] Train loss=0.14166715741157532
[20/24] Train loss=0.12505565583705902
Test set avg_accuracy=89.00% avg_sensitivity=76.25%, avg_specificity=93.18% avg_auc=92.03%
Fold[8] Epoch: 52 [52/100 (52%)] Train loss=0.142759 Test loss=0.541072 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.14218631386756897
[5/24] Train loss=0.10878337919712067
[10/24] Train loss=0.14861634373664856
[15/24] Train loss=0.12401953339576721
[20/24] Train loss=0.13004754483699799
Test set avg_accuracy=88.46% avg_sensitivity=76.25%, avg_specificity=92.48% avg_auc=91.72%
Fold[8] Epoch: 53 [53/100 (53%)] Train loss=0.132216 Test loss=0.496031 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.1451447308063507
[5/24] Train loss=0.1264803409576416
[10/24] Train loss=0.13693085312843323
[15/24] Train loss=0.11226391047239304
[20/24] Train loss=0.09439823776483536
Test set avg_accuracy=88.46% avg_sensitivity=65.40%, avg_specificity=96.04% avg_auc=91.87%
Fold[8] Epoch: 54 [54/100 (54%)] Train loss=0.126913 Test loss=0.591504 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.11227347701787949
[5/24] Train loss=0.112969309091568
[10/24] Train loss=0.14496269822120667
[15/24] Train loss=0.10189145803451538
[20/24] Train loss=0.09936387836933136
Test set avg_accuracy=88.65% avg_sensitivity=66.09%, avg_specificity=96.06% avg_auc=91.28%
Fold[8] Epoch: 55 [55/100 (55%)] Train loss=0.120955 Test loss=0.679125 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.11275031417608261
[5/24] Train loss=0.075815349817276
[10/24] Train loss=0.12147253006696701
[15/24] Train loss=0.12356629967689514
[20/24] Train loss=0.07191378623247147
Test set avg_accuracy=89.06% avg_sensitivity=68.40%, avg_specificity=95.85% avg_auc=91.43%
Fold[8] Epoch: 56 [56/100 (56%)] Train loss=0.111155 Test loss=0.695085 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.0834045484662056
[5/24] Train loss=0.07483287155628204
[10/24] Train loss=0.11971975117921829
[15/24] Train loss=0.09356113523244858
[20/24] Train loss=0.07963592559099197
Test set avg_accuracy=88.87% avg_sensitivity=72.04%, avg_specificity=94.40% avg_auc=92.01%
Fold[8] Epoch: 57 [57/100 (57%)] Train loss=0.100277 Test loss=0.609161 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.09143489599227905
[5/24] Train loss=0.1091933324933052
[10/24] Train loss=0.09195256978273392
[15/24] Train loss=0.08917903900146484
[20/24] Train loss=0.08096642792224884
Test set avg_accuracy=89.19% avg_sensitivity=70.98%, avg_specificity=95.17% avg_auc=92.04%
Fold[8] Epoch: 58 [58/100 (58%)] Train loss=0.090372 Test loss=0.612749 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.07260625064373016
[5/24] Train loss=0.06143060699105263
[10/24] Train loss=0.09258167445659637
[15/24] Train loss=0.0810893103480339
[20/24] Train loss=0.06921735405921936
Test set avg_accuracy=89.10% avg_sensitivity=69.14%, avg_specificity=95.66% avg_auc=91.94%
Fold[8] Epoch: 59 [59/100 (59%)] Train loss=0.080610 Test loss=0.655201 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.08851033449172974
[5/24] Train loss=0.0628771185874939
[10/24] Train loss=0.07875824719667435
[15/24] Train loss=0.05326567590236664
[20/24] Train loss=0.058555375784635544
Test set avg_accuracy=89.43% avg_sensitivity=71.99%, avg_specificity=95.16% avg_auc=92.05%
Fold[8] Epoch: 60 [60/100 (60%)] Train loss=0.071615 Test loss=0.732156 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.07692071795463562
[5/24] Train loss=0.049377620220184326
[10/24] Train loss=0.08876089751720428
[15/24] Train loss=0.06321422755718231
[20/24] Train loss=0.0524941124022007
Test set avg_accuracy=88.95% avg_sensitivity=68.88%, avg_specificity=95.54% avg_auc=91.76%
Fold[8] Epoch: 61 [61/100 (61%)] Train loss=0.070381 Test loss=0.755282 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.07092879712581635
[5/24] Train loss=0.06000753492116928
[10/24] Train loss=0.08660569787025452
[15/24] Train loss=0.06143598258495331
[20/24] Train loss=0.05358324944972992
Test set avg_accuracy=88.93% avg_sensitivity=69.35%, avg_specificity=95.36% avg_auc=91.74%
Fold[8] Epoch: 62 [62/100 (62%)] Train loss=0.066408 Test loss=0.707005 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.06734103709459305
[5/24] Train loss=0.05150209367275238
[10/24] Train loss=0.04975103959441185
[15/24] Train loss=0.06616964936256409
[20/24] Train loss=0.05082458257675171
Test set avg_accuracy=89.24% avg_sensitivity=71.30%, avg_specificity=95.14% avg_auc=91.81%
Fold[8] Epoch: 63 [63/100 (63%)] Train loss=0.062076 Test loss=0.669630 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.05896659940481186
[5/24] Train loss=0.03958761319518089
[10/24] Train loss=0.05817041173577309
[15/24] Train loss=0.04714193940162659
[20/24] Train loss=0.05055083706974983
Test set avg_accuracy=88.75% avg_sensitivity=70.83%, avg_specificity=94.64% avg_auc=91.73%
Fold[8] Epoch: 64 [64/100 (64%)] Train loss=0.058717 Test loss=0.748551 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.04660412296652794
[5/24] Train loss=0.049708813428878784
[10/24] Train loss=0.05438905954360962
[15/24] Train loss=0.05945300683379173
[20/24] Train loss=0.04453975707292557
Test set avg_accuracy=88.55% avg_sensitivity=75.46%, avg_specificity=92.86% avg_auc=91.77%
Fold[8] Epoch: 65 [65/100 (65%)] Train loss=0.054028 Test loss=0.698661 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.05162583291530609
[5/24] Train loss=0.03521637246012688
[10/24] Train loss=0.06031223386526108
[15/24] Train loss=0.06017809361219406
[20/24] Train loss=0.036551106721162796
Test set avg_accuracy=88.63% avg_sensitivity=73.62%, avg_specificity=93.57% avg_auc=91.94%
Fold[8] Epoch: 66 [66/100 (66%)] Train loss=0.048396 Test loss=0.715298 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.051548682153224945
[5/24] Train loss=0.030142104253172874
[10/24] Train loss=0.05499572679400444
[15/24] Train loss=0.04524645954370499
[20/24] Train loss=0.03236548230051994
Test set avg_accuracy=88.06% avg_sensitivity=75.20%, avg_specificity=92.29% avg_auc=91.79%
Fold[8] Epoch: 67 [67/100 (67%)] Train loss=0.045955 Test loss=0.691425 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.04274766519665718
[5/24] Train loss=0.030610762536525726
[10/24] Train loss=0.03942123427987099
[15/24] Train loss=0.03770100325345993
[20/24] Train loss=0.036371998488903046
Test set avg_accuracy=88.20% avg_sensitivity=75.36%, avg_specificity=92.42% avg_auc=92.10%
Fold[8] Epoch: 68 [68/100 (68%)] Train loss=0.041816 Test loss=0.696883 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.03732313588261604
[5/24] Train loss=0.02785000205039978
[10/24] Train loss=0.034625716507434845
[15/24] Train loss=0.042103927582502365
[20/24] Train loss=0.030120674520730972
Test set avg_accuracy=88.11% avg_sensitivity=73.67%, avg_specificity=92.86% avg_auc=92.12%
Fold[8] Epoch: 69 [69/100 (69%)] Train loss=0.037374 Test loss=0.722973 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.026029018685221672
[5/24] Train loss=0.028005151078104973
[10/24] Train loss=0.03447477146983147
[15/24] Train loss=0.026808548718690872
[20/24] Train loss=0.02481267601251602
Test set avg_accuracy=88.31% avg_sensitivity=71.51%, avg_specificity=93.82% avg_auc=92.04%
Fold[8] Epoch: 70 [70/100 (70%)] Train loss=0.034054 Test loss=0.716917 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.03315357118844986
[5/24] Train loss=0.024098128080368042
[10/24] Train loss=0.028769567608833313
[15/24] Train loss=0.022319398820400238
[20/24] Train loss=0.03672463074326515
Test set avg_accuracy=89.17% avg_sensitivity=71.30%, avg_specificity=95.04% avg_auc=92.06%
Fold[8] Epoch: 71 [71/100 (71%)] Train loss=0.029053 Test loss=0.754582 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.028762508183717728
[5/24] Train loss=0.028852755203843117
[10/24] Train loss=0.03633781522512436
[15/24] Train loss=0.025497663766145706
[20/24] Train loss=0.018082192167639732
Test set avg_accuracy=88.87% avg_sensitivity=72.56%, avg_specificity=94.22% avg_auc=92.10%
Fold[8] Epoch: 72 [72/100 (72%)] Train loss=0.028357 Test loss=0.779757 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.02868078090250492
[5/24] Train loss=0.02181086502969265
[10/24] Train loss=0.02333000674843788
[15/24] Train loss=0.025026291608810425
[20/24] Train loss=0.020816385746002197
Test set avg_accuracy=88.83% avg_sensitivity=71.72%, avg_specificity=94.45% avg_auc=91.99%
Fold[8] Epoch: 73 [73/100 (73%)] Train loss=0.025351 Test loss=0.796775 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.022306030616164207
[5/24] Train loss=0.019255666062235832
[10/24] Train loss=0.025621388107538223
[15/24] Train loss=0.022100698202848434
[20/24] Train loss=0.020489977672696114
Test set avg_accuracy=88.79% avg_sensitivity=72.14%, avg_specificity=94.26% avg_auc=92.09%
Fold[8] Epoch: 74 [74/100 (74%)] Train loss=0.025109 Test loss=0.802519 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.019665338099002838
[5/24] Train loss=0.021288996562361717
[10/24] Train loss=0.02917499653995037
[15/24] Train loss=0.017465999349951744
[20/24] Train loss=0.01916452869772911
Test set avg_accuracy=88.49% avg_sensitivity=72.25%, avg_specificity=93.82% avg_auc=92.12%
Fold[8] Epoch: 75 [75/100 (75%)] Train loss=0.023489 Test loss=0.813332 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.021841339766979218
[5/24] Train loss=0.022115744650363922
[10/24] Train loss=0.019883137196302414
[15/24] Train loss=0.018492769449949265
[20/24] Train loss=0.01956133544445038
Test set avg_accuracy=88.72% avg_sensitivity=72.62%, avg_specificity=94.01% avg_auc=92.11%
Fold[8] Epoch: 76 [76/100 (76%)] Train loss=0.022321 Test loss=0.792230 Current lr=[0.000262245679641298]

[0/24] Train loss=0.017105111852288246
[5/24] Train loss=0.01785506121814251
[10/24] Train loss=0.02049112506210804
[15/24] Train loss=0.020599227398633957
[20/24] Train loss=0.017509926110506058
Test set avg_accuracy=88.78% avg_sensitivity=72.04%, avg_specificity=94.27% avg_auc=92.06%
Fold[8] Epoch: 77 [77/100 (77%)] Train loss=0.022483 Test loss=0.838735 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.018859855830669403
[5/24] Train loss=0.015390192158520222
[10/24] Train loss=0.021914158016443253
[15/24] Train loss=0.021180616691708565
[20/24] Train loss=0.015378206968307495
Test set avg_accuracy=88.78% avg_sensitivity=72.14%, avg_specificity=94.24% avg_auc=92.06%
Fold[8] Epoch: 78 [78/100 (78%)] Train loss=0.021000 Test loss=0.834069 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.016662737354636192
[5/24] Train loss=0.018085340037941933
[10/24] Train loss=0.02385629341006279
[15/24] Train loss=0.01497759111225605
[20/24] Train loss=0.020847413688898087
Test set avg_accuracy=88.50% avg_sensitivity=73.14%, avg_specificity=93.55% avg_auc=92.09%
Fold[8] Epoch: 79 [79/100 (79%)] Train loss=0.020343 Test loss=0.831178 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.021130384877324104
[5/24] Train loss=0.015805717557668686
[10/24] Train loss=0.02418617717921734
[15/24] Train loss=0.02624044567346573
[20/24] Train loss=0.019683273509144783
Test set avg_accuracy=88.92% avg_sensitivity=72.88%, avg_specificity=94.19% avg_auc=92.14%
Fold[8] Epoch: 80 [80/100 (80%)] Train loss=0.020338 Test loss=0.836413 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.017280088737607002
[5/24] Train loss=0.012225477956235409
[10/24] Train loss=0.01628457009792328
[15/24] Train loss=0.02091010846197605
[20/24] Train loss=0.014119258150458336
Test set avg_accuracy=88.74% avg_sensitivity=72.20%, avg_specificity=94.17% avg_auc=92.07%
Fold[8] Epoch: 81 [81/100 (81%)] Train loss=0.018625 Test loss=0.849949 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.014565907418727875
[5/24] Train loss=0.020542755722999573
[10/24] Train loss=0.017053084447979927
[15/24] Train loss=0.015880798920989037
[20/24] Train loss=0.01398505736142397
Test set avg_accuracy=88.83% avg_sensitivity=72.72%, avg_specificity=94.12% avg_auc=92.12%
Fold[8] Epoch: 82 [82/100 (82%)] Train loss=0.018472 Test loss=0.845953 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.018100639805197716
[5/24] Train loss=0.013648439198732376
[10/24] Train loss=0.017570221796631813
[15/24] Train loss=0.017808984965085983
[20/24] Train loss=0.016140466555953026
Test set avg_accuracy=88.66% avg_sensitivity=72.04%, avg_specificity=94.12% avg_auc=92.09%
Fold[8] Epoch: 83 [83/100 (83%)] Train loss=0.017278 Test loss=0.858716 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.014764652587473392
[5/24] Train loss=0.0163788590580225
[10/24] Train loss=0.018865976482629776
[15/24] Train loss=0.014188471250236034
[20/24] Train loss=0.013486780226230621
Test set avg_accuracy=88.74% avg_sensitivity=72.78%, avg_specificity=93.98% avg_auc=92.14%
Fold[8] Epoch: 84 [84/100 (84%)] Train loss=0.018402 Test loss=0.853203 Current lr=[0.000122853263038123]

[0/24] Train loss=0.02454097755253315
[5/24] Train loss=0.012217649258673191
[10/24] Train loss=0.013802052475512028
[15/24] Train loss=0.014638139866292477
[20/24] Train loss=0.014814738184213638
Test set avg_accuracy=89.08% avg_sensitivity=72.51%, avg_specificity=94.52% avg_auc=92.14%
Fold[8] Epoch: 85 [85/100 (85%)] Train loss=0.017189 Test loss=0.845767 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.019300712272524834
[5/24] Train loss=0.012380119413137436
[10/24] Train loss=0.01695495843887329
[15/24] Train loss=0.010535787791013718
[20/24] Train loss=0.015919337049126625
Test set avg_accuracy=88.87% avg_sensitivity=72.56%, avg_specificity=94.22% avg_auc=92.15%
Fold[8] Epoch: 86 [86/100 (86%)] Train loss=0.016369 Test loss=0.860404 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.01635519228875637
[5/24] Train loss=0.01256631501019001
[10/24] Train loss=0.014191866852343082
[15/24] Train loss=0.013690383173525333
[20/24] Train loss=0.014903528615832329
Test set avg_accuracy=88.71% avg_sensitivity=72.83%, avg_specificity=93.93% avg_auc=92.15%
Fold[8] Epoch: 87 [87/100 (87%)] Train loss=0.014990 Test loss=0.862371 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.014376339502632618
[5/24] Train loss=0.010436231270432472
[10/24] Train loss=0.013899543322622776
[15/24] Train loss=0.01151091419160366
[20/24] Train loss=0.009854954667389393
Test set avg_accuracy=88.65% avg_sensitivity=72.78%, avg_specificity=93.86% avg_auc=92.15%
Fold[8] Epoch: 88 [88/100 (88%)] Train loss=0.015205 Test loss=0.863849 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.017677469179034233
[5/24] Train loss=0.011491010896861553
[10/24] Train loss=0.014541372656822205
[15/24] Train loss=0.018171526491642
[20/24] Train loss=0.01407033670693636
Test set avg_accuracy=88.76% avg_sensitivity=71.93%, avg_specificity=94.29% avg_auc=92.10%
Fold[8] Epoch: 89 [89/100 (89%)] Train loss=0.015739 Test loss=0.866133 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.014185331761837006
[5/24] Train loss=0.010666795074939728
[10/24] Train loss=0.018146049231290817
[15/24] Train loss=0.011913486756384373
[20/24] Train loss=0.013946155086159706
Test set avg_accuracy=88.76% avg_sensitivity=72.78%, avg_specificity=94.01% avg_auc=92.10%
Fold[8] Epoch: 90 [90/100 (90%)] Train loss=0.016419 Test loss=0.857213 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.014278746210038662
[5/24] Train loss=0.017448723316192627
[10/24] Train loss=0.023143956437706947
[15/24] Train loss=0.016940712928771973
[20/24] Train loss=0.011742214672267437
Test set avg_accuracy=88.76% avg_sensitivity=72.83%, avg_specificity=94.00% avg_auc=92.10%
Fold[8] Epoch: 91 [91/100 (91%)] Train loss=0.015233 Test loss=0.860583 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.013817966915667057
[5/24] Train loss=0.017513733357191086
[10/24] Train loss=0.014050773344933987
[15/24] Train loss=0.014545872807502747
[20/24] Train loss=0.01473078690469265
Test set avg_accuracy=88.71% avg_sensitivity=72.56%, avg_specificity=94.01% avg_auc=92.10%
Fold[8] Epoch: 92 [92/100 (92%)] Train loss=0.016460 Test loss=0.863625 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.015761489048600197
[5/24] Train loss=0.012397553771734238
[10/24] Train loss=0.014150227420032024
[15/24] Train loss=0.009938625618815422
[20/24] Train loss=0.013582498766481876
Test set avg_accuracy=88.70% avg_sensitivity=72.46%, avg_specificity=94.03% avg_auc=92.10%
Fold[8] Epoch: 93 [93/100 (93%)] Train loss=0.015158 Test loss=0.867237 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.014376139268279076
[5/24] Train loss=0.01168769784271717
[10/24] Train loss=0.0172013770788908
[15/24] Train loss=0.014627189375460148
[20/24] Train loss=0.011621334590017796
Test set avg_accuracy=88.67% avg_sensitivity=72.56%, avg_specificity=93.96% avg_auc=92.11%
Fold[8] Epoch: 94 [94/100 (94%)] Train loss=0.015221 Test loss=0.869311 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.012374776415526867
[5/24] Train loss=0.017365118488669395
[10/24] Train loss=0.01303017046302557
[15/24] Train loss=0.014756130054593086
[20/24] Train loss=0.010554881766438484
Test set avg_accuracy=88.71% avg_sensitivity=72.67%, avg_specificity=93.98% avg_auc=92.11%
Fold[8] Epoch: 95 [95/100 (95%)] Train loss=0.015283 Test loss=0.869297 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.010808628983795643
[5/24] Train loss=0.01652619242668152
[10/24] Train loss=0.01225290447473526
[15/24] Train loss=0.012310062535107136
[20/24] Train loss=0.010031587444245815
Test set avg_accuracy=88.70% avg_sensitivity=72.67%, avg_specificity=93.96% avg_auc=92.12%
Fold[8] Epoch: 96 [96/100 (96%)] Train loss=0.014564 Test loss=0.867920 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.017784425988793373
[5/24] Train loss=0.009395810775458813
[10/24] Train loss=0.015714701265096664
[15/24] Train loss=0.014390031807124615
[20/24] Train loss=0.010165974497795105
Test set avg_accuracy=88.68% avg_sensitivity=72.62%, avg_specificity=93.96% avg_auc=92.12%
Fold[8] Epoch: 97 [97/100 (97%)] Train loss=0.015035 Test loss=0.867969 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.013688528910279274
[5/24] Train loss=0.011851297691464424
[10/24] Train loss=0.015477098524570465
[15/24] Train loss=0.012191533111035824
[20/24] Train loss=0.011671693064272404
Test set avg_accuracy=88.67% avg_sensitivity=72.56%, avg_specificity=93.96% avg_auc=92.12%
Fold[8] Epoch: 98 [98/100 (98%)] Train loss=0.014376 Test loss=0.867889 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.01725061796605587
[5/24] Train loss=0.017683807760477066
[10/24] Train loss=0.016451844945549965
[15/24] Train loss=0.014530564658343792
[20/24] Train loss=0.017371980473399162
Test set avg_accuracy=88.67% avg_sensitivity=72.56%, avg_specificity=93.96% avg_auc=92.12%
Fold[8] Epoch: 99 [99/100 (99%)] Train loss=0.015621 Test loss=0.868030 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.014493492431938648
[5/24] Train loss=0.00837097130715847
[10/24] Train loss=0.015390758402645588
[15/24] Train loss=0.011133608408272266
[20/24] Train loss=0.011184087023139
Test set avg_accuracy=88.68% avg_sensitivity=72.56%, avg_specificity=93.98% avg_auc=92.12%
Fold[8] Epoch: 100 [100/100 (100%)] Train loss=0.014243 Test loss=0.867794 Current lr=[4.874217159761039e-09]

Fold[8] Result: acc=88.71% sen=78.78%, spe=91.97%, auc=92.84%!
Fold[8] Avg_overlap=0.67%(Â±0.25762206360542966)
[0/24] Train loss=1.389796495437622
[5/24] Train loss=1.306683897972107
[10/24] Train loss=1.2776240110397339
[15/24] Train loss=1.1060585975646973
[20/24] Train loss=1.070511817932129
Test set avg_accuracy=72.47% avg_sensitivity=5.91%, avg_specificity=97.79% avg_auc=71.88%
Best model saved!! Metric=71.87831679212437!!
Fold[9] Epoch: 1 [1/100 (1%)] Train loss=1.217497 Test loss=0.681772 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=0.9410495162010193
[5/24] Train loss=0.9409002065658569
[10/24] Train loss=1.067350149154663
[15/24] Train loss=0.9042782783508301
[20/24] Train loss=0.8986507654190063
Test set avg_accuracy=81.61% avg_sensitivity=53.50%, avg_specificity=92.31% avg_auc=86.97%
Best model saved!! Metric=86.97352613819056!!
Fold[9] Epoch: 2 [2/100 (2%)] Train loss=0.987091 Test loss=0.466153 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8533620834350586
[5/24] Train loss=0.8257056474685669
[10/24] Train loss=0.9764478802680969
[15/24] Train loss=0.8422946929931641
[20/24] Train loss=0.8446475267410278
Test set avg_accuracy=84.96% avg_sensitivity=70.13%, avg_specificity=90.60% avg_auc=89.64%
Best model saved!! Metric=89.63603111550216!!
Fold[9] Epoch: 3 [3/100 (3%)] Train loss=0.889581 Test loss=0.388664 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.7684321403503418
[5/24] Train loss=0.7708780169487
[10/24] Train loss=0.8619253039360046
[15/24] Train loss=0.7739755511283875
[20/24] Train loss=0.8165163993835449
Test set avg_accuracy=85.79% avg_sensitivity=80.91%, avg_specificity=87.65% avg_auc=92.42%
Best model saved!! Metric=92.41740125897104!!
Fold[9] Epoch: 4 [4/100 (4%)] Train loss=0.825174 Test loss=0.359249 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.7178986072540283
[5/24] Train loss=0.7550081014633179
[10/24] Train loss=0.8092803359031677
[15/24] Train loss=0.7623361349105835
[20/24] Train loss=0.7438746690750122
Test set avg_accuracy=84.86% avg_sensitivity=85.68%, avg_specificity=84.54% avg_auc=92.90%
Best model saved!! Metric=92.89997540222792!!
Fold[9] Epoch: 5 [5/100 (5%)] Train loss=0.777381 Test loss=0.371988 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.6733120083808899
[5/24] Train loss=0.6854575276374817
[10/24] Train loss=0.7941595315933228
[15/24] Train loss=0.751273512840271
[20/24] Train loss=0.7205787897109985
Test set avg_accuracy=83.29% avg_sensitivity=88.56%, avg_specificity=81.29% avg_auc=93.19%
Best model saved!! Metric=93.19201873643554!!
Fold[9] Epoch: 6 [6/100 (6%)] Train loss=0.749091 Test loss=0.402518 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.6738004684448242
[5/24] Train loss=0.7032490372657776
[10/24] Train loss=0.7777740359306335
[15/24] Train loss=0.7628270983695984
[20/24] Train loss=0.7141728401184082
Test set avg_accuracy=83.85% avg_sensitivity=87.85%, avg_specificity=82.33% avg_auc=93.50%
Best model saved!! Metric=93.50188186546241!!
Fold[9] Epoch: 7 [7/100 (7%)] Train loss=0.734871 Test loss=0.395849 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.6502688527107239
[5/24] Train loss=0.6742715835571289
[10/24] Train loss=0.7490625381469727
[15/24] Train loss=0.7791696190834045
[20/24] Train loss=0.6436510682106018
Test set avg_accuracy=85.46% avg_sensitivity=86.48%, avg_specificity=85.06% avg_auc=93.59%
Best model saved!! Metric=93.59195761572845!!
Fold[9] Epoch: 8 [8/100 (8%)] Train loss=0.712686 Test loss=0.354651 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.6180213689804077
[5/24] Train loss=0.6724758744239807
[10/24] Train loss=0.7392647862434387
[15/24] Train loss=0.7815107107162476
[20/24] Train loss=0.6453841924667358
Test set avg_accuracy=85.98% avg_sensitivity=85.40%, avg_specificity=86.20% avg_auc=93.82%
Best model saved!! Metric=93.82239185473996!!
Fold[9] Epoch: 9 [9/100 (9%)] Train loss=0.697389 Test loss=0.351652 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6172975897789001
[5/24] Train loss=0.6005114912986755
[10/24] Train loss=0.6961506009101868
[15/24] Train loss=0.7044399976730347
[20/24] Train loss=0.6563288569450378
Test set avg_accuracy=85.46% avg_sensitivity=87.15%, avg_specificity=84.81% avg_auc=93.96%
Best model saved!! Metric=93.95527588236014!!
Fold[9] Epoch: 10 [10/100 (10%)] Train loss=0.669649 Test loss=0.354879 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.5849413871765137
[5/24] Train loss=0.6083420515060425
[10/24] Train loss=0.699871301651001
[15/24] Train loss=0.6536027193069458
[20/24] Train loss=0.6060513854026794
Test set avg_accuracy=86.72% avg_sensitivity=85.02%, avg_specificity=87.37% avg_auc=94.17%
Best model saved!! Metric=94.17380194580608!!
Fold[9] Epoch: 11 [11/100 (11%)] Train loss=0.658342 Test loss=0.342930 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.5744897723197937
[5/24] Train loss=0.6013045310974121
[10/24] Train loss=0.6959295272827148
[15/24] Train loss=0.6585397720336914
[20/24] Train loss=0.6225124001502991
Test set avg_accuracy=85.40% avg_sensitivity=88.00%, avg_specificity=84.42% avg_auc=94.36%
Best model saved!! Metric=94.35788603213476!!
Fold[9] Epoch: 12 [12/100 (12%)] Train loss=0.649649 Test loss=0.365936 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.5894140005111694
[5/24] Train loss=0.5635995268821716
[10/24] Train loss=0.6856131553649902
[15/24] Train loss=0.6396989226341248
[20/24] Train loss=0.6337546706199646
Test set avg_accuracy=87.76% avg_sensitivity=83.36%, avg_specificity=89.43% avg_auc=94.20%
Fold[9] Epoch: 13 [13/100 (13%)] Train loss=0.638693 Test loss=0.315694 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.5652796030044556
[5/24] Train loss=0.5576107501983643
[10/24] Train loss=0.6785246729850769
[15/24] Train loss=0.6209330558776855
[20/24] Train loss=0.6103435754776001
Test set avg_accuracy=89.26% avg_sensitivity=81.76%, avg_specificity=92.11% avg_auc=94.72%
Best model saved!! Metric=94.71701690179508!!
Fold[9] Epoch: 14 [14/100 (14%)] Train loss=0.624259 Test loss=0.283865 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.5686324238777161
[5/24] Train loss=0.5293243527412415
[10/24] Train loss=0.6730286478996277
[15/24] Train loss=0.7020319104194641
[20/24] Train loss=0.5790507197380066
Test set avg_accuracy=88.91% avg_sensitivity=75.57%, avg_specificity=93.98% avg_auc=94.40%
Fold[9] Epoch: 15 [15/100 (15%)] Train loss=0.619103 Test loss=0.282353 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.5787462592124939
[5/24] Train loss=0.5487748980522156
[10/24] Train loss=0.6909682154655457
[15/24] Train loss=0.6326282024383545
[20/24] Train loss=0.5798667073249817
Test set avg_accuracy=89.08% avg_sensitivity=77.27%, avg_specificity=93.57% avg_auc=94.47%
Fold[9] Epoch: 16 [16/100 (16%)] Train loss=0.614476 Test loss=0.275713 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5686994194984436
[5/24] Train loss=0.5108696818351746
[10/24] Train loss=0.6470884680747986
[15/24] Train loss=0.6491721868515015
[20/24] Train loss=0.5710698366165161
Test set avg_accuracy=89.31% avg_sensitivity=79.58%, avg_specificity=93.01% avg_auc=94.37%
Fold[9] Epoch: 17 [17/100 (17%)] Train loss=0.600748 Test loss=0.282981 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5663405656814575
[5/24] Train loss=0.5141462087631226
[10/24] Train loss=0.6368365287780762
[15/24] Train loss=0.615731954574585
[20/24] Train loss=0.5482580065727234
Test set avg_accuracy=88.52% avg_sensitivity=81.95%, avg_specificity=91.01% avg_auc=94.33%
Fold[9] Epoch: 18 [18/100 (18%)] Train loss=0.599918 Test loss=0.299695 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.5226600766181946
[5/24] Train loss=0.5497602224349976
[10/24] Train loss=0.680849552154541
[15/24] Train loss=0.6239611506462097
[20/24] Train loss=0.5861544609069824
Test set avg_accuracy=88.85% avg_sensitivity=80.72%, avg_specificity=91.95% avg_auc=94.48%
Fold[9] Epoch: 19 [19/100 (19%)] Train loss=0.600386 Test loss=0.278569 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.5132602453231812
[5/24] Train loss=0.5378492474555969
[10/24] Train loss=0.6606850624084473
[15/24] Train loss=0.6417884230613708
[20/24] Train loss=0.5606229901313782
Test set avg_accuracy=89.09% avg_sensitivity=71.74%, avg_specificity=95.69% avg_auc=94.36%
Fold[9] Epoch: 20 [20/100 (20%)] Train loss=0.594809 Test loss=0.276212 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5384452939033508
[5/24] Train loss=0.47459423542022705
[10/24] Train loss=0.634665846824646
[15/24] Train loss=0.5598535537719727
[20/24] Train loss=0.5515553951263428
Test set avg_accuracy=88.98% avg_sensitivity=71.22%, avg_specificity=95.74% avg_auc=94.50%
Fold[9] Epoch: 21 [21/100 (21%)] Train loss=0.577154 Test loss=0.277778 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.571843683719635
[5/24] Train loss=0.4992171823978424
[10/24] Train loss=0.6449376940727234
[15/24] Train loss=0.6155592799186707
[20/24] Train loss=0.5684400796890259
Test set avg_accuracy=88.45% avg_sensitivity=70.79%, avg_specificity=95.17% avg_auc=93.87%
Fold[9] Epoch: 22 [22/100 (22%)] Train loss=0.580605 Test loss=0.282104 Current lr=[0.000842324016282456]

[0/24] Train loss=0.5684496760368347
[5/24] Train loss=0.4786423444747925
[10/24] Train loss=0.6147976517677307
[15/24] Train loss=0.6155932545661926
[20/24] Train loss=0.5289319753646851
Test set avg_accuracy=89.65% avg_sensitivity=76.28%, avg_specificity=94.73% avg_auc=94.36%
Fold[9] Epoch: 23 [23/100 (23%)] Train loss=0.571147 Test loss=0.276897 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5214149355888367
[5/24] Train loss=0.45845818519592285
[10/24] Train loss=0.6008244156837463
[15/24] Train loss=0.6206572651863098
[20/24] Train loss=0.5400968790054321
Test set avg_accuracy=88.55% avg_sensitivity=69.23%, avg_specificity=95.90% avg_auc=94.05%
Fold[9] Epoch: 24 [24/100 (24%)] Train loss=0.556964 Test loss=0.301839 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.5277003645896912
[5/24] Train loss=0.5022310018539429
[10/24] Train loss=0.6274864077568054
[15/24] Train loss=0.6069857478141785
[20/24] Train loss=0.5209729671478271
Test set avg_accuracy=89.36% avg_sensitivity=74.86%, avg_specificity=94.88% avg_auc=94.87%
Best model saved!! Metric=94.86961482063333!!
Fold[9] Epoch: 25 [25/100 (25%)] Train loss=0.562946 Test loss=0.276106 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.5090141296386719
[5/24] Train loss=0.48319539427757263
[10/24] Train loss=0.6161583662033081
[15/24] Train loss=0.5434250831604004
[20/24] Train loss=0.5179466009140015
Test set avg_accuracy=89.79% avg_sensitivity=79.21%, avg_specificity=93.82% avg_auc=94.99%
Best model saved!! Metric=94.99371635643124!!
Fold[9] Epoch: 26 [26/100 (26%)] Train loss=0.546819 Test loss=0.261034 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.5025749802589417
[5/24] Train loss=0.4773987829685211
[10/24] Train loss=0.605151355266571
[15/24] Train loss=0.5232732892036438
[20/24] Train loss=0.4907662868499756
Test set avg_accuracy=89.32% avg_sensitivity=75.76%, avg_specificity=94.48% avg_auc=94.57%
Fold[9] Epoch: 27 [27/100 (27%)] Train loss=0.538242 Test loss=0.273856 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.48473218083381653
[5/24] Train loss=0.45707622170448303
[10/24] Train loss=0.5813714861869812
[15/24] Train loss=0.5097540616989136
[20/24] Train loss=0.4997560679912567
Test set avg_accuracy=88.79% avg_sensitivity=68.53%, avg_specificity=96.50% avg_auc=94.07%
Fold[9] Epoch: 28 [28/100 (28%)] Train loss=0.522539 Test loss=0.308838 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.5099343061447144
[5/24] Train loss=0.44903624057769775
[10/24] Train loss=0.5891026854515076
[15/24] Train loss=0.517710268497467
[20/24] Train loss=0.4862637519836426
Test set avg_accuracy=89.40% avg_sensitivity=73.44%, avg_specificity=95.47% avg_auc=94.33%
Fold[9] Epoch: 29 [29/100 (29%)] Train loss=0.527029 Test loss=0.292962 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.5240882039070129
[5/24] Train loss=0.45017847418785095
[10/24] Train loss=0.5706914663314819
[15/24] Train loss=0.5429911613464355
[20/24] Train loss=0.4982846975326538
Test set avg_accuracy=89.10% avg_sensitivity=73.82%, avg_specificity=94.91% avg_auc=94.45%
Fold[9] Epoch: 30 [30/100 (30%)] Train loss=0.517432 Test loss=0.293900 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.42572566866874695
[5/24] Train loss=0.43593719601631165
[10/24] Train loss=0.5684901475906372
[15/24] Train loss=0.49002692103385925
[20/24] Train loss=0.47039443254470825
Test set avg_accuracy=89.36% avg_sensitivity=71.41%, avg_specificity=96.19% avg_auc=93.67%
Fold[9] Epoch: 31 [31/100 (31%)] Train loss=0.496376 Test loss=0.321990 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.47836408019065857
[5/24] Train loss=0.4420506954193115
[10/24] Train loss=0.5457537770271301
[15/24] Train loss=0.4764969050884247
[20/24] Train loss=0.4515933394432068
Test set avg_accuracy=88.61% avg_sensitivity=78.59%, avg_specificity=92.42% avg_auc=94.62%
Fold[9] Epoch: 32 [32/100 (32%)] Train loss=0.499187 Test loss=0.284429 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.47988513112068176
[5/24] Train loss=0.44904637336730957
[10/24] Train loss=0.5576572418212891
[15/24] Train loss=0.43639159202575684
[20/24] Train loss=0.4608822762966156
Test set avg_accuracy=88.58% avg_sensitivity=69.38%, avg_specificity=95.88% avg_auc=93.55%
Fold[9] Epoch: 33 [33/100 (33%)] Train loss=0.491285 Test loss=0.334546 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.44905778765678406
[5/24] Train loss=0.44782665371894836
[10/24] Train loss=0.514863908290863
[15/24] Train loss=0.42990463972091675
[20/24] Train loss=0.42707934975624084
Test set avg_accuracy=89.00% avg_sensitivity=68.53%, avg_specificity=96.78% avg_auc=93.93%
Fold[9] Epoch: 34 [34/100 (34%)] Train loss=0.476914 Test loss=0.339120 Current lr=[0.000991797016730875]

[0/24] Train loss=0.4527415931224823
[5/24] Train loss=0.4633232355117798
[10/24] Train loss=0.5178685784339905
[15/24] Train loss=0.44087615609169006
[20/24] Train loss=0.43840816617012024
Test set avg_accuracy=89.40% avg_sensitivity=73.96%, avg_specificity=95.27% avg_auc=94.18%
Fold[9] Epoch: 35 [35/100 (35%)] Train loss=0.466510 Test loss=0.323356 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.4175316095352173
[5/24] Train loss=0.4667142331600189
[10/24] Train loss=0.47240832448005676
[15/24] Train loss=0.4559779465198517
[20/24] Train loss=0.40246155858039856
Test set avg_accuracy=87.99% avg_sensitivity=78.54%, avg_specificity=91.59% avg_auc=94.05%
Fold[9] Epoch: 36 [36/100 (36%)] Train loss=0.456960 Test loss=0.315340 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.39456433057785034
[5/24] Train loss=0.3846709132194519
[10/24] Train loss=0.48593607544898987
[15/24] Train loss=0.4122864007949829
[20/24] Train loss=0.4019172191619873
Test set avg_accuracy=89.28% avg_sensitivity=74.15%, avg_specificity=95.04% avg_auc=93.93%
Fold[9] Epoch: 37 [37/100 (37%)] Train loss=0.436124 Test loss=0.321579 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.38452473282814026
[5/24] Train loss=0.40417975187301636
[10/24] Train loss=0.47979283332824707
[15/24] Train loss=0.3900580406188965
[20/24] Train loss=0.4276634454727173
Test set avg_accuracy=89.22% avg_sensitivity=73.25%, avg_specificity=95.29% avg_auc=93.91%
Fold[9] Epoch: 38 [38/100 (38%)] Train loss=0.428620 Test loss=0.344703 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.38982445001602173
[5/24] Train loss=0.3906143307685852
[10/24] Train loss=0.5099713802337646
[15/24] Train loss=0.3850804269313812
[20/24] Train loss=0.4227508008480072
Test set avg_accuracy=88.26% avg_sensitivity=81.24%, avg_specificity=90.92% avg_auc=94.27%
Fold[9] Epoch: 39 [39/100 (39%)] Train loss=0.437939 Test loss=0.298242 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.40002065896987915
[5/24] Train loss=0.41740044951438904
[10/24] Train loss=0.48451897501945496
[15/24] Train loss=0.41010934114456177
[20/24] Train loss=0.38640356063842773
Test set avg_accuracy=88.52% avg_sensitivity=82.33%, avg_specificity=90.87% avg_auc=94.39%
Fold[9] Epoch: 40 [40/100 (40%)] Train loss=0.435948 Test loss=0.318510 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.39902976155281067
[5/24] Train loss=0.3801649808883667
[10/24] Train loss=0.48935258388519287
[15/24] Train loss=0.38319507241249084
[20/24] Train loss=0.40092733502388
Test set avg_accuracy=87.30% avg_sensitivity=83.46%, avg_specificity=88.77% avg_auc=94.29%
Fold[9] Epoch: 41 [41/100 (41%)] Train loss=0.411029 Test loss=0.329878 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.39042651653289795
[5/24] Train loss=0.3817442059516907
[10/24] Train loss=0.46699145436286926
[15/24] Train loss=0.42021939158439636
[20/24] Train loss=0.3657160699367523
Test set avg_accuracy=88.39% avg_sensitivity=78.45%, avg_specificity=92.16% avg_auc=93.50%
Fold[9] Epoch: 42 [42/100 (42%)] Train loss=0.406352 Test loss=0.335005 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.41776368021965027
[5/24] Train loss=0.35352298617362976
[10/24] Train loss=0.4504614770412445
[15/24] Train loss=0.33028146624565125
[20/24] Train loss=0.3570978343486786
Test set avg_accuracy=88.07% avg_sensitivity=80.43%, avg_specificity=90.98% avg_auc=93.89%
Fold[9] Epoch: 43 [43/100 (43%)] Train loss=0.380651 Test loss=0.330302 Current lr=[0.000916771143003274]

[0/24] Train loss=0.3393656313419342
[5/24] Train loss=0.33011484146118164
[10/24] Train loss=0.4267745912075043
[15/24] Train loss=0.33603766560554504
[20/24] Train loss=0.354356586933136
Test set avg_accuracy=87.80% avg_sensitivity=80.43%, avg_specificity=90.60% avg_auc=93.89%
Fold[9] Epoch: 44 [44/100 (44%)] Train loss=0.363353 Test loss=0.350157 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.3378277122974396
[5/24] Train loss=0.27992236614227295
[10/24] Train loss=0.4676046371459961
[15/24] Train loss=0.37752529978752136
[20/24] Train loss=0.30067285895347595
Test set avg_accuracy=89.09% avg_sensitivity=75.90%, avg_specificity=94.10% avg_auc=93.68%
Fold[9] Epoch: 45 [45/100 (45%)] Train loss=0.352661 Test loss=0.350590 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.3243367075920105
[5/24] Train loss=0.2762400209903717
[10/24] Train loss=0.4404633939266205
[15/24] Train loss=0.32823482155799866
[20/24] Train loss=0.2940658926963806
Test set avg_accuracy=88.80% avg_sensitivity=70.84%, avg_specificity=95.63% avg_auc=93.72%
Fold[9] Epoch: 46 [46/100 (46%)] Train loss=0.345934 Test loss=0.355106 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.3128926157951355
[5/24] Train loss=0.2671978771686554
[10/24] Train loss=0.3691149055957794
[15/24] Train loss=0.2958292067050934
[20/24] Train loss=0.31329646706581116
Test set avg_accuracy=88.87% avg_sensitivity=75.33%, avg_specificity=94.02% avg_auc=94.08%
Fold[9] Epoch: 47 [47/100 (47%)] Train loss=0.323489 Test loss=0.343820 Current lr=[0.000860751215339601]

[0/24] Train loss=0.28519028425216675
[5/24] Train loss=0.24291086196899414
[10/24] Train loss=0.31084319949150085
[15/24] Train loss=0.2714177668094635
[20/24] Train loss=0.29144755005836487
Test set avg_accuracy=88.70% avg_sensitivity=77.41%, avg_specificity=92.99% avg_auc=93.43%
Fold[9] Epoch: 48 [48/100 (48%)] Train loss=0.301493 Test loss=0.389522 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.2790025770664215
[5/24] Train loss=0.23700642585754395
[10/24] Train loss=0.3203912079334259
[15/24] Train loss=0.24544933438301086
[20/24] Train loss=0.26526299118995667
Test set avg_accuracy=88.61% avg_sensitivity=75.57%, avg_specificity=93.57% avg_auc=93.46%
Fold[9] Epoch: 49 [49/100 (49%)] Train loss=0.277450 Test loss=0.382094 Current lr=[0.000828265354963756]

[0/24] Train loss=0.2544746398925781
[5/24] Train loss=0.21910271048545837
[10/24] Train loss=0.2987997233867645
[15/24] Train loss=0.22673442959785461
[20/24] Train loss=0.2661755084991455
Test set avg_accuracy=88.33% avg_sensitivity=74.20%, avg_specificity=93.71% avg_auc=93.33%
Fold[9] Epoch: 50 [50/100 (50%)] Train loss=0.251817 Test loss=0.411547 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.22409707307815552
[5/24] Train loss=0.20555834472179413
[10/24] Train loss=0.28104040026664734
[15/24] Train loss=0.23363842070102692
[20/24] Train loss=0.25644785165786743
Test set avg_accuracy=88.96% avg_sensitivity=74.53%, avg_specificity=94.45% avg_auc=93.39%
Fold[9] Epoch: 51 [51/100 (51%)] Train loss=0.248020 Test loss=0.478492 Current lr=[0.00079313651106947]

[0/24] Train loss=0.23947091400623322
[5/24] Train loss=0.1874946802854538
[10/24] Train loss=0.2445312887430191
[15/24] Train loss=0.2123371809720993
[20/24] Train loss=0.22819367051124573
Test set avg_accuracy=88.55% avg_sensitivity=76.75%, avg_specificity=93.04% avg_auc=93.70%
Fold[9] Epoch: 52 [52/100 (52%)] Train loss=0.233542 Test loss=0.427975 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.2383805215358734
[5/24] Train loss=0.18965964019298553
[10/24] Train loss=0.27190420031547546
[15/24] Train loss=0.1866423338651657
[20/24] Train loss=0.2015334516763687
Test set avg_accuracy=88.55% avg_sensitivity=71.03%, avg_specificity=95.22% avg_auc=93.26%
Fold[9] Epoch: 53 [53/100 (53%)] Train loss=0.222294 Test loss=0.458664 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.19475798308849335
[5/24] Train loss=0.170348659157753
[10/24] Train loss=0.24649196863174438
[15/24] Train loss=0.2070581614971161
[20/24] Train loss=0.1896820068359375
Test set avg_accuracy=88.87% avg_sensitivity=74.76%, avg_specificity=94.23% avg_auc=93.65%
Fold[9] Epoch: 54 [54/100 (54%)] Train loss=0.207619 Test loss=0.523268 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.19708427786827087
[5/24] Train loss=0.16055506467819214
[10/24] Train loss=0.22431473433971405
[15/24] Train loss=0.1623142957687378
[20/24] Train loss=0.17405399680137634
Test set avg_accuracy=89.08% avg_sensitivity=74.91%, avg_specificity=94.46% avg_auc=93.59%
Fold[9] Epoch: 55 [55/100 (55%)] Train loss=0.189814 Test loss=0.520628 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.1662711501121521
[5/24] Train loss=0.14992940425872803
[10/24] Train loss=0.19340556859970093
[15/24] Train loss=0.18173685669898987
[20/24] Train loss=0.1790008693933487
Test set avg_accuracy=88.74% avg_sensitivity=73.82%, avg_specificity=94.41% avg_auc=93.65%
Fold[9] Epoch: 56 [56/100 (56%)] Train loss=0.179017 Test loss=0.500788 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.14803411066532135
[5/24] Train loss=0.1400739997625351
[10/24] Train loss=0.17565588653087616
[15/24] Train loss=0.17026425898075104
[20/24] Train loss=0.16691619157791138
Test set avg_accuracy=89.01% avg_sensitivity=73.44%, avg_specificity=94.93% avg_auc=93.95%
Fold[9] Epoch: 57 [57/100 (57%)] Train loss=0.164468 Test loss=0.523943 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.1555892825126648
[5/24] Train loss=0.12422379851341248
[10/24] Train loss=0.18547873198986053
[15/24] Train loss=0.16711045801639557
[20/24] Train loss=0.15158823132514954
Test set avg_accuracy=88.96% avg_sensitivity=73.49%, avg_specificity=94.84% avg_auc=93.57%
Fold[9] Epoch: 58 [58/100 (58%)] Train loss=0.159940 Test loss=0.568180 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.15716467797756195
[5/24] Train loss=0.12639401853084564
[10/24] Train loss=0.1896260380744934
[15/24] Train loss=0.1657068282365799
[20/24] Train loss=0.1658860594034195
Test set avg_accuracy=88.68% avg_sensitivity=70.65%, avg_specificity=95.54% avg_auc=93.66%
Fold[9] Epoch: 59 [59/100 (59%)] Train loss=0.160064 Test loss=0.496342 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.1635696142911911
[5/24] Train loss=0.10153856873512268
[10/24] Train loss=0.14315631985664368
[15/24] Train loss=0.14591993391513824
[20/24] Train loss=0.13321396708488464
Test set avg_accuracy=88.87% avg_sensitivity=72.02%, avg_specificity=95.27% avg_auc=94.12%
Fold[9] Epoch: 60 [60/100 (60%)] Train loss=0.149467 Test loss=0.492661 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.13630235195159912
[5/24] Train loss=0.11298894137144089
[10/24] Train loss=0.14826838672161102
[15/24] Train loss=0.15756693482398987
[20/24] Train loss=0.15280170738697052
Test set avg_accuracy=88.53% avg_sensitivity=72.97%, avg_specificity=94.45% avg_auc=93.87%
Fold[9] Epoch: 61 [61/100 (61%)] Train loss=0.143012 Test loss=0.496298 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.1346319168806076
[5/24] Train loss=0.10562460124492645
[10/24] Train loss=0.13459019362926483
[15/24] Train loss=0.14103028178215027
[20/24] Train loss=0.1462986320257187
Test set avg_accuracy=88.67% avg_sensitivity=76.80%, avg_specificity=93.19% avg_auc=93.88%
Fold[9] Epoch: 62 [62/100 (62%)] Train loss=0.131612 Test loss=0.466870 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.1291205883026123
[5/24] Train loss=0.0971800684928894
[10/24] Train loss=0.14299696683883667
[15/24] Train loss=0.13191698491573334
[20/24] Train loss=0.12450464069843292
Test set avg_accuracy=88.18% avg_sensitivity=75.05%, avg_specificity=93.17% avg_auc=93.73%
Fold[9] Epoch: 63 [63/100 (63%)] Train loss=0.122248 Test loss=0.478803 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.11049449443817139
[5/24] Train loss=0.09247411042451859
[10/24] Train loss=0.11048446595668793
[15/24] Train loss=0.11081637442111969
[20/24] Train loss=0.1063900738954544
Test set avg_accuracy=88.53% avg_sensitivity=70.75%, avg_specificity=95.29% avg_auc=93.34%
Fold[9] Epoch: 64 [64/100 (64%)] Train loss=0.107970 Test loss=0.542887 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.11094383150339127
[5/24] Train loss=0.0856272503733635
[10/24] Train loss=0.10394492000341415
[15/24] Train loss=0.09463398903608322
[20/24] Train loss=0.11041969060897827
Test set avg_accuracy=88.37% avg_sensitivity=72.64%, avg_specificity=94.36% avg_auc=93.56%
Fold[9] Epoch: 65 [65/100 (65%)] Train loss=0.102210 Test loss=0.539001 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.09386806190013885
[5/24] Train loss=0.07239426672458649
[10/24] Train loss=0.09450442343950272
[15/24] Train loss=0.09644343703985214
[20/24] Train loss=0.10333503037691116
Test set avg_accuracy=88.48% avg_sensitivity=74.57%, avg_specificity=93.76% avg_auc=93.66%
Fold[9] Epoch: 66 [66/100 (66%)] Train loss=0.099496 Test loss=0.527123 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.10522166639566422
[5/24] Train loss=0.07558063417673111
[10/24] Train loss=0.10012293606996536
[15/24] Train loss=0.10954160988330841
[20/24] Train loss=0.09995255619287491
Test set avg_accuracy=88.63% avg_sensitivity=75.85%, avg_specificity=93.49% avg_auc=93.67%
Fold[9] Epoch: 67 [67/100 (67%)] Train loss=0.098625 Test loss=0.633788 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.10620640963315964
[5/24] Train loss=0.06408033519983292
[10/24] Train loss=0.10119760036468506
[15/24] Train loss=0.08149261772632599
[20/24] Train loss=0.09063363075256348
Test set avg_accuracy=88.35% avg_sensitivity=76.37%, avg_specificity=92.90% avg_auc=93.73%
Fold[9] Epoch: 68 [68/100 (68%)] Train loss=0.087850 Test loss=0.672180 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.10772775858640671
[5/24] Train loss=0.07291419059038162
[10/24] Train loss=0.0956779345870018
[15/24] Train loss=0.0886678546667099
[20/24] Train loss=0.0715501680970192
Test set avg_accuracy=87.70% avg_sensitivity=76.42%, avg_specificity=91.98% avg_auc=93.80%
Fold[9] Epoch: 69 [69/100 (69%)] Train loss=0.086993 Test loss=0.648680 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.08773046731948853
[5/24] Train loss=0.05585078150033951
[10/24] Train loss=0.07356231659650803
[15/24] Train loss=0.0817728340625763
[20/24] Train loss=0.0697111189365387
Test set avg_accuracy=87.89% avg_sensitivity=79.40%, avg_specificity=91.12% avg_auc=93.90%
Fold[9] Epoch: 70 [70/100 (70%)] Train loss=0.080775 Test loss=0.660421 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.09434537589550018
[5/24] Train loss=0.05546528846025467
[10/24] Train loss=0.07844721525907516
[15/24] Train loss=0.07098370045423508
[20/24] Train loss=0.07126802206039429
Test set avg_accuracy=88.01% avg_sensitivity=79.02%, avg_specificity=91.43% avg_auc=94.00%
Fold[9] Epoch: 71 [71/100 (71%)] Train loss=0.074033 Test loss=0.610658 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.07210889458656311
[5/24] Train loss=0.07014759629964828
[10/24] Train loss=0.07029437273740768
[15/24] Train loss=0.06078552454710007
[20/24] Train loss=0.06058775261044502
Test set avg_accuracy=88.14% avg_sensitivity=76.42%, avg_specificity=92.60% avg_auc=93.83%
Fold[9] Epoch: 72 [72/100 (72%)] Train loss=0.072474 Test loss=0.702035 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.07052337378263474
[5/24] Train loss=0.055906496942043304
[10/24] Train loss=0.07968217879533768
[15/24] Train loss=0.05687607079744339
[20/24] Train loss=0.08376748859882355
Test set avg_accuracy=88.46% avg_sensitivity=75.33%, avg_specificity=93.46% avg_auc=93.90%
Fold[9] Epoch: 73 [73/100 (73%)] Train loss=0.067100 Test loss=0.743180 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.06544430553913116
[5/24] Train loss=0.053062450140714645
[10/24] Train loss=0.06990425288677216
[15/24] Train loss=0.05196874961256981
[20/24] Train loss=0.08778679370880127
Test set avg_accuracy=88.84% avg_sensitivity=73.68%, avg_specificity=94.61% avg_auc=93.80%
Fold[9] Epoch: 74 [74/100 (74%)] Train loss=0.062277 Test loss=0.740456 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.06351541727781296
[5/24] Train loss=0.04784013703465462
[10/24] Train loss=0.08489383012056351
[15/24] Train loss=0.04425938054919243
[20/24] Train loss=0.0445985272526741
Test set avg_accuracy=88.79% avg_sensitivity=71.27%, avg_specificity=95.45% avg_auc=93.76%
Fold[9] Epoch: 75 [75/100 (75%)] Train loss=0.057431 Test loss=0.702390 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.07529129087924957
[5/24] Train loss=0.04236786812543869
[10/24] Train loss=0.04942822828888893
[15/24] Train loss=0.05578586831688881
[20/24] Train loss=0.04203687608242035
Test set avg_accuracy=88.61% avg_sensitivity=71.64%, avg_specificity=95.06% avg_auc=93.76%
Fold[9] Epoch: 76 [76/100 (76%)] Train loss=0.051159 Test loss=0.733171 Current lr=[0.000262245679641298]

[0/24] Train loss=0.05213603004813194
[5/24] Train loss=0.036012500524520874
[10/24] Train loss=0.04512536898255348
[15/24] Train loss=0.04992086440324783
[20/24] Train loss=0.05047926306724548
Test set avg_accuracy=88.95% avg_sensitivity=74.01%, avg_specificity=94.63% avg_auc=93.80%
Fold[9] Epoch: 77 [77/100 (77%)] Train loss=0.044649 Test loss=0.797898 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.04785330593585968
[5/24] Train loss=0.029284264892339706
[10/24] Train loss=0.04809288680553436
[15/24] Train loss=0.049956679344177246
[20/24] Train loss=0.03331765532493591
Test set avg_accuracy=88.97% avg_sensitivity=73.49%, avg_specificity=94.86% avg_auc=93.73%
Fold[9] Epoch: 78 [78/100 (78%)] Train loss=0.043017 Test loss=0.763268 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.04452470317482948
[5/24] Train loss=0.035185325890779495
[10/24] Train loss=0.05118834599852562
[15/24] Train loss=0.04714692011475563
[20/24] Train loss=0.03439103811979294
Test set avg_accuracy=88.66% avg_sensitivity=73.20%, avg_specificity=94.54% avg_auc=93.79%
Fold[9] Epoch: 79 [79/100 (79%)] Train loss=0.042255 Test loss=0.823450 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.04813438653945923
[5/24] Train loss=0.03414517268538475
[10/24] Train loss=0.04053276777267456
[15/24] Train loss=0.03979583829641342
[20/24] Train loss=0.03430110216140747
Test set avg_accuracy=88.80% avg_sensitivity=73.06%, avg_specificity=94.79% avg_auc=93.81%
Fold[9] Epoch: 80 [80/100 (80%)] Train loss=0.039590 Test loss=0.803759 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.04130241274833679
[5/24] Train loss=0.03625282272696495
[10/24] Train loss=0.0372663289308548
[15/24] Train loss=0.037314917892217636
[20/24] Train loss=0.04142899066209793
Test set avg_accuracy=89.13% avg_sensitivity=74.15%, avg_specificity=94.82% avg_auc=93.89%
Fold[9] Epoch: 81 [81/100 (81%)] Train loss=0.038644 Test loss=0.794272 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.045036058872938156
[5/24] Train loss=0.02474145218729973
[10/24] Train loss=0.028629973530769348
[15/24] Train loss=0.03501301631331444
[20/24] Train loss=0.023185085505247116
Test set avg_accuracy=88.98% avg_sensitivity=73.87%, avg_specificity=94.73% avg_auc=93.90%
Fold[9] Epoch: 82 [82/100 (82%)] Train loss=0.036094 Test loss=0.810725 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.037245236337184906
[5/24] Train loss=0.03458675369620323
[10/24] Train loss=0.04282945394515991
[15/24] Train loss=0.04103762283921242
[20/24] Train loss=0.03070354461669922
Test set avg_accuracy=88.79% avg_sensitivity=72.54%, avg_specificity=94.97% avg_auc=93.89%
Fold[9] Epoch: 83 [83/100 (83%)] Train loss=0.037187 Test loss=0.818205 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.04047119989991188
[5/24] Train loss=0.032877374440431595
[10/24] Train loss=0.02988496422767639
[15/24] Train loss=0.032486457377672195
[20/24] Train loss=0.033860377967357635
Test set avg_accuracy=88.85% avg_sensitivity=73.25%, avg_specificity=94.79% avg_auc=93.86%
Fold[9] Epoch: 84 [84/100 (84%)] Train loss=0.035250 Test loss=0.828809 Current lr=[0.000122853263038123]

[0/24] Train loss=0.03677432984113693
[5/24] Train loss=0.02655191160738468
[10/24] Train loss=0.03104318119585514
[15/24] Train loss=0.03120802715420723
[20/24] Train loss=0.028429869562387466
Test set avg_accuracy=89.08% avg_sensitivity=73.91%, avg_specificity=94.84% avg_auc=93.82%
Fold[9] Epoch: 85 [85/100 (85%)] Train loss=0.033035 Test loss=0.835907 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.0337025485932827
[5/24] Train loss=0.022528763860464096
[10/24] Train loss=0.03553168103098869
[15/24] Train loss=0.030322836712002754
[20/24] Train loss=0.02920721471309662
Test set avg_accuracy=88.82% avg_sensitivity=72.64%, avg_specificity=94.97% avg_auc=93.85%
Fold[9] Epoch: 86 [86/100 (86%)] Train loss=0.033627 Test loss=0.828471 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.031157992780208588
[5/24] Train loss=0.035783443599939346
[10/24] Train loss=0.03437811881303787
[15/24] Train loss=0.03341023996472359
[20/24] Train loss=0.0246597770601511
Test set avg_accuracy=88.84% avg_sensitivity=73.20%, avg_specificity=94.79% avg_auc=93.91%
Fold[9] Epoch: 87 [87/100 (87%)] Train loss=0.033532 Test loss=0.817257 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.030308125540614128
[5/24] Train loss=0.03378050774335861
[10/24] Train loss=0.029754674062132835
[15/24] Train loss=0.0318957157433033
[20/24] Train loss=0.028903640806674957
Test set avg_accuracy=88.71% avg_sensitivity=73.53%, avg_specificity=94.48% avg_auc=93.93%
Fold[9] Epoch: 88 [88/100 (88%)] Train loss=0.033686 Test loss=0.814694 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.038370996713638306
[5/24] Train loss=0.02292228862643242
[10/24] Train loss=0.028778182342648506
[15/24] Train loss=0.02644319459795952
[20/24] Train loss=0.03219527751207352
Test set avg_accuracy=88.97% avg_sensitivity=73.35%, avg_specificity=94.91% avg_auc=93.92%
Fold[9] Epoch: 89 [89/100 (89%)] Train loss=0.031531 Test loss=0.824319 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.029372503980994225
[5/24] Train loss=0.024508405476808548
[10/24] Train loss=0.024083198979496956
[15/24] Train loss=0.03134000673890114
[20/24] Train loss=0.026950305327773094
Test set avg_accuracy=89.05% avg_sensitivity=73.58%, avg_specificity=94.93% avg_auc=93.94%
Fold[9] Epoch: 90 [90/100 (90%)] Train loss=0.029301 Test loss=0.831387 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.03100845031440258
[5/24] Train loss=0.029389526695013046
[10/24] Train loss=0.03169967979192734
[15/24] Train loss=0.02294514887034893
[20/24] Train loss=0.0273008830845356
Test set avg_accuracy=89.18% avg_sensitivity=74.05%, avg_specificity=94.93% avg_auc=93.96%
Fold[9] Epoch: 91 [91/100 (91%)] Train loss=0.031457 Test loss=0.829419 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.025996726006269455
[5/24] Train loss=0.026599368080496788
[10/24] Train loss=0.02739015966653824
[15/24] Train loss=0.026174800470471382
[20/24] Train loss=0.028760256245732307
Test set avg_accuracy=89.02% avg_sensitivity=73.30%, avg_specificity=95.00% avg_auc=93.96%
Fold[9] Epoch: 92 [92/100 (92%)] Train loss=0.028419 Test loss=0.828291 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.02876168116927147
[5/24] Train loss=0.028416499495506287
[10/24] Train loss=0.024985630065202713
[15/24] Train loss=0.027768880128860474
[20/24] Train loss=0.023725610226392746
Test set avg_accuracy=89.02% avg_sensitivity=73.20%, avg_specificity=95.04% avg_auc=93.96%
Fold[9] Epoch: 93 [93/100 (93%)] Train loss=0.030295 Test loss=0.825614 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.02557845041155815
[5/24] Train loss=0.02577185444533825
[10/24] Train loss=0.029412223026156425
[15/24] Train loss=0.02317751944065094
[20/24] Train loss=0.027171537280082703
Test set avg_accuracy=88.83% avg_sensitivity=72.59%, avg_specificity=95.00% avg_auc=93.94%
Fold[9] Epoch: 94 [94/100 (94%)] Train loss=0.029694 Test loss=0.827130 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.03228801116347313
[5/24] Train loss=0.026668701320886612
[10/24] Train loss=0.030917495489120483
[15/24] Train loss=0.025835255160927773
[20/24] Train loss=0.025215407833456993
Test set avg_accuracy=88.79% avg_sensitivity=72.35%, avg_specificity=95.04% avg_auc=93.93%
Fold[9] Epoch: 95 [95/100 (95%)] Train loss=0.029098 Test loss=0.829084 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.030315736308693886
[5/24] Train loss=0.02489757351577282
[10/24] Train loss=0.026027387008070946
[15/24] Train loss=0.03596821054816246
[20/24] Train loss=0.029758626595139503
Test set avg_accuracy=88.78% avg_sensitivity=72.35%, avg_specificity=95.02% avg_auc=93.93%
Fold[9] Epoch: 96 [96/100 (96%)] Train loss=0.029795 Test loss=0.829044 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.02960079349577427
[5/24] Train loss=0.022391427308321
[10/24] Train loss=0.03143763914704323
[15/24] Train loss=0.028476307168602943
[20/24] Train loss=0.02406250312924385
Test set avg_accuracy=88.80% avg_sensitivity=72.45%, avg_specificity=95.02% avg_auc=93.93%
Fold[9] Epoch: 97 [97/100 (97%)] Train loss=0.028593 Test loss=0.828236 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.025675715878605843
[5/24] Train loss=0.021801328286528587
[10/24] Train loss=0.024373576045036316
[15/24] Train loss=0.0254497267305851
[20/24] Train loss=0.023197071626782417
Test set avg_accuracy=88.79% avg_sensitivity=72.40%, avg_specificity=95.02% avg_auc=93.93%
Fold[9] Epoch: 98 [98/100 (98%)] Train loss=0.027243 Test loss=0.828973 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.021610837429761887
[5/24] Train loss=0.020815186202526093
[10/24] Train loss=0.030788544565439224
[15/24] Train loss=0.0258497167378664
[20/24] Train loss=0.028752455487847328
Test set avg_accuracy=88.79% avg_sensitivity=72.40%, avg_specificity=95.02% avg_auc=93.93%
Fold[9] Epoch: 99 [99/100 (99%)] Train loss=0.028721 Test loss=0.828976 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.02955981157720089
[5/24] Train loss=0.016588136553764343
[10/24] Train loss=0.03696317970752716
[15/24] Train loss=0.028463708236813545
[20/24] Train loss=0.018520547077059746
Test set avg_accuracy=88.80% avg_sensitivity=72.45%, avg_specificity=95.02% avg_auc=93.93%
Fold[9] Epoch: 100 [100/100 (100%)] Train loss=0.027922 Test loss=0.829079 Current lr=[4.874217159761039e-09]

Fold[9] Result: acc=89.79% sen=79.21%, spe=93.82%, auc=94.99%!
Fold[9] Avg_overlap=0.70%(Â±0.23126952338609513)
[0/24] Train loss=1.4021403789520264
[5/24] Train loss=1.3217670917510986
[10/24] Train loss=1.2808070182800293
[15/24] Train loss=1.1019530296325684
[20/24] Train loss=1.006805419921875
Test set avg_accuracy=73.06% avg_sensitivity=13.32%, avg_specificity=92.48% avg_auc=72.93%
Best model saved!! Metric=72.92848937476465!!
Fold[10] Epoch: 1 [1/100 (1%)] Train loss=1.217157 Test loss=0.620662 Current lr=[4.2636802899249015e-05]

[0/24] Train loss=0.9657319784164429
[5/24] Train loss=0.9306339621543884
[10/24] Train loss=0.9897002577781677
[15/24] Train loss=0.8982693552970886
[20/24] Train loss=0.8511840105056763
Test set avg_accuracy=78.50% avg_sensitivity=64.38%, avg_specificity=83.09% avg_auc=83.93%
Best model saved!! Metric=83.93362652916794!!
Fold[10] Epoch: 2 [2/100 (2%)] Train loss=0.955666 Test loss=0.534072 Current lr=[5.051824189062357e-05]

[0/24] Train loss=0.8383309841156006
[5/24] Train loss=0.8812635540962219
[10/24] Train loss=0.9274279475212097
[15/24] Train loss=0.7847946286201477
[20/24] Train loss=0.8397005796432495
Test set avg_accuracy=80.65% avg_sensitivity=78.34%, avg_specificity=81.40% avg_auc=86.67%
Best model saved!! Metric=86.66946162446023!!
Fold[10] Epoch: 3 [3/100 (3%)] Train loss=0.863767 Test loss=0.500256 Current lr=[6.355772613586194e-05]

[0/24] Train loss=0.77247154712677
[5/24] Train loss=0.7985969185829163
[10/24] Train loss=0.798279881477356
[15/24] Train loss=0.7688373327255249
[20/24] Train loss=0.7220880389213562
Test set avg_accuracy=80.39% avg_sensitivity=82.22%, avg_specificity=79.80% avg_auc=89.39%
Best model saved!! Metric=89.38654156391624!!
Fold[10] Epoch: 4 [4/100 (4%)] Train loss=0.800368 Test loss=0.506000 Current lr=[8.161199501053706e-05]

[0/24] Train loss=0.7502700090408325
[5/24] Train loss=0.7457435727119446
[10/24] Train loss=0.7650452852249146
[15/24] Train loss=0.7650048732757568
[20/24] Train loss=0.7117279171943665
Test set avg_accuracy=80.85% avg_sensitivity=82.86%, avg_specificity=80.19% avg_auc=90.30%
Best model saved!! Metric=90.30106604012724!!
Fold[10] Epoch: 5 [5/100 (5%)] Train loss=0.762961 Test loss=0.481952 Current lr=[0.00010448269206251323]

[0/24] Train loss=0.6860124468803406
[5/24] Train loss=0.7526684403419495
[10/24] Train loss=0.7170373797416687
[15/24] Train loss=0.7622745633125305
[20/24] Train loss=0.6809271574020386
Test set avg_accuracy=82.63% avg_sensitivity=84.29%, avg_specificity=82.09% avg_auc=91.12%
Best model saved!! Metric=91.12417286832269!!
Fold[10] Epoch: 6 [6/100 (6%)] Train loss=0.732321 Test loss=0.454625 Current lr=[0.00013191854429056332]

[0/24] Train loss=0.6701961755752563
[5/24] Train loss=0.726996123790741
[10/24] Train loss=0.7135239243507385
[15/24] Train loss=0.748586118221283
[20/24] Train loss=0.6047418117523193
Test set avg_accuracy=83.35% avg_sensitivity=83.81%, avg_specificity=83.20% avg_auc=91.73%
Best model saved!! Metric=91.73294617856372!!
Fold[10] Epoch: 7 [7/100 (7%)] Train loss=0.704153 Test loss=0.447078 Current lr=[0.00016361812280011104]

[0/24] Train loss=0.6447661519050598
[5/24] Train loss=0.6913016438484192
[10/24] Train loss=0.711394727230072
[15/24] Train loss=0.7656920552253723
[20/24] Train loss=0.6142222881317139
Test set avg_accuracy=84.40% avg_sensitivity=84.93%, avg_specificity=84.23% avg_auc=92.19%
Best model saved!! Metric=92.18866990779205!!
Fold[10] Epoch: 8 [8/100 (8%)] Train loss=0.684153 Test loss=0.406316 Current lr=[0.00019923315450566092]

[0/24] Train loss=0.5969798564910889
[5/24] Train loss=0.6695383787155151
[10/24] Train loss=0.6885151267051697
[15/24] Train loss=0.7520226836204529
[20/24] Train loss=0.6093015074729919
Test set avg_accuracy=85.30% avg_sensitivity=81.37%, avg_specificity=86.58% avg_auc=92.47%
Best model saved!! Metric=92.47289110727216!!
Fold[10] Epoch: 9 [9/100 (9%)] Train loss=0.665386 Test loss=0.379053 Current lr=[0.00023837234849530427]

[0/24] Train loss=0.6123221516609192
[5/24] Train loss=0.633445680141449
[10/24] Train loss=0.6481949687004089
[15/24] Train loss=0.6930034756660461
[20/24] Train loss=0.5769813060760498
Test set avg_accuracy=85.96% avg_sensitivity=81.42%, avg_specificity=87.44% avg_auc=92.46%
Fold[10] Epoch: 10 [10/100 (10%)] Train loss=0.646760 Test loss=0.375109 Current lr=[0.00028060569501826566]

[0/24] Train loss=0.5707237720489502
[5/24] Train loss=0.609785795211792
[10/24] Train loss=0.641463041305542
[15/24] Train loss=0.6874496340751648
[20/24] Train loss=0.5631148219108582
Test set avg_accuracy=85.95% avg_sensitivity=80.47%, avg_specificity=87.73% avg_auc=92.55%
Best model saved!! Metric=92.54677616454133!!
Fold[10] Epoch: 11 [11/100 (11%)] Train loss=0.630046 Test loss=0.355614 Current lr=[0.00032546918986389186]

[0/24] Train loss=0.5706974864006042
[5/24] Train loss=0.5942668318748474
[10/24] Train loss=0.6044202446937561
[15/24] Train loss=0.6870124936103821
[20/24] Train loss=0.5596756339073181
Test set avg_accuracy=86.86% avg_sensitivity=79.94%, avg_specificity=89.11% avg_auc=92.56%
Best model saved!! Metric=92.56462469907501!!
Fold[10] Epoch: 12 [12/100 (12%)] Train loss=0.621902 Test loss=0.348953 Current lr=[0.0003724699322268521]

[0/24] Train loss=0.5566997528076172
[5/24] Train loss=0.5554720759391785
[10/24] Train loss=0.5982918739318848
[15/24] Train loss=0.67146235704422
[20/24] Train loss=0.545956552028656
Test set avg_accuracy=87.34% avg_sensitivity=79.35%, avg_specificity=89.94% avg_auc=92.72%
Best model saved!! Metric=92.71959283728877!!
Fold[10] Epoch: 13 [13/100 (13%)] Train loss=0.608679 Test loss=0.338163 Current lr=[0.00042109154004993995]

[0/24] Train loss=0.5596764087677002
[5/24] Train loss=0.5406865477561951
[10/24] Train loss=0.5983949303627014
[15/24] Train loss=0.7063106298446655
[20/24] Train loss=0.5495766401290894
Test set avg_accuracy=87.38% avg_sensitivity=81.05%, avg_specificity=89.44% avg_auc=92.61%
Fold[10] Epoch: 14 [14/100 (14%)] Train loss=0.599528 Test loss=0.345814 Current lr=[0.0004707998233478471]

[0/24] Train loss=0.5666365027427673
[5/24] Train loss=0.5551089644432068
[10/24] Train loss=0.5966243147850037
[15/24] Train loss=0.6378992795944214
[20/24] Train loss=0.5242486000061035
Test set avg_accuracy=88.06% avg_sensitivity=70.54%, avg_specificity=93.75% avg_auc=92.51%
Fold[10] Epoch: 15 [15/100 (15%)] Train loss=0.586474 Test loss=0.304388 Current lr=[0.0005210486531809205]

[0/24] Train loss=0.5495590567588806
[5/24] Train loss=0.5239079594612122
[10/24] Train loss=0.5928649306297302
[15/24] Train loss=0.641257107257843
[20/24] Train loss=0.5016195774078369
Test set avg_accuracy=88.20% avg_sensitivity=68.42%, avg_specificity=94.63% avg_auc=92.58%
Fold[10] Epoch: 16 [16/100 (16%)] Train loss=0.574876 Test loss=0.323362 Current lr=[0.0005712859617983785]

[0/24] Train loss=0.5122296214103699
[5/24] Train loss=0.5166876316070557
[10/24] Train loss=0.5566868782043457
[15/24] Train loss=0.6223021745681763
[20/24] Train loss=0.4892931878566742
Test set avg_accuracy=88.33% avg_sensitivity=70.75%, avg_specificity=94.05% avg_auc=92.64%
Fold[10] Epoch: 17 [17/100 (17%)] Train loss=0.559339 Test loss=0.309038 Current lr=[0.0006209598080293333]

[0/24] Train loss=0.5363669991493225
[5/24] Train loss=0.5036546587944031
[10/24] Train loss=0.569263756275177
[15/24] Train loss=0.5801281332969666
[20/24] Train loss=0.48402681946754456
Test set avg_accuracy=86.47% avg_sensitivity=50.42%, avg_specificity=98.19% avg_auc=92.42%
Fold[10] Epoch: 18 [18/100 (18%)] Train loss=0.543142 Test loss=0.361165 Current lr=[0.0006695244412831239]

[0/24] Train loss=0.5339692831039429
[5/24] Train loss=0.5125983357429504
[10/24] Train loss=0.5534650683403015
[15/24] Train loss=0.6140204668045044
[20/24] Train loss=0.5035297870635986
Test set avg_accuracy=88.02% avg_sensitivity=60.72%, avg_specificity=96.89% avg_auc=92.49%
Fold[10] Epoch: 19 [19/100 (19%)] Train loss=0.548436 Test loss=0.337846 Current lr=[0.0007164462975357315]

[0/24] Train loss=0.553398847579956
[5/24] Train loss=0.5393625497817993
[10/24] Train loss=0.5435128808021545
[15/24] Train loss=0.6456642746925354
[20/24] Train loss=0.48701199889183044
Test set avg_accuracy=89.00% avg_sensitivity=67.89%, avg_specificity=95.86% avg_auc=93.24%
Best model saved!! Metric=93.2369988673644!!
Fold[10] Epoch: 20 [20/100 (20%)] Train loss=0.564955 Test loss=0.301277 Current lr=[0.0007612098614263017]

[0/24] Train loss=0.5300804972648621
[5/24] Train loss=0.4960753321647644
[10/24] Train loss=0.5856741070747375
[15/24] Train loss=0.6084532737731934
[20/24] Train loss=0.4767817258834839
Test set avg_accuracy=89.05% avg_sensitivity=72.61%, avg_specificity=94.39% avg_auc=92.89%
Fold[10] Epoch: 21 [21/100 (21%)] Train loss=0.548782 Test loss=0.300558 Current lr=[0.0008033233300588038]

[0/24] Train loss=0.550163984298706
[5/24] Train loss=0.4649290442466736
[10/24] Train loss=0.5625061988830566
[15/24] Train loss=0.5668216943740845
[20/24] Train loss=0.46254798769950867
Test set avg_accuracy=89.00% avg_sensitivity=74.89%, avg_specificity=93.58% avg_auc=92.70%
Fold[10] Epoch: 22 [22/100 (22%)] Train loss=0.537132 Test loss=0.310339 Current lr=[0.000842324016282456]

[0/24] Train loss=0.521548867225647
[5/24] Train loss=0.5050509572029114
[10/24] Train loss=0.5652621388435364
[15/24] Train loss=0.5337335467338562
[20/24] Train loss=0.490358829498291
Test set avg_accuracy=88.03% avg_sensitivity=64.44%, avg_specificity=95.70% avg_auc=92.84%
Fold[10] Epoch: 23 [23/100 (23%)] Train loss=0.539130 Test loss=0.322468 Current lr=[0.0008777834320868119]

[0/24] Train loss=0.5587105751037598
[5/24] Train loss=0.4787426292896271
[10/24] Train loss=0.5539737939834595
[15/24] Train loss=0.5252344608306885
[20/24] Train loss=0.49143946170806885
Test set avg_accuracy=87.84% avg_sensitivity=67.25%, avg_specificity=94.53% avg_auc=91.99%
Fold[10] Epoch: 24 [24/100 (24%)] Train loss=0.526261 Test loss=0.336020 Current lr=[0.0009093119962618766]

[0/24] Train loss=0.4983197748661041
[5/24] Train loss=0.492583692073822
[10/24] Train loss=0.5130480527877808
[15/24] Train loss=0.5172114968299866
[20/24] Train loss=0.4500192105770111
Test set avg_accuracy=88.98% avg_sensitivity=70.86%, avg_specificity=94.88% avg_auc=93.33%
Best model saved!! Metric=93.32580654496329!!
Fold[10] Epoch: 25 [25/100 (25%)] Train loss=0.523050 Test loss=0.296783 Current lr=[0.0009365633146017091]

[0/24] Train loss=0.4880490303039551
[5/24] Train loss=0.45740756392478943
[10/24] Train loss=0.5535886287689209
[15/24] Train loss=0.5614811182022095
[20/24] Train loss=0.4432103633880615
Test set avg_accuracy=88.57% avg_sensitivity=72.56%, avg_specificity=93.77% avg_auc=92.75%
Fold[10] Epoch: 26 [26/100 (26%)] Train loss=0.509884 Test loss=0.336444 Current lr=[0.0009592379856262807]

[0/24] Train loss=0.47815245389938354
[5/24] Train loss=0.4298449158668518
[10/24] Train loss=0.49227017164230347
[15/24] Train loss=0.5539125204086304
[20/24] Train loss=0.4236229360103607
Test set avg_accuracy=88.40% avg_sensitivity=72.13%, avg_specificity=93.69% avg_auc=92.94%
Fold[10] Epoch: 27 [27/100 (27%)] Train loss=0.500065 Test loss=0.308321 Current lr=[0.0009770868900093536]

[0/24] Train loss=0.4678107798099518
[5/24] Train loss=0.44570663571357727
[10/24] Train loss=0.529782772064209
[15/24] Train loss=0.5298548936843872
[20/24] Train loss=0.4275383949279785
Test set avg_accuracy=88.83% avg_sensitivity=77.87%, avg_specificity=92.39% avg_auc=92.87%
Fold[10] Epoch: 28 [28/100 (28%)] Train loss=0.485830 Test loss=0.330483 Current lr=[0.0009899139275724874]

[0/24] Train loss=0.4763537347316742
[5/24] Train loss=0.4331829845905304
[10/24] Train loss=0.5266059637069702
[15/24] Train loss=0.5269463062286377
[20/24] Train loss=0.4130856394767761
Test set avg_accuracy=88.41% avg_sensitivity=69.69%, avg_specificity=94.50% avg_auc=92.70%
Fold[10] Epoch: 29 [29/100 (29%)] Train loss=0.487091 Test loss=0.332702 Current lr=[0.0009975781717747015]

[0/24] Train loss=0.48054444789886475
[5/24] Train loss=0.41920536756515503
[10/24] Train loss=0.4617084860801697
[15/24] Train loss=0.6080037951469421
[20/24] Train loss=0.3758498728275299
Test set avg_accuracy=89.10% avg_sensitivity=74.31%, avg_specificity=93.91% avg_auc=93.16%
Fold[10] Epoch: 30 [30/100 (30%)] Train loss=0.481211 Test loss=0.309892 Current lr=[0.0009999991257828402]

[0/24] Train loss=0.4738963544368744
[5/24] Train loss=0.420949250459671
[10/24] Train loss=0.47794127464294434
[15/24] Train loss=0.4769251346588135
[20/24] Train loss=0.3981965184211731
Test set avg_accuracy=88.49% avg_sensitivity=74.63%, avg_specificity=93.00% avg_auc=92.90%
Fold[10] Epoch: 31 [31/100 (31%)] Train loss=0.460118 Test loss=0.327798 Current lr=[0.0009994537136216012]

[0/24] Train loss=0.4252600073814392
[5/24] Train loss=0.37156787514686584
[10/24] Train loss=0.42394664883613586
[15/24] Train loss=0.43315252661705017
[20/24] Train loss=0.39911383390426636
Test set avg_accuracy=89.21% avg_sensitivity=74.79%, avg_specificity=93.89% avg_auc=93.31%
Fold[10] Epoch: 32 [32/100 (32%)] Train loss=0.448728 Test loss=0.312057 Current lr=[0.0009979024721774757]

[0/24] Train loss=0.4148617386817932
[5/24] Train loss=0.40196678042411804
[10/24] Train loss=0.4022701382637024
[15/24] Train loss=0.4096968173980713
[20/24] Train loss=0.37690576910972595
Test set avg_accuracy=88.76% avg_sensitivity=69.16%, avg_specificity=95.13% avg_auc=92.89%
Fold[10] Epoch: 33 [33/100 (33%)] Train loss=0.429103 Test loss=0.329024 Current lr=[0.0009953485254442886]

[0/24] Train loss=0.4275170862674713
[5/24] Train loss=0.36472705006599426
[10/24] Train loss=0.3889513909816742
[15/24] Train loss=0.3934895396232605
[20/24] Train loss=0.3720790445804596
Test set avg_accuracy=88.78% avg_sensitivity=66.08%, avg_specificity=96.15% avg_auc=92.55%
Fold[10] Epoch: 34 [34/100 (34%)] Train loss=0.423794 Test loss=0.350455 Current lr=[0.000991797016730875]

[0/24] Train loss=0.3985520601272583
[5/24] Train loss=0.3578115403652191
[10/24] Train loss=0.40408429503440857
[15/24] Train loss=0.3893711268901825
[20/24] Train loss=0.3570721447467804
Test set avg_accuracy=88.53% avg_sensitivity=69.48%, avg_specificity=94.72% avg_auc=92.65%
Fold[10] Epoch: 35 [35/100 (35%)] Train loss=0.404075 Test loss=0.338256 Current lr=[0.0009872550983031389]

[0/24] Train loss=0.4045470356941223
[5/24] Train loss=0.3612998425960541
[10/24] Train loss=0.3828998804092407
[15/24] Train loss=0.38302621245384216
[20/24] Train loss=0.3660171627998352
Test set avg_accuracy=88.35% avg_sensitivity=69.37%, avg_specificity=94.51% avg_auc=92.56%
Fold[10] Epoch: 36 [36/100 (36%)] Train loss=0.398850 Test loss=0.350054 Current lr=[0.0009817319169803439]

[0/24] Train loss=0.40411055088043213
[5/24] Train loss=0.35689622163772583
[10/24] Train loss=0.37450936436653137
[15/24] Train loss=0.3502207100391388
[20/24] Train loss=0.379318505525589
Test set avg_accuracy=89.05% avg_sensitivity=70.12%, avg_specificity=95.20% avg_auc=92.83%
Fold[10] Epoch: 37 [37/100 (37%)] Train loss=0.391697 Test loss=0.369560 Current lr=[0.0009752385957146344]

[0/24] Train loss=0.366456001996994
[5/24] Train loss=0.36461350321769714
[10/24] Train loss=0.3683371841907501
[15/24] Train loss=0.3470558226108551
[20/24] Train loss=0.36037206649780273
Test set avg_accuracy=87.55% avg_sensitivity=61.94%, avg_specificity=95.88% avg_auc=92.27%
Fold[10] Epoch: 38 [38/100 (38%)] Train loss=0.383523 Test loss=0.362409 Current lr=[0.0009677882111908913]

[0/24] Train loss=0.402510404586792
[5/24] Train loss=0.3440116047859192
[10/24] Train loss=0.35102131962776184
[15/24] Train loss=0.3407639265060425
[20/24] Train loss=0.36152124404907227
Test set avg_accuracy=88.66% avg_sensitivity=71.44%, avg_specificity=94.25% avg_auc=92.69%
Fold[10] Epoch: 39 [39/100 (39%)] Train loss=0.382029 Test loss=0.365016 Current lr=[0.0009593957674920288]

[0/24] Train loss=0.34520381689071655
[5/24] Train loss=0.3323180675506592
[10/24] Train loss=0.3549097180366516
[15/24] Train loss=0.31061258912086487
[20/24] Train loss=0.35029229521751404
Test set avg_accuracy=88.49% avg_sensitivity=69.37%, avg_specificity=94.70% avg_auc=92.45%
Fold[10] Epoch: 40 [40/100 (40%)] Train loss=0.359087 Test loss=0.346287 Current lr=[0.0009500781658827677]

[0/24] Train loss=0.3936655819416046
[5/24] Train loss=0.3068973124027252
[10/24] Train loss=0.3623124361038208
[15/24] Train loss=0.3379668593406677
[20/24] Train loss=0.3393469750881195
Test set avg_accuracy=87.15% avg_sensitivity=80.63%, avg_specificity=89.27% avg_auc=92.69%
Fold[10] Epoch: 41 [41/100 (41%)] Train loss=0.357409 Test loss=0.409717 Current lr=[0.0009398541707727383]

[0/24] Train loss=0.38201460242271423
[5/24] Train loss=0.31434085965156555
[10/24] Train loss=0.31801003217697144
[15/24] Train loss=0.31706753373146057
[20/24] Train loss=0.30852726101875305
Test set avg_accuracy=88.22% avg_sensitivity=78.98%, avg_specificity=91.22% avg_auc=92.42%
Fold[10] Epoch: 42 [42/100 (42%)] Train loss=0.337419 Test loss=0.370719 Current lr=[0.0009287443719274561]

[0/24] Train loss=0.3294273018836975
[5/24] Train loss=0.2740856111049652
[10/24] Train loss=0.2998938262462616
[15/24] Train loss=0.3026057183742523
[20/24] Train loss=0.3025239408016205
Test set avg_accuracy=87.15% avg_sensitivity=80.79%, avg_specificity=89.22% avg_auc=92.45%
Fold[10] Epoch: 43 [43/100 (43%)] Train loss=0.320171 Test loss=0.398105 Current lr=[0.000916771143003274]

[0/24] Train loss=0.3262660801410675
[5/24] Train loss=0.25312715768814087
[10/24] Train loss=0.3046412169933319
[15/24] Train loss=0.2719181776046753
[20/24] Train loss=0.29837194085121155
Test set avg_accuracy=86.11% avg_sensitivity=82.22%, avg_specificity=87.37% avg_auc=92.29%
Fold[10] Epoch: 44 [44/100 (44%)] Train loss=0.310773 Test loss=0.426661 Current lr=[0.0009039585964898167]

[0/24] Train loss=0.338276743888855
[5/24] Train loss=0.3005586862564087
[10/24] Train loss=0.30551421642303467
[15/24] Train loss=0.30091971158981323
[20/24] Train loss=0.29233700037002563
Test set avg_accuracy=87.12% avg_sensitivity=81.58%, avg_specificity=88.92% avg_auc=92.42%
Fold[10] Epoch: 45 [45/100 (45%)] Train loss=0.309372 Test loss=0.428569 Current lr=[0.0008903325351506349]

[0/24] Train loss=0.31443139910697937
[5/24] Train loss=0.3386548161506653
[10/24] Train loss=0.33419331908226013
[15/24] Train loss=0.309277206659317
[20/24] Train loss=0.2925000786781311
Test set avg_accuracy=88.24% avg_sensitivity=79.19%, avg_specificity=91.18% avg_auc=92.32%
Fold[10] Epoch: 46 [46/100 (46%)] Train loss=0.307600 Test loss=0.391743 Current lr=[0.0008759204000598737]

[0/24] Train loss=0.30988267064094543
[5/24] Train loss=0.22177882492542267
[10/24] Train loss=0.2531631588935852
[15/24] Train loss=0.2854223847389221
[20/24] Train loss=0.2295922338962555
Test set avg_accuracy=88.20% avg_sensitivity=75.11%, avg_specificity=92.46% avg_auc=92.36%
Fold[10] Epoch: 47 [47/100 (47%)] Train loss=0.264305 Test loss=0.395871 Current lr=[0.000860751215339601]

[0/24] Train loss=0.2854476869106293
[5/24] Train loss=0.2320644110441208
[10/24] Train loss=0.24697764217853546
[15/24] Train loss=0.20741094648838043
[20/24] Train loss=0.22027099132537842
Test set avg_accuracy=87.23% avg_sensitivity=73.35%, avg_specificity=91.74% avg_auc=91.59%
Fold[10] Epoch: 48 [48/100 (48%)] Train loss=0.251172 Test loss=0.430582 Current lr=[0.0008448555297090884]

[0/24] Train loss=0.27769413590431213
[5/24] Train loss=0.24657294154167175
[10/24] Train loss=0.24374772608280182
[15/24] Train loss=0.21716564893722534
[20/24] Train loss=0.21487227082252502
Test set avg_accuracy=87.28% avg_sensitivity=78.45%, avg_specificity=90.15% avg_auc=92.37%
Fold[10] Epoch: 49 [49/100 (49%)] Train loss=0.245029 Test loss=0.444070 Current lr=[0.000828265354963756]

[0/24] Train loss=0.24456298351287842
[5/24] Train loss=0.2049531787633896
[10/24] Train loss=0.2602328658103943
[15/24] Train loss=0.2007555067539215
[20/24] Train loss=0.20015281438827515
Test set avg_accuracy=87.17% avg_sensitivity=80.52%, avg_specificity=89.34% avg_auc=91.95%
Fold[10] Epoch: 50 [50/100 (50%)] Train loss=0.222495 Test loss=0.475392 Current lr=[0.0008110141015076771]

[0/24] Train loss=0.2214099019765854
[5/24] Train loss=0.237664133310318
[10/24] Train loss=0.20020157098770142
[15/24] Train loss=0.17845551669597626
[20/24] Train loss=0.16654813289642334
Test set avg_accuracy=88.05% avg_sensitivity=77.71%, avg_specificity=91.41% avg_auc=91.98%
Fold[10] Epoch: 51 [51/100 (51%)] Train loss=0.210693 Test loss=0.495707 Current lr=[0.00079313651106947]

[0/24] Train loss=0.19643227756023407
[5/24] Train loss=0.18976081907749176
[10/24] Train loss=0.21162304282188416
[15/24] Train loss=0.15810896456241608
[20/24] Train loss=0.1667172908782959
Test set avg_accuracy=88.16% avg_sensitivity=78.72%, avg_specificity=91.24% avg_auc=92.16%
Fold[10] Epoch: 52 [52/100 (52%)] Train loss=0.187969 Test loss=0.479700 Current lr=[0.0007746685867370803]

[0/24] Train loss=0.22225965559482574
[5/24] Train loss=0.15790733695030212
[10/24] Train loss=0.17844779789447784
[15/24] Train loss=0.1591753363609314
[20/24] Train loss=0.1868172138929367
Test set avg_accuracy=88.05% avg_sensitivity=77.44%, avg_specificity=91.49% avg_auc=91.88%
Fold[10] Epoch: 53 [53/100 (53%)] Train loss=0.176731 Test loss=0.540508 Current lr=[0.0007556475204523538]

[0/24] Train loss=0.1824108511209488
[5/24] Train loss=0.1640777587890625
[10/24] Train loss=0.15476080775260925
[15/24] Train loss=0.12691538035869598
[20/24] Train loss=0.16504943370819092
Test set avg_accuracy=88.66% avg_sensitivity=76.59%, avg_specificity=92.58% avg_auc=92.41%
Fold[10] Epoch: 54 [54/100 (54%)] Train loss=0.162124 Test loss=0.560179 Current lr=[0.0007361116181114143]

[0/24] Train loss=0.1558673232793808
[5/24] Train loss=0.16190224885940552
[10/24] Train loss=0.16838981211185455
[15/24] Train loss=0.14551042020320892
[20/24] Train loss=0.1224394366145134
Test set avg_accuracy=88.24% avg_sensitivity=69.85%, avg_specificity=94.22% avg_auc=92.29%
Fold[10] Epoch: 55 [55/100 (55%)] Train loss=0.153288 Test loss=0.632373 Current lr=[0.0007161002224216871]

[0/24] Train loss=0.18130433559417725
[5/24] Train loss=0.14355501532554626
[10/24] Train loss=0.14449797570705414
[15/24] Train loss=0.13358017802238464
[20/24] Train loss=0.11106633394956589
Test set avg_accuracy=87.62% avg_sensitivity=68.31%, avg_specificity=93.89% avg_auc=91.82%
Fold[10] Epoch: 56 [56/100 (56%)] Train loss=0.142911 Test loss=0.636066 Current lr=[0.0006956536336709223]

[0/24] Train loss=0.13476398587226868
[5/24] Train loss=0.11728885024785995
[10/24] Train loss=0.12201275676488876
[15/24] Train loss=0.09301699697971344
[20/24] Train loss=0.11699032038450241
Test set avg_accuracy=87.89% avg_sensitivity=71.66%, avg_specificity=93.17% avg_auc=92.30%
Fold[10] Epoch: 57 [57/100 (57%)] Train loss=0.125422 Test loss=0.697209 Current lr=[0.0006748130285677782]

[0/24] Train loss=0.13228702545166016
[5/24] Train loss=0.09952516853809357
[10/24] Train loss=0.12389884889125824
[15/24] Train loss=0.08418586850166321
[20/24] Train loss=0.09213914722204208
Test set avg_accuracy=88.06% avg_sensitivity=73.41%, avg_specificity=92.82% avg_auc=92.41%
Fold[10] Epoch: 58 [58/100 (58%)] Train loss=0.112749 Test loss=0.657102 Current lr=[0.0006536203773174097]

[0/24] Train loss=0.10742035508155823
[5/24] Train loss=0.0830145850777626
[10/24] Train loss=0.1062738448381424
[15/24] Train loss=0.07932823896408081
[20/24] Train loss=0.08287603408098221
Test set avg_accuracy=87.70% avg_sensitivity=72.24%, avg_specificity=92.72% avg_auc=92.23%
Fold[10] Epoch: 59 [59/100 (59%)] Train loss=0.096614 Test loss=0.751507 Current lr=[0.0006321183590990616]

[0/24] Train loss=0.09426619112491608
[5/24] Train loss=0.08556774258613586
[10/24] Train loss=0.10486038774251938
[15/24] Train loss=0.0831599310040474
[20/24] Train loss=0.07743765413761139
Test set avg_accuracy=87.94% avg_sensitivity=72.29%, avg_specificity=93.03% avg_auc=92.08%
Fold[10] Epoch: 60 [60/100 (60%)] Train loss=0.090442 Test loss=0.707798 Current lr=[0.0006103502761158805]

[0/24] Train loss=0.08783219009637833
[5/24] Train loss=0.06936968863010406
[10/24] Train loss=0.08550676703453064
[15/24] Train loss=0.07712813466787338
[20/24] Train loss=0.07036910206079483
Test set avg_accuracy=88.39% avg_sensitivity=76.70%, avg_specificity=92.18% avg_auc=91.93%
Fold[10] Epoch: 61 [61/100 (61%)] Train loss=0.081739 Test loss=0.756080 Current lr=[0.0005883599663900407]

[0/24] Train loss=0.07111630588769913
[5/24] Train loss=0.06470410525798798
[10/24] Train loss=0.08409573882818222
[15/24] Train loss=0.07442393898963928
[20/24] Train loss=0.06381484866142273
Test set avg_accuracy=88.45% avg_sensitivity=74.89%, avg_specificity=92.86% avg_auc=92.23%
Fold[10] Epoch: 62 [62/100 (62%)] Train loss=0.077969 Test loss=0.704167 Current lr=[0.0005661917154788018]

[0/24] Train loss=0.07758437842130661
[5/24] Train loss=0.05777426064014435
[10/24] Train loss=0.0803845152258873
[15/24] Train loss=0.0630570501089096
[20/24] Train loss=0.08937971293926239
Test set avg_accuracy=88.48% avg_sensitivity=73.04%, avg_specificity=93.50% avg_auc=92.31%
Fold[10] Epoch: 63 [63/100 (63%)] Train loss=0.074566 Test loss=0.678602 Current lr=[0.0005438901672892898]

[0/24] Train loss=0.08778192102909088
[5/24] Train loss=0.05152680724859238
[10/24] Train loss=0.06849630922079086
[15/24] Train loss=0.05710025876760483
[20/24] Train loss=0.08163004368543625
Test set avg_accuracy=88.33% avg_sensitivity=74.95%, avg_specificity=92.68% avg_auc=92.31%
Fold[10] Epoch: 64 [64/100 (64%)] Train loss=0.066360 Test loss=0.697294 Current lr=[0.0005215002341716101]

[0/24] Train loss=0.05647026374936104
[5/24] Train loss=0.05374107509851456
[10/24] Train loss=0.06704948097467422
[15/24] Train loss=0.06764300912618637
[20/24] Train loss=0.06218056380748749
Test set avg_accuracy=87.79% avg_sensitivity=76.49%, avg_specificity=91.46% avg_auc=92.06%
Fold[10] Epoch: 65 [65/100 (65%)] Train loss=0.059883 Test loss=0.710955 Current lr=[0.0004990670064713503]

[0/24] Train loss=0.054841019213199615
[5/24] Train loss=0.05562632903456688
[10/24] Train loss=0.04810767248272896
[15/24] Train loss=0.05069342628121376
[20/24] Train loss=0.03768589720129967
Test set avg_accuracy=87.89% avg_sensitivity=74.47%, avg_specificity=92.25% avg_auc=92.08%
Fold[10] Epoch: 66 [66/100 (66%)] Train loss=0.055616 Test loss=0.743471 Current lr=[0.00047663566172362587]

[0/24] Train loss=0.051883287727832794
[5/24] Train loss=0.04113404080271721
[10/24] Train loss=0.056314822286367416
[15/24] Train loss=0.03953234478831291
[20/24] Train loss=0.04864362254738808
Test set avg_accuracy=88.22% avg_sensitivity=74.52%, avg_specificity=92.67% avg_auc=92.12%
Fold[10] Epoch: 67 [67/100 (67%)] Train loss=0.051993 Test loss=0.786996 Current lr=[0.0004542513736715361]

[0/24] Train loss=0.04550798982381821
[5/24] Train loss=0.03968004137277603
[10/24] Train loss=0.04566541686654091
[15/24] Train loss=0.04177051782608032
[20/24] Train loss=0.04046158865094185
Test set avg_accuracy=88.11% avg_sensitivity=71.82%, avg_specificity=93.41% avg_auc=92.02%
Fold[10] Epoch: 68 [68/100 (68%)] Train loss=0.048934 Test loss=0.825974 Current lr=[0.00043195922129225843]

[0/24] Train loss=0.04489974305033684
[5/24] Train loss=0.036650400608778
[10/24] Train loss=0.0481460876762867
[15/24] Train loss=0.03690429404377937
[20/24] Train loss=0.0512276366353035
Test set avg_accuracy=88.09% avg_sensitivity=73.41%, avg_specificity=92.86% avg_auc=92.11%
Fold[10] Epoch: 69 [69/100 (69%)] Train loss=0.045050 Test loss=0.790379 Current lr=[0.00040980409801398603]

[0/24] Train loss=0.03895032778382301
[5/24] Train loss=0.04430718719959259
[10/24] Train loss=0.04137776046991348
[15/24] Train loss=0.0406767874956131
[20/24] Train loss=0.03811467066407204
Test set avg_accuracy=88.46% avg_sensitivity=73.89%, avg_specificity=93.20% avg_auc=92.08%
Fold[10] Epoch: 70 [70/100 (70%)] Train loss=0.042582 Test loss=0.801432 Current lr=[0.0003878306213065398]

[0/24] Train loss=0.03796699270606041
[5/24] Train loss=0.04100722074508667
[10/24] Train loss=0.04031353071331978
[15/24] Train loss=0.03404843062162399
[20/24] Train loss=0.03154189884662628
Test set avg_accuracy=88.19% avg_sensitivity=72.08%, avg_specificity=93.43% avg_auc=92.12%
Fold[10] Epoch: 71 [71/100 (71%)] Train loss=0.039104 Test loss=0.792032 Current lr=[0.0003660830428277199]

[0/24] Train loss=0.03976893797516823
[5/24] Train loss=0.03704158589243889
[10/24] Train loss=0.03778502345085144
[15/24] Train loss=0.03498179465532303
[20/24] Train loss=0.03549996390938759
Test set avg_accuracy=88.71% avg_sensitivity=75.27%, avg_specificity=93.08% avg_auc=92.13%
Fold[10] Epoch: 72 [72/100 (72%)] Train loss=0.037233 Test loss=0.793145 Current lr=[0.0003446051593063582]

[0/24] Train loss=0.036635760217905045
[5/24] Train loss=0.027979588136076927
[10/24] Train loss=0.04581779986619949
[15/24] Train loss=0.028055116534233093
[20/24] Train loss=0.03734470531344414
Test set avg_accuracy=88.07% avg_sensitivity=75.11%, avg_specificity=92.29% avg_auc=92.16%
Fold[10] Epoch: 73 [73/100 (73%)] Train loss=0.035921 Test loss=0.833558 Current lr=[0.00032344022434153323]

[0/24] Train loss=0.03418431431055069
[5/24] Train loss=0.030473753809928894
[10/24] Train loss=0.02801336906850338
[15/24] Train loss=0.03221963346004486
[20/24] Train loss=0.028762461617588997
Test set avg_accuracy=87.94% avg_sensitivity=73.73%, avg_specificity=92.56% avg_auc=92.19%
Fold[10] Epoch: 74 [74/100 (74%)] Train loss=0.032714 Test loss=0.818717 Current lr=[0.0003026308612955792]

[0/24] Train loss=0.03203488513827324
[5/24] Train loss=0.025884106755256653
[10/24] Train loss=0.027556011453270912
[15/24] Train loss=0.026723267510533333
[20/24] Train loss=0.019387120380997658
Test set avg_accuracy=88.39% avg_sensitivity=75.37%, avg_specificity=92.62% avg_auc=92.19%
Fold[10] Epoch: 75 [75/100 (75%)] Train loss=0.029294 Test loss=0.849618 Current lr=[0.00028221897745630566]

[0/24] Train loss=0.0337393544614315
[5/24] Train loss=0.03203549236059189
[10/24] Train loss=0.040933072566986084
[15/24] Train loss=0.02028607577085495
[20/24] Train loss=0.03198792785406113
Test set avg_accuracy=88.33% avg_sensitivity=72.56%, avg_specificity=93.46% avg_auc=92.12%
Fold[10] Epoch: 76 [76/100 (76%)] Train loss=0.029938 Test loss=0.797120 Current lr=[0.000262245679641298]

[0/24] Train loss=0.030227985233068466
[5/24] Train loss=0.019610587507486343
[10/24] Train loss=0.031249921768903732
[15/24] Train loss=0.02078889310359955
[20/24] Train loss=0.022209664806723595
Test set avg_accuracy=88.10% avg_sensitivity=74.15%, avg_specificity=92.63% avg_auc=92.14%
Fold[10] Epoch: 77 [77/100 (77%)] Train loss=0.027683 Test loss=0.857813 Current lr=[0.00024275119141425641]

[0/24] Train loss=0.02477261610329151
[5/24] Train loss=0.02451026439666748
[10/24] Train loss=0.031018245965242386
[15/24] Train loss=0.02871081419289112
[20/24] Train loss=0.025395315140485764
Test set avg_accuracy=88.32% avg_sensitivity=74.36%, avg_specificity=92.86% avg_auc=92.20%
Fold[10] Epoch: 78 [78/100 (78%)] Train loss=0.025869 Test loss=0.837130 Current lr=[0.00022377477208009256]

[0/24] Train loss=0.026236189529299736
[5/24] Train loss=0.021323584020137787
[10/24] Train loss=0.023357221856713295
[15/24] Train loss=0.022960115224123
[20/24] Train loss=0.02018030546605587
Test set avg_accuracy=88.26% avg_sensitivity=73.30%, avg_specificity=93.12% avg_auc=92.22%
Fold[10] Epoch: 79 [79/100 (79%)] Train loss=0.024954 Test loss=0.868302 Current lr=[0.00020535463762191364]

[0/24] Train loss=0.02536487951874733
[5/24] Train loss=0.021232182160019875
[10/24] Train loss=0.019132552668452263
[15/24] Train loss=0.02420627512037754
[20/24] Train loss=0.02166779711842537
Test set avg_accuracy=88.28% avg_sensitivity=74.20%, avg_specificity=92.86% avg_auc=92.26%
Fold[10] Epoch: 80 [80/100 (80%)] Train loss=0.026049 Test loss=0.828896 Current lr=[0.00018752788373911847]

[0/24] Train loss=0.030374787747859955
[5/24] Train loss=0.02350420132279396
[10/24] Train loss=0.022302187979221344
[15/24] Train loss=0.01959424838423729
[20/24] Train loss=0.02595708891749382
Test set avg_accuracy=88.23% avg_sensitivity=74.42%, avg_specificity=92.72% avg_auc=92.26%
Fold[10] Epoch: 81 [81/100 (81%)] Train loss=0.023753 Test loss=0.903998 Current lr=[0.0001703304111415958]

[0/24] Train loss=0.02357286401093006
[5/24] Train loss=0.018872084096074104
[10/24] Train loss=0.018665362149477005
[15/24] Train loss=0.024643221870064735
[20/24] Train loss=0.017206648364663124
Test set avg_accuracy=88.44% avg_sensitivity=74.52%, avg_specificity=92.96% avg_auc=92.29%
Fold[10] Epoch: 82 [82/100 (82%)] Train loss=0.024037 Test loss=0.912766 Current lr=[0.00015379685325047203]

[0/24] Train loss=0.025733761489391327
[5/24] Train loss=0.02082742191851139
[10/24] Train loss=0.023418724536895752
[15/24] Train loss=0.018625784665346146
[20/24] Train loss=0.015529990196228027
Test set avg_accuracy=88.41% avg_sensitivity=73.30%, avg_specificity=93.32% avg_auc=92.21%
Fold[10] Epoch: 83 [83/100 (83%)] Train loss=0.022522 Test loss=0.857039 Current lr=[0.00013796050645101065]

[0/24] Train loss=0.02160746417939663
[5/24] Train loss=0.028060078620910645
[10/24] Train loss=0.023158345371484756
[15/24] Train loss=0.01338997669517994
[20/24] Train loss=0.020721914246678352
Test set avg_accuracy=88.50% avg_sensitivity=74.73%, avg_specificity=92.98% avg_auc=92.21%
Fold[10] Epoch: 84 [84/100 (84%)] Train loss=0.021531 Test loss=0.903780 Current lr=[0.000122853263038123]

[0/24] Train loss=0.023600110784173012
[5/24] Train loss=0.021321939304471016
[10/24] Train loss=0.021776050329208374
[15/24] Train loss=0.013391736894845963
[20/24] Train loss=0.022881269454956055
Test set avg_accuracy=88.46% avg_sensitivity=74.31%, avg_specificity=93.06% avg_auc=92.24%
Fold[10] Epoch: 85 [85/100 (85%)] Train loss=0.022010 Test loss=0.896014 Current lr=[0.00010850554698953107]

[0/24] Train loss=0.02830103226006031
[5/24] Train loss=0.017818547785282135
[10/24] Train loss=0.012799589894711971
[15/24] Train loss=0.018036797642707825
[20/24] Train loss=0.01705246977508068
Test set avg_accuracy=88.49% avg_sensitivity=74.47%, avg_specificity=93.05% avg_auc=92.26%
Fold[10] Epoch: 86 [86/100 (86%)] Train loss=0.021274 Test loss=0.870304 Current lr=[9.494625269592486e-05]

[0/24] Train loss=0.018670450896024704
[5/24] Train loss=0.02835310623049736
[10/24] Train loss=0.017710130661725998
[15/24] Train loss=0.012072639539837837
[20/24] Train loss=0.021756233647465706
Test set avg_accuracy=88.45% avg_sensitivity=74.52%, avg_specificity=92.98% avg_auc=92.26%
Fold[10] Epoch: 87 [87/100 (87%)] Train loss=0.021878 Test loss=0.854404 Current lr=[8.220268677150526e-05]

[0/24] Train loss=0.024687545374035835
[5/24] Train loss=0.016663232818245888
[10/24] Train loss=0.01836942508816719
[15/24] Train loss=0.01571596786379814
[20/24] Train loss=0.018327610567212105
Test set avg_accuracy=88.46% avg_sensitivity=74.79%, avg_specificity=92.91% avg_auc=92.23%
Fold[10] Epoch: 88 [88/100 (88%)] Train loss=0.020476 Test loss=0.898526 Current lr=[7.030051306209665e-05]

[0/24] Train loss=0.023763542994856834
[5/24] Train loss=0.01881827600300312
[10/24] Train loss=0.02160004898905754
[15/24] Train loss=0.019106313586235046
[20/24] Train loss=0.020207688212394714
Test set avg_accuracy=88.36% avg_sensitivity=74.20%, avg_specificity=92.96% avg_auc=92.27%
Fold[10] Epoch: 89 [89/100 (89%)] Train loss=0.021828 Test loss=0.874791 Current lr=[5.9263700961577334e-05]

[0/24] Train loss=0.018974605947732925
[5/24] Train loss=0.016554368659853935
[10/24] Train loss=0.016166258603334427
[15/24] Train loss=0.015212133526802063
[20/24] Train loss=0.019149620085954666
Test set avg_accuracy=88.44% avg_sensitivity=74.63%, avg_specificity=92.93% avg_auc=92.27%
Fold[10] Epoch: 90 [90/100 (90%)] Train loss=0.020041 Test loss=0.874161 Current lr=[4.911447714070982e-05]

[0/24] Train loss=0.020089279860258102
[5/24] Train loss=0.021228782832622528
[10/24] Train loss=0.01579918898642063
[15/24] Train loss=0.016582835465669632
[20/24] Train loss=0.012214980088174343
Test set avg_accuracy=88.46% avg_sensitivity=74.73%, avg_specificity=92.93% avg_auc=92.26%
Fold[10] Epoch: 91 [91/100 (91%)] Train loss=0.019580 Test loss=0.887247 Current lr=[3.987328078558366e-05]

[0/24] Train loss=0.015989091247320175
[5/24] Train loss=0.016013028100132942
[10/24] Train loss=0.023936426267027855
[15/24] Train loss=0.01672140508890152
[20/24] Train loss=0.01437945943325758
Test set avg_accuracy=88.49% avg_sensitivity=74.89%, avg_specificity=92.91% avg_auc=92.24%
Fold[10] Epoch: 92 [92/100 (92%)] Train loss=0.019516 Test loss=0.892490 Current lr=[3.155872243581568e-05]

[0/24] Train loss=0.024202121421694756
[5/24] Train loss=0.012654701247811317
[10/24] Train loss=0.031154608353972435
[15/24] Train loss=0.01602127030491829
[20/24] Train loss=0.015901466831564903
Test set avg_accuracy=88.50% avg_sensitivity=74.79%, avg_specificity=92.96% avg_auc=92.26%
Fold[10] Epoch: 93 [93/100 (93%)] Train loss=0.019708 Test loss=0.903584 Current lr=[2.418754650539889e-05]

[0/24] Train loss=0.017381813377141953
[5/24] Train loss=0.012777332216501236
[10/24] Train loss=0.01635764352977276
[15/24] Train loss=0.015585707500576973
[20/24] Train loss=0.01381567120552063
Test set avg_accuracy=88.54% avg_sensitivity=74.84%, avg_specificity=93.00% avg_auc=92.27%
Fold[10] Epoch: 94 [94/100 (94%)] Train loss=0.018613 Test loss=0.904580 Current lr=[1.77745975616817e-05]

[0/24] Train loss=0.01700170710682869
[5/24] Train loss=0.016135867685079575
[10/24] Train loss=0.021662402898073196
[15/24] Train loss=0.019426558166742325
[20/24] Train loss=0.0176809374243021
Test set avg_accuracy=88.49% avg_sensitivity=74.68%, avg_specificity=92.98% avg_auc=92.27%
Fold[10] Epoch: 95 [95/100 (95%)] Train loss=0.018656 Test loss=0.904699 Current lr=[1.2332790430384687e-05]

[0/24] Train loss=0.023053858429193497
[5/24] Train loss=0.015041057951748371
[10/24] Train loss=0.019203823059797287
[15/24] Train loss=0.022247767075896263
[20/24] Train loss=0.01653851382434368
Test set avg_accuracy=88.52% avg_sensitivity=74.79%, avg_specificity=92.98% avg_auc=92.28%
Fold[10] Epoch: 96 [96/100 (96%)] Train loss=0.019566 Test loss=0.902927 Current lr=[7.873084186860226e-06]

[0/24] Train loss=0.021251309663057327
[5/24] Train loss=0.014624574221670628
[10/24] Train loss=0.026541968807578087
[15/24] Train loss=0.02131335809826851
[20/24] Train loss=0.0155210942029953
Test set avg_accuracy=88.52% avg_sensitivity=74.68%, avg_specificity=93.01% avg_auc=92.28%
Fold[10] Epoch: 97 [97/100 (97%)] Train loss=0.020713 Test loss=0.902227 Current lr=[4.404460085973346e-06]

[0/24] Train loss=0.017069784924387932
[5/24] Train loss=0.015049891546368599
[10/24] Train loss=0.015239862725138664
[15/24] Train loss=0.013196478597819805
[20/24] Train loss=0.0154960248619318
Test set avg_accuracy=88.49% avg_sensitivity=74.68%, avg_specificity=92.98% avg_auc=92.27%
Fold[10] Epoch: 98 [98/100 (98%)] Train loss=0.018928 Test loss=0.901296 Current lr=[1.933903475049599e-06]

[0/24] Train loss=0.01725859008729458
[5/24] Train loss=0.01245553232729435
[10/24] Train loss=0.017990322783589363
[15/24] Train loss=0.01985338144004345
[20/24] Train loss=0.020242974162101746
Test set avg_accuracy=88.49% avg_sensitivity=74.68%, avg_specificity=92.98% avg_auc=92.27%
Fold[10] Epoch: 99 [99/100 (99%)] Train loss=0.019311 Test loss=0.901760 Current lr=[4.6638972631532304e-07]

[0/24] Train loss=0.023330288007855415
[5/24] Train loss=0.015395751222968102
[10/24] Train loss=0.0201894398778677
[15/24] Train loss=0.021766850724816322
[20/24] Train loss=0.018676063045859337
Test set avg_accuracy=88.49% avg_sensitivity=74.68%, avg_specificity=92.98% avg_auc=92.27%
Fold[10] Epoch: 100 [100/100 (100%)] Train loss=0.019377 Test loss=0.902148 Current lr=[4.874217159761039e-09]

Fold[10] Result: acc=88.98% sen=70.86%, spe=94.88%, auc=93.33%!
Fold[10] Avg_overlap=0.71%(Â±0.25789046249555697)
Final Avg Result: avg_acc=89.73%(Â±0.8290055536434261) avg_sen=77.97% (Â±4.169399400389066) avg_spe=93.79% (Â±1.618919200600617) avg_auc=94.67% (Â±0.9473264640208297) avg_overlap=0.71% (Â±0.024527322924219035)
