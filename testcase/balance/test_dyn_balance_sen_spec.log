/home/jol/anaconda3/envs/jolpy/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (14) may be set too low.
  warnings.warn(
[0/24] Train loss=1.4338245391845703
[5/24] Train loss=1.2948658466339111
[10/24] Train loss=1.3191691637039185
[15/24] Train loss=1.119014024734497
[20/24] Train loss=1.0381377935409546
Test set avg_accuracy=74.34% avg_sensitivity=21.55%, avg_specificity=92.05% avg_auc=0.7881
Best model saved!! Metric=0.7881407524217166!!
Fold[1] Epoch: 1 [1/150 (1%)] Train loss=1.231164 Test loss=0.541778 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=1.0486690998077393
[5/24] Train loss=0.8984152674674988
[10/24] Train loss=1.0391547679901123
[15/24] Train loss=0.8639929890632629
[20/24] Train loss=0.8363573551177979
Test set avg_accuracy=81.26% avg_sensitivity=66.37%, avg_specificity=86.26% avg_auc=0.8687
Best model saved!! Metric=0.8686795224149583!!
Fold[1] Epoch: 2 [2/150 (1%)] Train loss=0.945726 Test loss=0.473324 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.8126915693283081
[5/24] Train loss=0.7979587912559509
[10/24] Train loss=0.9059948325157166
[15/24] Train loss=0.7994526028633118
[20/24] Train loss=0.7791626453399658
Test set avg_accuracy=81.20% avg_sensitivity=82.02%, avg_specificity=80.92% avg_auc=0.8902
Best model saved!! Metric=0.8902283847713449!!
Fold[1] Epoch: 3 [3/150 (2%)] Train loss=0.837497 Test loss=0.504009 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.8541848659515381
[5/24] Train loss=0.7607132196426392
[10/24] Train loss=0.9434397220611572
[15/24] Train loss=0.7783352136611938
[20/24] Train loss=0.7584133744239807
Test set avg_accuracy=82.96% avg_sensitivity=73.63%, avg_specificity=86.09% avg_auc=0.8969
Best model saved!! Metric=0.8968764136066681!!
Fold[1] Epoch: 4 [4/150 (3%)] Train loss=0.835886 Test loss=0.428481 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.8031507134437561
[5/24] Train loss=0.7034815549850464
[10/24] Train loss=0.8532191514968872
[15/24] Train loss=0.7439804673194885
[20/24] Train loss=0.7681256532669067
Test set avg_accuracy=79.09% avg_sensitivity=89.84%, avg_specificity=75.48% avg_auc=0.9116
Best model saved!! Metric=0.9115926109484117!!
Fold[1] Epoch: 5 [5/150 (3%)] Train loss=0.781270 Test loss=0.581342 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.7747023105621338
[5/24] Train loss=0.7369974255561829
[10/24] Train loss=0.8631428480148315
[15/24] Train loss=0.6997188925743103
[20/24] Train loss=0.7009678483009338
Test set avg_accuracy=83.26% avg_sensitivity=84.51%, avg_specificity=82.83% avg_auc=0.9220
Best model saved!! Metric=0.9220486596080198!!
Fold[1] Epoch: 6 [6/150 (4%)] Train loss=0.772595 Test loss=0.428906 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.7424321174621582
[5/24] Train loss=0.6968426704406738
[10/24] Train loss=0.8274675011634827
[15/24] Train loss=0.7369472980499268
[20/24] Train loss=0.7082992792129517
Test set avg_accuracy=84.47% avg_sensitivity=82.07%, avg_specificity=85.27% avg_auc=0.9278
Best model saved!! Metric=0.9278069835548547!!
Fold[1] Epoch: 7 [7/150 (5%)] Train loss=0.745820 Test loss=0.362147 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.7377981543540955
[5/24] Train loss=0.6594254970550537
[10/24] Train loss=0.8002086877822876
[15/24] Train loss=0.7708730697631836
[20/24] Train loss=0.628961980342865
Test set avg_accuracy=80.83% avg_sensitivity=90.67%, avg_specificity=77.53% avg_auc=0.9304
Best model saved!! Metric=0.9304414057220094!!
Fold[1] Epoch: 8 [8/150 (5%)] Train loss=0.713217 Test loss=0.513624 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.7406752705574036
[5/24] Train loss=0.6400691270828247
[10/24] Train loss=0.8001573085784912
[15/24] Train loss=0.7071657180786133
[20/24] Train loss=0.6958147883415222
Test set avg_accuracy=84.91% avg_sensitivity=81.04%, avg_specificity=86.21% avg_auc=0.9330
Best model saved!! Metric=0.9329759855823384!!
Fold[1] Epoch: 9 [9/150 (6%)] Train loss=0.720556 Test loss=0.329770 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.7085097432136536
[5/24] Train loss=0.6499756574630737
[10/24] Train loss=0.7605466842651367
[15/24] Train loss=0.715846061706543
[20/24] Train loss=0.6131519675254822
Test set avg_accuracy=79.56% avg_sensitivity=92.02%, avg_specificity=75.37% avg_auc=0.9331
Best model saved!! Metric=0.9330965082225727!!
Fold[1] Epoch: 10 [10/150 (7%)] Train loss=0.689049 Test loss=0.510287 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.7150278687477112
[5/24] Train loss=0.6429343819618225
[10/24] Train loss=0.753095269203186
[15/24] Train loss=0.6542471051216125
[20/24] Train loss=0.6386154890060425
Test set avg_accuracy=85.13% avg_sensitivity=84.61%, avg_specificity=85.30% avg_auc=0.9358
Best model saved!! Metric=0.9358088758729444!!
Fold[1] Epoch: 11 [11/150 (7%)] Train loss=0.683721 Test loss=0.349453 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.6287084817886353
[5/24] Train loss=0.5774117708206177
[10/24] Train loss=0.7308461666107178
[15/24] Train loss=0.6529596447944641
[20/24] Train loss=0.5873697400093079
Test set avg_accuracy=82.66% avg_sensitivity=88.55%, avg_specificity=80.68% avg_auc=0.9372
Best model saved!! Metric=0.9371500788465871!!
Fold[1] Epoch: 12 [12/150 (8%)] Train loss=0.645211 Test loss=0.417572 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6635838747024536
[5/24] Train loss=0.6035758256912231
[10/24] Train loss=0.709624171257019
[15/24] Train loss=0.6771127581596375
[20/24] Train loss=0.6020724177360535
Test set avg_accuracy=82.92% avg_sensitivity=88.91%, avg_specificity=80.90% avg_auc=0.9373
Best model saved!! Metric=0.9372675827889165!!
Fold[1] Epoch: 13 [13/150 (9%)] Train loss=0.650597 Test loss=0.402689 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.6721073389053345
[5/24] Train loss=0.57753986120224
[10/24] Train loss=0.7045058012008667
[15/24] Train loss=0.6289680600166321
[20/24] Train loss=0.6373072266578674
Test set avg_accuracy=84.38% avg_sensitivity=87.15%, avg_specificity=83.44% avg_auc=0.9374
Best model saved!! Metric=0.937446091462041!!
Fold[1] Epoch: 14 [14/150 (9%)] Train loss=0.645677 Test loss=0.356430 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.6908305883407593
[5/24] Train loss=0.5488295555114746
[10/24] Train loss=0.7019593119621277
[15/24] Train loss=0.6275521516799927
[20/24] Train loss=0.6241275072097778
Test set avg_accuracy=87.45% avg_sensitivity=75.70%, avg_specificity=91.39% avg_auc=0.9392
Best model saved!! Metric=0.9392303671998199!!
Fold[1] Epoch: 15 [15/150 (10%)] Train loss=0.632371 Test loss=0.278403 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.6320001482963562
[5/24] Train loss=0.5361442565917969
[10/24] Train loss=0.6939083933830261
[15/24] Train loss=0.600591778755188
[20/24] Train loss=0.5796780586242676
Test set avg_accuracy=87.21% avg_sensitivity=79.53%, avg_specificity=89.79% avg_auc=0.9367
Fold[1] Epoch: 16 [16/150 (11%)] Train loss=0.611454 Test loss=0.304393 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.6172288656234741
[5/24] Train loss=0.5483124852180481
[10/24] Train loss=0.693581759929657
[15/24] Train loss=0.5808606743812561
[20/24] Train loss=0.5617294311523438
Test set avg_accuracy=84.06% avg_sensitivity=87.82%, avg_specificity=82.80% avg_auc=0.9352
Fold[1] Epoch: 17 [17/150 (11%)] Train loss=0.602829 Test loss=0.395658 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.6337428689002991
[5/24] Train loss=0.518748939037323
[10/24] Train loss=0.6492164731025696
[15/24] Train loss=0.5942291021347046
[20/24] Train loss=0.5183188915252686
Test set avg_accuracy=87.63% avg_sensitivity=76.22%, avg_specificity=91.46% avg_auc=0.9366
Fold[1] Epoch: 18 [18/150 (12%)] Train loss=0.597108 Test loss=0.287265 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.6187390089035034
[5/24] Train loss=0.5326371192932129
[10/24] Train loss=0.6534321308135986
[15/24] Train loss=0.5668350458145142
[20/24] Train loss=0.548994779586792
Test set avg_accuracy=85.74% avg_sensitivity=86.01%, avg_specificity=85.65% avg_auc=0.9358
Fold[1] Epoch: 19 [19/150 (13%)] Train loss=0.590850 Test loss=0.358605 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.6268345713615417
[5/24] Train loss=0.5344163775444031
[10/24] Train loss=0.6622169613838196
[15/24] Train loss=0.5803453326225281
[20/24] Train loss=0.5742266774177551
Test set avg_accuracy=87.75% avg_sensitivity=74.46%, avg_specificity=92.21% avg_auc=0.9341
Fold[1] Epoch: 20 [20/150 (13%)] Train loss=0.588888 Test loss=0.292427 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.6065880656242371
[5/24] Train loss=0.5254368782043457
[10/24] Train loss=0.6552168726921082
[15/24] Train loss=0.5837056636810303
[20/24] Train loss=0.4981074035167694
Test set avg_accuracy=85.90% avg_sensitivity=83.21%, avg_specificity=86.80% avg_auc=0.9346
Fold[1] Epoch: 21 [21/150 (14%)] Train loss=0.573959 Test loss=0.340510 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.5710743069648743
[5/24] Train loss=0.5095006227493286
[10/24] Train loss=0.6333587169647217
[15/24] Train loss=0.5693964958190918
[20/24] Train loss=0.5026686787605286
Test set avg_accuracy=86.00% avg_sensitivity=84.40%, avg_specificity=86.54% avg_auc=0.9388
Fold[1] Epoch: 22 [22/150 (15%)] Train loss=0.561705 Test loss=0.333024 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.5611738562583923
[5/24] Train loss=0.5260029435157776
[10/24] Train loss=0.6261487007141113
[15/24] Train loss=0.5519002079963684
[20/24] Train loss=0.48688191175460815
Test set avg_accuracy=84.13% avg_sensitivity=88.13%, avg_specificity=82.78% avg_auc=0.9375
Fold[1] Epoch: 23 [23/150 (15%)] Train loss=0.554174 Test loss=0.404918 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5247583985328674
[5/24] Train loss=0.4963018596172333
[10/24] Train loss=0.6142750382423401
[15/24] Train loss=0.5703697204589844
[20/24] Train loss=0.5054425597190857
Test set avg_accuracy=81.69% avg_sensitivity=88.65%, avg_specificity=79.36% avg_auc=0.9395
Best model saved!! Metric=0.9395105654426673!!
Fold[1] Epoch: 24 [24/150 (16%)] Train loss=0.552402 Test loss=0.414575 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.5749373435974121
[5/24] Train loss=0.47016724944114685
[10/24] Train loss=0.6077317595481873
[15/24] Train loss=0.5611535310745239
[20/24] Train loss=0.4743092954158783
Test set avg_accuracy=87.30% avg_sensitivity=75.75%, avg_specificity=91.18% avg_auc=0.9334
Fold[1] Epoch: 25 [25/150 (17%)] Train loss=0.550818 Test loss=0.302105 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.6042864918708801
[5/24] Train loss=0.4957314431667328
[10/24] Train loss=0.6127262711524963
[15/24] Train loss=0.5160086154937744
[20/24] Train loss=0.4702031910419464
Test set avg_accuracy=86.11% avg_sensitivity=83.26%, avg_specificity=87.06% avg_auc=0.9370
Fold[1] Epoch: 26 [26/150 (17%)] Train loss=0.536079 Test loss=0.349695 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5103581547737122
[5/24] Train loss=0.4636085629463196
[10/24] Train loss=0.6072052121162415
[15/24] Train loss=0.5017261505126953
[20/24] Train loss=0.45017555356025696
Test set avg_accuracy=84.61% avg_sensitivity=87.05%, avg_specificity=83.79% avg_auc=0.9378
Fold[1] Epoch: 27 [27/150 (18%)] Train loss=0.507447 Test loss=0.415924 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5408381819725037
[5/24] Train loss=0.5025737285614014
[10/24] Train loss=0.567127525806427
[15/24] Train loss=0.5240244269371033
[20/24] Train loss=0.4388943016529083
Test set avg_accuracy=86.45% avg_sensitivity=82.28%, avg_specificity=87.84% avg_auc=0.9357
Fold[1] Epoch: 28 [28/150 (19%)] Train loss=0.527333 Test loss=0.355490 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5472055673599243
[5/24] Train loss=0.4236077666282654
[10/24] Train loss=0.5616757869720459
[15/24] Train loss=0.4905765652656555
[20/24] Train loss=0.41097599267959595
Test set avg_accuracy=81.73% avg_sensitivity=88.81%, avg_specificity=79.36% avg_auc=0.9365
Fold[1] Epoch: 29 [29/150 (19%)] Train loss=0.488849 Test loss=0.485053 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.5005308389663696
[5/24] Train loss=0.45425838232040405
[10/24] Train loss=0.5801169276237488
[15/24] Train loss=0.4540121257305145
[20/24] Train loss=0.4548879861831665
Test set avg_accuracy=86.46% avg_sensitivity=84.46%, avg_specificity=87.13% avg_auc=0.9409
Best model saved!! Metric=0.9408908763234962!!
Fold[1] Epoch: 30 [30/150 (20%)] Train loss=0.513427 Test loss=0.360860 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.4713880121707916
[5/24] Train loss=0.44264745712280273
[10/24] Train loss=0.595653772354126
[15/24] Train loss=0.4733481705188751
[20/24] Train loss=0.3972140848636627
Test set avg_accuracy=85.95% avg_sensitivity=85.49%, avg_specificity=86.10% avg_auc=0.9403
Fold[1] Epoch: 31 [31/150 (21%)] Train loss=0.491677 Test loss=0.384644 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.4869692325592041
[5/24] Train loss=0.43448498845100403
[10/24] Train loss=0.5406632423400879
[15/24] Train loss=0.4402075707912445
[20/24] Train loss=0.42024800181388855
Test set avg_accuracy=86.17% avg_sensitivity=86.11%, avg_specificity=86.19% avg_auc=0.9339
Fold[1] Epoch: 32 [32/150 (21%)] Train loss=0.471544 Test loss=0.392259 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.4765373468399048
[5/24] Train loss=0.39604103565216064
[10/24] Train loss=0.5359622240066528
[15/24] Train loss=0.5053143501281738
[20/24] Train loss=0.3879774808883667
Test set avg_accuracy=78.07% avg_sensitivity=92.95%, avg_specificity=73.08% avg_auc=0.9383
Fold[1] Epoch: 33 [33/150 (22%)] Train loss=0.457470 Test loss=0.649007 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.4646168351173401
[5/24] Train loss=0.44410642981529236
[10/24] Train loss=0.6193413734436035
[15/24] Train loss=0.40830162167549133
[20/24] Train loss=0.3943959176540375
Test set avg_accuracy=77.17% avg_sensitivity=92.59%, avg_specificity=72.00% avg_auc=0.9386
Fold[1] Epoch: 34 [34/150 (23%)] Train loss=0.479374 Test loss=0.574915 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.5037906169891357
[5/24] Train loss=0.43279650807380676
[10/24] Train loss=0.48285502195358276
[15/24] Train loss=0.4084179401397705
[20/24] Train loss=0.3987029194831848
Test set avg_accuracy=85.78% avg_sensitivity=82.80%, avg_specificity=86.78% avg_auc=0.9323
Fold[1] Epoch: 35 [35/150 (23%)] Train loss=0.472928 Test loss=0.371493 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.4807237982749939
[5/24] Train loss=0.365366131067276
[10/24] Train loss=0.4408937096595764
[15/24] Train loss=0.4142456352710724
[20/24] Train loss=0.41112014651298523
Test set avg_accuracy=83.09% avg_sensitivity=86.89%, avg_specificity=81.81% avg_auc=0.9329
Fold[1] Epoch: 36 [36/150 (24%)] Train loss=0.434629 Test loss=0.421828 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.44900432229042053
[5/24] Train loss=0.39383673667907715
[10/24] Train loss=0.4870109558105469
[15/24] Train loss=0.37680551409721375
[20/24] Train loss=0.36925408244132996
Test set avg_accuracy=84.60% avg_sensitivity=86.68%, avg_specificity=83.90% avg_auc=0.9360
Fold[1] Epoch: 37 [37/150 (25%)] Train loss=0.432516 Test loss=0.393725 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.4497515857219696
[5/24] Train loss=0.4064444303512573
[10/24] Train loss=0.5192421674728394
[15/24] Train loss=0.3771391808986664
[20/24] Train loss=0.40609070658683777
Test set avg_accuracy=88.26% avg_sensitivity=76.68%, avg_specificity=92.14% avg_auc=0.9328
Fold[1] Epoch: 38 [38/150 (25%)] Train loss=0.437680 Test loss=0.322739 Current lr=[0.000944367614404117]

[0/24] Train loss=0.40066683292388916
[5/24] Train loss=0.3641612231731415
[10/24] Train loss=0.4538511335849762
[15/24] Train loss=0.3134361207485199
[20/24] Train loss=0.33991822600364685
Test set avg_accuracy=86.02% avg_sensitivity=82.90%, avg_specificity=87.06% avg_auc=0.9279
Fold[1] Epoch: 39 [39/150 (26%)] Train loss=0.397120 Test loss=0.379963 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.38696786761283875
[5/24] Train loss=0.3255106806755066
[10/24] Train loss=0.3916613459587097
[15/24] Train loss=0.391663134098053
[20/24] Train loss=0.3545990288257599
Test set avg_accuracy=84.22% avg_sensitivity=87.31%, avg_specificity=83.18% avg_auc=0.9329
Fold[1] Epoch: 40 [40/150 (27%)] Train loss=0.373089 Test loss=0.463719 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.4205598533153534
[5/24] Train loss=0.3569970428943634
[10/24] Train loss=0.3771434426307678
[15/24] Train loss=0.31327852606773376
[20/24] Train loss=0.3918878734111786
Test set avg_accuracy=85.64% avg_sensitivity=85.39%, avg_specificity=85.72% avg_auc=0.9346
Fold[1] Epoch: 41 [41/150 (27%)] Train loss=0.401618 Test loss=0.420716 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.40293949842453003
[5/24] Train loss=0.3160981833934784
[10/24] Train loss=0.37520772218704224
[15/24] Train loss=0.30242985486984253
[20/24] Train loss=0.3317146599292755
Test set avg_accuracy=84.44% avg_sensitivity=85.80%, avg_specificity=83.98% avg_auc=0.9303
Fold[1] Epoch: 42 [42/150 (28%)] Train loss=0.361758 Test loss=0.446428 Current lr=[0.000989780311725182]

[0/24] Train loss=0.36538344621658325
[5/24] Train loss=0.3341815173625946
[10/24] Train loss=0.41230490803718567
[15/24] Train loss=0.2858647406101227
[20/24] Train loss=0.34564676880836487
Test set avg_accuracy=84.17% avg_sensitivity=86.94%, avg_specificity=83.23% avg_auc=0.9345
Fold[1] Epoch: 43 [43/150 (29%)] Train loss=0.358922 Test loss=0.421013 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.4258267283439636
[5/24] Train loss=0.3109525442123413
[10/24] Train loss=0.3982353210449219
[15/24] Train loss=0.2984924912452698
[20/24] Train loss=0.3306328058242798
Test set avg_accuracy=86.68% avg_sensitivity=80.88%, avg_specificity=88.63% avg_auc=0.9299
Fold[1] Epoch: 44 [44/150 (29%)] Train loss=0.359487 Test loss=0.380905 Current lr=[0.000998924125869967]

[0/24] Train loss=0.3402363657951355
[5/24] Train loss=0.29519596695899963
[10/24] Train loss=0.32858210802078247
[15/24] Train loss=0.24768374860286713
[20/24] Train loss=0.27817168831825256
Test set avg_accuracy=85.36% avg_sensitivity=85.91%, avg_specificity=85.18% avg_auc=0.9362
Fold[1] Epoch: 45 [45/150 (30%)] Train loss=0.320699 Test loss=0.401250 Current lr=[0.000999999611458977]

[0/24] Train loss=0.36720338463783264
[5/24] Train loss=0.28225457668304443
[10/24] Train loss=0.35380467772483826
[15/24] Train loss=0.2683597803115845
[20/24] Train loss=0.2781550884246826
Test set avg_accuracy=85.65% avg_sensitivity=86.11%, avg_specificity=85.50% avg_auc=0.9338
Fold[1] Epoch: 46 [46/150 (31%)] Train loss=0.327223 Test loss=0.394351 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.36496901512145996
[5/24] Train loss=0.30364692211151123
[10/24] Train loss=0.3644214868545532
[15/24] Train loss=0.25958287715911865
[20/24] Train loss=0.3246104419231415
Test set avg_accuracy=85.62% avg_sensitivity=86.32%, avg_specificity=85.39% avg_auc=0.9391
Fold[1] Epoch: 47 [47/150 (31%)] Train loss=0.327944 Test loss=0.422826 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.4183361232280731
[5/24] Train loss=0.28204599022865295
[10/24] Train loss=0.3618188798427582
[15/24] Train loss=0.23623248934745789
[20/24] Train loss=0.3169049620628357
Test set avg_accuracy=85.38% avg_sensitivity=85.75%, avg_specificity=85.25% avg_auc=0.9295
Fold[1] Epoch: 48 [48/150 (32%)] Train loss=0.324231 Test loss=0.392412 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.4156545102596283
[5/24] Train loss=0.25936856865882874
[10/24] Train loss=0.4081014096736908
[15/24] Train loss=0.264780730009079
[20/24] Train loss=0.29658326506614685
Test set avg_accuracy=87.30% avg_sensitivity=80.41%, avg_specificity=89.62% avg_auc=0.9346
Fold[1] Epoch: 49 [49/150 (33%)] Train loss=0.330323 Test loss=0.368986 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.36308348178863525
[5/24] Train loss=0.24779997766017914
[10/24] Train loss=0.3633555471897125
[15/24] Train loss=0.27670255303382874
[20/24] Train loss=0.2359057515859604
Test set avg_accuracy=88.89% avg_sensitivity=77.51%, avg_specificity=92.71% avg_auc=0.9391
Fold[1] Epoch: 50 [50/150 (33%)] Train loss=0.303511 Test loss=0.332055 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.3353361487388611
[5/24] Train loss=0.22565607726573944
[10/24] Train loss=0.2814576327800751
[15/24] Train loss=0.20746120810508728
[20/24] Train loss=0.22889232635498047
Test set avg_accuracy=88.16% avg_sensitivity=80.83%, avg_specificity=90.63% avg_auc=0.9368
Fold[1] Epoch: 51 [51/150 (34%)] Train loss=0.265469 Test loss=0.370954 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.26614201068878174
[5/24] Train loss=0.21049706637859344
[10/24] Train loss=0.26298296451568604
[15/24] Train loss=0.18975961208343506
[20/24] Train loss=0.19763198494911194
Test set avg_accuracy=88.10% avg_sensitivity=80.36%, avg_specificity=90.70% avg_auc=0.9316
Fold[1] Epoch: 52 [52/150 (35%)] Train loss=0.233151 Test loss=0.413720 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.20765219628810883
[5/24] Train loss=0.17881552875041962
[10/24] Train loss=0.23517508804798126
[15/24] Train loss=0.1830633133649826
[20/24] Train loss=0.18233005702495575
Test set avg_accuracy=84.00% avg_sensitivity=86.79%, avg_specificity=83.06% avg_auc=0.9330
Fold[1] Epoch: 53 [53/150 (35%)] Train loss=0.212722 Test loss=0.592027 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.2813481390476227
[5/24] Train loss=0.20083750784397125
[10/24] Train loss=0.2527773976325989
[15/24] Train loss=0.18820519745349884
[20/24] Train loss=0.15984541177749634
Test set avg_accuracy=87.15% avg_sensitivity=83.83%, avg_specificity=88.26% avg_auc=0.9356
Fold[1] Epoch: 54 [54/150 (36%)] Train loss=0.227525 Test loss=0.469558 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.22258897125720978
[5/24] Train loss=0.1946498304605484
[10/24] Train loss=0.19473843276500702
[15/24] Train loss=0.17398454248905182
[20/24] Train loss=0.15097185969352722
Test set avg_accuracy=87.80% avg_sensitivity=81.24%, avg_specificity=90.00% avg_auc=0.9337
Fold[1] Epoch: 55 [55/150 (37%)] Train loss=0.204155 Test loss=0.489615 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.2315351665019989
[5/24] Train loss=0.17861314117908478
[10/24] Train loss=0.17226630449295044
[15/24] Train loss=0.1494324654340744
[20/24] Train loss=0.15316028892993927
Test set avg_accuracy=87.51% avg_sensitivity=81.30%, avg_specificity=89.60% avg_auc=0.9346
Fold[1] Epoch: 56 [56/150 (37%)] Train loss=0.183746 Test loss=0.499965 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.20224466919898987
[5/24] Train loss=0.16781184077262878
[10/24] Train loss=0.16345053911209106
[15/24] Train loss=0.14288000762462616
[20/24] Train loss=0.1178077757358551
Test set avg_accuracy=86.84% avg_sensitivity=84.20%, avg_specificity=87.72% avg_auc=0.9351
Fold[1] Epoch: 57 [57/150 (38%)] Train loss=0.161786 Test loss=0.538549 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.16667450964450836
[5/24] Train loss=0.16362744569778442
[10/24] Train loss=0.18949918448925018
[15/24] Train loss=0.15624701976776123
[20/24] Train loss=0.16364146769046783
Test set avg_accuracy=84.44% avg_sensitivity=87.10%, avg_specificity=83.55% avg_auc=0.9319
Fold[1] Epoch: 58 [58/150 (39%)] Train loss=0.177434 Test loss=0.659834 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.212641641497612
[5/24] Train loss=0.18921633064746857
[10/24] Train loss=0.17431698739528656
[15/24] Train loss=0.1764676719903946
[20/24] Train loss=0.2040562778711319
Test set avg_accuracy=84.22% avg_sensitivity=87.46%, avg_specificity=83.13% avg_auc=0.9296
Fold[1] Epoch: 59 [59/150 (39%)] Train loss=0.197036 Test loss=0.624369 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.22352930903434753
[5/24] Train loss=0.17285385727882385
[10/24] Train loss=0.2147711217403412
[15/24] Train loss=0.17306701838970184
[20/24] Train loss=0.16598571836948395
Test set avg_accuracy=87.89% avg_sensitivity=80.78%, avg_specificity=90.28% avg_auc=0.9276
Fold[1] Epoch: 60 [60/150 (40%)] Train loss=0.194561 Test loss=0.497963 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.17915138602256775
[5/24] Train loss=0.12849390506744385
[10/24] Train loss=0.16038872301578522
[15/24] Train loss=0.1788650006055832
[20/24] Train loss=0.15176831185817719
Test set avg_accuracy=87.46% avg_sensitivity=84.35%, avg_specificity=88.50% avg_auc=0.9344
Fold[1] Epoch: 61 [61/150 (41%)] Train loss=0.160206 Test loss=0.526950 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.14446179568767548
[5/24] Train loss=0.1178651675581932
[10/24] Train loss=0.14801162481307983
[15/24] Train loss=0.14040715992450714
[20/24] Train loss=0.10999508947134018
Test set avg_accuracy=87.29% avg_sensitivity=83.63%, avg_specificity=88.52% avg_auc=0.9370
Fold[1] Epoch: 62 [62/150 (41%)] Train loss=0.135089 Test loss=0.646447 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.12028254568576813
[5/24] Train loss=0.09390667080879211
[10/24] Train loss=0.13853515684604645
[15/24] Train loss=0.11286510527133942
[20/24] Train loss=0.10927630960941315
Test set avg_accuracy=86.85% avg_sensitivity=84.09%, avg_specificity=87.77% avg_auc=0.9346
Fold[1] Epoch: 63 [63/150 (42%)] Train loss=0.126043 Test loss=0.694435 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.10138683021068573
[5/24] Train loss=0.11779613792896271
[10/24] Train loss=0.13496744632720947
[15/24] Train loss=0.12833721935749054
[20/24] Train loss=0.19070880115032196
Test set avg_accuracy=82.47% avg_sensitivity=87.93%, avg_specificity=80.64% avg_auc=0.9229
Fold[1] Epoch: 64 [64/150 (43%)] Train loss=0.129844 Test loss=0.848042 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.15019091963768005
[5/24] Train loss=0.17188991606235504
[10/24] Train loss=0.2223815768957138
[15/24] Train loss=0.1836128830909729
[20/24] Train loss=0.12247684597969055
Test set avg_accuracy=85.77% avg_sensitivity=82.02%, avg_specificity=87.03% avg_auc=0.9250
Fold[1] Epoch: 65 [65/150 (43%)] Train loss=0.179273 Test loss=0.771571 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.11971371620893478
[5/24] Train loss=0.1377163678407669
[10/24] Train loss=0.1383177787065506
[15/24] Train loss=0.10908356308937073
[20/24] Train loss=0.10794925689697266
Test set avg_accuracy=85.36% avg_sensitivity=88.81%, avg_specificity=84.21% avg_auc=0.9381
Fold[1] Epoch: 66 [66/150 (44%)] Train loss=0.140931 Test loss=0.752250 Current lr=[0.000904142181093812]

[0/24] Train loss=0.13680246472358704
[5/24] Train loss=0.14335143566131592
[10/24] Train loss=0.16360293328762054
[15/24] Train loss=0.1295918971300125
[20/24] Train loss=0.1413612812757492
Test set avg_accuracy=88.41% avg_sensitivity=81.24%, avg_specificity=90.82% avg_auc=0.9326
Fold[1] Epoch: 67 [67/150 (45%)] Train loss=0.142261 Test loss=0.739390 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.1580173671245575
[5/24] Train loss=0.15728279948234558
[10/24] Train loss=0.15911437571048737
[15/24] Train loss=0.11727815121412277
[20/24] Train loss=0.13371849060058594
Test set avg_accuracy=85.14% avg_sensitivity=87.25%, avg_specificity=84.43% avg_auc=0.9329
Fold[1] Epoch: 68 [68/150 (45%)] Train loss=0.151425 Test loss=1.002049 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.14685024321079254
[5/24] Train loss=0.13803641498088837
[10/24] Train loss=0.2025805115699768
[15/24] Train loss=0.14601196348667145
[20/24] Train loss=0.15175823867321014
Test set avg_accuracy=86.80% avg_sensitivity=84.72%, avg_specificity=87.50% avg_auc=0.9331
Fold[1] Epoch: 69 [69/150 (46%)] Train loss=0.174093 Test loss=0.730544 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.1439100205898285
[5/24] Train loss=0.18517360091209412
[10/24] Train loss=0.2140452116727829
[15/24] Train loss=0.13952279090881348
[20/24] Train loss=0.17943893373012543
Test set avg_accuracy=81.95% avg_sensitivity=88.13%, avg_specificity=79.88% avg_auc=0.9302
Fold[1] Epoch: 70 [70/150 (47%)] Train loss=0.161258 Test loss=1.077275 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.17792931199073792
[5/24] Train loss=0.16702741384506226
[10/24] Train loss=0.18269093334674835
[15/24] Train loss=0.14436975121498108
[20/24] Train loss=0.12135259807109833
Test set avg_accuracy=84.04% avg_sensitivity=86.99%, avg_specificity=83.04% avg_auc=0.9356
Fold[1] Epoch: 71 [71/150 (47%)] Train loss=0.157986 Test loss=0.807585 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.19214951992034912
[5/24] Train loss=0.13597552478313446
[10/24] Train loss=0.17326723039150238
[15/24] Train loss=0.10048860311508179
[20/24] Train loss=0.11807730793952942
Test set avg_accuracy=85.51% avg_sensitivity=84.15%, avg_specificity=85.97% avg_auc=0.9354
Fold[1] Epoch: 72 [72/150 (48%)] Train loss=0.156846 Test loss=0.979748 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.12778227031230927
[5/24] Train loss=0.0815756693482399
[10/24] Train loss=0.12106914818286896
[15/24] Train loss=0.10656075924634933
[20/24] Train loss=0.09411909431219101
Test set avg_accuracy=86.46% avg_sensitivity=84.66%, avg_specificity=87.06% avg_auc=0.9338
Fold[1] Epoch: 73 [73/150 (49%)] Train loss=0.116008 Test loss=0.929823 Current lr=[0.000834102481048427]

[0/24] Train loss=0.10868432372808456
[5/24] Train loss=0.07996835559606552
[10/24] Train loss=0.11658481508493423
[15/24] Train loss=0.0973292887210846
[20/24] Train loss=0.08488573133945465
Test set avg_accuracy=85.33% avg_sensitivity=84.46%, avg_specificity=85.62% avg_auc=0.9313
Fold[1] Epoch: 74 [74/150 (49%)] Train loss=0.098271 Test loss=0.749464 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.12358299642801285
[5/24] Train loss=0.07492400705814362
[10/24] Train loss=0.08117274194955826
[15/24] Train loss=0.07608083635568619
[20/24] Train loss=0.06960170716047287
Test set avg_accuracy=86.76% avg_sensitivity=82.85%, avg_specificity=88.07% avg_auc=0.9284
Fold[1] Epoch: 75 [75/150 (50%)] Train loss=0.086268 Test loss=0.813625 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.0760812982916832
[5/24] Train loss=0.06330428272485733
[10/24] Train loss=0.09594524651765823
[15/24] Train loss=0.08793339878320694
[20/24] Train loss=0.07862857729196548
Test set avg_accuracy=84.41% avg_sensitivity=89.43%, avg_specificity=82.73% avg_auc=0.9323
Fold[1] Epoch: 76 [76/150 (51%)] Train loss=0.085084 Test loss=0.999747 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.10780221968889236
[5/24] Train loss=0.10502713918685913
[10/24] Train loss=0.16933470964431763
[15/24] Train loss=0.09155561774969101
[20/24] Train loss=0.09714239835739136
Test set avg_accuracy=84.69% avg_sensitivity=86.22%, avg_specificity=84.17% avg_auc=0.9281
Fold[1] Epoch: 77 [77/150 (51%)] Train loss=0.108981 Test loss=0.997239 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.11800630390644073
[5/24] Train loss=0.12209546566009521
[10/24] Train loss=0.11641540378332138
[15/24] Train loss=0.0828624740242958
[20/24] Train loss=0.09560082107782364
Test set avg_accuracy=84.97% avg_sensitivity=87.05%, avg_specificity=84.28% avg_auc=0.9372
Fold[1] Epoch: 78 [78/150 (52%)] Train loss=0.112879 Test loss=0.925479 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.12911999225616455
[5/24] Train loss=0.11894287168979645
[10/24] Train loss=0.10463853180408478
[15/24] Train loss=0.07582253217697144
[20/24] Train loss=0.10877921432256699
Test set avg_accuracy=86.68% avg_sensitivity=83.16%, avg_specificity=87.86% avg_auc=0.9314
Fold[1] Epoch: 79 [79/150 (53%)] Train loss=0.111597 Test loss=0.703061 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.13813596963882446
[5/24] Train loss=0.10810533910989761
[10/24] Train loss=0.09087038040161133
[15/24] Train loss=0.08323458582162857
[20/24] Train loss=0.0894969254732132
Test set avg_accuracy=85.29% avg_sensitivity=85.85%, avg_specificity=85.10% avg_auc=0.9330
Fold[1] Epoch: 80 [80/150 (53%)] Train loss=0.095610 Test loss=0.864736 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.11195079982280731
[5/24] Train loss=0.10644321888685226
[10/24] Train loss=0.10544431209564209
[15/24] Train loss=0.17568615078926086
[20/24] Train loss=0.09008356928825378
Test set avg_accuracy=87.66% avg_sensitivity=83.63%, avg_specificity=89.01% avg_auc=0.9340
Fold[1] Epoch: 81 [81/150 (54%)] Train loss=0.111932 Test loss=0.682504 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.09449383616447449
[5/24] Train loss=0.08612633496522903
[10/24] Train loss=0.0769796222448349
[15/24] Train loss=0.08843585848808289
[20/24] Train loss=0.07825828343629837
Test set avg_accuracy=86.30% avg_sensitivity=85.34%, avg_specificity=86.63% avg_auc=0.9362
Fold[1] Epoch: 82 [82/150 (55%)] Train loss=0.091556 Test loss=0.733364 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.07739507406949997
[5/24] Train loss=0.10280827432870865
[10/24] Train loss=0.06648938357830048
[15/24] Train loss=0.07073584944009781
[20/24] Train loss=0.07564406841993332
Test set avg_accuracy=86.50% avg_sensitivity=86.74%, avg_specificity=86.42% avg_auc=0.9375
Fold[1] Epoch: 83 [83/150 (55%)] Train loss=0.079347 Test loss=0.857962 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.09780140221118927
[5/24] Train loss=0.08056442439556122
[10/24] Train loss=0.07700025290250778
[15/24] Train loss=0.06380264461040497
[20/24] Train loss=0.07537821680307388
Test set avg_accuracy=86.03% avg_sensitivity=85.39%, avg_specificity=86.24% avg_auc=0.9359
Fold[1] Epoch: 84 [84/150 (56%)] Train loss=0.083084 Test loss=0.749567 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.07538875937461853
[5/24] Train loss=0.06438102573156357
[10/24] Train loss=0.07450559735298157
[15/24] Train loss=0.0509813018143177
[20/24] Train loss=0.054746150970458984
Test set avg_accuracy=85.85% avg_sensitivity=86.37%, avg_specificity=85.67% avg_auc=0.9359
Fold[1] Epoch: 85 [85/150 (57%)] Train loss=0.069053 Test loss=0.839949 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.09486088901758194
[5/24] Train loss=0.08633927255868912
[10/24] Train loss=0.07742339372634888
[15/24] Train loss=0.11427739262580872
[20/24] Train loss=0.0813855230808258
Test set avg_accuracy=85.65% avg_sensitivity=87.98%, avg_specificity=84.87% avg_auc=0.9380
Fold[1] Epoch: 86 [86/150 (57%)] Train loss=0.075188 Test loss=0.819527 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.10110616683959961
[5/24] Train loss=0.07015912234783173
[10/24] Train loss=0.06674103438854218
[15/24] Train loss=0.07065624743700027
[20/24] Train loss=0.055560529232025146
Test set avg_accuracy=87.25% avg_sensitivity=83.06%, avg_specificity=88.66% avg_auc=0.9378
Fold[1] Epoch: 87 [87/150 (58%)] Train loss=0.071585 Test loss=0.746104 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.06545999646186829
[5/24] Train loss=0.05863345041871071
[10/24] Train loss=0.09382346272468567
[15/24] Train loss=0.05830810219049454
[20/24] Train loss=0.05071493238210678
Test set avg_accuracy=86.35% avg_sensitivity=84.25%, avg_specificity=87.06% avg_auc=0.9361
Fold[1] Epoch: 88 [88/150 (59%)] Train loss=0.064844 Test loss=0.836870 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.07465548068284988
[5/24] Train loss=0.04818595573306084
[10/24] Train loss=0.07513251155614853
[15/24] Train loss=0.060603927820920944
[20/24] Train loss=0.048332370817661285
Test set avg_accuracy=85.26% avg_sensitivity=87.41%, avg_specificity=84.54% avg_auc=0.9404
Fold[1] Epoch: 89 [89/150 (59%)] Train loss=0.060537 Test loss=0.855613 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.06414354592561722
[5/24] Train loss=0.05260710418224335
[10/24] Train loss=0.055612962692976
[15/24] Train loss=0.051770444959402084
[20/24] Train loss=0.07167632132768631
Test set avg_accuracy=87.30% avg_sensitivity=85.34%, avg_specificity=87.97% avg_auc=0.9379
Fold[1] Epoch: 90 [90/150 (60%)] Train loss=0.059123 Test loss=0.822152 Current lr=[0.00061065423442182]

[0/24] Train loss=0.05235924571752548
[5/24] Train loss=0.08339206129312515
[10/24] Train loss=0.048128560185432434
[15/24] Train loss=0.05128457024693489
[20/24] Train loss=0.04351081699132919
Test set avg_accuracy=86.89% avg_sensitivity=85.91%, avg_specificity=87.22% avg_auc=0.9380
Fold[1] Epoch: 91 [91/150 (61%)] Train loss=0.052026 Test loss=0.955481 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.04488375410437584
[5/24] Train loss=0.05121031776070595
[10/24] Train loss=0.05172267183661461
[15/24] Train loss=0.03461045026779175
[20/24] Train loss=0.03522355109453201
Test set avg_accuracy=86.77% avg_sensitivity=86.48%, avg_specificity=86.87% avg_auc=0.9389
Fold[1] Epoch: 92 [92/150 (61%)] Train loss=0.043558 Test loss=0.955598 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.039742276072502136
[5/24] Train loss=0.038649216294288635
[10/24] Train loss=0.04293004423379898
[15/24] Train loss=0.08041120320558548
[20/24] Train loss=0.03420673683285713
Test set avg_accuracy=84.73% avg_sensitivity=89.53%, avg_specificity=83.11% avg_auc=0.9380
Fold[1] Epoch: 93 [93/150 (62%)] Train loss=0.041693 Test loss=1.116372 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.0464416965842247
[5/24] Train loss=0.04583647474646568
[10/24] Train loss=0.044358376413583755
[15/24] Train loss=0.05495099350810051
[20/24] Train loss=0.04201178625226021
Test set avg_accuracy=85.77% avg_sensitivity=87.41%, avg_specificity=85.22% avg_auc=0.9379
Fold[1] Epoch: 94 [94/150 (63%)] Train loss=0.053034 Test loss=1.207321 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.06084302440285683
[5/24] Train loss=0.04645600542426109
[10/24] Train loss=0.0377478189766407
[15/24] Train loss=0.049720291048288345
[20/24] Train loss=0.03833086043596268
Test set avg_accuracy=86.97% avg_sensitivity=86.89%, avg_specificity=86.99% avg_auc=0.9393
Fold[1] Epoch: 95 [95/150 (63%)] Train loss=0.050714 Test loss=0.968535 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.05750960111618042
[5/24] Train loss=0.034033000469207764
[10/24] Train loss=0.03807041794061661
[15/24] Train loss=0.04275726526975632
[20/24] Train loss=0.030210185796022415
Test set avg_accuracy=85.76% avg_sensitivity=87.15%, avg_specificity=85.29% avg_auc=0.9382
Fold[1] Epoch: 96 [96/150 (64%)] Train loss=0.047452 Test loss=0.989078 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.04572540521621704
[5/24] Train loss=0.052576664835214615
[10/24] Train loss=0.05062157288193703
[15/24] Train loss=0.05244172737002373
[20/24] Train loss=0.03587910532951355
Test set avg_accuracy=86.00% avg_sensitivity=86.74%, avg_specificity=85.76% avg_auc=0.9386
Fold[1] Epoch: 97 [97/150 (65%)] Train loss=0.051926 Test loss=0.986230 Current lr=[0.000506858408304961]

[0/24] Train loss=0.058559563010931015
[5/24] Train loss=0.05137629806995392
[10/24] Train loss=0.05025414749979973
[15/24] Train loss=0.0586710162460804
[20/24] Train loss=0.04484976455569267
Test set avg_accuracy=87.29% avg_sensitivity=84.61%, avg_specificity=88.19% avg_auc=0.9372
Fold[1] Epoch: 98 [98/150 (65%)] Train loss=0.053305 Test loss=0.818329 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.04308316856622696
[5/24] Train loss=0.037440262734889984
[10/24] Train loss=0.04335305839776993
[15/24] Train loss=0.04688294231891632
[20/24] Train loss=0.029024546965956688
Test set avg_accuracy=86.95% avg_sensitivity=84.46%, avg_specificity=87.79% avg_auc=0.9385
Fold[1] Epoch: 99 [99/150 (66%)] Train loss=0.043114 Test loss=0.893889 Current lr=[0.000476946990416354]

[0/24] Train loss=0.03650044649839401
[5/24] Train loss=0.02962655946612358
[10/24] Train loss=0.035292744636535645
[15/24] Train loss=0.042225927114486694
[20/24] Train loss=0.0291451346129179
Test set avg_accuracy=86.77% avg_sensitivity=85.28%, avg_specificity=87.27% avg_auc=0.9387
Fold[1] Epoch: 100 [100/150 (67%)] Train loss=0.034508 Test loss=0.986946 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.03657274693250656
[5/24] Train loss=0.049119170755147934
[10/24] Train loss=0.03982573375105858
[15/24] Train loss=0.03401270881295204
[20/24] Train loss=0.024910133332014084
Test set avg_accuracy=86.12% avg_sensitivity=86.11%, avg_specificity=86.12% avg_auc=0.9392
Fold[1] Epoch: 101 [101/150 (67%)] Train loss=0.036974 Test loss=1.183898 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.02874886989593506
[5/24] Train loss=0.0330565981566906
[10/24] Train loss=0.03827357664704323
[15/24] Train loss=0.029090644791722298
[20/24] Train loss=0.024942833930253983
Test set avg_accuracy=85.22% avg_sensitivity=87.62%, avg_specificity=84.42% avg_auc=0.9387
Fold[1] Epoch: 102 [102/150 (68%)] Train loss=0.032608 Test loss=1.255120 Current lr=[0.000432267999769856]

[0/24] Train loss=0.03752991929650307
[5/24] Train loss=0.03368102014064789
[10/24] Train loss=0.03410908207297325
[15/24] Train loss=0.02895243465900421
[20/24] Train loss=0.027187585830688477
Test set avg_accuracy=85.92% avg_sensitivity=86.48%, avg_specificity=85.74% avg_auc=0.9345
Fold[1] Epoch: 103 [103/150 (69%)] Train loss=0.037860 Test loss=1.028491 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.046129029244184494
[5/24] Train loss=0.05233001336455345
[10/24] Train loss=0.03716680780053139
[15/24] Train loss=0.064919114112854
[20/24] Train loss=0.04080348461866379
Test set avg_accuracy=86.38% avg_sensitivity=84.61%, avg_specificity=86.97% avg_auc=0.9372
Fold[1] Epoch: 104 [104/150 (69%)] Train loss=0.042045 Test loss=0.917187 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.030476335436105728
[5/24] Train loss=0.04735077545046806
[10/24] Train loss=0.04873911663889885
[15/24] Train loss=0.03283572942018509
[20/24] Train loss=0.033603932708501816
Test set avg_accuracy=84.83% avg_sensitivity=87.93%, avg_specificity=83.79% avg_auc=0.9380
Fold[1] Epoch: 105 [105/150 (70%)] Train loss=0.037641 Test loss=1.299987 Current lr=[0.000388134363466264]

[0/24] Train loss=0.03855587914586067
[5/24] Train loss=0.049523260444402695
[10/24] Train loss=0.04054440185427666
[15/24] Train loss=0.03810812905430794
[20/24] Train loss=0.042737722396850586
Test set avg_accuracy=86.58% avg_sensitivity=84.09%, avg_specificity=87.41% avg_auc=0.9350
Fold[1] Epoch: 106 [106/150 (71%)] Train loss=0.041758 Test loss=0.981100 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.033299949020147324
[5/24] Train loss=0.037023890763521194
[10/24] Train loss=0.029930587857961655
[15/24] Train loss=0.04798727110028267
[20/24] Train loss=0.030479097738862038
Test set avg_accuracy=86.35% avg_sensitivity=85.28%, avg_specificity=86.71% avg_auc=0.9375
Fold[1] Epoch: 107 [107/150 (71%)] Train loss=0.034394 Test loss=1.139749 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.025125211104750633
[5/24] Train loss=0.025178490206599236
[10/24] Train loss=0.022976141422986984
[15/24] Train loss=0.03485919162631035
[20/24] Train loss=0.026443149894475937
Test set avg_accuracy=85.64% avg_sensitivity=88.39%, avg_specificity=84.71% avg_auc=0.9398
Fold[1] Epoch: 108 [108/150 (72%)] Train loss=0.029345 Test loss=1.397705 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.03447563946247101
[5/24] Train loss=0.028350921347737312
[10/24] Train loss=0.024983854964375496
[15/24] Train loss=0.040148284286260605
[20/24] Train loss=0.02756817825138569
Test set avg_accuracy=86.95% avg_sensitivity=84.30%, avg_specificity=87.84% avg_auc=0.9378
Fold[1] Epoch: 109 [109/150 (73%)] Train loss=0.032826 Test loss=1.057617 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.030348366126418114
[5/24] Train loss=0.038798462599515915
[10/24] Train loss=0.02986510470509529
[15/24] Train loss=0.026058649644255638
[20/24] Train loss=0.02017221413552761
Test set avg_accuracy=86.07% avg_sensitivity=86.68%, avg_specificity=85.86% avg_auc=0.9375
Fold[1] Epoch: 110 [110/150 (73%)] Train loss=0.029692 Test loss=1.278539 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.029647890478372574
[5/24] Train loss=0.0330331064760685
[10/24] Train loss=0.035169072449207306
[15/24] Train loss=0.04939824715256691
[20/24] Train loss=0.03016984462738037
Test set avg_accuracy=85.99% avg_sensitivity=85.91%, avg_specificity=86.02% avg_auc=0.9359
Fold[1] Epoch: 111 [111/150 (74%)] Train loss=0.033107 Test loss=1.039354 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.03618545085191727
[5/24] Train loss=0.0357741042971611
[10/24] Train loss=0.0217336006462574
[15/24] Train loss=0.026328913867473602
[20/24] Train loss=0.021348727867007256
Test set avg_accuracy=86.03% avg_sensitivity=86.89%, avg_specificity=85.74% avg_auc=0.9375
Fold[1] Epoch: 112 [112/150 (75%)] Train loss=0.028654 Test loss=1.199748 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.04817240312695503
[5/24] Train loss=0.02910841442644596
[10/24] Train loss=0.024803772568702698
[15/24] Train loss=0.029742443934082985
[20/24] Train loss=0.0202916469424963
Test set avg_accuracy=86.82% avg_sensitivity=84.61%, avg_specificity=87.57% avg_auc=0.9381
Fold[1] Epoch: 113 [113/150 (75%)] Train loss=0.029692 Test loss=1.099014 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.02280302159488201
[5/24] Train loss=0.035067152231931686
[10/24] Train loss=0.03282536566257477
[15/24] Train loss=0.02764156460762024
[20/24] Train loss=0.022179994732141495
Test set avg_accuracy=85.99% avg_sensitivity=85.60%, avg_specificity=86.12% avg_auc=0.9365
Fold[1] Epoch: 114 [114/150 (76%)] Train loss=0.028983 Test loss=1.234599 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.022015295922756195
[5/24] Train loss=0.031033415347337723
[10/24] Train loss=0.022955678403377533
[15/24] Train loss=0.02605927363038063
[20/24] Train loss=0.019562093541026115
Test set avg_accuracy=85.30% avg_sensitivity=87.72%, avg_specificity=84.49% avg_auc=0.9383
Fold[1] Epoch: 115 [115/150 (77%)] Train loss=0.025656 Test loss=1.348494 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.02651175670325756
[5/24] Train loss=0.024649275466799736
[10/24] Train loss=0.02487776055932045
[15/24] Train loss=0.02155742235481739
[20/24] Train loss=0.020478226244449615
Test set avg_accuracy=85.59% avg_sensitivity=85.75%, avg_specificity=85.53% avg_auc=0.9385
Fold[1] Epoch: 116 [116/150 (77%)] Train loss=0.029442 Test loss=1.126127 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.027977354824543
[5/24] Train loss=0.03347506746649742
[10/24] Train loss=0.032108522951602936
[15/24] Train loss=0.03129380941390991
[20/24] Train loss=0.022073857486248016
Test set avg_accuracy=86.32% avg_sensitivity=84.51%, avg_specificity=86.92% avg_auc=0.9373
Fold[1] Epoch: 117 [117/150 (78%)] Train loss=0.031776 Test loss=1.085474 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.03018668293952942
[5/24] Train loss=0.02666211500763893
[10/24] Train loss=0.02382849156856537
[15/24] Train loss=0.024596434086561203
[20/24] Train loss=0.025980740785598755
Test set avg_accuracy=85.65% avg_sensitivity=86.63%, avg_specificity=85.32% avg_auc=0.9374
Fold[1] Epoch: 118 [118/150 (79%)] Train loss=0.026722 Test loss=1.342063 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.02736733667552471
[5/24] Train loss=0.035488519817590714
[10/24] Train loss=0.028257103636860847
[15/24] Train loss=0.027376608923077583
[20/24] Train loss=0.022239362820982933
Test set avg_accuracy=87.06% avg_sensitivity=83.73%, avg_specificity=88.17% avg_auc=0.9368
Fold[1] Epoch: 119 [119/150 (79%)] Train loss=0.028766 Test loss=1.061242 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.05829744413495064
[5/24] Train loss=0.028999514877796173
[10/24] Train loss=0.01789378747344017
[15/24] Train loss=0.024453917518258095
[20/24] Train loss=0.018004490062594414
Test set avg_accuracy=86.39% avg_sensitivity=85.34%, avg_specificity=86.75% avg_auc=0.9376
Fold[1] Epoch: 120 [120/150 (80%)] Train loss=0.026798 Test loss=1.148216 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.01687733829021454
[5/24] Train loss=0.019013892859220505
[10/24] Train loss=0.02863844856619835
[15/24] Train loss=0.018779145553708076
[20/24] Train loss=0.015953702852129936
Test set avg_accuracy=86.52% avg_sensitivity=85.80%, avg_specificity=86.77% avg_auc=0.9380
Fold[1] Epoch: 121 [121/150 (81%)] Train loss=0.021136 Test loss=1.264331 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.01946442946791649
[5/24] Train loss=0.02167855203151703
[10/24] Train loss=0.02230781875550747
[15/24] Train loss=0.023373734205961227
[20/24] Train loss=0.013904799707233906
Test set avg_accuracy=85.92% avg_sensitivity=86.84%, avg_specificity=85.62% avg_auc=0.9383
Fold[1] Epoch: 122 [122/150 (81%)] Train loss=0.019609 Test loss=1.387136 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.01959129609167576
[5/24] Train loss=0.022863371297717094
[10/24] Train loss=0.019747408106923103
[15/24] Train loss=0.01923867128789425
[20/24] Train loss=0.023222073912620544
Test set avg_accuracy=86.41% avg_sensitivity=86.01%, avg_specificity=86.54% avg_auc=0.9388
Fold[1] Epoch: 123 [123/150 (82%)] Train loss=0.024024 Test loss=1.352412 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.01512035820633173
[5/24] Train loss=0.017177538946270943
[10/24] Train loss=0.016058938577771187
[15/24] Train loss=0.027943965047597885
[20/24] Train loss=0.01514205802232027
Test set avg_accuracy=86.16% avg_sensitivity=86.06%, avg_specificity=86.19% avg_auc=0.9382
Fold[1] Epoch: 124 [124/150 (83%)] Train loss=0.019306 Test loss=1.445873 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.01585771143436432
[5/24] Train loss=0.01879672333598137
[10/24] Train loss=0.02103503793478012
[15/24] Train loss=0.014806159771978855
[20/24] Train loss=0.01435911376029253
Test set avg_accuracy=85.52% avg_sensitivity=87.31%, avg_specificity=84.92% avg_auc=0.9383
Fold[1] Epoch: 125 [125/150 (83%)] Train loss=0.019446 Test loss=1.551863 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.020985426381230354
[5/24] Train loss=0.0195475947111845
[10/24] Train loss=0.019576821476221085
[15/24] Train loss=0.01898304931819439
[20/24] Train loss=0.02333945408463478
Test set avg_accuracy=84.65% avg_sensitivity=87.88%, avg_specificity=83.57% avg_auc=0.9379
Fold[1] Epoch: 126 [126/150 (84%)] Train loss=0.021662 Test loss=1.754977 Current lr=[0.000123057953306828]

[0/24] Train loss=0.0279157143086195
[5/24] Train loss=0.025976570323109627
[10/24] Train loss=0.020915938541293144
[15/24] Train loss=0.032188355922698975
[20/24] Train loss=0.029236359521746635
Test set avg_accuracy=85.98% avg_sensitivity=85.75%, avg_specificity=86.05% avg_auc=0.9374
Fold[1] Epoch: 127 [127/150 (85%)] Train loss=0.024209 Test loss=1.373537 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.017296474426984787
[5/24] Train loss=0.020649632439017296
[10/24] Train loss=0.01800636015832424
[15/24] Train loss=0.034078940749168396
[20/24] Train loss=0.016136862337589264
Test set avg_accuracy=86.24% avg_sensitivity=85.96%, avg_specificity=86.33% avg_auc=0.9379
Fold[1] Epoch: 128 [128/150 (85%)] Train loss=0.020052 Test loss=1.347573 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.013490879908204079
[5/24] Train loss=0.015087404288351536
[10/24] Train loss=0.01591530814766884
[15/24] Train loss=0.016537996008992195
[20/24] Train loss=0.01276390254497528
Test set avg_accuracy=86.17% avg_sensitivity=85.65%, avg_specificity=86.35% avg_auc=0.9381
Fold[1] Epoch: 129 [129/150 (86%)] Train loss=0.016280 Test loss=1.427770 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.017004022374749184
[5/24] Train loss=0.013925916515290737
[10/24] Train loss=0.013614699244499207
[15/24] Train loss=0.011684092693030834
[20/24] Train loss=0.012253250926733017
Test set avg_accuracy=86.02% avg_sensitivity=86.74%, avg_specificity=85.77% avg_auc=0.9384
Fold[1] Epoch: 130 [130/150 (87%)] Train loss=0.015962 Test loss=1.566011 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.013032606802880764
[5/24] Train loss=0.015377704054117203
[10/24] Train loss=0.014469295740127563
[15/24] Train loss=0.014706060290336609
[20/24] Train loss=0.012861081399023533
Test set avg_accuracy=85.62% avg_sensitivity=86.94%, avg_specificity=85.18% avg_auc=0.9381
Fold[1] Epoch: 131 [131/150 (87%)] Train loss=0.015288 Test loss=1.556493 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.020543145015835762
[5/24] Train loss=0.02214978076517582
[10/24] Train loss=0.017842816188931465
[15/24] Train loss=0.015559491701424122
[20/24] Train loss=0.014837168157100677
Test set avg_accuracy=85.76% avg_sensitivity=86.94%, avg_specificity=85.36% avg_auc=0.9380
Fold[1] Epoch: 132 [132/150 (88%)] Train loss=0.020103 Test loss=1.473414 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.018332017585635185
[5/24] Train loss=0.024136792868375778
[10/24] Train loss=0.020734095945954323
[15/24] Train loss=0.022205185145139694
[20/24] Train loss=0.0146524952724576
Test set avg_accuracy=86.04% avg_sensitivity=86.37%, avg_specificity=85.93% avg_auc=0.9372
Fold[1] Epoch: 133 [133/150 (89%)] Train loss=0.021450 Test loss=1.438352 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.02455751970410347
[5/24] Train loss=0.03146640583872795
[10/24] Train loss=0.023045115172863007
[15/24] Train loss=0.021913791075348854
[20/24] Train loss=0.017136225476861
Test set avg_accuracy=85.91% avg_sensitivity=85.96%, avg_specificity=85.90% avg_auc=0.9365
Fold[1] Epoch: 134 [134/150 (89%)] Train loss=0.027158 Test loss=1.347810 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.025637881830334663
[5/24] Train loss=0.026727138087153435
[10/24] Train loss=0.025388183072209358
[15/24] Train loss=0.02589990757405758
[20/24] Train loss=0.018803590908646584
Test set avg_accuracy=86.43% avg_sensitivity=84.87%, avg_specificity=86.96% avg_auc=0.9358
Fold[1] Epoch: 135 [135/150 (90%)] Train loss=0.026380 Test loss=1.240555 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.02670956961810589
[5/24] Train loss=0.022637642920017242
[10/24] Train loss=0.018259627744555473
[15/24] Train loss=0.02194012515246868
[20/24] Train loss=0.02031516283750534
Test set avg_accuracy=86.52% avg_sensitivity=83.89%, avg_specificity=87.41% avg_auc=0.9362
Fold[1] Epoch: 136 [136/150 (91%)] Train loss=0.022027 Test loss=1.220579 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.01669762283563614
[5/24] Train loss=0.022166956216096878
[10/24] Train loss=0.025828108191490173
[15/24] Train loss=0.019207483157515526
[20/24] Train loss=0.01445370726287365
Test set avg_accuracy=86.42% avg_sensitivity=83.94%, avg_specificity=87.25% avg_auc=0.9372
Fold[1] Epoch: 137 [137/150 (91%)] Train loss=0.020927 Test loss=1.240053 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.014060740359127522
[5/24] Train loss=0.01834622211754322
[10/24] Train loss=0.013842261396348476
[15/24] Train loss=0.013580231927335262
[20/24] Train loss=0.013672889210283756
Test set avg_accuracy=86.02% avg_sensitivity=84.66%, avg_specificity=86.47% avg_auc=0.9381
Fold[1] Epoch: 138 [138/150 (92%)] Train loss=0.018350 Test loss=1.301002 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.02576531656086445
[5/24] Train loss=0.01555111724883318
[10/24] Train loss=0.013576379977166653
[15/24] Train loss=0.014313042163848877
[20/24] Train loss=0.01661822944879532
Test set avg_accuracy=85.74% avg_sensitivity=86.17%, avg_specificity=85.60% avg_auc=0.9387
Fold[1] Epoch: 139 [139/150 (93%)] Train loss=0.015654 Test loss=1.368685 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.017381569370627403
[5/24] Train loss=0.01698075607419014
[10/24] Train loss=0.014872564002871513
[15/24] Train loss=0.01691358909010887
[20/24] Train loss=0.015510424971580505
Test set avg_accuracy=85.78% avg_sensitivity=86.53%, avg_specificity=85.53% avg_auc=0.9388
Fold[1] Epoch: 140 [140/150 (93%)] Train loss=0.017157 Test loss=1.390015 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.017722247168421745
[5/24] Train loss=0.022432025521993637
[10/24] Train loss=0.016558658331632614
[15/24] Train loss=0.01350055169314146
[20/24] Train loss=0.016056735068559647
Test set avg_accuracy=85.99% avg_sensitivity=86.22%, avg_specificity=85.91% avg_auc=0.9386
Fold[1] Epoch: 141 [141/150 (94%)] Train loss=0.019393 Test loss=1.385081 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.023317942395806313
[5/24] Train loss=0.02206045761704445
[10/24] Train loss=0.02126794308423996
[15/24] Train loss=0.023903433233499527
[20/24] Train loss=0.016127504408359528
Test set avg_accuracy=86.07% avg_sensitivity=85.70%, avg_specificity=86.19% avg_auc=0.9384
Fold[1] Epoch: 142 [142/150 (95%)] Train loss=0.022185 Test loss=1.361418 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.02122151292860508
[5/24] Train loss=0.021943723782896996
[10/24] Train loss=0.016016609966754913
[15/24] Train loss=0.017154423519968987
[20/24] Train loss=0.014566239900887012
Test set avg_accuracy=85.91% avg_sensitivity=84.82%, avg_specificity=86.28% avg_auc=0.9383
Fold[1] Epoch: 143 [143/150 (95%)] Train loss=0.018241 Test loss=1.342448 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.015425504185259342
[5/24] Train loss=0.01514132134616375
[10/24] Train loss=0.04516781121492386
[15/24] Train loss=0.03663911297917366
[20/24] Train loss=0.01494530774652958
Test set avg_accuracy=85.92% avg_sensitivity=84.82%, avg_specificity=86.30% avg_auc=0.9383
Fold[1] Epoch: 144 [144/150 (96%)] Train loss=0.018295 Test loss=1.352328 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.028804564848542213
[5/24] Train loss=0.01212450210005045
[10/24] Train loss=0.012148331850767136
[15/24] Train loss=0.011989613994956017
[20/24] Train loss=0.01948968693614006
Test set avg_accuracy=86.08% avg_sensitivity=85.70%, avg_specificity=86.21% avg_auc=0.9385
Fold[1] Epoch: 145 [145/150 (97%)] Train loss=0.017289 Test loss=1.372035 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.012049146927893162
[5/24] Train loss=0.013868293724954128
[10/24] Train loss=0.01290561631321907
[15/24] Train loss=0.011777053587138653
[20/24] Train loss=0.010993962176144123
Test set avg_accuracy=86.03% avg_sensitivity=85.60%, avg_specificity=86.17% avg_auc=0.9385
Fold[1] Epoch: 146 [146/150 (97%)] Train loss=0.013460 Test loss=1.375285 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.010762185789644718
[5/24] Train loss=0.011520206928253174
[10/24] Train loss=0.02745772898197174
[15/24] Train loss=0.011026850901544094
[20/24] Train loss=0.011961015872657299
Test set avg_accuracy=86.03% avg_sensitivity=85.70%, avg_specificity=86.14% avg_auc=0.9386
Fold[1] Epoch: 147 [147/150 (98%)] Train loss=0.014246 Test loss=1.380749 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.019586559385061264
[5/24] Train loss=0.017939433455467224
[10/24] Train loss=0.0128263458609581
[15/24] Train loss=0.00856757815927267
[20/24] Train loss=0.03417821228504181
Test set avg_accuracy=85.98% avg_sensitivity=85.70%, avg_specificity=86.07% avg_auc=0.9386
Fold[1] Epoch: 148 [148/150 (99%)] Train loss=0.018748 Test loss=1.383370 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.009680214338004589
[5/24] Train loss=0.010097806341946125
[10/24] Train loss=0.015161655843257904
[15/24] Train loss=0.013264630921185017
[20/24] Train loss=0.010401693172752857
Test set avg_accuracy=86.00% avg_sensitivity=85.70%, avg_specificity=86.10% avg_auc=0.9386
Fold[1] Epoch: 149 [149/150 (99%)] Train loss=0.014779 Test loss=1.384304 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.020921627059578896
[5/24] Train loss=0.04342491552233696
[10/24] Train loss=0.10057830810546875
[15/24] Train loss=0.007452152669429779
[20/24] Train loss=0.011035304516553879
Test set avg_accuracy=86.00% avg_sensitivity=85.70%, avg_specificity=86.10% avg_auc=0.9387
Fold[1] Epoch: 150 [150/150 (100%)] Train loss=0.026579 Test loss=1.385569 Current lr=[4.388541022775342e-09]

Fold[1] Result: acc=86.46% sen=84.46%, spe=87.13%, auc=0.94!
Fold[1] Avg_overlap=0.66%(0.2379864004997266)
[0/24] Train loss=1.4006437063217163
[5/24] Train loss=1.2957723140716553
[10/24] Train loss=1.23032808303833
[15/24] Train loss=1.033138394355774
[20/24] Train loss=1.0248539447784424
Test set avg_accuracy=70.26% avg_sensitivity=5.55%, avg_specificity=95.94% avg_auc=0.6675
Best model saved!! Metric=0.6674553599859161!!
Fold[2] Epoch: 1 [1/150 (1%)] Train loss=1.205097 Test loss=0.881304 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.9431244134902954
[5/24] Train loss=1.0061789751052856
[10/24] Train loss=0.9292452931404114
[15/24] Train loss=0.8222745060920715
[20/24] Train loss=0.8853681683540344
Test set avg_accuracy=76.25% avg_sensitivity=37.86%, avg_specificity=91.49% avg_auc=0.7880
Best model saved!! Metric=0.7880407474228609!!
Fold[2] Epoch: 2 [2/150 (1%)] Train loss=0.946783 Test loss=0.679722 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.7943728566169739
[5/24] Train loss=0.9274836778640747
[10/24] Train loss=0.8645092248916626
[15/24] Train loss=0.7583935856819153
[20/24] Train loss=0.8256892561912537
Test set avg_accuracy=80.89% avg_sensitivity=58.39%, avg_specificity=89.81% avg_auc=0.8493
Best model saved!! Metric=0.8492657858419642!!
Fold[2] Epoch: 3 [3/150 (2%)] Train loss=0.849301 Test loss=0.483166 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.7057774066925049
[5/24] Train loss=0.8062223196029663
[10/24] Train loss=0.7482807040214539
[15/24] Train loss=0.669617235660553
[20/24] Train loss=0.744947075843811
Test set avg_accuracy=82.57% avg_sensitivity=74.98%, avg_specificity=85.58% avg_auc=0.8757
Best model saved!! Metric=0.8757487515666893!!
Fold[2] Epoch: 4 [4/150 (3%)] Train loss=0.763327 Test loss=0.488568 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.6545971632003784
[5/24] Train loss=0.7481491565704346
[10/24] Train loss=0.6538646221160889
[15/24] Train loss=0.6423713564872742
[20/24] Train loss=0.657739520072937
Test set avg_accuracy=81.94% avg_sensitivity=82.54%, avg_specificity=81.70% avg_auc=0.8939
Best model saved!! Metric=0.8938769585073683!!
Fold[2] Epoch: 5 [5/150 (3%)] Train loss=0.695178 Test loss=0.517624 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.6647665500640869
[5/24] Train loss=0.7914584875106812
[10/24] Train loss=0.6806016564369202
[15/24] Train loss=0.6746631860733032
[20/24] Train loss=0.6858431696891785
Test set avg_accuracy=84.53% avg_sensitivity=78.96%, avg_specificity=86.74% avg_auc=0.9004
Best model saved!! Metric=0.9003563999107751!!
Fold[2] Epoch: 6 [6/150 (4%)] Train loss=0.719513 Test loss=0.432826 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.5843964219093323
[5/24] Train loss=0.7006433010101318
[10/24] Train loss=0.6547536849975586
[15/24] Train loss=0.6068031787872314
[20/24] Train loss=0.6471136808395386
Test set avg_accuracy=78.32% avg_sensitivity=89.18%, avg_specificity=74.01% avg_auc=0.9148
Best model saved!! Metric=0.9147546445520227!!
Fold[2] Epoch: 7 [7/150 (5%)] Train loss=0.661262 Test loss=0.643963 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.6665433645248413
[5/24] Train loss=0.6961722373962402
[10/24] Train loss=0.630622148513794
[15/24] Train loss=0.6568899154663086
[20/24] Train loss=0.6893517971038818
Test set avg_accuracy=84.87% avg_sensitivity=82.36%, avg_specificity=85.87% avg_auc=0.9167
Best model saved!! Metric=0.9167472448109621!!
Fold[2] Epoch: 8 [8/150 (5%)] Train loss=0.692099 Test loss=0.404841 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.5647139549255371
[5/24] Train loss=0.6550770401954651
[10/24] Train loss=0.6427567005157471
[15/24] Train loss=0.6203625202178955
[20/24] Train loss=0.5867170691490173
Test set avg_accuracy=79.11% avg_sensitivity=89.92%, avg_specificity=74.83% avg_auc=0.9255
Best model saved!! Metric=0.9254984480649407!!
Fold[2] Epoch: 9 [9/150 (6%)] Train loss=0.630894 Test loss=0.642393 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.6134947538375854
[5/24] Train loss=0.6865084767341614
[10/24] Train loss=0.6403175592422485
[15/24] Train loss=0.6051602959632874
[20/24] Train loss=0.6897594332695007
Test set avg_accuracy=84.10% avg_sensitivity=86.07%, avg_specificity=83.32% avg_auc=0.9259
Best model saved!! Metric=0.925928235215272!!
Fold[2] Epoch: 10 [10/150 (7%)] Train loss=0.653895 Test loss=0.431021 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.5705235004425049
[5/24] Train loss=0.6593272686004639
[10/24] Train loss=0.6427819728851318
[15/24] Train loss=0.6504004001617432
[20/24] Train loss=0.6071720719337463
Test set avg_accuracy=84.54% avg_sensitivity=86.02%, avg_specificity=83.96% avg_auc=0.9310
Best model saved!! Metric=0.9310204960790674!!
Fold[2] Epoch: 11 [11/150 (7%)] Train loss=0.652216 Test loss=0.408872 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.5897232294082642
[5/24] Train loss=0.686741828918457
[10/24] Train loss=0.6644886136054993
[15/24] Train loss=0.6166437864303589
[20/24] Train loss=0.6271073222160339
Test set avg_accuracy=84.28% avg_sensitivity=85.84%, avg_specificity=83.67% avg_auc=0.9334
Best model saved!! Metric=0.9334102493398982!!
Fold[2] Epoch: 12 [12/150 (8%)] Train loss=0.660941 Test loss=0.408447 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6351908445358276
[5/24] Train loss=0.7091853618621826
[10/24] Train loss=0.6696930527687073
[15/24] Train loss=0.5992838740348816
[20/24] Train loss=0.6049178838729858
Test set avg_accuracy=86.20% avg_sensitivity=84.92%, avg_specificity=86.70% avg_auc=0.9341
Best model saved!! Metric=0.9340509289437471!!
Fold[2] Epoch: 13 [13/150 (9%)] Train loss=0.660276 Test loss=0.373161 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.5875189304351807
[5/24] Train loss=0.6349853873252869
[10/24] Train loss=0.6568724513053894
[15/24] Train loss=0.6319547295570374
[20/24] Train loss=0.5627430081367493
Test set avg_accuracy=86.09% avg_sensitivity=85.66%, avg_specificity=86.27% avg_auc=0.9342
Best model saved!! Metric=0.9342063891911032!!
Fold[2] Epoch: 14 [14/150 (9%)] Train loss=0.628008 Test loss=0.370265 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.5516904592514038
[5/24] Train loss=0.5981218814849854
[10/24] Train loss=0.6402565836906433
[15/24] Train loss=0.5829334855079651
[20/24] Train loss=0.5312120318412781
Test set avg_accuracy=85.39% avg_sensitivity=88.27%, avg_specificity=84.25% avg_auc=0.9365
Best model saved!! Metric=0.9364511851489035!!
Fold[2] Epoch: 15 [15/150 (10%)] Train loss=0.604149 Test loss=0.413459 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.5543355345726013
[5/24] Train loss=0.6577674150466919
[10/24] Train loss=0.6527724862098694
[15/24] Train loss=0.5912409424781799
[20/24] Train loss=0.5763728022575378
Test set avg_accuracy=87.34% avg_sensitivity=81.35%, avg_specificity=89.72% avg_auc=0.9311
Fold[2] Epoch: 16 [16/150 (11%)] Train loss=0.610746 Test loss=0.333748 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.5793185234069824
[5/24] Train loss=0.6239446401596069
[10/24] Train loss=0.6026339530944824
[15/24] Train loss=0.5729674100875854
[20/24] Train loss=0.5835716724395752
Test set avg_accuracy=83.16% avg_sensitivity=88.27%, avg_specificity=81.14% avg_auc=0.9333
Fold[2] Epoch: 17 [17/150 (11%)] Train loss=0.600431 Test loss=0.448155 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.5937529802322388
[5/24] Train loss=0.6161964535713196
[10/24] Train loss=0.5993276238441467
[15/24] Train loss=0.5600785613059998
[20/24] Train loss=0.5899410843849182
Test set avg_accuracy=86.39% avg_sensitivity=85.66%, avg_specificity=86.69% avg_auc=0.9361
Fold[2] Epoch: 18 [18/150 (12%)] Train loss=0.605642 Test loss=0.363797 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.5513858199119568
[5/24] Train loss=0.5714962482452393
[10/24] Train loss=0.5938480496406555
[15/24] Train loss=0.5952602028846741
[20/24] Train loss=0.5205534100532532
Test set avg_accuracy=85.62% avg_sensitivity=86.21%, avg_specificity=85.39% avg_auc=0.9348
Fold[2] Epoch: 19 [19/150 (13%)] Train loss=0.569711 Test loss=0.377214 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.5362535119056702
[5/24] Train loss=0.588914155960083
[10/24] Train loss=0.5820030570030212
[15/24] Train loss=0.5756577849388123
[20/24] Train loss=0.5597211718559265
Test set avg_accuracy=86.69% avg_sensitivity=86.53%, avg_specificity=86.76% avg_auc=0.9412
Best model saved!! Metric=0.9412342343303571!!
Fold[2] Epoch: 20 [20/150 (13%)] Train loss=0.584376 Test loss=0.352991 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.517995297908783
[5/24] Train loss=0.5521945953369141
[10/24] Train loss=0.5985187292098999
[15/24] Train loss=0.5652178525924683
[20/24] Train loss=0.5760653614997864
Test set avg_accuracy=86.03% avg_sensitivity=86.48%, avg_specificity=85.85% avg_auc=0.9394
Fold[2] Epoch: 21 [21/150 (14%)] Train loss=0.564784 Test loss=0.383083 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.5364376902580261
[5/24] Train loss=0.5803301930427551
[10/24] Train loss=0.5666308403015137
[15/24] Train loss=0.5992753505706787
[20/24] Train loss=0.5317689180374146
Test set avg_accuracy=87.02% avg_sensitivity=85.06%, avg_specificity=87.80% avg_auc=0.9401
Fold[2] Epoch: 22 [22/150 (15%)] Train loss=0.572684 Test loss=0.333432 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.48958855867385864
[5/24] Train loss=0.563812255859375
[10/24] Train loss=0.5950688123703003
[15/24] Train loss=0.577915370464325
[20/24] Train loss=0.5467174649238586
Test set avg_accuracy=83.59% avg_sensitivity=90.38%, avg_specificity=80.90% avg_auc=0.9413
Best model saved!! Metric=0.9412500721035464!!
Fold[2] Epoch: 23 [23/150 (15%)] Train loss=0.555839 Test loss=0.466758 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5637167692184448
[5/24] Train loss=0.5718632340431213
[10/24] Train loss=0.5856916904449463
[15/24] Train loss=0.5282465815544128
[20/24] Train loss=0.5575172305107117
Test set avg_accuracy=87.25% avg_sensitivity=84.83%, avg_specificity=88.21% avg_auc=0.9423
Best model saved!! Metric=0.9423430034886447!!
Fold[2] Epoch: 24 [24/150 (16%)] Train loss=0.561730 Test loss=0.339620 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.49585115909576416
[5/24] Train loss=0.489531934261322
[10/24] Train loss=0.5762828588485718
[15/24] Train loss=0.513150155544281
[20/24] Train loss=0.5246596932411194
Test set avg_accuracy=85.14% avg_sensitivity=88.04%, avg_specificity=83.99% avg_auc=0.9387
Fold[2] Epoch: 25 [25/150 (17%)] Train loss=0.529557 Test loss=0.411523 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5343222618103027
[5/24] Train loss=0.5266718864440918
[10/24] Train loss=0.5519815683364868
[15/24] Train loss=0.5176504254341125
[20/24] Train loss=0.491875559091568
Test set avg_accuracy=86.97% avg_sensitivity=83.78%, avg_specificity=88.23% avg_auc=0.9386
Fold[2] Epoch: 26 [26/150 (17%)] Train loss=0.536792 Test loss=0.331354 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.4725954830646515
[5/24] Train loss=0.5129127502441406
[10/24] Train loss=0.6192377805709839
[15/24] Train loss=0.49065127968788147
[20/24] Train loss=0.504754900932312
Test set avg_accuracy=81.88% avg_sensitivity=91.93%, avg_specificity=77.88% avg_auc=0.9405
Fold[2] Epoch: 27 [27/150 (18%)] Train loss=0.532662 Test loss=0.499639 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5465973615646362
[5/24] Train loss=0.49702760577201843
[10/24] Train loss=0.5389032363891602
[15/24] Train loss=0.5168477892875671
[20/24] Train loss=0.4960910677909851
Test set avg_accuracy=85.01% avg_sensitivity=90.51%, avg_specificity=82.83% avg_auc=0.9442
Best model saved!! Metric=0.9442426193476237!!
Fold[2] Epoch: 28 [28/150 (19%)] Train loss=0.543802 Test loss=0.393014 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5120393633842468
[5/24] Train loss=0.5583425760269165
[10/24] Train loss=0.6687089204788208
[15/24] Train loss=0.4732204079627991
[20/24] Train loss=0.47311097383499146
Test set avg_accuracy=88.67% avg_sensitivity=82.63%, avg_specificity=91.07% avg_auc=0.9442
Fold[2] Epoch: 29 [29/150 (19%)] Train loss=0.538009 Test loss=0.295410 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.47800543904304504
[5/24] Train loss=0.5262745022773743
[10/24] Train loss=0.5691513419151306
[15/24] Train loss=0.4705309271812439
[20/24] Train loss=0.4691813290119171
Test set avg_accuracy=86.71% avg_sensitivity=86.98%, avg_specificity=86.60% avg_auc=0.9433
Fold[2] Epoch: 30 [30/150 (20%)] Train loss=0.511278 Test loss=0.348320 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.5030202865600586
[5/24] Train loss=0.5069698095321655
[10/24] Train loss=0.5288445353507996
[15/24] Train loss=0.4678793251514435
[20/24] Train loss=0.47414132952690125
Test set avg_accuracy=88.11% avg_sensitivity=80.34%, avg_specificity=91.20% avg_auc=0.9415
Fold[2] Epoch: 31 [31/150 (21%)] Train loss=0.509982 Test loss=0.309899 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.45161792635917664
[5/24] Train loss=0.49978822469711304
[10/24] Train loss=0.5505544543266296
[15/24] Train loss=0.4593574106693268
[20/24] Train loss=0.43272140622138977
Test set avg_accuracy=87.20% avg_sensitivity=84.56%, avg_specificity=88.25% avg_auc=0.9429
Fold[2] Epoch: 32 [32/150 (21%)] Train loss=0.492627 Test loss=0.348207 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.407041072845459
[5/24] Train loss=0.49254080653190613
[10/24] Train loss=0.5049119591712952
[15/24] Train loss=0.43796077370643616
[20/24] Train loss=0.43703487515449524
Test set avg_accuracy=86.59% avg_sensitivity=87.67%, avg_specificity=86.16% avg_auc=0.9390
Fold[2] Epoch: 33 [33/150 (22%)] Train loss=0.478675 Test loss=0.381206 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.4900631308555603
[5/24] Train loss=0.5216166377067566
[10/24] Train loss=0.5324086546897888
[15/24] Train loss=0.4281562268733978
[20/24] Train loss=0.4095456600189209
Test set avg_accuracy=87.50% avg_sensitivity=85.75%, avg_specificity=88.20% avg_auc=0.9433
Fold[2] Epoch: 34 [34/150 (23%)] Train loss=0.478219 Test loss=0.341473 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.41136375069618225
[5/24] Train loss=0.43625572323799133
[10/24] Train loss=0.49698689579963684
[15/24] Train loss=0.4434390366077423
[20/24] Train loss=0.4256770610809326
Test set avg_accuracy=86.90% avg_sensitivity=86.30%, avg_specificity=87.14% avg_auc=0.9372
Fold[2] Epoch: 35 [35/150 (23%)] Train loss=0.459102 Test loss=0.355921 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.4009000360965729
[5/24] Train loss=0.4270927608013153
[10/24] Train loss=0.4432356655597687
[15/24] Train loss=0.44336050748825073
[20/24] Train loss=0.4290752708911896
Test set avg_accuracy=84.41% avg_sensitivity=89.73%, avg_specificity=82.30% avg_auc=0.9414
Fold[2] Epoch: 36 [36/150 (24%)] Train loss=0.440104 Test loss=0.448719 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.4375472068786621
[5/24] Train loss=0.4282072186470032
[10/24] Train loss=0.4409824013710022
[15/24] Train loss=0.378118097782135
[20/24] Train loss=0.40557703375816345
Test set avg_accuracy=87.21% avg_sensitivity=85.20%, avg_specificity=88.01% avg_auc=0.9388
Fold[2] Epoch: 37 [37/150 (25%)] Train loss=0.435572 Test loss=0.366709 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.4252529740333557
[5/24] Train loss=0.38032761216163635
[10/24] Train loss=0.4133422076702118
[15/24] Train loss=0.39852219820022583
[20/24] Train loss=0.36295562982559204
Test set avg_accuracy=85.04% avg_sensitivity=87.53%, avg_specificity=84.05% avg_auc=0.9401
Fold[2] Epoch: 38 [38/150 (25%)] Train loss=0.406519 Test loss=0.428069 Current lr=[0.000944367614404117]

[0/24] Train loss=0.4085351526737213
[5/24] Train loss=0.4284352958202362
[10/24] Train loss=0.4280385673046112
[15/24] Train loss=0.36322641372680664
[20/24] Train loss=0.3664194643497467
Test set avg_accuracy=86.20% avg_sensitivity=84.33%, avg_specificity=86.94% avg_auc=0.9387
Fold[2] Epoch: 39 [39/150 (26%)] Train loss=0.415480 Test loss=0.378789 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.3779601752758026
[5/24] Train loss=0.39053353667259216
[10/24] Train loss=0.3946223258972168
[15/24] Train loss=0.32702845335006714
[20/24] Train loss=0.36223268508911133
Test set avg_accuracy=85.49% avg_sensitivity=89.83%, avg_specificity=83.78% avg_auc=0.9402
Fold[2] Epoch: 40 [40/150 (27%)] Train loss=0.374117 Test loss=0.431586 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.3649928569793701
[5/24] Train loss=0.3983028531074524
[10/24] Train loss=0.40648576617240906
[15/24] Train loss=0.33298638463020325
[20/24] Train loss=0.38570743799209595
Test set avg_accuracy=86.69% avg_sensitivity=80.48%, avg_specificity=89.16% avg_auc=0.9319
Fold[2] Epoch: 41 [41/150 (27%)] Train loss=0.400348 Test loss=0.348075 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.37892070412635803
[5/24] Train loss=0.34215885400772095
[10/24] Train loss=0.43445318937301636
[15/24] Train loss=0.3293094038963318
[20/24] Train loss=0.33541959524154663
Test set avg_accuracy=83.50% avg_sensitivity=89.64%, avg_specificity=81.07% avg_auc=0.9394
Fold[2] Epoch: 42 [42/150 (28%)] Train loss=0.374851 Test loss=0.553107 Current lr=[0.000989780311725182]

[0/24] Train loss=0.4201628565788269
[5/24] Train loss=0.3917804956436157
[10/24] Train loss=0.4149983823299408
[15/24] Train loss=0.3047049045562744
[20/24] Train loss=0.35046958923339844
Test set avg_accuracy=86.03% avg_sensitivity=84.56%, avg_specificity=86.61% avg_auc=0.9385
Fold[2] Epoch: 43 [43/150 (29%)] Train loss=0.387373 Test loss=0.404847 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.33309391140937805
[5/24] Train loss=0.4192594289779663
[10/24] Train loss=0.369925320148468
[15/24] Train loss=0.33499598503112793
[20/24] Train loss=0.32594549655914307
Test set avg_accuracy=86.48% avg_sensitivity=86.16%, avg_specificity=86.61% avg_auc=0.9359
Fold[2] Epoch: 44 [44/150 (29%)] Train loss=0.367799 Test loss=0.424914 Current lr=[0.000998924125869967]

[0/24] Train loss=0.32777678966522217
[5/24] Train loss=0.32948750257492065
[10/24] Train loss=0.371872216463089
[15/24] Train loss=0.2903333306312561
[20/24] Train loss=0.24230802059173584
Test set avg_accuracy=84.87% avg_sensitivity=85.88%, avg_specificity=84.47% avg_auc=0.9342
Fold[2] Epoch: 45 [45/150 (30%)] Train loss=0.321564 Test loss=0.488415 Current lr=[0.000999999611458977]

[0/24] Train loss=0.3064131438732147
[5/24] Train loss=0.3295270800590515
[10/24] Train loss=0.32457393407821655
[15/24] Train loss=0.25045713782310486
[20/24] Train loss=0.3058622181415558
Test set avg_accuracy=86.90% avg_sensitivity=83.68%, avg_specificity=88.18% avg_auc=0.9367
Fold[2] Epoch: 46 [46/150 (31%)] Train loss=0.316826 Test loss=0.415761 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.2704756259918213
[5/24] Train loss=0.2716018855571747
[10/24] Train loss=0.3581463098526001
[15/24] Train loss=0.22190184891223907
[20/24] Train loss=0.26879972219467163
Test set avg_accuracy=85.91% avg_sensitivity=87.53%, avg_specificity=85.27% avg_auc=0.9336
Fold[2] Epoch: 47 [47/150 (31%)] Train loss=0.290382 Test loss=0.457090 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.29351189732551575
[5/24] Train loss=0.2806914746761322
[10/24] Train loss=0.2918989062309265
[15/24] Train loss=0.22559501230716705
[20/24] Train loss=0.221969872713089
Test set avg_accuracy=83.11% avg_sensitivity=89.00%, avg_specificity=80.77% avg_auc=0.9353
Fold[2] Epoch: 48 [48/150 (32%)] Train loss=0.283869 Test loss=0.527578 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3091714382171631
[5/24] Train loss=0.2962421178817749
[10/24] Train loss=0.3007987439632416
[15/24] Train loss=0.32470157742500305
[20/24] Train loss=0.28380724787712097
Test set avg_accuracy=87.10% avg_sensitivity=84.05%, avg_specificity=88.30% avg_auc=0.9360
Fold[2] Epoch: 49 [49/150 (33%)] Train loss=0.305636 Test loss=0.410699 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3337879180908203
[5/24] Train loss=0.2657149136066437
[10/24] Train loss=0.304829865694046
[15/24] Train loss=0.20538441836833954
[20/24] Train loss=0.22820362448692322
Test set avg_accuracy=86.00% avg_sensitivity=88.18%, avg_specificity=85.14% avg_auc=0.9407
Fold[2] Epoch: 50 [50/150 (33%)] Train loss=0.275911 Test loss=0.447542 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.27252697944641113
[5/24] Train loss=0.26749300956726074
[10/24] Train loss=0.3033158481121063
[15/24] Train loss=0.22617042064666748
[20/24] Train loss=0.23790383338928223
Test set avg_accuracy=86.02% avg_sensitivity=85.66%, avg_specificity=86.16% avg_auc=0.9351
Fold[2] Epoch: 51 [51/150 (34%)] Train loss=0.290340 Test loss=0.456589 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.25026360154151917
[5/24] Train loss=0.25859659910202026
[10/24] Train loss=0.2677503228187561
[15/24] Train loss=0.19250577688217163
[20/24] Train loss=0.2368505299091339
Test set avg_accuracy=85.69% avg_sensitivity=87.99%, avg_specificity=84.78% avg_auc=0.9346
Fold[2] Epoch: 52 [52/150 (35%)] Train loss=0.258594 Test loss=0.420511 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.3003038465976715
[5/24] Train loss=0.2607972025871277
[10/24] Train loss=0.28414541482925415
[15/24] Train loss=0.26353663206100464
[20/24] Train loss=0.22839413583278656
Test set avg_accuracy=86.54% avg_sensitivity=84.97%, avg_specificity=87.16% avg_auc=0.9392
Fold[2] Epoch: 53 [53/150 (35%)] Train loss=0.278704 Test loss=0.433487 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.27221056818962097
[5/24] Train loss=0.19615307450294495
[10/24] Train loss=0.2722644507884979
[15/24] Train loss=0.2187952846288681
[20/24] Train loss=0.23500119149684906
Test set avg_accuracy=85.78% avg_sensitivity=86.02%, avg_specificity=85.69% avg_auc=0.9365
Fold[2] Epoch: 54 [54/150 (36%)] Train loss=0.230011 Test loss=0.540803 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.24141697585582733
[5/24] Train loss=0.2557675838470459
[10/24] Train loss=0.26091012358665466
[15/24] Train loss=0.18827350437641144
[20/24] Train loss=0.19945557415485382
Test set avg_accuracy=86.81% avg_sensitivity=84.51%, avg_specificity=87.72% avg_auc=0.9361
Fold[2] Epoch: 55 [55/150 (37%)] Train loss=0.232352 Test loss=0.482627 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.18708279728889465
[5/24] Train loss=0.23007486760616302
[10/24] Train loss=0.22752968966960907
[15/24] Train loss=0.15980517864227295
[20/24] Train loss=0.18184837698936462
Test set avg_accuracy=85.08% avg_sensitivity=88.41%, avg_specificity=83.76% avg_auc=0.9337
Fold[2] Epoch: 56 [56/150 (37%)] Train loss=0.213793 Test loss=0.575692 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.2653307318687439
[5/24] Train loss=0.1871524602174759
[10/24] Train loss=0.2406545877456665
[15/24] Train loss=0.20218130946159363
[20/24] Train loss=0.17163795232772827
Test set avg_accuracy=87.55% avg_sensitivity=82.58%, avg_specificity=89.52% avg_auc=0.9373
Fold[2] Epoch: 57 [57/150 (38%)] Train loss=0.219489 Test loss=0.431100 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.1884838044643402
[5/24] Train loss=0.14369110763072968
[10/24] Train loss=0.21340028941631317
[15/24] Train loss=0.18730716407299042
[20/24] Train loss=0.14682061970233917
Test set avg_accuracy=86.91% avg_sensitivity=81.76%, avg_specificity=88.96% avg_auc=0.9310
Fold[2] Epoch: 58 [58/150 (39%)] Train loss=0.190660 Test loss=0.475517 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.17747552692890167
[5/24] Train loss=0.16722823679447174
[10/24] Train loss=0.18053939938545227
[15/24] Train loss=0.13816961646080017
[20/24] Train loss=0.1366724967956543
Test set avg_accuracy=86.51% avg_sensitivity=85.84%, avg_specificity=86.78% avg_auc=0.9369
Fold[2] Epoch: 59 [59/150 (39%)] Train loss=0.173710 Test loss=0.573082 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.14025166630744934
[5/24] Train loss=0.1476643979549408
[10/24] Train loss=0.19746923446655273
[15/24] Train loss=0.13341842591762543
[20/24] Train loss=0.15264423191547394
Test set avg_accuracy=84.87% avg_sensitivity=88.18%, avg_specificity=83.56% avg_auc=0.9354
Fold[2] Epoch: 60 [60/150 (40%)] Train loss=0.162395 Test loss=0.790586 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.1851072758436203
[5/24] Train loss=0.21494752168655396
[10/24] Train loss=0.17540378868579865
[15/24] Train loss=0.12939493358135223
[20/24] Train loss=0.14251284301280975
Test set avg_accuracy=84.47% avg_sensitivity=88.22%, avg_specificity=82.98% avg_auc=0.9366
Fold[2] Epoch: 61 [61/150 (41%)] Train loss=0.176996 Test loss=0.594672 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.20328043401241302
[5/24] Train loss=0.178914874792099
[10/24] Train loss=0.18672959506511688
[15/24] Train loss=0.156807079911232
[20/24] Train loss=0.1364058256149292
Test set avg_accuracy=87.98% avg_sensitivity=84.05%, avg_specificity=89.54% avg_auc=0.9413
Fold[2] Epoch: 62 [62/150 (41%)] Train loss=0.179194 Test loss=0.558937 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.1758236289024353
[5/24] Train loss=0.14544421434402466
[10/24] Train loss=0.16324584186077118
[15/24] Train loss=0.139352485537529
[20/24] Train loss=0.14096251130104065
Test set avg_accuracy=86.58% avg_sensitivity=87.99%, avg_specificity=86.01% avg_auc=0.9393
Fold[2] Epoch: 63 [63/150 (42%)] Train loss=0.156941 Test loss=0.717549 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.16284658014774323
[5/24] Train loss=0.13979515433311462
[10/24] Train loss=0.16441568732261658
[15/24] Train loss=0.14518629014492035
[20/24] Train loss=0.1293559968471527
Test set avg_accuracy=86.51% avg_sensitivity=86.07%, avg_specificity=86.69% avg_auc=0.9391
Fold[2] Epoch: 64 [64/150 (43%)] Train loss=0.153757 Test loss=0.652716 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.14486536383628845
[5/24] Train loss=0.11769095063209534
[10/24] Train loss=0.19645945727825165
[15/24] Train loss=0.1149337962269783
[20/24] Train loss=0.12546904385089874
Test set avg_accuracy=84.91% avg_sensitivity=86.62%, avg_specificity=84.23% avg_auc=0.9330
Fold[2] Epoch: 65 [65/150 (43%)] Train loss=0.139809 Test loss=0.804563 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.17556177079677582
[5/24] Train loss=0.11105458438396454
[10/24] Train loss=0.1541074961423874
[15/24] Train loss=0.11531922966241837
[20/24] Train loss=0.11024462431669235
Test set avg_accuracy=86.03% avg_sensitivity=87.21%, avg_specificity=85.56% avg_auc=0.9366
Fold[2] Epoch: 66 [66/150 (44%)] Train loss=0.138055 Test loss=0.710720 Current lr=[0.000904142181093812]

[0/24] Train loss=0.15034066140651703
[5/24] Train loss=0.1257244497537613
[10/24] Train loss=0.13886073231697083
[15/24] Train loss=0.11090932041406631
[20/24] Train loss=0.11996256560087204
Test set avg_accuracy=87.54% avg_sensitivity=82.68%, avg_specificity=89.47% avg_auc=0.9365
Fold[2] Epoch: 67 [67/150 (45%)] Train loss=0.143327 Test loss=0.629163 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.14518678188323975
[5/24] Train loss=0.11002925038337708
[10/24] Train loss=0.14759011566638947
[15/24] Train loss=0.1336219608783722
[20/24] Train loss=0.1830928921699524
Test set avg_accuracy=86.52% avg_sensitivity=84.10%, avg_specificity=87.49% avg_auc=0.9334
Fold[2] Epoch: 68 [68/150 (45%)] Train loss=0.137522 Test loss=0.572957 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.10508372634649277
[5/24] Train loss=0.12475385516881943
[10/24] Train loss=0.15081222355365753
[15/24] Train loss=0.10924416035413742
[20/24] Train loss=0.10763441771268845
Test set avg_accuracy=87.14% avg_sensitivity=86.39%, avg_specificity=87.43% avg_auc=0.9366
Fold[2] Epoch: 69 [69/150 (46%)] Train loss=0.128785 Test loss=0.646989 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.11933546513319016
[5/24] Train loss=0.11946112662553787
[10/24] Train loss=0.16943176090717316
[15/24] Train loss=0.1176547184586525
[20/24] Train loss=0.09864716976881027
Test set avg_accuracy=87.85% avg_sensitivity=84.19%, avg_specificity=89.31% avg_auc=0.9356
Fold[2] Epoch: 70 [70/150 (47%)] Train loss=0.126987 Test loss=0.714166 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.1363464742898941
[5/24] Train loss=0.13255654275417328
[10/24] Train loss=0.1281372308731079
[15/24] Train loss=0.13583259284496307
[20/24] Train loss=0.08059900254011154
Test set avg_accuracy=87.29% avg_sensitivity=85.06%, avg_specificity=88.18% avg_auc=0.9352
Fold[2] Epoch: 71 [71/150 (47%)] Train loss=0.122030 Test loss=0.735277 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.13111752271652222
[5/24] Train loss=0.11215732991695404
[10/24] Train loss=0.10699869692325592
[15/24] Train loss=0.10087092965841293
[20/24] Train loss=0.09140431880950928
Test set avg_accuracy=86.77% avg_sensitivity=82.31%, avg_specificity=88.54% avg_auc=0.9344
Fold[2] Epoch: 72 [72/150 (48%)] Train loss=0.118784 Test loss=0.668313 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.11411722749471664
[5/24] Train loss=0.10406585037708282
[10/24] Train loss=0.10075536370277405
[15/24] Train loss=0.12167813628911972
[20/24] Train loss=0.11018554866313934
Test set avg_accuracy=86.28% avg_sensitivity=85.33%, avg_specificity=86.65% avg_auc=0.9306
Fold[2] Epoch: 73 [73/150 (49%)] Train loss=0.108868 Test loss=0.726899 Current lr=[0.000834102481048427]

[0/24] Train loss=0.0930769145488739
[5/24] Train loss=0.127345472574234
[10/24] Train loss=0.12179747223854065
[15/24] Train loss=0.10646500438451767
[20/24] Train loss=0.08711151033639908
Test set avg_accuracy=83.46% avg_sensitivity=90.60%, avg_specificity=80.63% avg_auc=0.9319
Fold[2] Epoch: 74 [74/150 (49%)] Train loss=0.110224 Test loss=1.267408 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.1473826766014099
[5/24] Train loss=0.12385763227939606
[10/24] Train loss=0.1231776624917984
[15/24] Train loss=0.11056698858737946
[20/24] Train loss=0.09379004687070847
Test set avg_accuracy=85.90% avg_sensitivity=87.21%, avg_specificity=85.38% avg_auc=0.9340
Fold[2] Epoch: 75 [75/150 (50%)] Train loss=0.124400 Test loss=0.974097 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.1274448037147522
[5/24] Train loss=0.13680334389209747
[10/24] Train loss=0.145509272813797
[15/24] Train loss=0.15999868512153625
[20/24] Train loss=0.14618022739887238
Test set avg_accuracy=86.00% avg_sensitivity=86.62%, avg_specificity=85.76% avg_auc=0.9294
Fold[2] Epoch: 76 [76/150 (51%)] Train loss=0.140261 Test loss=0.680588 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.14315809309482574
[5/24] Train loss=0.1337495595216751
[10/24] Train loss=0.12312724441289902
[15/24] Train loss=0.1277303695678711
[20/24] Train loss=0.11723843216896057
Test set avg_accuracy=87.14% avg_sensitivity=84.97%, avg_specificity=88.00% avg_auc=0.9321
Fold[2] Epoch: 77 [77/150 (51%)] Train loss=0.125155 Test loss=0.856021 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.08565440773963928
[5/24] Train loss=0.0837615504860878
[10/24] Train loss=0.11054757982492447
[15/24] Train loss=0.09628046303987503
[20/24] Train loss=0.09989536553621292
Test set avg_accuracy=85.03% avg_sensitivity=86.66%, avg_specificity=84.38% avg_auc=0.9301
Fold[2] Epoch: 78 [78/150 (52%)] Train loss=0.100357 Test loss=0.881518 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.11455143243074417
[5/24] Train loss=0.10432706773281097
[10/24] Train loss=0.11626390367746353
[15/24] Train loss=0.07760205119848251
[20/24] Train loss=0.08896055817604065
Test set avg_accuracy=86.41% avg_sensitivity=84.37%, avg_specificity=87.21% avg_auc=0.9356
Fold[2] Epoch: 79 [79/150 (53%)] Train loss=0.095440 Test loss=0.827035 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.0821022242307663
[5/24] Train loss=0.0728909820318222
[10/24] Train loss=0.11770428717136383
[15/24] Train loss=0.07780763506889343
[20/24] Train loss=0.08767279982566833
Test set avg_accuracy=85.90% avg_sensitivity=85.06%, avg_specificity=86.23% avg_auc=0.9338
Fold[2] Epoch: 80 [80/150 (53%)] Train loss=0.084516 Test loss=0.908358 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.06146674603223801
[5/24] Train loss=0.054307833313941956
[10/24] Train loss=0.12915416061878204
[15/24] Train loss=0.07187848538160324
[20/24] Train loss=0.06172672286629677
Test set avg_accuracy=86.39% avg_sensitivity=84.37%, avg_specificity=87.20% avg_auc=0.9355
Fold[2] Epoch: 81 [81/150 (54%)] Train loss=0.074683 Test loss=0.914770 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.05558009818196297
[5/24] Train loss=0.1227421909570694
[10/24] Train loss=0.07834156602621078
[15/24] Train loss=0.07066618651151657
[20/24] Train loss=0.07721743732690811
Test set avg_accuracy=85.23% avg_sensitivity=85.29%, avg_specificity=85.21% avg_auc=0.9298
Fold[2] Epoch: 82 [82/150 (55%)] Train loss=0.078142 Test loss=1.067384 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.0748911201953888
[5/24] Train loss=0.06767910718917847
[10/24] Train loss=0.09267435222864151
[15/24] Train loss=0.08114765584468842
[20/24] Train loss=0.08152893930673599
Test set avg_accuracy=86.05% avg_sensitivity=84.46%, avg_specificity=86.69% avg_auc=0.9323
Fold[2] Epoch: 83 [83/150 (55%)] Train loss=0.082501 Test loss=0.960871 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.0689396783709526
[5/24] Train loss=0.05335455760359764
[10/24] Train loss=0.06674410402774811
[15/24] Train loss=0.053368594497442245
[20/24] Train loss=0.05387025699019432
Test set avg_accuracy=86.37% avg_sensitivity=86.98%, avg_specificity=86.12% avg_auc=0.9358
Fold[2] Epoch: 84 [84/150 (56%)] Train loss=0.064142 Test loss=1.172544 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.07815663516521454
[5/24] Train loss=0.1387736201286316
[10/24] Train loss=0.0664089098572731
[15/24] Train loss=0.06521207094192505
[20/24] Train loss=0.0605788417160511
Test set avg_accuracy=85.33% avg_sensitivity=85.98%, avg_specificity=85.07% avg_auc=0.9313
Fold[2] Epoch: 85 [85/150 (57%)] Train loss=0.071729 Test loss=1.010289 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.06782986968755722
[5/24] Train loss=0.07492540776729584
[10/24] Train loss=0.07668812572956085
[15/24] Train loss=0.06294296681880951
[20/24] Train loss=0.07288546115159988
Test set avg_accuracy=86.25% avg_sensitivity=85.01%, avg_specificity=86.74% avg_auc=0.9335
Fold[2] Epoch: 86 [86/150 (57%)] Train loss=0.073893 Test loss=1.022370 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.05448035150766373
[5/24] Train loss=0.07858127355575562
[10/24] Train loss=0.06828108429908752
[15/24] Train loss=0.06070586293935776
[20/24] Train loss=0.0651760995388031
Test set avg_accuracy=86.17% avg_sensitivity=84.60%, avg_specificity=86.80% avg_auc=0.9327
Fold[2] Epoch: 87 [87/150 (58%)] Train loss=0.070131 Test loss=0.999728 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.05987245589494705
[5/24] Train loss=0.05920281633734703
[10/24] Train loss=0.059281378984451294
[15/24] Train loss=0.049097735434770584
[20/24] Train loss=0.05822714418172836
Test set avg_accuracy=85.08% avg_sensitivity=87.35%, avg_specificity=84.18% avg_auc=0.9336
Fold[2] Epoch: 88 [88/150 (59%)] Train loss=0.065130 Test loss=0.956192 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.06675203889608383
[5/24] Train loss=0.06263738870620728
[10/24] Train loss=0.0844317227602005
[15/24] Train loss=0.07742233574390411
[20/24] Train loss=0.07143984735012054
Test set avg_accuracy=85.43% avg_sensitivity=85.79%, avg_specificity=85.29% avg_auc=0.9344
Fold[2] Epoch: 89 [89/150 (59%)] Train loss=0.068458 Test loss=0.907471 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.07139778137207031
[5/24] Train loss=0.06971680372953415
[10/24] Train loss=0.06943410634994507
[15/24] Train loss=0.07727163285017014
[20/24] Train loss=0.058750737458467484
Test set avg_accuracy=86.24% avg_sensitivity=84.46%, avg_specificity=86.94% avg_auc=0.9355
Fold[2] Epoch: 90 [90/150 (60%)] Train loss=0.067596 Test loss=0.939739 Current lr=[0.00061065423442182]

[0/24] Train loss=0.045943040400743484
[5/24] Train loss=0.04463775455951691
[10/24] Train loss=0.06251423805952072
[15/24] Train loss=0.05993055924773216
[20/24] Train loss=0.05379674583673477
Test set avg_accuracy=85.34% avg_sensitivity=85.15%, avg_specificity=85.41% avg_auc=0.9343
Fold[2] Epoch: 91 [91/150 (61%)] Train loss=0.059117 Test loss=0.928798 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.03509001433849335
[5/24] Train loss=0.05516751855611801
[10/24] Train loss=0.059285953640937805
[15/24] Train loss=0.05196474492549896
[20/24] Train loss=0.04906994849443436
Test set avg_accuracy=86.65% avg_sensitivity=85.38%, avg_specificity=87.16% avg_auc=0.9333
Fold[2] Epoch: 92 [92/150 (61%)] Train loss=0.051605 Test loss=0.932328 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.04193542152643204
[5/24] Train loss=0.04162909463047981
[10/24] Train loss=0.05691612884402275
[15/24] Train loss=0.042046837508678436
[20/24] Train loss=0.04661339521408081
Test set avg_accuracy=85.74% avg_sensitivity=86.85%, avg_specificity=85.30% avg_auc=0.9378
Fold[2] Epoch: 93 [93/150 (62%)] Train loss=0.048620 Test loss=1.029176 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.05530525743961334
[5/24] Train loss=0.04865897446870804
[10/24] Train loss=0.05585417523980141
[15/24] Train loss=0.04172235727310181
[20/24] Train loss=0.055025987327098846
Test set avg_accuracy=86.29% avg_sensitivity=86.21%, avg_specificity=86.32% avg_auc=0.9383
Fold[2] Epoch: 94 [94/150 (63%)] Train loss=0.052212 Test loss=1.045924 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.030968355014920235
[5/24] Train loss=0.048400964587926865
[10/24] Train loss=0.06330408900976181
[15/24] Train loss=0.0372348390519619
[20/24] Train loss=0.0683073177933693
Test set avg_accuracy=86.38% avg_sensitivity=86.71%, avg_specificity=86.25% avg_auc=0.9361
Fold[2] Epoch: 95 [95/150 (63%)] Train loss=0.046307 Test loss=1.178658 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.050693951547145844
[5/24] Train loss=0.06447578221559525
[10/24] Train loss=0.05406659096479416
[15/24] Train loss=0.0449102409183979
[20/24] Train loss=0.04431850463151932
Test set avg_accuracy=85.29% avg_sensitivity=86.25%, avg_specificity=84.90% avg_auc=0.9386
Fold[2] Epoch: 96 [96/150 (64%)] Train loss=0.049373 Test loss=1.219464 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.058244042098522186
[5/24] Train loss=0.049274787306785583
[10/24] Train loss=0.07833756506443024
[15/24] Train loss=0.056739818304777145
[20/24] Train loss=0.06794573366641998
Test set avg_accuracy=85.76% avg_sensitivity=85.06%, avg_specificity=86.03% avg_auc=0.9370
Fold[2] Epoch: 97 [97/150 (65%)] Train loss=0.052985 Test loss=0.976087 Current lr=[0.000506858408304961]

[0/24] Train loss=0.044475007802248
[5/24] Train loss=0.034799616783857346
[10/24] Train loss=0.05112940073013306
[15/24] Train loss=0.05914875864982605
[20/24] Train loss=0.043559007346630096
Test set avg_accuracy=86.80% avg_sensitivity=84.19%, avg_specificity=87.83% avg_auc=0.9381
Fold[2] Epoch: 98 [98/150 (65%)] Train loss=0.044050 Test loss=1.088488 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.031609274446964264
[5/24] Train loss=0.029167084023356438
[10/24] Train loss=0.037516601383686066
[15/24] Train loss=0.034386198967695236
[20/24] Train loss=0.04324527829885483
Test set avg_accuracy=86.26% avg_sensitivity=84.56%, avg_specificity=86.94% avg_auc=0.9375
Fold[2] Epoch: 99 [99/150 (66%)] Train loss=0.038311 Test loss=1.142374 Current lr=[0.000476946990416354]

[0/24] Train loss=0.028146525844931602
[5/24] Train loss=0.023336470127105713
[10/24] Train loss=0.03865166753530502
[15/24] Train loss=0.05607542023062706
[20/24] Train loss=0.03847191482782364
Test set avg_accuracy=84.69% avg_sensitivity=88.08%, avg_specificity=83.34% avg_auc=0.9352
Fold[2] Epoch: 100 [100/150 (67%)] Train loss=0.034605 Test loss=1.244114 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.039435453712940216
[5/24] Train loss=0.03082660585641861
[10/24] Train loss=0.03736964985728264
[15/24] Train loss=0.045690275728702545
[20/24] Train loss=0.030758116394281387
Test set avg_accuracy=86.17% avg_sensitivity=85.20%, avg_specificity=86.56% avg_auc=0.9374
Fold[2] Epoch: 101 [101/150 (67%)] Train loss=0.038834 Test loss=1.196282 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.03801170364022255
[5/24] Train loss=0.026429779827594757
[10/24] Train loss=0.030989879742264748
[15/24] Train loss=0.033110715448856354
[20/24] Train loss=0.0318344384431839
Test set avg_accuracy=86.50% avg_sensitivity=84.60%, avg_specificity=87.25% avg_auc=0.9371
Fold[2] Epoch: 102 [102/150 (68%)] Train loss=0.034530 Test loss=1.168087 Current lr=[0.000432267999769856]

[0/24] Train loss=0.02458123303949833
[5/24] Train loss=0.03880545124411583
[10/24] Train loss=0.032877467572689056
[15/24] Train loss=0.028649048879742622
[20/24] Train loss=0.03040536865592003
Test set avg_accuracy=85.68% avg_sensitivity=86.39%, avg_specificity=85.39% avg_auc=0.9370
Fold[2] Epoch: 103 [103/150 (69%)] Train loss=0.033998 Test loss=1.308370 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.03116953931748867
[5/24] Train loss=0.07639782875776291
[10/24] Train loss=0.035877425223588943
[15/24] Train loss=0.03525106981396675
[20/24] Train loss=0.030852215364575386
Test set avg_accuracy=85.81% avg_sensitivity=86.98%, avg_specificity=85.34% avg_auc=0.9381
Fold[2] Epoch: 104 [104/150 (69%)] Train loss=0.037798 Test loss=1.167140 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.04062226042151451
[5/24] Train loss=0.04046459496021271
[10/24] Train loss=0.03542272746562958
[15/24] Train loss=0.03942081704735756
[20/24] Train loss=0.054680731147527695
Test set avg_accuracy=86.02% avg_sensitivity=85.56%, avg_specificity=86.19% avg_auc=0.9381
Fold[2] Epoch: 105 [105/150 (70%)] Train loss=0.041196 Test loss=1.274251 Current lr=[0.000388134363466264]

[0/24] Train loss=0.029448242858052254
[5/24] Train loss=0.046213410794734955
[10/24] Train loss=0.03904939070343971
[15/24] Train loss=0.025936422869563103
[20/24] Train loss=0.05721119046211243
Test set avg_accuracy=85.49% avg_sensitivity=88.54%, avg_specificity=84.29% avg_auc=0.9367
Fold[2] Epoch: 106 [106/150 (71%)] Train loss=0.037123 Test loss=1.129491 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.04236817732453346
[5/24] Train loss=0.05756412819027901
[10/24] Train loss=0.03679871931672096
[15/24] Train loss=0.030335957184433937
[20/24] Train loss=0.029545964673161507
Test set avg_accuracy=86.13% avg_sensitivity=85.29%, avg_specificity=86.47% avg_auc=0.9360
Fold[2] Epoch: 107 [107/150 (71%)] Train loss=0.039003 Test loss=1.138539 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.02793930470943451
[5/24] Train loss=0.033157188445329666
[10/24] Train loss=0.030846942216157913
[15/24] Train loss=0.03207404538989067
[20/24] Train loss=0.02896733768284321
Test set avg_accuracy=85.21% avg_sensitivity=87.63%, avg_specificity=84.25% avg_auc=0.9354
Fold[2] Epoch: 108 [108/150 (72%)] Train loss=0.035997 Test loss=1.147043 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.031836312264204025
[5/24] Train loss=0.030412234365940094
[10/24] Train loss=0.03786427527666092
[15/24] Train loss=0.027667749673128128
[20/24] Train loss=0.030367575585842133
Test set avg_accuracy=86.43% avg_sensitivity=84.33%, avg_specificity=87.27% avg_auc=0.9363
Fold[2] Epoch: 109 [109/150 (73%)] Train loss=0.037052 Test loss=1.069105 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.047235146164894104
[5/24] Train loss=0.03341003134846687
[10/24] Train loss=0.030950939282774925
[15/24] Train loss=0.025456242263317108
[20/24] Train loss=0.02764960005879402
Test set avg_accuracy=84.97% avg_sensitivity=85.15%, avg_specificity=84.90% avg_auc=0.9356
Fold[2] Epoch: 110 [110/150 (73%)] Train loss=0.033995 Test loss=1.158378 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.04635995626449585
[5/24] Train loss=0.0361480638384819
[10/24] Train loss=0.034192103892564774
[15/24] Train loss=0.03232308477163315
[20/24] Train loss=0.02804901823401451
Test set avg_accuracy=85.55% avg_sensitivity=84.92%, avg_specificity=85.79% avg_auc=0.9363
Fold[2] Epoch: 111 [111/150 (74%)] Train loss=0.035973 Test loss=1.063698 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.026833616197109222
[5/24] Train loss=0.026874586939811707
[10/24] Train loss=0.02948368526995182
[15/24] Train loss=0.02340291440486908
[20/24] Train loss=0.05099864676594734
Test set avg_accuracy=86.28% avg_sensitivity=84.83%, avg_specificity=86.85% avg_auc=0.9375
Fold[2] Epoch: 112 [112/150 (75%)] Train loss=0.029151 Test loss=1.109308 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.040691979229450226
[5/24] Train loss=0.03764361888170242
[10/24] Train loss=0.02508249506354332
[15/24] Train loss=0.022018421441316605
[20/24] Train loss=0.025313224643468857
Test set avg_accuracy=85.43% avg_sensitivity=85.98%, avg_specificity=85.21% avg_auc=0.9379
Fold[2] Epoch: 113 [113/150 (75%)] Train loss=0.028219 Test loss=1.360291 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.049409419298172
[5/24] Train loss=0.023393146693706512
[10/24] Train loss=0.029029691591858864
[15/24] Train loss=0.02681560628116131
[20/24] Train loss=0.039707496762275696
Test set avg_accuracy=86.46% avg_sensitivity=83.87%, avg_specificity=87.49% avg_auc=0.9370
Fold[2] Epoch: 114 [114/150 (76%)] Train loss=0.030554 Test loss=1.077438 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.02380470559000969
[5/24] Train loss=0.022004324942827225
[10/24] Train loss=0.02669871412217617
[15/24] Train loss=0.022407835349440575
[20/24] Train loss=0.02923251874744892
Test set avg_accuracy=85.70% avg_sensitivity=86.21%, avg_specificity=85.50% avg_auc=0.9386
Fold[2] Epoch: 115 [115/150 (77%)] Train loss=0.025268 Test loss=1.227490 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.031582631170749664
[5/24] Train loss=0.036275770515203476
[10/24] Train loss=0.029199348762631416
[15/24] Train loss=0.023419393226504326
[20/24] Train loss=0.026675492525100708
Test set avg_accuracy=86.54% avg_sensitivity=83.50%, avg_specificity=87.74% avg_auc=0.9375
Fold[2] Epoch: 116 [116/150 (77%)] Train loss=0.028769 Test loss=1.079334 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.03313489258289337
[5/24] Train loss=0.020657943561673164
[10/24] Train loss=0.029879646375775337
[15/24] Train loss=0.020857999101281166
[20/24] Train loss=0.021661465987563133
Test set avg_accuracy=85.76% avg_sensitivity=86.94%, avg_specificity=85.29% avg_auc=0.9378
Fold[2] Epoch: 117 [117/150 (78%)] Train loss=0.024858 Test loss=1.258489 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.03222453221678734
[5/24] Train loss=0.03032328374683857
[10/24] Train loss=0.026757657527923584
[15/24] Train loss=0.05801334232091904
[20/24] Train loss=0.022105030715465546
Test set avg_accuracy=86.24% avg_sensitivity=84.78%, avg_specificity=86.81% avg_auc=0.9369
Fold[2] Epoch: 118 [118/150 (79%)] Train loss=0.028013 Test loss=1.095806 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.03119492530822754
[5/24] Train loss=0.019972439855337143
[10/24] Train loss=0.01991003006696701
[15/24] Train loss=0.02395901083946228
[20/24] Train loss=0.016681646928191185
Test set avg_accuracy=85.66% avg_sensitivity=86.21%, avg_specificity=85.45% avg_auc=0.9375
Fold[2] Epoch: 119 [119/150 (79%)] Train loss=0.023736 Test loss=1.148571 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.029312746599316597
[5/24] Train loss=0.027988135814666748
[10/24] Train loss=0.024814141914248466
[15/24] Train loss=0.020324161276221275
[20/24] Train loss=0.02502349205315113
Test set avg_accuracy=86.25% avg_sensitivity=84.83%, avg_specificity=86.81% avg_auc=0.9380
Fold[2] Epoch: 120 [120/150 (80%)] Train loss=0.026045 Test loss=1.054693 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.03259067237377167
[5/24] Train loss=0.02268574945628643
[10/24] Train loss=0.01868891902267933
[15/24] Train loss=0.017007838934659958
[20/24] Train loss=0.018325958400964737
Test set avg_accuracy=85.95% avg_sensitivity=85.56%, avg_specificity=86.10% avg_auc=0.9379
Fold[2] Epoch: 121 [121/150 (81%)] Train loss=0.023442 Test loss=1.214982 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.027684286236763
[5/24] Train loss=0.018741196021437645
[10/24] Train loss=0.017239391803741455
[15/24] Train loss=0.015264686197042465
[20/24] Train loss=0.016380101442337036
Test set avg_accuracy=86.09% avg_sensitivity=85.24%, avg_specificity=86.43% avg_auc=0.9381
Fold[2] Epoch: 122 [122/150 (81%)] Train loss=0.018885 Test loss=1.322616 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.02067408338189125
[5/24] Train loss=0.016643814742565155
[10/24] Train loss=0.01718691736459732
[15/24] Train loss=0.014347436837852001
[20/24] Train loss=0.014846487902104855
Test set avg_accuracy=86.08% avg_sensitivity=85.20%, avg_specificity=86.43% avg_auc=0.9386
Fold[2] Epoch: 123 [123/150 (82%)] Train loss=0.015906 Test loss=1.310707 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.016716647893190384
[5/24] Train loss=0.012603629380464554
[10/24] Train loss=0.01675271987915039
[15/24] Train loss=0.012311593629419804
[20/24] Train loss=0.010456491261720657
Test set avg_accuracy=85.51% avg_sensitivity=86.11%, avg_specificity=85.27% avg_auc=0.9388
Fold[2] Epoch: 124 [124/150 (83%)] Train loss=0.014157 Test loss=1.427021 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.01586831919848919
[5/24] Train loss=0.014471503905951977
[10/24] Train loss=0.014735832810401917
[15/24] Train loss=0.017194127663969994
[20/24] Train loss=0.019333824515342712
Test set avg_accuracy=85.83% avg_sensitivity=85.61%, avg_specificity=85.92% avg_auc=0.9387
Fold[2] Epoch: 125 [125/150 (83%)] Train loss=0.016686 Test loss=1.398129 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.014805325306952
[5/24] Train loss=0.012673669494688511
[10/24] Train loss=0.014089379459619522
[15/24] Train loss=0.011164238676428795
[20/24] Train loss=0.018540415912866592
Test set avg_accuracy=85.76% avg_sensitivity=85.33%, avg_specificity=85.92% avg_auc=0.9384
Fold[2] Epoch: 126 [126/150 (84%)] Train loss=0.014367 Test loss=1.395406 Current lr=[0.000123057953306828]

[0/24] Train loss=0.01208215206861496
[5/24] Train loss=0.01401190459728241
[10/24] Train loss=0.01088899839669466
[15/24] Train loss=0.009556373581290245
[20/24] Train loss=0.010564792901277542
Test set avg_accuracy=84.93% avg_sensitivity=86.66%, avg_specificity=84.25% avg_auc=0.9382
Fold[2] Epoch: 127 [127/150 (85%)] Train loss=0.013901 Test loss=1.523354 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.016591809689998627
[5/24] Train loss=0.013393966481089592
[10/24] Train loss=0.014213569462299347
[15/24] Train loss=0.04322192072868347
[20/24] Train loss=0.012529011815786362
Test set avg_accuracy=84.80% avg_sensitivity=86.53%, avg_specificity=84.12% avg_auc=0.9378
Fold[2] Epoch: 128 [128/150 (85%)] Train loss=0.015959 Test loss=1.593356 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.01800857111811638
[5/24] Train loss=0.015559572726488113
[10/24] Train loss=0.016947945579886436
[15/24] Train loss=0.017253868281841278
[20/24] Train loss=0.016539424657821655
Test set avg_accuracy=85.78% avg_sensitivity=85.47%, avg_specificity=85.90% avg_auc=0.9376
Fold[2] Epoch: 129 [129/150 (86%)] Train loss=0.017103 Test loss=1.430635 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.01609303615987301
[5/24] Train loss=0.011410614475607872
[10/24] Train loss=0.019807802513241768
[15/24] Train loss=0.015222957357764244
[20/24] Train loss=0.027594225481152534
Test set avg_accuracy=85.87% avg_sensitivity=85.11%, avg_specificity=86.18% avg_auc=0.9374
Fold[2] Epoch: 130 [130/150 (87%)] Train loss=0.014173 Test loss=1.422524 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.013662225566804409
[5/24] Train loss=0.015890473499894142
[10/24] Train loss=0.012408049777150154
[15/24] Train loss=0.01114476379007101
[20/24] Train loss=0.010536144487559795
Test set avg_accuracy=85.04% avg_sensitivity=85.98%, avg_specificity=84.67% avg_auc=0.9383
Fold[2] Epoch: 131 [131/150 (87%)] Train loss=0.014505 Test loss=1.528266 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.01406841166317463
[5/24] Train loss=0.014358465559780598
[10/24] Train loss=0.015366364270448685
[15/24] Train loss=0.012327977456152439
[20/24] Train loss=0.012107189744710922
Test set avg_accuracy=84.84% avg_sensitivity=86.57%, avg_specificity=84.16% avg_auc=0.9380
Fold[2] Epoch: 132 [132/150 (88%)] Train loss=0.014452 Test loss=1.557003 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.016830839216709137
[5/24] Train loss=0.025892814621329308
[10/24] Train loss=0.016912102699279785
[15/24] Train loss=0.013696128502488136
[20/24] Train loss=0.01667260192334652
Test set avg_accuracy=85.04% avg_sensitivity=85.47%, avg_specificity=84.87% avg_auc=0.9380
Fold[2] Epoch: 133 [133/150 (89%)] Train loss=0.017210 Test loss=1.459453 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.018948182463645935
[5/24] Train loss=0.019748223945498466
[10/24] Train loss=0.020032236352562904
[15/24] Train loss=0.05300208926200867
[20/24] Train loss=0.017453288659453392
Test set avg_accuracy=85.83% avg_sensitivity=85.15%, avg_specificity=86.10% avg_auc=0.9376
Fold[2] Epoch: 134 [134/150 (89%)] Train loss=0.021106 Test loss=1.310516 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.01842387020587921
[5/24] Train loss=0.014035343192517757
[10/24] Train loss=0.016545286402106285
[15/24] Train loss=0.014504432678222656
[20/24] Train loss=0.013581085950136185
Test set avg_accuracy=85.96% avg_sensitivity=85.06%, avg_specificity=86.32% avg_auc=0.9376
Fold[2] Epoch: 135 [135/150 (90%)] Train loss=0.017356 Test loss=1.277141 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.01382613554596901
[5/24] Train loss=0.016254141926765442
[10/24] Train loss=0.021050553768873215
[15/24] Train loss=0.015374739654362202
[20/24] Train loss=0.02475116029381752
Test set avg_accuracy=85.69% avg_sensitivity=85.70%, avg_specificity=85.69% avg_auc=0.9378
Fold[2] Epoch: 136 [136/150 (91%)] Train loss=0.015004 Test loss=1.342278 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.016305282711982727
[5/24] Train loss=0.014232787303626537
[10/24] Train loss=0.014312158338725567
[15/24] Train loss=0.014726446010172367
[20/24] Train loss=0.017537876963615417
Test set avg_accuracy=85.74% avg_sensitivity=85.79%, avg_specificity=85.72% avg_auc=0.9379
Fold[2] Epoch: 137 [137/150 (91%)] Train loss=0.016307 Test loss=1.359204 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.01870109885931015
[5/24] Train loss=0.01688787341117859
[10/24] Train loss=0.018507851287722588
[15/24] Train loss=0.015015431679785252
[20/24] Train loss=0.014560297131538391
Test set avg_accuracy=85.76% avg_sensitivity=85.33%, avg_specificity=85.92% avg_auc=0.9378
Fold[2] Epoch: 138 [138/150 (92%)] Train loss=0.017582 Test loss=1.320886 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.01429190207272768
[5/24] Train loss=0.01533206645399332
[10/24] Train loss=0.01714986376464367
[15/24] Train loss=0.014291681349277496
[20/24] Train loss=0.014431999996304512
Test set avg_accuracy=85.86% avg_sensitivity=85.06%, avg_specificity=86.18% avg_auc=0.9379
Fold[2] Epoch: 139 [139/150 (93%)] Train loss=0.015287 Test loss=1.291272 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.014175592921674252
[5/24] Train loss=0.0127011239528656
[10/24] Train loss=0.013170729391276836
[15/24] Train loss=0.010363809764385223
[20/24] Train loss=0.02984548546373844
Test set avg_accuracy=85.81% avg_sensitivity=85.06%, avg_specificity=86.10% avg_auc=0.9379
Fold[2] Epoch: 140 [140/150 (93%)] Train loss=0.013558 Test loss=1.328925 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.008887328207492828
[5/24] Train loss=0.010049236007034779
[10/24] Train loss=0.010832294821739197
[15/24] Train loss=0.008792410604655743
[20/24] Train loss=0.009942670352756977
Test set avg_accuracy=85.70% avg_sensitivity=85.29%, avg_specificity=85.87% avg_auc=0.9379
Fold[2] Epoch: 141 [141/150 (94%)] Train loss=0.012455 Test loss=1.347269 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.008439268916845322
[5/24] Train loss=0.007543282583355904
[10/24] Train loss=0.045429810881614685
[15/24] Train loss=0.02322991006076336
[20/24] Train loss=0.00906414445489645
Test set avg_accuracy=85.55% avg_sensitivity=85.52%, avg_specificity=85.56% avg_auc=0.9379
Fold[2] Epoch: 142 [142/150 (95%)] Train loss=0.012691 Test loss=1.433745 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.008269795216619968
[5/24] Train loss=0.013974043540656567
[10/24] Train loss=0.009591157548129559
[15/24] Train loss=0.008789055049419403
[20/24] Train loss=0.009094995446503162
Test set avg_accuracy=85.26% avg_sensitivity=85.75%, avg_specificity=85.07% avg_auc=0.9380
Fold[2] Epoch: 143 [143/150 (95%)] Train loss=0.010391 Test loss=1.462688 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.009748687967658043
[5/24] Train loss=0.009620718657970428
[10/24] Train loss=0.0089358976110816
[15/24] Train loss=0.007427205331623554
[20/24] Train loss=0.011830136179924011
Test set avg_accuracy=85.14% avg_sensitivity=86.02%, avg_specificity=84.79% avg_auc=0.9379
Fold[2] Epoch: 144 [144/150 (96%)] Train loss=0.011057 Test loss=1.505951 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.011220866814255714
[5/24] Train loss=0.010911351069808006
[10/24] Train loss=0.00978674367070198
[15/24] Train loss=0.010836412198841572
[20/24] Train loss=0.011840002611279488
Test set avg_accuracy=85.14% avg_sensitivity=86.02%, avg_specificity=84.79% avg_auc=0.9379
Fold[2] Epoch: 145 [145/150 (97%)] Train loss=0.011301 Test loss=1.517987 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.014978229068219662
[5/24] Train loss=0.012391109019517899
[10/24] Train loss=0.012941829860210419
[15/24] Train loss=0.016382260248064995
[20/24] Train loss=0.011616012081503868
Test set avg_accuracy=85.16% avg_sensitivity=86.02%, avg_specificity=84.81% avg_auc=0.9379
Fold[2] Epoch: 146 [146/150 (97%)] Train loss=0.013055 Test loss=1.517976 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.014700799249112606
[5/24] Train loss=0.015894874930381775
[10/24] Train loss=0.015374022535979748
[15/24] Train loss=0.019792690873146057
[20/24] Train loss=0.01597025617957115
Test set avg_accuracy=85.12% avg_sensitivity=86.02%, avg_specificity=84.76% avg_auc=0.9379
Fold[2] Epoch: 147 [147/150 (98%)] Train loss=0.018368 Test loss=1.527965 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.021953454241156578
[5/24] Train loss=0.01838371902704239
[10/24] Train loss=0.020937925204634666
[15/24] Train loss=0.01925424113869667
[20/24] Train loss=0.0189829058945179
Test set avg_accuracy=85.12% avg_sensitivity=86.02%, avg_specificity=84.76% avg_auc=0.9380
Fold[2] Epoch: 148 [148/150 (99%)] Train loss=0.018964 Test loss=1.504577 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.03251929208636284
[5/24] Train loss=0.02062191255390644
[10/24] Train loss=0.02299470826983452
[15/24] Train loss=0.02199614979326725
[20/24] Train loss=0.02157684601843357
Test set avg_accuracy=85.10% avg_sensitivity=85.98%, avg_specificity=84.76% avg_auc=0.9380
Fold[2] Epoch: 149 [149/150 (99%)] Train loss=0.022416 Test loss=1.504214 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.029973627999424934
[5/24] Train loss=0.03049437701702118
[10/24] Train loss=0.029149990528821945
[15/24] Train loss=0.025600790977478027
[20/24] Train loss=0.05951912701129913
Test set avg_accuracy=85.10% avg_sensitivity=85.98%, avg_specificity=84.76% avg_auc=0.9380
Fold[2] Epoch: 150 [150/150 (100%)] Train loss=0.028596 Test loss=1.503505 Current lr=[4.388541022775342e-09]

Fold[2] Result: acc=85.01% sen=90.51%, spe=82.83%, auc=0.94!
Fold[2] Avg_overlap=0.60%(0.2217626547291817)
[0/24] Train loss=1.4021642208099365
[5/24] Train loss=1.3438332080841064
[10/24] Train loss=1.2177376747131348
[15/24] Train loss=1.022843360900879
[20/24] Train loss=0.9635411500930786
Test set avg_accuracy=78.07% avg_sensitivity=43.51%, avg_specificity=88.67% avg_auc=0.8276
Best model saved!! Metric=0.8276410392747237!!
Fold[3] Epoch: 1 [1/150 (1%)] Train loss=1.190721 Test loss=0.469766 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.9651997089385986
[5/24] Train loss=0.9720107913017273
[10/24] Train loss=0.9574784636497498
[15/24] Train loss=0.8132480978965759
[20/24] Train loss=0.7938500046730042
Test set avg_accuracy=81.76% avg_sensitivity=84.13%, avg_specificity=81.03% avg_auc=0.8820
Best model saved!! Metric=0.8819572710220658!!
Fold[3] Epoch: 2 [2/150 (1%)] Train loss=0.945759 Test loss=0.500067 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.9506220817565918
[5/24] Train loss=0.9234790205955505
[10/24] Train loss=0.8812673687934875
[15/24] Train loss=0.8020225167274475
[20/24] Train loss=0.7809430956840515
Test set avg_accuracy=83.85% avg_sensitivity=78.08%, avg_specificity=85.62% avg_auc=0.8956
Best model saved!! Metric=0.8956267260414216!!
Fold[3] Epoch: 3 [3/150 (2%)] Train loss=0.895949 Test loss=0.401586 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.8022935390472412
[5/24] Train loss=0.8747674822807312
[10/24] Train loss=0.858039915561676
[15/24] Train loss=0.7531071901321411
[20/24] Train loss=0.7220627069473267
Test set avg_accuracy=83.96% avg_sensitivity=84.18%, avg_specificity=83.89% avg_auc=0.9094
Best model saved!! Metric=0.9093632117955965!!
Fold[3] Epoch: 4 [4/150 (3%)] Train loss=0.825810 Test loss=0.417905 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.760324239730835
[5/24] Train loss=0.8311255574226379
[10/24] Train loss=0.7502608895301819
[15/24] Train loss=0.6920000314712524
[20/24] Train loss=0.6793076992034912
Test set avg_accuracy=84.09% avg_sensitivity=86.18%, avg_specificity=83.45% avg_auc=0.9190
Best model saved!! Metric=0.9189626266833685!!
Fold[3] Epoch: 5 [5/150 (3%)] Train loss=0.785689 Test loss=0.421335 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.7496544718742371
[5/24] Train loss=0.7946015000343323
[10/24] Train loss=0.7446490526199341
[15/24] Train loss=0.6740233302116394
[20/24] Train loss=0.6543947458267212
Test set avg_accuracy=86.77% avg_sensitivity=82.96%, avg_specificity=87.94% avg_auc=0.9284
Best model saved!! Metric=0.9284438408950926!!
Fold[3] Epoch: 6 [6/150 (4%)] Train loss=0.763597 Test loss=0.343311 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.7116727828979492
[5/24] Train loss=0.7571520209312439
[10/24] Train loss=0.7278175950050354
[15/24] Train loss=0.6316207647323608
[20/24] Train loss=0.6319059133529663
Test set avg_accuracy=84.28% avg_sensitivity=92.67%, avg_specificity=81.71% avg_auc=0.9303
Best model saved!! Metric=0.9302501303794997!!
Fold[3] Epoch: 7 [7/150 (5%)] Train loss=0.729188 Test loss=0.451237 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.7749230861663818
[5/24] Train loss=0.7249921560287476
[10/24] Train loss=0.703106164932251
[15/24] Train loss=0.6247239708900452
[20/24] Train loss=0.6297157406806946
Test set avg_accuracy=87.68% avg_sensitivity=84.46%, avg_specificity=88.67% avg_auc=0.9375
Best model saved!! Metric=0.9375188582947607!!
Fold[3] Epoch: 8 [8/150 (5%)] Train loss=0.727286 Test loss=0.313152 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.6645245552062988
[5/24] Train loss=0.6924073696136475
[10/24] Train loss=0.7171186208724976
[15/24] Train loss=0.5922435522079468
[20/24] Train loss=0.619117796421051
Test set avg_accuracy=85.09% avg_sensitivity=92.73%, avg_specificity=82.75% avg_auc=0.9383
Best model saved!! Metric=0.9383187898667655!!
Fold[3] Epoch: 9 [9/150 (6%)] Train loss=0.697604 Test loss=0.429651 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.7392484545707703
[5/24] Train loss=0.706691324710846
[10/24] Train loss=0.6478782892227173
[15/24] Train loss=0.6079279780387878
[20/24] Train loss=0.5854459404945374
Test set avg_accuracy=89.19% avg_sensitivity=82.57%, avg_specificity=91.22% avg_auc=0.9441
Best model saved!! Metric=0.9441205359890847!!
Fold[3] Epoch: 10 [10/150 (7%)] Train loss=0.698111 Test loss=0.285609 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.6629136204719543
[5/24] Train loss=0.6934831142425537
[10/24] Train loss=0.7100340723991394
[15/24] Train loss=0.5654511451721191
[20/24] Train loss=0.5694629549980164
Test set avg_accuracy=86.39% avg_sensitivity=91.51%, avg_specificity=84.82% avg_auc=0.9450
Best model saved!! Metric=0.9450253564996587!!
Fold[3] Epoch: 11 [11/150 (7%)] Train loss=0.672740 Test loss=0.373082 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.6947492361068726
[5/24] Train loss=0.6855566501617432
[10/24] Train loss=0.6793109178543091
[15/24] Train loss=0.565726637840271
[20/24] Train loss=0.5710722804069519
Test set avg_accuracy=88.83% avg_sensitivity=86.96%, avg_specificity=89.40% avg_auc=0.9460
Best model saved!! Metric=0.9459698289942104!!
Fold[3] Epoch: 12 [12/150 (8%)] Train loss=0.669586 Test loss=0.301421 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6326183676719666
[5/24] Train loss=0.6470449566841125
[10/24] Train loss=0.6777966022491455
[15/24] Train loss=0.5642600059509277
[20/24] Train loss=0.5602129697799683
Test set avg_accuracy=87.38% avg_sensitivity=91.12%, avg_specificity=86.24% avg_auc=0.9469
Best model saved!! Metric=0.9468545402843388!!
Fold[3] Epoch: 13 [13/150 (9%)] Train loss=0.644656 Test loss=0.357702 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.6392053365707397
[5/24] Train loss=0.6694905757904053
[10/24] Train loss=0.6889623999595642
[15/24] Train loss=0.5682079792022705
[20/24] Train loss=0.5405164957046509
Test set avg_accuracy=86.04% avg_sensitivity=92.23%, avg_specificity=84.14% avg_auc=0.9453
Fold[3] Epoch: 14 [14/150 (9%)] Train loss=0.644966 Test loss=0.372813 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.692503035068512
[5/24] Train loss=0.6381696462631226
[10/24] Train loss=0.6622349619865417
[15/24] Train loss=0.5554320216178894
[20/24] Train loss=0.5137066841125488
Test set avg_accuracy=89.39% avg_sensitivity=84.85%, avg_specificity=90.78% avg_auc=0.9470
Best model saved!! Metric=0.9469577298521659!!
Fold[3] Epoch: 15 [15/150 (10%)] Train loss=0.631947 Test loss=0.288143 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.6002834439277649
[5/24] Train loss=0.6229878067970276
[10/24] Train loss=0.658403754234314
[15/24] Train loss=0.530473530292511
[20/24] Train loss=0.5294087529182434
Test set avg_accuracy=88.58% avg_sensitivity=88.24%, avg_specificity=88.69% avg_auc=0.9483
Best model saved!! Metric=0.9483289804266478!!
Fold[3] Epoch: 16 [16/150 (11%)] Train loss=0.618082 Test loss=0.315476 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.569590151309967
[5/24] Train loss=0.5969218015670776
[10/24] Train loss=0.6420159935951233
[15/24] Train loss=0.5181283950805664
[20/24] Train loss=0.5363399982452393
Test set avg_accuracy=87.02% avg_sensitivity=89.90%, avg_specificity=86.13% avg_auc=0.9489
Best model saved!! Metric=0.9489348533008766!!
Fold[3] Epoch: 17 [17/150 (11%)] Train loss=0.608250 Test loss=0.349373 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.5945128202438354
[5/24] Train loss=0.6281048059463501
[10/24] Train loss=0.6577008366584778
[15/24] Train loss=0.5347282886505127
[20/24] Train loss=0.5146805047988892
Test set avg_accuracy=90.13% avg_sensitivity=83.30%, avg_specificity=92.23% avg_auc=0.9506
Best model saved!! Metric=0.950593769578167!!
Fold[3] Epoch: 18 [18/150 (12%)] Train loss=0.599081 Test loss=0.265772 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.587469756603241
[5/24] Train loss=0.5887318849563599
[10/24] Train loss=0.6338437795639038
[15/24] Train loss=0.5015113949775696
[20/24] Train loss=0.5099648833274841
Test set avg_accuracy=88.50% avg_sensitivity=89.90%, avg_specificity=88.07% avg_auc=0.9497
Fold[3] Epoch: 19 [19/150 (13%)] Train loss=0.598239 Test loss=0.329620 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.6167777180671692
[5/24] Train loss=0.5971461534500122
[10/24] Train loss=0.6133440732955933
[15/24] Train loss=0.5019395351409912
[20/24] Train loss=0.519274890422821
Test set avg_accuracy=89.38% avg_sensitivity=85.02%, avg_specificity=90.71% avg_auc=0.9502
Fold[3] Epoch: 20 [20/150 (13%)] Train loss=0.591598 Test loss=0.276337 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.5768300294876099
[5/24] Train loss=0.5569884777069092
[10/24] Train loss=0.6414909958839417
[15/24] Train loss=0.49628621339797974
[20/24] Train loss=0.5126289129257202
Test set avg_accuracy=88.32% avg_sensitivity=89.18%, avg_specificity=88.06% avg_auc=0.9471
Fold[3] Epoch: 21 [21/150 (14%)] Train loss=0.580894 Test loss=0.328697 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.6011841893196106
[5/24] Train loss=0.5674799680709839
[10/24] Train loss=0.5942080616950989
[15/24] Train loss=0.48685771226882935
[20/24] Train loss=0.48894014954566956
Test set avg_accuracy=89.36% avg_sensitivity=87.13%, avg_specificity=90.05% avg_auc=0.9489
Fold[3] Epoch: 22 [22/150 (15%)] Train loss=0.572447 Test loss=0.293579 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.5603016018867493
[5/24] Train loss=0.5740842223167419
[10/24] Train loss=0.6237559914588928
[15/24] Train loss=0.4853278696537018
[20/24] Train loss=0.47002509236335754
Test set avg_accuracy=89.71% avg_sensitivity=85.46%, avg_specificity=91.02% avg_auc=0.9470
Fold[3] Epoch: 23 [23/150 (15%)] Train loss=0.563614 Test loss=0.291029 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5611512660980225
[5/24] Train loss=0.5717317461967468
[10/24] Train loss=0.6260707974433899
[15/24] Train loss=0.464656800031662
[20/24] Train loss=0.45279455184936523
Test set avg_accuracy=86.46% avg_sensitivity=92.40%, avg_specificity=84.64% avg_auc=0.9515
Best model saved!! Metric=0.9515372507731191!!
Fold[3] Epoch: 24 [24/150 (16%)] Train loss=0.568159 Test loss=0.398918 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.5995760560035706
[5/24] Train loss=0.5431342124938965
[10/24] Train loss=0.6712833642959595
[15/24] Train loss=0.4806380271911621
[20/24] Train loss=0.4490044414997101
Test set avg_accuracy=88.59% avg_sensitivity=85.24%, avg_specificity=89.62% avg_auc=0.9459
Fold[3] Epoch: 25 [25/150 (17%)] Train loss=0.566359 Test loss=0.297023 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5641961693763733
[5/24] Train loss=0.5629363059997559
[10/24] Train loss=0.5938413143157959
[15/24] Train loss=0.48319825530052185
[20/24] Train loss=0.45200586318969727
Test set avg_accuracy=87.59% avg_sensitivity=90.12%, avg_specificity=86.82% avg_auc=0.9524
Best model saved!! Metric=0.9523506829015738!!
Fold[3] Epoch: 26 [26/150 (17%)] Train loss=0.558063 Test loss=0.362987 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5598195195198059
[5/24] Train loss=0.5342116355895996
[10/24] Train loss=0.6009799242019653
[15/24] Train loss=0.470305472612381
[20/24] Train loss=0.4994836449623108
Test set avg_accuracy=88.59% avg_sensitivity=87.90%, avg_specificity=88.81% avg_auc=0.9495
Fold[3] Epoch: 27 [27/150 (18%)] Train loss=0.543683 Test loss=0.319185 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5400773286819458
[5/24] Train loss=0.5280578136444092
[10/24] Train loss=0.5902234315872192
[15/24] Train loss=0.4403354227542877
[20/24] Train loss=0.4316084384918213
Test set avg_accuracy=87.51% avg_sensitivity=88.73%, avg_specificity=87.14% avg_auc=0.9478
Fold[3] Epoch: 28 [28/150 (19%)] Train loss=0.525849 Test loss=0.360063 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5283364653587341
[5/24] Train loss=0.5519360899925232
[10/24] Train loss=0.6236234307289124
[15/24] Train loss=0.46203476190567017
[20/24] Train loss=0.4564017355442047
Test set avg_accuracy=89.28% avg_sensitivity=85.63%, avg_specificity=90.40% avg_auc=0.9497
Fold[3] Epoch: 29 [29/150 (19%)] Train loss=0.536890 Test loss=0.300409 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.537937581539154
[5/24] Train loss=0.5007513761520386
[10/24] Train loss=0.5495079159736633
[15/24] Train loss=0.43095800280570984
[20/24] Train loss=0.4574878513813019
Test set avg_accuracy=88.78% avg_sensitivity=89.57%, avg_specificity=88.53% avg_auc=0.9526
Best model saved!! Metric=0.9525648508197953!!
Fold[3] Epoch: 30 [30/150 (20%)] Train loss=0.512458 Test loss=0.339729 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.5010198950767517
[5/24] Train loss=0.5257775783538818
[10/24] Train loss=0.5622097253799438
[15/24] Train loss=0.4194331467151642
[20/24] Train loss=0.43975552916526794
Test set avg_accuracy=89.79% avg_sensitivity=85.74%, avg_specificity=91.03% avg_auc=0.9485
Fold[3] Epoch: 31 [31/150 (21%)] Train loss=0.515912 Test loss=0.285648 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.5297545790672302
[5/24] Train loss=0.5220640301704407
[10/24] Train loss=0.5141772627830505
[15/24] Train loss=0.42174994945526123
[20/24] Train loss=0.44064825773239136
Test set avg_accuracy=89.09% avg_sensitivity=88.62%, avg_specificity=89.23% avg_auc=0.9489
Fold[3] Epoch: 32 [32/150 (21%)] Train loss=0.491520 Test loss=0.329656 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.48941895365715027
[5/24] Train loss=0.4709070026874542
[10/24] Train loss=0.4574015736579895
[15/24] Train loss=0.4489351212978363
[20/24] Train loss=0.40241628885269165
Test set avg_accuracy=84.64% avg_sensitivity=91.90%, avg_specificity=82.41% avg_auc=0.9450
Fold[3] Epoch: 33 [33/150 (22%)] Train loss=0.477097 Test loss=0.481741 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.5137845873832703
[5/24] Train loss=0.5015571117401123
[10/24] Train loss=0.4890473186969757
[15/24] Train loss=0.4006116986274719
[20/24] Train loss=0.39965617656707764
Test set avg_accuracy=88.98% avg_sensitivity=86.90%, avg_specificity=89.62% avg_auc=0.9482
Fold[3] Epoch: 34 [34/150 (23%)] Train loss=0.476801 Test loss=0.316498 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.47657912969589233
[5/24] Train loss=0.4602024257183075
[10/24] Train loss=0.4489579200744629
[15/24] Train loss=0.3771381676197052
[20/24] Train loss=0.3785821199417114
Test set avg_accuracy=86.55% avg_sensitivity=90.46%, avg_specificity=85.35% avg_auc=0.9487
Fold[3] Epoch: 35 [35/150 (23%)] Train loss=0.447188 Test loss=0.403594 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.471143901348114
[5/24] Train loss=0.49951910972595215
[10/24] Train loss=0.44358116388320923
[15/24] Train loss=0.3652922511100769
[20/24] Train loss=0.38997507095336914
Test set avg_accuracy=88.24% avg_sensitivity=87.74%, avg_specificity=88.40% avg_auc=0.9471
Fold[3] Epoch: 36 [36/150 (24%)] Train loss=0.452877 Test loss=0.335678 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.44196826219558716
[5/24] Train loss=0.4061080813407898
[10/24] Train loss=0.4271176755428314
[15/24] Train loss=0.3564860224723816
[20/24] Train loss=0.37181639671325684
Test set avg_accuracy=88.45% avg_sensitivity=86.35%, avg_specificity=89.09% avg_auc=0.9475
Fold[3] Epoch: 37 [37/150 (25%)] Train loss=0.424657 Test loss=0.314247 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.4175928235054016
[5/24] Train loss=0.3893561363220215
[10/24] Train loss=0.4605688154697418
[15/24] Train loss=0.3389120399951935
[20/24] Train loss=0.36331063508987427
Test set avg_accuracy=82.49% avg_sensitivity=94.40%, avg_specificity=78.84% avg_auc=0.9458
Fold[3] Epoch: 38 [38/150 (25%)] Train loss=0.416578 Test loss=0.539794 Current lr=[0.000944367614404117]

[0/24] Train loss=0.4278094172477722
[5/24] Train loss=0.48368626832962036
[10/24] Train loss=0.4478624165058136
[15/24] Train loss=0.3416233956813812
[20/24] Train loss=0.39614227414131165
Test set avg_accuracy=87.60% avg_sensitivity=89.96%, avg_specificity=86.88% avg_auc=0.9476
Fold[3] Epoch: 39 [39/150 (26%)] Train loss=0.437345 Test loss=0.351760 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.41815197467803955
[5/24] Train loss=0.4838862121105194
[10/24] Train loss=0.45827576518058777
[15/24] Train loss=0.3460037410259247
[20/24] Train loss=0.3729458153247833
Test set avg_accuracy=87.96% avg_sensitivity=87.13%, avg_specificity=88.21% avg_auc=0.9475
Fold[3] Epoch: 40 [40/150 (27%)] Train loss=0.434733 Test loss=0.332069 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.4164324700832367
[5/24] Train loss=0.45235422253608704
[10/24] Train loss=0.5158631801605225
[15/24] Train loss=0.3573075234889984
[20/24] Train loss=0.35146117210388184
Test set avg_accuracy=86.84% avg_sensitivity=88.73%, avg_specificity=86.25% avg_auc=0.9427
Fold[3] Epoch: 41 [41/150 (27%)] Train loss=0.413365 Test loss=0.411502 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.4803694784641266
[5/24] Train loss=0.42618414759635925
[10/24] Train loss=0.3575926125049591
[15/24] Train loss=0.36256885528564453
[20/24] Train loss=0.3344510793685913
Test set avg_accuracy=89.08% avg_sensitivity=87.18%, avg_specificity=89.66% avg_auc=0.9446
Fold[3] Epoch: 42 [42/150 (28%)] Train loss=0.399732 Test loss=0.352816 Current lr=[0.000989780311725182]

[0/24] Train loss=0.3894083499908447
[5/24] Train loss=0.381130188703537
[10/24] Train loss=0.3690965175628662
[15/24] Train loss=0.3004511892795563
[20/24] Train loss=0.296406626701355
Test set avg_accuracy=87.73% avg_sensitivity=87.40%, avg_specificity=87.84% avg_auc=0.9406
Fold[3] Epoch: 43 [43/150 (29%)] Train loss=0.361542 Test loss=0.371895 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.3533300459384918
[5/24] Train loss=0.34478047490119934
[10/24] Train loss=0.3674677014350891
[15/24] Train loss=0.2996685802936554
[20/24] Train loss=0.2944568693637848
Test set avg_accuracy=86.54% avg_sensitivity=89.46%, avg_specificity=85.64% avg_auc=0.9413
Fold[3] Epoch: 44 [44/150 (29%)] Train loss=0.342273 Test loss=0.399676 Current lr=[0.000998924125869967]

[0/24] Train loss=0.387370765209198
[5/24] Train loss=0.3647594451904297
[10/24] Train loss=0.3814149498939514
[15/24] Train loss=0.28031426668167114
[20/24] Train loss=0.284035861492157
Test set avg_accuracy=86.39% avg_sensitivity=90.29%, avg_specificity=85.20% avg_auc=0.9423
Fold[3] Epoch: 45 [45/150 (30%)] Train loss=0.352312 Test loss=0.427031 Current lr=[0.000999999611458977]

[0/24] Train loss=0.3870423138141632
[5/24] Train loss=0.36251914501190186
[10/24] Train loss=0.3539169728755951
[15/24] Train loss=0.29227277636528015
[20/24] Train loss=0.27621322870254517
Test set avg_accuracy=88.52% avg_sensitivity=86.51%, avg_specificity=89.13% avg_auc=0.9442
Fold[3] Epoch: 46 [46/150 (31%)] Train loss=0.346259 Test loss=0.336706 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.3247835040092468
[5/24] Train loss=0.32527467608451843
[10/24] Train loss=0.30625107884407043
[15/24] Train loss=0.2756974399089813
[20/24] Train loss=0.2702707350254059
Test set avg_accuracy=86.56% avg_sensitivity=91.18%, avg_specificity=85.15% avg_auc=0.9447
Fold[3] Epoch: 47 [47/150 (31%)] Train loss=0.307755 Test loss=0.421468 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.35256943106651306
[5/24] Train loss=0.28376710414886475
[10/24] Train loss=0.33636000752449036
[15/24] Train loss=0.23989079892635345
[20/24] Train loss=0.2713436186313629
Test set avg_accuracy=89.11% avg_sensitivity=85.90%, avg_specificity=90.10% avg_auc=0.9496
Fold[3] Epoch: 48 [48/150 (32%)] Train loss=0.305703 Test loss=0.348421 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3056613504886627
[5/24] Train loss=0.28817984461784363
[10/24] Train loss=0.3273141086101532
[15/24] Train loss=0.24000602960586548
[20/24] Train loss=0.238514244556427
Test set avg_accuracy=87.16% avg_sensitivity=90.40%, avg_specificity=86.17% avg_auc=0.9482
Fold[3] Epoch: 49 [49/150 (33%)] Train loss=0.275381 Test loss=0.402594 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3298121988773346
[5/24] Train loss=0.2900239825248718
[10/24] Train loss=0.30036842823028564
[15/24] Train loss=0.2144533395767212
[20/24] Train loss=0.22732655704021454
Test set avg_accuracy=89.31% avg_sensitivity=85.68%, avg_specificity=90.42% avg_auc=0.9441
Fold[3] Epoch: 50 [50/150 (33%)] Train loss=0.286671 Test loss=0.354695 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.2849743366241455
[5/24] Train loss=0.23816099762916565
[10/24] Train loss=0.298694908618927
[15/24] Train loss=0.19808919727802277
[20/24] Train loss=0.21268923580646515
Test set avg_accuracy=88.31% avg_sensitivity=89.18%, avg_specificity=88.04% avg_auc=0.9419
Fold[3] Epoch: 51 [51/150 (34%)] Train loss=0.250926 Test loss=0.401717 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.2804093062877655
[5/24] Train loss=0.24003620445728302
[10/24] Train loss=0.24861225485801697
[15/24] Train loss=0.1960841864347458
[20/24] Train loss=0.22335003316402435
Test set avg_accuracy=88.80% avg_sensitivity=86.07%, avg_specificity=89.64% avg_auc=0.9428
Fold[3] Epoch: 52 [52/150 (35%)] Train loss=0.253830 Test loss=0.362910 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.2741377651691437
[5/24] Train loss=0.2350088357925415
[10/24] Train loss=0.23733706772327423
[15/24] Train loss=0.18950290977954865
[20/24] Train loss=0.22214862704277039
Test set avg_accuracy=89.24% avg_sensitivity=84.52%, avg_specificity=90.69% avg_auc=0.9361
Fold[3] Epoch: 53 [53/150 (35%)] Train loss=0.255136 Test loss=0.358853 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.2798618972301483
[5/24] Train loss=0.2592979669570923
[10/24] Train loss=0.2417699694633484
[15/24] Train loss=0.1949908286333084
[20/24] Train loss=0.19175848364830017
Test set avg_accuracy=85.76% avg_sensitivity=90.57%, avg_specificity=84.28% avg_auc=0.9319
Fold[3] Epoch: 54 [54/150 (36%)] Train loss=0.237172 Test loss=0.585043 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.27459853887557983
[5/24] Train loss=0.2287382334470749
[10/24] Train loss=0.23352445662021637
[15/24] Train loss=0.21211859583854675
[20/24] Train loss=0.21109899878501892
Test set avg_accuracy=87.54% avg_sensitivity=87.40%, avg_specificity=87.58% avg_auc=0.9368
Fold[3] Epoch: 55 [55/150 (37%)] Train loss=0.234345 Test loss=0.487874 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.21593891084194183
[5/24] Train loss=0.21430547535419464
[10/24] Train loss=0.244245707988739
[15/24] Train loss=0.17182478308677673
[20/24] Train loss=0.13090485334396362
Test set avg_accuracy=87.71% avg_sensitivity=89.84%, avg_specificity=87.05% avg_auc=0.9404
Fold[3] Epoch: 56 [56/150 (37%)] Train loss=0.204496 Test loss=0.602022 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.2626626491546631
[5/24] Train loss=0.23328566551208496
[10/24] Train loss=0.24209904670715332
[15/24] Train loss=0.154030904173851
[20/24] Train loss=0.15371695160865784
Test set avg_accuracy=87.53% avg_sensitivity=88.79%, avg_specificity=87.14% avg_auc=0.9423
Fold[3] Epoch: 57 [57/150 (38%)] Train loss=0.214797 Test loss=0.521361 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.20633402466773987
[5/24] Train loss=0.23479227721691132
[10/24] Train loss=0.2164893001317978
[15/24] Train loss=0.15250654518604279
[20/24] Train loss=0.15506945550441742
Test set avg_accuracy=88.42% avg_sensitivity=86.90%, avg_specificity=88.89% avg_auc=0.9443
Fold[3] Epoch: 58 [58/150 (39%)] Train loss=0.201600 Test loss=0.524132 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.18451723456382751
[5/24] Train loss=0.17256034910678864
[10/24] Train loss=0.18622958660125732
[15/24] Train loss=0.1665416806936264
[20/24] Train loss=0.1386922150850296
Test set avg_accuracy=88.02% avg_sensitivity=87.96%, avg_specificity=88.04% avg_auc=0.9459
Fold[3] Epoch: 59 [59/150 (39%)] Train loss=0.183356 Test loss=0.561441 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.19015514850616455
[5/24] Train loss=0.17350289225578308
[10/24] Train loss=0.2135770320892334
[15/24] Train loss=0.1527738720178604
[20/24] Train loss=0.13126826286315918
Test set avg_accuracy=88.74% avg_sensitivity=87.35%, avg_specificity=89.16% avg_auc=0.9447
Fold[3] Epoch: 60 [60/150 (40%)] Train loss=0.177247 Test loss=0.491239 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.1546696424484253
[5/24] Train loss=0.1704006791114807
[10/24] Train loss=0.16529446840286255
[15/24] Train loss=0.1285349726676941
[20/24] Train loss=0.12155108153820038
Test set avg_accuracy=88.39% avg_sensitivity=88.96%, avg_specificity=88.21% avg_auc=0.9462
Fold[3] Epoch: 61 [61/150 (41%)] Train loss=0.166317 Test loss=0.690992 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.18427467346191406
[5/24] Train loss=0.16904036700725555
[10/24] Train loss=0.18139980733394623
[15/24] Train loss=0.17656241357326508
[20/24] Train loss=0.13239026069641113
Test set avg_accuracy=89.71% avg_sensitivity=87.13%, avg_specificity=90.51% avg_auc=0.9434
Fold[3] Epoch: 62 [62/150 (41%)] Train loss=0.180426 Test loss=0.570753 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.16668492555618286
[5/24] Train loss=0.17471323907375336
[10/24] Train loss=0.17834194004535675
[15/24] Train loss=0.13437259197235107
[20/24] Train loss=0.12364508211612701
Test set avg_accuracy=87.83% avg_sensitivity=89.51%, avg_specificity=87.31% avg_auc=0.9414
Fold[3] Epoch: 63 [63/150 (42%)] Train loss=0.169464 Test loss=0.650311 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.18047542870044708
[5/24] Train loss=0.16819733381271362
[10/24] Train loss=0.18394416570663452
[15/24] Train loss=0.14570820331573486
[20/24] Train loss=0.12374192476272583
Test set avg_accuracy=87.99% avg_sensitivity=88.01%, avg_specificity=87.99% avg_auc=0.9410
Fold[3] Epoch: 64 [64/150 (43%)] Train loss=0.165792 Test loss=0.499567 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.1491498053073883
[5/24] Train loss=0.15299856662750244
[10/24] Train loss=0.16609160602092743
[15/24] Train loss=0.1439998894929886
[20/24] Train loss=0.10940053313970566
Test set avg_accuracy=89.18% avg_sensitivity=85.41%, avg_specificity=90.34% avg_auc=0.9452
Fold[3] Epoch: 65 [65/150 (43%)] Train loss=0.158386 Test loss=0.489702 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.13876675069332123
[5/24] Train loss=0.13042579591274261
[10/24] Train loss=0.1634363830089569
[15/24] Train loss=0.1315000355243683
[20/24] Train loss=0.14309895038604736
Test set avg_accuracy=88.59% avg_sensitivity=86.96%, avg_specificity=89.09% avg_auc=0.9439
Fold[3] Epoch: 66 [66/150 (44%)] Train loss=0.149901 Test loss=0.539441 Current lr=[0.000904142181093812]

[0/24] Train loss=0.14799223840236664
[5/24] Train loss=0.1530022919178009
[10/24] Train loss=0.17964020371437073
[15/24] Train loss=0.12748049199581146
[20/24] Train loss=0.10870850086212158
Test set avg_accuracy=86.72% avg_sensitivity=90.12%, avg_specificity=85.68% avg_auc=0.9414
Fold[3] Epoch: 67 [67/150 (45%)] Train loss=0.145508 Test loss=0.881369 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.16032585501670837
[5/24] Train loss=0.1470872312784195
[10/24] Train loss=0.17193758487701416
[15/24] Train loss=0.1283484250307083
[20/24] Train loss=0.13244205713272095
Test set avg_accuracy=89.48% avg_sensitivity=85.79%, avg_specificity=90.61% avg_auc=0.9485
Fold[3] Epoch: 68 [68/150 (45%)] Train loss=0.144051 Test loss=0.642671 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.11475442349910736
[5/24] Train loss=0.1119333952665329
[10/24] Train loss=0.11270461976528168
[15/24] Train loss=0.12674707174301147
[20/24] Train loss=0.11022980511188507
Test set avg_accuracy=89.30% avg_sensitivity=86.13%, avg_specificity=90.27% avg_auc=0.9445
Fold[3] Epoch: 69 [69/150 (46%)] Train loss=0.125698 Test loss=0.544342 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.13394734263420105
[5/24] Train loss=0.10470958054065704
[10/24] Train loss=0.09859296679496765
[15/24] Train loss=0.12061480432748795
[20/24] Train loss=0.0846538245677948
Test set avg_accuracy=89.97% avg_sensitivity=86.40%, avg_specificity=91.07% avg_auc=0.9445
Fold[3] Epoch: 70 [70/150 (47%)] Train loss=0.117877 Test loss=0.650616 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.08261638879776001
[5/24] Train loss=0.11621076613664627
[10/24] Train loss=0.09198575466871262
[15/24] Train loss=0.10465303063392639
[20/24] Train loss=0.13740235567092896
Test set avg_accuracy=88.28% avg_sensitivity=89.12%, avg_specificity=88.02% avg_auc=0.9432
Fold[3] Epoch: 71 [71/150 (47%)] Train loss=0.114982 Test loss=0.642211 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.10583938658237457
[5/24] Train loss=0.1300579458475113
[10/24] Train loss=0.11279220879077911
[15/24] Train loss=0.10524633526802063
[20/24] Train loss=0.0805976614356041
Test set avg_accuracy=89.61% avg_sensitivity=84.46%, avg_specificity=91.19% avg_auc=0.9445
Fold[3] Epoch: 72 [72/150 (48%)] Train loss=0.116521 Test loss=0.584628 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.09578511118888855
[5/24] Train loss=0.11748003214597702
[10/24] Train loss=0.09198891371488571
[15/24] Train loss=0.07611186057329178
[20/24] Train loss=0.08916781842708588
Test set avg_accuracy=87.89% avg_sensitivity=88.79%, avg_specificity=87.61% avg_auc=0.9464
Fold[3] Epoch: 73 [73/150 (49%)] Train loss=0.102316 Test loss=0.666842 Current lr=[0.000834102481048427]

[0/24] Train loss=0.09090320765972137
[5/24] Train loss=0.10957558453083038
[10/24] Train loss=0.08517579734325409
[15/24] Train loss=0.07956470549106598
[20/24] Train loss=0.07965212315320969
Test set avg_accuracy=89.11% avg_sensitivity=86.35%, avg_specificity=89.96% avg_auc=0.9461
Fold[3] Epoch: 74 [74/150 (49%)] Train loss=0.099750 Test loss=0.680878 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.06670235842466354
[5/24] Train loss=0.06696072220802307
[10/24] Train loss=0.08096253871917725
[15/24] Train loss=0.08855488151311874
[20/24] Train loss=0.07330682128667831
Test set avg_accuracy=88.79% avg_sensitivity=87.79%, avg_specificity=89.09% avg_auc=0.9473
Fold[3] Epoch: 75 [75/150 (50%)] Train loss=0.092033 Test loss=0.691947 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.10937686264514923
[5/24] Train loss=0.07272671908140182
[10/24] Train loss=0.09907114505767822
[15/24] Train loss=0.08258112519979477
[20/24] Train loss=0.09161627292633057
Test set avg_accuracy=88.01% avg_sensitivity=89.18%, avg_specificity=87.65% avg_auc=0.9434
Fold[3] Epoch: 76 [76/150 (51%)] Train loss=0.093935 Test loss=0.639430 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.10171066224575043
[5/24] Train loss=0.10510431975126266
[10/24] Train loss=0.07974060624837875
[15/24] Train loss=0.08410589396953583
[20/24] Train loss=0.06024031713604927
Test set avg_accuracy=88.40% avg_sensitivity=87.96%, avg_specificity=88.53% avg_auc=0.9445
Fold[3] Epoch: 77 [77/150 (51%)] Train loss=0.087839 Test loss=0.699921 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.09464099258184433
[5/24] Train loss=0.08211378008127213
[10/24] Train loss=0.09428076446056366
[15/24] Train loss=0.10295449197292328
[20/24] Train loss=0.07110415399074554
Test set avg_accuracy=87.88% avg_sensitivity=86.57%, avg_specificity=88.28% avg_auc=0.9439
Fold[3] Epoch: 78 [78/150 (52%)] Train loss=0.078143 Test loss=0.703748 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.07294772565364838
[5/24] Train loss=0.0703815445303917
[10/24] Train loss=0.06771475821733475
[15/24] Train loss=0.17962801456451416
[20/24] Train loss=0.07015044242143631
Test set avg_accuracy=85.96% avg_sensitivity=89.73%, avg_specificity=84.81% avg_auc=0.9415
Fold[3] Epoch: 79 [79/150 (53%)] Train loss=0.082404 Test loss=0.772608 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.08356810361146927
[5/24] Train loss=0.08648848533630371
[10/24] Train loss=0.07687855511903763
[15/24] Train loss=0.08273029327392578
[20/24] Train loss=0.06523245573043823
Test set avg_accuracy=88.10% avg_sensitivity=88.85%, avg_specificity=87.87% avg_auc=0.9431
Fold[3] Epoch: 80 [80/150 (53%)] Train loss=0.086247 Test loss=0.761323 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.08659269660711288
[5/24] Train loss=0.07857130467891693
[10/24] Train loss=0.08600672334432602
[15/24] Train loss=0.0880412831902504
[20/24] Train loss=0.06484439224004745
Test set avg_accuracy=87.34% avg_sensitivity=87.29%, avg_specificity=87.36% avg_auc=0.9392
Fold[3] Epoch: 81 [81/150 (54%)] Train loss=0.088880 Test loss=0.676854 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.07139624655246735
[5/24] Train loss=0.06776886433362961
[10/24] Train loss=0.0822281464934349
[15/24] Train loss=0.06039035692811012
[20/24] Train loss=0.06508922576904297
Test set avg_accuracy=88.45% avg_sensitivity=88.40%, avg_specificity=88.47% avg_auc=0.9452
Fold[3] Epoch: 82 [82/150 (55%)] Train loss=0.072519 Test loss=0.724478 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.05820220708847046
[5/24] Train loss=0.047116972506046295
[10/24] Train loss=0.05477270856499672
[15/24] Train loss=0.05203843489289284
[20/24] Train loss=0.10288811475038528
Test set avg_accuracy=85.38% avg_sensitivity=89.51%, avg_specificity=84.11% avg_auc=0.9411
Fold[3] Epoch: 83 [83/150 (55%)] Train loss=0.067046 Test loss=1.119830 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.06993871182203293
[5/24] Train loss=0.07919081300497055
[10/24] Train loss=0.08020976930856705
[15/24] Train loss=0.06301622837781906
[20/24] Train loss=0.07007341831922531
Test set avg_accuracy=88.10% avg_sensitivity=87.35%, avg_specificity=88.33% avg_auc=0.9449
Fold[3] Epoch: 84 [84/150 (56%)] Train loss=0.073078 Test loss=0.841570 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.045773811638355255
[5/24] Train loss=0.04755845293402672
[10/24] Train loss=0.0601360909640789
[15/24] Train loss=0.05005089193582535
[20/24] Train loss=0.0478653647005558
Test set avg_accuracy=87.32% avg_sensitivity=89.62%, avg_specificity=86.61% avg_auc=0.9468
Fold[3] Epoch: 85 [85/150 (57%)] Train loss=0.059797 Test loss=0.975985 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.06640592217445374
[5/24] Train loss=0.05124548450112343
[10/24] Train loss=0.061942294239997864
[15/24] Train loss=0.0594455823302269
[20/24] Train loss=0.056941766291856766
Test set avg_accuracy=86.94% avg_sensitivity=89.79%, avg_specificity=86.07% avg_auc=0.9463
Fold[3] Epoch: 86 [86/150 (57%)] Train loss=0.060381 Test loss=0.937346 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.0674847811460495
[5/24] Train loss=0.04697561636567116
[10/24] Train loss=0.07219503819942474
[15/24] Train loss=0.06828251481056213
[20/24] Train loss=0.05651696026325226
Test set avg_accuracy=87.90% avg_sensitivity=88.96%, avg_specificity=87.58% avg_auc=0.9452
Fold[3] Epoch: 87 [87/150 (58%)] Train loss=0.065872 Test loss=0.905106 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.08136528730392456
[5/24] Train loss=0.06990963965654373
[10/24] Train loss=0.07909287512302399
[15/24] Train loss=0.06535922735929489
[20/24] Train loss=0.05401172488927841
Test set avg_accuracy=88.79% avg_sensitivity=87.29%, avg_specificity=89.25% avg_auc=0.9456
Fold[3] Epoch: 88 [88/150 (59%)] Train loss=0.065864 Test loss=0.925801 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.06468634307384491
[5/24] Train loss=0.043773747980594635
[10/24] Train loss=0.08589484542608261
[15/24] Train loss=0.04443899542093277
[20/24] Train loss=0.04855971410870552
Test set avg_accuracy=88.09% avg_sensitivity=89.51%, avg_specificity=87.65% avg_auc=0.9455
Fold[3] Epoch: 89 [89/150 (59%)] Train loss=0.053232 Test loss=0.977237 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.06946185231208801
[5/24] Train loss=0.05575123429298401
[10/24] Train loss=0.047790538519620895
[15/24] Train loss=0.049370020627975464
[20/24] Train loss=0.047647520899772644
Test set avg_accuracy=88.57% avg_sensitivity=87.18%, avg_specificity=88.99% avg_auc=0.9483
Fold[3] Epoch: 90 [90/150 (60%)] Train loss=0.054276 Test loss=0.961571 Current lr=[0.00061065423442182]

[0/24] Train loss=0.050363678485155106
[5/24] Train loss=0.04479284584522247
[10/24] Train loss=0.04468638449907303
[15/24] Train loss=0.03769877180457115
[20/24] Train loss=0.03138731047511101
Test set avg_accuracy=88.57% avg_sensitivity=87.96%, avg_specificity=88.75% avg_auc=0.9471
Fold[3] Epoch: 91 [91/150 (61%)] Train loss=0.046941 Test loss=1.067767 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.0489502027630806
[5/24] Train loss=0.05230216681957245
[10/24] Train loss=0.04490701109170914
[15/24] Train loss=0.06237082928419113
[20/24] Train loss=0.04770670458674431
Test set avg_accuracy=86.67% avg_sensitivity=89.46%, avg_specificity=85.81% avg_auc=0.9445
Fold[3] Epoch: 92 [92/150 (61%)] Train loss=0.045646 Test loss=1.159255 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.05057575926184654
[5/24] Train loss=0.06823759526014328
[10/24] Train loss=0.055050771683454514
[15/24] Train loss=0.04798344895243645
[20/24] Train loss=0.05407143756747246
Test set avg_accuracy=88.02% avg_sensitivity=87.13%, avg_specificity=88.30% avg_auc=0.9462
Fold[3] Epoch: 93 [93/150 (62%)] Train loss=0.055240 Test loss=0.939499 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.0708555206656456
[5/24] Train loss=0.04806967079639435
[10/24] Train loss=0.036330077797174454
[15/24] Train loss=0.027824124321341515
[20/24] Train loss=0.04357173666357994
Test set avg_accuracy=88.58% avg_sensitivity=87.29%, avg_specificity=88.98% avg_auc=0.9475
Fold[3] Epoch: 94 [94/150 (63%)] Train loss=0.046812 Test loss=0.962507 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.043930403888225555
[5/24] Train loss=0.032332345843315125
[10/24] Train loss=0.04313979670405388
[15/24] Train loss=0.04705525562167168
[20/24] Train loss=0.0297604538500309
Test set avg_accuracy=88.19% avg_sensitivity=87.79%, avg_specificity=88.31% avg_auc=0.9440
Fold[3] Epoch: 95 [95/150 (63%)] Train loss=0.042665 Test loss=0.801057 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.07968982309103012
[5/24] Train loss=0.0401308611035347
[10/24] Train loss=0.06284597516059875
[15/24] Train loss=0.03568758815526962
[20/24] Train loss=0.03348488360643387
Test set avg_accuracy=88.03% avg_sensitivity=87.18%, avg_specificity=88.30% avg_auc=0.9462
Fold[3] Epoch: 96 [96/150 (64%)] Train loss=0.045483 Test loss=0.969499 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.03794853016734123
[5/24] Train loss=0.0514572411775589
[10/24] Train loss=0.035294145345687866
[15/24] Train loss=0.04500390216708183
[20/24] Train loss=0.0549214705824852
Test set avg_accuracy=86.05% avg_sensitivity=90.23%, avg_specificity=84.77% avg_auc=0.9440
Fold[3] Epoch: 97 [97/150 (65%)] Train loss=0.039013 Test loss=1.102719 Current lr=[0.000506858408304961]

[0/24] Train loss=0.04414882883429527
[5/24] Train loss=0.04550223425030708
[10/24] Train loss=0.03498582914471626
[15/24] Train loss=0.048154156655073166
[20/24] Train loss=0.03771814703941345
Test set avg_accuracy=87.40% avg_sensitivity=88.96%, avg_specificity=86.92% avg_auc=0.9441
Fold[3] Epoch: 98 [98/150 (65%)] Train loss=0.043202 Test loss=1.258977 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.05556101351976395
[5/24] Train loss=0.046020541340112686
[10/24] Train loss=0.04493824765086174
[15/24] Train loss=0.034846119582653046
[20/24] Train loss=0.03305754065513611
Test set avg_accuracy=88.49% avg_sensitivity=86.35%, avg_specificity=89.15% avg_auc=0.9447
Fold[3] Epoch: 99 [99/150 (66%)] Train loss=0.043940 Test loss=0.945206 Current lr=[0.000476946990416354]

[0/24] Train loss=0.030823029577732086
[5/24] Train loss=0.02868170291185379
[10/24] Train loss=0.037931229919195175
[15/24] Train loss=0.050018198788166046
[20/24] Train loss=0.02165471762418747
Test set avg_accuracy=88.36% avg_sensitivity=86.79%, avg_specificity=88.84% avg_auc=0.9454
Fold[3] Epoch: 100 [100/150 (67%)] Train loss=0.035082 Test loss=1.080835 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.03814258053898811
[5/24] Train loss=0.031533412635326385
[10/24] Train loss=0.029829304665327072
[15/24] Train loss=0.03782109543681145
[20/24] Train loss=0.03380059450864792
Test set avg_accuracy=86.91% avg_sensitivity=90.23%, avg_specificity=85.90% avg_auc=0.9444
Fold[3] Epoch: 101 [101/150 (67%)] Train loss=0.035743 Test loss=1.430135 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.04602568969130516
[5/24] Train loss=0.03628477454185486
[10/24] Train loss=0.035942502319812775
[15/24] Train loss=0.03661756590008736
[20/24] Train loss=0.028229644522070885
Test set avg_accuracy=87.81% avg_sensitivity=88.73%, avg_specificity=87.53% avg_auc=0.9443
Fold[3] Epoch: 102 [102/150 (68%)] Train loss=0.038453 Test loss=1.201419 Current lr=[0.000432267999769856]

[0/24] Train loss=0.05802643299102783
[5/24] Train loss=0.0447816401720047
[10/24] Train loss=0.04680774360895157
[15/24] Train loss=0.03928242623806
[20/24] Train loss=0.031318120658397675
Test set avg_accuracy=88.31% avg_sensitivity=86.79%, avg_specificity=88.77% avg_auc=0.9440
Fold[3] Epoch: 103 [103/150 (69%)] Train loss=0.045394 Test loss=1.147748 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.04313621670007706
[5/24] Train loss=0.03371887281537056
[10/24] Train loss=0.03588806837797165
[15/24] Train loss=0.03264259174466133
[20/24] Train loss=0.025896307080984116
Test set avg_accuracy=88.02% avg_sensitivity=87.46%, avg_specificity=88.19% avg_auc=0.9426
Fold[3] Epoch: 104 [104/150 (69%)] Train loss=0.035652 Test loss=1.006184 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.032395005226135254
[5/24] Train loss=0.03769379481673241
[10/24] Train loss=0.02910996973514557
[15/24] Train loss=0.02918616309762001
[20/24] Train loss=0.025076236575841904
Test set avg_accuracy=87.75% avg_sensitivity=87.68%, avg_specificity=87.77% avg_auc=0.9460
Fold[3] Epoch: 105 [105/150 (70%)] Train loss=0.030569 Test loss=1.227546 Current lr=[0.000388134363466264]

[0/24] Train loss=0.028665488585829735
[5/24] Train loss=0.03788889944553375
[10/24] Train loss=0.0478530190885067
[15/24] Train loss=0.026272468268871307
[20/24] Train loss=0.022125348448753357
Test set avg_accuracy=87.16% avg_sensitivity=89.79%, avg_specificity=86.36% avg_auc=0.9448
Fold[3] Epoch: 106 [106/150 (71%)] Train loss=0.031707 Test loss=1.530842 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.0349072627723217
[5/24] Train loss=0.03591529652476311
[10/24] Train loss=0.034202706068754196
[15/24] Train loss=0.043639469891786575
[20/24] Train loss=0.02807852439582348
Test set avg_accuracy=87.57% avg_sensitivity=88.68%, avg_specificity=87.22% avg_auc=0.9450
Fold[3] Epoch: 107 [107/150 (71%)] Train loss=0.032437 Test loss=1.170254 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.0363113209605217
[5/24] Train loss=0.03650400787591934
[10/24] Train loss=0.02929953671991825
[15/24] Train loss=0.039655350148677826
[20/24] Train loss=0.02385578863322735
Test set avg_accuracy=88.20% avg_sensitivity=88.29%, avg_specificity=88.18% avg_auc=0.9460
Fold[3] Epoch: 108 [108/150 (72%)] Train loss=0.034970 Test loss=1.046230 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.03996438533067703
[5/24] Train loss=0.03233630210161209
[10/24] Train loss=0.033394452184438705
[15/24] Train loss=0.03714454919099808
[20/24] Train loss=0.024577084928750992
Test set avg_accuracy=88.68% avg_sensitivity=87.18%, avg_specificity=89.15% avg_auc=0.9455
Fold[3] Epoch: 109 [109/150 (73%)] Train loss=0.037034 Test loss=0.971133 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.028592094779014587
[5/24] Train loss=0.032047104090452194
[10/24] Train loss=0.02284637838602066
[15/24] Train loss=0.023118695244193077
[20/24] Train loss=0.03043542429804802
Test set avg_accuracy=88.55% avg_sensitivity=87.35%, avg_specificity=88.92% avg_auc=0.9479
Fold[3] Epoch: 110 [110/150 (73%)] Train loss=0.027094 Test loss=1.134144 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.023789148777723312
[5/24] Train loss=0.02378377877175808
[10/24] Train loss=0.022768275812268257
[15/24] Train loss=0.021056562662124634
[20/24] Train loss=0.020991597324609756
Test set avg_accuracy=87.86% avg_sensitivity=88.57%, avg_specificity=87.65% avg_auc=0.9457
Fold[3] Epoch: 111 [111/150 (74%)] Train loss=0.028052 Test loss=1.144262 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.0298223327845335
[5/24] Train loss=0.035444967448711395
[10/24] Train loss=0.02500612661242485
[15/24] Train loss=0.027889488264918327
[20/24] Train loss=0.021529074758291245
Test set avg_accuracy=88.70% avg_sensitivity=86.46%, avg_specificity=89.38% avg_auc=0.9465
Fold[3] Epoch: 112 [112/150 (75%)] Train loss=0.028893 Test loss=0.892276 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.025732161477208138
[5/24] Train loss=0.022988449782133102
[10/24] Train loss=0.023241449147462845
[15/24] Train loss=0.022952988743782043
[20/24] Train loss=0.015467362478375435
Test set avg_accuracy=87.99% avg_sensitivity=88.73%, avg_specificity=87.77% avg_auc=0.9468
Fold[3] Epoch: 113 [113/150 (75%)] Train loss=0.025473 Test loss=1.361971 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.028023138642311096
[5/24] Train loss=0.02733076550066471
[10/24] Train loss=0.026562537997961044
[15/24] Train loss=0.02255832776427269
[20/24] Train loss=0.019270503893494606
Test set avg_accuracy=88.85% avg_sensitivity=87.01%, avg_specificity=89.42% avg_auc=0.9465
Fold[3] Epoch: 114 [114/150 (76%)] Train loss=0.025347 Test loss=1.091760 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.024085404351353645
[5/24] Train loss=0.021630635485053062
[10/24] Train loss=0.02248307317495346
[15/24] Train loss=0.016692854464054108
[20/24] Train loss=0.02349749207496643
Test set avg_accuracy=87.98% avg_sensitivity=88.90%, avg_specificity=87.70% avg_auc=0.9454
Fold[3] Epoch: 115 [115/150 (77%)] Train loss=0.022472 Test loss=1.205702 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.026544790714979172
[5/24] Train loss=0.028592778369784355
[10/24] Train loss=0.03289295360445976
[15/24] Train loss=0.01817222870886326
[20/24] Train loss=0.03923667594790459
Test set avg_accuracy=88.72% avg_sensitivity=87.13%, avg_specificity=89.21% avg_auc=0.9468
Fold[3] Epoch: 116 [116/150 (77%)] Train loss=0.026898 Test loss=1.118598 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.030531208962202072
[5/24] Train loss=0.029611146077513695
[10/24] Train loss=0.019583143293857574
[15/24] Train loss=0.017323145642876625
[20/24] Train loss=0.028461435809731483
Test set avg_accuracy=88.31% avg_sensitivity=88.40%, avg_specificity=88.28% avg_auc=0.9489
Fold[3] Epoch: 117 [117/150 (78%)] Train loss=0.022503 Test loss=1.345410 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.02610977552831173
[5/24] Train loss=0.02498345449566841
[10/24] Train loss=0.026916302740573883
[15/24] Train loss=0.022206708788871765
[20/24] Train loss=0.015596618875861168
Test set avg_accuracy=89.04% avg_sensitivity=88.07%, avg_specificity=89.33% avg_auc=0.9476
Fold[3] Epoch: 118 [118/150 (79%)] Train loss=0.025049 Test loss=1.102849 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.02332497574388981
[5/24] Train loss=0.01722262054681778
[10/24] Train loss=0.018737317994236946
[15/24] Train loss=0.017930755391716957
[20/24] Train loss=0.01388827059417963
Test set avg_accuracy=88.20% avg_sensitivity=88.62%, avg_specificity=88.07% avg_auc=0.9477
Fold[3] Epoch: 119 [119/150 (79%)] Train loss=0.022845 Test loss=1.063973 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.023562626913189888
[5/24] Train loss=0.025822829455137253
[10/24] Train loss=0.022875476628541946
[15/24] Train loss=0.024022525176405907
[20/24] Train loss=0.016450045630335808
Test set avg_accuracy=88.87% avg_sensitivity=86.96%, avg_specificity=89.45% avg_auc=0.9473
Fold[3] Epoch: 120 [120/150 (80%)] Train loss=0.022162 Test loss=1.092800 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.06078072637319565
[5/24] Train loss=0.017753323540091515
[10/24] Train loss=0.019309187307953835
[15/24] Train loss=0.015603086911141872
[20/24] Train loss=0.014813847839832306
Test set avg_accuracy=87.90% avg_sensitivity=88.24%, avg_specificity=87.80% avg_auc=0.9471
Fold[3] Epoch: 121 [121/150 (81%)] Train loss=0.023033 Test loss=1.177544 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.026087841019034386
[5/24] Train loss=0.02069816365838051
[10/24] Train loss=0.024446872994303703
[15/24] Train loss=0.022039098665118217
[20/24] Train loss=0.017017671838402748
Test set avg_accuracy=88.71% avg_sensitivity=86.07%, avg_specificity=89.52% avg_auc=0.9467
Fold[3] Epoch: 122 [122/150 (81%)] Train loss=0.024447 Test loss=1.052583 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.021971123293042183
[5/24] Train loss=0.01945875957608223
[10/24] Train loss=0.01690930500626564
[15/24] Train loss=0.019588861614465714
[20/24] Train loss=0.014016730710864067
Test set avg_accuracy=88.28% avg_sensitivity=86.24%, avg_specificity=88.91% avg_auc=0.9471
Fold[3] Epoch: 123 [123/150 (82%)] Train loss=0.020671 Test loss=1.175620 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.02096816524863243
[5/24] Train loss=0.023265905678272247
[10/24] Train loss=0.015731506049633026
[15/24] Train loss=0.022516751661896706
[20/24] Train loss=0.014602615498006344
Test set avg_accuracy=87.81% avg_sensitivity=87.40%, avg_specificity=87.94% avg_auc=0.9468
Fold[3] Epoch: 124 [124/150 (83%)] Train loss=0.018623 Test loss=1.315246 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.0423269160091877
[5/24] Train loss=0.03046564757823944
[10/24] Train loss=0.022150659933686256
[15/24] Train loss=0.02834094502031803
[20/24] Train loss=0.012131276540458202
Test set avg_accuracy=87.32% avg_sensitivity=88.18%, avg_specificity=87.05% avg_auc=0.9466
Fold[3] Epoch: 125 [125/150 (83%)] Train loss=0.018379 Test loss=1.371558 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.019669367000460625
[5/24] Train loss=0.025425903499126434
[10/24] Train loss=0.04481640085577965
[15/24] Train loss=0.016154710203409195
[20/24] Train loss=0.020639693364501
Test set avg_accuracy=87.21% avg_sensitivity=87.46%, avg_specificity=87.14% avg_auc=0.9462
Fold[3] Epoch: 126 [126/150 (84%)] Train loss=0.019844 Test loss=1.340676 Current lr=[0.000123057953306828]

[0/24] Train loss=0.017906030640006065
[5/24] Train loss=0.02383500151336193
[10/24] Train loss=0.02171589620411396
[15/24] Train loss=0.015679528936743736
[20/24] Train loss=0.0127619169652462
Test set avg_accuracy=87.71% avg_sensitivity=87.46%, avg_specificity=87.78% avg_auc=0.9466
Fold[3] Epoch: 127 [127/150 (85%)] Train loss=0.022048 Test loss=1.212906 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.017741847783327103
[5/24] Train loss=0.017197811976075172
[10/24] Train loss=0.019585581496357918
[15/24] Train loss=0.0148397758603096
[20/24] Train loss=0.012111789546906948
Test set avg_accuracy=88.06% avg_sensitivity=87.40%, avg_specificity=88.26% avg_auc=0.9472
Fold[3] Epoch: 128 [128/150 (85%)] Train loss=0.016518 Test loss=1.184851 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.020624181255698204
[5/24] Train loss=0.012466412968933582
[10/24] Train loss=0.014954148791730404
[15/24] Train loss=0.011563495732843876
[20/24] Train loss=0.014940631575882435
Test set avg_accuracy=87.80% avg_sensitivity=87.46%, avg_specificity=87.90% avg_auc=0.9475
Fold[3] Epoch: 129 [129/150 (86%)] Train loss=0.014832 Test loss=1.364248 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.015794528648257256
[5/24] Train loss=0.03659918159246445
[10/24] Train loss=0.04020608961582184
[15/24] Train loss=0.009964051656425
[20/24] Train loss=0.011440218426287174
Test set avg_accuracy=87.30% avg_sensitivity=89.23%, avg_specificity=86.71% avg_auc=0.9474
Fold[3] Epoch: 130 [130/150 (87%)] Train loss=0.017647 Test loss=1.529749 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.0161292627453804
[5/24] Train loss=0.0189918614923954
[10/24] Train loss=0.015238410793244839
[15/24] Train loss=0.012694978155195713
[20/24] Train loss=0.01168972346931696
Test set avg_accuracy=87.14% avg_sensitivity=88.90%, avg_specificity=86.59% avg_auc=0.9475
Fold[3] Epoch: 131 [131/150 (87%)] Train loss=0.016301 Test loss=1.477612 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.02163536101579666
[5/24] Train loss=0.018222516402602196
[10/24] Train loss=0.017770914360880852
[15/24] Train loss=0.014654523693025112
[20/24] Train loss=0.012492486275732517
Test set avg_accuracy=87.66% avg_sensitivity=88.01%, avg_specificity=87.55% avg_auc=0.9474
Fold[3] Epoch: 132 [132/150 (88%)] Train loss=0.017325 Test loss=1.352248 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.02047211118042469
[5/24] Train loss=0.020305506885051727
[10/24] Train loss=0.019271397963166237
[15/24] Train loss=0.01605047844350338
[20/24] Train loss=0.03366425633430481
Test set avg_accuracy=88.03% avg_sensitivity=87.07%, avg_specificity=88.33% avg_auc=0.9472
Fold[3] Epoch: 133 [133/150 (89%)] Train loss=0.019823 Test loss=1.258167 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.014041048474609852
[5/24] Train loss=0.015073413029313087
[10/24] Train loss=0.01416956726461649
[15/24] Train loss=0.015298023819923401
[20/24] Train loss=0.011624556966125965
Test set avg_accuracy=88.26% avg_sensitivity=86.96%, avg_specificity=88.65% avg_auc=0.9477
Fold[3] Epoch: 134 [134/150 (89%)] Train loss=0.015261 Test loss=1.228086 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.017244137823581696
[5/24] Train loss=0.02062331512570381
[10/24] Train loss=0.011072145774960518
[15/24] Train loss=0.014578867703676224
[20/24] Train loss=0.013157457113265991
Test set avg_accuracy=87.90% avg_sensitivity=87.24%, avg_specificity=88.11% avg_auc=0.9480
Fold[3] Epoch: 135 [135/150 (90%)] Train loss=0.015113 Test loss=1.280530 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.01231772918254137
[5/24] Train loss=0.01077180914580822
[10/24] Train loss=0.011107340455055237
[15/24] Train loss=0.019109409302473068
[20/24] Train loss=0.017461929470300674
Test set avg_accuracy=87.67% avg_sensitivity=88.35%, avg_specificity=87.46% avg_auc=0.9484
Fold[3] Epoch: 136 [136/150 (91%)] Train loss=0.012761 Test loss=1.378249 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.014278316870331764
[5/24] Train loss=0.013200422748923302
[10/24] Train loss=0.01146057527512312
[15/24] Train loss=0.014386176131665707
[20/24] Train loss=0.009943274781107903
Test set avg_accuracy=87.49% avg_sensitivity=88.46%, avg_specificity=87.19% avg_auc=0.9487
Fold[3] Epoch: 137 [137/150 (91%)] Train loss=0.013851 Test loss=1.416041 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.017176317051053047
[5/24] Train loss=0.0171009860932827
[10/24] Train loss=0.015649229288101196
[15/24] Train loss=0.013956847600638866
[20/24] Train loss=0.01429793331772089
Test set avg_accuracy=87.71% avg_sensitivity=88.46%, avg_specificity=87.48% avg_auc=0.9486
Fold[3] Epoch: 138 [138/150 (92%)] Train loss=0.018768 Test loss=1.395062 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.01852562464773655
[5/24] Train loss=0.01843065395951271
[10/24] Train loss=0.01756833866238594
[15/24] Train loss=0.016880862414836884
[20/24] Train loss=0.012854189611971378
Test set avg_accuracy=87.79% avg_sensitivity=87.85%, avg_specificity=87.77% avg_auc=0.9484
Fold[3] Epoch: 139 [139/150 (93%)] Train loss=0.017932 Test loss=1.340087 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.023632317781448364
[5/24] Train loss=0.024505004286766052
[10/24] Train loss=0.019576987251639366
[15/24] Train loss=0.020443642511963844
[20/24] Train loss=0.013588961213827133
Test set avg_accuracy=88.02% avg_sensitivity=87.01%, avg_specificity=88.33% avg_auc=0.9483
Fold[3] Epoch: 140 [140/150 (93%)] Train loss=0.019525 Test loss=1.263713 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.020632438361644745
[5/24] Train loss=0.018123019486665726
[10/24] Train loss=0.014300861395895481
[15/24] Train loss=0.018042350187897682
[20/24] Train loss=0.013491993770003319
Test set avg_accuracy=88.19% avg_sensitivity=86.74%, avg_specificity=88.64% avg_auc=0.9483
Fold[3] Epoch: 141 [141/150 (94%)] Train loss=0.015507 Test loss=1.228564 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.01469084806740284
[5/24] Train loss=0.012740644626319408
[10/24] Train loss=0.014261187054216862
[15/24] Train loss=0.014423901215195656
[20/24] Train loss=0.011435151100158691
Test set avg_accuracy=88.29% avg_sensitivity=86.57%, avg_specificity=88.82% avg_auc=0.9483
Fold[3] Epoch: 142 [142/150 (95%)] Train loss=0.014018 Test loss=1.202687 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.017406420782208443
[5/24] Train loss=0.014762847684323788
[10/24] Train loss=0.013169177807867527
[15/24] Train loss=0.016072958707809448
[20/24] Train loss=0.009955696761608124
Test set avg_accuracy=88.35% avg_sensitivity=86.68%, avg_specificity=88.86% avg_auc=0.9484
Fold[3] Epoch: 143 [143/150 (95%)] Train loss=0.013605 Test loss=1.228766 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.015829162672162056
[5/24] Train loss=0.011385664343833923
[10/24] Train loss=0.009590554051101208
[15/24] Train loss=0.009118677116930485
[20/24] Train loss=0.006650273222476244
Test set avg_accuracy=88.37% avg_sensitivity=86.79%, avg_specificity=88.86% avg_auc=0.9485
Fold[3] Epoch: 144 [144/150 (96%)] Train loss=0.011897 Test loss=1.245155 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.010767855681478977
[5/24] Train loss=0.018132181838154793
[10/24] Train loss=0.00975942425429821
[15/24] Train loss=0.014039749279618263
[20/24] Train loss=0.010856261476874352
Test set avg_accuracy=88.15% avg_sensitivity=86.90%, avg_specificity=88.53% avg_auc=0.9485
Fold[3] Epoch: 145 [145/150 (97%)] Train loss=0.014230 Test loss=1.275520 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.010864385403692722
[5/24] Train loss=0.00884953048080206
[10/24] Train loss=0.01017380878329277
[15/24] Train loss=0.006451212335377932
[20/24] Train loss=0.008333763107657433
Test set avg_accuracy=88.11% avg_sensitivity=87.01%, avg_specificity=88.45% avg_auc=0.9485
Fold[3] Epoch: 146 [146/150 (97%)] Train loss=0.012579 Test loss=1.303746 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.010543033480644226
[5/24] Train loss=0.007959204725921154
[10/24] Train loss=0.01339438371360302
[15/24] Train loss=0.017467543482780457
[20/24] Train loss=0.011232579126954079
Test set avg_accuracy=88.05% avg_sensitivity=87.01%, avg_specificity=88.36% avg_auc=0.9484
Fold[3] Epoch: 147 [147/150 (98%)] Train loss=0.017398 Test loss=1.330764 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.009596101939678192
[5/24] Train loss=0.04722714424133301
[10/24] Train loss=0.021192684769630432
[15/24] Train loss=0.009527292102575302
[20/24] Train loss=0.011558225378394127
Test set avg_accuracy=88.09% avg_sensitivity=87.01%, avg_specificity=88.41% avg_auc=0.9484
Fold[3] Epoch: 148 [148/150 (99%)] Train loss=0.013226 Test loss=1.345607 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.16095973551273346
[5/24] Train loss=0.010206125676631927
[10/24] Train loss=0.010315980762243271
[15/24] Train loss=0.031757503747940063
[20/24] Train loss=0.021976308897137642
Test set avg_accuracy=87.96% avg_sensitivity=87.01%, avg_specificity=88.24% avg_auc=0.9485
Fold[3] Epoch: 149 [149/150 (99%)] Train loss=0.023694 Test loss=1.335757 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.02906198985874653
[5/24] Train loss=0.012964515946805477
[10/24] Train loss=0.014030673541128635
[15/24] Train loss=0.008012632839381695
[20/24] Train loss=0.022662967443466187
Test set avg_accuracy=87.96% avg_sensitivity=87.01%, avg_specificity=88.24% avg_auc=0.9485
Fold[3] Epoch: 150 [150/150 (100%)] Train loss=0.030326 Test loss=1.346737 Current lr=[4.388541022775342e-09]

Fold[3] Result: acc=88.78% sen=89.57%, spe=88.53%, auc=0.95!
Fold[3] Avg_overlap=0.66%(0.23089596317368333)
[0/24] Train loss=1.404500961303711
[5/24] Train loss=1.3310039043426514
[10/24] Train loss=1.323660969734192
[15/24] Train loss=1.1797722578048706
[20/24] Train loss=1.1020843982696533
Test set avg_accuracy=75.52% avg_sensitivity=8.90%, avg_specificity=97.07% avg_auc=0.6950
Best model saved!! Metric=0.6949650627130475!!
Fold[4] Epoch: 1 [1/150 (1%)] Train loss=1.265811 Test loss=0.592220 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=1.118648886680603
[5/24] Train loss=0.9212602376937866
[10/24] Train loss=1.0668385028839111
[15/24] Train loss=0.9443825483322144
[20/24] Train loss=0.8538717031478882
Test set avg_accuracy=79.53% avg_sensitivity=70.91%, avg_specificity=82.32% avg_auc=0.8394
Best model saved!! Metric=0.8393504048895034!!
Fold[4] Epoch: 2 [2/150 (1%)] Train loss=0.996286 Test loss=0.511694 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.8505955338478088
[5/24] Train loss=0.7771368622779846
[10/24] Train loss=0.9056411385536194
[15/24] Train loss=0.856805682182312
[20/24] Train loss=0.7629923820495605
Test set avg_accuracy=80.53% avg_sensitivity=75.76%, avg_specificity=82.08% avg_auc=0.8591
Best model saved!! Metric=0.859061334633832!!
Fold[4] Epoch: 3 [3/150 (2%)] Train loss=0.867968 Test loss=0.525866 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.7444089651107788
[5/24] Train loss=0.6845890879631042
[10/24] Train loss=0.8238055109977722
[15/24] Train loss=0.7584285140037537
[20/24] Train loss=0.7529774308204651
Test set avg_accuracy=81.24% avg_sensitivity=87.91%, avg_specificity=79.08% avg_auc=0.8817
Best model saved!! Metric=0.8816956324191068!!
Fold[4] Epoch: 4 [4/150 (3%)] Train loss=0.790955 Test loss=0.599898 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.7831076979637146
[5/24] Train loss=0.7283901572227478
[10/24] Train loss=0.8349995017051697
[15/24] Train loss=0.7450599670410156
[20/24] Train loss=0.7180033326148987
Test set avg_accuracy=84.56% avg_sensitivity=84.07%, avg_specificity=84.71% avg_auc=0.9067
Best model saved!! Metric=0.9066980860027666!!
Fold[4] Epoch: 5 [5/150 (3%)] Train loss=0.791962 Test loss=0.455212 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.702592670917511
[5/24] Train loss=0.6400263905525208
[10/24] Train loss=0.8078232407569885
[15/24] Train loss=0.7239407896995544
[20/24] Train loss=0.6487488150596619
Test set avg_accuracy=78.74% avg_sensitivity=92.75%, avg_specificity=74.20% avg_auc=0.9167
Best model saved!! Metric=0.9167245443105275!!
Fold[4] Epoch: 6 [6/150 (4%)] Train loss=0.725950 Test loss=0.633921 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.7563530206680298
[5/24] Train loss=0.6676471829414368
[10/24] Train loss=0.7749667167663574
[15/24] Train loss=0.7257966995239258
[20/24] Train loss=0.6409773826599121
Test set avg_accuracy=84.79% avg_sensitivity=87.05%, avg_specificity=84.06% avg_auc=0.9233
Best model saved!! Metric=0.9233350816742686!!
Fold[4] Epoch: 7 [7/150 (5%)] Train loss=0.737932 Test loss=0.432993 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.6853963136672974
[5/24] Train loss=0.6372688412666321
[10/24] Train loss=0.8006255030632019
[15/24] Train loss=0.7100544571876526
[20/24] Train loss=0.6573846340179443
Test set avg_accuracy=83.68% avg_sensitivity=90.04%, avg_specificity=81.63% avg_auc=0.9331
Best model saved!! Metric=0.9330570110016946!!
Fold[4] Epoch: 8 [8/150 (5%)] Train loss=0.716034 Test loss=0.442611 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.7124876976013184
[5/24] Train loss=0.6224094033241272
[10/24] Train loss=0.7746596336364746
[15/24] Train loss=0.6958634853363037
[20/24] Train loss=0.641853392124176
Test set avg_accuracy=85.81% avg_sensitivity=89.18%, avg_specificity=84.71% avg_auc=0.9361
Best model saved!! Metric=0.9361392078445637!!
Fold[4] Epoch: 9 [9/150 (6%)] Train loss=0.710035 Test loss=0.384822 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.7328196167945862
[5/24] Train loss=0.6056901216506958
[10/24] Train loss=0.7419728636741638
[15/24] Train loss=0.6646519303321838
[20/24] Train loss=0.6376235485076904
Test set avg_accuracy=88.32% avg_sensitivity=84.92%, avg_specificity=89.42% avg_auc=0.9381
Best model saved!! Metric=0.9380953268435088!!
Fold[4] Epoch: 10 [10/150 (7%)] Train loss=0.700006 Test loss=0.299280 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.6668417453765869
[5/24] Train loss=0.5759117007255554
[10/24] Train loss=0.79405277967453
[15/24] Train loss=0.6680028438568115
[20/24] Train loss=0.5813260674476624
Test set avg_accuracy=87.32% avg_sensitivity=88.28%, avg_specificity=87.01% avg_auc=0.9368
Fold[4] Epoch: 11 [11/150 (7%)] Train loss=0.676751 Test loss=0.344664 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.678753674030304
[5/24] Train loss=0.5822905898094177
[10/24] Train loss=0.7360472083091736
[15/24] Train loss=0.6254008412361145
[20/24] Train loss=0.6018678545951843
Test set avg_accuracy=86.76% avg_sensitivity=87.80%, avg_specificity=86.42% avg_auc=0.9359
Fold[4] Epoch: 12 [12/150 (8%)] Train loss=0.667886 Test loss=0.345161 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6864515542984009
[5/24] Train loss=0.6185732483863831
[10/24] Train loss=0.7374523282051086
[15/24] Train loss=0.6326889395713806
[20/24] Train loss=0.5629271268844604
Test set avg_accuracy=89.80% avg_sensitivity=83.70%, avg_specificity=91.78% avg_auc=0.9440
Best model saved!! Metric=0.9439520700580074!!
Fold[4] Epoch: 13 [13/150 (9%)] Train loss=0.663602 Test loss=0.273861 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.6237778067588806
[5/24] Train loss=0.5616886615753174
[10/24] Train loss=0.7641961574554443
[15/24] Train loss=0.6261557340621948
[20/24] Train loss=0.5433862805366516
Test set avg_accuracy=90.26% avg_sensitivity=83.43%, avg_specificity=92.47% avg_auc=0.9431
Fold[4] Epoch: 14 [14/150 (9%)] Train loss=0.640439 Test loss=0.271077 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.6044098138809204
[5/24] Train loss=0.5422448515892029
[10/24] Train loss=0.7641345262527466
[15/24] Train loss=0.6442312002182007
[20/24] Train loss=0.5539354085922241
Test set avg_accuracy=89.44% avg_sensitivity=86.09%, avg_specificity=90.52% avg_auc=0.9464
Best model saved!! Metric=0.9463659006130148!!
Fold[4] Epoch: 15 [15/150 (10%)] Train loss=0.629996 Test loss=0.289943 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.6068701148033142
[5/24] Train loss=0.5491138696670532
[10/24] Train loss=0.7604418992996216
[15/24] Train loss=0.6522858738899231
[20/24] Train loss=0.511971652507782
Test set avg_accuracy=88.65% avg_sensitivity=88.07%, avg_specificity=88.83% avg_auc=0.9503
Best model saved!! Metric=0.9502625311563812!!
Fold[4] Epoch: 16 [16/150 (11%)] Train loss=0.623021 Test loss=0.305683 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.5729423761367798
[5/24] Train loss=0.5317510962486267
[10/24] Train loss=0.735300600528717
[15/24] Train loss=0.6029539704322815
[20/24] Train loss=0.4986002445220947
Test set avg_accuracy=85.01% avg_sensitivity=91.21%, avg_specificity=83.01% avg_auc=0.9501
Fold[4] Epoch: 17 [17/150 (11%)] Train loss=0.596002 Test loss=0.387647 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.5853209495544434
[5/24] Train loss=0.5292761921882629
[10/24] Train loss=0.727223813533783
[15/24] Train loss=0.6645073294639587
[20/24] Train loss=0.507039487361908
Test set avg_accuracy=87.53% avg_sensitivity=88.87%, avg_specificity=87.09% avg_auc=0.9519
Best model saved!! Metric=0.9519115046311449!!
Fold[4] Epoch: 18 [18/150 (12%)] Train loss=0.602182 Test loss=0.311691 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.5688390731811523
[5/24] Train loss=0.5349010825157166
[10/24] Train loss=0.7085944414138794
[15/24] Train loss=0.5849711298942566
[20/24] Train loss=0.49361535906791687
Test set avg_accuracy=90.20% avg_sensitivity=83.32%, avg_specificity=92.42% avg_auc=0.9506
Fold[4] Epoch: 19 [19/150 (13%)] Train loss=0.598185 Test loss=0.262691 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.6138588190078735
[5/24] Train loss=0.5298209190368652
[10/24] Train loss=0.7448574900627136
[15/24] Train loss=0.5755378603935242
[20/24] Train loss=0.45969095826148987
Test set avg_accuracy=86.84% avg_sensitivity=89.93%, avg_specificity=85.83% avg_auc=0.9537
Best model saved!! Metric=0.953664497199885!!
Fold[4] Epoch: 20 [20/150 (13%)] Train loss=0.589575 Test loss=0.326011 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.5863274931907654
[5/24] Train loss=0.5074582695960999
[10/24] Train loss=0.7193843722343445
[15/24] Train loss=0.5872098207473755
[20/24] Train loss=0.47259408235549927
Test set avg_accuracy=88.97% avg_sensitivity=87.00%, avg_specificity=89.61% avg_auc=0.9530
Fold[4] Epoch: 21 [21/150 (14%)] Train loss=0.587989 Test loss=0.282375 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.550214409828186
[5/24] Train loss=0.48093482851982117
[10/24] Train loss=0.6879234910011292
[15/24] Train loss=0.5625565052032471
[20/24] Train loss=0.5030486583709717
Test set avg_accuracy=87.64% avg_sensitivity=90.46%, avg_specificity=86.73% avg_auc=0.9583
Best model saved!! Metric=0.958307898537958!!
Fold[4] Epoch: 22 [22/150 (15%)] Train loss=0.563305 Test loss=0.304367 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.5652139782905579
[5/24] Train loss=0.49575865268707275
[10/24] Train loss=0.7046224474906921
[15/24] Train loss=0.5654413104057312
[20/24] Train loss=0.48123908042907715
Test set avg_accuracy=88.70% avg_sensitivity=86.15%, avg_specificity=89.52% avg_auc=0.9539
Fold[4] Epoch: 23 [23/150 (15%)] Train loss=0.576435 Test loss=0.270032 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5590239763259888
[5/24] Train loss=0.48880916833877563
[10/24] Train loss=0.711283802986145
[15/24] Train loss=0.5753807425498962
[20/24] Train loss=0.45827093720436096
Test set avg_accuracy=86.08% avg_sensitivity=91.16%, avg_specificity=84.44% avg_auc=0.9533
Fold[4] Epoch: 24 [24/150 (16%)] Train loss=0.559523 Test loss=0.348148 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.5990473031997681
[5/24] Train loss=0.49194344878196716
[10/24] Train loss=0.6843030452728271
[15/24] Train loss=0.553044855594635
[20/24] Train loss=0.4516567289829254
Test set avg_accuracy=90.22% avg_sensitivity=85.72%, avg_specificity=91.68% avg_auc=0.9572
Fold[4] Epoch: 25 [25/150 (17%)] Train loss=0.564440 Test loss=0.242589 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5607997179031372
[5/24] Train loss=0.4981568455696106
[10/24] Train loss=0.6103910803794861
[15/24] Train loss=0.5887064933776855
[20/24] Train loss=0.48428475856781006
Test set avg_accuracy=88.72% avg_sensitivity=89.93%, avg_specificity=88.33% avg_auc=0.9573
Fold[4] Epoch: 26 [26/150 (17%)] Train loss=0.559741 Test loss=0.313618 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5865241289138794
[5/24] Train loss=0.5156731605529785
[10/24] Train loss=0.6477777361869812
[15/24] Train loss=0.5158010721206665
[20/24] Train loss=0.4426140785217285
Test set avg_accuracy=89.34% avg_sensitivity=87.91%, avg_specificity=89.80% avg_auc=0.9557
Fold[4] Epoch: 27 [27/150 (18%)] Train loss=0.557623 Test loss=0.266746 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5451712608337402
[5/24] Train loss=0.45900893211364746
[10/24] Train loss=0.6177414655685425
[15/24] Train loss=0.5215930342674255
[20/24] Train loss=0.5221853256225586
Test set avg_accuracy=88.52% avg_sensitivity=89.18%, avg_specificity=88.30% avg_auc=0.9557
Fold[4] Epoch: 28 [28/150 (19%)] Train loss=0.527290 Test loss=0.292475 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5389902591705322
[5/24] Train loss=0.474852591753006
[10/24] Train loss=0.638547420501709
[15/24] Train loss=0.5693902373313904
[20/24] Train loss=0.421287477016449
Test set avg_accuracy=90.72% avg_sensitivity=86.15%, avg_specificity=92.19% avg_auc=0.9553
Fold[4] Epoch: 29 [29/150 (19%)] Train loss=0.528027 Test loss=0.255262 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.5134855508804321
[5/24] Train loss=0.43506765365600586
[10/24] Train loss=0.5988727807998657
[15/24] Train loss=0.49172937870025635
[20/24] Train loss=0.41608476638793945
Test set avg_accuracy=89.47% avg_sensitivity=87.53%, avg_specificity=90.09% avg_auc=0.9551
Fold[4] Epoch: 30 [30/150 (20%)] Train loss=0.506250 Test loss=0.287377 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.49079370498657227
[5/24] Train loss=0.44061148166656494
[10/24] Train loss=0.5462616086006165
[15/24] Train loss=0.49784111976623535
[20/24] Train loss=0.3897598087787628
Test set avg_accuracy=87.81% avg_sensitivity=89.61%, avg_specificity=87.23% avg_auc=0.9551
Fold[4] Epoch: 31 [31/150 (21%)] Train loss=0.486189 Test loss=0.316552 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.47143056988716125
[5/24] Train loss=0.42949092388153076
[10/24] Train loss=0.625837504863739
[15/24] Train loss=0.47809699177742004
[20/24] Train loss=0.3943481147289276
Test set avg_accuracy=90.46% avg_sensitivity=81.78%, avg_specificity=93.26% avg_auc=0.9533
Fold[4] Epoch: 32 [32/150 (21%)] Train loss=0.495676 Test loss=0.260556 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.4954468607902527
[5/24] Train loss=0.425641268491745
[10/24] Train loss=0.5109649300575256
[15/24] Train loss=0.4770975410938263
[20/24] Train loss=0.3811478912830353
Test set avg_accuracy=88.75% avg_sensitivity=88.76%, avg_specificity=88.75% avg_auc=0.9564
Fold[4] Epoch: 33 [33/150 (22%)] Train loss=0.473065 Test loss=0.312406 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.47620880603790283
[5/24] Train loss=0.4149565100669861
[10/24] Train loss=0.5762248039245605
[15/24] Train loss=0.4482648968696594
[20/24] Train loss=0.3999406695365906
Test set avg_accuracy=87.59% avg_sensitivity=88.39%, avg_specificity=87.33% avg_auc=0.9551
Fold[4] Epoch: 34 [34/150 (23%)] Train loss=0.469439 Test loss=0.309564 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.489013671875
[5/24] Train loss=0.4170604944229126
[10/24] Train loss=0.5762896537780762
[15/24] Train loss=0.41477546095848083
[20/24] Train loss=0.38591820001602173
Test set avg_accuracy=90.42% avg_sensitivity=81.94%, avg_specificity=93.16% avg_auc=0.9543
Fold[4] Epoch: 35 [35/150 (23%)] Train loss=0.475826 Test loss=0.251017 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.45388731360435486
[5/24] Train loss=0.40969032049179077
[10/24] Train loss=0.5233390927314758
[15/24] Train loss=0.4105662703514099
[20/24] Train loss=0.3427201509475708
Test set avg_accuracy=87.99% avg_sensitivity=89.18%, avg_specificity=87.61% avg_auc=0.9561
Fold[4] Epoch: 36 [36/150 (24%)] Train loss=0.436586 Test loss=0.319037 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.47629377245903015
[5/24] Train loss=0.44024303555488586
[10/24] Train loss=0.5065286159515381
[15/24] Train loss=0.3968031108379364
[20/24] Train loss=0.3844144344329834
Test set avg_accuracy=90.82% avg_sensitivity=87.11%, avg_specificity=92.02% avg_auc=0.9588
Best model saved!! Metric=0.9587920050538774!!
Fold[4] Epoch: 37 [37/150 (25%)] Train loss=0.450826 Test loss=0.267263 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.42821601033210754
[5/24] Train loss=0.39012911915779114
[10/24] Train loss=0.49792948365211487
[15/24] Train loss=0.4078849256038666
[20/24] Train loss=0.36118289828300476
Test set avg_accuracy=90.31% avg_sensitivity=85.99%, avg_specificity=91.71% avg_auc=0.9595
Best model saved!! Metric=0.9595224339256117!!
Fold[4] Epoch: 38 [38/150 (25%)] Train loss=0.426143 Test loss=0.256062 Current lr=[0.000944367614404117]

[0/24] Train loss=0.44045400619506836
[5/24] Train loss=0.33618083596229553
[10/24] Train loss=0.47496065497398376
[15/24] Train loss=0.38450080156326294
[20/24] Train loss=0.3423203229904175
Test set avg_accuracy=87.06% avg_sensitivity=90.89%, avg_specificity=85.82% avg_auc=0.9552
Fold[4] Epoch: 39 [39/150 (26%)] Train loss=0.418659 Test loss=0.336093 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.41226503252983093
[5/24] Train loss=0.43334922194480896
[10/24] Train loss=0.5112056732177734
[15/24] Train loss=0.373378723859787
[20/24] Train loss=0.3235175311565399
Test set avg_accuracy=90.57% avg_sensitivity=83.64%, avg_specificity=92.81% avg_auc=0.9544
Fold[4] Epoch: 40 [40/150 (27%)] Train loss=0.429901 Test loss=0.270019 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.3743234872817993
[5/24] Train loss=0.3318767547607422
[10/24] Train loss=0.4249694347381592
[15/24] Train loss=0.3405453562736511
[20/24] Train loss=0.34402182698249817
Test set avg_accuracy=89.10% avg_sensitivity=87.80%, avg_specificity=89.52% avg_auc=0.9531
Fold[4] Epoch: 41 [41/150 (27%)] Train loss=0.390328 Test loss=0.304082 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.40564316511154175
[5/24] Train loss=0.33862313628196716
[10/24] Train loss=0.41814354062080383
[15/24] Train loss=0.3450774550437927
[20/24] Train loss=0.31002360582351685
Test set avg_accuracy=88.58% avg_sensitivity=88.55%, avg_specificity=88.59% avg_auc=0.9535
Fold[4] Epoch: 42 [42/150 (28%)] Train loss=0.372876 Test loss=0.343435 Current lr=[0.000989780311725182]

[0/24] Train loss=0.3410501778125763
[5/24] Train loss=0.30711135268211365
[10/24] Train loss=0.3895571529865265
[15/24] Train loss=0.2969991862773895
[20/24] Train loss=0.25843939185142517
Test set avg_accuracy=83.96% avg_sensitivity=93.23%, avg_specificity=80.96% avg_auc=0.9523
Fold[4] Epoch: 43 [43/150 (29%)] Train loss=0.330510 Test loss=0.463941 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.3449332118034363
[5/24] Train loss=0.31977832317352295
[10/24] Train loss=0.4028279483318329
[15/24] Train loss=0.37024182081222534
[20/24] Train loss=0.27652308344841003
Test set avg_accuracy=85.48% avg_sensitivity=92.54%, avg_specificity=83.20% avg_auc=0.9538
Fold[4] Epoch: 44 [44/150 (29%)] Train loss=0.344711 Test loss=0.419685 Current lr=[0.000998924125869967]

[0/24] Train loss=0.37708964943885803
[5/24] Train loss=0.34241968393325806
[10/24] Train loss=0.32456597685813904
[15/24] Train loss=0.290749192237854
[20/24] Train loss=0.2901090681552887
Test set avg_accuracy=88.59% avg_sensitivity=89.77%, avg_specificity=88.21% avg_auc=0.9571
Fold[4] Epoch: 45 [45/150 (30%)] Train loss=0.338724 Test loss=0.371034 Current lr=[0.000999999611458977]

[0/24] Train loss=0.3671862781047821
[5/24] Train loss=0.2863865792751312
[10/24] Train loss=0.3667484223842621
[15/24] Train loss=0.3091227412223816
[20/24] Train loss=0.2395932376384735
Test set avg_accuracy=88.66% avg_sensitivity=89.98%, avg_specificity=88.23% avg_auc=0.9583
Fold[4] Epoch: 46 [46/150 (31%)] Train loss=0.329246 Test loss=0.344700 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.3487231731414795
[5/24] Train loss=0.27237844467163086
[10/24] Train loss=0.3297650218009949
[15/24] Train loss=0.24372845888137817
[20/24] Train loss=0.25499793887138367
Test set avg_accuracy=90.29% avg_sensitivity=86.63%, avg_specificity=91.47% avg_auc=0.9562
Fold[4] Epoch: 47 [47/150 (31%)] Train loss=0.316608 Test loss=0.283947 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.3414077162742615
[5/24] Train loss=0.27795305848121643
[10/24] Train loss=0.2954782247543335
[15/24] Train loss=0.29484355449676514
[20/24] Train loss=0.21266569197177887
Test set avg_accuracy=89.22% avg_sensitivity=86.68%, avg_specificity=90.04% avg_auc=0.9525
Fold[4] Epoch: 48 [48/150 (32%)] Train loss=0.283440 Test loss=0.345132 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.25683385133743286
[5/24] Train loss=0.2142990529537201
[10/24] Train loss=0.2508260905742645
[15/24] Train loss=0.22714097797870636
[20/24] Train loss=0.21364614367485046
Test set avg_accuracy=88.29% avg_sensitivity=88.87%, avg_specificity=88.11% avg_auc=0.9516
Fold[4] Epoch: 49 [49/150 (33%)] Train loss=0.267065 Test loss=0.325387 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.30109772086143494
[5/24] Train loss=0.2177741825580597
[10/24] Train loss=0.2907818853855133
[15/24] Train loss=0.23872293531894684
[20/24] Train loss=0.28209903836250305
Test set avg_accuracy=87.36% avg_sensitivity=87.59%, avg_specificity=87.28% avg_auc=0.9492
Fold[4] Epoch: 50 [50/150 (33%)] Train loss=0.278002 Test loss=0.398629 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.2842889428138733
[5/24] Train loss=0.26711931824684143
[10/24] Train loss=0.2825140058994293
[15/24] Train loss=0.2472335398197174
[20/24] Train loss=0.2141840159893036
Test set avg_accuracy=89.65% avg_sensitivity=81.41%, avg_specificity=92.31% avg_auc=0.9479
Fold[4] Epoch: 51 [51/150 (34%)] Train loss=0.271310 Test loss=0.344553 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.25803375244140625
[5/24] Train loss=0.1972293257713318
[10/24] Train loss=0.2692715525627136
[15/24] Train loss=0.19466345012187958
[20/24] Train loss=0.21206700801849365
Test set avg_accuracy=88.48% avg_sensitivity=89.50%, avg_specificity=88.14% avg_auc=0.9531
Fold[4] Epoch: 52 [52/150 (35%)] Train loss=0.241414 Test loss=0.416193 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.2963384985923767
[5/24] Train loss=0.2057727575302124
[10/24] Train loss=0.2958763837814331
[15/24] Train loss=0.17687737941741943
[20/24] Train loss=0.17822374403476715
Test set avg_accuracy=89.77% avg_sensitivity=85.30%, avg_specificity=91.21% avg_auc=0.9509
Fold[4] Epoch: 53 [53/150 (35%)] Train loss=0.250570 Test loss=0.324894 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.24080203473567963
[5/24] Train loss=0.17760968208312988
[10/24] Train loss=0.2961314618587494
[15/24] Train loss=0.23529329895973206
[20/24] Train loss=0.19327011704444885
Test set avg_accuracy=90.39% avg_sensitivity=85.40%, avg_specificity=92.00% avg_auc=0.9544
Fold[4] Epoch: 54 [54/150 (36%)] Train loss=0.226787 Test loss=0.334087 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.22569774091243744
[5/24] Train loss=0.17125892639160156
[10/24] Train loss=0.2753594219684601
[15/24] Train loss=0.20870482921600342
[20/24] Train loss=0.19855503737926483
Test set avg_accuracy=88.96% avg_sensitivity=80.02%, avg_specificity=91.85% avg_auc=0.9423
Fold[4] Epoch: 55 [55/150 (37%)] Train loss=0.235470 Test loss=0.345194 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.25883013010025024
[5/24] Train loss=0.16460692882537842
[10/24] Train loss=0.22828064858913422
[15/24] Train loss=0.17968937754631042
[20/24] Train loss=0.1561281532049179
Test set avg_accuracy=89.69% avg_sensitivity=80.18%, avg_specificity=92.76% avg_auc=0.9442
Fold[4] Epoch: 56 [56/150 (37%)] Train loss=0.210651 Test loss=0.371908 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.26949700713157654
[5/24] Train loss=0.13950780034065247
[10/24] Train loss=0.2218690663576126
[15/24] Train loss=0.17117534577846527
[20/24] Train loss=0.171602264046669
Test set avg_accuracy=88.93% avg_sensitivity=87.32%, avg_specificity=89.45% avg_auc=0.9499
Fold[4] Epoch: 57 [57/150 (38%)] Train loss=0.187372 Test loss=0.453225 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.18225397169589996
[5/24] Train loss=0.14401525259017944
[10/24] Train loss=0.2184356451034546
[15/24] Train loss=0.1344156116247177
[20/24] Train loss=0.139107346534729
Test set avg_accuracy=86.69% avg_sensitivity=92.59%, avg_specificity=84.78% avg_auc=0.9507
Fold[4] Epoch: 58 [58/150 (39%)] Train loss=0.171367 Test loss=0.670929 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.20579679310321808
[5/24] Train loss=0.14973865449428558
[10/24] Train loss=0.20166568458080292
[15/24] Train loss=0.1360742300748825
[20/24] Train loss=0.12905168533325195
Test set avg_accuracy=87.93% avg_sensitivity=88.17%, avg_specificity=87.85% avg_auc=0.9502
Fold[4] Epoch: 59 [59/150 (39%)] Train loss=0.169310 Test loss=0.630979 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.17901131510734558
[5/24] Train loss=0.17913848161697388
[10/24] Train loss=0.19965481758117676
[15/24] Train loss=0.14355866611003876
[20/24] Train loss=0.13428917527198792
Test set avg_accuracy=89.17% avg_sensitivity=85.08%, avg_specificity=90.49% avg_auc=0.9528
Fold[4] Epoch: 60 [60/150 (40%)] Train loss=0.171716 Test loss=0.486064 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.17641299962997437
[5/24] Train loss=0.12753137946128845
[10/24] Train loss=0.15309064090251923
[15/24] Train loss=0.12039483338594437
[20/24] Train loss=0.10347874462604523
Test set avg_accuracy=88.98% avg_sensitivity=84.66%, avg_specificity=90.38% avg_auc=0.9503
Fold[4] Epoch: 61 [61/150 (41%)] Train loss=0.140428 Test loss=0.504030 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.13785851001739502
[5/24] Train loss=0.13817791640758514
[10/24] Train loss=0.13254252076148987
[15/24] Train loss=0.1159777045249939
[20/24] Train loss=0.11560077965259552
Test set avg_accuracy=89.43% avg_sensitivity=85.08%, avg_specificity=90.83% avg_auc=0.9510
Fold[4] Epoch: 62 [62/150 (41%)] Train loss=0.135160 Test loss=0.489403 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.12849776446819305
[5/24] Train loss=0.08220382779836655
[10/24] Train loss=0.14793281257152557
[15/24] Train loss=0.11763247102499008
[20/24] Train loss=0.09725566953420639
Test set avg_accuracy=87.99% avg_sensitivity=89.98%, avg_specificity=87.35% avg_auc=0.9502
Fold[4] Epoch: 63 [63/150 (42%)] Train loss=0.123551 Test loss=0.580512 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.14210493862628937
[5/24] Train loss=0.10731112957000732
[10/24] Train loss=0.11987684667110443
[15/24] Train loss=0.1070081889629364
[20/24] Train loss=0.0929969996213913
Test set avg_accuracy=87.73% avg_sensitivity=89.66%, avg_specificity=87.11% avg_auc=0.9492
Fold[4] Epoch: 64 [64/150 (43%)] Train loss=0.121635 Test loss=0.647100 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.14237499237060547
[5/24] Train loss=0.11242848634719849
[10/24] Train loss=0.1452704817056656
[15/24] Train loss=0.129241943359375
[20/24] Train loss=0.10843592137098312
Test set avg_accuracy=89.58% avg_sensitivity=84.50%, avg_specificity=91.23% avg_auc=0.9510
Fold[4] Epoch: 65 [65/150 (43%)] Train loss=0.137285 Test loss=0.514236 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.13627690076828003
[5/24] Train loss=0.13885003328323364
[10/24] Train loss=0.13572296500205994
[15/24] Train loss=0.1256646364927292
[20/24] Train loss=0.09133854508399963
Test set avg_accuracy=87.81% avg_sensitivity=88.97%, avg_specificity=87.44% avg_auc=0.9473
Fold[4] Epoch: 66 [66/150 (44%)] Train loss=0.132835 Test loss=0.528749 Current lr=[0.000904142181093812]

[0/24] Train loss=0.13048194348812103
[5/24] Train loss=0.1471598893404007
[10/24] Train loss=0.12152695655822754
[15/24] Train loss=0.10567539930343628
[20/24] Train loss=0.0976787731051445
Test set avg_accuracy=89.74% avg_sensitivity=81.09%, avg_specificity=92.54% avg_auc=0.9478
Fold[4] Epoch: 67 [67/150 (45%)] Train loss=0.132645 Test loss=0.430162 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.11806181818246841
[5/24] Train loss=0.11817099899053574
[10/24] Train loss=0.15782061219215393
[15/24] Train loss=0.0980711355805397
[20/24] Train loss=0.0882965475320816
Test set avg_accuracy=89.54% avg_sensitivity=84.28%, avg_specificity=91.25% avg_auc=0.9486
Fold[4] Epoch: 68 [68/150 (45%)] Train loss=0.114903 Test loss=0.484812 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.08229394257068634
[5/24] Train loss=0.08643995225429535
[10/24] Train loss=0.10199039429426193
[15/24] Train loss=0.0859752893447876
[20/24] Train loss=0.07049012184143066
Test set avg_accuracy=87.97% avg_sensitivity=86.52%, avg_specificity=88.44% avg_auc=0.9490
Fold[4] Epoch: 69 [69/150 (46%)] Train loss=0.099091 Test loss=0.577319 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.09628339111804962
[5/24] Train loss=0.07759369164705276
[10/24] Train loss=0.11443934589624405
[15/24] Train loss=0.08120731264352798
[20/24] Train loss=0.07447665929794312
Test set avg_accuracy=88.27% avg_sensitivity=87.59%, avg_specificity=88.49% avg_auc=0.9498
Fold[4] Epoch: 70 [70/150 (47%)] Train loss=0.094179 Test loss=0.685496 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.07127971947193146
[5/24] Train loss=0.07879524677991867
[10/24] Train loss=0.0903383195400238
[15/24] Train loss=0.08572999387979507
[20/24] Train loss=0.06954124569892883
Test set avg_accuracy=86.12% avg_sensitivity=91.58%, avg_specificity=84.35% avg_auc=0.9496
Fold[4] Epoch: 71 [71/150 (47%)] Train loss=0.087851 Test loss=0.790826 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.10751388967037201
[5/24] Train loss=0.06443225592374802
[10/24] Train loss=0.10549202561378479
[15/24] Train loss=0.073076531291008
[20/24] Train loss=0.09188606590032578
Test set avg_accuracy=87.68% avg_sensitivity=87.80%, avg_specificity=87.64% avg_auc=0.9502
Fold[4] Epoch: 72 [72/150 (48%)] Train loss=0.092361 Test loss=0.754401 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.09137767553329468
[5/24] Train loss=0.12361282110214233
[10/24] Train loss=0.10525810718536377
[15/24] Train loss=0.11729015409946442
[20/24] Train loss=0.08582351356744766
Test set avg_accuracy=89.57% avg_sensitivity=87.11%, avg_specificity=90.37% avg_auc=0.9520
Fold[4] Epoch: 73 [73/150 (49%)] Train loss=0.113692 Test loss=0.711818 Current lr=[0.000834102481048427]

[0/24] Train loss=0.08660119771957397
[5/24] Train loss=0.09150400757789612
[10/24] Train loss=0.10004227608442307
[15/24] Train loss=0.07265621423721313
[20/24] Train loss=0.06616512686014175
Test set avg_accuracy=88.66% avg_sensitivity=89.08%, avg_specificity=88.52% avg_auc=0.9503
Fold[4] Epoch: 74 [74/150 (49%)] Train loss=0.096501 Test loss=0.688140 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.1178482174873352
[5/24] Train loss=0.08526761084794998
[10/24] Train loss=0.09389802068471909
[15/24] Train loss=0.09105334430932999
[20/24] Train loss=0.09324483573436737
Test set avg_accuracy=87.96% avg_sensitivity=88.49%, avg_specificity=87.78% avg_auc=0.9478
Fold[4] Epoch: 75 [75/150 (50%)] Train loss=0.096594 Test loss=0.655482 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.09271186590194702
[5/24] Train loss=0.058089569211006165
[10/24] Train loss=0.09114604443311691
[15/24] Train loss=0.08285032212734222
[20/24] Train loss=0.07245448231697083
Test set avg_accuracy=89.92% avg_sensitivity=84.18%, avg_specificity=91.78% avg_auc=0.9488
Fold[4] Epoch: 76 [76/150 (51%)] Train loss=0.091962 Test loss=0.596698 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.07852498441934586
[5/24] Train loss=0.08837790787220001
[10/24] Train loss=0.11418560892343521
[15/24] Train loss=0.0801779180765152
[20/24] Train loss=0.05789262801408768
Test set avg_accuracy=88.50% avg_sensitivity=87.48%, avg_specificity=88.83% avg_auc=0.9476
Fold[4] Epoch: 77 [77/150 (51%)] Train loss=0.093168 Test loss=0.686157 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.0701245665550232
[5/24] Train loss=0.06932757794857025
[10/24] Train loss=0.07432729750871658
[15/24] Train loss=0.05687742307782173
[20/24] Train loss=0.06055494397878647
Test set avg_accuracy=87.73% avg_sensitivity=89.72%, avg_specificity=87.09% avg_auc=0.9497
Fold[4] Epoch: 78 [78/150 (52%)] Train loss=0.078530 Test loss=0.904602 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.08516984432935715
[5/24] Train loss=0.07226095348596573
[10/24] Train loss=0.08312707394361496
[15/24] Train loss=0.07146730273962021
[20/24] Train loss=0.06147526949644089
Test set avg_accuracy=89.13% avg_sensitivity=85.62%, avg_specificity=90.26% avg_auc=0.9475
Fold[4] Epoch: 79 [79/150 (53%)] Train loss=0.079142 Test loss=0.552835 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.07592470198869705
[5/24] Train loss=0.05411679670214653
[10/24] Train loss=0.08050931990146637
[15/24] Train loss=0.048195596784353256
[20/24] Train loss=0.057985614985227585
Test set avg_accuracy=86.59% avg_sensitivity=89.77%, avg_specificity=85.56% avg_auc=0.9460
Fold[4] Epoch: 80 [80/150 (53%)] Train loss=0.071898 Test loss=0.678077 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.07080078125
[5/24] Train loss=0.06754633784294128
[10/24] Train loss=0.08571694791316986
[15/24] Train loss=0.06049785390496254
[20/24] Train loss=0.065228670835495
Test set avg_accuracy=88.35% avg_sensitivity=87.21%, avg_specificity=88.71% avg_auc=0.9482
Fold[4] Epoch: 81 [81/150 (54%)] Train loss=0.072373 Test loss=0.623164 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.05880091339349747
[5/24] Train loss=0.041659142822027206
[10/24] Train loss=0.11019142717123032
[15/24] Train loss=0.04590800777077675
[20/24] Train loss=0.050617776811122894
Test set avg_accuracy=88.33% avg_sensitivity=88.12%, avg_specificity=88.40% avg_auc=0.9492
Fold[4] Epoch: 82 [82/150 (55%)] Train loss=0.060380 Test loss=0.743699 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.04059217870235443
[5/24] Train loss=0.05333840101957321
[10/24] Train loss=0.09342173486948013
[15/24] Train loss=0.05803227052092552
[20/24] Train loss=0.04537174478173256
Test set avg_accuracy=87.90% avg_sensitivity=89.08%, avg_specificity=87.52% avg_auc=0.9494
Fold[4] Epoch: 83 [83/150 (55%)] Train loss=0.057048 Test loss=0.837433 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.06235282123088837
[5/24] Train loss=0.05223056674003601
[10/24] Train loss=0.0689777359366417
[15/24] Train loss=0.05371330678462982
[20/24] Train loss=0.0448397658765316
Test set avg_accuracy=88.84% avg_sensitivity=87.32%, avg_specificity=89.33% avg_auc=0.9504
Fold[4] Epoch: 84 [84/150 (56%)] Train loss=0.059730 Test loss=0.681477 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.05179256945848465
[5/24] Train loss=0.062409818172454834
[10/24] Train loss=0.060140594840049744
[15/24] Train loss=0.04438725486397743
[20/24] Train loss=0.03960392624139786
Test set avg_accuracy=87.59% avg_sensitivity=89.40%, avg_specificity=87.01% avg_auc=0.9502
Fold[4] Epoch: 85 [85/150 (57%)] Train loss=0.052847 Test loss=0.741053 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.04687344655394554
[5/24] Train loss=0.06354877352714539
[10/24] Train loss=0.054165229201316833
[15/24] Train loss=0.040856730192899704
[20/24] Train loss=0.04004913195967674
Test set avg_accuracy=87.62% avg_sensitivity=87.75%, avg_specificity=87.58% avg_auc=0.9491
Fold[4] Epoch: 86 [86/150 (57%)] Train loss=0.055794 Test loss=0.694591 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.05710579827427864
[5/24] Train loss=0.0556151419878006
[10/24] Train loss=0.0978512391448021
[15/24] Train loss=0.09976613521575928
[20/24] Train loss=0.08188828080892563
Test set avg_accuracy=89.92% avg_sensitivity=84.55%, avg_specificity=91.66% avg_auc=0.9485
Fold[4] Epoch: 87 [87/150 (58%)] Train loss=0.071722 Test loss=0.587834 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.07760481536388397
[5/24] Train loss=0.05881032720208168
[10/24] Train loss=0.09630937874317169
[15/24] Train loss=0.04806991666555405
[20/24] Train loss=0.054391346871852875
Test set avg_accuracy=87.17% avg_sensitivity=89.40%, avg_specificity=86.46% avg_auc=0.9470
Fold[4] Epoch: 88 [88/150 (59%)] Train loss=0.071683 Test loss=0.902509 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.0580228753387928
[5/24] Train loss=0.050857726484537125
[10/24] Train loss=0.09045784920454025
[15/24] Train loss=0.07235673815011978
[20/24] Train loss=0.04385960474610329
Test set avg_accuracy=87.86% avg_sensitivity=88.65%, avg_specificity=87.61% avg_auc=0.9495
Fold[4] Epoch: 89 [89/150 (59%)] Train loss=0.065372 Test loss=0.703437 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.06821848452091217
[5/24] Train loss=0.06231536716222763
[10/24] Train loss=0.09112758934497833
[15/24] Train loss=0.038676582276821136
[20/24] Train loss=0.05538415536284447
Test set avg_accuracy=89.15% avg_sensitivity=84.60%, avg_specificity=90.63% avg_auc=0.9457
Fold[4] Epoch: 90 [90/150 (60%)] Train loss=0.063521 Test loss=0.679673 Current lr=[0.00061065423442182]

[0/24] Train loss=0.05555563420057297
[5/24] Train loss=0.033538732677698135
[10/24] Train loss=0.07756465673446655
[15/24] Train loss=0.0387178473174572
[20/24] Train loss=0.04250815510749817
Test set avg_accuracy=88.36% avg_sensitivity=87.16%, avg_specificity=88.75% avg_auc=0.9481
Fold[4] Epoch: 91 [91/150 (61%)] Train loss=0.053237 Test loss=0.593294 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.04284895583987236
[5/24] Train loss=0.04354267194867134
[10/24] Train loss=0.06259489804506302
[15/24] Train loss=0.03591368719935417
[20/24] Train loss=0.03142813593149185
Test set avg_accuracy=89.34% avg_sensitivity=88.23%, avg_specificity=89.69% avg_auc=0.9537
Fold[4] Epoch: 92 [92/150 (61%)] Train loss=0.045295 Test loss=0.722085 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.037298157811164856
[5/24] Train loss=0.03259269893169403
[10/24] Train loss=0.04947672039270401
[15/24] Train loss=0.030590258538722992
[20/24] Train loss=0.0354657880961895
Test set avg_accuracy=87.79% avg_sensitivity=88.39%, avg_specificity=87.59% avg_auc=0.9513
Fold[4] Epoch: 93 [93/150 (62%)] Train loss=0.044171 Test loss=0.879174 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.047303207218647
[5/24] Train loss=0.03370976448059082
[10/24] Train loss=0.05398286506533623
[15/24] Train loss=0.023690247908234596
[20/24] Train loss=0.04152188450098038
Test set avg_accuracy=87.93% avg_sensitivity=88.44%, avg_specificity=87.76% avg_auc=0.9521
Fold[4] Epoch: 94 [94/150 (63%)] Train loss=0.046308 Test loss=0.876694 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.05004013702273369
[5/24] Train loss=0.04043080657720566
[10/24] Train loss=0.05163715407252312
[15/24] Train loss=0.03215957432985306
[20/24] Train loss=0.047878194600343704
Test set avg_accuracy=88.33% avg_sensitivity=87.16%, avg_specificity=88.71% avg_auc=0.9525
Fold[4] Epoch: 95 [95/150 (63%)] Train loss=0.045309 Test loss=0.686798 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.03548922762274742
[5/24] Train loss=0.02934814803302288
[10/24] Train loss=0.0512126088142395
[15/24] Train loss=0.04541153833270073
[20/24] Train loss=0.037854522466659546
Test set avg_accuracy=88.59% avg_sensitivity=86.68%, avg_specificity=89.21% avg_auc=0.9510
Fold[4] Epoch: 96 [96/150 (64%)] Train loss=0.038684 Test loss=0.697046 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.0321924090385437
[5/24] Train loss=0.02489551715552807
[10/24] Train loss=0.04758763685822487
[15/24] Train loss=0.028062479570508003
[20/24] Train loss=0.026329370215535164
Test set avg_accuracy=88.53% avg_sensitivity=86.31%, avg_specificity=89.25% avg_auc=0.9521
Fold[4] Epoch: 97 [97/150 (65%)] Train loss=0.035309 Test loss=0.855419 Current lr=[0.000506858408304961]

[0/24] Train loss=0.0352458693087101
[5/24] Train loss=0.027934260666370392
[10/24] Train loss=0.03720011189579964
[15/24] Train loss=0.02741430513560772
[20/24] Train loss=0.02870246395468712
Test set avg_accuracy=87.84% avg_sensitivity=89.29%, avg_specificity=87.37% avg_auc=0.9519
Fold[4] Epoch: 98 [98/150 (65%)] Train loss=0.032702 Test loss=0.961068 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.053353201597929
[5/24] Train loss=0.03272911533713341
[10/24] Train loss=0.05120624229311943
[15/24] Train loss=0.03545922785997391
[20/24] Train loss=0.027382690459489822
Test set avg_accuracy=86.86% avg_sensitivity=89.08%, avg_specificity=86.15% avg_auc=0.9499
Fold[4] Epoch: 99 [99/150 (66%)] Train loss=0.039239 Test loss=0.897068 Current lr=[0.000476946990416354]

[0/24] Train loss=0.04084863141179085
[5/24] Train loss=0.03697305545210838
[10/24] Train loss=0.03679205849766731
[15/24] Train loss=0.024641118943691254
[20/24] Train loss=0.0324895866215229
Test set avg_accuracy=88.23% avg_sensitivity=87.53%, avg_specificity=88.45% avg_auc=0.9499
Fold[4] Epoch: 100 [100/150 (67%)] Train loss=0.036842 Test loss=0.908343 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.03357703983783722
[5/24] Train loss=0.026755210012197495
[10/24] Train loss=0.03168376162648201
[15/24] Train loss=0.021811682730913162
[20/24] Train loss=0.022416479885578156
Test set avg_accuracy=88.57% avg_sensitivity=86.79%, avg_specificity=89.14% avg_auc=0.9522
Fold[4] Epoch: 101 [101/150 (67%)] Train loss=0.030288 Test loss=0.850378 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.03872630000114441
[5/24] Train loss=0.01991971582174301
[10/24] Train loss=0.05556076392531395
[15/24] Train loss=0.022946501150727272
[20/24] Train loss=0.04234146326780319
Test set avg_accuracy=87.68% avg_sensitivity=88.23%, avg_specificity=87.51% avg_auc=0.9512
Fold[4] Epoch: 102 [102/150 (68%)] Train loss=0.031565 Test loss=0.944886 Current lr=[0.000432267999769856]

[0/24] Train loss=0.04570482671260834
[5/24] Train loss=0.02505786158144474
[10/24] Train loss=0.04339417815208435
[15/24] Train loss=0.024425093084573746
[20/24] Train loss=0.02835267223417759
Test set avg_accuracy=88.05% avg_sensitivity=86.68%, avg_specificity=88.49% avg_auc=0.9488
Fold[4] Epoch: 103 [103/150 (69%)] Train loss=0.031646 Test loss=0.925255 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.03179492428898811
[5/24] Train loss=0.02201361022889614
[10/24] Train loss=0.04169385880231857
[15/24] Train loss=0.027361784130334854
[20/24] Train loss=0.017690205946564674
Test set avg_accuracy=87.71% avg_sensitivity=88.23%, avg_specificity=87.54% avg_auc=0.9488
Fold[4] Epoch: 104 [104/150 (69%)] Train loss=0.028373 Test loss=0.940917 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.04457182064652443
[5/24] Train loss=0.02397501841187477
[10/24] Train loss=0.0358930304646492
[15/24] Train loss=0.024808861315250397
[20/24] Train loss=0.026893477886915207
Test set avg_accuracy=88.20% avg_sensitivity=86.57%, avg_specificity=88.73% avg_auc=0.9488
Fold[4] Epoch: 105 [105/150 (70%)] Train loss=0.033434 Test loss=0.819920 Current lr=[0.000388134363466264]

[0/24] Train loss=0.027926351875066757
[5/24] Train loss=0.024516714736819267
[10/24] Train loss=0.037366703152656555
[15/24] Train loss=0.01801309362053871
[20/24] Train loss=0.02482655830681324
Test set avg_accuracy=87.41% avg_sensitivity=89.82%, avg_specificity=86.63% avg_auc=0.9516
Fold[4] Epoch: 106 [106/150 (71%)] Train loss=0.031467 Test loss=1.087014 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.05061132460832596
[5/24] Train loss=0.029044704511761665
[10/24] Train loss=0.04243311285972595
[15/24] Train loss=0.019830163568258286
[20/24] Train loss=0.01933172531425953
Test set avg_accuracy=88.67% avg_sensitivity=86.31%, avg_specificity=89.44% avg_auc=0.9506
Fold[4] Epoch: 107 [107/150 (71%)] Train loss=0.030756 Test loss=0.792988 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.035090409219264984
[5/24] Train loss=0.02117108926177025
[10/24] Train loss=0.03980093076825142
[15/24] Train loss=0.023172995075583458
[20/24] Train loss=0.022419163957238197
Test set avg_accuracy=87.28% avg_sensitivity=88.65%, avg_specificity=86.83% avg_auc=0.9509
Fold[4] Epoch: 108 [108/150 (72%)] Train loss=0.026952 Test loss=1.021876 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.02785671316087246
[5/24] Train loss=0.024159476161003113
[10/24] Train loss=0.030400656163692474
[15/24] Train loss=0.01671498455107212
[20/24] Train loss=0.014818355441093445
Test set avg_accuracy=88.68% avg_sensitivity=86.41%, avg_specificity=89.42% avg_auc=0.9516
Fold[4] Epoch: 109 [109/150 (73%)] Train loss=0.026229 Test loss=0.825370 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.01752718910574913
[5/24] Train loss=0.027241330593824387
[10/24] Train loss=0.03141496330499649
[15/24] Train loss=0.019388386979699135
[20/24] Train loss=0.03619568422436714
Test set avg_accuracy=87.88% avg_sensitivity=87.91%, avg_specificity=87.87% avg_auc=0.9525
Fold[4] Epoch: 110 [110/150 (73%)] Train loss=0.024687 Test loss=1.067995 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.02582216076552868
[5/24] Train loss=0.01878219097852707
[10/24] Train loss=0.03307182714343071
[15/24] Train loss=0.016300497576594353
[20/24] Train loss=0.03049050085246563
Test set avg_accuracy=88.83% avg_sensitivity=86.09%, avg_specificity=89.71% avg_auc=0.9522
Fold[4] Epoch: 111 [111/150 (74%)] Train loss=0.026450 Test loss=0.742684 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.02556345984339714
[5/24] Train loss=0.012305567041039467
[10/24] Train loss=0.0250910185277462
[15/24] Train loss=0.022715413942933083
[20/24] Train loss=0.016019383445382118
Test set avg_accuracy=87.89% avg_sensitivity=88.17%, avg_specificity=87.80% avg_auc=0.9506
Fold[4] Epoch: 112 [112/150 (75%)] Train loss=0.023367 Test loss=1.104062 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.023760566487908363
[5/24] Train loss=0.01862368732690811
[10/24] Train loss=0.02889387495815754
[15/24] Train loss=0.013120824471116066
[20/24] Train loss=0.022248249500989914
Test set avg_accuracy=89.40% avg_sensitivity=85.46%, avg_specificity=90.68% avg_auc=0.9522
Fold[4] Epoch: 113 [113/150 (75%)] Train loss=0.023345 Test loss=0.773379 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.02525067888200283
[5/24] Train loss=0.012538598850369453
[10/24] Train loss=0.027341624721884727
[15/24] Train loss=0.01603682152926922
[20/24] Train loss=0.02618524059653282
Test set avg_accuracy=88.63% avg_sensitivity=87.80%, avg_specificity=88.90% avg_auc=0.9522
Fold[4] Epoch: 114 [114/150 (76%)] Train loss=0.022649 Test loss=1.010055 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.019357310608029366
[5/24] Train loss=0.013866047374904156
[10/24] Train loss=0.02362462878227234
[15/24] Train loss=0.016255423426628113
[20/24] Train loss=0.014685066416859627
Test set avg_accuracy=89.15% avg_sensitivity=87.05%, avg_specificity=89.83% avg_auc=0.9524
Fold[4] Epoch: 115 [115/150 (77%)] Train loss=0.019282 Test loss=0.988150 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.020021844655275345
[5/24] Train loss=0.011045864783227444
[10/24] Train loss=0.021830571815371513
[15/24] Train loss=0.013348042964935303
[20/24] Train loss=0.013373399153351784
Test set avg_accuracy=87.68% avg_sensitivity=88.71%, avg_specificity=87.35% avg_auc=0.9522
Fold[4] Epoch: 116 [116/150 (77%)] Train loss=0.017300 Test loss=1.226246 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.016522087156772614
[5/24] Train loss=0.015493336133658886
[10/24] Train loss=0.021177299320697784
[15/24] Train loss=0.012172959744930267
[20/24] Train loss=0.015506804920732975
Test set avg_accuracy=87.93% avg_sensitivity=87.43%, avg_specificity=88.09% avg_auc=0.9514
Fold[4] Epoch: 117 [117/150 (78%)] Train loss=0.019647 Test loss=0.981678 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.015301357954740524
[5/24] Train loss=0.01761695183813572
[10/24] Train loss=0.020073438063263893
[15/24] Train loss=0.012190574780106544
[20/24] Train loss=0.012885535135865211
Test set avg_accuracy=88.16% avg_sensitivity=89.08%, avg_specificity=87.87% avg_auc=0.9521
Fold[4] Epoch: 118 [118/150 (79%)] Train loss=0.019691 Test loss=1.122143 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.016061093658208847
[5/24] Train loss=0.016042346134781837
[10/24] Train loss=0.02360766939818859
[15/24] Train loss=0.01246997993439436
[20/24] Train loss=0.013684705831110477
Test set avg_accuracy=88.46% avg_sensitivity=87.64%, avg_specificity=88.73% avg_auc=0.9517
Fold[4] Epoch: 119 [119/150 (79%)] Train loss=0.019508 Test loss=0.878243 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.01402757503092289
[5/24] Train loss=0.012134616263210773
[10/24] Train loss=0.0180974081158638
[15/24] Train loss=0.022533072158694267
[20/24] Train loss=0.016656925901770592
Test set avg_accuracy=87.77% avg_sensitivity=87.43%, avg_specificity=87.89% avg_auc=0.9515
Fold[4] Epoch: 120 [120/150 (80%)] Train loss=0.016403 Test loss=0.956470 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.010881351307034492
[5/24] Train loss=0.009190626442432404
[10/24] Train loss=0.017787227407097816
[15/24] Train loss=0.01696423627436161
[20/24] Train loss=0.012109534814953804
Test set avg_accuracy=87.16% avg_sensitivity=89.98%, avg_specificity=86.25% avg_auc=0.9511
Fold[4] Epoch: 121 [121/150 (81%)] Train loss=0.016259 Test loss=1.291611 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.014626781456172466
[5/24] Train loss=0.013471010141074657
[10/24] Train loss=0.0190716702491045
[15/24] Train loss=0.011953428387641907
[20/24] Train loss=0.010962298139929771
Test set avg_accuracy=87.47% avg_sensitivity=87.64%, avg_specificity=87.42% avg_auc=0.9516
Fold[4] Epoch: 122 [122/150 (81%)] Train loss=0.016495 Test loss=1.047572 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.01664057746529579
[5/24] Train loss=0.012089754454791546
[10/24] Train loss=0.021206799894571304
[15/24] Train loss=0.01320727914571762
[20/24] Train loss=0.015950269997119904
Test set avg_accuracy=88.06% avg_sensitivity=87.21%, avg_specificity=88.33% avg_auc=0.9514
Fold[4] Epoch: 123 [123/150 (82%)] Train loss=0.017692 Test loss=0.959047 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.010749287903308868
[5/24] Train loss=0.0111673129722476
[10/24] Train loss=0.015321082435548306
[15/24] Train loss=0.012890891171991825
[20/24] Train loss=0.012068635784089565
Test set avg_accuracy=87.97% avg_sensitivity=88.33%, avg_specificity=87.85% avg_auc=0.9520
Fold[4] Epoch: 124 [124/150 (83%)] Train loss=0.016142 Test loss=1.090164 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.017601685598492622
[5/24] Train loss=0.01449511107057333
[10/24] Train loss=0.023799298331141472
[15/24] Train loss=0.011952708475291729
[20/24] Train loss=0.010144134983420372
Test set avg_accuracy=88.74% avg_sensitivity=87.43%, avg_specificity=89.16% avg_auc=0.9527
Fold[4] Epoch: 125 [125/150 (83%)] Train loss=0.017389 Test loss=1.012648 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.01671099290251732
[5/24] Train loss=0.009126393124461174
[10/24] Train loss=0.015566232614219189
[15/24] Train loss=0.01180308498442173
[20/24] Train loss=0.022874848917126656
Test set avg_accuracy=88.65% avg_sensitivity=87.43%, avg_specificity=89.04% avg_auc=0.9523
Fold[4] Epoch: 126 [126/150 (84%)] Train loss=0.019424 Test loss=1.051116 Current lr=[0.000123057953306828]

[0/24] Train loss=0.009362583048641682
[5/24] Train loss=0.0154279675334692
[10/24] Train loss=0.017131304368376732
[15/24] Train loss=0.01130861509591341
[20/24] Train loss=0.01098040584474802
Test set avg_accuracy=87.23% avg_sensitivity=88.01%, avg_specificity=86.97% avg_auc=0.9517
Fold[4] Epoch: 127 [127/150 (85%)] Train loss=0.016824 Test loss=1.099076 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.014223900623619556
[5/24] Train loss=0.012109731324017048
[10/24] Train loss=0.022805875167250633
[15/24] Train loss=0.014302963390946388
[20/24] Train loss=0.013122647069394588
Test set avg_accuracy=87.58% avg_sensitivity=88.01%, avg_specificity=87.44% avg_auc=0.9515
Fold[4] Epoch: 128 [128/150 (85%)] Train loss=0.017968 Test loss=0.993341 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.017083631828427315
[5/24] Train loss=0.012507094070315361
[10/24] Train loss=0.023501036688685417
[15/24] Train loss=0.013173120096325874
[20/24] Train loss=0.017588375136256218
Test set avg_accuracy=88.50% avg_sensitivity=86.63%, avg_specificity=89.11% avg_auc=0.9518
Fold[4] Epoch: 129 [129/150 (86%)] Train loss=0.017476 Test loss=0.882451 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.012158196419477463
[5/24] Train loss=0.012677469290792942
[10/24] Train loss=0.01871376670897007
[15/24] Train loss=0.015438389964401722
[20/24] Train loss=0.010755719617009163
Test set avg_accuracy=88.54% avg_sensitivity=86.79%, avg_specificity=89.11% avg_auc=0.9521
Fold[4] Epoch: 130 [130/150 (87%)] Train loss=0.015343 Test loss=0.912939 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.010831141844391823
[5/24] Train loss=0.008590457029640675
[10/24] Train loss=0.015527969226241112
[15/24] Train loss=0.009589217603206635
[20/24] Train loss=0.01255970261991024
Test set avg_accuracy=87.83% avg_sensitivity=87.53%, avg_specificity=87.92% avg_auc=0.9516
Fold[4] Epoch: 131 [131/150 (87%)] Train loss=0.013709 Test loss=1.151673 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.010806496255099773
[5/24] Train loss=0.007741844281554222
[10/24] Train loss=0.011914337053894997
[15/24] Train loss=0.010445808991789818
[20/24] Train loss=0.007791826035827398
Test set avg_accuracy=87.53% avg_sensitivity=87.69%, avg_specificity=87.47% avg_auc=0.9512
Fold[4] Epoch: 132 [132/150 (88%)] Train loss=0.012625 Test loss=1.207975 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.011729652062058449
[5/24] Train loss=0.013372067362070084
[10/24] Train loss=0.026725202798843384
[15/24] Train loss=0.013249173760414124
[20/24] Train loss=0.007877974770963192
Test set avg_accuracy=87.62% avg_sensitivity=87.64%, avg_specificity=87.61% avg_auc=0.9513
Fold[4] Epoch: 133 [133/150 (89%)] Train loss=0.014485 Test loss=1.191241 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.012502088211476803
[5/24] Train loss=0.01070822961628437
[10/24] Train loss=0.0174556951969862
[15/24] Train loss=0.011324305087327957
[20/24] Train loss=0.015205263160169125
Test set avg_accuracy=87.76% avg_sensitivity=87.37%, avg_specificity=87.89% avg_auc=0.9514
Fold[4] Epoch: 134 [134/150 (89%)] Train loss=0.014206 Test loss=1.135085 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.011544277891516685
[5/24] Train loss=0.009546530432999134
[10/24] Train loss=0.015059633180499077
[15/24] Train loss=0.04129375144839287
[20/24] Train loss=0.008789358660578728
Test set avg_accuracy=87.84% avg_sensitivity=87.16%, avg_specificity=88.06% avg_auc=0.9514
Fold[4] Epoch: 135 [135/150 (90%)] Train loss=0.014580 Test loss=1.108660 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.010401284322142601
[5/24] Train loss=0.012352406047284603
[10/24] Train loss=0.012161189690232277
[15/24] Train loss=0.010348785668611526
[20/24] Train loss=0.009193668141961098
Test set avg_accuracy=87.96% avg_sensitivity=87.53%, avg_specificity=88.09% avg_auc=0.9516
Fold[4] Epoch: 136 [136/150 (91%)] Train loss=0.012038 Test loss=1.134762 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.008359602652490139
[5/24] Train loss=0.008702081628143787
[10/24] Train loss=0.012944734655320644
[15/24] Train loss=0.009142200462520123
[20/24] Train loss=0.010978924110531807
Test set avg_accuracy=87.67% avg_sensitivity=87.80%, avg_specificity=87.63% avg_auc=0.9518
Fold[4] Epoch: 137 [137/150 (91%)] Train loss=0.011584 Test loss=1.196184 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.00856177881360054
[5/24] Train loss=0.0071685598231852055
[10/24] Train loss=0.012405062094330788
[15/24] Train loss=0.007980084046721458
[20/24] Train loss=0.01633412018418312
Test set avg_accuracy=87.70% avg_sensitivity=87.91%, avg_specificity=87.63% avg_auc=0.9519
Fold[4] Epoch: 138 [138/150 (92%)] Train loss=0.011536 Test loss=1.226513 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.010936510749161243
[5/24] Train loss=0.008858266286551952
[10/24] Train loss=0.015797074884176254
[15/24] Train loss=0.009440292604267597
[20/24] Train loss=0.009626573882997036
Test set avg_accuracy=87.60% avg_sensitivity=87.85%, avg_specificity=87.52% avg_auc=0.9519
Fold[4] Epoch: 139 [139/150 (93%)] Train loss=0.012895 Test loss=1.194840 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.01648891344666481
[5/24] Train loss=0.01286887377500534
[10/24] Train loss=0.017254715785384178
[15/24] Train loss=0.01079337578266859
[20/24] Train loss=0.009987162426114082
Test set avg_accuracy=87.92% avg_sensitivity=87.59%, avg_specificity=88.02% avg_auc=0.9520
Fold[4] Epoch: 140 [140/150 (93%)] Train loss=0.014941 Test loss=1.164525 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.017356444150209427
[5/24] Train loss=0.009067398495972157
[10/24] Train loss=0.012729584239423275
[15/24] Train loss=0.009055259637534618
[20/24] Train loss=0.009898603893816471
Test set avg_accuracy=87.96% avg_sensitivity=87.59%, avg_specificity=88.08% avg_auc=0.9520
Fold[4] Epoch: 141 [141/150 (94%)] Train loss=0.012240 Test loss=1.131126 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.009308439679443836
[5/24] Train loss=0.007028239779174328
[10/24] Train loss=0.011584397405385971
[15/24] Train loss=0.0185246579349041
[20/24] Train loss=0.0068216328509151936
Test set avg_accuracy=87.97% avg_sensitivity=87.59%, avg_specificity=88.09% avg_auc=0.9521
Fold[4] Epoch: 142 [142/150 (95%)] Train loss=0.011221 Test loss=1.130894 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.009529653005301952
[5/24] Train loss=0.031192516908049583
[10/24] Train loss=0.013074452988803387
[15/24] Train loss=0.00757758179679513
[20/24] Train loss=0.007310013752430677
Test set avg_accuracy=87.96% avg_sensitivity=87.59%, avg_specificity=88.08% avg_auc=0.9521
Fold[4] Epoch: 143 [143/150 (95%)] Train loss=0.011890 Test loss=1.149809 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.007861711084842682
[5/24] Train loss=0.015964606776833534
[10/24] Train loss=0.009913711808621883
[15/24] Train loss=0.00492931017652154
[20/24] Train loss=0.006093386095017195
Test set avg_accuracy=87.75% avg_sensitivity=87.59%, avg_specificity=87.80% avg_auc=0.9522
Fold[4] Epoch: 144 [144/150 (96%)] Train loss=0.010397 Test loss=1.169700 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.011104782111942768
[5/24] Train loss=0.005792279727756977
[10/24] Train loss=0.008185319602489471
[15/24] Train loss=0.010203336365520954
[20/24] Train loss=0.0053309304639697075
Test set avg_accuracy=87.67% avg_sensitivity=87.75%, avg_specificity=87.64% avg_auc=0.9521
Fold[4] Epoch: 145 [145/150 (97%)] Train loss=0.014157 Test loss=1.190010 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.007771224249154329
[5/24] Train loss=0.01266805175691843
[10/24] Train loss=0.010947893373668194
[15/24] Train loss=0.006225057877600193
[20/24] Train loss=0.006087038200348616
Test set avg_accuracy=87.63% avg_sensitivity=87.80%, avg_specificity=87.58% avg_auc=0.9522
Fold[4] Epoch: 146 [146/150 (97%)] Train loss=0.011868 Test loss=1.196370 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.008295876905322075
[5/24] Train loss=0.008483834564685822
[10/24] Train loss=0.0116219287738204
[15/24] Train loss=0.013401846401393414
[20/24] Train loss=0.007555241230875254
Test set avg_accuracy=87.62% avg_sensitivity=87.85%, avg_specificity=87.54% avg_auc=0.9520
Fold[4] Epoch: 147 [147/150 (98%)] Train loss=0.009684 Test loss=1.222640 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.014723142609000206
[5/24] Train loss=0.006748686544597149
[10/24] Train loss=0.013084384612739086
[15/24] Train loss=0.007641190197318792
[20/24] Train loss=0.008790402673184872
Test set avg_accuracy=87.60% avg_sensitivity=87.85%, avg_specificity=87.52% avg_auc=0.9520
Fold[4] Epoch: 148 [148/150 (99%)] Train loss=0.010605 Test loss=1.224419 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.011430122889578342
[5/24] Train loss=0.008547340519726276
[10/24] Train loss=0.01663464680314064
[15/24] Train loss=0.01324894092977047
[20/24] Train loss=0.009525095112621784
Test set avg_accuracy=87.60% avg_sensitivity=87.85%, avg_specificity=87.52% avg_auc=0.9520
Fold[4] Epoch: 149 [149/150 (99%)] Train loss=0.012799 Test loss=1.223567 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.013550673611462116
[5/24] Train loss=0.010271084494888783
[10/24] Train loss=0.015114894136786461
[15/24] Train loss=0.009582950733602047
[20/24] Train loss=0.011321566998958588
Test set avg_accuracy=87.62% avg_sensitivity=87.85%, avg_specificity=87.54% avg_auc=0.9520
Fold[4] Epoch: 150 [150/150 (100%)] Train loss=0.013717 Test loss=1.223549 Current lr=[4.388541022775342e-09]

Fold[4] Result: acc=90.31% sen=85.99%, spe=91.71%, auc=0.96!
Fold[4] Avg_overlap=0.67%(0.22238276415554953)
[0/24] Train loss=1.440422534942627
[5/24] Train loss=1.3188915252685547
[10/24] Train loss=1.2594200372695923
[15/24] Train loss=1.0637916326522827
[20/24] Train loss=1.0441441535949707
Test set avg_accuracy=77.34% avg_sensitivity=18.21%, avg_specificity=95.11% avg_auc=0.7591
Best model saved!! Metric=0.759052380568783!!
Fold[5] Epoch: 1 [1/150 (1%)] Train loss=1.204952 Test loss=0.576718 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=1.016127586364746
[5/24] Train loss=0.9119750261306763
[10/24] Train loss=1.0043047666549683
[15/24] Train loss=0.8033724427223206
[20/24] Train loss=0.9211959838867188
Test set avg_accuracy=81.48% avg_sensitivity=55.52%, avg_specificity=89.28% avg_auc=0.8467
Best model saved!! Metric=0.8467043909638833!!
Fold[5] Epoch: 2 [2/150 (1%)] Train loss=0.953338 Test loss=0.501927 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.798870861530304
[5/24] Train loss=0.7988097071647644
[10/24] Train loss=0.9215416312217712
[15/24] Train loss=0.704696774482727
[20/24] Train loss=0.8178590536117554
Test set avg_accuracy=83.92% avg_sensitivity=68.43%, avg_specificity=88.57% avg_auc=0.8755
Best model saved!! Metric=0.8754752681144011!!
Fold[5] Epoch: 3 [3/150 (2%)] Train loss=0.829712 Test loss=0.440759 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.7390276193618774
[5/24] Train loss=0.7357639670372009
[10/24] Train loss=0.8312607407569885
[15/24] Train loss=0.635489821434021
[20/24] Train loss=0.7325171828269958
Test set avg_accuracy=84.26% avg_sensitivity=82.81%, avg_specificity=84.69% avg_auc=0.8999
Best model saved!! Metric=0.8998689445430498!!
Fold[5] Epoch: 4 [4/150 (3%)] Train loss=0.753534 Test loss=0.465320 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.6606321334838867
[5/24] Train loss=0.673801600933075
[10/24] Train loss=0.7818894386291504
[15/24] Train loss=0.5842889547348022
[20/24] Train loss=0.6912169456481934
Test set avg_accuracy=79.44% avg_sensitivity=94.14%, avg_specificity=75.03% avg_auc=0.9164
Best model saved!! Metric=0.9163850722575516!!
Fold[5] Epoch: 5 [5/150 (3%)] Train loss=0.691267 Test loss=0.651270 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.7045004367828369
[5/24] Train loss=0.6937384605407715
[10/24] Train loss=0.8614122271537781
[15/24] Train loss=0.5808355808258057
[20/24] Train loss=0.6771774291992188
Test set avg_accuracy=84.65% avg_sensitivity=86.13%, avg_specificity=84.20% avg_auc=0.9198
Best model saved!! Metric=0.9197890208531938!!
Fold[5] Epoch: 6 [6/150 (4%)] Train loss=0.712518 Test loss=0.436991 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.666934609413147
[5/24] Train loss=0.6949148178100586
[10/24] Train loss=0.8025165796279907
[15/24] Train loss=0.6135279536247253
[20/24] Train loss=0.708258330821991
Test set avg_accuracy=85.26% avg_sensitivity=89.29%, avg_specificity=84.05% avg_auc=0.9305
Best model saved!! Metric=0.9304666857047521!!
Fold[5] Epoch: 7 [7/150 (5%)] Train loss=0.705921 Test loss=0.436181 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.6851485967636108
[5/24] Train loss=0.6705374121665955
[10/24] Train loss=0.7960707545280457
[15/24] Train loss=0.5935367345809937
[20/24] Train loss=0.6829788088798523
Test set avg_accuracy=86.77% avg_sensitivity=86.81%, avg_specificity=86.76% avg_auc=0.9357
Best model saved!! Metric=0.9357152510717514!!
Fold[5] Epoch: 8 [8/150 (5%)] Train loss=0.711256 Test loss=0.364735 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.6861730217933655
[5/24] Train loss=0.688110888004303
[10/24] Train loss=0.7783970832824707
[15/24] Train loss=0.616303026676178
[20/24] Train loss=0.6604267358779907
Test set avg_accuracy=87.04% avg_sensitivity=85.63%, avg_specificity=87.47% avg_auc=0.9378
Best model saved!! Metric=0.9377555777072673!!
Fold[5] Epoch: 9 [9/150 (6%)] Train loss=0.700809 Test loss=0.327583 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.6657853126525879
[5/24] Train loss=0.6882586479187012
[10/24] Train loss=0.7978854775428772
[15/24] Train loss=0.5672357678413391
[20/24] Train loss=0.6228412985801697
Test set avg_accuracy=87.46% avg_sensitivity=88.16%, avg_specificity=87.25% avg_auc=0.9407
Best model saved!! Metric=0.9406935640708567!!
Fold[5] Epoch: 10 [10/150 (7%)] Train loss=0.681982 Test loss=0.352787 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.6445111632347107
[5/24] Train loss=0.6546574831008911
[10/24] Train loss=0.7903170585632324
[15/24] Train loss=0.5520595908164978
[20/24] Train loss=0.6307846903800964
Test set avg_accuracy=86.34% avg_sensitivity=89.97%, avg_specificity=85.25% avg_auc=0.9435
Best model saved!! Metric=0.9435378712188053!!
Fold[5] Epoch: 11 [11/150 (7%)] Train loss=0.677464 Test loss=0.357571 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.6961924433708191
[5/24] Train loss=0.6424285173416138
[10/24] Train loss=0.7994539141654968
[15/24] Train loss=0.5578836798667908
[20/24] Train loss=0.6241621375083923
Test set avg_accuracy=88.33% avg_sensitivity=87.94%, avg_specificity=88.45% avg_auc=0.9445
Best model saved!! Metric=0.9445082122741438!!
Fold[5] Epoch: 12 [12/150 (8%)] Train loss=0.681239 Test loss=0.307025 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6624484062194824
[5/24] Train loss=0.6013034582138062
[10/24] Train loss=0.8021338582038879
[15/24] Train loss=0.5603490471839905
[20/24] Train loss=0.612128734588623
Test set avg_accuracy=87.80% avg_sensitivity=87.88%, avg_specificity=87.78% avg_auc=0.9433
Fold[5] Epoch: 13 [13/150 (9%)] Train loss=0.655456 Test loss=0.327070 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.6544659733772278
[5/24] Train loss=0.6135231256484985
[10/24] Train loss=0.7654546499252319
[15/24] Train loss=0.5399460196495056
[20/24] Train loss=0.5705051422119141
Test set avg_accuracy=88.92% avg_sensitivity=87.60%, avg_specificity=89.32% avg_auc=0.9478
Best model saved!! Metric=0.9478226812318199!!
Fold[5] Epoch: 14 [14/150 (9%)] Train loss=0.647773 Test loss=0.288706 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.6349465250968933
[5/24] Train loss=0.5853536128997803
[10/24] Train loss=0.7497092485427856
[15/24] Train loss=0.5125486254692078
[20/24] Train loss=0.5465577244758606
Test set avg_accuracy=88.95% avg_sensitivity=85.74%, avg_specificity=89.91% avg_auc=0.9472
Fold[5] Epoch: 15 [15/150 (10%)] Train loss=0.629066 Test loss=0.296069 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.6327019333839417
[5/24] Train loss=0.5822499990463257
[10/24] Train loss=0.7602460980415344
[15/24] Train loss=0.5103980898857117
[20/24] Train loss=0.5574991703033447
Test set avg_accuracy=85.90% avg_sensitivity=92.11%, avg_specificity=84.03% avg_auc=0.9468
Fold[5] Epoch: 16 [16/150 (11%)] Train loss=0.622684 Test loss=0.393400 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.6304317712783813
[5/24] Train loss=0.5737482905387878
[10/24] Train loss=0.7138856649398804
[15/24] Train loss=0.5276924967765808
[20/24] Train loss=0.5245074033737183
Test set avg_accuracy=89.10% avg_sensitivity=86.53%, avg_specificity=89.87% avg_auc=0.9485
Best model saved!! Metric=0.9484884574607598!!
Fold[5] Epoch: 17 [17/150 (11%)] Train loss=0.617609 Test loss=0.296050 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.6260131001472473
[5/24] Train loss=0.5602230429649353
[10/24] Train loss=0.7347570657730103
[15/24] Train loss=0.5151862502098083
[20/24] Train loss=0.5404379963874817
Test set avg_accuracy=88.50% avg_sensitivity=89.52%, avg_specificity=88.20% avg_auc=0.9486
Best model saved!! Metric=0.9486378288030706!!
Fold[5] Epoch: 18 [18/150 (12%)] Train loss=0.610862 Test loss=0.326953 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.5995771884918213
[5/24] Train loss=0.552029550075531
[10/24] Train loss=0.7230169177055359
[15/24] Train loss=0.49071601033210754
[20/24] Train loss=0.5791109204292297
Test set avg_accuracy=88.74% avg_sensitivity=88.11%, avg_specificity=88.93% avg_auc=0.9500
Best model saved!! Metric=0.9499836980030245!!
Fold[5] Epoch: 19 [19/150 (13%)] Train loss=0.598967 Test loss=0.300141 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.6221128702163696
[5/24] Train loss=0.595571756362915
[10/24] Train loss=0.7442715167999268
[15/24] Train loss=0.4892779290676117
[20/24] Train loss=0.5442310571670532
Test set avg_accuracy=88.37% avg_sensitivity=88.84%, avg_specificity=88.23% avg_auc=0.9500
Fold[5] Epoch: 20 [20/150 (13%)] Train loss=0.604059 Test loss=0.309769 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.6151607036590576
[5/24] Train loss=0.525635838508606
[10/24] Train loss=0.6824060082435608
[15/24] Train loss=0.4734959602355957
[20/24] Train loss=0.5462949872016907
Test set avg_accuracy=90.42% avg_sensitivity=82.13%, avg_specificity=92.91% avg_auc=0.9474
Fold[5] Epoch: 21 [21/150 (14%)] Train loss=0.584038 Test loss=0.263249 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.6151040196418762
[5/24] Train loss=0.5716341137886047
[10/24] Train loss=0.6776754260063171
[15/24] Train loss=0.4896107614040375
[20/24] Train loss=0.5309787392616272
Test set avg_accuracy=89.04% avg_sensitivity=89.01%, avg_specificity=89.05% avg_auc=0.9492
Fold[5] Epoch: 22 [22/150 (15%)] Train loss=0.588313 Test loss=0.303993 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.6325728297233582
[5/24] Train loss=0.5470960736274719
[10/24] Train loss=0.689612627029419
[15/24] Train loss=0.44631820917129517
[20/24] Train loss=0.5180082321166992
Test set avg_accuracy=84.22% avg_sensitivity=93.01%, avg_specificity=81.58% avg_auc=0.9461
Fold[5] Epoch: 23 [23/150 (15%)] Train loss=0.573524 Test loss=0.417066 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5839551687240601
[5/24] Train loss=0.5356281995773315
[10/24] Train loss=0.6746364831924438
[15/24] Train loss=0.48765185475349426
[20/24] Train loss=0.48347118496894836
Test set avg_accuracy=89.43% avg_sensitivity=80.21%, avg_specificity=92.19% avg_auc=0.9406
Fold[5] Epoch: 24 [24/150 (16%)] Train loss=0.565154 Test loss=0.279558 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.601624071598053
[5/24] Train loss=0.5094785690307617
[10/24] Train loss=0.6076881885528564
[15/24] Train loss=0.4246411919593811
[20/24] Train loss=0.4790375828742981
Test set avg_accuracy=87.90% avg_sensitivity=89.57%, avg_specificity=87.40% avg_auc=0.9437
Fold[5] Epoch: 25 [25/150 (17%)] Train loss=0.550499 Test loss=0.353667 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5588337182998657
[5/24] Train loss=0.5128589868545532
[10/24] Train loss=0.6480661034584045
[15/24] Train loss=0.43504321575164795
[20/24] Train loss=0.46992725133895874
Test set avg_accuracy=88.48% avg_sensitivity=89.40%, avg_specificity=88.20% avg_auc=0.9493
Fold[5] Epoch: 26 [26/150 (17%)] Train loss=0.542629 Test loss=0.329391 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5687773823738098
[5/24] Train loss=0.5188280344009399
[10/24] Train loss=0.5718078017234802
[15/24] Train loss=0.4419625699520111
[20/24] Train loss=0.4683797061443329
Test set avg_accuracy=90.56% avg_sensitivity=85.29%, avg_specificity=92.14% avg_auc=0.9531
Best model saved!! Metric=0.9531368172775204!!
Fold[5] Epoch: 27 [27/150 (18%)] Train loss=0.542447 Test loss=0.262561 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5859500169754028
[5/24] Train loss=0.5158208608627319
[10/24] Train loss=0.5993416905403137
[15/24] Train loss=0.48169565200805664
[20/24] Train loss=0.5151095390319824
Test set avg_accuracy=88.55% avg_sensitivity=89.57%, avg_specificity=88.25% avg_auc=0.9522
Fold[5] Epoch: 28 [28/150 (19%)] Train loss=0.545224 Test loss=0.339573 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5334765911102295
[5/24] Train loss=0.5245444178581238
[10/24] Train loss=0.6354606747627258
[15/24] Train loss=0.42497262358665466
[20/24] Train loss=0.441158264875412
Test set avg_accuracy=89.69% avg_sensitivity=74.35%, avg_specificity=94.29% avg_auc=0.9473
Fold[5] Epoch: 29 [29/150 (19%)] Train loss=0.537558 Test loss=0.252509 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.5937165021896362
[5/24] Train loss=0.47561269998550415
[10/24] Train loss=0.6077390313148499
[15/24] Train loss=0.4209883511066437
[20/24] Train loss=0.47406288981437683
Test set avg_accuracy=88.12% avg_sensitivity=88.11%, avg_specificity=88.13% avg_auc=0.9489
Fold[5] Epoch: 30 [30/150 (20%)] Train loss=0.528612 Test loss=0.314109 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.5282942652702332
[5/24] Train loss=0.47857874631881714
[10/24] Train loss=0.5270060300827026
[15/24] Train loss=0.3652186989784241
[20/24] Train loss=0.43715357780456543
Test set avg_accuracy=88.10% avg_sensitivity=87.94%, avg_specificity=88.15% avg_auc=0.9453
Fold[5] Epoch: 31 [31/150 (21%)] Train loss=0.486905 Test loss=0.329359 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.4665653705596924
[5/24] Train loss=0.4231260120868683
[10/24] Train loss=0.49525901675224304
[15/24] Train loss=0.37872061133384705
[20/24] Train loss=0.4151368737220764
Test set avg_accuracy=85.34% avg_sensitivity=92.05%, avg_specificity=83.32% avg_auc=0.9498
Fold[5] Epoch: 32 [32/150 (21%)] Train loss=0.457156 Test loss=0.412194 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.4771101474761963
[5/24] Train loss=0.45741006731987
[10/24] Train loss=0.5543159246444702
[15/24] Train loss=0.38635194301605225
[20/24] Train loss=0.4469260275363922
Test set avg_accuracy=87.63% avg_sensitivity=89.40%, avg_specificity=87.10% avg_auc=0.9504
Fold[5] Epoch: 33 [33/150 (22%)] Train loss=0.479705 Test loss=0.312205 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.49163809418678284
[5/24] Train loss=0.48414111137390137
[10/24] Train loss=0.5020369291305542
[15/24] Train loss=0.3782743215560913
[20/24] Train loss=0.42788949608802795
Test set avg_accuracy=87.97% avg_sensitivity=89.68%, avg_specificity=87.45% avg_auc=0.9501
Fold[5] Epoch: 34 [34/150 (23%)] Train loss=0.469994 Test loss=0.312857 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.5241070985794067
[5/24] Train loss=0.466172456741333
[10/24] Train loss=0.5272634029388428
[15/24] Train loss=0.36987459659576416
[20/24] Train loss=0.41244542598724365
Test set avg_accuracy=89.38% avg_sensitivity=83.71%, avg_specificity=91.08% avg_auc=0.9490
Fold[5] Epoch: 35 [35/150 (23%)] Train loss=0.470360 Test loss=0.272820 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.4818483889102936
[5/24] Train loss=0.41643640398979187
[10/24] Train loss=0.518842875957489
[15/24] Train loss=0.3297634720802307
[20/24] Train loss=0.36483120918273926
Test set avg_accuracy=89.41% avg_sensitivity=82.24%, avg_specificity=91.57% avg_auc=0.9482
Fold[5] Epoch: 36 [36/150 (24%)] Train loss=0.441538 Test loss=0.275993 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.47357654571533203
[5/24] Train loss=0.41990166902542114
[10/24] Train loss=0.49356022477149963
[15/24] Train loss=0.36920851469039917
[20/24] Train loss=0.3679462969303131
Test set avg_accuracy=89.18% avg_sensitivity=83.31%, avg_specificity=90.94% avg_auc=0.9445
Fold[5] Epoch: 37 [37/150 (25%)] Train loss=0.418997 Test loss=0.296854 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.47864314913749695
[5/24] Train loss=0.4136444926261902
[10/24] Train loss=0.4135567545890808
[15/24] Train loss=0.31920892000198364
[20/24] Train loss=0.38126856088638306
Test set avg_accuracy=88.18% avg_sensitivity=90.14%, avg_specificity=87.59% avg_auc=0.9456
Fold[5] Epoch: 38 [38/150 (25%)] Train loss=0.404771 Test loss=0.349483 Current lr=[0.000944367614404117]

[0/24] Train loss=0.429547518491745
[5/24] Train loss=0.41250407695770264
[10/24] Train loss=0.44527870416641235
[15/24] Train loss=0.35713323950767517
[20/24] Train loss=0.3700929284095764
Test set avg_accuracy=89.30% avg_sensitivity=87.71%, avg_specificity=89.77% avg_auc=0.9515
Fold[5] Epoch: 39 [39/150 (26%)] Train loss=0.406146 Test loss=0.300716 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.4302594065666199
[5/24] Train loss=0.3697122037410736
[10/24] Train loss=0.42862188816070557
[15/24] Train loss=0.30616697669029236
[20/24] Train loss=0.34389257431030273
Test set avg_accuracy=88.10% avg_sensitivity=86.70%, avg_specificity=88.52% avg_auc=0.9417
Fold[5] Epoch: 40 [40/150 (27%)] Train loss=0.391473 Test loss=0.345889 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.4376377463340759
[5/24] Train loss=0.3537377417087555
[10/24] Train loss=0.37465956807136536
[15/24] Train loss=0.3093340992927551
[20/24] Train loss=0.36198052763938904
Test set avg_accuracy=77.92% avg_sensitivity=93.97%, avg_specificity=73.10% avg_auc=0.9358
Fold[5] Epoch: 41 [41/150 (27%)] Train loss=0.370110 Test loss=0.651437 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.41869255900382996
[5/24] Train loss=0.4016447961330414
[10/24] Train loss=0.5610188245773315
[15/24] Train loss=0.37624648213386536
[20/24] Train loss=0.3690812289714813
Test set avg_accuracy=86.20% avg_sensitivity=89.06%, avg_specificity=85.34% avg_auc=0.9477
Fold[5] Epoch: 42 [42/150 (28%)] Train loss=0.435032 Test loss=0.413390 Current lr=[0.000989780311725182]

[0/24] Train loss=0.436800479888916
[5/24] Train loss=0.40837207436561584
[10/24] Train loss=0.45969006419181824
[15/24] Train loss=0.3524792492389679
[20/24] Train loss=0.33120259642601013
Test set avg_accuracy=85.95% avg_sensitivity=90.42%, avg_specificity=84.61% avg_auc=0.9471
Fold[5] Epoch: 43 [43/150 (29%)] Train loss=0.433621 Test loss=0.418847 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.4619418680667877
[5/24] Train loss=0.3967176079750061
[10/24] Train loss=0.468474417924881
[15/24] Train loss=0.33891209959983826
[20/24] Train loss=0.34218618273735046
Test set avg_accuracy=89.58% avg_sensitivity=81.51%, avg_specificity=92.01% avg_auc=0.9504
Fold[5] Epoch: 44 [44/150 (29%)] Train loss=0.409744 Test loss=0.273287 Current lr=[0.000998924125869967]

[0/24] Train loss=0.41781553626060486
[5/24] Train loss=0.352832555770874
[10/24] Train loss=0.33996549248695374
[15/24] Train loss=0.2933354079723358
[20/24] Train loss=0.33811303973197937
Test set avg_accuracy=89.10% avg_sensitivity=85.46%, avg_specificity=90.20% avg_auc=0.9501
Fold[5] Epoch: 45 [45/150 (30%)] Train loss=0.357101 Test loss=0.309496 Current lr=[0.000999999611458977]

[0/24] Train loss=0.3781624138355255
[5/24] Train loss=0.32494911551475525
[10/24] Train loss=0.28298649191856384
[15/24] Train loss=0.28414779901504517
[20/24] Train loss=0.3034234642982483
Test set avg_accuracy=88.39% avg_sensitivity=88.95%, avg_specificity=88.22% avg_auc=0.9513
Fold[5] Epoch: 46 [46/150 (31%)] Train loss=0.317967 Test loss=0.355030 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.3730497360229492
[5/24] Train loss=0.3554857075214386
[10/24] Train loss=0.31575408577919006
[15/24] Train loss=0.2779890298843384
[20/24] Train loss=0.276761919260025
Test set avg_accuracy=86.81% avg_sensitivity=90.02%, avg_specificity=85.84% avg_auc=0.9482
Fold[5] Epoch: 47 [47/150 (31%)] Train loss=0.322677 Test loss=0.435819 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.4060429334640503
[5/24] Train loss=0.31716102361679077
[10/24] Train loss=0.34037259221076965
[15/24] Train loss=0.23779082298278809
[20/24] Train loss=0.23695895075798035
Test set avg_accuracy=88.72% avg_sensitivity=85.68%, avg_specificity=89.64% avg_auc=0.9493
Fold[5] Epoch: 48 [48/150 (32%)] Train loss=0.318228 Test loss=0.330953 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3030101954936981
[5/24] Train loss=0.26541778445243835
[10/24] Train loss=0.2906566858291626
[15/24] Train loss=0.2107342928647995
[20/24] Train loss=0.22865645587444305
Test set avg_accuracy=88.76% avg_sensitivity=84.16%, avg_specificity=90.15% avg_auc=0.9503
Fold[5] Epoch: 49 [49/150 (33%)] Train loss=0.269574 Test loss=0.330478 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.2730454206466675
[5/24] Train loss=0.2354438304901123
[10/24] Train loss=0.277374267578125
[15/24] Train loss=0.17601378262043
[20/24] Train loss=0.1789020597934723
Test set avg_accuracy=86.63% avg_sensitivity=90.59%, avg_specificity=85.44% avg_auc=0.9499
Fold[5] Epoch: 50 [50/150 (33%)] Train loss=0.232771 Test loss=0.470107 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.2857624888420105
[5/24] Train loss=0.25158295035362244
[10/24] Train loss=0.2522071897983551
[15/24] Train loss=0.20220547914505005
[20/24] Train loss=0.18416057527065277
Test set avg_accuracy=88.37% avg_sensitivity=86.98%, avg_specificity=88.79% avg_auc=0.9514
Fold[5] Epoch: 51 [51/150 (34%)] Train loss=0.239448 Test loss=0.381889 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.23457573354244232
[5/24] Train loss=0.21887877583503723
[10/24] Train loss=0.23845191299915314
[15/24] Train loss=0.18150345981121063
[20/24] Train loss=0.1680784523487091
Test set avg_accuracy=88.96% avg_sensitivity=85.96%, avg_specificity=89.86% avg_auc=0.9463
Fold[5] Epoch: 52 [52/150 (35%)] Train loss=0.222219 Test loss=0.400827 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.2015446424484253
[5/24] Train loss=0.21017740666866302
[10/24] Train loss=0.2288084179162979
[15/24] Train loss=0.17646485567092896
[20/24] Train loss=0.206896111369133
Test set avg_accuracy=85.18% avg_sensitivity=90.98%, avg_specificity=83.44% avg_auc=0.9451
Fold[5] Epoch: 53 [53/150 (35%)] Train loss=0.208769 Test loss=0.582417 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.2706003785133362
[5/24] Train loss=0.2099861204624176
[10/24] Train loss=0.19769532978534698
[15/24] Train loss=0.16361233592033386
[20/24] Train loss=0.1780039221048355
Test set avg_accuracy=87.33% avg_sensitivity=85.12%, avg_specificity=88.00% avg_auc=0.9415
Fold[5] Epoch: 54 [54/150 (36%)] Train loss=0.208302 Test loss=0.451080 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.1815267950296402
[5/24] Train loss=0.15064232051372528
[10/24] Train loss=0.1951637864112854
[15/24] Train loss=0.15395963191986084
[20/24] Train loss=0.1560242772102356
Test set avg_accuracy=85.53% avg_sensitivity=91.21%, avg_specificity=83.83% avg_auc=0.9475
Fold[5] Epoch: 55 [55/150 (37%)] Train loss=0.179415 Test loss=0.568265 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.24212421476840973
[5/24] Train loss=0.17827746272087097
[10/24] Train loss=0.21106413006782532
[15/24] Train loss=0.13862238824367523
[20/24] Train loss=0.15216919779777527
Test set avg_accuracy=88.33% avg_sensitivity=88.95%, avg_specificity=88.15% avg_auc=0.9491
Fold[5] Epoch: 56 [56/150 (37%)] Train loss=0.192588 Test loss=0.473761 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.23114454746246338
[5/24] Train loss=0.178054541349411
[10/24] Train loss=0.18502478301525116
[15/24] Train loss=0.17586959898471832
[20/24] Train loss=0.1895797997713089
Test set avg_accuracy=89.00% avg_sensitivity=85.79%, avg_specificity=89.96% avg_auc=0.9477
Fold[5] Epoch: 57 [57/150 (38%)] Train loss=0.188934 Test loss=0.390474 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.18555203080177307
[5/24] Train loss=0.151854008436203
[10/24] Train loss=0.18448692560195923
[15/24] Train loss=0.19058024883270264
[20/24] Train loss=0.15790517628192902
Test set avg_accuracy=87.36% avg_sensitivity=88.90%, avg_specificity=86.89% avg_auc=0.9446
Fold[5] Epoch: 58 [58/150 (39%)] Train loss=0.174199 Test loss=0.476545 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.17042657732963562
[5/24] Train loss=0.1590048372745514
[10/24] Train loss=0.1681402623653412
[15/24] Train loss=0.14796340465545654
[20/24] Train loss=0.1371029019355774
Test set avg_accuracy=89.28% avg_sensitivity=85.29%, avg_specificity=90.48% avg_auc=0.9447
Fold[5] Epoch: 59 [59/150 (39%)] Train loss=0.172673 Test loss=0.394881 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.18100933730602264
[5/24] Train loss=0.16004203259944916
[10/24] Train loss=0.17608754336833954
[15/24] Train loss=0.15368592739105225
[20/24] Train loss=0.1493377834558487
Test set avg_accuracy=87.37% avg_sensitivity=86.81%, avg_specificity=87.54% avg_auc=0.9435
Fold[5] Epoch: 60 [60/150 (40%)] Train loss=0.157947 Test loss=0.470041 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.15167002379894257
[5/24] Train loss=0.14640627801418304
[10/24] Train loss=0.1733878254890442
[15/24] Train loss=0.11966431140899658
[20/24] Train loss=0.12392553687095642
Test set avg_accuracy=86.68% avg_sensitivity=89.46%, avg_specificity=85.84% avg_auc=0.9457
Fold[5] Epoch: 61 [61/150 (41%)] Train loss=0.141400 Test loss=0.565908 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.18809965252876282
[5/24] Train loss=0.11700671911239624
[10/24] Train loss=0.1450551450252533
[15/24] Train loss=0.12632501125335693
[20/24] Train loss=0.09805285930633545
Test set avg_accuracy=88.84% avg_sensitivity=83.65%, avg_specificity=90.40% avg_auc=0.9431
Fold[5] Epoch: 62 [62/150 (41%)] Train loss=0.141172 Test loss=0.471845 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.13163554668426514
[5/24] Train loss=0.10634120553731918
[10/24] Train loss=0.13457559049129486
[15/24] Train loss=0.12046372890472412
[20/24] Train loss=0.10415776818990707
Test set avg_accuracy=88.61% avg_sensitivity=82.64%, avg_specificity=90.40% avg_auc=0.9417
Fold[5] Epoch: 63 [63/150 (42%)] Train loss=0.124461 Test loss=0.494178 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.14135056734085083
[5/24] Train loss=0.09840374439954758
[10/24] Train loss=0.11061500757932663
[15/24] Train loss=0.10451407730579376
[20/24] Train loss=0.1017250046133995
Test set avg_accuracy=87.02% avg_sensitivity=87.37%, avg_specificity=86.91% avg_auc=0.9418
Fold[5] Epoch: 64 [64/150 (43%)] Train loss=0.117055 Test loss=0.596193 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.14175166189670563
[5/24] Train loss=0.11456368118524551
[10/24] Train loss=0.12361544370651245
[15/24] Train loss=0.09189987927675247
[20/24] Train loss=0.09486724436283112
Test set avg_accuracy=86.47% avg_sensitivity=88.67%, avg_specificity=85.81% avg_auc=0.9473
Fold[5] Epoch: 65 [65/150 (43%)] Train loss=0.110953 Test loss=0.569125 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.129041850566864
[5/24] Train loss=0.10895200818777084
[10/24] Train loss=0.11166547983884811
[15/24] Train loss=0.10004247725009918
[20/24] Train loss=0.0957195833325386
Test set avg_accuracy=89.92% avg_sensitivity=84.55%, avg_specificity=91.53% avg_auc=0.9463
Fold[5] Epoch: 66 [66/150 (44%)] Train loss=0.118364 Test loss=0.468097 Current lr=[0.000904142181093812]

[0/24] Train loss=0.11689601093530655
[5/24] Train loss=0.10489010065793991
[10/24] Train loss=0.11999892443418503
[15/24] Train loss=0.12408629804849625
[20/24] Train loss=0.11277301609516144
Test set avg_accuracy=89.73% avg_sensitivity=83.20%, avg_specificity=91.69% avg_auc=0.9405
Fold[5] Epoch: 67 [67/150 (45%)] Train loss=0.113723 Test loss=0.521224 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.11813624948263168
[5/24] Train loss=0.10854339599609375
[10/24] Train loss=0.10923557728528976
[15/24] Train loss=0.09781339019536972
[20/24] Train loss=0.08188445121049881
Test set avg_accuracy=88.80% avg_sensitivity=81.96%, avg_specificity=90.86% avg_auc=0.9438
Fold[5] Epoch: 68 [68/150 (45%)] Train loss=0.105808 Test loss=0.482681 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.10966720432043076
[5/24] Train loss=0.07511093467473984
[10/24] Train loss=0.09146194159984589
[15/24] Train loss=0.070011667907238
[20/24] Train loss=0.07316725701093674
Test set avg_accuracy=88.57% avg_sensitivity=83.60%, avg_specificity=90.06% avg_auc=0.9382
Fold[5] Epoch: 69 [69/150 (46%)] Train loss=0.091771 Test loss=0.560693 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.09965380281209946
[5/24] Train loss=0.08104493468999863
[10/24] Train loss=0.11126172542572021
[15/24] Train loss=0.0824168249964714
[20/24] Train loss=0.08047784864902496
Test set avg_accuracy=87.57% avg_sensitivity=86.36%, avg_specificity=87.93% avg_auc=0.9417
Fold[5] Epoch: 70 [70/150 (47%)] Train loss=0.098423 Test loss=0.577528 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.09313920140266418
[5/24] Train loss=0.06921369582414627
[10/24] Train loss=0.09826243668794632
[15/24] Train loss=0.0992148220539093
[20/24] Train loss=0.09766238182783127
Test set avg_accuracy=85.60% avg_sensitivity=88.22%, avg_specificity=84.81% avg_auc=0.9379
Fold[5] Epoch: 71 [71/150 (47%)] Train loss=0.102494 Test loss=0.741497 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.13042248785495758
[5/24] Train loss=0.08842350542545319
[10/24] Train loss=0.1272408366203308
[15/24] Train loss=0.07905442267656326
[20/24] Train loss=0.08408764749765396
Test set avg_accuracy=85.65% avg_sensitivity=90.36%, avg_specificity=84.24% avg_auc=0.9420
Fold[5] Epoch: 72 [72/150 (48%)] Train loss=0.113987 Test loss=0.755651 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.10457365214824677
[5/24] Train loss=0.1033172756433487
[10/24] Train loss=0.13411939144134521
[15/24] Train loss=0.09488338232040405
[20/24] Train loss=0.09325608611106873
Test set avg_accuracy=87.46% avg_sensitivity=88.78%, avg_specificity=87.06% avg_auc=0.9455
Fold[5] Epoch: 73 [73/150 (49%)] Train loss=0.113473 Test loss=0.666836 Current lr=[0.000834102481048427]

[0/24] Train loss=0.10660500824451447
[5/24] Train loss=0.09696604311466217
[10/24] Train loss=0.12443377822637558
[15/24] Train loss=0.10072436928749084
[20/24] Train loss=0.08402640372514725
Test set avg_accuracy=87.83% avg_sensitivity=84.44%, avg_specificity=88.84% avg_auc=0.9426
Fold[5] Epoch: 74 [74/150 (49%)] Train loss=0.107374 Test loss=0.539460 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.12645390629768372
[5/24] Train loss=0.10040472447872162
[10/24] Train loss=0.09513602405786514
[15/24] Train loss=0.10043691098690033
[20/24] Train loss=0.09826207160949707
Test set avg_accuracy=88.14% avg_sensitivity=82.24%, avg_specificity=89.91% avg_auc=0.9397
Fold[5] Epoch: 75 [75/150 (50%)] Train loss=0.101245 Test loss=0.526244 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.09159693866968155
[5/24] Train loss=0.07678593695163727
[10/24] Train loss=0.08574746549129486
[15/24] Train loss=0.10405030101537704
[20/24] Train loss=0.0834316536784172
Test set avg_accuracy=85.78% avg_sensitivity=88.28%, avg_specificity=85.03% avg_auc=0.9405
Fold[5] Epoch: 76 [76/150 (51%)] Train loss=0.089083 Test loss=0.684912 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.1042913943529129
[5/24] Train loss=0.08624310046434402
[10/24] Train loss=0.132949560880661
[15/24] Train loss=0.07393386214971542
[20/24] Train loss=0.07260456681251526
Test set avg_accuracy=86.98% avg_sensitivity=86.13%, avg_specificity=87.23% avg_auc=0.9408
Fold[5] Epoch: 77 [77/150 (51%)] Train loss=0.100468 Test loss=0.605105 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.07472607493400574
[5/24] Train loss=0.05804053694009781
[10/24] Train loss=0.07438480108976364
[15/24] Train loss=0.056888412684202194
[20/24] Train loss=0.06827013939619064
Test set avg_accuracy=86.21% avg_sensitivity=91.94%, avg_specificity=84.49% avg_auc=0.9413
Fold[5] Epoch: 78 [78/150 (52%)] Train loss=0.077253 Test loss=0.877036 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.11810620874166489
[5/24] Train loss=0.05948961526155472
[10/24] Train loss=0.11220096796751022
[15/24] Train loss=0.07362721860408783
[20/24] Train loss=0.07139050215482712
Test set avg_accuracy=86.69% avg_sensitivity=87.20%, avg_specificity=86.54% avg_auc=0.9392
Fold[5] Epoch: 79 [79/150 (53%)] Train loss=0.088026 Test loss=0.632586 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.07716383785009384
[5/24] Train loss=0.07683859765529633
[10/24] Train loss=0.07396361976861954
[15/24] Train loss=0.07061583548784256
[20/24] Train loss=0.06582579761743546
Test set avg_accuracy=87.68% avg_sensitivity=86.36%, avg_specificity=88.08% avg_auc=0.9455
Fold[5] Epoch: 80 [80/150 (53%)] Train loss=0.083003 Test loss=0.572826 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.06668919324874878
[5/24] Train loss=0.07623741030693054
[10/24] Train loss=0.0699620172381401
[15/24] Train loss=0.05448634922504425
[20/24] Train loss=0.06204172968864441
Test set avg_accuracy=86.71% avg_sensitivity=88.05%, avg_specificity=86.30% avg_auc=0.9390
Fold[5] Epoch: 81 [81/150 (54%)] Train loss=0.073732 Test loss=0.710669 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.07085257023572922
[5/24] Train loss=0.0682254210114479
[10/24] Train loss=0.059574853628873825
[15/24] Train loss=0.06528063863515854
[20/24] Train loss=0.0834295004606247
Test set avg_accuracy=88.50% avg_sensitivity=85.79%, avg_specificity=89.32% avg_auc=0.9421
Fold[5] Epoch: 82 [82/150 (55%)] Train loss=0.072566 Test loss=0.755006 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.08009915798902512
[5/24] Train loss=0.05562366917729378
[10/24] Train loss=0.052533626556396484
[15/24] Train loss=0.05180647596716881
[20/24] Train loss=0.056019023060798645
Test set avg_accuracy=88.20% avg_sensitivity=87.49%, avg_specificity=88.42% avg_auc=0.9443
Fold[5] Epoch: 83 [83/150 (55%)] Train loss=0.063681 Test loss=0.726408 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.05943039432168007
[5/24] Train loss=0.05159953609108925
[10/24] Train loss=0.05092206969857216
[15/24] Train loss=0.03668837994337082
[20/24] Train loss=0.044230200350284576
Test set avg_accuracy=87.42% avg_sensitivity=88.11%, avg_specificity=87.22% avg_auc=0.9441
Fold[5] Epoch: 84 [84/150 (56%)] Train loss=0.052687 Test loss=0.833795 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.054627660661935806
[5/24] Train loss=0.07232480496168137
[10/24] Train loss=0.06547793745994568
[15/24] Train loss=0.0656655877828598
[20/24] Train loss=0.05012422800064087
Test set avg_accuracy=87.89% avg_sensitivity=84.89%, avg_specificity=88.79% avg_auc=0.9442
Fold[5] Epoch: 85 [85/150 (57%)] Train loss=0.058924 Test loss=0.688370 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.044145338237285614
[5/24] Train loss=0.041580695658922195
[10/24] Train loss=0.049180421978235245
[15/24] Train loss=0.03665170818567276
[20/24] Train loss=0.060096465051174164
Test set avg_accuracy=87.19% avg_sensitivity=86.92%, avg_specificity=87.27% avg_auc=0.9400
Fold[5] Epoch: 86 [86/150 (57%)] Train loss=0.050406 Test loss=0.901421 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.044706348329782486
[5/24] Train loss=0.03661110997200012
[10/24] Train loss=0.037750352174043655
[15/24] Train loss=0.04064090922474861
[20/24] Train loss=0.03815505653619766
Test set avg_accuracy=86.25% avg_sensitivity=89.57%, avg_specificity=85.25% avg_auc=0.9436
Fold[5] Epoch: 87 [87/150 (58%)] Train loss=0.047837 Test loss=1.040358 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.055726125836372375
[5/24] Train loss=0.06398061662912369
[10/24] Train loss=0.061685964465141296
[15/24] Train loss=0.04748990759253502
[20/24] Train loss=0.065590500831604
Test set avg_accuracy=84.43% avg_sensitivity=90.42%, avg_specificity=82.63% avg_auc=0.9340
Fold[5] Epoch: 88 [88/150 (59%)] Train loss=0.072536 Test loss=0.959517 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.08544262498617172
[5/24] Train loss=0.05630412697792053
[10/24] Train loss=0.06477200984954834
[15/24] Train loss=0.04888467863202095
[20/24] Train loss=0.04656962677836418
Test set avg_accuracy=87.47% avg_sensitivity=85.12%, avg_specificity=88.18% avg_auc=0.9430
Fold[5] Epoch: 89 [89/150 (59%)] Train loss=0.066181 Test loss=0.815316 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.06073826178908348
[5/24] Train loss=0.03841439634561539
[10/24] Train loss=0.04145827889442444
[15/24] Train loss=0.03375886008143425
[20/24] Train loss=0.051002323627471924
Test set avg_accuracy=87.06% avg_sensitivity=86.30%, avg_specificity=87.28% avg_auc=0.9418
Fold[5] Epoch: 90 [90/150 (60%)] Train loss=0.050389 Test loss=0.844701 Current lr=[0.00061065423442182]

[0/24] Train loss=0.0409480519592762
[5/24] Train loss=0.04176546260714531
[10/24] Train loss=0.04322037473320961
[15/24] Train loss=0.035545606166124344
[20/24] Train loss=0.0314391627907753
Test set avg_accuracy=86.24% avg_sensitivity=87.54%, avg_specificity=85.84% avg_auc=0.9403
Fold[5] Epoch: 91 [91/150 (61%)] Train loss=0.042824 Test loss=0.841378 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.041682589799165726
[5/24] Train loss=0.045401763170957565
[10/24] Train loss=0.039243701845407486
[15/24] Train loss=0.04030817374587059
[20/24] Train loss=0.05646234005689621
Test set avg_accuracy=85.92% avg_sensitivity=89.06%, avg_specificity=84.98% avg_auc=0.9404
Fold[5] Epoch: 92 [92/150 (61%)] Train loss=0.047846 Test loss=0.895062 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.05652480199933052
[5/24] Train loss=0.048734452575445175
[10/24] Train loss=0.03673173859715462
[15/24] Train loss=0.02601800672709942
[20/24] Train loss=0.04217660799622536
Test set avg_accuracy=87.32% avg_sensitivity=87.32%, avg_specificity=87.32% avg_auc=0.9437
Fold[5] Epoch: 93 [93/150 (62%)] Train loss=0.051220 Test loss=0.796339 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.05101751536130905
[5/24] Train loss=0.08332020789384842
[10/24] Train loss=0.033348213881254196
[15/24] Train loss=0.03280169889330864
[20/24] Train loss=0.027783788740634918
Test set avg_accuracy=87.41% avg_sensitivity=86.64%, avg_specificity=87.64% avg_auc=0.9454
Fold[5] Epoch: 94 [94/150 (63%)] Train loss=0.043510 Test loss=0.836004 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.03940477594733238
[5/24] Train loss=0.048748139292001724
[10/24] Train loss=0.04296617582440376
[15/24] Train loss=0.024426361545920372
[20/24] Train loss=0.040418561547994614
Test set avg_accuracy=86.88% avg_sensitivity=86.70%, avg_specificity=86.93% avg_auc=0.9384
Fold[5] Epoch: 95 [95/150 (63%)] Train loss=0.040730 Test loss=0.841009 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.03424730524420738
[5/24] Train loss=0.04119079187512398
[10/24] Train loss=0.03109964355826378
[15/24] Train loss=0.02306041494011879
[20/24] Train loss=0.02242215722799301
Test set avg_accuracy=87.67% avg_sensitivity=85.29%, avg_specificity=88.38% avg_auc=0.9419
Fold[5] Epoch: 96 [96/150 (64%)] Train loss=0.034677 Test loss=0.872537 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.03252600133419037
[5/24] Train loss=0.04281730204820633
[10/24] Train loss=0.04931637644767761
[15/24] Train loss=0.03273220732808113
[20/24] Train loss=0.03781452402472496
Test set avg_accuracy=87.37% avg_sensitivity=88.61%, avg_specificity=87.00% avg_auc=0.9447
Fold[5] Epoch: 97 [97/150 (65%)] Train loss=0.037507 Test loss=1.018353 Current lr=[0.000506858408304961]

[0/24] Train loss=0.04712379351258278
[5/24] Train loss=0.0382341630756855
[10/24] Train loss=0.03587845340371132
[15/24] Train loss=0.030474750325083733
[20/24] Train loss=0.03166931867599487
Test set avg_accuracy=87.23% avg_sensitivity=89.06%, avg_specificity=86.67% avg_auc=0.9436
Fold[5] Epoch: 98 [98/150 (65%)] Train loss=0.039234 Test loss=0.899876 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.03746843710541725
[5/24] Train loss=0.04615535959601402
[10/24] Train loss=0.030270786955952644
[15/24] Train loss=0.02781670168042183
[20/24] Train loss=0.029154179617762566
Test set avg_accuracy=86.52% avg_sensitivity=89.57%, avg_specificity=85.61% avg_auc=0.9457
Fold[5] Epoch: 99 [99/150 (66%)] Train loss=0.038232 Test loss=0.834918 Current lr=[0.000476946990416354]

[0/24] Train loss=0.04415590688586235
[5/24] Train loss=0.047993067651987076
[10/24] Train loss=0.03672727569937706
[15/24] Train loss=0.030232369899749756
[20/24] Train loss=0.027154745534062386
Test set avg_accuracy=88.65% avg_sensitivity=84.72%, avg_specificity=89.82% avg_auc=0.9469
Fold[5] Epoch: 100 [100/150 (67%)] Train loss=0.041904 Test loss=0.864564 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.07284361869096756
[5/24] Train loss=0.042729418724775314
[10/24] Train loss=0.04888805374503136
[15/24] Train loss=0.031107809394598007
[20/24] Train loss=0.03259536996483803
Test set avg_accuracy=88.61% avg_sensitivity=86.64%, avg_specificity=89.20% avg_auc=0.9464
Fold[5] Epoch: 101 [101/150 (67%)] Train loss=0.042766 Test loss=0.735850 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.04140934348106384
[5/24] Train loss=0.03492235392332077
[10/24] Train loss=0.02705490216612816
[15/24] Train loss=0.024768520146608353
[20/24] Train loss=0.030996929854154587
Test set avg_accuracy=86.52% avg_sensitivity=89.57%, avg_specificity=85.61% avg_auc=0.9454
Fold[5] Epoch: 102 [102/150 (68%)] Train loss=0.035109 Test loss=0.888784 Current lr=[0.000432267999769856]

[0/24] Train loss=0.05154890939593315
[5/24] Train loss=0.0357794351875782
[10/24] Train loss=0.03108510747551918
[15/24] Train loss=0.035398706793785095
[20/24] Train loss=0.05256309360265732
Test set avg_accuracy=87.11% avg_sensitivity=89.97%, avg_specificity=86.25% avg_auc=0.9452
Fold[5] Epoch: 103 [103/150 (69%)] Train loss=0.049524 Test loss=0.992152 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.06308715790510178
[5/24] Train loss=0.039650872349739075
[10/24] Train loss=0.05086778849363327
[15/24] Train loss=0.02896897867321968
[20/24] Train loss=0.036607276648283005
Test set avg_accuracy=89.38% avg_sensitivity=84.55%, avg_specificity=90.82% avg_auc=0.9454
Fold[5] Epoch: 104 [104/150 (69%)] Train loss=0.045809 Test loss=0.669335 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.05119563266634941
[5/24] Train loss=0.04192747175693512
[10/24] Train loss=0.0337015762925148
[15/24] Train loss=0.029583409428596497
[20/24] Train loss=0.05586311221122742
Test set avg_accuracy=88.07% avg_sensitivity=85.23%, avg_specificity=88.93% avg_auc=0.9446
Fold[5] Epoch: 105 [105/150 (70%)] Train loss=0.038306 Test loss=0.709209 Current lr=[0.000388134363466264]

[0/24] Train loss=0.04640384018421173
[5/24] Train loss=0.021611616015434265
[10/24] Train loss=0.028007833287119865
[15/24] Train loss=0.021376334130764008
[20/24] Train loss=0.030769703909754753
Test set avg_accuracy=87.89% avg_sensitivity=87.20%, avg_specificity=88.10% avg_auc=0.9427
Fold[5] Epoch: 106 [106/150 (71%)] Train loss=0.029457 Test loss=0.882117 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.034206219017505646
[5/24] Train loss=0.02044205740094185
[10/24] Train loss=0.0222000814974308
[15/24] Train loss=0.02001735381782055
[20/24] Train loss=0.022706633433699608
Test set avg_accuracy=86.91% avg_sensitivity=89.46%, avg_specificity=86.15% avg_auc=0.9437
Fold[5] Epoch: 107 [107/150 (71%)] Train loss=0.027964 Test loss=0.998123 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.04072558879852295
[5/24] Train loss=0.036981500685214996
[10/24] Train loss=0.02482186257839203
[15/24] Train loss=0.020598342642188072
[20/24] Train loss=0.02625216729938984
Test set avg_accuracy=87.20% avg_sensitivity=86.53%, avg_specificity=87.40% avg_auc=0.9414
Fold[5] Epoch: 108 [108/150 (72%)] Train loss=0.031388 Test loss=0.856743 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.037053532898426056
[5/24] Train loss=0.045231569558382034
[10/24] Train loss=0.03205924853682518
[15/24] Train loss=0.020641662180423737
[20/24] Train loss=0.0323050320148468
Test set avg_accuracy=84.90% avg_sensitivity=88.44%, avg_specificity=83.83% avg_auc=0.9380
Fold[5] Epoch: 109 [109/150 (73%)] Train loss=0.036080 Test loss=0.972018 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.04193495213985443
[5/24] Train loss=0.031118718907237053
[10/24] Train loss=0.02496819943189621
[15/24] Train loss=0.020163102075457573
[20/24] Train loss=0.01956072263419628
Test set avg_accuracy=88.39% avg_sensitivity=84.72%, avg_specificity=89.49% avg_auc=0.9418
Fold[5] Epoch: 110 [110/150 (73%)] Train loss=0.031071 Test loss=0.752489 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.02564883790910244
[5/24] Train loss=0.02905326522886753
[10/24] Train loss=0.02399297058582306
[15/24] Train loss=0.01920173689723015
[20/24] Train loss=0.021063655614852905
Test set avg_accuracy=87.37% avg_sensitivity=88.67%, avg_specificity=86.98% avg_auc=0.9443
Fold[5] Epoch: 111 [111/150 (74%)] Train loss=0.025393 Test loss=0.971353 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.0407383106648922
[5/24] Train loss=0.02743273787200451
[10/24] Train loss=0.027722833678126335
[15/24] Train loss=0.018994173035025597
[20/24] Train loss=0.017981017008423805
Test set avg_accuracy=87.94% avg_sensitivity=87.49%, avg_specificity=88.08% avg_auc=0.9440
Fold[5] Epoch: 112 [112/150 (75%)] Train loss=0.029811 Test loss=0.795705 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.028619224205613136
[5/24] Train loss=0.020718522369861603
[10/24] Train loss=0.026723451912403107
[15/24] Train loss=0.015415945090353489
[20/24] Train loss=0.01601923070847988
Test set avg_accuracy=87.47% avg_sensitivity=89.29%, avg_specificity=86.93% avg_auc=0.9462
Fold[5] Epoch: 113 [113/150 (75%)] Train loss=0.024397 Test loss=0.953010 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.035071905702352524
[5/24] Train loss=0.022416068241000175
[10/24] Train loss=0.022085901349782944
[15/24] Train loss=0.023068610578775406
[20/24] Train loss=0.01658444106578827
Test set avg_accuracy=87.89% avg_sensitivity=86.92%, avg_specificity=88.18% avg_auc=0.9456
Fold[5] Epoch: 114 [114/150 (76%)] Train loss=0.024729 Test loss=0.764782 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.02290959842503071
[5/24] Train loss=0.015896152704954147
[10/24] Train loss=0.020476914942264557
[15/24] Train loss=0.015388470143079758
[20/24] Train loss=0.01791887730360031
Test set avg_accuracy=87.36% avg_sensitivity=88.50%, avg_specificity=87.01% avg_auc=0.9438
Fold[5] Epoch: 115 [115/150 (77%)] Train loss=0.022191 Test loss=0.908255 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.03007657639682293
[5/24] Train loss=0.03454417735338211
[10/24] Train loss=0.023170195519924164
[15/24] Train loss=0.01870112307369709
[20/24] Train loss=0.02413780242204666
Test set avg_accuracy=87.99% avg_sensitivity=86.87%, avg_specificity=88.33% avg_auc=0.9436
Fold[5] Epoch: 116 [116/150 (77%)] Train loss=0.024607 Test loss=0.786938 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.020473381504416466
[5/24] Train loss=0.021613460034132004
[10/24] Train loss=0.01805020682513714
[15/24] Train loss=0.016057569533586502
[20/24] Train loss=0.019357407465577126
Test set avg_accuracy=87.27% avg_sensitivity=87.88%, avg_specificity=87.08% avg_auc=0.9460
Fold[5] Epoch: 117 [117/150 (78%)] Train loss=0.021739 Test loss=0.928442 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.029482640326023102
[5/24] Train loss=0.018568003550171852
[10/24] Train loss=0.025186477228999138
[15/24] Train loss=0.01495714858174324
[20/24] Train loss=0.016110161319375038
Test set avg_accuracy=88.12% avg_sensitivity=86.98%, avg_specificity=88.47% avg_auc=0.9455
Fold[5] Epoch: 118 [118/150 (79%)] Train loss=0.023714 Test loss=0.830663 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.027754586189985275
[5/24] Train loss=0.015749851241707802
[10/24] Train loss=0.01457289233803749
[15/24] Train loss=0.023811284452676773
[20/24] Train loss=0.014043970964848995
Test set avg_accuracy=87.89% avg_sensitivity=88.16%, avg_specificity=87.81% avg_auc=0.9455
Fold[5] Epoch: 119 [119/150 (79%)] Train loss=0.019383 Test loss=0.876873 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.024579012766480446
[5/24] Train loss=0.01791294477880001
[10/24] Train loss=0.01806742139160633
[15/24] Train loss=0.014914710074663162
[20/24] Train loss=0.03775394335389137
Test set avg_accuracy=88.36% avg_sensitivity=85.91%, avg_specificity=89.10% avg_auc=0.9462
Fold[5] Epoch: 120 [120/150 (80%)] Train loss=0.022342 Test loss=0.792657 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.014177790842950344
[5/24] Train loss=0.024603625759482384
[10/24] Train loss=0.016249453648924828
[15/24] Train loss=0.013840983621776104
[20/24] Train loss=0.01318766176700592
Test set avg_accuracy=87.67% avg_sensitivity=87.20%, avg_specificity=87.81% avg_auc=0.9453
Fold[5] Epoch: 121 [121/150 (81%)] Train loss=0.017664 Test loss=0.882247 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.01595299318432808
[5/24] Train loss=0.01995822973549366
[10/24] Train loss=0.01406603492796421
[15/24] Train loss=0.011083757504820824
[20/24] Train loss=0.012044506147503853
Test set avg_accuracy=87.40% avg_sensitivity=88.11%, avg_specificity=87.18% avg_auc=0.9458
Fold[5] Epoch: 122 [122/150 (81%)] Train loss=0.015599 Test loss=0.983825 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.02311919443309307
[5/24] Train loss=0.01734611764550209
[10/24] Train loss=0.020188594236969948
[15/24] Train loss=0.015207679010927677
[20/24] Train loss=0.019016440957784653
Test set avg_accuracy=86.42% avg_sensitivity=89.74%, avg_specificity=85.42% avg_auc=0.9422
Fold[5] Epoch: 123 [123/150 (82%)] Train loss=0.022430 Test loss=1.092375 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.030987782403826714
[5/24] Train loss=0.04001642391085625
[10/24] Train loss=0.01995878480374813
[15/24] Train loss=0.01363944448530674
[20/24] Train loss=0.013130667619407177
Test set avg_accuracy=87.68% avg_sensitivity=87.20%, avg_specificity=87.83% avg_auc=0.9441
Fold[5] Epoch: 124 [124/150 (83%)] Train loss=0.022739 Test loss=0.770674 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.016834672540426254
[5/24] Train loss=0.012620210647583008
[10/24] Train loss=0.018077878281474113
[15/24] Train loss=0.012620612047612667
[20/24] Train loss=0.013020891696214676
Test set avg_accuracy=87.94% avg_sensitivity=87.49%, avg_specificity=88.08% avg_auc=0.9451
Fold[5] Epoch: 125 [125/150 (83%)] Train loss=0.019154 Test loss=0.819851 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.019185520708560944
[5/24] Train loss=0.014702880755066872
[10/24] Train loss=0.012642459943890572
[15/24] Train loss=0.017576461657881737
[20/24] Train loss=0.026059729978442192
Test set avg_accuracy=87.47% avg_sensitivity=88.39%, avg_specificity=87.20% avg_auc=0.9456
Fold[5] Epoch: 126 [126/150 (84%)] Train loss=0.016905 Test loss=0.945428 Current lr=[0.000123057953306828]

[0/24] Train loss=0.0225716270506382
[5/24] Train loss=0.01932315155863762
[10/24] Train loss=0.0199558287858963
[15/24] Train loss=0.012945610098540783
[20/24] Train loss=0.012362230569124222
Test set avg_accuracy=87.86% avg_sensitivity=87.60%, avg_specificity=87.94% avg_auc=0.9456
Fold[5] Epoch: 127 [127/150 (85%)] Train loss=0.018427 Test loss=0.926446 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.014056541956961155
[5/24] Train loss=0.011832541786134243
[10/24] Train loss=0.013138700276613235
[15/24] Train loss=0.009326488710939884
[20/24] Train loss=0.018131710588932037
Test set avg_accuracy=88.15% avg_sensitivity=87.49%, avg_specificity=88.35% avg_auc=0.9458
Fold[5] Epoch: 128 [128/150 (85%)] Train loss=0.013965 Test loss=0.912597 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.012283866293728352
[5/24] Train loss=0.010444659739732742
[10/24] Train loss=0.012919911183416843
[15/24] Train loss=0.0135341202840209
[20/24] Train loss=0.0108944708481431
Test set avg_accuracy=87.37% avg_sensitivity=88.22%, avg_specificity=87.11% avg_auc=0.9463
Fold[5] Epoch: 129 [129/150 (86%)] Train loss=0.015829 Test loss=1.062989 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.01791464537382126
[5/24] Train loss=0.013280327431857586
[10/24] Train loss=0.013424933888018131
[15/24] Train loss=0.012382440268993378
[20/24] Train loss=0.012571289204061031
Test set avg_accuracy=87.19% avg_sensitivity=88.39%, avg_specificity=86.83% avg_auc=0.9455
Fold[5] Epoch: 130 [130/150 (87%)] Train loss=0.015874 Test loss=1.093705 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.01697634533047676
[5/24] Train loss=0.016822004690766335
[10/24] Train loss=0.013482673093676567
[15/24] Train loss=0.01370162982493639
[20/24] Train loss=0.012293138541281223
Test set avg_accuracy=87.70% avg_sensitivity=87.03%, avg_specificity=87.89% avg_auc=0.9454
Fold[5] Epoch: 131 [131/150 (87%)] Train loss=0.017828 Test loss=0.978873 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.0166156142950058
[5/24] Train loss=0.013961389660835266
[10/24] Train loss=0.0247646551579237
[15/24] Train loss=0.017066236585378647
[20/24] Train loss=0.01195866335183382
Test set avg_accuracy=87.86% avg_sensitivity=86.53%, avg_specificity=88.27% avg_auc=0.9456
Fold[5] Epoch: 132 [132/150 (88%)] Train loss=0.015350 Test loss=0.939494 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.013286318629980087
[5/24] Train loss=0.010840529575943947
[10/24] Train loss=0.012465155683457851
[15/24] Train loss=0.012690307572484016
[20/24] Train loss=0.01388489454984665
Test set avg_accuracy=87.54% avg_sensitivity=88.22%, avg_specificity=87.33% avg_auc=0.9458
Fold[5] Epoch: 133 [133/150 (89%)] Train loss=0.013515 Test loss=0.998131 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.01209377869963646
[5/24] Train loss=0.013490223325788975
[10/24] Train loss=0.010786384344100952
[15/24] Train loss=0.012848458252847195
[20/24] Train loss=0.011294332332909107
Test set avg_accuracy=87.43% avg_sensitivity=88.28%, avg_specificity=87.18% avg_auc=0.9455
Fold[5] Epoch: 134 [134/150 (89%)] Train loss=0.014810 Test loss=1.007660 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.01530914381146431
[5/24] Train loss=0.015572846867144108
[10/24] Train loss=0.01342221163213253
[15/24] Train loss=0.010869811289012432
[20/24] Train loss=0.012189694680273533
Test set avg_accuracy=87.47% avg_sensitivity=87.66%, avg_specificity=87.42% avg_auc=0.9454
Fold[5] Epoch: 135 [135/150 (90%)] Train loss=0.015988 Test loss=0.964307 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.023318136110901833
[5/24] Train loss=0.01632113941013813
[10/24] Train loss=0.015801433473825455
[15/24] Train loss=0.014432750642299652
[20/24] Train loss=0.014693064615130424
Test set avg_accuracy=88.03% avg_sensitivity=86.92%, avg_specificity=88.37% avg_auc=0.9455
Fold[5] Epoch: 136 [136/150 (91%)] Train loss=0.018930 Test loss=0.902497 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.017437396571040154
[5/24] Train loss=0.015806730836629868
[10/24] Train loss=0.014092395082116127
[15/24] Train loss=0.011279061436653137
[20/24] Train loss=0.010351779870688915
Test set avg_accuracy=88.11% avg_sensitivity=86.36%, avg_specificity=88.64% avg_auc=0.9456
Fold[5] Epoch: 137 [137/150 (91%)] Train loss=0.015546 Test loss=0.854417 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.013139408081769943
[5/24] Train loss=0.013973996974527836
[10/24] Train loss=0.01586875133216381
[15/24] Train loss=0.010775911621749401
[20/24] Train loss=0.00958796963095665
Test set avg_accuracy=88.14% avg_sensitivity=86.70%, avg_specificity=88.57% avg_auc=0.9458
Fold[5] Epoch: 138 [138/150 (92%)] Train loss=0.014246 Test loss=0.876850 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.01154849212616682
[5/24] Train loss=0.015341119840741158
[10/24] Train loss=0.010579858906567097
[15/24] Train loss=0.010069466196000576
[20/24] Train loss=0.011811892502009869
Test set avg_accuracy=87.79% avg_sensitivity=87.37%, avg_specificity=87.91% avg_auc=0.9459
Fold[5] Epoch: 139 [139/150 (93%)] Train loss=0.014476 Test loss=0.921386 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.011157471686601639
[5/24] Train loss=0.01071631908416748
[10/24] Train loss=0.008249996230006218
[15/24] Train loss=0.010745285078883171
[20/24] Train loss=0.007704755291342735
Test set avg_accuracy=87.47% avg_sensitivity=87.54%, avg_specificity=87.45% avg_auc=0.9459
Fold[5] Epoch: 140 [140/150 (93%)] Train loss=0.012533 Test loss=0.965679 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.013001944869756699
[5/24] Train loss=0.024388059973716736
[10/24] Train loss=0.00933302752673626
[15/24] Train loss=0.0068764397874474525
[20/24] Train loss=0.008827202022075653
Test set avg_accuracy=87.32% avg_sensitivity=87.82%, avg_specificity=87.17% avg_auc=0.9457
Fold[5] Epoch: 141 [141/150 (94%)] Train loss=0.013780 Test loss=0.993200 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.016706546768546104
[5/24] Train loss=0.011363701894879341
[10/24] Train loss=0.014134380035102367
[15/24] Train loss=0.009363719262182713
[20/24] Train loss=0.009326876141130924
Test set avg_accuracy=87.30% avg_sensitivity=87.77%, avg_specificity=87.17% avg_auc=0.9457
Fold[5] Epoch: 142 [142/150 (95%)] Train loss=0.013412 Test loss=1.004559 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.013623298145830631
[5/24] Train loss=0.016116883605718613
[10/24] Train loss=0.013158408924937248
[15/24] Train loss=0.014624124392867088
[20/24] Train loss=0.012123826891183853
Test set avg_accuracy=87.30% avg_sensitivity=87.43%, avg_specificity=87.27% avg_auc=0.9457
Fold[5] Epoch: 143 [143/150 (95%)] Train loss=0.015272 Test loss=0.985908 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.034651417285203934
[5/24] Train loss=0.015607872046530247
[10/24] Train loss=0.01747909002006054
[15/24] Train loss=0.025645218789577484
[20/24] Train loss=0.013877054676413536
Test set avg_accuracy=87.42% avg_sensitivity=87.43%, avg_specificity=87.42% avg_auc=0.9457
Fold[5] Epoch: 144 [144/150 (96%)] Train loss=0.019154 Test loss=0.974904 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.025064919143915176
[5/24] Train loss=0.021879618987441063
[10/24] Train loss=0.019859779626131058
[15/24] Train loss=0.01950480416417122
[20/24] Train loss=0.01557726040482521
Test set avg_accuracy=87.70% avg_sensitivity=87.37%, avg_specificity=87.79% avg_auc=0.9457
Fold[5] Epoch: 145 [145/150 (97%)] Train loss=0.020762 Test loss=0.962160 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.017651934176683426
[5/24] Train loss=0.013404821045696735
[10/24] Train loss=0.014420941472053528
[15/24] Train loss=0.0308359544724226
[20/24] Train loss=0.01211141049861908
Test set avg_accuracy=87.75% avg_sensitivity=87.37%, avg_specificity=87.86% avg_auc=0.9457
Fold[5] Epoch: 146 [146/150 (97%)] Train loss=0.017427 Test loss=0.955099 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.016931412741541862
[5/24] Train loss=0.012581191956996918
[10/24] Train loss=0.014187456108629704
[15/24] Train loss=0.023345284163951874
[20/24] Train loss=0.012021136470139027
Test set avg_accuracy=87.75% avg_sensitivity=87.37%, avg_specificity=87.86% avg_auc=0.9456
Fold[5] Epoch: 147 [147/150 (98%)] Train loss=0.016045 Test loss=0.953556 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.013327773660421371
[5/24] Train loss=0.010227533988654613
[10/24] Train loss=0.010575504042208195
[15/24] Train loss=0.010556116700172424
[20/24] Train loss=0.009690936654806137
Test set avg_accuracy=87.75% avg_sensitivity=87.37%, avg_specificity=87.86% avg_auc=0.9456
Fold[5] Epoch: 148 [148/150 (99%)] Train loss=0.012125 Test loss=0.953399 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.014421992003917694
[5/24] Train loss=0.010478317737579346
[10/24] Train loss=0.008472285233438015
[15/24] Train loss=0.009916845709085464
[20/24] Train loss=0.009721826761960983
Test set avg_accuracy=87.75% avg_sensitivity=87.37%, avg_specificity=87.86% avg_auc=0.9457
Fold[5] Epoch: 149 [149/150 (99%)] Train loss=0.012612 Test loss=0.953945 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.011374563910067081
[5/24] Train loss=0.014446241781115532
[10/24] Train loss=0.014021588489413261
[15/24] Train loss=0.008208511397242546
[20/24] Train loss=0.00795274879783392
Test set avg_accuracy=87.73% avg_sensitivity=87.37%, avg_specificity=87.84% avg_auc=0.9456
Fold[5] Epoch: 150 [150/150 (100%)] Train loss=0.013897 Test loss=0.954282 Current lr=[4.388541022775342e-09]

Fold[5] Result: acc=90.56% sen=85.29%, spe=92.14%, auc=0.95!
Fold[5] Avg_overlap=0.65%(0.21805335262661654)
[0/24] Train loss=1.385319709777832
[5/24] Train loss=1.33681321144104
[10/24] Train loss=1.2962347269058228
[15/24] Train loss=1.1467899084091187
[20/24] Train loss=1.0302209854125977
Test set avg_accuracy=71.61% avg_sensitivity=21.72%, avg_specificity=89.33% avg_auc=0.7277
Best model saved!! Metric=0.7276807135310929!!
Fold[6] Epoch: 1 [1/150 (1%)] Train loss=1.222603 Test loss=0.661438 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.9083022475242615
[5/24] Train loss=0.9441787004470825
[10/24] Train loss=1.0074117183685303
[15/24] Train loss=0.9461464285850525
[20/24] Train loss=0.8933920860290527
Test set avg_accuracy=78.28% avg_sensitivity=70.23%, avg_specificity=81.14% avg_auc=0.8376
Best model saved!! Metric=0.8376219833434116!!
Fold[6] Epoch: 2 [2/150 (1%)] Train loss=0.950623 Test loss=0.579768 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.8128213882446289
[5/24] Train loss=0.8412726521492004
[10/24] Train loss=0.8990990519523621
[15/24] Train loss=0.8226587772369385
[20/24] Train loss=0.8080062866210938
Test set avg_accuracy=79.95% avg_sensitivity=76.59%, avg_specificity=81.14% avg_auc=0.8503
Best model saved!! Metric=0.8503037000298842!!
Fold[6] Epoch: 3 [3/150 (2%)] Train loss=0.845205 Test loss=0.558632 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.7098551988601685
[5/24] Train loss=0.7503668069839478
[10/24] Train loss=0.8177052140235901
[15/24] Train loss=0.7027497887611389
[20/24] Train loss=0.7670214772224426
Test set avg_accuracy=78.66% avg_sensitivity=89.41%, avg_specificity=74.84% avg_auc=0.8827
Best model saved!! Metric=0.8827436317171073!!
Fold[6] Epoch: 4 [4/150 (3%)] Train loss=0.763597 Test loss=0.657131 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.7636306881904602
[5/24] Train loss=0.7735564112663269
[10/24] Train loss=0.8126596212387085
[15/24] Train loss=0.7312211990356445
[20/24] Train loss=0.692247211933136
Test set avg_accuracy=82.06% avg_sensitivity=81.76%, avg_specificity=82.16% avg_auc=0.9002
Best model saved!! Metric=0.9001932301743527!!
Fold[6] Epoch: 5 [5/150 (3%)] Train loss=0.771648 Test loss=0.471603 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.6713854074478149
[5/24] Train loss=0.6988104581832886
[10/24] Train loss=0.7676853537559509
[15/24] Train loss=0.7029210925102234
[20/24] Train loss=0.6782300472259521
Test set avg_accuracy=78.72% avg_sensitivity=93.69%, avg_specificity=73.41% avg_auc=0.9119
Best model saved!! Metric=0.9118990625758504!!
Fold[6] Epoch: 6 [6/150 (4%)] Train loss=0.708503 Test loss=0.645610 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.7375734448432922
[5/24] Train loss=0.6881444454193115
[10/24] Train loss=0.7381525635719299
[15/24] Train loss=0.6978461742401123
[20/24] Train loss=0.667110800743103
Test set avg_accuracy=83.19% avg_sensitivity=86.98%, avg_specificity=81.85% avg_auc=0.9167
Best model saved!! Metric=0.9167187243511408!!
Fold[6] Epoch: 7 [7/150 (5%)] Train loss=0.727102 Test loss=0.455257 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.6595308184623718
[5/24] Train loss=0.6696915030479431
[10/24] Train loss=0.7365906834602356
[15/24] Train loss=0.7354971766471863
[20/24] Train loss=0.6823723912239075
Test set avg_accuracy=83.76% avg_sensitivity=88.52%, avg_specificity=82.07% avg_auc=0.9239
Best model saved!! Metric=0.9238747122066473!!
Fold[6] Epoch: 8 [8/150 (5%)] Train loss=0.710061 Test loss=0.443787 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.6866909265518188
[5/24] Train loss=0.7049652338027954
[10/24] Train loss=0.7391388416290283
[15/24] Train loss=0.712470531463623
[20/24] Train loss=0.7081915140151978
Test set avg_accuracy=84.53% avg_sensitivity=87.87%, avg_specificity=83.35% avg_auc=0.9315
Best model saved!! Metric=0.9314508590657887!!
Fold[6] Epoch: 9 [9/150 (6%)] Train loss=0.711428 Test loss=0.390738 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.709503710269928
[5/24] Train loss=0.6565660238265991
[10/24] Train loss=0.7380917072296143
[15/24] Train loss=0.6897338032722473
[20/24] Train loss=0.6633347272872925
Test set avg_accuracy=87.99% avg_sensitivity=79.52%, avg_specificity=91.00% avg_auc=0.9300
Fold[6] Epoch: 10 [10/150 (7%)] Train loss=0.699379 Test loss=0.326497 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.641417384147644
[5/24] Train loss=0.6412575840950012
[10/24] Train loss=0.7442676424980164
[15/24] Train loss=0.7462248206138611
[20/24] Train loss=0.6304629445075989
Test set avg_accuracy=86.59% avg_sensitivity=86.48%, avg_specificity=86.63% avg_auc=0.9340
Best model saved!! Metric=0.933972689971673!!
Fold[6] Epoch: 11 [11/150 (7%)] Train loss=0.671006 Test loss=0.369584 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.5919966697692871
[5/24] Train loss=0.6080010533332825
[10/24] Train loss=0.7534425854682922
[15/24] Train loss=0.7181552648544312
[20/24] Train loss=0.6078651547431946
Test set avg_accuracy=86.41% avg_sensitivity=87.77%, avg_specificity=85.92% avg_auc=0.9352
Best model saved!! Metric=0.9351998015435966!!
Fold[6] Epoch: 12 [12/150 (8%)] Train loss=0.651656 Test loss=0.386270 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6568647027015686
[5/24] Train loss=0.6629705429077148
[10/24] Train loss=0.7086742520332336
[15/24] Train loss=0.7096728086471558
[20/24] Train loss=0.584440290927887
Test set avg_accuracy=86.69% avg_sensitivity=88.97%, avg_specificity=85.89% avg_auc=0.9430
Best model saved!! Metric=0.9430245888816712!!
Fold[6] Epoch: 13 [13/150 (9%)] Train loss=0.655461 Test loss=0.354754 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.6566891074180603
[5/24] Train loss=0.6306089162826538
[10/24] Train loss=0.7287222743034363
[15/24] Train loss=0.6941323280334473
[20/24] Train loss=0.5742773413658142
Test set avg_accuracy=87.94% avg_sensitivity=86.48%, avg_specificity=88.46% avg_auc=0.9419
Fold[6] Epoch: 14 [14/150 (9%)] Train loss=0.654048 Test loss=0.318220 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.584229588508606
[5/24] Train loss=0.5684208273887634
[10/24] Train loss=0.6865965723991394
[15/24] Train loss=0.684867262840271
[20/24] Train loss=0.6005898118019104
Test set avg_accuracy=87.55% avg_sensitivity=86.98%, avg_specificity=87.76% avg_auc=0.9404
Fold[6] Epoch: 15 [15/150 (10%)] Train loss=0.630532 Test loss=0.339134 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.5675147175788879
[5/24] Train loss=0.5526642799377441
[10/24] Train loss=0.6789615750312805
[15/24] Train loss=0.6845465898513794
[20/24] Train loss=0.5822359919548035
Test set avg_accuracy=85.03% avg_sensitivity=91.90%, avg_specificity=82.59% avg_auc=0.9429
Fold[6] Epoch: 16 [16/150 (11%)] Train loss=0.613857 Test loss=0.420009 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.6519001722335815
[5/24] Train loss=0.6014352440834045
[10/24] Train loss=0.7036870718002319
[15/24] Train loss=0.7026724815368652
[20/24] Train loss=0.5629801154136658
Test set avg_accuracy=87.77% avg_sensitivity=87.77%, avg_specificity=87.77% avg_auc=0.9394
Fold[6] Epoch: 17 [17/150 (11%)] Train loss=0.627059 Test loss=0.330521 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.5529465079307556
[5/24] Train loss=0.5241876840591431
[10/24] Train loss=0.696904182434082
[15/24] Train loss=0.6517454385757446
[20/24] Train loss=0.586043655872345
Test set avg_accuracy=83.22% avg_sensitivity=92.89%, avg_specificity=79.78% avg_auc=0.9410
Fold[6] Epoch: 18 [18/150 (12%)] Train loss=0.609603 Test loss=0.450530 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.642516553401947
[5/24] Train loss=0.5673137307167053
[10/24] Train loss=0.6668545007705688
[15/24] Train loss=0.622160792350769
[20/24] Train loss=0.5460860729217529
Test set avg_accuracy=88.76% avg_sensitivity=83.60%, avg_specificity=90.60% avg_auc=0.9409
Fold[6] Epoch: 19 [19/150 (13%)] Train loss=0.609735 Test loss=0.299315 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.5752288103103638
[5/24] Train loss=0.530571699142456
[10/24] Train loss=0.638359010219574
[15/24] Train loss=0.6652477383613586
[20/24] Train loss=0.5395093560218811
Test set avg_accuracy=86.58% avg_sensitivity=89.91%, avg_specificity=85.39% avg_auc=0.9395
Fold[6] Epoch: 20 [20/150 (13%)] Train loss=0.586364 Test loss=0.371388 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.5695436596870422
[5/24] Train loss=0.5126703381538391
[10/24] Train loss=0.6745017766952515
[15/24] Train loss=0.6051914691925049
[20/24] Train loss=0.5617241859436035
Test set avg_accuracy=88.66% avg_sensitivity=83.20%, avg_specificity=90.60% avg_auc=0.9389
Fold[6] Epoch: 21 [21/150 (14%)] Train loss=0.584254 Test loss=0.309522 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.5545947551727295
[5/24] Train loss=0.5405179858207703
[10/24] Train loss=0.618845522403717
[15/24] Train loss=0.6198636293411255
[20/24] Train loss=0.5252744555473328
Test set avg_accuracy=87.57% avg_sensitivity=87.28%, avg_specificity=87.67% avg_auc=0.9415
Fold[6] Epoch: 22 [22/150 (15%)] Train loss=0.571519 Test loss=0.333610 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.5202348232269287
[5/24] Train loss=0.5527918934822083
[10/24] Train loss=0.6031492352485657
[15/24] Train loss=0.6106823086738586
[20/24] Train loss=0.5082428455352783
Test set avg_accuracy=86.98% avg_sensitivity=89.66%, avg_specificity=86.03% avg_auc=0.9476
Best model saved!! Metric=0.9476100349210312!!
Fold[6] Epoch: 23 [23/150 (15%)] Train loss=0.561975 Test loss=0.341711 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5383417010307312
[5/24] Train loss=0.5358132719993591
[10/24] Train loss=0.6334176063537598
[15/24] Train loss=0.5972574353218079
[20/24] Train loss=0.46966320276260376
Test set avg_accuracy=88.12% avg_sensitivity=84.49%, avg_specificity=89.41% avg_auc=0.9314
Fold[6] Epoch: 24 [24/150 (16%)] Train loss=0.566286 Test loss=0.332978 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.5546686053276062
[5/24] Train loss=0.49417805671691895
[10/24] Train loss=0.5833916068077087
[15/24] Train loss=0.5622219443321228
[20/24] Train loss=0.5090115070343018
Test set avg_accuracy=86.00% avg_sensitivity=89.71%, avg_specificity=84.69% avg_auc=0.9362
Fold[6] Epoch: 25 [25/150 (17%)] Train loss=0.549229 Test loss=0.407080 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5042762160301208
[5/24] Train loss=0.5645250678062439
[10/24] Train loss=0.5867669582366943
[15/24] Train loss=0.5724801421165466
[20/24] Train loss=0.49241095781326294
Test set avg_accuracy=85.81% avg_sensitivity=91.00%, avg_specificity=83.96% avg_auc=0.9440
Fold[6] Epoch: 26 [26/150 (17%)] Train loss=0.549830 Test loss=0.361144 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5438170433044434
[5/24] Train loss=0.5290149450302124
[10/24] Train loss=0.6208528280258179
[15/24] Train loss=0.5485957264900208
[20/24] Train loss=0.45939016342163086
Test set avg_accuracy=88.74% avg_sensitivity=80.42%, avg_specificity=91.69% avg_auc=0.9386
Fold[6] Epoch: 27 [27/150 (18%)] Train loss=0.541888 Test loss=0.291399 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5471622943878174
[5/24] Train loss=0.46899110078811646
[10/24] Train loss=0.5819411873817444
[15/24] Train loss=0.5666476488113403
[20/24] Train loss=0.46534544229507446
Test set avg_accuracy=87.20% avg_sensitivity=89.51%, avg_specificity=86.38% avg_auc=0.9363
Fold[6] Epoch: 28 [28/150 (19%)] Train loss=0.528954 Test loss=0.368445 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5131844282150269
[5/24] Train loss=0.5331438183784485
[10/24] Train loss=0.5483608245849609
[15/24] Train loss=0.5405083894729614
[20/24] Train loss=0.4545685052871704
Test set avg_accuracy=89.24% avg_sensitivity=82.95%, avg_specificity=91.48% avg_auc=0.9443
Fold[6] Epoch: 29 [29/150 (19%)] Train loss=0.532062 Test loss=0.282603 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.49531930685043335
[5/24] Train loss=0.46583253145217896
[10/24] Train loss=0.5418152213096619
[15/24] Train loss=0.4921554923057556
[20/24] Train loss=0.4240003228187561
Test set avg_accuracy=88.55% avg_sensitivity=84.44%, avg_specificity=90.01% avg_auc=0.9385
Fold[6] Epoch: 30 [30/150 (20%)] Train loss=0.507041 Test loss=0.320327 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.4940013587474823
[5/24] Train loss=0.4636527895927429
[10/24] Train loss=0.5376349687576294
[15/24] Train loss=0.4930896461009979
[20/24] Train loss=0.3988350033760071
Test set avg_accuracy=88.23% avg_sensitivity=87.87%, avg_specificity=88.36% avg_auc=0.9398
Fold[6] Epoch: 31 [31/150 (21%)] Train loss=0.488807 Test loss=0.350053 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.4346681237220764
[5/24] Train loss=0.43288564682006836
[10/24] Train loss=0.4972393214702606
[15/24] Train loss=0.4896946847438812
[20/24] Train loss=0.4526595175266266
Test set avg_accuracy=83.84% avg_sensitivity=92.59%, avg_specificity=80.73% avg_auc=0.9387
Fold[6] Epoch: 32 [32/150 (21%)] Train loss=0.471231 Test loss=0.479165 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.5079143643379211
[5/24] Train loss=0.5327733755111694
[10/24] Train loss=0.5326110124588013
[15/24] Train loss=0.47020623087882996
[20/24] Train loss=0.41759350895881653
Test set avg_accuracy=86.71% avg_sensitivity=90.46%, avg_specificity=85.37% avg_auc=0.9428
Fold[6] Epoch: 33 [33/150 (22%)] Train loss=0.495488 Test loss=0.378380 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.48762190341949463
[5/24] Train loss=0.46424075961112976
[10/24] Train loss=0.5245679020881653
[15/24] Train loss=0.4807444214820862
[20/24] Train loss=0.4026256799697876
Test set avg_accuracy=86.61% avg_sensitivity=89.12%, avg_specificity=85.73% avg_auc=0.9395
Fold[6] Epoch: 34 [34/150 (23%)] Train loss=0.480237 Test loss=0.367276 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.4946640133857727
[5/24] Train loss=0.4669504463672638
[10/24] Train loss=0.5239661931991577
[15/24] Train loss=0.44186875224113464
[20/24] Train loss=0.42743659019470215
Test set avg_accuracy=88.95% avg_sensitivity=82.21%, avg_specificity=91.34% avg_auc=0.9466
Fold[6] Epoch: 35 [35/150 (23%)] Train loss=0.470977 Test loss=0.302081 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.4433988928794861
[5/24] Train loss=0.41523477435112
[10/24] Train loss=0.5143248438835144
[15/24] Train loss=0.3756885528564453
[20/24] Train loss=0.41183778643608093
Test set avg_accuracy=88.72% avg_sensitivity=83.90%, avg_specificity=90.44% avg_auc=0.9402
Fold[6] Epoch: 36 [36/150 (24%)] Train loss=0.426955 Test loss=0.323461 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.37218916416168213
[5/24] Train loss=0.37509942054748535
[10/24] Train loss=0.4553956687450409
[15/24] Train loss=0.34923768043518066
[20/24] Train loss=0.3550199568271637
Test set avg_accuracy=86.28% avg_sensitivity=82.21%, avg_specificity=87.72% avg_auc=0.9279
Fold[6] Epoch: 37 [37/150 (25%)] Train loss=0.405840 Test loss=0.366410 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.41605979204177856
[5/24] Train loss=0.31998181343078613
[10/24] Train loss=0.46781572699546814
[15/24] Train loss=0.4143027067184448
[20/24] Train loss=0.34540095925331116
Test set avg_accuracy=83.92% avg_sensitivity=91.85%, avg_specificity=81.10% avg_auc=0.9441
Fold[6] Epoch: 38 [38/150 (25%)] Train loss=0.397277 Test loss=0.440006 Current lr=[0.000944367614404117]

[0/24] Train loss=0.41882583498954773
[5/24] Train loss=0.43253692984580994
[10/24] Train loss=0.45271286368370056
[15/24] Train loss=0.37254494428634644
[20/24] Train loss=0.3730454444885254
Test set avg_accuracy=87.40% avg_sensitivity=85.59%, avg_specificity=88.04% avg_auc=0.9356
Fold[6] Epoch: 39 [39/150 (26%)] Train loss=0.414648 Test loss=0.363134 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.3852778375148773
[5/24] Train loss=0.3374626338481903
[10/24] Train loss=0.45732319355010986
[15/24] Train loss=0.40367424488067627
[20/24] Train loss=0.31014302372932434
Test set avg_accuracy=83.32% avg_sensitivity=91.25%, avg_specificity=80.50% avg_auc=0.9274
Fold[6] Epoch: 40 [40/150 (27%)] Train loss=0.371269 Test loss=0.526098 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.40608713030815125
[5/24] Train loss=0.38544055819511414
[10/24] Train loss=0.40078070759773254
[15/24] Train loss=0.3435070812702179
[20/24] Train loss=0.31037288904190063
Test set avg_accuracy=87.66% avg_sensitivity=86.78%, avg_specificity=87.97% avg_auc=0.9359
Fold[6] Epoch: 41 [41/150 (27%)] Train loss=0.370736 Test loss=0.379067 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.3166472911834717
[5/24] Train loss=0.31786954402923584
[10/24] Train loss=0.39241233468055725
[15/24] Train loss=0.2581348121166229
[20/24] Train loss=0.3098636865615845
Test set avg_accuracy=85.49% avg_sensitivity=88.47%, avg_specificity=84.44% avg_auc=0.9301
Fold[6] Epoch: 42 [42/150 (28%)] Train loss=0.330047 Test loss=0.463925 Current lr=[0.000989780311725182]

[0/24] Train loss=0.3274872899055481
[5/24] Train loss=0.28468313813209534
[10/24] Train loss=0.340690553188324
[15/24] Train loss=0.2780872881412506
[20/24] Train loss=0.2781907618045807
Test set avg_accuracy=86.82% avg_sensitivity=85.24%, avg_specificity=87.39% avg_auc=0.9320
Fold[6] Epoch: 43 [43/150 (29%)] Train loss=0.319011 Test loss=0.391034 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.2905232310295105
[5/24] Train loss=0.30945974588394165
[10/24] Train loss=0.28855788707733154
[15/24] Train loss=0.29717734456062317
[20/24] Train loss=0.2719366252422333
Test set avg_accuracy=83.18% avg_sensitivity=90.71%, avg_specificity=80.50% avg_auc=0.9345
Fold[6] Epoch: 44 [44/150 (29%)] Train loss=0.300311 Test loss=0.499995 Current lr=[0.000998924125869967]

[0/24] Train loss=0.3260694444179535
[5/24] Train loss=0.28368252515792847
[10/24] Train loss=0.36624324321746826
[15/24] Train loss=0.2716905176639557
[20/24] Train loss=0.3393290936946869
Test set avg_accuracy=81.33% avg_sensitivity=92.94%, avg_specificity=77.21% avg_auc=0.9342
Fold[6] Epoch: 45 [45/150 (30%)] Train loss=0.317615 Test loss=0.544208 Current lr=[0.000999999611458977]

[0/24] Train loss=0.38324958086013794
[5/24] Train loss=0.30155786871910095
[10/24] Train loss=0.3609089255332947
[15/24] Train loss=0.27949807047843933
[20/24] Train loss=0.28414639830589294
Test set avg_accuracy=86.33% avg_sensitivity=85.54%, avg_specificity=86.61% avg_auc=0.9314
Fold[6] Epoch: 46 [46/150 (31%)] Train loss=0.324727 Test loss=0.429663 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.29971784353256226
[5/24] Train loss=0.25903159379959106
[10/24] Train loss=0.28499218821525574
[15/24] Train loss=0.2521870732307434
[20/24] Train loss=0.19341720640659332
Test set avg_accuracy=85.05% avg_sensitivity=86.88%, avg_specificity=84.40% avg_auc=0.9320
Fold[6] Epoch: 47 [47/150 (31%)] Train loss=0.281320 Test loss=0.500652 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.32403549551963806
[5/24] Train loss=0.34894028306007385
[10/24] Train loss=0.35154157876968384
[15/24] Train loss=0.260749489068985
[20/24] Train loss=0.21466805040836334
Test set avg_accuracy=87.21% avg_sensitivity=84.49%, avg_specificity=88.18% avg_auc=0.9338
Fold[6] Epoch: 48 [48/150 (32%)] Train loss=0.292154 Test loss=0.451104 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.2460213601589203
[5/24] Train loss=0.22268608212471008
[10/24] Train loss=0.3174845576286316
[15/24] Train loss=0.20839346945285797
[20/24] Train loss=0.22801293432712555
Test set avg_accuracy=86.41% avg_sensitivity=85.69%, avg_specificity=86.66% avg_auc=0.9353
Fold[6] Epoch: 49 [49/150 (33%)] Train loss=0.260026 Test loss=0.502310 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.26221105456352234
[5/24] Train loss=0.22791513800621033
[10/24] Train loss=0.2760392129421234
[15/24] Train loss=0.2069919854402542
[20/24] Train loss=0.18755954504013062
Test set avg_accuracy=85.72% avg_sensitivity=88.92%, avg_specificity=84.58% avg_auc=0.9355
Fold[6] Epoch: 50 [50/150 (33%)] Train loss=0.249369 Test loss=0.441435 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.2543695271015167
[5/24] Train loss=0.1865725964307785
[10/24] Train loss=0.32316502928733826
[15/24] Train loss=0.23461391031742096
[20/24] Train loss=0.2140273153781891
Test set avg_accuracy=88.45% avg_sensitivity=82.41%, avg_specificity=90.60% avg_auc=0.9345
Fold[6] Epoch: 51 [51/150 (34%)] Train loss=0.249610 Test loss=0.373549 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.3063335120677948
[5/24] Train loss=0.1670970916748047
[10/24] Train loss=0.2853342890739441
[15/24] Train loss=0.24985504150390625
[20/24] Train loss=0.18549102544784546
Test set avg_accuracy=84.61% avg_sensitivity=87.62%, avg_specificity=83.54% avg_auc=0.9313
Fold[6] Epoch: 52 [52/150 (35%)] Train loss=0.234822 Test loss=0.495959 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.254517525434494
[5/24] Train loss=0.2231578677892685
[10/24] Train loss=0.3858296573162079
[15/24] Train loss=0.27876248955726624
[20/24] Train loss=0.24716448783874512
Test set avg_accuracy=86.67% avg_sensitivity=84.59%, avg_specificity=87.40% avg_auc=0.9334
Fold[6] Epoch: 53 [53/150 (35%)] Train loss=0.272945 Test loss=0.421554 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.2609265148639679
[5/24] Train loss=0.2182234525680542
[10/24] Train loss=0.24862442910671234
[15/24] Train loss=0.2190386950969696
[20/24] Train loss=0.16966137290000916
Test set avg_accuracy=83.09% avg_sensitivity=90.31%, avg_specificity=80.52% avg_auc=0.9355
Fold[6] Epoch: 54 [54/150 (36%)] Train loss=0.229395 Test loss=0.545106 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.228805810213089
[5/24] Train loss=0.21553924679756165
[10/24] Train loss=0.2272539883852005
[15/24] Train loss=0.1897192746400833
[20/24] Train loss=0.22296760976314545
Test set avg_accuracy=85.96% avg_sensitivity=87.38%, avg_specificity=85.46% avg_auc=0.9350
Fold[6] Epoch: 55 [55/150 (37%)] Train loss=0.223644 Test loss=0.497018 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.21354499459266663
[5/24] Train loss=0.18369156122207642
[10/24] Train loss=0.2528698146343231
[15/24] Train loss=0.19440343976020813
[20/24] Train loss=0.15964755415916443
Test set avg_accuracy=87.20% avg_sensitivity=84.49%, avg_specificity=88.16% avg_auc=0.9347
Fold[6] Epoch: 56 [56/150 (37%)] Train loss=0.206069 Test loss=0.505153 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.17515912652015686
[5/24] Train loss=0.1779821515083313
[10/24] Train loss=0.21207396686077118
[15/24] Train loss=0.17569224536418915
[20/24] Train loss=0.1430860310792923
Test set avg_accuracy=87.47% avg_sensitivity=85.34%, avg_specificity=88.23% avg_auc=0.9387
Fold[6] Epoch: 57 [57/150 (38%)] Train loss=0.175557 Test loss=0.557929 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.166643425822258
[5/24] Train loss=0.1536387801170349
[10/24] Train loss=0.15803353488445282
[15/24] Train loss=0.12345132231712341
[20/24] Train loss=0.11917387694120407
Test set avg_accuracy=87.72% avg_sensitivity=86.53%, avg_specificity=88.14% avg_auc=0.9423
Fold[6] Epoch: 58 [58/150 (39%)] Train loss=0.150775 Test loss=0.606358 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.13085076212882996
[5/24] Train loss=0.11124511063098907
[10/24] Train loss=0.1427997350692749
[15/24] Train loss=0.13187991082668304
[20/24] Train loss=0.1139378473162651
Test set avg_accuracy=87.55% avg_sensitivity=84.84%, avg_specificity=88.51% avg_auc=0.9415
Fold[6] Epoch: 59 [59/150 (39%)] Train loss=0.131298 Test loss=0.561595 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.13245104253292084
[5/24] Train loss=0.12423907220363617
[10/24] Train loss=0.14405831694602966
[15/24] Train loss=0.13443878293037415
[20/24] Train loss=0.11053148657083511
Test set avg_accuracy=86.90% avg_sensitivity=85.98%, avg_specificity=87.23% avg_auc=0.9372
Fold[6] Epoch: 60 [60/150 (40%)] Train loss=0.133191 Test loss=0.656928 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.1093086376786232
[5/24] Train loss=0.13357585668563843
[10/24] Train loss=0.12375357002019882
[15/24] Train loss=0.12111116200685501
[20/24] Train loss=0.10181135684251785
Test set avg_accuracy=87.64% avg_sensitivity=84.54%, avg_specificity=88.74% avg_auc=0.9318
Fold[6] Epoch: 61 [61/150 (41%)] Train loss=0.130148 Test loss=0.690830 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.2285463958978653
[5/24] Train loss=0.14409799873828888
[10/24] Train loss=0.1949482411146164
[15/24] Train loss=0.17933358252048492
[20/24] Train loss=0.1303921788930893
Test set avg_accuracy=82.38% avg_sensitivity=89.51%, avg_specificity=79.85% avg_auc=0.9268
Fold[6] Epoch: 62 [62/150 (41%)] Train loss=0.168850 Test loss=0.858850 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.22873809933662415
[5/24] Train loss=0.16541488468647003
[10/24] Train loss=0.19781924784183502
[15/24] Train loss=0.1896846741437912
[20/24] Train loss=0.15393133461475372
Test set avg_accuracy=85.85% avg_sensitivity=89.02%, avg_specificity=84.72% avg_auc=0.9353
Fold[6] Epoch: 63 [63/150 (42%)] Train loss=0.187292 Test loss=0.677074 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.17218579351902008
[5/24] Train loss=0.14207608997821808
[10/24] Train loss=0.16860845685005188
[15/24] Train loss=0.1587742567062378
[20/24] Train loss=0.13882847130298615
Test set avg_accuracy=85.95% avg_sensitivity=86.23%, avg_specificity=85.85% avg_auc=0.9372
Fold[6] Epoch: 64 [64/150 (43%)] Train loss=0.154274 Test loss=0.623675 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.16450361907482147
[5/24] Train loss=0.14986148476600647
[10/24] Train loss=0.1797298789024353
[15/24] Train loss=0.15035022795200348
[20/24] Train loss=0.1347249448299408
Test set avg_accuracy=87.93% avg_sensitivity=83.30%, avg_specificity=89.57% avg_auc=0.9366
Fold[6] Epoch: 65 [65/150 (43%)] Train loss=0.144450 Test loss=0.607824 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.11076690256595612
[5/24] Train loss=0.11496138572692871
[10/24] Train loss=0.1385098248720169
[15/24] Train loss=0.13699300587177277
[20/24] Train loss=0.09863022714853287
Test set avg_accuracy=87.43% avg_sensitivity=83.55%, avg_specificity=88.81% avg_auc=0.9390
Fold[6] Epoch: 66 [66/150 (44%)] Train loss=0.123734 Test loss=0.618644 Current lr=[0.000904142181093812]

[0/24] Train loss=0.08985836803913116
[5/24] Train loss=0.0991930216550827
[10/24] Train loss=0.11943992972373962
[15/24] Train loss=0.14991892874240875
[20/24] Train loss=0.09652511775493622
Test set avg_accuracy=87.08% avg_sensitivity=82.65%, avg_specificity=88.66% avg_auc=0.9349
Fold[6] Epoch: 67 [67/150 (45%)] Train loss=0.120759 Test loss=0.577493 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.10379737615585327
[5/24] Train loss=0.12352704256772995
[10/24] Train loss=0.11652760952711105
[15/24] Train loss=0.11525619029998779
[20/24] Train loss=0.07230236381292343
Test set avg_accuracy=87.17% avg_sensitivity=84.99%, avg_specificity=87.95% avg_auc=0.9386
Fold[6] Epoch: 68 [68/150 (45%)] Train loss=0.104255 Test loss=0.596006 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.15043291449546814
[5/24] Train loss=0.09780253469944
[10/24] Train loss=0.12386924773454666
[15/24] Train loss=0.2866717278957367
[20/24] Train loss=0.13265348970890045
Test set avg_accuracy=84.64% avg_sensitivity=89.41%, avg_specificity=82.94% avg_auc=0.9323
Fold[6] Epoch: 69 [69/150 (46%)] Train loss=0.134383 Test loss=0.748446 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.16096077859401703
[5/24] Train loss=0.1356867253780365
[10/24] Train loss=0.1443413496017456
[15/24] Train loss=0.12452517449855804
[20/24] Train loss=0.09866762161254883
Test set avg_accuracy=86.07% avg_sensitivity=88.62%, avg_specificity=85.16% avg_auc=0.9369
Fold[6] Epoch: 70 [70/150 (47%)] Train loss=0.136642 Test loss=0.617139 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.13791100680828094
[5/24] Train loss=0.13651463389396667
[10/24] Train loss=0.1072889193892479
[15/24] Train loss=0.11855781078338623
[20/24] Train loss=0.10561446100473404
Test set avg_accuracy=86.69% avg_sensitivity=86.48%, avg_specificity=86.77% avg_auc=0.9360
Fold[6] Epoch: 71 [71/150 (47%)] Train loss=0.122839 Test loss=0.624566 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.0960065945982933
[5/24] Train loss=0.08987341821193695
[10/24] Train loss=0.11154109984636307
[15/24] Train loss=0.10473113507032394
[20/24] Train loss=0.08240331709384918
Test set avg_accuracy=87.25% avg_sensitivity=84.49%, avg_specificity=88.23% avg_auc=0.9338
Fold[6] Epoch: 72 [72/150 (48%)] Train loss=0.099968 Test loss=0.681173 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.08386021107435226
[5/24] Train loss=0.0979241207242012
[10/24] Train loss=0.12602145969867706
[15/24] Train loss=0.09109653532505035
[20/24] Train loss=0.0741414725780487
Test set avg_accuracy=84.60% avg_sensitivity=89.17%, avg_specificity=82.97% avg_auc=0.9318
Fold[6] Epoch: 73 [73/150 (49%)] Train loss=0.097133 Test loss=0.814430 Current lr=[0.000834102481048427]

[0/24] Train loss=0.11158464103937149
[5/24] Train loss=0.10838396847248077
[10/24] Train loss=0.10833345353603363
[15/24] Train loss=0.12352080643177032
[20/24] Train loss=0.09278860688209534
Test set avg_accuracy=84.99% avg_sensitivity=88.47%, avg_specificity=83.75% avg_auc=0.9292
Fold[6] Epoch: 74 [74/150 (49%)] Train loss=0.115187 Test loss=0.826704 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.12665432691574097
[5/24] Train loss=0.13124488294124603
[10/24] Train loss=0.12398236989974976
[15/24] Train loss=0.10178424417972565
[20/24] Train loss=0.08568867295980453
Test set avg_accuracy=86.54% avg_sensitivity=82.70%, avg_specificity=87.90% avg_auc=0.9284
Fold[6] Epoch: 75 [75/150 (50%)] Train loss=0.111953 Test loss=0.648182 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.11239355057477951
[5/24] Train loss=0.1206374391913414
[10/24] Train loss=0.11866671591997147
[15/24] Train loss=0.09824567288160324
[20/24] Train loss=0.07305712252855301
Test set avg_accuracy=86.22% avg_sensitivity=84.15%, avg_specificity=86.96% avg_auc=0.9313
Fold[6] Epoch: 76 [76/150 (51%)] Train loss=0.099988 Test loss=0.713661 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.09838148206472397
[5/24] Train loss=0.07586052268743515
[10/24] Train loss=0.08965839445590973
[15/24] Train loss=0.07485191524028778
[20/24] Train loss=0.06369566917419434
Test set avg_accuracy=84.71% avg_sensitivity=88.17%, avg_specificity=83.49% avg_auc=0.9313
Fold[6] Epoch: 77 [77/150 (51%)] Train loss=0.088585 Test loss=0.764651 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.10073596239089966
[5/24] Train loss=0.10248184949159622
[10/24] Train loss=0.09063997864723206
[15/24] Train loss=0.11739630997180939
[20/24] Train loss=0.1035592183470726
Test set avg_accuracy=85.72% avg_sensitivity=87.62%, avg_specificity=85.04% avg_auc=0.9368
Fold[6] Epoch: 78 [78/150 (52%)] Train loss=0.102214 Test loss=0.748623 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.08795265108346939
[5/24] Train loss=0.07746867090463638
[10/24] Train loss=0.10031911730766296
[15/24] Train loss=0.08430531620979309
[20/24] Train loss=0.08386602252721786
Test set avg_accuracy=86.90% avg_sensitivity=85.83%, avg_specificity=87.28% avg_auc=0.9350
Fold[6] Epoch: 79 [79/150 (53%)] Train loss=0.093215 Test loss=0.727749 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.0923856869339943
[5/24] Train loss=0.07148081809282303
[10/24] Train loss=0.08025538176298141
[15/24] Train loss=0.08792416006326675
[20/24] Train loss=0.07800315320491791
Test set avg_accuracy=86.64% avg_sensitivity=87.18%, avg_specificity=86.45% avg_auc=0.9388
Fold[6] Epoch: 80 [80/150 (53%)] Train loss=0.084756 Test loss=0.727743 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.08801586180925369
[5/24] Train loss=0.08338254690170288
[10/24] Train loss=0.07383904606103897
[15/24] Train loss=0.10109525173902512
[20/24] Train loss=0.08839046955108643
Test set avg_accuracy=87.98% avg_sensitivity=84.44%, avg_specificity=89.24% avg_auc=0.9384
Fold[6] Epoch: 81 [81/150 (54%)] Train loss=0.084710 Test loss=0.721365 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.07321162521839142
[5/24] Train loss=0.05677379295229912
[10/24] Train loss=0.07614017277956009
[15/24] Train loss=0.0914066806435585
[20/24] Train loss=0.07116884738206863
Test set avg_accuracy=86.94% avg_sensitivity=87.77%, avg_specificity=86.64% avg_auc=0.9384
Fold[6] Epoch: 82 [82/150 (55%)] Train loss=0.072530 Test loss=0.826583 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.07537328451871872
[5/24] Train loss=0.06916087865829468
[10/24] Train loss=0.05941502004861832
[15/24] Train loss=0.0809408500790596
[20/24] Train loss=0.05460616946220398
Test set avg_accuracy=86.84% avg_sensitivity=83.70%, avg_specificity=87.95% avg_auc=0.9353
Fold[6] Epoch: 83 [83/150 (55%)] Train loss=0.072788 Test loss=0.738652 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.06132032349705696
[5/24] Train loss=0.04997609555721283
[10/24] Train loss=0.0615561343729496
[15/24] Train loss=0.07286986708641052
[20/24] Train loss=0.057986631989479065
Test set avg_accuracy=85.98% avg_sensitivity=86.73%, avg_specificity=85.71% avg_auc=0.9340
Fold[6] Epoch: 84 [84/150 (56%)] Train loss=0.061300 Test loss=0.902067 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.07650746405124664
[5/24] Train loss=0.04620677977800369
[10/24] Train loss=0.06075294315814972
[15/24] Train loss=0.05692477524280548
[20/24] Train loss=0.05100637674331665
Test set avg_accuracy=87.03% avg_sensitivity=84.49%, avg_specificity=87.93% avg_auc=0.9334
Fold[6] Epoch: 85 [85/150 (57%)] Train loss=0.064544 Test loss=0.703846 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.05327589064836502
[5/24] Train loss=0.04402673989534378
[10/24] Train loss=0.05623913183808327
[15/24] Train loss=0.06742645800113678
[20/24] Train loss=0.044873036444187164
Test set avg_accuracy=86.47% avg_sensitivity=88.17%, avg_specificity=85.87% avg_auc=0.9362
Fold[6] Epoch: 86 [86/150 (57%)] Train loss=0.054075 Test loss=0.863290 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.06686928123235703
[5/24] Train loss=0.050881437957286835
[10/24] Train loss=0.0593944676220417
[15/24] Train loss=0.063656285405159
[20/24] Train loss=0.059673890471458435
Test set avg_accuracy=87.49% avg_sensitivity=84.94%, avg_specificity=88.39% avg_auc=0.9365
Fold[6] Epoch: 87 [87/150 (58%)] Train loss=0.061703 Test loss=0.766611 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.051530346274375916
[5/24] Train loss=0.043116968125104904
[10/24] Train loss=0.04930434003472328
[15/24] Train loss=0.059749457985162735
[20/24] Train loss=0.039471257477998734
Test set avg_accuracy=86.72% avg_sensitivity=85.59%, avg_specificity=87.12% avg_auc=0.9361
Fold[6] Epoch: 88 [88/150 (59%)] Train loss=0.056257 Test loss=0.922411 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.04379235953092575
[5/24] Train loss=0.039946336299180984
[10/24] Train loss=0.03945201262831688
[15/24] Train loss=0.044624123722314835
[20/24] Train loss=0.03549300134181976
Test set avg_accuracy=86.67% avg_sensitivity=87.87%, avg_specificity=86.24% avg_auc=0.9380
Fold[6] Epoch: 89 [89/150 (59%)] Train loss=0.047301 Test loss=0.954717 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.04863229766488075
[5/24] Train loss=0.04073427990078926
[10/24] Train loss=0.04789513349533081
[15/24] Train loss=0.04578854888677597
[20/24] Train loss=0.04573267325758934
Test set avg_accuracy=86.85% avg_sensitivity=85.88%, avg_specificity=87.19% avg_auc=0.9351
Fold[6] Epoch: 90 [90/150 (60%)] Train loss=0.051036 Test loss=0.965236 Current lr=[0.00061065423442182]

[0/24] Train loss=0.03770217299461365
[5/24] Train loss=0.03631412237882614
[10/24] Train loss=0.04861292988061905
[15/24] Train loss=0.042166054248809814
[20/24] Train loss=0.03715734928846359
Test set avg_accuracy=86.85% avg_sensitivity=84.59%, avg_specificity=87.65% avg_auc=0.9369
Fold[6] Epoch: 91 [91/150 (61%)] Train loss=0.043439 Test loss=0.945020 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.03532332926988602
[5/24] Train loss=0.029337532818317413
[10/24] Train loss=0.0492769256234169
[15/24] Train loss=0.04262729734182358
[20/24] Train loss=0.059967800974845886
Test set avg_accuracy=86.60% avg_sensitivity=88.37%, avg_specificity=85.97% avg_auc=0.9348
Fold[6] Epoch: 92 [92/150 (61%)] Train loss=0.039943 Test loss=1.037946 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.041182033717632294
[5/24] Train loss=0.03378372639417648
[10/24] Train loss=0.04264715313911438
[15/24] Train loss=0.043235424906015396
[20/24] Train loss=0.03984910994768143
Test set avg_accuracy=86.99% avg_sensitivity=86.98%, avg_specificity=87.00% avg_auc=0.9361
Fold[6] Epoch: 93 [93/150 (62%)] Train loss=0.042294 Test loss=0.936331 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.03724341467022896
[5/24] Train loss=0.06743048876523972
[10/24] Train loss=0.04218878597021103
[15/24] Train loss=0.04234196990728378
[20/24] Train loss=0.03368734195828438
Test set avg_accuracy=85.57% avg_sensitivity=88.47%, avg_specificity=84.54% avg_auc=0.9368
Fold[6] Epoch: 94 [94/150 (63%)] Train loss=0.044778 Test loss=1.023252 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.06567922979593277
[5/24] Train loss=0.049149543046951294
[10/24] Train loss=0.048974644392728806
[15/24] Train loss=0.048424843698740005
[20/24] Train loss=0.04149571433663368
Test set avg_accuracy=86.58% avg_sensitivity=85.14%, avg_specificity=87.09% avg_auc=0.9350
Fold[6] Epoch: 95 [95/150 (63%)] Train loss=0.048298 Test loss=1.049203 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.03274282440543175
[5/24] Train loss=0.040882211178541183
[10/24] Train loss=0.03435974195599556
[15/24] Train loss=0.04048651456832886
[20/24] Train loss=0.027638882398605347
Test set avg_accuracy=86.78% avg_sensitivity=86.23%, avg_specificity=86.98% avg_auc=0.9319
Fold[6] Epoch: 96 [96/150 (64%)] Train loss=0.041400 Test loss=1.057179 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.030700523406267166
[5/24] Train loss=0.025509072467684746
[10/24] Train loss=0.03994730859994888
[15/24] Train loss=0.03886500373482704
[20/24] Train loss=0.03202565014362335
Test set avg_accuracy=85.17% avg_sensitivity=87.28%, avg_specificity=84.42% avg_auc=0.9286
Fold[6] Epoch: 97 [97/150 (65%)] Train loss=0.045140 Test loss=1.097269 Current lr=[0.000506858408304961]

[0/24] Train loss=0.04405691847205162
[5/24] Train loss=0.038148630410432816
[10/24] Train loss=0.0704074427485466
[15/24] Train loss=0.04138911888003349
[20/24] Train loss=0.10298048704862595
Test set avg_accuracy=86.50% avg_sensitivity=87.57%, avg_specificity=86.12% avg_auc=0.9339
Fold[6] Epoch: 98 [98/150 (65%)] Train loss=0.050094 Test loss=1.083442 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.06788640469312668
[5/24] Train loss=0.070820152759552
[10/24] Train loss=0.05022192373871803
[15/24] Train loss=0.053794290870428085
[20/24] Train loss=0.04104967042803764
Test set avg_accuracy=86.61% avg_sensitivity=87.52%, avg_specificity=86.29% avg_auc=0.9338
Fold[6] Epoch: 99 [99/150 (66%)] Train loss=0.058919 Test loss=0.979512 Current lr=[0.000476946990416354]

[0/24] Train loss=0.06437832117080688
[5/24] Train loss=0.08457399904727936
[10/24] Train loss=0.04308285191655159
[15/24] Train loss=0.0353698655962944
[20/24] Train loss=0.04400625452399254
Test set avg_accuracy=87.67% avg_sensitivity=84.79%, avg_specificity=88.69% avg_auc=0.9326
Fold[6] Epoch: 100 [100/150 (67%)] Train loss=0.053491 Test loss=0.927854 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.04370269179344177
[5/24] Train loss=0.04495786875486374
[10/24] Train loss=0.046372152864933014
[15/24] Train loss=0.05584993585944176
[20/24] Train loss=0.034512653946876526
Test set avg_accuracy=87.54% avg_sensitivity=84.94%, avg_specificity=88.46% avg_auc=0.9320
Fold[6] Epoch: 101 [101/150 (67%)] Train loss=0.044708 Test loss=0.895669 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.043631039559841156
[5/24] Train loss=0.02748393639922142
[10/24] Train loss=0.031845103949308395
[15/24] Train loss=0.035785481333732605
[20/24] Train loss=0.03941338509321213
Test set avg_accuracy=85.81% avg_sensitivity=89.07%, avg_specificity=84.65% avg_auc=0.9380
Fold[6] Epoch: 102 [102/150 (68%)] Train loss=0.044444 Test loss=1.282619 Current lr=[0.000432267999769856]

[0/24] Train loss=0.05099395662546158
[5/24] Train loss=0.050530217587947845
[10/24] Train loss=0.06864190101623535
[15/24] Train loss=0.03809560835361481
[20/24] Train loss=0.04521234333515167
Test set avg_accuracy=86.95% avg_sensitivity=85.83%, avg_specificity=87.35% avg_auc=0.9351
Fold[6] Epoch: 103 [103/150 (69%)] Train loss=0.050241 Test loss=0.959373 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.05717474967241287
[5/24] Train loss=0.04195946455001831
[10/24] Train loss=0.04745696112513542
[15/24] Train loss=0.05594697222113609
[20/24] Train loss=0.03412124142050743
Test set avg_accuracy=86.74% avg_sensitivity=84.29%, avg_specificity=87.61% avg_auc=0.9314
Fold[6] Epoch: 104 [104/150 (69%)] Train loss=0.046743 Test loss=0.924290 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.06460168957710266
[5/24] Train loss=0.028097011148929596
[10/24] Train loss=0.05247185751795769
[15/24] Train loss=0.03926880657672882
[20/24] Train loss=0.03173410892486572
Test set avg_accuracy=85.72% avg_sensitivity=87.43%, avg_specificity=85.11% avg_auc=0.9334
Fold[6] Epoch: 105 [105/150 (70%)] Train loss=0.040628 Test loss=1.081199 Current lr=[0.000388134363466264]

[0/24] Train loss=0.06007019057869911
[5/24] Train loss=0.03025994636118412
[10/24] Train loss=0.032884251326322556
[15/24] Train loss=0.03551124408841133
[20/24] Train loss=0.04326443746685982
Test set avg_accuracy=86.68% avg_sensitivity=88.22%, avg_specificity=86.13% avg_auc=0.9366
Fold[6] Epoch: 106 [106/150 (71%)] Train loss=0.041056 Test loss=1.268608 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.049191974103450775
[5/24] Train loss=0.03851892054080963
[10/24] Train loss=0.03785015642642975
[15/24] Train loss=0.03722142428159714
[20/24] Train loss=0.03502291068434715
Test set avg_accuracy=87.89% avg_sensitivity=86.13%, avg_specificity=88.51% avg_auc=0.9384
Fold[6] Epoch: 107 [107/150 (71%)] Train loss=0.042357 Test loss=0.928472 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.05234790965914726
[5/24] Train loss=0.02769586443901062
[10/24] Train loss=0.03218528628349304
[15/24] Train loss=0.03652670606970787
[20/24] Train loss=0.04115990921854973
Test set avg_accuracy=86.78% avg_sensitivity=88.02%, avg_specificity=86.34% avg_auc=0.9359
Fold[6] Epoch: 108 [108/150 (72%)] Train loss=0.037599 Test loss=1.048519 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.03615589067339897
[5/24] Train loss=0.04253692924976349
[10/24] Train loss=0.044959355145692825
[15/24] Train loss=0.028216293081641197
[20/24] Train loss=0.05153319984674454
Test set avg_accuracy=87.41% avg_sensitivity=83.55%, avg_specificity=88.78% avg_auc=0.9329
Fold[6] Epoch: 109 [109/150 (73%)] Train loss=0.036470 Test loss=0.941871 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.03359093889594078
[5/24] Train loss=0.030171269550919533
[10/24] Train loss=0.029485078528523445
[15/24] Train loss=0.02498725801706314
[20/24] Train loss=0.03646772727370262
Test set avg_accuracy=86.54% avg_sensitivity=85.44%, avg_specificity=86.93% avg_auc=0.9344
Fold[6] Epoch: 110 [110/150 (73%)] Train loss=0.032344 Test loss=1.166461 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.023523161187767982
[5/24] Train loss=0.02325781062245369
[10/24] Train loss=0.02782112918794155
[15/24] Train loss=0.020532522350549698
[20/24] Train loss=0.02689470164477825
Test set avg_accuracy=87.03% avg_sensitivity=86.98%, avg_specificity=87.05% avg_auc=0.9368
Fold[6] Epoch: 111 [111/150 (74%)] Train loss=0.026869 Test loss=1.131880 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.02151397615671158
[5/24] Train loss=0.01949782855808735
[10/24] Train loss=0.021931296214461327
[15/24] Train loss=0.02203819900751114
[20/24] Train loss=0.017253965139389038
Test set avg_accuracy=86.89% avg_sensitivity=86.83%, avg_specificity=86.91% avg_auc=0.9360
Fold[6] Epoch: 112 [112/150 (75%)] Train loss=0.021851 Test loss=1.276253 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.015308058820664883
[5/24] Train loss=0.017604589462280273
[10/24] Train loss=0.01669301837682724
[15/24] Train loss=0.01877572573721409
[20/24] Train loss=0.02200668677687645
Test set avg_accuracy=86.24% avg_sensitivity=88.47%, avg_specificity=85.44% avg_auc=0.9372
Fold[6] Epoch: 113 [113/150 (75%)] Train loss=0.021392 Test loss=1.349774 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.023105178028345108
[5/24] Train loss=0.020666787400841713
[10/24] Train loss=0.020448021590709686
[15/24] Train loss=0.020737875252962112
[20/24] Train loss=0.018205108121037483
Test set avg_accuracy=86.90% avg_sensitivity=85.98%, avg_specificity=87.23% avg_auc=0.9362
Fold[6] Epoch: 114 [114/150 (76%)] Train loss=0.022019 Test loss=1.166228 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.018051736056804657
[5/24] Train loss=0.01524791307747364
[10/24] Train loss=0.015791306272149086
[15/24] Train loss=0.01923116110265255
[20/24] Train loss=0.01996239461004734
Test set avg_accuracy=86.71% avg_sensitivity=87.92%, avg_specificity=86.27% avg_auc=0.9368
Fold[6] Epoch: 115 [115/150 (77%)] Train loss=0.022181 Test loss=1.432557 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.020130615681409836
[5/24] Train loss=0.024574099108576775
[10/24] Train loss=0.032766640186309814
[15/24] Train loss=0.028919007629156113
[20/24] Train loss=0.028532350435853004
Test set avg_accuracy=86.54% avg_sensitivity=86.93%, avg_specificity=86.40% avg_auc=0.9288
Fold[6] Epoch: 116 [116/150 (77%)] Train loss=0.028736 Test loss=1.202769 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.05510421469807625
[5/24] Train loss=0.023027092218399048
[10/24] Train loss=0.030898895114660263
[15/24] Train loss=0.02640254981815815
[20/24] Train loss=0.028928328305482864
Test set avg_accuracy=86.69% avg_sensitivity=85.39%, avg_specificity=87.16% avg_auc=0.9315
Fold[6] Epoch: 117 [117/150 (78%)] Train loss=0.030983 Test loss=1.137838 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.02143023908138275
[5/24] Train loss=0.02189481444656849
[10/24] Train loss=0.021669434383511543
[15/24] Train loss=0.023030230775475502
[20/24] Train loss=0.018110547214746475
Test set avg_accuracy=86.68% avg_sensitivity=87.72%, avg_specificity=86.31% avg_auc=0.9349
Fold[6] Epoch: 118 [118/150 (79%)] Train loss=0.025414 Test loss=1.283487 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.026538973674178123
[5/24] Train loss=0.022542111575603485
[10/24] Train loss=0.025759071111679077
[15/24] Train loss=0.022624453529715538
[20/24] Train loss=0.05910510942339897
Test set avg_accuracy=87.36% avg_sensitivity=84.89%, avg_specificity=88.23% avg_auc=0.9331
Fold[6] Epoch: 119 [119/150 (79%)] Train loss=0.027809 Test loss=1.078014 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.01899777725338936
[5/24] Train loss=0.016423022374510765
[10/24] Train loss=0.027559060603380203
[15/24] Train loss=0.01815013214945793
[20/24] Train loss=0.015712855383753777
Test set avg_accuracy=87.04% avg_sensitivity=87.13%, avg_specificity=87.01% avg_auc=0.9387
Fold[6] Epoch: 120 [120/150 (80%)] Train loss=0.022560 Test loss=1.343343 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.04163481667637825
[5/24] Train loss=0.025241121649742126
[10/24] Train loss=0.02389654889702797
[15/24] Train loss=0.024206139147281647
[20/24] Train loss=0.019339988008141518
Test set avg_accuracy=87.28% avg_sensitivity=85.83%, avg_specificity=87.79% avg_auc=0.9362
Fold[6] Epoch: 121 [121/150 (81%)] Train loss=0.025729 Test loss=1.227864 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.05033660680055618
[5/24] Train loss=0.017004922032356262
[10/24] Train loss=0.016670862212777138
[15/24] Train loss=0.036142755299806595
[20/24] Train loss=0.022395307198166847
Test set avg_accuracy=87.08% avg_sensitivity=87.33%, avg_specificity=87.00% avg_auc=0.9353
Fold[6] Epoch: 122 [122/150 (81%)] Train loss=0.023076 Test loss=1.298681 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.025184912607073784
[5/24] Train loss=0.01975150592625141
[10/24] Train loss=0.022543316707015038
[15/24] Train loss=0.021684397011995316
[20/24] Train loss=0.02564997598528862
Test set avg_accuracy=87.07% avg_sensitivity=85.88%, avg_specificity=87.49% avg_auc=0.9351
Fold[6] Epoch: 123 [123/150 (82%)] Train loss=0.025086 Test loss=1.159299 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.022018970921635628
[5/24] Train loss=0.0150300869718194
[10/24] Train loss=0.022627579048275948
[15/24] Train loss=0.01401248574256897
[20/24] Train loss=0.017359813675284386
Test set avg_accuracy=87.11% avg_sensitivity=85.69%, avg_specificity=87.61% avg_auc=0.9353
Fold[6] Epoch: 124 [124/150 (83%)] Train loss=0.020070 Test loss=1.107249 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.017157694324851036
[5/24] Train loss=0.020679237321019173
[10/24] Train loss=0.0157603919506073
[15/24] Train loss=0.012523051351308823
[20/24] Train loss=0.04510178044438362
Test set avg_accuracy=86.29% avg_sensitivity=87.92%, avg_specificity=85.71% avg_auc=0.9370
Fold[6] Epoch: 125 [125/150 (83%)] Train loss=0.022634 Test loss=1.551922 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.022867748513817787
[5/24] Train loss=0.019155200570821762
[10/24] Train loss=0.022536838427186012
[15/24] Train loss=0.018915899097919464
[20/24] Train loss=0.019135674461722374
Test set avg_accuracy=86.90% avg_sensitivity=86.53%, avg_specificity=87.03% avg_auc=0.9350
Fold[6] Epoch: 126 [126/150 (84%)] Train loss=0.020753 Test loss=1.438307 Current lr=[0.000123057953306828]

[0/24] Train loss=0.024805186316370964
[5/24] Train loss=0.018493834882974625
[10/24] Train loss=0.012887183576822281
[15/24] Train loss=0.01642012409865856
[20/24] Train loss=0.017734557390213013
Test set avg_accuracy=87.21% avg_sensitivity=85.93%, avg_specificity=87.67% avg_auc=0.9345
Fold[6] Epoch: 127 [127/150 (85%)] Train loss=0.016595 Test loss=1.394701 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.012581165879964828
[5/24] Train loss=0.010444572195410728
[10/24] Train loss=0.016284368932247162
[15/24] Train loss=0.03522518277168274
[20/24] Train loss=0.010792730376124382
Test set avg_accuracy=87.15% avg_sensitivity=87.62%, avg_specificity=86.98% avg_auc=0.9368
Fold[6] Epoch: 128 [128/150 (85%)] Train loss=0.016246 Test loss=1.492642 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.02004690282046795
[5/24] Train loss=0.015224190428853035
[10/24] Train loss=0.015675395727157593
[15/24] Train loss=0.015205830335617065
[20/24] Train loss=0.013633033260703087
Test set avg_accuracy=87.06% avg_sensitivity=87.52%, avg_specificity=86.89% avg_auc=0.9366
Fold[6] Epoch: 129 [129/150 (86%)] Train loss=0.016741 Test loss=1.520468 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.01911311224102974
[5/24] Train loss=0.017633598297834396
[10/24] Train loss=0.017591526731848717
[15/24] Train loss=0.015885159373283386
[20/24] Train loss=0.018059827387332916
Test set avg_accuracy=87.15% avg_sensitivity=85.93%, avg_specificity=87.58% avg_auc=0.9357
Fold[6] Epoch: 130 [130/150 (87%)] Train loss=0.019195 Test loss=1.395316 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.014936614781618118
[5/24] Train loss=0.015495562925934792
[10/24] Train loss=0.019912226125597954
[15/24] Train loss=0.02056911028921604
[20/24] Train loss=0.017595017328858376
Test set avg_accuracy=87.32% avg_sensitivity=85.79%, avg_specificity=87.86% avg_auc=0.9360
Fold[6] Epoch: 131 [131/150 (87%)] Train loss=0.016724 Test loss=1.369576 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.013885334134101868
[5/24] Train loss=0.020317452028393745
[10/24] Train loss=0.011416271328926086
[15/24] Train loss=0.025269510224461555
[20/24] Train loss=0.012679744511842728
Test set avg_accuracy=86.95% avg_sensitivity=86.93%, avg_specificity=86.96% avg_auc=0.9371
Fold[6] Epoch: 132 [132/150 (88%)] Train loss=0.016801 Test loss=1.567360 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.015041429549455643
[5/24] Train loss=0.0104864202439785
[10/24] Train loss=0.01068856567144394
[15/24] Train loss=0.015247521921992302
[20/24] Train loss=0.022707276046276093
Test set avg_accuracy=86.80% avg_sensitivity=87.67%, avg_specificity=86.49% avg_auc=0.9375
Fold[6] Epoch: 133 [133/150 (89%)] Train loss=0.014827 Test loss=1.681934 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.013745336793363094
[5/24] Train loss=0.018593426793813705
[10/24] Train loss=0.012248378247022629
[15/24] Train loss=0.018137967213988304
[20/24] Train loss=0.01513398066163063
Test set avg_accuracy=86.46% avg_sensitivity=87.97%, avg_specificity=85.92% avg_auc=0.9367
Fold[6] Epoch: 134 [134/150 (89%)] Train loss=0.015799 Test loss=1.673467 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.015948887914419174
[5/24] Train loss=0.015596357174217701
[10/24] Train loss=0.018003223463892937
[15/24] Train loss=0.020232107490301132
[20/24] Train loss=0.011911291629076004
Test set avg_accuracy=87.08% avg_sensitivity=87.62%, avg_specificity=86.89% avg_auc=0.9361
Fold[6] Epoch: 135 [135/150 (90%)] Train loss=0.016527 Test loss=1.599023 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.019904296845197678
[5/24] Train loss=0.0170389823615551
[10/24] Train loss=0.017568396404385567
[15/24] Train loss=0.0152916694059968
[20/24] Train loss=0.013306885026395321
Test set avg_accuracy=87.15% avg_sensitivity=87.18%, avg_specificity=87.14% avg_auc=0.9362
Fold[6] Epoch: 136 [136/150 (91%)] Train loss=0.019679 Test loss=1.499425 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.022615492343902588
[5/24] Train loss=0.01872105523943901
[10/24] Train loss=0.02168680727481842
[15/24] Train loss=0.018307803198695183
[20/24] Train loss=0.016656745225191116
Test set avg_accuracy=87.36% avg_sensitivity=86.68%, avg_specificity=87.60% avg_auc=0.9360
Fold[6] Epoch: 137 [137/150 (91%)] Train loss=0.022153 Test loss=1.407397 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.017521793022751808
[5/24] Train loss=0.012925790622830391
[10/24] Train loss=0.022651636973023415
[15/24] Train loss=0.014426371082663536
[20/24] Train loss=0.012182154692709446
Test set avg_accuracy=87.43% avg_sensitivity=86.38%, avg_specificity=87.81% avg_auc=0.9357
Fold[6] Epoch: 138 [138/150 (92%)] Train loss=0.017828 Test loss=1.309481 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.01562119834125042
[5/24] Train loss=0.010571973398327827
[10/24] Train loss=0.013763803988695145
[15/24] Train loss=0.011882858350872993
[20/24] Train loss=0.010269043035805225
Test set avg_accuracy=87.38% avg_sensitivity=86.38%, avg_specificity=87.74% avg_auc=0.9358
Fold[6] Epoch: 139 [139/150 (93%)] Train loss=0.014501 Test loss=1.308885 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.04859692603349686
[5/24] Train loss=0.01848738268017769
[10/24] Train loss=0.016184348613023758
[15/24] Train loss=0.01185585930943489
[20/24] Train loss=0.010845622979104519
Test set avg_accuracy=87.25% avg_sensitivity=86.68%, avg_specificity=87.46% avg_auc=0.9365
Fold[6] Epoch: 140 [140/150 (93%)] Train loss=0.016403 Test loss=1.344600 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.01915851980447769
[5/24] Train loss=0.008832599967718124
[10/24] Train loss=0.010173509828746319
[15/24] Train loss=0.012187443673610687
[20/24] Train loss=0.02384273335337639
Test set avg_accuracy=86.98% avg_sensitivity=86.68%, avg_specificity=87.09% avg_auc=0.9367
Fold[6] Epoch: 141 [141/150 (94%)] Train loss=0.012923 Test loss=1.439873 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.011713434010744095
[5/24] Train loss=0.00785952340811491
[10/24] Train loss=0.011257527396082878
[15/24] Train loss=0.008431989699602127
[20/24] Train loss=0.011044236831367016
Test set avg_accuracy=86.77% avg_sensitivity=87.03%, avg_specificity=86.68% avg_auc=0.9369
Fold[6] Epoch: 142 [142/150 (95%)] Train loss=0.014950 Test loss=1.481997 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.010733965784311295
[5/24] Train loss=0.010143573395907879
[10/24] Train loss=0.013485106639564037
[15/24] Train loss=0.009580441750586033
[20/24] Train loss=0.008423572406172752
Test set avg_accuracy=86.89% avg_sensitivity=87.48%, avg_specificity=86.68% avg_auc=0.9370
Fold[6] Epoch: 143 [143/150 (95%)] Train loss=0.012764 Test loss=1.516465 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.02147758938372135
[5/24] Train loss=0.014426595531404018
[10/24] Train loss=0.012206919491291046
[15/24] Train loss=0.012789673171937466
[20/24] Train loss=0.014955658465623856
Test set avg_accuracy=86.86% avg_sensitivity=87.48%, avg_specificity=86.64% avg_auc=0.9369
Fold[6] Epoch: 144 [144/150 (96%)] Train loss=0.014150 Test loss=1.531483 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.018200820311903954
[5/24] Train loss=0.01255815476179123
[10/24] Train loss=0.013384438119828701
[15/24] Train loss=0.01568557322025299
[20/24] Train loss=0.010825121775269508
Test set avg_accuracy=86.84% avg_sensitivity=87.43%, avg_specificity=86.63% avg_auc=0.9369
Fold[6] Epoch: 145 [145/150 (97%)] Train loss=0.015686 Test loss=1.519158 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.01900879293680191
[5/24] Train loss=0.01684390753507614
[10/24] Train loss=0.01557036954909563
[15/24] Train loss=0.017326172441244125
[20/24] Train loss=0.012875082902610302
Test set avg_accuracy=86.84% avg_sensitivity=87.43%, avg_specificity=86.63% avg_auc=0.9369
Fold[6] Epoch: 146 [146/150 (97%)] Train loss=0.018738 Test loss=1.506374 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.025083500891923904
[5/24] Train loss=0.018761875107884407
[10/24] Train loss=0.020143596455454826
[15/24] Train loss=0.018917717039585114
[20/24] Train loss=0.024904765188694
Test set avg_accuracy=86.85% avg_sensitivity=87.43%, avg_specificity=86.64% avg_auc=0.9369
Fold[6] Epoch: 147 [147/150 (98%)] Train loss=0.022311 Test loss=1.503371 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.027980180457234383
[5/24] Train loss=0.02470199018716812
[10/24] Train loss=0.025499241426587105
[15/24] Train loss=0.02801397815346718
[20/24] Train loss=0.021967217326164246
Test set avg_accuracy=86.85% avg_sensitivity=87.43%, avg_specificity=86.64% avg_auc=0.9368
Fold[6] Epoch: 148 [148/150 (99%)] Train loss=0.026202 Test loss=1.501036 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.03413733094930649
[5/24] Train loss=0.030398519709706306
[10/24] Train loss=0.02958456240594387
[15/24] Train loss=0.02701004035770893
[20/24] Train loss=0.02383945696055889
Test set avg_accuracy=86.84% avg_sensitivity=87.33%, avg_specificity=86.66% avg_auc=0.9368
Fold[6] Epoch: 149 [149/150 (99%)] Train loss=0.030747 Test loss=1.488802 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.04368925839662552
[5/24] Train loss=0.0359371192753315
[10/24] Train loss=0.03803905099630356
[15/24] Train loss=0.04064064100384712
[20/24] Train loss=0.040368903428316116
Test set avg_accuracy=86.82% avg_sensitivity=87.33%, avg_specificity=86.64% avg_auc=0.9368
Fold[6] Epoch: 150 [150/150 (100%)] Train loss=0.040290 Test loss=1.488767 Current lr=[4.388541022775342e-09]

Fold[6] Result: acc=86.98% sen=89.66%, spe=86.03%, auc=0.95!
Fold[6] Avg_overlap=0.78%(0.1862052201902109)
[0/24] Train loss=1.418292760848999
[5/24] Train loss=1.2744711637496948
[10/24] Train loss=1.2428566217422485
[15/24] Train loss=1.0399137735366821
[20/24] Train loss=1.0182151794433594
Test set avg_accuracy=81.30% avg_sensitivity=60.66%, avg_specificity=89.06% avg_auc=0.8643
Best model saved!! Metric=0.8643036447161324!!
Fold[7] Epoch: 1 [1/150 (1%)] Train loss=1.189552 Test loss=0.434977 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.9930842518806458
[5/24] Train loss=0.8945792317390442
[10/24] Train loss=0.9670785665512085
[15/24] Train loss=0.8755938410758972
[20/24] Train loss=0.8734531998634338
Test set avg_accuracy=81.46% avg_sensitivity=85.84%, avg_specificity=79.81% avg_auc=0.8937
Best model saved!! Metric=0.8937424231592074!!
Fold[7] Epoch: 2 [2/150 (1%)] Train loss=0.940904 Test loss=0.495064 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.9445158243179321
[5/24] Train loss=0.8721783757209778
[10/24] Train loss=0.9481083154678345
[15/24] Train loss=0.8418774604797363
[20/24] Train loss=0.8565676808357239
Test set avg_accuracy=83.02% avg_sensitivity=83.26%, avg_specificity=82.93% avg_auc=0.9022
Best model saved!! Metric=0.9022270755002477!!
Fold[7] Epoch: 3 [3/150 (2%)] Train loss=0.893509 Test loss=0.430714 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.8834823966026306
[5/24] Train loss=0.7985406517982483
[10/24] Train loss=0.8724397420883179
[15/24] Train loss=0.7752326130867004
[20/24] Train loss=0.7949879169464111
Test set avg_accuracy=83.92% avg_sensitivity=82.93%, avg_specificity=84.29% avg_auc=0.9074
Best model saved!! Metric=0.9074162478557641!!
Fold[7] Epoch: 4 [4/150 (3%)] Train loss=0.839684 Test loss=0.408233 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.8014925718307495
[5/24] Train loss=0.7691958546638489
[10/24] Train loss=0.8334935307502747
[15/24] Train loss=0.8156434893608093
[20/24] Train loss=0.74444580078125
Test set avg_accuracy=79.86% avg_sensitivity=92.18%, avg_specificity=75.23% avg_auc=0.9088
Best model saved!! Metric=0.9087655906858744!!
Fold[7] Epoch: 5 [5/150 (3%)] Train loss=0.808445 Test loss=0.543315 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.8374744653701782
[5/24] Train loss=0.7206801176071167
[10/24] Train loss=0.7779012322425842
[15/24] Train loss=0.7813717126846313
[20/24] Train loss=0.7525675892829895
Test set avg_accuracy=85.44% avg_sensitivity=81.83%, avg_specificity=86.80% avg_auc=0.9225
Best model saved!! Metric=0.9225329874710775!!
Fold[7] Epoch: 6 [6/150 (4%)] Train loss=0.783084 Test loss=0.350710 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.7582747340202332
[5/24] Train loss=0.723667562007904
[10/24] Train loss=0.8390676975250244
[15/24] Train loss=0.7695329785346985
[20/24] Train loss=0.7689491510391235
Test set avg_accuracy=80.86% avg_sensitivity=91.37%, avg_specificity=76.91% avg_auc=0.9236
Best model saved!! Metric=0.9236493182903922!!
Fold[7] Epoch: 7 [7/150 (5%)] Train loss=0.767387 Test loss=0.480622 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.7409344911575317
[5/24] Train loss=0.6503605842590332
[10/24] Train loss=0.7720821499824524
[15/24] Train loss=0.7399478554725647
[20/24] Train loss=0.6920090913772583
Test set avg_accuracy=86.61% avg_sensitivity=84.41%, avg_specificity=87.44% avg_auc=0.9319
Best model saved!! Metric=0.9319333308904654!!
Fold[7] Epoch: 8 [8/150 (5%)] Train loss=0.737761 Test loss=0.331685 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.6968748569488525
[5/24] Train loss=0.6465522050857544
[10/24] Train loss=0.7703644037246704
[15/24] Train loss=0.7375789284706116
[20/24] Train loss=0.7013991475105286
Test set avg_accuracy=81.97% avg_sensitivity=93.42%, avg_specificity=77.66% avg_auc=0.9302
Fold[7] Epoch: 9 [9/150 (6%)] Train loss=0.715098 Test loss=0.454901 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.6967693567276001
[5/24] Train loss=0.6496597528457642
[10/24] Train loss=0.7298851609230042
[15/24] Train loss=0.7093138694763184
[20/24] Train loss=0.6503710746765137
Test set avg_accuracy=86.73% avg_sensitivity=83.07%, avg_specificity=88.11% avg_auc=0.9347
Best model saved!! Metric=0.9347393831553669!!
Fold[7] Epoch: 10 [10/150 (7%)] Train loss=0.692837 Test loss=0.314289 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.6968498229980469
[5/24] Train loss=0.6404070258140564
[10/24] Train loss=0.7505668997764587
[15/24] Train loss=0.7330755591392517
[20/24] Train loss=0.6119996905326843
Test set avg_accuracy=82.10% avg_sensitivity=93.37%, avg_specificity=77.86% avg_auc=0.9359
Best model saved!! Metric=0.935869209538357!!
Fold[7] Epoch: 11 [11/150 (7%)] Train loss=0.679900 Test loss=0.457518 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.6698223352432251
[5/24] Train loss=0.6618250608444214
[10/24] Train loss=0.7367416024208069
[15/24] Train loss=0.6933830380439758
[20/24] Train loss=0.6355639696121216
Test set avg_accuracy=86.03% avg_sensitivity=89.51%, avg_specificity=84.72% avg_auc=0.9387
Best model saved!! Metric=0.9387448749956333!!
Fold[7] Epoch: 12 [12/150 (8%)] Train loss=0.671215 Test loss=0.348462 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6434668302536011
[5/24] Train loss=0.5838753581047058
[10/24] Train loss=0.7013528943061829
[15/24] Train loss=0.6745613813400269
[20/24] Train loss=0.6029080152511597
Test set avg_accuracy=87.40% avg_sensitivity=85.93%, avg_specificity=87.95% avg_auc=0.9410
Best model saved!! Metric=0.9410223367807665!!
Fold[7] Epoch: 13 [13/150 (9%)] Train loss=0.648804 Test loss=0.303581 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.6230117678642273
[5/24] Train loss=0.5734977126121521
[10/24] Train loss=0.6874083280563354
[15/24] Train loss=0.6779102683067322
[20/24] Train loss=0.6070303916931152
Test set avg_accuracy=88.14% avg_sensitivity=85.60%, avg_specificity=89.09% avg_auc=0.9449
Best model saved!! Metric=0.9449275087505491!!
Fold[7] Epoch: 14 [14/150 (9%)] Train loss=0.632967 Test loss=0.291187 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.6227103471755981
[5/24] Train loss=0.5710440874099731
[10/24] Train loss=0.6976824998855591
[15/24] Train loss=0.6190169453620911
[20/24] Train loss=0.5800074338912964
Test set avg_accuracy=87.34% avg_sensitivity=90.03%, avg_specificity=86.33% avg_auc=0.9456
Best model saved!! Metric=0.9456429444552495!!
Fold[7] Epoch: 15 [15/150 (10%)] Train loss=0.631979 Test loss=0.319621 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.5971404314041138
[5/24] Train loss=0.5653466582298279
[10/24] Train loss=0.6416363716125488
[15/24] Train loss=0.6616842150688171
[20/24] Train loss=0.5739474296569824
Test set avg_accuracy=89.67% avg_sensitivity=80.64%, avg_specificity=93.07% avg_auc=0.9465
Best model saved!! Metric=0.9465448837250421!!
Fold[7] Epoch: 16 [16/150 (11%)] Train loss=0.617279 Test loss=0.266626 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.6314988136291504
[5/24] Train loss=0.5864408016204834
[10/24] Train loss=0.6990324854850769
[15/24] Train loss=0.6497474908828735
[20/24] Train loss=0.5355439186096191
Test set avg_accuracy=86.64% avg_sensitivity=91.18%, avg_specificity=84.94% avg_auc=0.9480
Best model saved!! Metric=0.9479943328882359!!
Fold[7] Epoch: 17 [17/150 (11%)] Train loss=0.618307 Test loss=0.335149 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.5959337949752808
[5/24] Train loss=0.5584957003593445
[10/24] Train loss=0.6460260152816772
[15/24] Train loss=0.6587633490562439
[20/24] Train loss=0.5200940370559692
Test set avg_accuracy=89.48% avg_sensitivity=79.45%, avg_specificity=93.25% avg_auc=0.9478
Fold[7] Epoch: 18 [18/150 (12%)] Train loss=0.602096 Test loss=0.259724 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.6056633591651917
[5/24] Train loss=0.5423851013183594
[10/24] Train loss=0.6497710347175598
[15/24] Train loss=0.6121460199356079
[20/24] Train loss=0.5863299369812012
Test set avg_accuracy=86.71% avg_sensitivity=91.61%, avg_specificity=84.86% avg_auc=0.9452
Fold[7] Epoch: 19 [19/150 (13%)] Train loss=0.605224 Test loss=0.339870 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.6035285592079163
[5/24] Train loss=0.5394299030303955
[10/24] Train loss=0.6449989676475525
[15/24] Train loss=0.5904794335365295
[20/24] Train loss=0.5235449075698853
Test set avg_accuracy=89.97% avg_sensitivity=84.74%, avg_specificity=91.94% avg_auc=0.9496
Best model saved!! Metric=0.9495860406672583!!
Fold[7] Epoch: 20 [20/150 (13%)] Train loss=0.598836 Test loss=0.264140 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.5885533094406128
[5/24] Train loss=0.5471486449241638
[10/24] Train loss=0.6408109068870544
[15/24] Train loss=0.6204499006271362
[20/24] Train loss=0.51878821849823
Test set avg_accuracy=89.39% avg_sensitivity=86.41%, avg_specificity=90.51% avg_auc=0.9455
Fold[7] Epoch: 21 [21/150 (14%)] Train loss=0.586747 Test loss=0.287580 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.5973505973815918
[5/24] Train loss=0.5533016324043274
[10/24] Train loss=0.6680104732513428
[15/24] Train loss=0.5584859848022461
[20/24] Train loss=0.5159811973571777
Test set avg_accuracy=85.01% avg_sensitivity=92.70%, avg_specificity=82.12% avg_auc=0.9488
Fold[7] Epoch: 22 [22/150 (15%)] Train loss=0.577274 Test loss=0.377226 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.5568846464157104
[5/24] Train loss=0.5228069424629211
[10/24] Train loss=0.6312692165374756
[15/24] Train loss=0.5231184959411621
[20/24] Train loss=0.5059347152709961
Test set avg_accuracy=88.24% avg_sensitivity=86.41%, avg_specificity=88.93% avg_auc=0.9466
Fold[7] Epoch: 23 [23/150 (15%)] Train loss=0.576464 Test loss=0.288175 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5942040085792542
[5/24] Train loss=0.5230844616889954
[10/24] Train loss=0.6143463253974915
[15/24] Train loss=0.6799176335334778
[20/24] Train loss=0.49573197960853577
Test set avg_accuracy=86.82% avg_sensitivity=91.37%, avg_specificity=85.12% avg_auc=0.9469
Fold[7] Epoch: 24 [24/150 (16%)] Train loss=0.563681 Test loss=0.353860 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.5517985224723816
[5/24] Train loss=0.5391988158226013
[10/24] Train loss=0.6056488156318665
[15/24] Train loss=0.5433124303817749
[20/24] Train loss=0.48546716570854187
Test set avg_accuracy=88.46% avg_sensitivity=87.74%, avg_specificity=88.73% avg_auc=0.9483
Fold[7] Epoch: 25 [25/150 (17%)] Train loss=0.559075 Test loss=0.288072 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5464789271354675
[5/24] Train loss=0.5380522012710571
[10/24] Train loss=0.5953900814056396
[15/24] Train loss=0.5577459335327148
[20/24] Train loss=0.46286261081695557
Test set avg_accuracy=86.15% avg_sensitivity=91.18%, avg_specificity=84.26% avg_auc=0.9468
Fold[7] Epoch: 26 [26/150 (17%)] Train loss=0.549343 Test loss=0.351739 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5513771176338196
[5/24] Train loss=0.5497561693191528
[10/24] Train loss=0.6085675954818726
[15/24] Train loss=0.5242201089859009
[20/24] Train loss=0.47417163848876953
Test set avg_accuracy=89.28% avg_sensitivity=84.79%, avg_specificity=90.97% avg_auc=0.9491
Fold[7] Epoch: 27 [27/150 (18%)] Train loss=0.545887 Test loss=0.275975 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5968404412269592
[5/24] Train loss=0.5609387755393982
[10/24] Train loss=0.555119514465332
[15/24] Train loss=0.5191190838813782
[20/24] Train loss=0.4872359335422516
Test set avg_accuracy=86.33% avg_sensitivity=90.56%, avg_specificity=84.74% avg_auc=0.9449
Fold[7] Epoch: 28 [28/150 (19%)] Train loss=0.542040 Test loss=0.329634 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5174686908721924
[5/24] Train loss=0.5363031625747681
[10/24] Train loss=0.5856803059577942
[15/24] Train loss=0.49691885709762573
[20/24] Train loss=0.4980868995189667
Test set avg_accuracy=88.53% avg_sensitivity=84.64%, avg_specificity=89.99% avg_auc=0.9448
Fold[7] Epoch: 29 [29/150 (19%)] Train loss=0.529300 Test loss=0.287767 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.5527665615081787
[5/24] Train loss=0.5151327848434448
[10/24] Train loss=0.5545941591262817
[15/24] Train loss=0.4497036933898926
[20/24] Train loss=0.4412057399749756
Test set avg_accuracy=87.93% avg_sensitivity=88.27%, avg_specificity=87.80% avg_auc=0.9480
Fold[7] Epoch: 30 [30/150 (20%)] Train loss=0.523071 Test loss=0.303306 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.48889464139938354
[5/24] Train loss=0.47495049238204956
[10/24] Train loss=0.5421735048294067
[15/24] Train loss=0.4989464581012726
[20/24] Train loss=0.45714056491851807
Test set avg_accuracy=88.78% avg_sensitivity=82.59%, avg_specificity=91.10% avg_auc=0.9434
Fold[7] Epoch: 31 [31/150 (21%)] Train loss=0.511771 Test loss=0.281760 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.559004008769989
[5/24] Train loss=0.44766929745674133
[10/24] Train loss=0.5076634287834167
[15/24] Train loss=0.49710360169410706
[20/24] Train loss=0.4506467878818512
Test set avg_accuracy=86.46% avg_sensitivity=91.32%, avg_specificity=84.63% avg_auc=0.9476
Fold[7] Epoch: 32 [32/150 (21%)] Train loss=0.501545 Test loss=0.340389 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.49074316024780273
[5/24] Train loss=0.5130961537361145
[10/24] Train loss=0.5346977710723877
[15/24] Train loss=0.4596552550792694
[20/24] Train loss=0.42693808674812317
Test set avg_accuracy=88.03% avg_sensitivity=85.84%, avg_specificity=88.86% avg_auc=0.9464
Fold[7] Epoch: 33 [33/150 (22%)] Train loss=0.504731 Test loss=0.301232 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.5213775038719177
[5/24] Train loss=0.4105556905269623
[10/24] Train loss=0.4852699935436249
[15/24] Train loss=0.4174640476703644
[20/24] Train loss=0.4269784688949585
Test set avg_accuracy=85.61% avg_sensitivity=89.65%, avg_specificity=84.09% avg_auc=0.9440
Fold[7] Epoch: 34 [34/150 (23%)] Train loss=0.478907 Test loss=0.356413 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.506774365901947
[5/24] Train loss=0.46442022919654846
[10/24] Train loss=0.529769778251648
[15/24] Train loss=0.4629473388195038
[20/24] Train loss=0.39217719435691833
Test set avg_accuracy=88.03% avg_sensitivity=87.98%, avg_specificity=88.05% avg_auc=0.9468
Fold[7] Epoch: 35 [35/150 (23%)] Train loss=0.479115 Test loss=0.298783 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.4885379672050476
[5/24] Train loss=0.41455078125
[10/24] Train loss=0.4570300877094269
[15/24] Train loss=0.4686850607395172
[20/24] Train loss=0.4058930277824402
Test set avg_accuracy=87.63% avg_sensitivity=86.22%, avg_specificity=88.16% avg_auc=0.9415
Fold[7] Epoch: 36 [36/150 (24%)] Train loss=0.458891 Test loss=0.324151 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.4682423174381256
[5/24] Train loss=0.4384588599205017
[10/24] Train loss=0.4025518000125885
[15/24] Train loss=0.3871088922023773
[20/24] Train loss=0.40031740069389343
Test set avg_accuracy=84.47% avg_sensitivity=92.23%, avg_specificity=81.55% avg_auc=0.9410
Fold[7] Epoch: 37 [37/150 (25%)] Train loss=0.434912 Test loss=0.412241 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.44870904088020325
[5/24] Train loss=0.4171493947505951
[10/24] Train loss=0.49386924505233765
[15/24] Train loss=0.40681079030036926
[20/24] Train loss=0.3955518305301666
Test set avg_accuracy=87.25% avg_sensitivity=91.23%, avg_specificity=85.76% avg_auc=0.9497
Best model saved!! Metric=0.9497203983992895!!
Fold[7] Epoch: 38 [38/150 (25%)] Train loss=0.437903 Test loss=0.347915 Current lr=[0.000944367614404117]

[0/24] Train loss=0.4592445492744446
[5/24] Train loss=0.42411231994628906
[10/24] Train loss=0.4766363501548767
[15/24] Train loss=0.3774314820766449
[20/24] Train loss=0.3543018400669098
Test set avg_accuracy=87.15% avg_sensitivity=85.98%, avg_specificity=87.59% avg_auc=0.9386
Fold[7] Epoch: 39 [39/150 (26%)] Train loss=0.436664 Test loss=0.332471 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.44695454835891724
[5/24] Train loss=0.34609100222587585
[10/24] Train loss=0.4119667410850525
[15/24] Train loss=0.3563440442085266
[20/24] Train loss=0.34353238344192505
Test set avg_accuracy=86.85% avg_sensitivity=87.98%, avg_specificity=86.42% avg_auc=0.9435
Fold[7] Epoch: 40 [40/150 (27%)] Train loss=0.403519 Test loss=0.344954 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.394912987947464
[5/24] Train loss=0.39485329389572144
[10/24] Train loss=0.3999406397342682
[15/24] Train loss=0.3651794493198395
[20/24] Train loss=0.34544068574905396
Test set avg_accuracy=88.52% avg_sensitivity=83.98%, avg_specificity=90.22% avg_auc=0.9425
Fold[7] Epoch: 41 [41/150 (27%)] Train loss=0.396077 Test loss=0.321784 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.38354089856147766
[5/24] Train loss=0.34995463490486145
[10/24] Train loss=0.36753904819488525
[15/24] Train loss=0.37685155868530273
[20/24] Train loss=0.33709830045700073
Test set avg_accuracy=87.79% avg_sensitivity=83.40%, avg_specificity=89.43% avg_auc=0.9397
Fold[7] Epoch: 42 [42/150 (28%)] Train loss=0.387019 Test loss=0.332755 Current lr=[0.000989780311725182]

[0/24] Train loss=0.4354831278324127
[5/24] Train loss=0.3292463719844818
[10/24] Train loss=0.3557544946670532
[15/24] Train loss=0.3378779888153076
[20/24] Train loss=0.3290165066719055
Test set avg_accuracy=85.52% avg_sensitivity=87.94%, avg_specificity=84.61% avg_auc=0.9401
Fold[7] Epoch: 43 [43/150 (29%)] Train loss=0.361318 Test loss=0.436306 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.36701616644859314
[5/24] Train loss=0.3144680857658386
[10/24] Train loss=0.35512322187423706
[15/24] Train loss=0.33928588032722473
[20/24] Train loss=0.3042948544025421
Test set avg_accuracy=84.48% avg_sensitivity=90.61%, avg_specificity=82.18% avg_auc=0.9362
Fold[7] Epoch: 44 [44/150 (29%)] Train loss=0.350926 Test loss=0.461381 Current lr=[0.000998924125869967]

[0/24] Train loss=0.36824557185173035
[5/24] Train loss=0.3414854109287262
[10/24] Train loss=0.3695657253265381
[15/24] Train loss=0.33676090836524963
[20/24] Train loss=0.3067370653152466
Test set avg_accuracy=87.60% avg_sensitivity=86.12%, avg_specificity=88.16% avg_auc=0.9405
Fold[7] Epoch: 45 [45/150 (30%)] Train loss=0.370432 Test loss=0.357648 Current lr=[0.000999999611458977]

[0/24] Train loss=0.32821425795555115
[5/24] Train loss=0.2956518828868866
[10/24] Train loss=0.3442932367324829
[15/24] Train loss=0.30165037512779236
[20/24] Train loss=0.30482569336891174
Test set avg_accuracy=84.49% avg_sensitivity=92.42%, avg_specificity=81.52% avg_auc=0.9400
Fold[7] Epoch: 46 [46/150 (31%)] Train loss=0.328713 Test loss=0.480582 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.34119415283203125
[5/24] Train loss=0.2617511749267578
[10/24] Train loss=0.3398300111293793
[15/24] Train loss=0.33080846071243286
[20/24] Train loss=0.317813903093338
Test set avg_accuracy=88.19% avg_sensitivity=80.93%, avg_specificity=90.92% avg_auc=0.9380
Fold[7] Epoch: 47 [47/150 (31%)] Train loss=0.329997 Test loss=0.345444 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.31286731362342834
[5/24] Train loss=0.2743653953075409
[10/24] Train loss=0.32485437393188477
[15/24] Train loss=0.3058551847934723
[20/24] Train loss=0.2494269460439682
Test set avg_accuracy=87.41% avg_sensitivity=80.11%, avg_specificity=90.15% avg_auc=0.9315
Fold[7] Epoch: 48 [48/150 (32%)] Train loss=0.299942 Test loss=0.386936 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.2701275646686554
[5/24] Train loss=0.2533915042877197
[10/24] Train loss=0.31222546100616455
[15/24] Train loss=0.2396763265132904
[20/24] Train loss=0.25713402032852173
Test set avg_accuracy=87.71% avg_sensitivity=88.22%, avg_specificity=87.52% avg_auc=0.9396
Fold[7] Epoch: 49 [49/150 (33%)] Train loss=0.289673 Test loss=0.396143 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.2844594419002533
[5/24] Train loss=0.2287282645702362
[10/24] Train loss=0.3379207253456116
[15/24] Train loss=0.26797881722450256
[20/24] Train loss=0.2747489809989929
Test set avg_accuracy=88.45% avg_sensitivity=76.78%, avg_specificity=92.84% avg_auc=0.9372
Fold[7] Epoch: 50 [50/150 (33%)] Train loss=0.289006 Test loss=0.335123 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.2909969389438629
[5/24] Train loss=0.24578940868377686
[10/24] Train loss=0.2837170362472534
[15/24] Train loss=0.22010131180286407
[20/24] Train loss=0.261138916015625
Test set avg_accuracy=87.71% avg_sensitivity=86.93%, avg_specificity=88.00% avg_auc=0.9401
Fold[7] Epoch: 51 [51/150 (34%)] Train loss=0.268215 Test loss=0.353064 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.2700737714767456
[5/24] Train loss=0.20510153472423553
[10/24] Train loss=0.27983710169792175
[15/24] Train loss=0.21471112966537476
[20/24] Train loss=0.2334272861480713
Test set avg_accuracy=85.91% avg_sensitivity=90.99%, avg_specificity=84.01% avg_auc=0.9435
Fold[7] Epoch: 52 [52/150 (35%)] Train loss=0.244404 Test loss=0.450510 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.23286865651607513
[5/24] Train loss=0.20935508608818054
[10/24] Train loss=0.2673708200454712
[15/24] Train loss=0.18911947309970856
[20/24] Train loss=0.2135888934135437
Test set avg_accuracy=84.54% avg_sensitivity=91.65%, avg_specificity=81.87% avg_auc=0.9351
Fold[7] Epoch: 53 [53/150 (35%)] Train loss=0.252921 Test loss=0.451631 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.2704106569290161
[5/24] Train loss=0.20549893379211426
[10/24] Train loss=0.3000704050064087
[15/24] Train loss=0.21236923336982727
[20/24] Train loss=0.23069672286510468
Test set avg_accuracy=86.81% avg_sensitivity=88.41%, avg_specificity=86.21% avg_auc=0.9367
Fold[7] Epoch: 54 [54/150 (36%)] Train loss=0.265533 Test loss=0.387055 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.2721119821071625
[5/24] Train loss=0.23597778379917145
[10/24] Train loss=0.26551562547683716
[15/24] Train loss=0.21078146994113922
[20/24] Train loss=0.19921332597732544
Test set avg_accuracy=86.09% avg_sensitivity=87.36%, avg_specificity=85.62% avg_auc=0.9362
Fold[7] Epoch: 55 [55/150 (37%)] Train loss=0.246068 Test loss=0.413986 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.2687990367412567
[5/24] Train loss=0.17656829953193665
[10/24] Train loss=0.2691613435745239
[15/24] Train loss=0.18249264359474182
[20/24] Train loss=0.2078748196363449
Test set avg_accuracy=88.33% avg_sensitivity=78.11%, avg_specificity=92.17% avg_auc=0.9395
Fold[7] Epoch: 56 [56/150 (37%)] Train loss=0.233337 Test loss=0.367536 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.24845360219478607
[5/24] Train loss=0.15288196504116058
[10/24] Train loss=0.20872364938259125
[15/24] Train loss=0.19702497124671936
[20/24] Train loss=0.18633073568344116
Test set avg_accuracy=88.53% avg_sensitivity=81.97%, avg_specificity=90.99% avg_auc=0.9421
Fold[7] Epoch: 57 [57/150 (38%)] Train loss=0.204589 Test loss=0.382864 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.19697009027004242
[5/24] Train loss=0.13122501969337463
[10/24] Train loss=0.25010356307029724
[15/24] Train loss=0.18351231515407562
[20/24] Train loss=0.1608010232448578
Test set avg_accuracy=87.86% avg_sensitivity=85.31%, avg_specificity=88.82% avg_auc=0.9442
Fold[7] Epoch: 58 [58/150 (39%)] Train loss=0.187938 Test loss=0.447434 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.16829551756381989
[5/24] Train loss=0.14054110646247864
[10/24] Train loss=0.1854153424501419
[15/24] Train loss=0.16049602627754211
[20/24] Train loss=0.16846947371959686
Test set avg_accuracy=87.71% avg_sensitivity=86.03%, avg_specificity=88.34% avg_auc=0.9425
Fold[7] Epoch: 59 [59/150 (39%)] Train loss=0.172493 Test loss=0.479846 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.14755254983901978
[5/24] Train loss=0.11920322477817535
[10/24] Train loss=0.16281892359256744
[15/24] Train loss=0.11497324705123901
[20/24] Train loss=0.13679854571819305
Test set avg_accuracy=86.95% avg_sensitivity=88.79%, avg_specificity=86.26% avg_auc=0.9429
Fold[7] Epoch: 60 [60/150 (40%)] Train loss=0.154880 Test loss=0.526885 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.17344321310520172
[5/24] Train loss=0.18992330133914948
[10/24] Train loss=0.1789301037788391
[15/24] Train loss=0.1480519324541092
[20/24] Train loss=0.1676272451877594
Test set avg_accuracy=87.77% avg_sensitivity=87.03%, avg_specificity=88.05% avg_auc=0.9434
Fold[7] Epoch: 61 [61/150 (41%)] Train loss=0.164609 Test loss=0.494883 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.1820915788412094
[5/24] Train loss=0.1025950089097023
[10/24] Train loss=0.12034253776073456
[15/24] Train loss=0.11800654977560043
[20/24] Train loss=0.1301756650209427
Test set avg_accuracy=87.53% avg_sensitivity=85.88%, avg_specificity=88.14% avg_auc=0.9419
Fold[7] Epoch: 62 [62/150 (41%)] Train loss=0.137803 Test loss=0.492459 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.12227494269609451
[5/24] Train loss=0.10207059234380722
[10/24] Train loss=0.14306841790676117
[15/24] Train loss=0.12443111091852188
[20/24] Train loss=0.15298274159431458
Test set avg_accuracy=87.10% avg_sensitivity=90.70%, avg_specificity=85.74% avg_auc=0.9425
Fold[7] Epoch: 63 [63/150 (42%)] Train loss=0.131987 Test loss=0.526093 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.14532867074012756
[5/24] Train loss=0.10243291407823563
[10/24] Train loss=0.13542979955673218
[15/24] Train loss=0.12854640185832977
[20/24] Train loss=0.1141924113035202
Test set avg_accuracy=85.27% avg_sensitivity=91.42%, avg_specificity=82.97% avg_auc=0.9418
Fold[7] Epoch: 64 [64/150 (43%)] Train loss=0.149470 Test loss=0.545597 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.18122363090515137
[5/24] Train loss=0.12814247608184814
[10/24] Train loss=0.17597419023513794
[15/24] Train loss=0.1544468253850937
[20/24] Train loss=0.16198144853115082
Test set avg_accuracy=86.86% avg_sensitivity=89.18%, avg_specificity=85.99% avg_auc=0.9438
Fold[7] Epoch: 65 [65/150 (43%)] Train loss=0.153157 Test loss=0.515552 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.15483900904655457
[5/24] Train loss=0.11466877162456512
[10/24] Train loss=0.1477595716714859
[15/24] Train loss=0.1415543407201767
[20/24] Train loss=0.11537312716245651
Test set avg_accuracy=88.48% avg_sensitivity=80.64%, avg_specificity=91.42% avg_auc=0.9405
Fold[7] Epoch: 66 [66/150 (44%)] Train loss=0.143117 Test loss=0.450626 Current lr=[0.000904142181093812]

[0/24] Train loss=0.1383262723684311
[5/24] Train loss=0.10758526623249054
[10/24] Train loss=0.1276036500930786
[15/24] Train loss=0.10682816803455353
[20/24] Train loss=0.09361391514539719
Test set avg_accuracy=87.37% avg_sensitivity=84.64%, avg_specificity=88.39% avg_auc=0.9376
Fold[7] Epoch: 67 [67/150 (45%)] Train loss=0.125449 Test loss=0.440185 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.12288596481084824
[5/24] Train loss=0.08631539344787598
[10/24] Train loss=0.1139543429017067
[15/24] Train loss=0.10977867990732193
[20/24] Train loss=0.104914590716362
Test set avg_accuracy=86.04% avg_sensitivity=89.70%, avg_specificity=84.67% avg_auc=0.9394
Fold[7] Epoch: 68 [68/150 (45%)] Train loss=0.114242 Test loss=0.590696 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.11356818675994873
[5/24] Train loss=0.09767703711986542
[10/24] Train loss=0.09933945536613464
[15/24] Train loss=0.0890108048915863
[20/24] Train loss=0.09107408672571182
Test set avg_accuracy=86.56% avg_sensitivity=83.69%, avg_specificity=87.64% avg_auc=0.9367
Fold[7] Epoch: 69 [69/150 (46%)] Train loss=0.112117 Test loss=0.624499 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.08912716060876846
[5/24] Train loss=0.09649302810430527
[10/24] Train loss=0.10075731575489044
[15/24] Train loss=0.08240396529436111
[20/24] Train loss=0.08240742981433868
Test set avg_accuracy=83.93% avg_sensitivity=90.99%, avg_specificity=81.28% avg_auc=0.9305
Fold[7] Epoch: 70 [70/150 (47%)] Train loss=0.101318 Test loss=0.700358 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.12087918072938919
[5/24] Train loss=0.09578139334917068
[10/24] Train loss=0.09884447604417801
[15/24] Train loss=0.0875067338347435
[20/24] Train loss=0.09278085827827454
Test set avg_accuracy=85.77% avg_sensitivity=86.93%, avg_specificity=85.33% avg_auc=0.9323
Fold[7] Epoch: 71 [71/150 (47%)] Train loss=0.101263 Test loss=0.610564 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.11480452120304108
[5/24] Train loss=0.08779829740524292
[10/24] Train loss=0.11699055135250092
[15/24] Train loss=0.08700946718454361
[20/24] Train loss=0.08718672394752502
Test set avg_accuracy=87.60% avg_sensitivity=81.83%, avg_specificity=89.77% avg_auc=0.9369
Fold[7] Epoch: 72 [72/150 (48%)] Train loss=0.097118 Test loss=0.501591 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.08103018999099731
[5/24] Train loss=0.07138931006193161
[10/24] Train loss=0.06976275891065598
[15/24] Train loss=0.07502393424510956
[20/24] Train loss=0.07440163940191269
Test set avg_accuracy=86.47% avg_sensitivity=84.02%, avg_specificity=87.39% avg_auc=0.9346
Fold[7] Epoch: 73 [73/150 (49%)] Train loss=0.083461 Test loss=0.621769 Current lr=[0.000834102481048427]

[0/24] Train loss=0.08196113258600235
[5/24] Train loss=0.06676775217056274
[10/24] Train loss=0.08014658093452454
[15/24] Train loss=0.1276586651802063
[20/24] Train loss=0.07446525245904922
Test set avg_accuracy=87.58% avg_sensitivity=84.98%, avg_specificity=88.55% avg_auc=0.9361
Fold[7] Epoch: 74 [74/150 (49%)] Train loss=0.075175 Test loss=0.610709 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.09004640579223633
[5/24] Train loss=0.059810489416122437
[10/24] Train loss=0.05982907861471176
[15/24] Train loss=0.08326305449008942
[20/24] Train loss=0.0690169483423233
Test set avg_accuracy=85.61% avg_sensitivity=87.79%, avg_specificity=84.79% avg_auc=0.9314
Fold[7] Epoch: 75 [75/150 (50%)] Train loss=0.071958 Test loss=0.857039 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.08564113080501556
[5/24] Train loss=0.08364410698413849
[10/24] Train loss=0.0674690529704094
[15/24] Train loss=0.08047238737344742
[20/24] Train loss=0.07169558107852936
Test set avg_accuracy=87.50% avg_sensitivity=85.26%, avg_specificity=88.34% avg_auc=0.9365
Fold[7] Epoch: 76 [76/150 (51%)] Train loss=0.074221 Test loss=0.657371 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.08078276365995407
[5/24] Train loss=0.05828583240509033
[10/24] Train loss=0.07266343384981155
[15/24] Train loss=0.05308808758854866
[20/24] Train loss=0.06323530524969101
Test set avg_accuracy=87.49% avg_sensitivity=85.07%, avg_specificity=88.39% avg_auc=0.9353
Fold[7] Epoch: 77 [77/150 (51%)] Train loss=0.072315 Test loss=0.770012 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.05982201546430588
[5/24] Train loss=0.05195910483598709
[10/24] Train loss=0.059682201594114304
[15/24] Train loss=0.05530216917395592
[20/24] Train loss=0.05388795956969261
Test set avg_accuracy=86.71% avg_sensitivity=86.36%, avg_specificity=86.84% avg_auc=0.9377
Fold[7] Epoch: 78 [78/150 (52%)] Train loss=0.063103 Test loss=0.846035 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.07061133533716202
[5/24] Train loss=0.04626539722084999
[10/24] Train loss=0.05071823298931122
[15/24] Train loss=0.06446101516485214
[20/24] Train loss=0.06815973669290543
Test set avg_accuracy=84.43% avg_sensitivity=90.84%, avg_specificity=82.02% avg_auc=0.9329
Fold[7] Epoch: 79 [79/150 (53%)] Train loss=0.062181 Test loss=0.980519 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.07380976527929306
[5/24] Train loss=0.059800393879413605
[10/24] Train loss=0.07160887867212296
[15/24] Train loss=0.08489035069942474
[20/24] Train loss=0.0708332508802414
Test set avg_accuracy=87.36% avg_sensitivity=85.50%, avg_specificity=88.05% avg_auc=0.9367
Fold[7] Epoch: 80 [80/150 (53%)] Train loss=0.075925 Test loss=0.784386 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.07837551832199097
[5/24] Train loss=0.05229564756155014
[10/24] Train loss=0.05893731489777565
[15/24] Train loss=0.05303223431110382
[20/24] Train loss=0.06358285993337631
Test set avg_accuracy=86.25% avg_sensitivity=90.22%, avg_specificity=84.76% avg_auc=0.9327
Fold[7] Epoch: 81 [81/150 (54%)] Train loss=0.065226 Test loss=0.880166 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.07892154902219772
[5/24] Train loss=0.04457144811749458
[10/24] Train loss=0.05866291746497154
[15/24] Train loss=0.10825872421264648
[20/24] Train loss=0.07015065103769302
Test set avg_accuracy=86.48% avg_sensitivity=86.84%, avg_specificity=86.35% avg_auc=0.9339
Fold[7] Epoch: 82 [82/150 (55%)] Train loss=0.071833 Test loss=0.796923 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.08136837184429169
[5/24] Train loss=0.06264078617095947
[10/24] Train loss=0.08778491616249084
[15/24] Train loss=0.05292840674519539
[20/24] Train loss=0.0754406526684761
Test set avg_accuracy=87.27% avg_sensitivity=89.03%, avg_specificity=86.60% avg_auc=0.9381
Fold[7] Epoch: 83 [83/150 (55%)] Train loss=0.072083 Test loss=0.741354 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.06496355682611465
[5/24] Train loss=0.048853207379579544
[10/24] Train loss=0.06832586973905563
[15/24] Train loss=0.05611526221036911
[20/24] Train loss=0.0638115331530571
Test set avg_accuracy=87.53% avg_sensitivity=87.27%, avg_specificity=87.62% avg_auc=0.9410
Fold[7] Epoch: 84 [84/150 (56%)] Train loss=0.062185 Test loss=0.718348 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.06345933675765991
[5/24] Train loss=0.046313367784023285
[10/24] Train loss=0.043251413851976395
[15/24] Train loss=0.04544447362422943
[20/24] Train loss=0.046125080436468124
Test set avg_accuracy=87.55% avg_sensitivity=87.12%, avg_specificity=87.71% avg_auc=0.9411
Fold[7] Epoch: 85 [85/150 (57%)] Train loss=0.053674 Test loss=0.788729 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.04438333958387375
[5/24] Train loss=0.03488548472523689
[10/24] Train loss=0.05652303248643875
[15/24] Train loss=0.04669208824634552
[20/24] Train loss=0.05449607968330383
Test set avg_accuracy=87.10% avg_sensitivity=87.55%, avg_specificity=86.92% avg_auc=0.9417
Fold[7] Epoch: 86 [86/150 (57%)] Train loss=0.051521 Test loss=0.829915 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.06364960223436356
[5/24] Train loss=0.046268727630376816
[10/24] Train loss=0.054263196885585785
[15/24] Train loss=0.04415808990597725
[20/24] Train loss=0.046369701623916626
Test set avg_accuracy=88.22% avg_sensitivity=85.74%, avg_specificity=89.15% avg_auc=0.9428
Fold[7] Epoch: 87 [87/150 (58%)] Train loss=0.054007 Test loss=0.689844 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.04782376438379288
[5/24] Train loss=0.04257207363843918
[10/24] Train loss=0.049188703298568726
[15/24] Train loss=0.04959745705127716
[20/24] Train loss=0.04311886057257652
Test set avg_accuracy=88.49% avg_sensitivity=88.56%, avg_specificity=88.46% avg_auc=0.9431
Fold[7] Epoch: 88 [88/150 (59%)] Train loss=0.044244 Test loss=0.765383 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.0405251607298851
[5/24] Train loss=0.03619873896241188
[10/24] Train loss=0.04145786166191101
[15/24] Train loss=0.04138786718249321
[20/24] Train loss=0.05261572450399399
Test set avg_accuracy=88.55% avg_sensitivity=85.65%, avg_specificity=89.65% avg_auc=0.9419
Fold[7] Epoch: 89 [89/150 (59%)] Train loss=0.046617 Test loss=0.771970 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.06017656624317169
[5/24] Train loss=0.0276300311088562
[10/24] Train loss=0.038733113557100296
[15/24] Train loss=0.027485469356179237
[20/24] Train loss=0.03272518143057823
Test set avg_accuracy=88.67% avg_sensitivity=84.22%, avg_specificity=90.35% avg_auc=0.9425
Fold[7] Epoch: 90 [90/150 (60%)] Train loss=0.040281 Test loss=0.752472 Current lr=[0.00061065423442182]

[0/24] Train loss=0.045085422694683075
[5/24] Train loss=0.029477689415216446
[10/24] Train loss=0.04035838693380356
[15/24] Train loss=0.05083940550684929
[20/24] Train loss=0.04891320317983627
Test set avg_accuracy=88.62% avg_sensitivity=84.79%, avg_specificity=90.06% avg_auc=0.9410
Fold[7] Epoch: 91 [91/150 (61%)] Train loss=0.043135 Test loss=0.714595 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.036125026643276215
[5/24] Train loss=0.03472975268959999
[10/24] Train loss=0.03999071195721626
[15/24] Train loss=0.03605959564447403
[20/24] Train loss=0.028847958892583847
Test set avg_accuracy=87.89% avg_sensitivity=85.41%, avg_specificity=88.82% avg_auc=0.9398
Fold[7] Epoch: 92 [92/150 (61%)] Train loss=0.040004 Test loss=0.815777 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.06055210530757904
[5/24] Train loss=0.033088959753513336
[10/24] Train loss=0.03087291494011879
[15/24] Train loss=0.026725230738520622
[20/24] Train loss=0.10809875279664993
Test set avg_accuracy=86.35% avg_sensitivity=88.27%, avg_specificity=85.63% avg_auc=0.9351
Fold[7] Epoch: 93 [93/150 (62%)] Train loss=0.037955 Test loss=0.991499 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.03812558948993683
[5/24] Train loss=0.04506544768810272
[10/24] Train loss=0.04445037245750427
[15/24] Train loss=0.0369502454996109
[20/24] Train loss=0.09145195782184601
Test set avg_accuracy=87.10% avg_sensitivity=85.36%, avg_specificity=87.75% avg_auc=0.9406
Fold[7] Epoch: 94 [94/150 (63%)] Train loss=0.046716 Test loss=0.910580 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.03367709368467331
[5/24] Train loss=0.025756483897566795
[10/24] Train loss=0.03163127228617668
[15/24] Train loss=0.030866745859384537
[20/24] Train loss=0.034609947353601456
Test set avg_accuracy=87.60% avg_sensitivity=88.41%, avg_specificity=87.30% avg_auc=0.9416
Fold[7] Epoch: 95 [95/150 (63%)] Train loss=0.038645 Test loss=0.883606 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.04346710443496704
[5/24] Train loss=0.029984833672642708
[10/24] Train loss=0.03413994982838631
[15/24] Train loss=0.027449321001768112
[20/24] Train loss=0.04549894854426384
Test set avg_accuracy=87.12% avg_sensitivity=88.65%, avg_specificity=86.55% avg_auc=0.9418
Fold[7] Epoch: 96 [96/150 (64%)] Train loss=0.042504 Test loss=0.910161 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.038053613156080246
[5/24] Train loss=0.035217732191085815
[10/24] Train loss=0.03355597332119942
[15/24] Train loss=0.039877306669950485
[20/24] Train loss=0.04192997142672539
Test set avg_accuracy=87.57% avg_sensitivity=85.93%, avg_specificity=88.18% avg_auc=0.9423
Fold[7] Epoch: 97 [97/150 (65%)] Train loss=0.039311 Test loss=0.859606 Current lr=[0.000506858408304961]

[0/24] Train loss=0.02521897666156292
[5/24] Train loss=0.023513516411185265
[10/24] Train loss=0.03427661582827568
[15/24] Train loss=0.033062875270843506
[20/24] Train loss=0.029284479096531868
Test set avg_accuracy=87.30% avg_sensitivity=89.41%, avg_specificity=86.51% avg_auc=0.9438
Fold[7] Epoch: 98 [98/150 (65%)] Train loss=0.032245 Test loss=0.906738 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.023228220641613007
[5/24] Train loss=0.03756130859255791
[10/24] Train loss=0.029411062598228455
[15/24] Train loss=0.03774004802107811
[20/24] Train loss=0.04171685501933098
Test set avg_accuracy=88.05% avg_sensitivity=86.60%, avg_specificity=88.59% avg_auc=0.9402
Fold[7] Epoch: 99 [99/150 (66%)] Train loss=0.039153 Test loss=0.792971 Current lr=[0.000476946990416354]

[0/24] Train loss=0.02398284338414669
[5/24] Train loss=0.03128978982567787
[10/24] Train loss=0.026479603722691536
[15/24] Train loss=0.04255468025803566
[20/24] Train loss=0.035647645592689514
Test set avg_accuracy=87.79% avg_sensitivity=88.32%, avg_specificity=87.59% avg_auc=0.9411
Fold[7] Epoch: 100 [100/150 (67%)] Train loss=0.033162 Test loss=0.848006 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.045396625995635986
[5/24] Train loss=0.03071458451449871
[10/24] Train loss=0.033480752259492874
[15/24] Train loss=0.030182525515556335
[20/24] Train loss=0.04319504275918007
Test set avg_accuracy=86.97% avg_sensitivity=85.46%, avg_specificity=87.53% avg_auc=0.9406
Fold[7] Epoch: 101 [101/150 (67%)] Train loss=0.037821 Test loss=0.839569 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.023806780576705933
[5/24] Train loss=0.019290689378976822
[10/24] Train loss=0.025519996881484985
[15/24] Train loss=0.031804539263248444
[20/24] Train loss=0.03529753163456917
Test set avg_accuracy=87.63% avg_sensitivity=86.36%, avg_specificity=88.11% avg_auc=0.9422
Fold[7] Epoch: 102 [102/150 (68%)] Train loss=0.029393 Test loss=0.925828 Current lr=[0.000432267999769856]

[0/24] Train loss=0.03192076086997986
[5/24] Train loss=0.02725183218717575
[10/24] Train loss=0.021972522139549255
[15/24] Train loss=0.028636731207370758
[20/24] Train loss=0.027588361874222755
Test set avg_accuracy=87.77% avg_sensitivity=88.36%, avg_specificity=87.55% avg_auc=0.9432
Fold[7] Epoch: 103 [103/150 (69%)] Train loss=0.028145 Test loss=0.947899 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.029593385756015778
[5/24] Train loss=0.023347577080130577
[10/24] Train loss=0.023806767538189888
[15/24] Train loss=0.019406629726290703
[20/24] Train loss=0.022900572046637535
Test set avg_accuracy=87.81% avg_sensitivity=84.31%, avg_specificity=89.13% avg_auc=0.9405
Fold[7] Epoch: 104 [104/150 (69%)] Train loss=0.029140 Test loss=0.857382 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.02234814688563347
[5/24] Train loss=0.015567351132631302
[10/24] Train loss=0.03160037845373154
[15/24] Train loss=0.02485966868698597
[20/24] Train loss=0.03690587729215622
Test set avg_accuracy=86.34% avg_sensitivity=90.37%, avg_specificity=84.83% avg_auc=0.9396
Fold[7] Epoch: 105 [105/150 (70%)] Train loss=0.029675 Test loss=0.999965 Current lr=[0.000388134363466264]

[0/24] Train loss=0.029414137825369835
[5/24] Train loss=0.024545617401599884
[10/24] Train loss=0.03190281242132187
[15/24] Train loss=0.020323941484093666
[20/24] Train loss=0.03461485728621483
Test set avg_accuracy=87.83% avg_sensitivity=85.26%, avg_specificity=88.79% avg_auc=0.9415
Fold[7] Epoch: 106 [106/150 (71%)] Train loss=0.029987 Test loss=0.931624 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.017539191991090775
[5/24] Train loss=0.02178124152123928
[10/24] Train loss=0.020575683563947678
[15/24] Train loss=0.0234124306589365
[20/24] Train loss=0.018702825531363487
Test set avg_accuracy=87.17% avg_sensitivity=88.70%, avg_specificity=86.60% avg_auc=0.9422
Fold[7] Epoch: 107 [107/150 (71%)] Train loss=0.025318 Test loss=1.068343 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.022862151265144348
[5/24] Train loss=0.019301502034068108
[10/24] Train loss=0.023668210953474045
[15/24] Train loss=0.025082021951675415
[20/24] Train loss=0.023731743916869164
Test set avg_accuracy=88.06% avg_sensitivity=86.08%, avg_specificity=88.81% avg_auc=0.9401
Fold[7] Epoch: 108 [108/150 (72%)] Train loss=0.027711 Test loss=0.876717 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.02765839919447899
[5/24] Train loss=0.017669668421149254
[10/24] Train loss=0.029926739633083344
[15/24] Train loss=0.016976580023765564
[20/24] Train loss=0.023605186492204666
Test set avg_accuracy=87.11% avg_sensitivity=87.70%, avg_specificity=86.89% avg_auc=0.9432
Fold[7] Epoch: 109 [109/150 (73%)] Train loss=0.024776 Test loss=1.055689 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.026602694764733315
[5/24] Train loss=0.02176380157470703
[10/24] Train loss=0.023629838600754738
[15/24] Train loss=0.026270633563399315
[20/24] Train loss=0.031177783384919167
Test set avg_accuracy=88.10% avg_sensitivity=85.55%, avg_specificity=89.06% avg_auc=0.9413
Fold[7] Epoch: 110 [110/150 (73%)] Train loss=0.028946 Test loss=0.795864 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.019799189642071724
[5/24] Train loss=0.017730440944433212
[10/24] Train loss=0.041607752442359924
[15/24] Train loss=0.021797778084874153
[20/24] Train loss=0.02219906821846962
Test set avg_accuracy=87.64% avg_sensitivity=86.36%, avg_specificity=88.12% avg_auc=0.9411
Fold[7] Epoch: 111 [111/150 (74%)] Train loss=0.026158 Test loss=1.009111 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.01984044350683689
[5/24] Train loss=0.015746494755148888
[10/24] Train loss=0.03790820762515068
[15/24] Train loss=0.02828042209148407
[20/24] Train loss=0.03695640712976456
Test set avg_accuracy=86.09% avg_sensitivity=90.13%, avg_specificity=84.58% avg_auc=0.9411
Fold[7] Epoch: 112 [112/150 (75%)] Train loss=0.022286 Test loss=1.162791 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.02082384191453457
[5/24] Train loss=0.017203427851200104
[10/24] Train loss=0.023471686989068985
[15/24] Train loss=0.019230278208851814
[20/24] Train loss=0.018028244376182556
Test set avg_accuracy=87.72% avg_sensitivity=86.46%, avg_specificity=88.20% avg_auc=0.9413
Fold[7] Epoch: 113 [113/150 (75%)] Train loss=0.023333 Test loss=0.921552 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.015373766422271729
[5/24] Train loss=0.01430013682693243
[10/24] Train loss=0.015889696776866913
[15/24] Train loss=0.0204683318734169
[20/24] Train loss=0.01611904241144657
Test set avg_accuracy=87.17% avg_sensitivity=87.70%, avg_specificity=86.98% avg_auc=0.9428
Fold[7] Epoch: 114 [114/150 (76%)] Train loss=0.018996 Test loss=1.097579 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.021878238767385483
[5/24] Train loss=0.02277194708585739
[10/24] Train loss=0.022114118561148643
[15/24] Train loss=0.018102439120411873
[20/24] Train loss=0.027383990585803986
Test set avg_accuracy=87.79% avg_sensitivity=85.36%, avg_specificity=88.70% avg_auc=0.9414
Fold[7] Epoch: 115 [115/150 (77%)] Train loss=0.021102 Test loss=1.000409 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.013574536889791489
[5/24] Train loss=0.011160146445035934
[10/24] Train loss=0.018987976014614105
[15/24] Train loss=0.016680089756846428
[20/24] Train loss=0.033279336988925934
Test set avg_accuracy=87.85% avg_sensitivity=87.70%, avg_specificity=87.91% avg_auc=0.9434
Fold[7] Epoch: 116 [116/150 (77%)] Train loss=0.017566 Test loss=1.090394 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.015448292717337608
[5/24] Train loss=0.011771833524107933
[10/24] Train loss=0.012308952398598194
[15/24] Train loss=0.016035061329603195
[20/24] Train loss=0.016145681962370872
Test set avg_accuracy=86.67% avg_sensitivity=90.61%, avg_specificity=85.19% avg_auc=0.9435
Fold[7] Epoch: 117 [117/150 (78%)] Train loss=0.016156 Test loss=1.129756 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.018798012286424637
[5/24] Train loss=0.018048109486699104
[10/24] Train loss=0.024379771202802658
[15/24] Train loss=0.01727096363902092
[20/24] Train loss=0.017362164333462715
Test set avg_accuracy=87.41% avg_sensitivity=88.75%, avg_specificity=86.91% avg_auc=0.9427
Fold[7] Epoch: 118 [118/150 (79%)] Train loss=0.018863 Test loss=0.981895 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.015691488981246948
[5/24] Train loss=0.014085222966969013
[10/24] Train loss=0.02078731544315815
[15/24] Train loss=0.015300912782549858
[20/24] Train loss=0.01687982678413391
Test set avg_accuracy=87.97% avg_sensitivity=87.84%, avg_specificity=88.02% avg_auc=0.9424
Fold[7] Epoch: 119 [119/150 (79%)] Train loss=0.018686 Test loss=0.969928 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.015413438901305199
[5/24] Train loss=0.021744757890701294
[10/24] Train loss=0.012814641930162907
[15/24] Train loss=0.014757590368390083
[20/24] Train loss=0.01478644274175167
Test set avg_accuracy=87.97% avg_sensitivity=88.89%, avg_specificity=87.62% avg_auc=0.9427
Fold[7] Epoch: 120 [120/150 (80%)] Train loss=0.017418 Test loss=1.055034 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.0153605155646801
[5/24] Train loss=0.012508893385529518
[10/24] Train loss=0.012960978783667088
[15/24] Train loss=0.017103441059589386
[20/24] Train loss=0.016926582902669907
Test set avg_accuracy=88.10% avg_sensitivity=85.74%, avg_specificity=88.98% avg_auc=0.9424
Fold[7] Epoch: 121 [121/150 (81%)] Train loss=0.017723 Test loss=0.962596 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.009616059251129627
[5/24] Train loss=0.022700104862451553
[10/24] Train loss=0.010470570996403694
[15/24] Train loss=0.016854584217071533
[20/24] Train loss=0.01366107165813446
Test set avg_accuracy=87.94% avg_sensitivity=87.70%, avg_specificity=88.04% avg_auc=0.9432
Fold[7] Epoch: 122 [122/150 (81%)] Train loss=0.014827 Test loss=1.095592 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.010930958203971386
[5/24] Train loss=0.011822187341749668
[10/24] Train loss=0.011971878819167614
[15/24] Train loss=0.0183594711124897
[20/24] Train loss=0.01579262875020504
Test set avg_accuracy=87.51% avg_sensitivity=90.70%, avg_specificity=86.32% avg_auc=0.9444
Fold[7] Epoch: 123 [123/150 (82%)] Train loss=0.017291 Test loss=1.224963 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.017898306250572205
[5/24] Train loss=0.011444147676229477
[10/24] Train loss=0.02498926967382431
[15/24] Train loss=0.01453531626611948
[20/24] Train loss=0.016613543033599854
Test set avg_accuracy=87.88% avg_sensitivity=88.70%, avg_specificity=87.57% avg_auc=0.9433
Fold[7] Epoch: 124 [124/150 (83%)] Train loss=0.017197 Test loss=1.052843 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.01876605860888958
[5/24] Train loss=0.012159368023276329
[10/24] Train loss=0.01273931935429573
[15/24] Train loss=0.012727269902825356
[20/24] Train loss=0.019597100093960762
Test set avg_accuracy=87.96% avg_sensitivity=85.46%, avg_specificity=88.89% avg_auc=0.9422
Fold[7] Epoch: 125 [125/150 (83%)] Train loss=0.017939 Test loss=1.017523 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.017293721437454224
[5/24] Train loss=0.009099241346120834
[10/24] Train loss=0.013497323729097843
[15/24] Train loss=0.008801916614174843
[20/24] Train loss=0.013911566697061062
Test set avg_accuracy=87.81% avg_sensitivity=87.22%, avg_specificity=88.04% avg_auc=0.9421
Fold[7] Epoch: 126 [126/150 (84%)] Train loss=0.015060 Test loss=1.108989 Current lr=[0.000123057953306828]

[0/24] Train loss=0.009414632804691792
[5/24] Train loss=0.008618124760687351
[10/24] Train loss=0.01590709201991558
[15/24] Train loss=0.023231107741594315
[20/24] Train loss=0.0191084835678339
Test set avg_accuracy=87.53% avg_sensitivity=89.56%, avg_specificity=86.76% avg_auc=0.9433
Fold[7] Epoch: 127 [127/150 (85%)] Train loss=0.014256 Test loss=1.171547 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.018142063170671463
[5/24] Train loss=0.01530381478369236
[10/24] Train loss=0.015834879130125046
[15/24] Train loss=0.011660031974315643
[20/24] Train loss=0.014943866990506649
Test set avg_accuracy=87.58% avg_sensitivity=88.17%, avg_specificity=87.35% avg_auc=0.9434
Fold[7] Epoch: 128 [128/150 (85%)] Train loss=0.014153 Test loss=1.130487 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.016570359468460083
[5/24] Train loss=0.022469371557235718
[10/24] Train loss=0.014523777179419994
[15/24] Train loss=0.015670347958803177
[20/24] Train loss=0.02172892913222313
Test set avg_accuracy=87.55% avg_sensitivity=86.50%, avg_specificity=87.95% avg_auc=0.9431
Fold[7] Epoch: 129 [129/150 (86%)] Train loss=0.017136 Test loss=1.025414 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.011886759661138058
[5/24] Train loss=0.012744864448904991
[10/24] Train loss=0.010226890444755554
[15/24] Train loss=0.010489062406122684
[20/24] Train loss=0.014205271378159523
Test set avg_accuracy=87.90% avg_sensitivity=87.17%, avg_specificity=88.18% avg_auc=0.9433
Fold[7] Epoch: 130 [130/150 (87%)] Train loss=0.013807 Test loss=1.042229 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.01094015222042799
[5/24] Train loss=0.009002654813230038
[10/24] Train loss=0.013433905318379402
[15/24] Train loss=0.009591000154614449
[20/24] Train loss=0.010664451867341995
Test set avg_accuracy=87.77% avg_sensitivity=87.55%, avg_specificity=87.86% avg_auc=0.9436
Fold[7] Epoch: 131 [131/150 (87%)] Train loss=0.012401 Test loss=1.093024 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.013787918724119663
[5/24] Train loss=0.009816579520702362
[10/24] Train loss=0.009988383390009403
[15/24] Train loss=0.015987057238817215
[20/24] Train loss=0.014362101443111897
Test set avg_accuracy=87.60% avg_sensitivity=89.08%, avg_specificity=87.05% avg_auc=0.9438
Fold[7] Epoch: 132 [132/150 (88%)] Train loss=0.012460 Test loss=1.173583 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.009944967925548553
[5/24] Train loss=0.010729927569627762
[10/24] Train loss=0.00929071195423603
[15/24] Train loss=0.016256194561719894
[20/24] Train loss=0.010615264065563679
Test set avg_accuracy=87.85% avg_sensitivity=89.08%, avg_specificity=87.39% avg_auc=0.9437
Fold[7] Epoch: 133 [133/150 (89%)] Train loss=0.011986 Test loss=1.166637 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.012972298078238964
[5/24] Train loss=0.008653340861201286
[10/24] Train loss=0.015433233231306076
[15/24] Train loss=0.010738877579569817
[20/24] Train loss=0.01627398654818535
Test set avg_accuracy=87.85% avg_sensitivity=87.60%, avg_specificity=87.95% avg_auc=0.9438
Fold[7] Epoch: 134 [134/150 (89%)] Train loss=0.013024 Test loss=1.106056 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.008822305127978325
[5/24] Train loss=0.00844290480017662
[10/24] Train loss=0.012470986694097519
[15/24] Train loss=0.0097122797742486
[20/24] Train loss=0.01686134748160839
Test set avg_accuracy=87.88% avg_sensitivity=87.41%, avg_specificity=88.05% avg_auc=0.9439
Fold[7] Epoch: 135 [135/150 (90%)] Train loss=0.011033 Test loss=1.104861 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.011166074313223362
[5/24] Train loss=0.007348456420004368
[10/24] Train loss=0.027144288644194603
[15/24] Train loss=0.013341651298105717
[20/24] Train loss=0.011035339906811714
Test set avg_accuracy=88.01% avg_sensitivity=88.03%, avg_specificity=88.00% avg_auc=0.9442
Fold[7] Epoch: 136 [136/150 (91%)] Train loss=0.011657 Test loss=1.133013 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.009772825054824352
[5/24] Train loss=0.008568614721298218
[10/24] Train loss=0.012155425734817982
[15/24] Train loss=0.013271340169012547
[20/24] Train loss=0.010263588279485703
Test set avg_accuracy=87.89% avg_sensitivity=88.51%, avg_specificity=87.66% avg_auc=0.9442
Fold[7] Epoch: 137 [137/150 (91%)] Train loss=0.012146 Test loss=1.144446 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.010786889120936394
[5/24] Train loss=0.01892487332224846
[10/24] Train loss=0.009564923122525215
[15/24] Train loss=0.015031058341264725
[20/24] Train loss=0.011283205822110176
Test set avg_accuracy=87.84% avg_sensitivity=88.65%, avg_specificity=87.53% avg_auc=0.9441
Fold[7] Epoch: 138 [138/150 (92%)] Train loss=0.013356 Test loss=1.126049 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.012916634790599346
[5/24] Train loss=0.013392521068453789
[10/24] Train loss=0.012202225625514984
[15/24] Train loss=0.014575514942407608
[20/24] Train loss=0.014759204350411892
Test set avg_accuracy=88.10% avg_sensitivity=87.51%, avg_specificity=88.32% avg_auc=0.9439
Fold[7] Epoch: 139 [139/150 (93%)] Train loss=0.013565 Test loss=1.094260 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.011453607119619846
[5/24] Train loss=0.012574009597301483
[10/24] Train loss=0.011707221157848835
[15/24] Train loss=0.011800014413893223
[20/24] Train loss=0.010382372885942459
Test set avg_accuracy=88.11% avg_sensitivity=87.32%, avg_specificity=88.41% avg_auc=0.9438
Fold[7] Epoch: 140 [140/150 (93%)] Train loss=0.011889 Test loss=1.083237 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.01029546745121479
[5/24] Train loss=0.007078852970153093
[10/24] Train loss=0.0073652309365570545
[15/24] Train loss=0.0074820751324296
[20/24] Train loss=0.018036728724837303
Test set avg_accuracy=88.10% avg_sensitivity=87.41%, avg_specificity=88.36% avg_auc=0.9438
Fold[7] Epoch: 141 [141/150 (94%)] Train loss=0.010828 Test loss=1.070998 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.007352072279900312
[5/24] Train loss=0.013679379597306252
[10/24] Train loss=0.01032040175050497
[15/24] Train loss=0.00919905211776495
[20/24] Train loss=0.01125252339988947
Test set avg_accuracy=88.07% avg_sensitivity=87.36%, avg_specificity=88.34% avg_auc=0.9438
Fold[7] Epoch: 142 [142/150 (95%)] Train loss=0.010223 Test loss=1.089579 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.03466969355940819
[5/24] Train loss=0.0071873171254992485
[10/24] Train loss=0.008654316887259483
[15/24] Train loss=0.007340239826589823
[20/24] Train loss=0.007839641533792019
Test set avg_accuracy=88.03% avg_sensitivity=87.65%, avg_specificity=88.18% avg_auc=0.9439
Fold[7] Epoch: 143 [143/150 (95%)] Train loss=0.010750 Test loss=1.113074 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.01606496050953865
[5/24] Train loss=0.011172407306730747
[10/24] Train loss=0.00615663779899478
[15/24] Train loss=0.006093931384384632
[20/24] Train loss=0.010551294311881065
Test set avg_accuracy=88.06% avg_sensitivity=88.08%, avg_specificity=88.05% avg_auc=0.9441
Fold[7] Epoch: 144 [144/150 (96%)] Train loss=0.010493 Test loss=1.125156 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.020419927313923836
[5/24] Train loss=0.01313360407948494
[10/24] Train loss=0.007045196834951639
[15/24] Train loss=0.009076057933270931
[20/24] Train loss=0.006515678949654102
Test set avg_accuracy=87.97% avg_sensitivity=88.08%, avg_specificity=87.93% avg_auc=0.9440
Fold[7] Epoch: 145 [145/150 (97%)] Train loss=0.012001 Test loss=1.155038 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.010424354113638401
[5/24] Train loss=0.0071061705239117146
[10/24] Train loss=0.007224627770483494
[15/24] Train loss=0.007064960431307554
[20/24] Train loss=0.010548550635576248
Test set avg_accuracy=87.62% avg_sensitivity=88.13%, avg_specificity=87.43% avg_auc=0.9441
Fold[7] Epoch: 146 [146/150 (97%)] Train loss=0.009959 Test loss=1.156894 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.008945145644247532
[5/24] Train loss=0.010313337668776512
[10/24] Train loss=0.03021172061562538
[15/24] Train loss=0.010497525334358215
[20/24] Train loss=0.009593076072633266
Test set avg_accuracy=87.62% avg_sensitivity=88.13%, avg_specificity=87.43% avg_auc=0.9441
Fold[7] Epoch: 147 [147/150 (98%)] Train loss=0.011606 Test loss=1.157407 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.009874352253973484
[5/24] Train loss=0.01432118657976389
[10/24] Train loss=0.00913382787257433
[15/24] Train loss=0.016769248992204666
[20/24] Train loss=0.015962468460202217
Test set avg_accuracy=87.73% avg_sensitivity=88.17%, avg_specificity=87.57% avg_auc=0.9441
Fold[7] Epoch: 148 [148/150 (99%)] Train loss=0.013674 Test loss=1.157910 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.011593556962907314
[5/24] Train loss=0.00955619104206562
[10/24] Train loss=0.013382862322032452
[15/24] Train loss=0.014730200171470642
[20/24] Train loss=0.012494103983044624
Test set avg_accuracy=87.73% avg_sensitivity=88.17%, avg_specificity=87.57% avg_auc=0.9441
Fold[7] Epoch: 149 [149/150 (99%)] Train loss=0.013968 Test loss=1.156855 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.02229990065097809
[5/24] Train loss=0.01187669113278389
[10/24] Train loss=0.013685944490134716
[15/24] Train loss=0.01494554802775383
[20/24] Train loss=0.01665736548602581
Test set avg_accuracy=87.72% avg_sensitivity=88.13%, avg_specificity=87.57% avg_auc=0.9441
Fold[7] Epoch: 150 [150/150 (100%)] Train loss=0.017545 Test loss=1.156720 Current lr=[4.388541022775342e-09]

Fold[7] Result: acc=87.25% sen=91.23%, spe=85.76%, auc=0.95!
Fold[7] Avg_overlap=0.77%(0.19386357552657033)
[0/24] Train loss=1.42947256565094
[5/24] Train loss=1.303492784500122
[10/24] Train loss=1.325976848602295
[15/24] Train loss=1.1643400192260742
[20/24] Train loss=1.0897583961486816
Test set avg_accuracy=75.51% avg_sensitivity=13.74%, avg_specificity=95.80% avg_auc=0.7294
Best model saved!! Metric=0.7293873841229085!!
Fold[8] Epoch: 1 [1/150 (1%)] Train loss=1.262057 Test loss=0.542276 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=1.0454058647155762
[5/24] Train loss=0.9094318747520447
[10/24] Train loss=1.0221296548843384
[15/24] Train loss=0.8709986805915833
[20/24] Train loss=0.9067613482475281
Test set avg_accuracy=80.87% avg_sensitivity=75.83%, avg_specificity=82.53% avg_auc=0.8532
Best model saved!! Metric=0.8532198457677493!!
Fold[8] Epoch: 2 [2/150 (1%)] Train loss=0.972623 Test loss=0.514476 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.8111327886581421
[5/24] Train loss=0.7944505214691162
[10/24] Train loss=0.8814360499382019
[15/24] Train loss=0.7723098993301392
[20/24] Train loss=0.8103752732276917
Test set avg_accuracy=81.35% avg_sensitivity=76.57%, avg_specificity=82.93% avg_auc=0.8617
Best model saved!! Metric=0.8617220764322194!!
Fold[8] Epoch: 3 [3/150 (2%)] Train loss=0.855979 Test loss=0.516290 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.7787938714027405
[5/24] Train loss=0.7155707478523254
[10/24] Train loss=0.8221682906150818
[15/24] Train loss=0.7160683274269104
[20/24] Train loss=0.7355197072029114
Test set avg_accuracy=78.36% avg_sensitivity=85.83%, avg_specificity=75.90% avg_auc=0.8894
Best model saved!! Metric=0.8893994954873417!!
Fold[8] Epoch: 4 [4/150 (3%)] Train loss=0.777975 Test loss=0.608209 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.7979565262794495
[5/24] Train loss=0.725212037563324
[10/24] Train loss=0.8138883113861084
[15/24] Train loss=0.7129185199737549
[20/24] Train loss=0.6786972284317017
Test set avg_accuracy=82.16% avg_sensitivity=82.41%, avg_specificity=82.08% avg_auc=0.8963
Best model saved!! Metric=0.8963292345437319!!
Fold[8] Epoch: 5 [5/150 (3%)] Train loss=0.777219 Test loss=0.479861 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.7411127090454102
[5/24] Train loss=0.7291378974914551
[10/24] Train loss=0.7781557440757751
[15/24] Train loss=0.6978652477264404
[20/24] Train loss=0.7084190249443054
Test set avg_accuracy=82.47% avg_sensitivity=83.15%, avg_specificity=82.25% avg_auc=0.9034
Best model saved!! Metric=0.9033600838176375!!
Fold[8] Epoch: 6 [6/150 (4%)] Train loss=0.762896 Test loss=0.466385 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.7503558993339539
[5/24] Train loss=0.6813574433326721
[10/24] Train loss=0.7791516184806824
[15/24] Train loss=0.7038663625717163
[20/24] Train loss=0.673443615436554
Test set avg_accuracy=86.08% avg_sensitivity=76.83%, avg_specificity=89.12% avg_auc=0.9083
Best model saved!! Metric=0.9083015041101303!!
Fold[8] Epoch: 7 [7/150 (5%)] Train loss=0.755342 Test loss=0.375839 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.7053302526473999
[5/24] Train loss=0.6314442157745361
[10/24] Train loss=0.7594782114028931
[15/24] Train loss=0.6515508890151978
[20/24] Train loss=0.639643132686615
Test set avg_accuracy=82.23% avg_sensitivity=85.26%, avg_specificity=81.23% avg_auc=0.9098
Best model saved!! Metric=0.909833733811776!!
Fold[8] Epoch: 8 [8/150 (5%)] Train loss=0.713079 Test loss=0.475018 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.7239699959754944
[5/24] Train loss=0.6655566096305847
[10/24] Train loss=0.7174249291419983
[15/24] Train loss=0.6601207852363586
[20/24] Train loss=0.6206876039505005
Test set avg_accuracy=85.18% avg_sensitivity=81.89%, avg_specificity=86.27% avg_auc=0.9129
Best model saved!! Metric=0.9128693175943893!!
Fold[8] Epoch: 9 [9/150 (6%)] Train loss=0.713351 Test loss=0.396178 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.6750226616859436
[5/24] Train loss=0.6024163961410522
[10/24] Train loss=0.6977835893630981
[15/24] Train loss=0.5908878445625305
[20/24] Train loss=0.5896690487861633
Test set avg_accuracy=82.84% avg_sensitivity=84.36%, avg_specificity=82.34% avg_auc=0.9117
Fold[8] Epoch: 10 [10/150 (7%)] Train loss=0.676713 Test loss=0.470212 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.6571642756462097
[5/24] Train loss=0.6089184880256653
[10/24] Train loss=0.6893268823623657
[15/24] Train loss=0.6309824585914612
[20/24] Train loss=0.6248827576637268
Test set avg_accuracy=86.56% avg_sensitivity=80.62%, avg_specificity=88.51% avg_auc=0.9129
Fold[8] Epoch: 11 [11/150 (7%)] Train loss=0.686202 Test loss=0.379074 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.6184399127960205
[5/24] Train loss=0.5790606737136841
[10/24] Train loss=0.672418475151062
[15/24] Train loss=0.5812870264053345
[20/24] Train loss=0.5381871461868286
Test set avg_accuracy=82.30% avg_sensitivity=84.89%, avg_specificity=81.46% avg_auc=0.9129
Best model saved!! Metric=0.912917868716854!!
Fold[8] Epoch: 12 [12/150 (8%)] Train loss=0.641276 Test loss=0.464214 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.645056426525116
[5/24] Train loss=0.6122726798057556
[10/24] Train loss=0.6882607936859131
[15/24] Train loss=0.5881229639053345
[20/24] Train loss=0.6137143969535828
Test set avg_accuracy=84.43% avg_sensitivity=83.62%, avg_specificity=84.69% avg_auc=0.9142
Best model saved!! Metric=0.9141813820746524!!
Fold[8] Epoch: 13 [13/150 (9%)] Train loss=0.656119 Test loss=0.391158 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.633280336856842
[5/24] Train loss=0.5671065449714661
[10/24] Train loss=0.6673846244812012
[15/24] Train loss=0.5753251314163208
[20/24] Train loss=0.5481740236282349
Test set avg_accuracy=84.67% avg_sensitivity=82.89%, avg_specificity=85.26% avg_auc=0.9151
Best model saved!! Metric=0.915080853104252!!
Fold[8] Epoch: 14 [14/150 (9%)] Train loss=0.626456 Test loss=0.427332 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.5895907282829285
[5/24] Train loss=0.5459083914756775
[10/24] Train loss=0.6667198538780212
[15/24] Train loss=0.5532870888710022
[20/24] Train loss=0.5346583127975464
Test set avg_accuracy=82.07% avg_sensitivity=86.15%, avg_specificity=80.73% avg_auc=0.9151
Fold[8] Epoch: 15 [15/150 (10%)] Train loss=0.603496 Test loss=0.501830 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.6216331124305725
[5/24] Train loss=0.5823661088943481
[10/24] Train loss=0.6889362931251526
[15/24] Train loss=0.5474532842636108
[20/24] Train loss=0.5238857269287109
Test set avg_accuracy=84.43% avg_sensitivity=85.62%, avg_specificity=84.03% avg_auc=0.9175
Best model saved!! Metric=0.9174677374147613!!
Fold[8] Epoch: 16 [16/150 (11%)] Train loss=0.614751 Test loss=0.427166 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.6334237456321716
[5/24] Train loss=0.5740683674812317
[10/24] Train loss=0.684372067451477
[15/24] Train loss=0.5376414060592651
[20/24] Train loss=0.536523699760437
Test set avg_accuracy=87.40% avg_sensitivity=80.46%, avg_specificity=89.67% avg_auc=0.9195
Best model saved!! Metric=0.9194573769878065!!
Fold[8] Epoch: 17 [17/150 (11%)] Train loss=0.616529 Test loss=0.361199 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.6089178919792175
[5/24] Train loss=0.5257105827331543
[10/24] Train loss=0.6504040956497192
[15/24] Train loss=0.5261092185974121
[20/24] Train loss=0.519006609916687
Test set avg_accuracy=85.96% avg_sensitivity=83.36%, avg_specificity=86.82% avg_auc=0.9192
Fold[8] Epoch: 18 [18/150 (12%)] Train loss=0.598557 Test loss=0.405015 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.5729675889015198
[5/24] Train loss=0.50433748960495
[10/24] Train loss=0.6375227570533752
[15/24] Train loss=0.5218837261199951
[20/24] Train loss=0.5152261853218079
Test set avg_accuracy=82.79% avg_sensitivity=87.89%, avg_specificity=81.11% avg_auc=0.9208
Best model saved!! Metric=0.9208060597630612!!
Fold[8] Epoch: 19 [19/150 (13%)] Train loss=0.572117 Test loss=0.490462 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.5870617628097534
[5/24] Train loss=0.5149017572402954
[10/24] Train loss=0.6304551959037781
[15/24] Train loss=0.5360279083251953
[20/24] Train loss=0.5253628492355347
Test set avg_accuracy=86.02% avg_sensitivity=83.78%, avg_specificity=86.75% avg_auc=0.9186
Fold[8] Epoch: 20 [20/150 (13%)] Train loss=0.589764 Test loss=0.379564 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.5986505150794983
[5/24] Train loss=0.5159627199172974
[10/24] Train loss=0.6281759142875671
[15/24] Train loss=0.503677248954773
[20/24] Train loss=0.48944371938705444
Test set avg_accuracy=79.32% avg_sensitivity=90.36%, avg_specificity=75.70% avg_auc=0.9213
Best model saved!! Metric=0.9212566834081505!!
Fold[8] Epoch: 21 [21/150 (14%)] Train loss=0.569158 Test loss=0.520549 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.5901299715042114
[5/24] Train loss=0.5236043930053711
[10/24] Train loss=0.6112498044967651
[15/24] Train loss=0.5272085666656494
[20/24] Train loss=0.4624435007572174
Test set avg_accuracy=86.02% avg_sensitivity=82.83%, avg_specificity=87.06% avg_auc=0.9168
Fold[8] Epoch: 22 [22/150 (15%)] Train loss=0.574676 Test loss=0.380470 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.6062542200088501
[5/24] Train loss=0.5121898651123047
[10/24] Train loss=0.6050785779953003
[15/24] Train loss=0.4884120523929596
[20/24] Train loss=0.4728323817253113
Test set avg_accuracy=82.67% avg_sensitivity=84.83%, avg_specificity=81.96% avg_auc=0.9169
Fold[8] Epoch: 23 [23/150 (15%)] Train loss=0.557625 Test loss=0.449145 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5765060782432556
[5/24] Train loss=0.5178724527359009
[10/24] Train loss=0.571125864982605
[15/24] Train loss=0.4972224831581116
[20/24] Train loss=0.4999677836894989
Test set avg_accuracy=84.39% avg_sensitivity=87.78%, avg_specificity=83.27% avg_auc=0.9243
Best model saved!! Metric=0.9242897166627544!!
Fold[8] Epoch: 24 [24/150 (16%)] Train loss=0.566540 Test loss=0.410140 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.594947874546051
[5/24] Train loss=0.5212052464485168
[10/24] Train loss=0.5976439118385315
[15/24] Train loss=0.47036245465278625
[20/24] Train loss=0.4667297899723053
Test set avg_accuracy=88.09% avg_sensitivity=78.15%, avg_specificity=91.35% avg_auc=0.9181
Fold[8] Epoch: 25 [25/150 (17%)] Train loss=0.564661 Test loss=0.337700 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5755012631416321
[5/24] Train loss=0.47088176012039185
[10/24] Train loss=0.5751782059669495
[15/24] Train loss=0.46922916173934937
[20/24] Train loss=0.49030178785324097
Test set avg_accuracy=87.60% avg_sensitivity=81.67%, avg_specificity=89.55% avg_auc=0.9212
Fold[8] Epoch: 26 [26/150 (17%)] Train loss=0.552334 Test loss=0.361308 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5516397356987
[5/24] Train loss=0.4875313341617584
[10/24] Train loss=0.5493642687797546
[15/24] Train loss=0.5003787875175476
[20/24] Train loss=0.43836238980293274
Test set avg_accuracy=81.82% avg_sensitivity=87.57%, avg_specificity=79.93% avg_auc=0.9221
Fold[8] Epoch: 27 [27/150 (18%)] Train loss=0.522488 Test loss=0.504808 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5633529424667358
[5/24] Train loss=0.4946177303791046
[10/24] Train loss=0.5653311610221863
[15/24] Train loss=0.4819512665271759
[20/24] Train loss=0.4807758629322052
Test set avg_accuracy=84.80% avg_sensitivity=85.68%, avg_specificity=84.52% avg_auc=0.9238
Fold[8] Epoch: 28 [28/150 (19%)] Train loss=0.528930 Test loss=0.401524 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5901651978492737
[5/24] Train loss=0.4556867182254791
[10/24] Train loss=0.5515870451927185
[15/24] Train loss=0.46918565034866333
[20/24] Train loss=0.44789615273475647
Test set avg_accuracy=88.37% avg_sensitivity=79.99%, avg_specificity=91.13% avg_auc=0.9228
Fold[8] Epoch: 29 [29/150 (19%)] Train loss=0.535238 Test loss=0.332479 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.5971747040748596
[5/24] Train loss=0.46468108892440796
[10/24] Train loss=0.5395246744155884
[15/24] Train loss=0.44524163007736206
[20/24] Train loss=0.44532135128974915
Test set avg_accuracy=87.80% avg_sensitivity=80.83%, avg_specificity=90.09% avg_auc=0.9180
Fold[8] Epoch: 30 [30/150 (20%)] Train loss=0.519365 Test loss=0.360160 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.5841489434242249
[5/24] Train loss=0.45937469601631165
[10/24] Train loss=0.5461471080780029
[15/24] Train loss=0.43450257182121277
[20/24] Train loss=0.45032957196235657
Test set avg_accuracy=83.27% avg_sensitivity=86.89%, avg_specificity=82.08% avg_auc=0.9206
Fold[8] Epoch: 31 [31/150 (21%)] Train loss=0.516032 Test loss=0.469746 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.5292014479637146
[5/24] Train loss=0.4767880141735077
[10/24] Train loss=0.5139898657798767
[15/24] Train loss=0.4517221748828888
[20/24] Train loss=0.43361330032348633
Test set avg_accuracy=85.82% avg_sensitivity=82.62%, avg_specificity=86.87% avg_auc=0.9225
Fold[8] Epoch: 32 [32/150 (21%)] Train loss=0.515311 Test loss=0.395063 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.5239567756652832
[5/24] Train loss=0.4175551235675812
[10/24] Train loss=0.5590632557868958
[15/24] Train loss=0.4778674840927124
[20/24] Train loss=0.45588791370391846
Test set avg_accuracy=78.33% avg_sensitivity=89.78%, avg_specificity=74.57% avg_auc=0.9243
Best model saved!! Metric=0.9242904453850427!!
Fold[8] Epoch: 33 [33/150 (22%)] Train loss=0.495172 Test loss=0.573801 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.5275744795799255
[5/24] Train loss=0.44534265995025635
[10/24] Train loss=0.4853459894657135
[15/24] Train loss=0.48592251539230347
[20/24] Train loss=0.41993093490600586
Test set avg_accuracy=86.88% avg_sensitivity=80.62%, avg_specificity=88.93% avg_auc=0.9158
Fold[8] Epoch: 34 [34/150 (23%)] Train loss=0.511275 Test loss=0.368847 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.5285055637359619
[5/24] Train loss=0.40016281604766846
[10/24] Train loss=0.5087966322898865
[15/24] Train loss=0.40078744292259216
[20/24] Train loss=0.40812650322914124
Test set avg_accuracy=84.92% avg_sensitivity=83.41%, avg_specificity=85.42% avg_auc=0.9154
Fold[8] Epoch: 35 [35/150 (23%)] Train loss=0.474841 Test loss=0.427239 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.502144455909729
[5/24] Train loss=0.4153556525707245
[10/24] Train loss=0.4573790729045868
[15/24] Train loss=0.40628841519355774
[20/24] Train loss=0.41868045926094055
Test set avg_accuracy=79.64% avg_sensitivity=89.52%, avg_specificity=76.39% avg_auc=0.9238
Fold[8] Epoch: 36 [36/150 (24%)] Train loss=0.455418 Test loss=0.555348 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.47148147225379944
[5/24] Train loss=0.43589988350868225
[10/24] Train loss=0.4602620601654053
[15/24] Train loss=0.39671018719673157
[20/24] Train loss=0.3565589487552643
Test set avg_accuracy=78.89% avg_sensitivity=91.42%, avg_specificity=74.78% avg_auc=0.9271
Best model saved!! Metric=0.9270510731392145!!
Fold[8] Epoch: 37 [37/150 (25%)] Train loss=0.457362 Test loss=0.554468 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.5098686218261719
[5/24] Train loss=0.4050753712654114
[10/24] Train loss=0.5333919525146484
[15/24] Train loss=0.4117373824119568
[20/24] Train loss=0.3935404121875763
Test set avg_accuracy=84.80% avg_sensitivity=86.36%, avg_specificity=84.29% avg_auc=0.9226
Fold[8] Epoch: 38 [38/150 (25%)] Train loss=0.471410 Test loss=0.418321 Current lr=[0.000944367614404117]

[0/24] Train loss=0.4821595251560211
[5/24] Train loss=0.40744292736053467
[10/24] Train loss=0.4439944922924042
[15/24] Train loss=0.42362380027770996
[20/24] Train loss=0.351345956325531
Test set avg_accuracy=86.93% avg_sensitivity=82.41%, avg_specificity=88.41% avg_auc=0.9249
Fold[8] Epoch: 39 [39/150 (26%)] Train loss=0.461160 Test loss=0.373568 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.486014723777771
[5/24] Train loss=0.40039998292922974
[10/24] Train loss=0.4772210121154785
[15/24] Train loss=0.3922901451587677
[20/24] Train loss=0.3431943356990814
Test set avg_accuracy=87.73% avg_sensitivity=80.83%, avg_specificity=90.00% avg_auc=0.9206
Fold[8] Epoch: 40 [40/150 (27%)] Train loss=0.439372 Test loss=0.371775 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.44593140482902527
[5/24] Train loss=0.3852103650569916
[10/24] Train loss=0.4380265176296234
[15/24] Train loss=0.3728208839893341
[20/24] Train loss=0.3335244059562683
Test set avg_accuracy=85.46% avg_sensitivity=84.47%, avg_specificity=85.78% avg_auc=0.9217
Fold[8] Epoch: 41 [41/150 (27%)] Train loss=0.416670 Test loss=0.431929 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.384073406457901
[5/24] Train loss=0.3506144881248474
[10/24] Train loss=0.43391573429107666
[15/24] Train loss=0.34331992268562317
[20/24] Train loss=0.32720306515693665
Test set avg_accuracy=80.08% avg_sensitivity=89.52%, avg_specificity=76.98% avg_auc=0.9219
Fold[8] Epoch: 42 [42/150 (28%)] Train loss=0.394767 Test loss=0.567658 Current lr=[0.000989780311725182]

[0/24] Train loss=0.4402451515197754
[5/24] Train loss=0.4014021158218384
[10/24] Train loss=0.4343647360801697
[15/24] Train loss=0.3770581781864166
[20/24] Train loss=0.3415929973125458
Test set avg_accuracy=84.44% avg_sensitivity=85.89%, avg_specificity=83.96% avg_auc=0.9209
Fold[8] Epoch: 43 [43/150 (29%)] Train loss=0.416152 Test loss=0.452696 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.45379742980003357
[5/24] Train loss=0.33163321018218994
[10/24] Train loss=0.43539106845855713
[15/24] Train loss=0.353177011013031
[20/24] Train loss=0.32389959692955017
Test set avg_accuracy=82.51% avg_sensitivity=87.94%, avg_specificity=80.73% avg_auc=0.9268
Fold[8] Epoch: 44 [44/150 (29%)] Train loss=0.403184 Test loss=0.501637 Current lr=[0.000998924125869967]

[0/24] Train loss=0.45189014077186584
[5/24] Train loss=0.3316459059715271
[10/24] Train loss=0.4205658733844757
[15/24] Train loss=0.34737199544906616
[20/24] Train loss=0.3564549386501312
Test set avg_accuracy=88.11% avg_sensitivity=77.41%, avg_specificity=91.63% avg_auc=0.9212
Fold[8] Epoch: 45 [45/150 (30%)] Train loss=0.402947 Test loss=0.373910 Current lr=[0.000999999611458977]

[0/24] Train loss=0.4519946575164795
[5/24] Train loss=0.34064963459968567
[10/24] Train loss=0.38635513186454773
[15/24] Train loss=0.31722724437713623
[20/24] Train loss=0.3060557246208191
Test set avg_accuracy=86.51% avg_sensitivity=77.83%, avg_specificity=89.36% avg_auc=0.9125
Fold[8] Epoch: 46 [46/150 (31%)] Train loss=0.375680 Test loss=0.419638 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.36531591415405273
[5/24] Train loss=0.31669631600379944
[10/24] Train loss=0.37241169810295105
[15/24] Train loss=0.27651146054267883
[20/24] Train loss=0.2875502109527588
Test set avg_accuracy=83.57% avg_sensitivity=87.47%, avg_specificity=82.29% avg_auc=0.9277
Best model saved!! Metric=0.9276630176808979!!
Fold[8] Epoch: 47 [47/150 (31%)] Train loss=0.343764 Test loss=0.474597 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.3676932454109192
[5/24] Train loss=0.2826562523841858
[10/24] Train loss=0.36270788311958313
[15/24] Train loss=0.30189046263694763
[20/24] Train loss=0.3215687572956085
Test set avg_accuracy=83.85% avg_sensitivity=88.20%, avg_specificity=82.43% avg_auc=0.9283
Best model saved!! Metric=0.9283016516763937!!
Fold[8] Epoch: 48 [48/150 (32%)] Train loss=0.353694 Test loss=0.441660 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.3921276926994324
[5/24] Train loss=0.29687124490737915
[10/24] Train loss=0.3640458583831787
[15/24] Train loss=0.2864115238189697
[20/24] Train loss=0.3137085735797882
Test set avg_accuracy=84.82% avg_sensitivity=84.62%, avg_specificity=84.88% avg_auc=0.9176
Fold[8] Epoch: 49 [49/150 (33%)] Train loss=0.346259 Test loss=0.442884 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3534936308860779
[5/24] Train loss=0.2698729634284973
[10/24] Train loss=0.35683074593544006
[15/24] Train loss=0.2561184763908386
[20/24] Train loss=0.2775060534477234
Test set avg_accuracy=86.15% avg_sensitivity=83.10%, avg_specificity=87.15% avg_auc=0.9248
Fold[8] Epoch: 50 [50/150 (33%)] Train loss=0.322275 Test loss=0.400923 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.32506313920021057
[5/24] Train loss=0.2294030785560608
[10/24] Train loss=0.33138492703437805
[15/24] Train loss=0.2589508593082428
[20/24] Train loss=0.24845445156097412
Test set avg_accuracy=82.28% avg_sensitivity=89.20%, avg_specificity=80.00% avg_auc=0.9208
Fold[8] Epoch: 51 [51/150 (34%)] Train loss=0.297734 Test loss=0.541020 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.36149898171424866
[5/24] Train loss=0.23948898911476135
[10/24] Train loss=0.3459245264530182
[15/24] Train loss=0.2759983241558075
[20/24] Train loss=0.250990092754364
Test set avg_accuracy=86.43% avg_sensitivity=82.04%, avg_specificity=87.87% avg_auc=0.9170
Fold[8] Epoch: 52 [52/150 (35%)] Train loss=0.299419 Test loss=0.437053 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.3111921548843384
[5/24] Train loss=0.20591513812541962
[10/24] Train loss=0.35935091972351074
[15/24] Train loss=0.2273266613483429
[20/24] Train loss=0.2329442948102951
Test set avg_accuracy=85.09% avg_sensitivity=83.68%, avg_specificity=85.56% avg_auc=0.9230
Fold[8] Epoch: 53 [53/150 (35%)] Train loss=0.280280 Test loss=0.495192 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.3491132855415344
[5/24] Train loss=0.21600870788097382
[10/24] Train loss=0.31686535477638245
[15/24] Train loss=0.22090275585651398
[20/24] Train loss=0.19176116585731506
Test set avg_accuracy=86.98% avg_sensitivity=78.52%, avg_specificity=89.76% avg_auc=0.9169
Fold[8] Epoch: 54 [54/150 (36%)] Train loss=0.268458 Test loss=0.444201 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.24940252304077148
[5/24] Train loss=0.22146496176719666
[10/24] Train loss=0.2431839108467102
[15/24] Train loss=0.18234720826148987
[20/24] Train loss=0.20271331071853638
Test set avg_accuracy=83.76% avg_sensitivity=88.15%, avg_specificity=82.32% avg_auc=0.9256
Fold[8] Epoch: 55 [55/150 (37%)] Train loss=0.229194 Test loss=0.623321 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.2626095712184906
[5/24] Train loss=0.18508189916610718
[10/24] Train loss=0.26616230607032776
[15/24] Train loss=0.1726311445236206
[20/24] Train loss=0.159882590174675
Test set avg_accuracy=85.34% avg_sensitivity=86.99%, avg_specificity=84.80% avg_auc=0.9248
Fold[8] Epoch: 56 [56/150 (37%)] Train loss=0.229652 Test loss=0.547714 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.275082528591156
[5/24] Train loss=0.20085561275482178
[10/24] Train loss=0.2591291069984436
[15/24] Train loss=0.21054762601852417
[20/24] Train loss=0.1947098821401596
Test set avg_accuracy=86.48% avg_sensitivity=83.57%, avg_specificity=87.44% avg_auc=0.9204
Fold[8] Epoch: 57 [57/150 (38%)] Train loss=0.232682 Test loss=0.462650 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.248002290725708
[5/24] Train loss=0.18313312530517578
[10/24] Train loss=0.249715656042099
[15/24] Train loss=0.17473562061786652
[20/24] Train loss=0.15720206499099731
Test set avg_accuracy=83.29% avg_sensitivity=88.41%, avg_specificity=81.61% avg_auc=0.9227
Fold[8] Epoch: 58 [58/150 (39%)] Train loss=0.206136 Test loss=0.684024 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.25295233726501465
[5/24] Train loss=0.16435563564300537
[10/24] Train loss=0.25404033064842224
[15/24] Train loss=0.2015819400548935
[20/24] Train loss=0.16168448328971863
Test set avg_accuracy=86.04% avg_sensitivity=84.52%, avg_specificity=86.54% avg_auc=0.9244
Fold[8] Epoch: 59 [59/150 (39%)] Train loss=0.219487 Test loss=0.548779 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.21464887261390686
[5/24] Train loss=0.17556989192962646
[10/24] Train loss=0.2615574300289154
[15/24] Train loss=0.20885436236858368
[20/24] Train loss=0.24595555663108826
Test set avg_accuracy=84.04% avg_sensitivity=86.68%, avg_specificity=83.17% avg_auc=0.9199
Fold[8] Epoch: 60 [60/150 (40%)] Train loss=0.213460 Test loss=0.627286 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.24644127488136292
[5/24] Train loss=0.16442805528640747
[10/24] Train loss=0.22744989395141602
[15/24] Train loss=0.20970918238162994
[20/24] Train loss=0.1378668248653412
Test set avg_accuracy=83.18% avg_sensitivity=87.94%, avg_specificity=81.61% avg_auc=0.9225
Fold[8] Epoch: 61 [61/150 (41%)] Train loss=0.208388 Test loss=0.719307 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.25595203042030334
[5/24] Train loss=0.18015897274017334
[10/24] Train loss=0.2275080382823944
[15/24] Train loss=0.18450035154819489
[20/24] Train loss=0.14579369127750397
Test set avg_accuracy=85.26% avg_sensitivity=84.94%, avg_specificity=85.37% avg_auc=0.9231
Fold[8] Epoch: 62 [62/150 (41%)] Train loss=0.213614 Test loss=0.576943 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.21706365048885345
[5/24] Train loss=0.17284952104091644
[10/24] Train loss=0.24841506779193878
[15/24] Train loss=0.18385349214076996
[20/24] Train loss=0.13672667741775513
Test set avg_accuracy=83.42% avg_sensitivity=88.10%, avg_specificity=81.89% avg_auc=0.9224
Fold[8] Epoch: 63 [63/150 (42%)] Train loss=0.195005 Test loss=0.753079 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.28062576055526733
[5/24] Train loss=0.17007389664649963
[10/24] Train loss=0.17177028954029083
[15/24] Train loss=0.16571027040481567
[20/24] Train loss=0.13838082551956177
Test set avg_accuracy=86.56% avg_sensitivity=82.57%, avg_specificity=87.87% avg_auc=0.9192
Fold[8] Epoch: 64 [64/150 (43%)] Train loss=0.193454 Test loss=0.669885 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.20099759101867676
[5/24] Train loss=0.15180766582489014
[10/24] Train loss=0.1614316701889038
[15/24] Train loss=0.16634786128997803
[20/24] Train loss=0.12520334124565125
Test set avg_accuracy=87.29% avg_sensitivity=79.57%, avg_specificity=89.83% avg_auc=0.9144
Fold[8] Epoch: 65 [65/150 (43%)] Train loss=0.180540 Test loss=0.695353 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.19354449212551117
[5/24] Train loss=0.16168445348739624
[10/24] Train loss=0.1563241332769394
[15/24] Train loss=0.1697729229927063
[20/24] Train loss=0.14663125574588776
Test set avg_accuracy=85.98% avg_sensitivity=83.57%, avg_specificity=86.77% avg_auc=0.9201
Fold[8] Epoch: 66 [66/150 (44%)] Train loss=0.167554 Test loss=0.595423 Current lr=[0.000904142181093812]

[0/24] Train loss=0.15119963884353638
[5/24] Train loss=0.14000959694385529
[10/24] Train loss=0.15129010379314423
[15/24] Train loss=0.1840071678161621
[20/24] Train loss=0.12538306415081024
Test set avg_accuracy=85.14% avg_sensitivity=81.04%, avg_specificity=86.49% avg_auc=0.9147
Fold[8] Epoch: 67 [67/150 (45%)] Train loss=0.164356 Test loss=0.608998 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.1457386463880539
[5/24] Train loss=0.16430649161338806
[10/24] Train loss=0.17469167709350586
[15/24] Train loss=0.12439386546611786
[20/24] Train loss=0.09502840787172318
Test set avg_accuracy=86.26% avg_sensitivity=80.94%, avg_specificity=88.01% avg_auc=0.9163
Fold[8] Epoch: 68 [68/150 (45%)] Train loss=0.147990 Test loss=0.666077 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.10403282195329666
[5/24] Train loss=0.1241956502199173
[10/24] Train loss=0.16678547859191895
[15/24] Train loss=0.13060012459754944
[20/24] Train loss=0.13914178311824799
Test set avg_accuracy=85.21% avg_sensitivity=80.52%, avg_specificity=86.75% avg_auc=0.8976
Fold[8] Epoch: 69 [69/150 (46%)] Train loss=0.157233 Test loss=0.720306 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.24378366768360138
[5/24] Train loss=0.17691750824451447
[10/24] Train loss=0.19752462208271027
[15/24] Train loss=0.19805312156677246
[20/24] Train loss=0.12648741900920868
Test set avg_accuracy=79.80% avg_sensitivity=88.94%, avg_specificity=76.80% avg_auc=0.9079
Fold[8] Epoch: 70 [70/150 (47%)] Train loss=0.197857 Test loss=1.109565 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.20749621093273163
[5/24] Train loss=0.1766735166311264
[10/24] Train loss=0.20500946044921875
[15/24] Train loss=0.15894807875156403
[20/24] Train loss=0.1460813730955124
Test set avg_accuracy=87.33% avg_sensitivity=79.20%, avg_specificity=90.00% avg_auc=0.9056
Fold[8] Epoch: 71 [71/150 (47%)] Train loss=0.199529 Test loss=0.701411 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.18118725717067719
[5/24] Train loss=0.15896561741828918
[10/24] Train loss=0.16948620975017548
[15/24] Train loss=0.16834238171577454
[20/24] Train loss=0.11963992565870285
Test set avg_accuracy=84.39% avg_sensitivity=83.46%, avg_specificity=84.69% avg_auc=0.9083
Fold[8] Epoch: 72 [72/150 (48%)] Train loss=0.173208 Test loss=0.678363 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.14481744170188904
[5/24] Train loss=0.11500900983810425
[10/24] Train loss=0.13268232345581055
[15/24] Train loss=0.13477952778339386
[20/24] Train loss=0.10078717023134232
Test set avg_accuracy=85.72% avg_sensitivity=81.25%, avg_specificity=87.18% avg_auc=0.9039
Fold[8] Epoch: 73 [73/150 (49%)] Train loss=0.138032 Test loss=0.764086 Current lr=[0.000834102481048427]

[0/24] Train loss=0.1422647386789322
[5/24] Train loss=0.19618378579616547
[10/24] Train loss=0.18778961896896362
[15/24] Train loss=0.14973695576190948
[20/24] Train loss=0.12065182626247406
Test set avg_accuracy=79.51% avg_sensitivity=89.94%, avg_specificity=76.08% avg_auc=0.9151
Fold[8] Epoch: 74 [74/150 (49%)] Train loss=0.165252 Test loss=1.119271 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.15034550428390503
[5/24] Train loss=0.1812918782234192
[10/24] Train loss=0.1684323102235794
[15/24] Train loss=0.16379429399967194
[20/24] Train loss=0.11042908579111099
Test set avg_accuracy=84.95% avg_sensitivity=85.99%, avg_specificity=84.60% avg_auc=0.9140
Fold[8] Epoch: 75 [75/150 (50%)] Train loss=0.159878 Test loss=0.882424 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.15391883254051208
[5/24] Train loss=0.16818423569202423
[10/24] Train loss=0.19837555289268494
[15/24] Train loss=0.13652420043945312
[20/24] Train loss=0.1028241217136383
Test set avg_accuracy=85.21% avg_sensitivity=84.15%, avg_specificity=85.56% avg_auc=0.9150
Fold[8] Epoch: 76 [76/150 (51%)] Train loss=0.155469 Test loss=0.760688 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.11928009986877441
[5/24] Train loss=0.09827032685279846
[10/24] Train loss=0.14120154082775116
[15/24] Train loss=0.11897779256105423
[20/24] Train loss=0.09890710562467575
Test set avg_accuracy=83.97% avg_sensitivity=86.36%, avg_specificity=83.19% avg_auc=0.9227
Fold[8] Epoch: 77 [77/150 (51%)] Train loss=0.123143 Test loss=1.012263 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.16980615258216858
[5/24] Train loss=0.12789952754974365
[10/24] Train loss=0.1526314616203308
[15/24] Train loss=0.12803097069263458
[20/24] Train loss=0.12305986881256104
Test set avg_accuracy=86.09% avg_sensitivity=84.78%, avg_specificity=86.52% avg_auc=0.9228
Fold[8] Epoch: 78 [78/150 (52%)] Train loss=0.146252 Test loss=0.671302 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.10532823204994202
[5/24] Train loss=0.10734421759843826
[10/24] Train loss=0.14189128577709198
[15/24] Train loss=0.10923166573047638
[20/24] Train loss=0.1205323338508606
Test set avg_accuracy=82.58% avg_sensitivity=90.36%, avg_specificity=80.02% avg_auc=0.9222
Fold[8] Epoch: 79 [79/150 (53%)] Train loss=0.120931 Test loss=0.902213 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.11638611555099487
[5/24] Train loss=0.09888425469398499
[10/24] Train loss=0.1263718605041504
[15/24] Train loss=0.13649310171604156
[20/24] Train loss=0.11932437866926193
Test set avg_accuracy=82.86% avg_sensitivity=89.68%, avg_specificity=80.63% avg_auc=0.9239
Fold[8] Epoch: 80 [80/150 (53%)] Train loss=0.139280 Test loss=0.734553 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.17829591035842896
[5/24] Train loss=0.11738596856594086
[10/24] Train loss=0.1543988585472107
[15/24] Train loss=0.12514446675777435
[20/24] Train loss=0.1493055671453476
Test set avg_accuracy=84.82% avg_sensitivity=86.78%, avg_specificity=84.17% avg_auc=0.9220
Fold[8] Epoch: 81 [81/150 (54%)] Train loss=0.143919 Test loss=0.776236 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.1442151814699173
[5/24] Train loss=0.08474181592464447
[10/24] Train loss=0.13125112652778625
[15/24] Train loss=0.11506638675928116
[20/24] Train loss=0.10608497262001038
Test set avg_accuracy=87.40% avg_sensitivity=79.09%, avg_specificity=90.12% avg_auc=0.9213
Fold[8] Epoch: 82 [82/150 (55%)] Train loss=0.128069 Test loss=0.582843 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.12014260143041611
[5/24] Train loss=0.10932774841785431
[10/24] Train loss=0.1164657324552536
[15/24] Train loss=0.1067657396197319
[20/24] Train loss=0.07879270613193512
Test set avg_accuracy=86.80% avg_sensitivity=81.31%, avg_specificity=88.60% avg_auc=0.9216
Fold[8] Epoch: 83 [83/150 (55%)] Train loss=0.112573 Test loss=0.641232 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.09424814581871033
[5/24] Train loss=0.0664442926645279
[10/24] Train loss=0.09768366068601608
[15/24] Train loss=0.08572609722614288
[20/24] Train loss=0.07068315893411636
Test set avg_accuracy=84.93% avg_sensitivity=84.47%, avg_specificity=85.09% avg_auc=0.9225
Fold[8] Epoch: 84 [84/150 (56%)] Train loss=0.094236 Test loss=0.760570 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.07717897742986679
[5/24] Train loss=0.0735764130949974
[10/24] Train loss=0.07655647397041321
[15/24] Train loss=0.06848878413438797
[20/24] Train loss=0.06249896436929703
Test set avg_accuracy=85.31% avg_sensitivity=84.47%, avg_specificity=85.59% avg_auc=0.9259
Fold[8] Epoch: 85 [85/150 (57%)] Train loss=0.080113 Test loss=0.762660 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.06202197074890137
[5/24] Train loss=0.04938274621963501
[10/24] Train loss=0.06847092509269714
[15/24] Train loss=0.07397308945655823
[20/24] Train loss=0.06588628143072128
Test set avg_accuracy=84.36% avg_sensitivity=86.26%, avg_specificity=83.74% avg_auc=0.9245
Fold[8] Epoch: 86 [86/150 (57%)] Train loss=0.076085 Test loss=0.892923 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.07851336896419525
[5/24] Train loss=0.06093224138021469
[10/24] Train loss=0.07441339641809464
[15/24] Train loss=0.0684850737452507
[20/24] Train loss=0.07006124407052994
Test set avg_accuracy=85.00% avg_sensitivity=84.36%, avg_specificity=85.21% avg_auc=0.9228
Fold[8] Epoch: 87 [87/150 (58%)] Train loss=0.083579 Test loss=0.813682 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.07333211600780487
[5/24] Train loss=0.05435075983405113
[10/24] Train loss=0.06979530304670334
[15/24] Train loss=0.055717550218105316
[20/24] Train loss=0.05824899300932884
Test set avg_accuracy=83.57% avg_sensitivity=84.73%, avg_specificity=83.19% avg_auc=0.9197
Fold[8] Epoch: 88 [88/150 (59%)] Train loss=0.069290 Test loss=0.853342 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.0831359252333641
[5/24] Train loss=0.04676244407892227
[10/24] Train loss=0.058733973652124405
[15/24] Train loss=0.06203019246459007
[20/24] Train loss=0.07209186255931854
Test set avg_accuracy=84.61% avg_sensitivity=87.20%, avg_specificity=83.76% avg_auc=0.9235
Fold[8] Epoch: 89 [89/150 (59%)] Train loss=0.073506 Test loss=0.894851 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.07551080733537674
[5/24] Train loss=0.06991316378116608
[10/24] Train loss=0.08191606402397156
[15/24] Train loss=0.10326332598924637
[20/24] Train loss=0.07420489192008972
Test set avg_accuracy=85.18% avg_sensitivity=84.73%, avg_specificity=85.33% avg_auc=0.9215
Fold[8] Epoch: 90 [90/150 (60%)] Train loss=0.076821 Test loss=0.794723 Current lr=[0.00061065423442182]

[0/24] Train loss=0.07061807066202164
[5/24] Train loss=0.050720274448394775
[10/24] Train loss=0.06291276216506958
[15/24] Train loss=0.06248436123132706
[20/24] Train loss=0.050870709121227264
Test set avg_accuracy=84.01% avg_sensitivity=87.36%, avg_specificity=82.91% avg_auc=0.9233
Fold[8] Epoch: 91 [91/150 (61%)] Train loss=0.062900 Test loss=0.981147 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.07373210787773132
[5/24] Train loss=0.05042653903365135
[10/24] Train loss=0.08218443393707275
[15/24] Train loss=0.06265701353549957
[20/24] Train loss=0.06397886574268341
Test set avg_accuracy=85.65% avg_sensitivity=84.94%, avg_specificity=85.88% avg_auc=0.9237
Fold[8] Epoch: 92 [92/150 (61%)] Train loss=0.073009 Test loss=0.815732 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.08439255505800247
[5/24] Train loss=0.05165645107626915
[10/24] Train loss=0.06204861402511597
[15/24] Train loss=0.0781121626496315
[20/24] Train loss=0.05321376770734787
Test set avg_accuracy=85.01% avg_sensitivity=85.78%, avg_specificity=84.76% avg_auc=0.9201
Fold[8] Epoch: 93 [93/150 (62%)] Train loss=0.067165 Test loss=0.937954 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.08135554194450378
[5/24] Train loss=0.06386521458625793
[10/24] Train loss=0.07061996310949326
[15/24] Train loss=0.07266709208488464
[20/24] Train loss=0.05449077486991882
Test set avg_accuracy=85.22% avg_sensitivity=84.20%, avg_specificity=85.56% avg_auc=0.9224
Fold[8] Epoch: 94 [94/150 (63%)] Train loss=0.069552 Test loss=0.892738 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.0873657763004303
[5/24] Train loss=0.05343764275312424
[10/24] Train loss=0.06282303482294083
[15/24] Train loss=0.07285699248313904
[20/24] Train loss=0.054780881851911545
Test set avg_accuracy=84.69% avg_sensitivity=85.26%, avg_specificity=84.50% avg_auc=0.9220
Fold[8] Epoch: 95 [95/150 (63%)] Train loss=0.062059 Test loss=0.995981 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.09698456525802612
[5/24] Train loss=0.05280272290110588
[10/24] Train loss=0.0792543962597847
[15/24] Train loss=0.05653955042362213
[20/24] Train loss=0.05217215418815613
Test set avg_accuracy=84.30% avg_sensitivity=86.05%, avg_specificity=83.72% avg_auc=0.9215
Fold[8] Epoch: 96 [96/150 (64%)] Train loss=0.070224 Test loss=0.999669 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.08565980941057205
[5/24] Train loss=0.06421110779047012
[10/24] Train loss=0.063821941614151
[15/24] Train loss=0.061795420944690704
[20/24] Train loss=0.059087399393320084
Test set avg_accuracy=85.33% avg_sensitivity=84.62%, avg_specificity=85.56% avg_auc=0.9232
Fold[8] Epoch: 97 [97/150 (65%)] Train loss=0.067032 Test loss=0.884750 Current lr=[0.000506858408304961]

[0/24] Train loss=0.05318565294146538
[5/24] Train loss=0.05060478672385216
[10/24] Train loss=0.059232715517282486
[15/24] Train loss=0.04912556707859039
[20/24] Train loss=0.03891001641750336
Test set avg_accuracy=85.89% avg_sensitivity=83.10%, avg_specificity=86.80% avg_auc=0.9223
Fold[8] Epoch: 98 [98/150 (65%)] Train loss=0.061341 Test loss=0.874652 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.05510643497109413
[5/24] Train loss=0.04210279881954193
[10/24] Train loss=0.04964234307408333
[15/24] Train loss=0.0351647287607193
[20/24] Train loss=0.035781122744083405
Test set avg_accuracy=86.15% avg_sensitivity=83.36%, avg_specificity=87.06% avg_auc=0.9229
Fold[8] Epoch: 99 [99/150 (66%)] Train loss=0.051763 Test loss=0.824473 Current lr=[0.000476946990416354]

[0/24] Train loss=0.07299026846885681
[5/24] Train loss=0.03240949660539627
[10/24] Train loss=0.06412515044212341
[15/24] Train loss=0.04680074378848076
[20/24] Train loss=0.03878936171531677
Test set avg_accuracy=85.25% avg_sensitivity=82.99%, avg_specificity=85.99% avg_auc=0.9218
Fold[8] Epoch: 100 [100/150 (67%)] Train loss=0.049303 Test loss=0.905469 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.042303938418626785
[5/24] Train loss=0.02855038456618786
[10/24] Train loss=0.04142773523926735
[15/24] Train loss=0.03618475794792175
[20/24] Train loss=0.05185505747795105
Test set avg_accuracy=84.60% avg_sensitivity=84.15%, avg_specificity=84.74% avg_auc=0.9209
Fold[8] Epoch: 101 [101/150 (67%)] Train loss=0.045000 Test loss=0.989810 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.039570633322000504
[5/24] Train loss=0.028352631255984306
[10/24] Train loss=0.04420867934823036
[15/24] Train loss=0.03592022508382797
[20/24] Train loss=0.02581377513706684
Test set avg_accuracy=84.47% avg_sensitivity=86.78%, avg_specificity=83.71% avg_auc=0.9236
Fold[8] Epoch: 102 [102/150 (68%)] Train loss=0.039993 Test loss=1.041238 Current lr=[0.000432267999769856]

[0/24] Train loss=0.044564299285411835
[5/24] Train loss=0.02665138989686966
[10/24] Train loss=0.05543186143040657
[15/24] Train loss=0.0313592404127121
[20/24] Train loss=0.02567819133400917
Test set avg_accuracy=84.66% avg_sensitivity=84.89%, avg_specificity=84.59% avg_auc=0.9238
Fold[8] Epoch: 103 [103/150 (69%)] Train loss=0.040067 Test loss=0.950892 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.046908460557460785
[5/24] Train loss=0.0280055683106184
[10/24] Train loss=0.03904044255614281
[15/24] Train loss=0.03284516558051109
[20/24] Train loss=0.02805788815021515
Test set avg_accuracy=85.81% avg_sensitivity=83.57%, avg_specificity=86.54% avg_auc=0.9235
Fold[8] Epoch: 104 [104/150 (69%)] Train loss=0.044211 Test loss=0.938362 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.05081823095679283
[5/24] Train loss=0.028747452422976494
[10/24] Train loss=0.04111406207084656
[15/24] Train loss=0.034273792058229446
[20/24] Train loss=0.028630444779992104
Test set avg_accuracy=85.78% avg_sensitivity=83.78%, avg_specificity=86.44% avg_auc=0.9220
Fold[8] Epoch: 105 [105/150 (70%)] Train loss=0.038711 Test loss=1.005437 Current lr=[0.000388134363466264]

[0/24] Train loss=0.03082800842821598
[5/24] Train loss=0.0390184111893177
[10/24] Train loss=0.02972889505326748
[15/24] Train loss=0.02862250618636608
[20/24] Train loss=0.02649000659584999
Test set avg_accuracy=84.67% avg_sensitivity=86.57%, avg_specificity=84.05% avg_auc=0.9242
Fold[8] Epoch: 106 [106/150 (71%)] Train loss=0.033287 Test loss=1.143919 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.043265074491500854
[5/24] Train loss=0.029384717345237732
[10/24] Train loss=0.0320577472448349
[15/24] Train loss=0.025737540796399117
[20/24] Train loss=0.04251217097043991
Test set avg_accuracy=85.47% avg_sensitivity=83.78%, avg_specificity=86.02% avg_auc=0.9227
Fold[8] Epoch: 107 [107/150 (71%)] Train loss=0.037108 Test loss=0.993854 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.03330113738775253
[5/24] Train loss=0.027422672137618065
[10/24] Train loss=0.029300114139914513
[15/24] Train loss=0.03866812586784363
[20/24] Train loss=0.02581348642706871
Test set avg_accuracy=84.79% avg_sensitivity=86.05%, avg_specificity=84.38% avg_auc=0.9241
Fold[8] Epoch: 108 [108/150 (72%)] Train loss=0.032556 Test loss=1.087961 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.04078272357583046
[5/24] Train loss=0.030965043231844902
[10/24] Train loss=0.04597575217485428
[15/24] Train loss=0.04106243699789047
[20/24] Train loss=0.02560359798371792
Test set avg_accuracy=84.28% avg_sensitivity=85.99%, avg_specificity=83.72% avg_auc=0.9247
Fold[8] Epoch: 109 [109/150 (73%)] Train loss=0.037890 Test loss=1.030115 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.043564263731241226
[5/24] Train loss=0.036760441958904266
[10/24] Train loss=0.03878723829984665
[15/24] Train loss=0.04432782158255577
[20/24] Train loss=0.034384697675704956
Test set avg_accuracy=85.22% avg_sensitivity=86.05%, avg_specificity=84.95% avg_auc=0.9260
Fold[8] Epoch: 110 [110/150 (73%)] Train loss=0.042296 Test loss=0.985264 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.05295160785317421
[5/24] Train loss=0.049475181847810745
[10/24] Train loss=0.06898245215415955
[15/24] Train loss=0.03854929283261299
[20/24] Train loss=0.04640220105648041
Test set avg_accuracy=86.13% avg_sensitivity=84.15%, avg_specificity=86.78% avg_auc=0.9228
Fold[8] Epoch: 111 [111/150 (74%)] Train loss=0.048763 Test loss=0.936894 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.0446365661919117
[5/24] Train loss=0.0341038815677166
[10/24] Train loss=0.03977116942405701
[15/24] Train loss=0.03707697615027428
[20/24] Train loss=0.0388798750936985
Test set avg_accuracy=85.85% avg_sensitivity=82.78%, avg_specificity=86.85% avg_auc=0.9224
Fold[8] Epoch: 112 [112/150 (75%)] Train loss=0.038217 Test loss=0.950863 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.03616027161478996
[5/24] Train loss=0.024381542578339577
[10/24] Train loss=0.043649762868881226
[15/24] Train loss=0.03349617123603821
[20/24] Train loss=0.02728070318698883
Test set avg_accuracy=85.00% avg_sensitivity=86.78%, avg_specificity=84.41% avg_auc=0.9235
Fold[8] Epoch: 113 [113/150 (75%)] Train loss=0.035127 Test loss=1.172907 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.044582922011613846
[5/24] Train loss=0.04312719777226448
[10/24] Train loss=0.03752078860998154
[15/24] Train loss=0.03252213075757027
[20/24] Train loss=0.03595834597945213
Test set avg_accuracy=86.50% avg_sensitivity=83.31%, avg_specificity=87.55% avg_auc=0.9224
Fold[8] Epoch: 114 [114/150 (76%)] Train loss=0.040604 Test loss=0.937096 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.04729054868221283
[5/24] Train loss=0.04399189352989197
[10/24] Train loss=0.03539898246526718
[15/24] Train loss=0.039646975696086884
[20/24] Train loss=0.028480885550379753
Test set avg_accuracy=84.34% avg_sensitivity=87.73%, avg_specificity=83.22% avg_auc=0.9249
Fold[8] Epoch: 115 [115/150 (77%)] Train loss=0.040571 Test loss=1.158581 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.04458029195666313
[5/24] Train loss=0.041227731853723526
[10/24] Train loss=0.04854574054479599
[15/24] Train loss=0.04281434044241905
[20/24] Train loss=0.029606712982058525
Test set avg_accuracy=85.98% avg_sensitivity=84.52%, avg_specificity=86.46% avg_auc=0.9222
Fold[8] Epoch: 116 [116/150 (77%)] Train loss=0.041734 Test loss=0.986575 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.03350231051445007
[5/24] Train loss=0.02778691053390503
[10/24] Train loss=0.039751823991537094
[15/24] Train loss=0.027067672461271286
[20/24] Train loss=0.025459077209234238
Test set avg_accuracy=85.46% avg_sensitivity=83.99%, avg_specificity=85.94% avg_auc=0.9239
Fold[8] Epoch: 117 [117/150 (78%)] Train loss=0.031959 Test loss=1.127942 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.02794674038887024
[5/24] Train loss=0.09018686413764954
[10/24] Train loss=0.02904300019145012
[15/24] Train loss=0.02523188665509224
[20/24] Train loss=0.028063692152500153
Test set avg_accuracy=83.58% avg_sensitivity=87.63%, avg_specificity=82.25% avg_auc=0.9249
Fold[8] Epoch: 118 [118/150 (79%)] Train loss=0.034511 Test loss=1.248061 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.03459848463535309
[5/24] Train loss=0.030221540480852127
[10/24] Train loss=0.03339330479502678
[15/24] Train loss=0.038716357201337814
[20/24] Train loss=0.027084171772003174
Test set avg_accuracy=85.66% avg_sensitivity=85.36%, avg_specificity=85.76% avg_auc=0.9244
Fold[8] Epoch: 119 [119/150 (79%)] Train loss=0.035923 Test loss=0.987502 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.0303790420293808
[5/24] Train loss=0.027638111263513565
[10/24] Train loss=0.026216281577944756
[15/24] Train loss=0.028684446588158607
[20/24] Train loss=0.018380261957645416
Test set avg_accuracy=85.38% avg_sensitivity=85.10%, avg_specificity=85.47% avg_auc=0.9240
Fold[8] Epoch: 120 [120/150 (80%)] Train loss=0.029823 Test loss=1.138876 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.026954175904393196
[5/24] Train loss=0.02217225357890129
[10/24] Train loss=0.021933043375611305
[15/24] Train loss=0.026310523971915245
[20/24] Train loss=0.016357293352484703
Test set avg_accuracy=84.90% avg_sensitivity=85.94%, avg_specificity=84.55% avg_auc=0.9243
Fold[8] Epoch: 121 [121/150 (81%)] Train loss=0.024794 Test loss=1.292464 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.026662085205316544
[5/24] Train loss=0.02533203922212124
[10/24] Train loss=0.029925482347607613
[15/24] Train loss=0.021234791725873947
[20/24] Train loss=0.04463653638958931
Test set avg_accuracy=85.64% avg_sensitivity=84.78%, avg_specificity=85.92% avg_auc=0.9242
Fold[8] Epoch: 122 [122/150 (81%)] Train loss=0.027805 Test loss=1.108126 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.027849538251757622
[5/24] Train loss=0.023921776562929153
[10/24] Train loss=0.023440688848495483
[15/24] Train loss=0.022473638877272606
[20/24] Train loss=0.01856193318963051
Test set avg_accuracy=84.87% avg_sensitivity=86.10%, avg_specificity=84.47% avg_auc=0.9259
Fold[8] Epoch: 123 [123/150 (82%)] Train loss=0.025776 Test loss=1.292019 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.029825061559677124
[5/24] Train loss=0.02878454327583313
[10/24] Train loss=0.03166116401553154
[15/24] Train loss=0.028918910771608353
[20/24] Train loss=0.022781401872634888
Test set avg_accuracy=84.40% avg_sensitivity=86.47%, avg_specificity=83.72% avg_auc=0.9255
Fold[8] Epoch: 124 [124/150 (83%)] Train loss=0.030505 Test loss=1.302015 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.04827288165688515
[5/24] Train loss=0.03157855197787285
[10/24] Train loss=0.031113600358366966
[15/24] Train loss=0.02480858936905861
[20/24] Train loss=0.02201675996184349
Test set avg_accuracy=85.49% avg_sensitivity=84.89%, avg_specificity=85.69% avg_auc=0.9236
Fold[8] Epoch: 125 [125/150 (83%)] Train loss=0.034109 Test loss=1.112562 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.02439233846962452
[5/24] Train loss=0.022117767482995987
[10/24] Train loss=0.023715633898973465
[15/24] Train loss=0.023402763530611992
[20/24] Train loss=0.024665821343660355
Test set avg_accuracy=85.81% avg_sensitivity=83.83%, avg_specificity=86.46% avg_auc=0.9240
Fold[8] Epoch: 126 [126/150 (84%)] Train loss=0.027361 Test loss=1.078768 Current lr=[0.000123057953306828]

[0/24] Train loss=0.02912774309515953
[5/24] Train loss=0.018197031691670418
[10/24] Train loss=0.025969775393605232
[15/24] Train loss=0.022503087297081947
[20/24] Train loss=0.01772780902683735
Test set avg_accuracy=85.39% avg_sensitivity=84.41%, avg_specificity=85.71% avg_auc=0.9241
Fold[8] Epoch: 127 [127/150 (85%)] Train loss=0.024956 Test loss=1.186694 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.03154023364186287
[5/24] Train loss=0.020365934818983078
[10/24] Train loss=0.02079899050295353
[15/24] Train loss=0.022608257830142975
[20/24] Train loss=0.015604500658810139
Test set avg_accuracy=85.04% avg_sensitivity=84.78%, avg_specificity=85.12% avg_auc=0.9243
Fold[8] Epoch: 128 [128/150 (85%)] Train loss=0.023154 Test loss=1.483897 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.01672123372554779
[5/24] Train loss=0.03542984649538994
[10/24] Train loss=0.020519576966762543
[15/24] Train loss=0.02148418128490448
[20/24] Train loss=0.014626582153141499
Test set avg_accuracy=84.48% avg_sensitivity=86.05%, avg_specificity=83.96% avg_auc=0.9251
Fold[8] Epoch: 129 [129/150 (86%)] Train loss=0.020060 Test loss=1.638587 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.023895254358649254
[5/24] Train loss=0.018553340807557106
[10/24] Train loss=0.02082357183098793
[15/24] Train loss=0.01885511539876461
[20/24] Train loss=0.015538038685917854
Test set avg_accuracy=84.49% avg_sensitivity=85.26%, avg_specificity=84.24% avg_auc=0.9248
Fold[8] Epoch: 130 [130/150 (87%)] Train loss=0.021885 Test loss=1.537883 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.02829384244978428
[5/24] Train loss=0.023382369428873062
[10/24] Train loss=0.023433316498994827
[15/24] Train loss=0.021163279190659523
[20/24] Train loss=0.018702257424592972
Test set avg_accuracy=84.88% avg_sensitivity=84.83%, avg_specificity=84.90% avg_auc=0.9242
Fold[8] Epoch: 131 [131/150 (87%)] Train loss=0.024293 Test loss=1.305900 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.02035321481525898
[5/24] Train loss=0.01703445240855217
[10/24] Train loss=0.01755191944539547
[15/24] Train loss=0.019125530496239662
[20/24] Train loss=0.022554412484169006
Test set avg_accuracy=84.91% avg_sensitivity=84.57%, avg_specificity=85.02% avg_auc=0.9244
Fold[8] Epoch: 132 [132/150 (88%)] Train loss=0.019715 Test loss=1.246109 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.01847004145383835
[5/24] Train loss=0.01623968593776226
[10/24] Train loss=0.020579466596245766
[15/24] Train loss=0.018195684999227524
[20/24] Train loss=0.018238311633467674
Test set avg_accuracy=84.18% avg_sensitivity=84.89%, avg_specificity=83.95% avg_auc=0.9247
Fold[8] Epoch: 133 [133/150 (89%)] Train loss=0.019790 Test loss=1.391682 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.028263892978429794
[5/24] Train loss=0.017739463597536087
[10/24] Train loss=0.019758250564336777
[15/24] Train loss=0.018576370552182198
[20/24] Train loss=0.013613437302410603
Test set avg_accuracy=84.35% avg_sensitivity=85.20%, avg_specificity=84.07% avg_auc=0.9242
Fold[8] Epoch: 134 [134/150 (89%)] Train loss=0.018882 Test loss=1.402096 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.026254551485180855
[5/24] Train loss=0.021291397511959076
[10/24] Train loss=0.021252816542983055
[15/24] Train loss=0.02085179276764393
[20/24] Train loss=0.025276511907577515
Test set avg_accuracy=84.95% avg_sensitivity=84.83%, avg_specificity=84.99% avg_auc=0.9238
Fold[8] Epoch: 135 [135/150 (90%)] Train loss=0.024102 Test loss=1.362066 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.01745181530714035
[5/24] Train loss=0.021966800093650818
[10/24] Train loss=0.018422260880470276
[15/24] Train loss=0.01911408267915249
[20/24] Train loss=0.012359037064015865
Test set avg_accuracy=85.29% avg_sensitivity=84.78%, avg_specificity=85.45% avg_auc=0.9234
Fold[8] Epoch: 136 [136/150 (91%)] Train loss=0.019863 Test loss=1.319409 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.020509077236056328
[5/24] Train loss=0.015406220220029354
[10/24] Train loss=0.016995344310998917
[15/24] Train loss=0.01890585944056511
[20/24] Train loss=0.013358266092836857
Test set avg_accuracy=85.04% avg_sensitivity=84.78%, avg_specificity=85.12% avg_auc=0.9235
Fold[8] Epoch: 137 [137/150 (91%)] Train loss=0.020759 Test loss=1.353799 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.017768334597349167
[5/24] Train loss=0.013438079506158829
[10/24] Train loss=0.013235824182629585
[15/24] Train loss=0.015160102397203445
[20/24] Train loss=0.010023563168942928
Test set avg_accuracy=84.73% avg_sensitivity=85.26%, avg_specificity=84.55% avg_auc=0.9238
Fold[8] Epoch: 138 [138/150 (92%)] Train loss=0.016417 Test loss=1.433397 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.028079062700271606
[5/24] Train loss=0.013001027517020702
[10/24] Train loss=0.015977932140231133
[15/24] Train loss=0.014279640279710293
[20/24] Train loss=0.012191331945359707
Test set avg_accuracy=84.53% avg_sensitivity=85.26%, avg_specificity=84.29% avg_auc=0.9237
Fold[8] Epoch: 139 [139/150 (93%)] Train loss=0.020778 Test loss=1.496922 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.020800046622753143
[5/24] Train loss=0.019525393843650818
[10/24] Train loss=0.022499235346913338
[15/24] Train loss=0.016578106209635735
[20/24] Train loss=0.017534641548991203
Test set avg_accuracy=84.64% avg_sensitivity=85.20%, avg_specificity=84.45% avg_auc=0.9235
Fold[8] Epoch: 140 [140/150 (93%)] Train loss=0.020227 Test loss=1.481592 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.023467976599931717
[5/24] Train loss=0.021277623251080513
[10/24] Train loss=0.024570723995566368
[15/24] Train loss=0.027705084532499313
[20/24] Train loss=0.02173147350549698
Test set avg_accuracy=84.84% avg_sensitivity=85.04%, avg_specificity=84.78% avg_auc=0.9233
Fold[8] Epoch: 141 [141/150 (94%)] Train loss=0.025112 Test loss=1.454075 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.031535547226667404
[5/24] Train loss=0.02434840053319931
[10/24] Train loss=0.025879641994833946
[15/24] Train loss=0.021768881008028984
[20/24] Train loss=0.02076495625078678
Test set avg_accuracy=85.18% avg_sensitivity=84.83%, avg_specificity=85.30% avg_auc=0.9232
Fold[8] Epoch: 142 [142/150 (95%)] Train loss=0.026439 Test loss=1.399335 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.0203639455139637
[5/24] Train loss=0.021265264600515366
[10/24] Train loss=0.02079370804131031
[15/24] Train loss=0.019633052870631218
[20/24] Train loss=0.018397558480501175
Test set avg_accuracy=85.21% avg_sensitivity=84.57%, avg_specificity=85.42% avg_auc=0.9231
Fold[8] Epoch: 143 [143/150 (95%)] Train loss=0.022078 Test loss=1.329259 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.017510205507278442
[5/24] Train loss=0.017808403819799423
[10/24] Train loss=0.016823388636112213
[15/24] Train loss=0.016916556283831596
[20/24] Train loss=0.012861273251473904
Test set avg_accuracy=85.26% avg_sensitivity=84.57%, avg_specificity=85.49% avg_auc=0.9231
Fold[8] Epoch: 144 [144/150 (96%)] Train loss=0.018344 Test loss=1.311772 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.0150033850222826
[5/24] Train loss=0.012006119824945927
[10/24] Train loss=0.015992052853107452
[15/24] Train loss=0.014616766013205051
[20/24] Train loss=0.012277166359126568
Test set avg_accuracy=85.17% avg_sensitivity=84.68%, avg_specificity=85.33% avg_auc=0.9231
Fold[8] Epoch: 145 [145/150 (97%)] Train loss=0.019589 Test loss=1.349964 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.016466211527585983
[5/24] Train loss=0.03448164463043213
[10/24] Train loss=0.013546867296099663
[15/24] Train loss=0.02138284593820572
[20/24] Train loss=0.009623674675822258
Test set avg_accuracy=85.00% avg_sensitivity=84.68%, avg_specificity=85.11% avg_auc=0.9233
Fold[8] Epoch: 146 [146/150 (97%)] Train loss=0.019933 Test loss=1.357509 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.011955502443015575
[5/24] Train loss=0.010206405073404312
[10/24] Train loss=0.013913228176534176
[15/24] Train loss=0.010332638397812843
[20/24] Train loss=0.012066865339875221
Test set avg_accuracy=85.05% avg_sensitivity=84.89%, avg_specificity=85.11% avg_auc=0.9233
Fold[8] Epoch: 147 [147/150 (98%)] Train loss=0.017309 Test loss=1.372515 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.03002956323325634
[5/24] Train loss=0.012924162670969963
[10/24] Train loss=0.017966683954000473
[15/24] Train loss=0.012465158477425575
[20/24] Train loss=0.014453892596065998
Test set avg_accuracy=85.01% avg_sensitivity=85.04%, avg_specificity=85.00% avg_auc=0.9233
Fold[8] Epoch: 148 [148/150 (99%)] Train loss=0.022337 Test loss=1.377369 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.017526399344205856
[5/24] Train loss=0.010133725591003895
[10/24] Train loss=0.011912583373486996
[15/24] Train loss=0.017889434471726418
[20/24] Train loss=0.011595227755606174
Test set avg_accuracy=85.03% avg_sensitivity=85.04%, avg_specificity=85.02% avg_auc=0.9233
Fold[8] Epoch: 149 [149/150 (99%)] Train loss=0.015071 Test loss=1.377339 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.014330782927572727
[5/24] Train loss=0.012397369369864464
[10/24] Train loss=0.014521682634949684
[15/24] Train loss=0.012687782756984234
[20/24] Train loss=0.00983807910233736
Test set avg_accuracy=85.03% avg_sensitivity=85.04%, avg_specificity=85.02% avg_auc=0.9233
Fold[8] Epoch: 150 [150/150 (100%)] Train loss=0.015830 Test loss=1.378073 Current lr=[4.388541022775342e-09]

Fold[8] Result: acc=83.85% sen=88.20%, spe=82.43%, auc=0.93!
Fold[8] Avg_overlap=0.81%(0.18468091873599132)
[0/24] Train loss=1.393337368965149
[5/24] Train loss=1.3154866695404053
[10/24] Train loss=1.295271396636963
[15/24] Train loss=1.1241395473480225
[20/24] Train loss=1.031424880027771
Test set avg_accuracy=72.15% avg_sensitivity=2.84%, avg_specificity=98.51% avg_auc=0.7417
Best model saved!! Metric=0.7417041125844104!!
Fold[9] Epoch: 1 [1/150 (1%)] Train loss=1.226154 Test loss=0.658391 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=0.934004008769989
[5/24] Train loss=0.9124578237533569
[10/24] Train loss=1.001131296157837
[15/24] Train loss=0.8386313915252686
[20/24] Train loss=0.914841890335083
Test set avg_accuracy=83.40% avg_sensitivity=69.94%, avg_specificity=88.52% avg_auc=0.8837
Best model saved!! Metric=0.8837367956849258!!
Fold[9] Epoch: 2 [2/150 (1%)] Train loss=0.944496 Test loss=0.432393 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.7885673642158508
[5/24] Train loss=0.835828423500061
[10/24] Train loss=0.8831442594528198
[15/24] Train loss=0.8206205368041992
[20/24] Train loss=0.7921527624130249
Test set avg_accuracy=84.60% avg_sensitivity=76.84%, avg_specificity=87.54% avg_auc=0.9001
Best model saved!! Metric=0.9000820407045563!!
Fold[9] Epoch: 3 [3/150 (2%)] Train loss=0.828288 Test loss=0.408214 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.7158663868904114
[5/24] Train loss=0.7294871211051941
[10/24] Train loss=0.8148236274719238
[15/24] Train loss=0.7287222743034363
[20/24] Train loss=0.7064598202705383
Test set avg_accuracy=82.49% avg_sensitivity=88.14%, avg_specificity=80.34% avg_auc=0.9143
Best model saved!! Metric=0.914323522197111!!
Fold[9] Epoch: 4 [4/150 (3%)] Train loss=0.755826 Test loss=0.506207 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.7678475975990295
[5/24] Train loss=0.7207313776016235
[10/24] Train loss=0.8046767115592957
[15/24] Train loss=0.7737812995910645
[20/24] Train loss=0.7066711187362671
Test set avg_accuracy=83.87% avg_sensitivity=86.86%, avg_specificity=82.73% avg_auc=0.9245
Best model saved!! Metric=0.924516563745602!!
Fold[9] Epoch: 5 [5/150 (3%)] Train loss=0.763238 Test loss=0.429760 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.7010530233383179
[5/24] Train loss=0.7204235196113586
[10/24] Train loss=0.7912321090698242
[15/24] Train loss=0.7400264143943787
[20/24] Train loss=0.7271196246147156
Test set avg_accuracy=85.57% avg_sensitivity=83.27%, avg_specificity=86.45% avg_auc=0.9281
Best model saved!! Metric=0.9280902904711492!!
Fold[9] Epoch: 6 [6/150 (4%)] Train loss=0.753420 Test loss=0.379279 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.6499600410461426
[5/24] Train loss=0.6404215097427368
[10/24] Train loss=0.7827098965644836
[15/24] Train loss=0.7530791163444519
[20/24] Train loss=0.7097565531730652
Test set avg_accuracy=81.11% avg_sensitivity=91.26%, avg_specificity=77.25% avg_auc=0.9344
Best model saved!! Metric=0.9344468100358909!!
Fold[9] Epoch: 7 [7/150 (5%)] Train loss=0.705926 Test loss=0.512162 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.7425215840339661
[5/24] Train loss=0.6438115835189819
[10/24] Train loss=0.778556227684021
[15/24] Train loss=0.7138440608978271
[20/24] Train loss=0.7051573991775513
Test set avg_accuracy=86.43% avg_sensitivity=85.11%, avg_specificity=86.93% avg_auc=0.9363
Best model saved!! Metric=0.9363167418416257!!
Fold[9] Epoch: 8 [8/150 (5%)] Train loss=0.724964 Test loss=0.352394 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.6333768367767334
[5/24] Train loss=0.5962328910827637
[10/24] Train loss=0.7397096753120422
[15/24] Train loss=0.7595187425613403
[20/24] Train loss=0.646254301071167
Test set avg_accuracy=80.23% avg_sensitivity=92.96%, avg_specificity=75.40% avg_auc=0.9398
Best model saved!! Metric=0.9397814093843897!!
Fold[9] Epoch: 9 [9/150 (6%)] Train loss=0.682171 Test loss=0.559564 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.6998895406723022
[5/24] Train loss=0.663709282875061
[10/24] Train loss=0.7199450731277466
[15/24] Train loss=0.7002646327018738
[20/24] Train loss=0.6769260168075562
Test set avg_accuracy=85.82% avg_sensitivity=86.15%, avg_specificity=85.69% avg_auc=0.9415
Best model saved!! Metric=0.941458449130856!!
Fold[9] Epoch: 10 [10/150 (7%)] Train loss=0.695989 Test loss=0.359561 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.6292975544929504
[5/24] Train loss=0.6232427358627319
[10/24] Train loss=0.6915185451507568
[15/24] Train loss=0.6911815404891968
[20/24] Train loss=0.6415944695472717
Test set avg_accuracy=86.64% avg_sensitivity=85.49%, avg_specificity=87.08% avg_auc=0.9424
Best model saved!! Metric=0.9423845178768726!!
Fold[9] Epoch: 11 [11/150 (7%)] Train loss=0.672680 Test loss=0.333302 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.5791105628013611
[5/24] Train loss=0.6078290343284607
[10/24] Train loss=0.7109808921813965
[15/24] Train loss=0.6843002438545227
[20/24] Train loss=0.6068194508552551
Test set avg_accuracy=85.26% avg_sensitivity=87.71%, avg_specificity=84.33% avg_auc=0.9422
Fold[9] Epoch: 12 [12/150 (8%)] Train loss=0.645170 Test loss=0.392187 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6099234819412231
[5/24] Train loss=0.6044386625289917
[10/24] Train loss=0.7261963486671448
[15/24] Train loss=0.6633100509643555
[20/24] Train loss=0.6109943985939026
Test set avg_accuracy=85.81% avg_sensitivity=86.48%, avg_specificity=85.55% avg_auc=0.9431
Best model saved!! Metric=0.9430718710206989!!
Fold[9] Epoch: 13 [13/150 (9%)] Train loss=0.651317 Test loss=0.360251 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.6294410824775696
[5/24] Train loss=0.6026846766471863
[10/24] Train loss=0.6967571377754211
[15/24] Train loss=0.6728013753890991
[20/24] Train loss=0.6682672500610352
Test set avg_accuracy=86.84% avg_sensitivity=84.50%, avg_specificity=87.72% avg_auc=0.9455
Best model saved!! Metric=0.9454842108803693!!
Fold[9] Epoch: 14 [14/150 (9%)] Train loss=0.650058 Test loss=0.319366 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.555749773979187
[5/24] Train loss=0.5374040007591248
[10/24] Train loss=0.6675906777381897
[15/24] Train loss=0.6517695188522339
[20/24] Train loss=0.574598491191864
Test set avg_accuracy=86.61% avg_sensitivity=85.26%, avg_specificity=87.13% avg_auc=0.9459
Best model saved!! Metric=0.9458583161533977!!
Fold[9] Epoch: 15 [15/150 (10%)] Train loss=0.622613 Test loss=0.330263 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.5761799216270447
[5/24] Train loss=0.542981743812561
[10/24] Train loss=0.6397531032562256
[15/24] Train loss=0.6484767198562622
[20/24] Train loss=0.61070317029953
Test set avg_accuracy=86.89% avg_sensitivity=87.71%, avg_specificity=86.57% avg_auc=0.9452
Fold[9] Epoch: 16 [16/150 (11%)] Train loss=0.612806 Test loss=0.348829 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.5809332132339478
[5/24] Train loss=0.5727561712265015
[10/24] Train loss=0.6837599277496338
[15/24] Train loss=0.6821064352989197
[20/24] Train loss=0.5589494705200195
Test set avg_accuracy=88.84% avg_sensitivity=78.50%, avg_specificity=92.77% avg_auc=0.9411
Fold[9] Epoch: 17 [17/150 (11%)] Train loss=0.613234 Test loss=0.298172 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.5753203630447388
[5/24] Train loss=0.5163863301277161
[10/24] Train loss=0.6719949245452881
[15/24] Train loss=0.6397456526756287
[20/24] Train loss=0.5938370823860168
Test set avg_accuracy=86.59% avg_sensitivity=88.37%, avg_specificity=85.91% avg_auc=0.9436
Fold[9] Epoch: 18 [18/150 (12%)] Train loss=0.605572 Test loss=0.377481 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.5624629855155945
[5/24] Train loss=0.5487627983093262
[10/24] Train loss=0.6556840538978577
[15/24] Train loss=0.6333500146865845
[20/24] Train loss=0.5790429711341858
Test set avg_accuracy=88.98% avg_sensitivity=85.35%, avg_specificity=90.37% avg_auc=0.9473
Best model saved!! Metric=0.9472938798432811!!
Fold[9] Epoch: 19 [19/150 (13%)] Train loss=0.597967 Test loss=0.306703 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.5445737242698669
[5/24] Train loss=0.5083130598068237
[10/24] Train loss=0.6547709107398987
[15/24] Train loss=0.5920063257217407
[20/24] Train loss=0.5417190194129944
Test set avg_accuracy=87.83% avg_sensitivity=85.59%, avg_specificity=88.68% avg_auc=0.9422
Fold[9] Epoch: 20 [20/150 (13%)] Train loss=0.579288 Test loss=0.333881 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.5232874751091003
[5/24] Train loss=0.4945536255836487
[10/24] Train loss=0.6119009852409363
[15/24] Train loss=0.634256899356842
[20/24] Train loss=0.5867260098457336
Test set avg_accuracy=86.51% avg_sensitivity=86.06%, avg_specificity=86.68% avg_auc=0.9389
Fold[9] Epoch: 21 [21/150 (14%)] Train loss=0.569755 Test loss=0.373427 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.527560830116272
[5/24] Train loss=0.49498695135116577
[10/24] Train loss=0.6096065640449524
[15/24] Train loss=0.5750235319137573
[20/24] Train loss=0.5119476318359375
Test set avg_accuracy=83.72% avg_sensitivity=90.60%, avg_specificity=81.11% avg_auc=0.9427
Fold[9] Epoch: 22 [22/150 (15%)] Train loss=0.547810 Test loss=0.474160 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.49878016114234924
[5/24] Train loss=0.48100924491882324
[10/24] Train loss=0.5765478610992432
[15/24] Train loss=0.5909003615379333
[20/24] Train loss=0.5014848709106445
Test set avg_accuracy=85.66% avg_sensitivity=89.22%, avg_specificity=84.31% avg_auc=0.9429
Fold[9] Epoch: 23 [23/150 (15%)] Train loss=0.561952 Test loss=0.397217 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5137252807617188
[5/24] Train loss=0.47572430968284607
[10/24] Train loss=0.6409564018249512
[15/24] Train loss=0.534111738204956
[20/24] Train loss=0.5403311252593994
Test set avg_accuracy=87.02% avg_sensitivity=85.30%, avg_specificity=87.67% avg_auc=0.9452
Fold[9] Epoch: 24 [24/150 (16%)] Train loss=0.565618 Test loss=0.319631 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.546393871307373
[5/24] Train loss=0.480354905128479
[10/24] Train loss=0.5799877643585205
[15/24] Train loss=0.5346802473068237
[20/24] Train loss=0.5074983835220337
Test set avg_accuracy=84.08% avg_sensitivity=90.17%, avg_specificity=81.76% avg_auc=0.9460
Fold[9] Epoch: 25 [25/150 (17%)] Train loss=0.545316 Test loss=0.415928 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5592908263206482
[5/24] Train loss=0.5003078579902649
[10/24] Train loss=0.5959115028381348
[15/24] Train loss=0.5235180854797363
[20/24] Train loss=0.5016732215881348
Test set avg_accuracy=85.10% avg_sensitivity=88.89%, avg_specificity=83.66% avg_auc=0.9473
Best model saved!! Metric=0.9472979992906058!!
Fold[9] Epoch: 26 [26/150 (17%)] Train loss=0.563450 Test loss=0.381460 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5431104302406311
[5/24] Train loss=0.4904986321926117
[10/24] Train loss=0.5826793909072876
[15/24] Train loss=0.5161001086235046
[20/24] Train loss=0.5241720676422119
Test set avg_accuracy=87.30% avg_sensitivity=83.93%, avg_specificity=88.59% avg_auc=0.9445
Fold[9] Epoch: 27 [27/150 (18%)] Train loss=0.553212 Test loss=0.312965 Current lr=[0.000669125424222739]

[0/24] Train loss=0.5070664286613464
[5/24] Train loss=0.48935264348983765
[10/24] Train loss=0.5761170983314514
[15/24] Train loss=0.5122172236442566
[20/24] Train loss=0.5102004408836365
Test set avg_accuracy=87.58% avg_sensitivity=84.74%, avg_specificity=88.66% avg_auc=0.9445
Fold[9] Epoch: 28 [28/150 (19%)] Train loss=0.526194 Test loss=0.335174 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5035355687141418
[5/24] Train loss=0.4691964089870453
[10/24] Train loss=0.5629643797874451
[15/24] Train loss=0.5123879909515381
[20/24] Train loss=0.5047004818916321
Test set avg_accuracy=86.13% avg_sensitivity=88.09%, avg_specificity=85.39% avg_auc=0.9439
Fold[9] Epoch: 29 [29/150 (19%)] Train loss=0.518301 Test loss=0.357620 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.4957076609134674
[5/24] Train loss=0.4619864821434021
[10/24] Train loss=0.5674837231636047
[15/24] Train loss=0.5572618246078491
[20/24] Train loss=0.4448068141937256
Test set avg_accuracy=87.04% avg_sensitivity=86.20%, avg_specificity=87.37% avg_auc=0.9447
Fold[9] Epoch: 30 [30/150 (20%)] Train loss=0.520294 Test loss=0.347262 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.4366695284843445
[5/24] Train loss=0.4534497857093811
[10/24] Train loss=0.5265836715698242
[15/24] Train loss=0.5043032169342041
[20/24] Train loss=0.46240416169166565
Test set avg_accuracy=81.97% avg_sensitivity=92.01%, avg_specificity=78.15% avg_auc=0.9445
Fold[9] Epoch: 31 [31/150 (21%)] Train loss=0.489126 Test loss=0.490802 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.4935415983200073
[5/24] Train loss=0.43581241369247437
[10/24] Train loss=0.5318875312805176
[15/24] Train loss=0.4688366949558258
[20/24] Train loss=0.4334324300289154
Test set avg_accuracy=88.91% avg_sensitivity=81.90%, avg_specificity=91.57% avg_auc=0.9439
Fold[9] Epoch: 32 [32/150 (21%)] Train loss=0.504554 Test loss=0.315123 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.49426451325416565
[5/24] Train loss=0.4203471839427948
[10/24] Train loss=0.514887809753418
[15/24] Train loss=0.4462912976741791
[20/24] Train loss=0.432924747467041
Test set avg_accuracy=87.33% avg_sensitivity=87.48%, avg_specificity=87.28% avg_auc=0.9460
Fold[9] Epoch: 33 [33/150 (22%)] Train loss=0.490021 Test loss=0.344989 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.4537489712238312
[5/24] Train loss=0.4563821256160736
[10/24] Train loss=0.5732680559158325
[15/24] Train loss=0.4499627947807312
[20/24] Train loss=0.42357543110847473
Test set avg_accuracy=88.67% avg_sensitivity=80.91%, avg_specificity=91.62% avg_auc=0.9432
Fold[9] Epoch: 34 [34/150 (23%)] Train loss=0.481407 Test loss=0.315696 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.5167021751403809
[5/24] Train loss=0.43339353799819946
[10/24] Train loss=0.5226620435714722
[15/24] Train loss=0.4495183527469635
[20/24] Train loss=0.44465014338493347
Test set avg_accuracy=86.77% avg_sensitivity=84.31%, avg_specificity=87.71% avg_auc=0.9429
Fold[9] Epoch: 35 [35/150 (23%)] Train loss=0.468616 Test loss=0.336923 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.5148031711578369
[5/24] Train loss=0.36592912673950195
[10/24] Train loss=0.5124204158782959
[15/24] Train loss=0.46417543292045593
[20/24] Train loss=0.4028451144695282
Test set avg_accuracy=85.30% avg_sensitivity=86.53%, avg_specificity=84.83% avg_auc=0.9395
Fold[9] Epoch: 36 [36/150 (24%)] Train loss=0.441221 Test loss=0.405838 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.418684720993042
[5/24] Train loss=0.4194485545158386
[10/24] Train loss=0.5215287208557129
[15/24] Train loss=0.4101502001285553
[20/24] Train loss=0.36790525913238525
Test set avg_accuracy=87.24% avg_sensitivity=80.95%, avg_specificity=89.63% avg_auc=0.9334
Fold[9] Epoch: 37 [37/150 (25%)] Train loss=0.459410 Test loss=0.336374 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.4111640751361847
[5/24] Train loss=0.3505137860774994
[10/24] Train loss=0.4542109966278076
[15/24] Train loss=0.3767560124397278
[20/24] Train loss=0.3468153774738312
Test set avg_accuracy=86.22% avg_sensitivity=86.11%, avg_specificity=86.27% avg_auc=0.9421
Fold[9] Epoch: 38 [38/150 (25%)] Train loss=0.412330 Test loss=0.395489 Current lr=[0.000944367614404117]

[0/24] Train loss=0.36543962359428406
[5/24] Train loss=0.38242432475090027
[10/24] Train loss=0.4302756190299988
[15/24] Train loss=0.4311399757862091
[20/24] Train loss=0.3663179576396942
Test set avg_accuracy=85.27% avg_sensitivity=86.77%, avg_specificity=84.71% avg_auc=0.9366
Fold[9] Epoch: 39 [39/150 (26%)] Train loss=0.398207 Test loss=0.505690 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.40897059440612793
[5/24] Train loss=0.34913352131843567
[10/24] Train loss=0.4780861437320709
[15/24] Train loss=0.34892991185188293
[20/24] Train loss=0.37085476517677307
Test set avg_accuracy=85.73% avg_sensitivity=87.33%, avg_specificity=85.12% avg_auc=0.9456
Fold[9] Epoch: 40 [40/150 (27%)] Train loss=0.406945 Test loss=0.406108 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.386847585439682
[5/24] Train loss=0.41725993156433105
[10/24] Train loss=0.4103545844554901
[15/24] Train loss=0.31888219714164734
[20/24] Train loss=0.3787226676940918
Test set avg_accuracy=87.34% avg_sensitivity=84.17%, avg_specificity=88.55% avg_auc=0.9449
Fold[9] Epoch: 41 [41/150 (27%)] Train loss=0.412192 Test loss=0.344312 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.39304232597351074
[5/24] Train loss=0.34647390246391296
[10/24] Train loss=0.40857642889022827
[15/24] Train loss=0.35287538170814514
[20/24] Train loss=0.35216638445854187
Test set avg_accuracy=86.03% avg_sensitivity=86.25%, avg_specificity=85.95% avg_auc=0.9428
Fold[9] Epoch: 42 [42/150 (28%)] Train loss=0.378737 Test loss=0.375124 Current lr=[0.000989780311725182]

[0/24] Train loss=0.35342127084732056
[5/24] Train loss=0.35063281655311584
[10/24] Train loss=0.39179643988609314
[15/24] Train loss=0.33936744928359985
[20/24] Train loss=0.34769994020462036
Test set avg_accuracy=87.59% avg_sensitivity=81.47%, avg_specificity=89.92% avg_auc=0.9438
Fold[9] Epoch: 43 [43/150 (29%)] Train loss=0.385481 Test loss=0.358915 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.32400184869766235
[5/24] Train loss=0.330876886844635
[10/24] Train loss=0.3595178723335266
[15/24] Train loss=0.3183882236480713
[20/24] Train loss=0.3165675103664398
Test set avg_accuracy=86.32% avg_sensitivity=85.68%, avg_specificity=86.56% avg_auc=0.9431
Fold[9] Epoch: 44 [44/150 (29%)] Train loss=0.352545 Test loss=0.416395 Current lr=[0.000998924125869967]

[0/24] Train loss=0.3250018060207367
[5/24] Train loss=0.2793635129928589
[10/24] Train loss=0.324545681476593
[15/24] Train loss=0.2831830680370331
[20/24] Train loss=0.31710711121559143
Test set avg_accuracy=84.71% avg_sensitivity=87.15%, avg_specificity=83.79% avg_auc=0.9390
Fold[9] Epoch: 45 [45/150 (30%)] Train loss=0.316300 Test loss=0.515482 Current lr=[0.000999999611458977]

[0/24] Train loss=0.3352563977241516
[5/24] Train loss=0.28073376417160034
[10/24] Train loss=0.3947838544845581
[15/24] Train loss=0.2733592987060547
[20/24] Train loss=0.26565679907798767
Test set avg_accuracy=87.25% avg_sensitivity=82.28%, avg_specificity=89.14% avg_auc=0.9389
Fold[9] Epoch: 46 [46/150 (31%)] Train loss=0.330917 Test loss=0.397189 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.29319262504577637
[5/24] Train loss=0.24201197922229767
[10/24] Train loss=0.28644654154777527
[15/24] Train loss=0.2755188047885895
[20/24] Train loss=0.2493278533220291
Test set avg_accuracy=84.82% avg_sensitivity=87.62%, avg_specificity=83.75% avg_auc=0.9431
Fold[9] Epoch: 47 [47/150 (31%)] Train loss=0.285406 Test loss=0.498228 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.29265883564949036
[5/24] Train loss=0.2452509105205536
[10/24] Train loss=0.3659709393978119
[15/24] Train loss=0.2525285482406616
[20/24] Train loss=0.2630499005317688
Test set avg_accuracy=82.62% avg_sensitivity=87.29%, avg_specificity=80.84% avg_auc=0.9366
Fold[9] Epoch: 48 [48/150 (32%)] Train loss=0.312587 Test loss=0.494143 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.35681018233299255
[5/24] Train loss=0.2575887441635132
[10/24] Train loss=0.33370667695999146
[15/24] Train loss=0.2827441096305847
[20/24] Train loss=0.3312486708164215
Test set avg_accuracy=84.39% avg_sensitivity=87.85%, avg_specificity=83.07% avg_auc=0.9452
Fold[9] Epoch: 49 [49/150 (33%)] Train loss=0.320376 Test loss=0.447371 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3204787075519562
[5/24] Train loss=0.3107304275035858
[10/24] Train loss=0.31460821628570557
[15/24] Train loss=0.3315005302429199
[20/24] Train loss=0.2576872408390045
Test set avg_accuracy=86.81% avg_sensitivity=82.70%, avg_specificity=88.37% avg_auc=0.9432
Fold[9] Epoch: 50 [50/150 (33%)] Train loss=0.317173 Test loss=0.392717 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.28327903151512146
[5/24] Train loss=0.26379817724227905
[10/24] Train loss=0.32748961448669434
[15/24] Train loss=0.2512039244174957
[20/24] Train loss=0.25355926156044006
Test set avg_accuracy=86.33% avg_sensitivity=84.78%, avg_specificity=86.92% avg_auc=0.9383
Fold[9] Epoch: 51 [51/150 (34%)] Train loss=0.296033 Test loss=0.495888 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.2985117733478546
[5/24] Train loss=0.2269343137741089
[10/24] Train loss=0.30886760354042053
[15/24] Train loss=0.21894076466560364
[20/24] Train loss=0.2099417746067047
Test set avg_accuracy=87.49% avg_sensitivity=80.39%, avg_specificity=90.19% avg_auc=0.9363
Fold[9] Epoch: 52 [52/150 (35%)] Train loss=0.260655 Test loss=0.448672 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.2521056532859802
[5/24] Train loss=0.19261303544044495
[10/24] Train loss=0.27389490604400635
[15/24] Train loss=0.22092877328395844
[20/24] Train loss=0.22810880839824677
Test set avg_accuracy=86.89% avg_sensitivity=82.51%, avg_specificity=88.55% avg_auc=0.9408
Fold[9] Epoch: 53 [53/150 (35%)] Train loss=0.248747 Test loss=0.435843 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.23197245597839355
[5/24] Train loss=0.17247755825519562
[10/24] Train loss=0.2689635455608368
[15/24] Train loss=0.2149713784456253
[20/24] Train loss=0.21598531305789948
Test set avg_accuracy=85.83% avg_sensitivity=86.63%, avg_specificity=85.53% avg_auc=0.9383
Fold[9] Epoch: 54 [54/150 (36%)] Train loss=0.227545 Test loss=0.555689 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.22701551020145416
[5/24] Train loss=0.19130997359752655
[10/24] Train loss=0.24263332784175873
[15/24] Train loss=0.20589931309223175
[20/24] Train loss=0.23676492273807526
Test set avg_accuracy=86.45% avg_sensitivity=87.15%, avg_specificity=86.18% avg_auc=0.9436
Fold[9] Epoch: 55 [55/150 (37%)] Train loss=0.243030 Test loss=0.543581 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.2819647192955017
[5/24] Train loss=0.19304333627223969
[10/24] Train loss=0.23820848762989044
[15/24] Train loss=0.18083925545215607
[20/24] Train loss=0.19439028203487396
Test set avg_accuracy=86.94% avg_sensitivity=84.07%, avg_specificity=88.03% avg_auc=0.9427
Fold[9] Epoch: 56 [56/150 (37%)] Train loss=0.227401 Test loss=0.478692 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.18681436777114868
[5/24] Train loss=0.16508479416370392
[10/24] Train loss=0.23042181134223938
[15/24] Train loss=0.18998335301876068
[20/24] Train loss=0.17121398448944092
Test set avg_accuracy=86.89% avg_sensitivity=84.17%, avg_specificity=87.92% avg_auc=0.9424
Fold[9] Epoch: 57 [57/150 (38%)] Train loss=0.193954 Test loss=0.537749 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.15846700966358185
[5/24] Train loss=0.16753916442394257
[10/24] Train loss=0.22364652156829834
[15/24] Train loss=0.17640727758407593
[20/24] Train loss=0.1500035971403122
Test set avg_accuracy=84.92% avg_sensitivity=88.23%, avg_specificity=83.66% avg_auc=0.9438
Fold[9] Epoch: 58 [58/150 (39%)] Train loss=0.179652 Test loss=0.746805 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.22597737610340118
[5/24] Train loss=0.19442230463027954
[10/24] Train loss=0.2254018932580948
[15/24] Train loss=0.2292064130306244
[20/24] Train loss=0.16737018525600433
Test set avg_accuracy=85.86% avg_sensitivity=85.68%, avg_specificity=85.93% avg_auc=0.9435
Fold[9] Epoch: 59 [59/150 (39%)] Train loss=0.201420 Test loss=0.637382 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.1807752400636673
[5/24] Train loss=0.133619487285614
[10/24] Train loss=0.21181152760982513
[15/24] Train loss=0.1622038334608078
[20/24] Train loss=0.16297459602355957
Test set avg_accuracy=86.22% avg_sensitivity=85.54%, avg_specificity=86.48% avg_auc=0.9381
Fold[9] Epoch: 60 [60/150 (40%)] Train loss=0.177800 Test loss=0.555735 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.15490281581878662
[5/24] Train loss=0.12193045020103455
[10/24] Train loss=0.17490753531455994
[15/24] Train loss=0.1411253809928894
[20/24] Train loss=0.15411444008350372
Test set avg_accuracy=81.25% avg_sensitivity=90.88%, avg_specificity=77.59% avg_auc=0.9395
Fold[9] Epoch: 61 [61/150 (41%)] Train loss=0.157226 Test loss=0.701942 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.20405572652816772
[5/24] Train loss=0.13648788630962372
[10/24] Train loss=0.19848930835723877
[15/24] Train loss=0.19816192984580994
[20/24] Train loss=0.23217390477657318
Test set avg_accuracy=84.52% avg_sensitivity=88.37%, avg_specificity=83.05% avg_auc=0.9402
Fold[9] Epoch: 62 [62/150 (41%)] Train loss=0.180310 Test loss=0.644357 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.1969100683927536
[5/24] Train loss=0.1718372404575348
[10/24] Train loss=0.2097272276878357
[15/24] Train loss=0.1631588637828827
[20/24] Train loss=0.15754258632659912
Test set avg_accuracy=86.60% avg_sensitivity=85.78%, avg_specificity=86.92% avg_auc=0.9420
Fold[9] Epoch: 63 [63/150 (42%)] Train loss=0.190967 Test loss=0.573962 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.1541120409965515
[5/24] Train loss=0.11144013702869415
[10/24] Train loss=0.17079387605190277
[15/24] Train loss=0.16128791868686676
[20/24] Train loss=0.153589129447937
Test set avg_accuracy=85.17% avg_sensitivity=87.81%, avg_specificity=84.17% avg_auc=0.9390
Fold[9] Epoch: 64 [64/150 (43%)] Train loss=0.160986 Test loss=0.729432 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.1863207221031189
[5/24] Train loss=0.13542552292346954
[10/24] Train loss=0.20199313759803772
[15/24] Train loss=0.13947990536689758
[20/24] Train loss=0.1822139024734497
Test set avg_accuracy=83.82% avg_sensitivity=88.42%, avg_specificity=82.06% avg_auc=0.9370
Fold[9] Epoch: 65 [65/150 (43%)] Train loss=0.175586 Test loss=0.664804 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.20468170940876007
[5/24] Train loss=0.13072213530540466
[10/24] Train loss=0.19060829281806946
[15/24] Train loss=0.17024870216846466
[20/24] Train loss=0.1413775533437729
Test set avg_accuracy=87.17% avg_sensitivity=82.89%, avg_specificity=88.80% avg_auc=0.9391
Fold[9] Epoch: 66 [66/150 (44%)] Train loss=0.174490 Test loss=0.532191 Current lr=[0.000904142181093812]

[0/24] Train loss=0.16587212681770325
[5/24] Train loss=0.11870051175355911
[10/24] Train loss=0.16151632368564606
[15/24] Train loss=0.14460350573062897
[20/24] Train loss=0.15300340950489044
Test set avg_accuracy=84.78% avg_sensitivity=86.58%, avg_specificity=84.09% avg_auc=0.9366
Fold[9] Epoch: 67 [67/150 (45%)] Train loss=0.147664 Test loss=0.623845 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.17496588826179504
[5/24] Train loss=0.13887640833854675
[10/24] Train loss=0.16087952256202698
[15/24] Train loss=0.12945768237113953
[20/24] Train loss=0.15676183998584747
Test set avg_accuracy=86.55% avg_sensitivity=83.22%, avg_specificity=87.81% avg_auc=0.9381
Fold[9] Epoch: 68 [68/150 (45%)] Train loss=0.158452 Test loss=0.576642 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.13088269531726837
[5/24] Train loss=0.11550576239824295
[10/24] Train loss=0.17176982760429382
[15/24] Train loss=0.1531011313199997
[20/24] Train loss=0.1218813881278038
Test set avg_accuracy=86.67% avg_sensitivity=82.42%, avg_specificity=88.28% avg_auc=0.9384
Fold[9] Epoch: 69 [69/150 (46%)] Train loss=0.145608 Test loss=0.525428 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.13811324536800385
[5/24] Train loss=0.1178932636976242
[10/24] Train loss=0.1473807990550995
[15/24] Train loss=0.132240429520607
[20/24] Train loss=0.1403844654560089
Test set avg_accuracy=87.53% avg_sensitivity=79.87%, avg_specificity=90.44% avg_auc=0.9343
Fold[9] Epoch: 70 [70/150 (47%)] Train loss=0.135560 Test loss=0.568342 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.1495269536972046
[5/24] Train loss=0.10485296696424484
[10/24] Train loss=0.1318219155073166
[15/24] Train loss=0.12145271897315979
[20/24] Train loss=0.10822636634111404
Test set avg_accuracy=87.10% avg_sensitivity=81.29%, avg_specificity=89.31% avg_auc=0.9308
Fold[9] Epoch: 71 [71/150 (47%)] Train loss=0.118249 Test loss=0.613336 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.11227373033761978
[5/24] Train loss=0.14515556395053864
[10/24] Train loss=0.14190033078193665
[15/24] Train loss=0.12818212807178497
[20/24] Train loss=0.12211304157972336
Test set avg_accuracy=86.43% avg_sensitivity=84.03%, avg_specificity=87.35% avg_auc=0.9341
Fold[9] Epoch: 72 [72/150 (48%)] Train loss=0.146745 Test loss=0.671021 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.25199148058891296
[5/24] Train loss=0.23697268962860107
[10/24] Train loss=0.21931695938110352
[15/24] Train loss=0.17491300404071808
[20/24] Train loss=0.19340577721595764
Test set avg_accuracy=82.88% avg_sensitivity=90.26%, avg_specificity=80.07% avg_auc=0.9296
Fold[9] Epoch: 73 [73/150 (49%)] Train loss=0.198941 Test loss=0.809372 Current lr=[0.000834102481048427]

[0/24] Train loss=0.21299801766872406
[5/24] Train loss=0.19387055933475494
[10/24] Train loss=0.19620807468891144
[15/24] Train loss=0.15816591680049896
[20/24] Train loss=0.18852005898952484
Test set avg_accuracy=85.52% avg_sensitivity=84.26%, avg_specificity=86.00% avg_auc=0.9323
Fold[9] Epoch: 74 [74/150 (49%)] Train loss=0.185843 Test loss=0.676534 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.14775387942790985
[5/24] Train loss=0.1461077183485031
[10/24] Train loss=0.17683841288089752
[15/24] Train loss=0.16872605681419373
[20/24] Train loss=0.1454358547925949
Test set avg_accuracy=84.32% avg_sensitivity=88.28%, avg_specificity=82.82% avg_auc=0.9349
Fold[9] Epoch: 75 [75/150 (50%)] Train loss=0.154035 Test loss=0.883188 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.1703043431043625
[5/24] Train loss=0.11641611903905869
[10/24] Train loss=0.20375588536262512
[15/24] Train loss=0.15156735479831696
[20/24] Train loss=0.13735046982765198
Test set avg_accuracy=85.60% avg_sensitivity=87.52%, avg_specificity=84.87% avg_auc=0.9344
Fold[9] Epoch: 76 [76/150 (51%)] Train loss=0.163245 Test loss=0.767629 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.16134746372699738
[5/24] Train loss=0.13399803638458252
[10/24] Train loss=0.20778873562812805
[15/24] Train loss=0.14712655544281006
[20/24] Train loss=0.12250117212533951
Test set avg_accuracy=85.14% avg_sensitivity=88.52%, avg_specificity=83.86% avg_auc=0.9408
Fold[9] Epoch: 77 [77/150 (51%)] Train loss=0.175056 Test loss=0.706535 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.16638235747814178
[5/24] Train loss=0.13335953652858734
[10/24] Train loss=0.1575704962015152
[15/24] Train loss=0.13384072482585907
[20/24] Train loss=0.13928435742855072
Test set avg_accuracy=86.46% avg_sensitivity=84.92%, avg_specificity=87.04% avg_auc=0.9410
Fold[9] Epoch: 78 [78/150 (52%)] Train loss=0.156591 Test loss=0.715297 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.11567665636539459
[5/24] Train loss=0.11535289138555527
[10/24] Train loss=0.1475926786661148
[15/24] Train loss=0.11663328856229782
[20/24] Train loss=0.10699444264173508
Test set avg_accuracy=87.66% avg_sensitivity=82.61%, avg_specificity=89.58% avg_auc=0.9389
Fold[9] Epoch: 79 [79/150 (53%)] Train loss=0.132839 Test loss=0.640157 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.15453048050403595
[5/24] Train loss=0.10668522119522095
[10/24] Train loss=0.13132032752037048
[15/24] Train loss=0.14121580123901367
[20/24] Train loss=0.10890951752662659
Test set avg_accuracy=85.83% avg_sensitivity=87.19%, avg_specificity=85.32% avg_auc=0.9373
Fold[9] Epoch: 80 [80/150 (53%)] Train loss=0.121525 Test loss=0.773002 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.11141031980514526
[5/24] Train loss=0.120729461312294
[10/24] Train loss=0.13461698591709137
[15/24] Train loss=0.08730857074260712
[20/24] Train loss=0.10539868474006653
Test set avg_accuracy=86.45% avg_sensitivity=81.57%, avg_specificity=88.30% avg_auc=0.9355
Fold[9] Epoch: 81 [81/150 (54%)] Train loss=0.113981 Test loss=0.623988 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.1301770955324173
[5/24] Train loss=0.08098936825990677
[10/24] Train loss=0.09603394567966461
[15/24] Train loss=0.07954041659832001
[20/24] Train loss=0.09223194420337677
Test set avg_accuracy=85.21% avg_sensitivity=86.58%, avg_specificity=84.69% avg_auc=0.9384
Fold[9] Epoch: 82 [82/150 (55%)] Train loss=0.099707 Test loss=0.684135 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.10743645578622818
[5/24] Train loss=0.07960344105958939
[10/24] Train loss=0.10794549435377121
[15/24] Train loss=0.11012513190507889
[20/24] Train loss=0.10367852449417114
Test set avg_accuracy=86.64% avg_sensitivity=83.32%, avg_specificity=87.90% avg_auc=0.9378
Fold[9] Epoch: 83 [83/150 (55%)] Train loss=0.106822 Test loss=0.687784 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.08565330505371094
[5/24] Train loss=0.07394608855247498
[10/24] Train loss=0.1002713069319725
[15/24] Train loss=0.08888375759124756
[20/24] Train loss=0.11926902830600739
Test set avg_accuracy=85.40% avg_sensitivity=87.43%, avg_specificity=84.63% avg_auc=0.9391
Fold[9] Epoch: 84 [84/150 (56%)] Train loss=0.100377 Test loss=0.764136 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.09898839145898819
[5/24] Train loss=0.0988827496767044
[10/24] Train loss=0.09233268350362778
[15/24] Train loss=0.10056882351636887
[20/24] Train loss=0.08795614540576935
Test set avg_accuracy=86.30% avg_sensitivity=86.25%, avg_specificity=86.32% avg_auc=0.9403
Fold[9] Epoch: 85 [85/150 (57%)] Train loss=0.099215 Test loss=0.648318 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.07769747078418732
[5/24] Train loss=0.0648278146982193
[10/24] Train loss=0.09996870905160904
[15/24] Train loss=0.08759761601686478
[20/24] Train loss=0.08459123224020004
Test set avg_accuracy=86.41% avg_sensitivity=86.29%, avg_specificity=86.45% avg_auc=0.9405
Fold[9] Epoch: 86 [86/150 (57%)] Train loss=0.088970 Test loss=0.711909 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.06567747890949249
[5/24] Train loss=0.055585481226444244
[10/24] Train loss=0.07348140329122543
[15/24] Train loss=0.07941628992557526
[20/24] Train loss=0.06340819597244263
Test set avg_accuracy=86.24% avg_sensitivity=86.96%, avg_specificity=85.96% avg_auc=0.9425
Fold[9] Epoch: 87 [87/150 (58%)] Train loss=0.071691 Test loss=0.754754 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.07531115412712097
[5/24] Train loss=0.05157805606722832
[10/24] Train loss=0.09269889444112778
[15/24] Train loss=0.07615575194358826
[20/24] Train loss=0.08482365310192108
Test set avg_accuracy=86.09% avg_sensitivity=85.11%, avg_specificity=86.47% avg_auc=0.9391
Fold[9] Epoch: 88 [88/150 (59%)] Train loss=0.080399 Test loss=0.854561 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.07217969000339508
[5/24] Train loss=0.06510403007268906
[10/24] Train loss=0.06440306454896927
[15/24] Train loss=0.07067190855741501
[20/24] Train loss=0.06408179551362991
Test set avg_accuracy=86.15% avg_sensitivity=85.63%, avg_specificity=86.34% avg_auc=0.9420
Fold[9] Epoch: 89 [89/150 (59%)] Train loss=0.070334 Test loss=0.917219 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.05943094566464424
[5/24] Train loss=0.05269284173846245
[10/24] Train loss=0.05578284710645676
[15/24] Train loss=0.0746074989438057
[20/24] Train loss=0.07053420692682266
Test set avg_accuracy=84.92% avg_sensitivity=87.71%, avg_specificity=83.86% avg_auc=0.9382
Fold[9] Epoch: 90 [90/150 (60%)] Train loss=0.064956 Test loss=1.110662 Current lr=[0.00061065423442182]

[0/24] Train loss=0.0828610435128212
[5/24] Train loss=0.05594724789261818
[10/24] Train loss=0.07954545319080353
[15/24] Train loss=0.060756243765354156
[20/24] Train loss=0.07981213927268982
Test set avg_accuracy=85.23% avg_sensitivity=87.57%, avg_specificity=84.35% avg_auc=0.9387
Fold[9] Epoch: 91 [91/150 (61%)] Train loss=0.080957 Test loss=1.062668 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.08421719819307327
[5/24] Train loss=0.07280014455318451
[10/24] Train loss=0.1377534568309784
[15/24] Train loss=0.07681472599506378
[20/24] Train loss=0.08612357079982758
Test set avg_accuracy=86.35% avg_sensitivity=86.44%, avg_specificity=86.32% avg_auc=0.9399
Fold[9] Epoch: 92 [92/150 (61%)] Train loss=0.085067 Test loss=0.869223 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.09368777275085449
[5/24] Train loss=0.07460596412420273
[10/24] Train loss=0.08785025775432587
[15/24] Train loss=0.06964728236198425
[20/24] Train loss=0.07189751416444778
Test set avg_accuracy=86.28% avg_sensitivity=84.55%, avg_specificity=86.93% avg_auc=0.9439
Fold[9] Epoch: 93 [93/150 (62%)] Train loss=0.085553 Test loss=0.920541 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.07352299988269806
[5/24] Train loss=0.052175335586071014
[10/24] Train loss=0.06821932643651962
[15/24] Train loss=0.06896120309829712
[20/24] Train loss=0.059057239443063736
Test set avg_accuracy=86.46% avg_sensitivity=85.21%, avg_specificity=86.93% avg_auc=0.9427
Fold[9] Epoch: 94 [94/150 (63%)] Train loss=0.070185 Test loss=0.983830 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.07162275910377502
[5/24] Train loss=0.05419868230819702
[10/24] Train loss=0.05576881021261215
[15/24] Train loss=0.08240444213151932
[20/24] Train loss=0.06578748673200607
Test set avg_accuracy=85.86% avg_sensitivity=86.86%, avg_specificity=85.48% avg_auc=0.9384
Fold[9] Epoch: 95 [95/150 (63%)] Train loss=0.062281 Test loss=0.879669 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.07762571424245834
[5/24] Train loss=0.05175185576081276
[10/24] Train loss=0.058042220771312714
[15/24] Train loss=0.0589301697909832
[20/24] Train loss=0.06508738547563553
Test set avg_accuracy=85.14% avg_sensitivity=86.39%, avg_specificity=84.67% avg_auc=0.9372
Fold[9] Epoch: 96 [96/150 (64%)] Train loss=0.068206 Test loss=0.898488 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.08642669022083282
[5/24] Train loss=0.05964386835694313
[10/24] Train loss=0.06001880019903183
[15/24] Train loss=0.06981542706489563
[20/24] Train loss=0.06439396739006042
Test set avg_accuracy=85.73% avg_sensitivity=85.96%, avg_specificity=85.64% avg_auc=0.9408
Fold[9] Epoch: 97 [97/150 (65%)] Train loss=0.074886 Test loss=0.803080 Current lr=[0.000506858408304961]

[0/24] Train loss=0.07685064524412155
[5/24] Train loss=0.08259555697441101
[10/24] Train loss=0.08068089187145233
[15/24] Train loss=0.06064460054039955
[20/24] Train loss=0.06503629684448242
Test set avg_accuracy=87.68% avg_sensitivity=82.94%, avg_specificity=89.49% avg_auc=0.9407
Fold[9] Epoch: 98 [98/150 (65%)] Train loss=0.072956 Test loss=0.800127 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.06843386590480804
[5/24] Train loss=0.055983301252126694
[10/24] Train loss=0.06122976914048195
[15/24] Train loss=0.042790185660123825
[20/24] Train loss=0.060607314109802246
Test set avg_accuracy=87.41% avg_sensitivity=82.33%, avg_specificity=89.34% avg_auc=0.9396
Fold[9] Epoch: 99 [99/150 (66%)] Train loss=0.057759 Test loss=0.774284 Current lr=[0.000476946990416354]

[0/24] Train loss=0.06081711873412132
[5/24] Train loss=0.05109988898038864
[10/24] Train loss=0.057900648564100266
[15/24] Train loss=0.05134515091776848
[20/24] Train loss=0.05149464309215546
Test set avg_accuracy=87.12% avg_sensitivity=83.55%, avg_specificity=88.48% avg_auc=0.9402
Fold[9] Epoch: 100 [100/150 (67%)] Train loss=0.053201 Test loss=0.768118 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.05685878545045853
[5/24] Train loss=0.04159808158874512
[10/24] Train loss=0.04776531457901001
[15/24] Train loss=0.045223187655210495
[20/24] Train loss=0.048896241933107376
Test set avg_accuracy=86.68% avg_sensitivity=83.74%, avg_specificity=87.80% avg_auc=0.9399
Fold[9] Epoch: 101 [101/150 (67%)] Train loss=0.046607 Test loss=0.863927 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.04501569643616676
[5/24] Train loss=0.035298559814691544
[10/24] Train loss=0.04389311373233795
[15/24] Train loss=0.04023874178528786
[20/24] Train loss=0.0392155759036541
Test set avg_accuracy=86.50% avg_sensitivity=84.59%, avg_specificity=87.22% avg_auc=0.9413
Fold[9] Epoch: 102 [102/150 (68%)] Train loss=0.043061 Test loss=1.115723 Current lr=[0.000432267999769856]

[0/24] Train loss=0.03670467436313629
[5/24] Train loss=0.023985104635357857
[10/24] Train loss=0.038691747933626175
[15/24] Train loss=0.03849823400378227
[20/24] Train loss=0.033675890415906906
Test set avg_accuracy=86.60% avg_sensitivity=84.50%, avg_specificity=87.40% avg_auc=0.9419
Fold[9] Epoch: 103 [103/150 (69%)] Train loss=0.039902 Test loss=1.103683 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.026493044570088387
[5/24] Train loss=0.03389797359704971
[10/24] Train loss=0.04008123278617859
[15/24] Train loss=0.03434012085199356
[20/24] Train loss=0.035968031734228134
Test set avg_accuracy=85.20% avg_sensitivity=87.00%, avg_specificity=84.51% avg_auc=0.9401
Fold[9] Epoch: 104 [104/150 (69%)] Train loss=0.037671 Test loss=1.304284 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.040834877640008926
[5/24] Train loss=0.034609273076057434
[10/24] Train loss=0.03768044337630272
[15/24] Train loss=0.03089994005858898
[20/24] Train loss=0.040667399764060974
Test set avg_accuracy=86.41% avg_sensitivity=84.36%, avg_specificity=87.19% avg_auc=0.9408
Fold[9] Epoch: 105 [105/150 (70%)] Train loss=0.039401 Test loss=0.941641 Current lr=[0.000388134363466264]

[0/24] Train loss=0.03846680372953415
[5/24] Train loss=0.027304833754897118
[10/24] Train loss=0.03764442354440689
[15/24] Train loss=0.030402950942516327
[20/24] Train loss=0.032329197973012924
Test set avg_accuracy=85.27% avg_sensitivity=86.39%, avg_specificity=84.85% avg_auc=0.9395
Fold[9] Epoch: 106 [106/150 (71%)] Train loss=0.036384 Test loss=1.227663 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.042375147342681885
[5/24] Train loss=0.041162777692079544
[10/24] Train loss=0.04145827889442444
[15/24] Train loss=0.03670380264520645
[20/24] Train loss=0.03316248953342438
Test set avg_accuracy=86.63% avg_sensitivity=85.35%, avg_specificity=87.11% avg_auc=0.9409
Fold[9] Epoch: 107 [107/150 (71%)] Train loss=0.044784 Test loss=0.952744 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.0364229753613472
[5/24] Train loss=0.029187774285674095
[10/24] Train loss=0.033184606581926346
[15/24] Train loss=0.024268439039587975
[20/24] Train loss=0.027107592672109604
Test set avg_accuracy=86.76% avg_sensitivity=84.64%, avg_specificity=87.56% avg_auc=0.9404
Fold[9] Epoch: 108 [108/150 (72%)] Train loss=0.032426 Test loss=1.078200 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.031896647065877914
[5/24] Train loss=0.024691948667168617
[10/24] Train loss=0.03263330087065697
[15/24] Train loss=0.04522113502025604
[20/24] Train loss=0.03485599160194397
Test set avg_accuracy=85.44% avg_sensitivity=86.48%, avg_specificity=85.05% avg_auc=0.9391
Fold[9] Epoch: 109 [109/150 (73%)] Train loss=0.033363 Test loss=1.388126 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.037918850779533386
[5/24] Train loss=0.03658903017640114
[10/24] Train loss=0.03180369362235069
[15/24] Train loss=0.030919712036848068
[20/24] Train loss=0.0288381390273571
Test set avg_accuracy=86.24% avg_sensitivity=85.07%, avg_specificity=86.68% avg_auc=0.9399
Fold[9] Epoch: 110 [110/150 (73%)] Train loss=0.036844 Test loss=1.098028 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.04112579673528671
[5/24] Train loss=0.025434717535972595
[10/24] Train loss=0.02607978694140911
[15/24] Train loss=0.02607479877769947
[20/24] Train loss=0.025068607181310654
Test set avg_accuracy=85.96% avg_sensitivity=86.01%, avg_specificity=85.95% avg_auc=0.9415
Fold[9] Epoch: 111 [111/150 (74%)] Train loss=0.029480 Test loss=1.300759 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.03411853313446045
[5/24] Train loss=0.026536379009485245
[10/24] Train loss=0.03154878318309784
[15/24] Train loss=0.042329348623752594
[20/24] Train loss=0.025398757308721542
Test set avg_accuracy=86.28% avg_sensitivity=85.26%, avg_specificity=86.66% avg_auc=0.9401
Fold[9] Epoch: 112 [112/150 (75%)] Train loss=0.033619 Test loss=1.006915 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.029447706416249275
[5/24] Train loss=0.026400571689009666
[10/24] Train loss=0.02993701584637165
[15/24] Train loss=0.025327812880277634
[20/24] Train loss=0.028551282361149788
Test set avg_accuracy=86.17% avg_sensitivity=85.54%, avg_specificity=86.41% avg_auc=0.9403
Fold[9] Epoch: 113 [113/150 (75%)] Train loss=0.028121 Test loss=1.197355 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.02453101985156536
[5/24] Train loss=0.029538339003920555
[10/24] Train loss=0.02272755093872547
[15/24] Train loss=0.01952947862446308
[20/24] Train loss=0.02367887645959854
Test set avg_accuracy=85.36% avg_sensitivity=87.05%, avg_specificity=84.72% avg_auc=0.9403
Fold[9] Epoch: 114 [114/150 (76%)] Train loss=0.027299 Test loss=1.384253 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.030045002698898315
[5/24] Train loss=0.02929803356528282
[10/24] Train loss=0.029286548495292664
[15/24] Train loss=0.06832276284694672
[20/24] Train loss=0.030043063685297966
Test set avg_accuracy=84.60% avg_sensitivity=87.76%, avg_specificity=83.39% avg_auc=0.9365
Fold[9] Epoch: 115 [115/150 (77%)] Train loss=0.033798 Test loss=1.306903 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.03715251386165619
[5/24] Train loss=0.04640774801373482
[10/24] Train loss=0.04703019559383392
[15/24] Train loss=0.055031560361385345
[20/24] Train loss=0.028834369033575058
Test set avg_accuracy=86.64% avg_sensitivity=84.83%, avg_specificity=87.33% avg_auc=0.9374
Fold[9] Epoch: 116 [116/150 (77%)] Train loss=0.041815 Test loss=1.061940 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.024505890905857086
[5/24] Train loss=0.02272897958755493
[10/24] Train loss=0.026250051334500313
[15/24] Train loss=0.03391382843255997
[20/24] Train loss=0.025499237701296806
Test set avg_accuracy=85.86% avg_sensitivity=86.67%, avg_specificity=85.55% avg_auc=0.9409
Fold[9] Epoch: 117 [117/150 (78%)] Train loss=0.031818 Test loss=1.313821 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.03230943903326988
[5/24] Train loss=0.034515369683504105
[10/24] Train loss=0.04032187536358833
[15/24] Train loss=0.026104150339961052
[20/24] Train loss=0.029109220951795578
Test set avg_accuracy=86.15% avg_sensitivity=85.11%, avg_specificity=86.54% avg_auc=0.9402
Fold[9] Epoch: 118 [118/150 (79%)] Train loss=0.032348 Test loss=1.149276 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.047613803297281265
[5/24] Train loss=0.021729128435254097
[10/24] Train loss=0.028376922011375427
[15/24] Train loss=0.021238069981336594
[20/24] Train loss=0.02169664204120636
Test set avg_accuracy=86.33% avg_sensitivity=85.21%, avg_specificity=86.75% avg_auc=0.9407
Fold[9] Epoch: 119 [119/150 (79%)] Train loss=0.027865 Test loss=1.182527 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.02222433127462864
[5/24] Train loss=0.01877756416797638
[10/24] Train loss=0.03195370361208916
[15/24] Train loss=0.020000839605927467
[20/24] Train loss=0.02714151330292225
Test set avg_accuracy=85.72% avg_sensitivity=85.44%, avg_specificity=85.82% avg_auc=0.9418
Fold[9] Epoch: 120 [120/150 (80%)] Train loss=0.023650 Test loss=1.362178 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.017677832394838333
[5/24] Train loss=0.019111832603812218
[10/24] Train loss=0.020822271704673767
[15/24] Train loss=0.015914438292384148
[20/24] Train loss=0.02014826238155365
Test set avg_accuracy=85.81% avg_sensitivity=85.44%, avg_specificity=85.95% avg_auc=0.9421
Fold[9] Epoch: 121 [121/150 (81%)] Train loss=0.020611 Test loss=1.381807 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.020707761868834496
[5/24] Train loss=0.01675593852996826
[10/24] Train loss=0.01985565945506096
[15/24] Train loss=0.016378749161958694
[20/24] Train loss=0.02198551967740059
Test set avg_accuracy=84.77% avg_sensitivity=88.09%, avg_specificity=83.50% avg_auc=0.9401
Fold[9] Epoch: 122 [122/150 (81%)] Train loss=0.024296 Test loss=1.539414 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.025580570101737976
[5/24] Train loss=0.022304851561784744
[10/24] Train loss=0.030945464968681335
[15/24] Train loss=0.027356695383787155
[20/24] Train loss=0.020915362983942032
Test set avg_accuracy=84.86% avg_sensitivity=87.15%, avg_specificity=83.99% avg_auc=0.9390
Fold[9] Epoch: 123 [123/150 (82%)] Train loss=0.025607 Test loss=1.431887 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.04366030916571617
[5/24] Train loss=0.025080014020204544
[10/24] Train loss=0.02743428759276867
[15/24] Train loss=0.02052449807524681
[20/24] Train loss=0.020852239802479744
Test set avg_accuracy=85.99% avg_sensitivity=85.82%, avg_specificity=86.05% avg_auc=0.9377
Fold[9] Epoch: 124 [124/150 (83%)] Train loss=0.027707 Test loss=1.320346 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.02134350873529911
[5/24] Train loss=0.03237370029091835
[10/24] Train loss=0.02061905525624752
[15/24] Train loss=0.017348716035485268
[20/24] Train loss=0.017769496887922287
Test set avg_accuracy=85.12% avg_sensitivity=86.63%, avg_specificity=84.54% avg_auc=0.9401
Fold[9] Epoch: 125 [125/150 (83%)] Train loss=0.021930 Test loss=1.430958 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.02591865137219429
[5/24] Train loss=0.019840817898511887
[10/24] Train loss=0.025654897093772888
[15/24] Train loss=0.02099623903632164
[20/24] Train loss=0.02035580202937126
Test set avg_accuracy=85.53% avg_sensitivity=86.48%, avg_specificity=85.17% avg_auc=0.9401
Fold[9] Epoch: 126 [126/150 (84%)] Train loss=0.024936 Test loss=1.383624 Current lr=[0.000123057953306828]

[0/24] Train loss=0.03001973405480385
[5/24] Train loss=0.02341466397047043
[10/24] Train loss=0.030787251889705658
[15/24] Train loss=0.02066999115049839
[20/24] Train loss=0.020785149186849594
Test set avg_accuracy=86.20% avg_sensitivity=85.59%, avg_specificity=86.43% avg_auc=0.9390
Fold[9] Epoch: 127 [127/150 (85%)] Train loss=0.027054 Test loss=1.249558 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.022963333874940872
[5/24] Train loss=0.0382930226624012
[10/24] Train loss=0.022302154451608658
[15/24] Train loss=0.020956477150321007
[20/24] Train loss=0.016482461243867874
Test set avg_accuracy=85.87% avg_sensitivity=86.15%, avg_specificity=85.77% avg_auc=0.9398
Fold[9] Epoch: 128 [128/150 (85%)] Train loss=0.025123 Test loss=1.298306 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.026373568922281265
[5/24] Train loss=0.024466387927532196
[10/24] Train loss=0.04024086892604828
[15/24] Train loss=0.022572848945856094
[20/24] Train loss=0.028147535398602486
Test set avg_accuracy=86.24% avg_sensitivity=85.68%, avg_specificity=86.45% avg_auc=0.9398
Fold[9] Epoch: 129 [129/150 (86%)] Train loss=0.026915 Test loss=1.263824 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.019785406067967415
[5/24] Train loss=0.018983973190188408
[10/24] Train loss=0.020745810121297836
[15/24] Train loss=0.016233226284384727
[20/24] Train loss=0.0239915419369936
Test set avg_accuracy=86.24% avg_sensitivity=85.59%, avg_specificity=86.48% avg_auc=0.9404
Fold[9] Epoch: 130 [130/150 (87%)] Train loss=0.021101 Test loss=1.300935 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.022906048223376274
[5/24] Train loss=0.018297024071216583
[10/24] Train loss=0.022768154740333557
[15/24] Train loss=0.04098967835307121
[20/24] Train loss=0.016135860234498978
Test set avg_accuracy=86.05% avg_sensitivity=86.39%, avg_specificity=85.93% avg_auc=0.9413
Fold[9] Epoch: 131 [131/150 (87%)] Train loss=0.025670 Test loss=1.364026 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.02338835969567299
[5/24] Train loss=0.019645091146230698
[10/24] Train loss=0.02221776358783245
[15/24] Train loss=0.021137453615665436
[20/24] Train loss=0.02027120254933834
Test set avg_accuracy=86.17% avg_sensitivity=86.48%, avg_specificity=86.05% avg_auc=0.9414
Fold[9] Epoch: 132 [132/150 (88%)] Train loss=0.023024 Test loss=1.331421 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.024576028808951378
[5/24] Train loss=0.02725033275783062
[10/24] Train loss=0.02534247376024723
[15/24] Train loss=0.01950613409280777
[20/24] Train loss=0.018887775018811226
Test set avg_accuracy=86.35% avg_sensitivity=85.78%, avg_specificity=86.57% avg_auc=0.9412
Fold[9] Epoch: 133 [133/150 (89%)] Train loss=0.026555 Test loss=1.291771 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.02200080268085003
[5/24] Train loss=0.018481699749827385
[10/24] Train loss=0.02134847268462181
[15/24] Train loss=0.017017651349306107
[20/24] Train loss=0.02269013039767742
Test set avg_accuracy=86.46% avg_sensitivity=85.44%, avg_specificity=86.84% avg_auc=0.9409
Fold[9] Epoch: 134 [134/150 (89%)] Train loss=0.021232 Test loss=1.284245 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.02373713254928589
[5/24] Train loss=0.014824365265667439
[10/24] Train loss=0.017148928716778755
[15/24] Train loss=0.0201199259608984
[20/24] Train loss=0.01778344437479973
Test set avg_accuracy=86.51% avg_sensitivity=85.82%, avg_specificity=86.77% avg_auc=0.9411
Fold[9] Epoch: 135 [135/150 (90%)] Train loss=0.022209 Test loss=1.328217 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.023937521502375603
[5/24] Train loss=0.021711507812142372
[10/24] Train loss=0.01640547811985016
[15/24] Train loss=0.04005732387304306
[20/24] Train loss=0.01867969147861004
Test set avg_accuracy=85.82% avg_sensitivity=86.67%, avg_specificity=85.50% avg_auc=0.9415
Fold[9] Epoch: 136 [136/150 (91%)] Train loss=0.020152 Test loss=1.396933 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.0204487144947052
[5/24] Train loss=0.017935538664460182
[10/24] Train loss=0.016903206706047058
[15/24] Train loss=0.01795688085258007
[20/24] Train loss=0.01605222374200821
Test set avg_accuracy=85.68% avg_sensitivity=86.77%, avg_specificity=85.26% avg_auc=0.9415
Fold[9] Epoch: 137 [137/150 (91%)] Train loss=0.019367 Test loss=1.421776 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.019902382045984268
[5/24] Train loss=0.021540207788348198
[10/24] Train loss=0.028682945296168327
[15/24] Train loss=0.021388106048107147
[20/24] Train loss=0.021522097289562225
Test set avg_accuracy=85.95% avg_sensitivity=86.44%, avg_specificity=85.77% avg_auc=0.9415
Fold[9] Epoch: 138 [138/150 (92%)] Train loss=0.022983 Test loss=1.401995 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.02803579345345497
[5/24] Train loss=0.02267908863723278
[10/24] Train loss=0.028558379039168358
[15/24] Train loss=0.02231176756322384
[20/24] Train loss=0.021277181804180145
Test set avg_accuracy=86.29% avg_sensitivity=86.15%, avg_specificity=86.34% avg_auc=0.9415
Fold[9] Epoch: 139 [139/150 (93%)] Train loss=0.026203 Test loss=1.330574 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.022135693579912186
[5/24] Train loss=0.018084706738591194
[10/24] Train loss=0.02280130423605442
[15/24] Train loss=0.01810106821358204
[20/24] Train loss=0.016314703971147537
Test set avg_accuracy=86.24% avg_sensitivity=85.73%, avg_specificity=86.43% avg_auc=0.9414
Fold[9] Epoch: 140 [140/150 (93%)] Train loss=0.021936 Test loss=1.331336 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.019151510670781136
[5/24] Train loss=0.014582700096070766
[10/24] Train loss=0.019149428233504295
[15/24] Train loss=0.014077396132051945
[20/24] Train loss=0.017395302653312683
Test set avg_accuracy=86.21% avg_sensitivity=85.92%, avg_specificity=86.32% avg_auc=0.9415
Fold[9] Epoch: 141 [141/150 (94%)] Train loss=0.018866 Test loss=1.344689 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.02828560397028923
[5/24] Train loss=0.01435067504644394
[10/24] Train loss=0.021656425669789314
[15/24] Train loss=0.011332236230373383
[20/24] Train loss=0.02189599722623825
Test set avg_accuracy=86.26% avg_sensitivity=86.39%, avg_specificity=86.21% avg_auc=0.9417
Fold[9] Epoch: 142 [142/150 (95%)] Train loss=0.018264 Test loss=1.360527 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.019259724766016006
[5/24] Train loss=0.015360213816165924
[10/24] Train loss=0.01990622468292713
[15/24] Train loss=0.013443847186863422
[20/24] Train loss=0.016837522387504578
Test set avg_accuracy=86.25% avg_sensitivity=86.44%, avg_specificity=86.18% avg_auc=0.9417
Fold[9] Epoch: 143 [143/150 (95%)] Train loss=0.018720 Test loss=1.377221 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.023270608857274055
[5/24] Train loss=0.016853313893079758
[10/24] Train loss=0.019264714792370796
[15/24] Train loss=0.019753603264689445
[20/24] Train loss=0.018623290583491325
Test set avg_accuracy=86.28% avg_sensitivity=86.34%, avg_specificity=86.25% avg_auc=0.9418
Fold[9] Epoch: 144 [144/150 (96%)] Train loss=0.020636 Test loss=1.376457 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.028331050649285316
[5/24] Train loss=0.021891120821237564
[10/24] Train loss=0.026547497138381004
[15/24] Train loss=0.01863027550280094
[20/24] Train loss=0.025118784978985786
Test set avg_accuracy=86.26% avg_sensitivity=86.29%, avg_specificity=86.25% avg_auc=0.9417
Fold[9] Epoch: 145 [145/150 (97%)] Train loss=0.027717 Test loss=1.371678 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.030545992776751518
[5/24] Train loss=0.03247697651386261
[10/24] Train loss=0.03390016779303551
[15/24] Train loss=0.02984285168349743
[20/24] Train loss=0.02506626397371292
Test set avg_accuracy=86.20% avg_sensitivity=86.01%, avg_specificity=86.27% avg_auc=0.9416
Fold[9] Epoch: 146 [146/150 (97%)] Train loss=0.029649 Test loss=1.366583 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.02385227382183075
[5/24] Train loss=0.023432141169905663
[10/24] Train loss=0.027372591197490692
[15/24] Train loss=0.02123415470123291
[20/24] Train loss=0.024258211255073547
Test set avg_accuracy=86.21% avg_sensitivity=86.06%, avg_specificity=86.27% avg_auc=0.9416
Fold[9] Epoch: 147 [147/150 (98%)] Train loss=0.024160 Test loss=1.363341 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.025008127093315125
[5/24] Train loss=0.016318509355187416
[10/24] Train loss=0.019365331158041954
[15/24] Train loss=0.01750844717025757
[20/24] Train loss=0.018453622236847878
Test set avg_accuracy=86.18% avg_sensitivity=85.96%, avg_specificity=86.27% avg_auc=0.9416
Fold[9] Epoch: 148 [148/150 (99%)] Train loss=0.020519 Test loss=1.363325 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.0180977676063776
[5/24] Train loss=0.015056638978421688
[10/24] Train loss=0.016151346266269684
[15/24] Train loss=0.016239473596215248
[20/24] Train loss=0.015708090737462044
Test set avg_accuracy=86.20% avg_sensitivity=85.96%, avg_specificity=86.29% avg_auc=0.9415
Fold[9] Epoch: 149 [149/150 (99%)] Train loss=0.019462 Test loss=1.362576 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.0180923230946064
[5/24] Train loss=0.01371385995298624
[10/24] Train loss=0.01779116503894329
[15/24] Train loss=0.017190562561154366
[20/24] Train loss=0.012479313649237156
Test set avg_accuracy=86.20% avg_sensitivity=86.01%, avg_specificity=86.27% avg_auc=0.9416
Fold[9] Epoch: 150 [150/150 (100%)] Train loss=0.016126 Test loss=1.363369 Current lr=[4.388541022775342e-09]

Fold[9] Result: acc=85.10% sen=88.89%, spe=83.66%, auc=0.95!
Fold[9] Avg_overlap=0.71%(0.22734456401549014)
[0/24] Train loss=1.4081106185913086
[5/24] Train loss=1.334298014640808
[10/24] Train loss=1.290245771408081
[15/24] Train loss=1.1359808444976807
[20/24] Train loss=1.0427569150924683
Test set avg_accuracy=71.72% avg_sensitivity=14.97%, avg_specificity=90.17% avg_auc=0.6969
Best model saved!! Metric=0.6969055549694568!!
Fold[10] Epoch: 1 [1/150 (1%)] Train loss=1.230571 Test loss=0.633107 Current lr=[4.1171423292630984e-05]

[0/24] Train loss=1.0068496465682983
[5/24] Train loss=0.9537971019744873
[10/24] Train loss=0.9903037548065186
[15/24] Train loss=0.9225603342056274
[20/24] Train loss=0.883170485496521
Test set avg_accuracy=76.39% avg_sensitivity=74.47%, avg_specificity=77.02% avg_auc=0.8202
Best model saved!! Metric=0.8202010153425967!!
Fold[10] Epoch: 2 [2/150 (1%)] Train loss=0.967846 Test loss=0.618165 Current lr=[4.467997553498032e-05]

[0/24] Train loss=0.8214666247367859
[5/24] Train loss=0.7957892417907715
[10/24] Train loss=0.868487536907196
[15/24] Train loss=0.8098170161247253
[20/24] Train loss=0.8160678148269653
Test set avg_accuracy=77.43% avg_sensitivity=78.13%, avg_specificity=77.21% avg_auc=0.8394
Best model saved!! Metric=0.8394352610116941!!
Fold[10] Epoch: 3 [3/150 (2%)] Train loss=0.856036 Test loss=0.606283 Current lr=[5.050853172779721e-05]

[0/24] Train loss=0.8260961174964905
[5/24] Train loss=0.8055499196052551
[10/24] Train loss=0.8437426090240479
[15/24] Train loss=0.8071555495262146
[20/24] Train loss=0.7594195604324341
Test set avg_accuracy=81.07% avg_sensitivity=76.96%, avg_specificity=82.40% avg_auc=0.8660
Best model saved!! Metric=0.8660476641039504!!
Fold[10] Epoch: 4 [4/150 (3%)] Train loss=0.825374 Test loss=0.502214 Current lr=[5.8628643094054377e-05]

[0/24] Train loss=0.7164657711982727
[5/24] Train loss=0.7502886652946472
[10/24] Train loss=0.7764040231704712
[15/24] Train loss=0.8041467666625977
[20/24] Train loss=0.7464281320571899
Test set avg_accuracy=76.76% avg_sensitivity=86.73%, avg_specificity=73.52% avg_auc=0.8871
Best model saved!! Metric=0.8871117737688632!!
Fold[10] Epoch: 5 [5/150 (3%)] Train loss=0.771608 Test loss=0.617301 Current lr=[6.900067593544634e-05]

[0/24] Train loss=0.770668089389801
[5/24] Train loss=0.7358065843582153
[10/24] Train loss=0.7660068869590759
[15/24] Train loss=0.7650066614151001
[20/24] Train loss=0.7231313586235046
Test set avg_accuracy=81.30% avg_sensitivity=82.01%, avg_specificity=81.07% avg_auc=0.8974
Best model saved!! Metric=0.8973527940053833!!
Fold[10] Epoch: 6 [6/150 (4%)] Train loss=0.760957 Test loss=0.463344 Current lr=[8.157400508171375e-05]

[0/24] Train loss=0.6968250870704651
[5/24] Train loss=0.7739710807800293
[10/24] Train loss=0.7268863320350647
[15/24] Train loss=0.7524559497833252
[20/24] Train loss=0.726295530796051
Test set avg_accuracy=82.23% avg_sensitivity=83.23%, avg_specificity=81.90% avg_auc=0.9076
Best model saved!! Metric=0.907574353936165!!
Fold[10] Epoch: 7 [7/150 (5%)] Train loss=0.741656 Test loss=0.430116 Current lr=[9.628726098857366e-05]

[0/24] Train loss=0.705838680267334
[5/24] Train loss=0.7140097618103027
[10/24] Train loss=0.7172699570655823
[15/24] Train loss=0.7149105668067932
[20/24] Train loss=0.6886860728263855
Test set avg_accuracy=85.00% avg_sensitivity=79.03%, avg_specificity=86.94% avg_auc=0.9128
Best model saved!! Metric=0.9128086725012783!!
Fold[10] Epoch: 8 [8/150 (5%)] Train loss=0.717731 Test loss=0.361690 Current lr=[0.0001130686292781937]

[0/24] Train loss=0.6579863429069519
[5/24] Train loss=0.6699306964874268
[10/24] Train loss=0.7081802487373352
[15/24] Train loss=0.7629172205924988
[20/24] Train loss=0.6621841192245483
Test set avg_accuracy=82.16% avg_sensitivity=85.40%, avg_specificity=81.11% avg_auc=0.9146
Best model saved!! Metric=0.9145946706785117!!
Fold[10] Epoch: 9 [9/150 (6%)] Train loss=0.702191 Test loss=0.458277 Current lr=[0.00013183620126017137]

[0/24] Train loss=0.6984953284263611
[5/24] Train loss=0.7176658511161804
[10/24] Train loss=0.6909105181694031
[15/24] Train loss=0.6972270011901855
[20/24] Train loss=0.667316734790802
Test set avg_accuracy=84.30% avg_sensitivity=82.32%, avg_specificity=84.94% avg_auc=0.9209
Best model saved!! Metric=0.9208961008324065!!
Fold[10] Epoch: 10 [10/150 (7%)] Train loss=0.695579 Test loss=0.369315 Current lr=[0.00015249837372214897]

[0/24] Train loss=0.6166800260543823
[5/24] Train loss=0.6330946683883667
[10/24] Train loss=0.6583632230758667
[15/24] Train loss=0.7471028566360474
[20/24] Train loss=0.6148943901062012
Test set avg_accuracy=83.54% avg_sensitivity=85.30%, avg_specificity=82.97% avg_auc=0.9187
Fold[10] Epoch: 11 [11/150 (7%)] Train loss=0.660509 Test loss=0.421116 Current lr=[0.0001749542960387167]

[0/24] Train loss=0.6360135674476624
[5/24] Train loss=0.7146289944648743
[10/24] Train loss=0.6722210049629211
[15/24] Train loss=0.6816922426223755
[20/24] Train loss=0.621291995048523
Test set avg_accuracy=84.22% avg_sensitivity=84.98%, avg_specificity=83.97% avg_auc=0.9222
Best model saved!! Metric=0.9222146395713274!!
Fold[10] Epoch: 12 [12/150 (8%)] Train loss=0.666244 Test loss=0.379106 Current lr=[0.00019909436241629503]

[0/24] Train loss=0.6812924146652222
[5/24] Train loss=0.6995053887367249
[10/24] Train loss=0.6732200384140015
[15/24] Train loss=0.6688520908355713
[20/24] Train loss=0.6177017092704773
Test set avg_accuracy=86.05% avg_sensitivity=81.74%, avg_specificity=87.46% avg_auc=0.9272
Best model saved!! Metric=0.9272027967160894!!
Fold[10] Epoch: 13 [13/150 (9%)] Train loss=0.654970 Test loss=0.332994 Current lr=[0.00022480074687138227]

[0/24] Train loss=0.5612657070159912
[5/24] Train loss=0.6054224371910095
[10/24] Train loss=0.6483528017997742
[15/24] Train loss=0.6801835894584656
[20/24] Train loss=0.5450547337532043
Test set avg_accuracy=85.89% avg_sensitivity=81.90%, avg_specificity=87.18% avg_auc=0.9239
Fold[10] Epoch: 14 [14/150 (9%)] Train loss=0.619482 Test loss=0.350646 Current lr=[0.0002519479783309785]

[0/24] Train loss=0.589383065700531
[5/24] Train loss=0.6054571866989136
[10/24] Train loss=0.618744969367981
[15/24] Train loss=0.6749626994132996
[20/24] Train loss=0.5723202228546143
Test set avg_accuracy=84.40% avg_sensitivity=86.68%, avg_specificity=83.66% avg_auc=0.9249
Fold[10] Epoch: 15 [15/150 (10%)] Train loss=0.615239 Test loss=0.387761 Current lr=[0.00028040355304815765]

[0/24] Train loss=0.6085343956947327
[5/24] Train loss=0.6567549705505371
[10/24] Train loss=0.6540833115577698
[15/24] Train loss=0.6389889121055603
[20/24] Train loss=0.5138028264045715
Test set avg_accuracy=85.87% avg_sensitivity=84.71%, avg_specificity=86.25% avg_auc=0.9246
Fold[10] Epoch: 16 [16/150 (11%)] Train loss=0.614161 Test loss=0.358533 Current lr=[0.0003100285813436328]

[0/24] Train loss=0.5708625316619873
[5/24] Train loss=0.5510849356651306
[10/24] Train loss=0.6172420382499695
[15/24] Train loss=0.6818845272064209
[20/24] Train loss=0.5350984930992126
Test set avg_accuracy=84.49% avg_sensitivity=85.88%, avg_specificity=84.04% avg_auc=0.9266
Fold[10] Epoch: 17 [17/150 (11%)] Train loss=0.604339 Test loss=0.379802 Current lr=[0.00034067846551661155]

[0/24] Train loss=0.5811719298362732
[5/24] Train loss=0.5915205478668213
[10/24] Train loss=0.6045567989349365
[15/24] Train loss=0.6943410634994507
[20/24] Train loss=0.5072535872459412
Test set avg_accuracy=87.19% avg_sensitivity=80.36%, avg_specificity=89.41% avg_auc=0.9255
Fold[10] Epoch: 18 [18/150 (12%)] Train loss=0.602968 Test loss=0.317200 Current lr=[0.0003722036056161077]

[0/24] Train loss=0.5697689056396484
[5/24] Train loss=0.5428206324577332
[10/24] Train loss=0.5961915850639343
[15/24] Train loss=0.6473466157913208
[20/24] Train loss=0.519595742225647
Test set avg_accuracy=86.16% avg_sensitivity=83.60%, avg_specificity=86.99% avg_auc=0.9217
Fold[10] Epoch: 19 [19/150 (13%)] Train loss=0.589061 Test loss=0.355043 Current lr=[0.00040445012962788784]

[0/24] Train loss=0.5398352742195129
[5/24] Train loss=0.5268346071243286
[10/24] Train loss=0.5851173996925354
[15/24] Train loss=0.666999340057373
[20/24] Train loss=0.5194928646087646
Test set avg_accuracy=83.49% avg_sensitivity=87.42%, avg_specificity=82.21% avg_auc=0.9243
Fold[10] Epoch: 20 [20/150 (13%)] Train loss=0.581006 Test loss=0.410546 Current lr=[0.00043726064451306116]

[0/24] Train loss=0.5290234088897705
[5/24] Train loss=0.5379777550697327
[10/24] Train loss=0.6230087876319885
[15/24] Train loss=0.5896733999252319
[20/24] Train loss=0.4821908473968506
Test set avg_accuracy=84.84% avg_sensitivity=85.40%, avg_specificity=84.66% avg_auc=0.9271
Fold[10] Epoch: 21 [21/150 (14%)] Train loss=0.580268 Test loss=0.354413 Current lr=[0.00047047500443254584]

[0/24] Train loss=0.5485224723815918
[5/24] Train loss=0.537519633769989
[10/24] Train loss=0.5710954666137695
[15/24] Train loss=0.5939070582389832
[20/24] Train loss=0.5087733268737793
Test set avg_accuracy=86.29% avg_sensitivity=84.18%, avg_specificity=86.97% avg_auc=0.9255
Fold[10] Epoch: 22 [22/150 (15%)] Train loss=0.567707 Test loss=0.335371 Current lr=[0.0005039310924077602]

[0/24] Train loss=0.5407137870788574
[5/24] Train loss=0.4902765452861786
[10/24] Train loss=0.598007082939148
[15/24] Train loss=0.6197828650474548
[20/24] Train loss=0.5019595623016357
Test set avg_accuracy=85.20% avg_sensitivity=85.46%, avg_specificity=85.11% avg_auc=0.9252
Fold[10] Epoch: 23 [23/150 (15%)] Train loss=0.562144 Test loss=0.382726 Current lr=[0.0005374656116023109]

[0/24] Train loss=0.5331129431724548
[5/24] Train loss=0.4993991553783417
[10/24] Train loss=0.5663759708404541
[15/24] Train loss=0.5830876231193542
[20/24] Train loss=0.4638626277446747
Test set avg_accuracy=87.81% avg_sensitivity=74.84%, avg_specificity=92.03% avg_auc=0.9253
Fold[10] Epoch: 24 [24/150 (16%)] Train loss=0.551312 Test loss=0.313863 Current lr=[0.0005709148823624825]

[0/24] Train loss=0.5467185974121094
[5/24] Train loss=0.4877874553203583
[10/24] Train loss=0.6082346439361572
[15/24] Train loss=0.6827717423439026
[20/24] Train loss=0.5119416117668152
Test set avg_accuracy=82.12% avg_sensitivity=88.59%, avg_specificity=80.02% avg_auc=0.9253
Fold[10] Epoch: 25 [25/150 (17%)] Train loss=0.566254 Test loss=0.449681 Current lr=[0.0006041156411262332]

[0/24] Train loss=0.5669604539871216
[5/24] Train loss=0.5530584454536438
[10/24] Train loss=0.5635194778442383
[15/24] Train loss=0.5704282522201538
[20/24] Train loss=0.4720894694328308
Test set avg_accuracy=88.32% avg_sensitivity=74.73%, avg_specificity=92.74% avg_auc=0.9281
Best model saved!! Metric=0.9281444007800973!!
Fold[10] Epoch: 26 [26/150 (17%)] Train loss=0.552944 Test loss=0.307202 Current lr=[0.0006369058373012762]

[0/24] Train loss=0.5333037376403809
[5/24] Train loss=0.512813150882721
[10/24] Train loss=0.5513456463813782
[15/24] Train loss=0.5722958445549011
[20/24] Train loss=0.4615330696105957
Test set avg_accuracy=84.96% avg_sensitivity=86.25%, avg_specificity=84.54% avg_auc=0.9249
Fold[10] Epoch: 27 [27/150 (18%)] Train loss=0.544010 Test loss=0.401102 Current lr=[0.000669125424222739]

[0/24] Train loss=0.49880069494247437
[5/24] Train loss=0.5009503960609436
[10/24] Train loss=0.5387590527534485
[15/24] Train loss=0.5956646203994751
[20/24] Train loss=0.4879961907863617
Test set avg_accuracy=87.85% avg_sensitivity=78.03%, avg_specificity=91.05% avg_auc=0.9271
Fold[10] Epoch: 28 [28/150 (19%)] Train loss=0.537814 Test loss=0.325744 Current lr=[0.0007006171403297933]

[0/24] Train loss=0.5277925133705139
[5/24] Train loss=0.4654519259929657
[10/24] Train loss=0.5373110771179199
[15/24] Train loss=0.6266030669212341
[20/24] Train loss=0.4827415645122528
Test set avg_accuracy=85.43% avg_sensitivity=83.92%, avg_specificity=85.92% avg_auc=0.9254
Fold[10] Epoch: 29 [29/150 (19%)] Train loss=0.538708 Test loss=0.358914 Current lr=[0.0007312272767483865]

[0/24] Train loss=0.46871569752693176
[5/24] Train loss=0.48471593856811523
[10/24] Train loss=0.5374587178230286
[15/24] Train loss=0.5405197143554688
[20/24] Train loss=0.45282959938049316
Test set avg_accuracy=83.24% avg_sensitivity=86.94%, avg_specificity=82.04% avg_auc=0.9300
Best model saved!! Metric=0.9299554455155397!!
Fold[10] Epoch: 30 [30/150 (20%)] Train loss=0.511940 Test loss=0.421246 Current lr=[0.0007608064275335541]

[0/24] Train loss=0.4884576201438904
[5/24] Train loss=0.48929154872894287
[10/24] Train loss=0.49395129084587097
[15/24] Train loss=0.5175727605819702
[20/24] Train loss=0.44072574377059937
Test set avg_accuracy=85.85% avg_sensitivity=84.87%, avg_specificity=86.16% avg_auc=0.9283
Fold[10] Epoch: 31 [31/150 (21%)] Train loss=0.506762 Test loss=0.356101 Current lr=[0.0007892102189094385]

[0/24] Train loss=0.4862231910228729
[5/24] Train loss=0.47622784972190857
[10/24] Train loss=0.5090433359146118
[15/24] Train loss=0.48423030972480774
[20/24] Train loss=0.42663589119911194
Test set avg_accuracy=84.54% avg_sensitivity=84.18%, avg_specificity=84.66% avg_auc=0.9252
Fold[10] Epoch: 32 [32/150 (21%)] Train loss=0.490708 Test loss=0.372134 Current lr=[0.0008163000139476357]

[0/24] Train loss=0.4965134561061859
[5/24] Train loss=0.4411197602748871
[10/24] Train loss=0.4796804189682007
[15/24] Train loss=0.45900893211364746
[20/24] Train loss=0.43418213725090027
Test set avg_accuracy=76.16% avg_sensitivity=91.51%, avg_specificity=71.17% avg_auc=0.9281
Fold[10] Epoch: 33 [33/150 (22%)] Train loss=0.486384 Test loss=0.545504 Current lr=[0.0008419435892443951]

[0/24] Train loss=0.4861973524093628
[5/24] Train loss=0.475897878408432
[10/24] Train loss=0.4828435182571411
[15/24] Train loss=0.4852248728275299
[20/24] Train loss=0.46715256571769714
Test set avg_accuracy=84.54% avg_sensitivity=88.75%, avg_specificity=83.18% avg_auc=0.9312
Best model saved!! Metric=0.9312231127258128!!
Fold[10] Epoch: 34 [34/150 (23%)] Train loss=0.497395 Test loss=0.399968 Current lr=[0.0008660157802938455]

[0/24] Train loss=0.5126397609710693
[5/24] Train loss=0.4311623275279999
[10/24] Train loss=0.48782116174697876
[15/24] Train loss=0.48968181014060974
[20/24] Train loss=0.4232020080089569
Test set avg_accuracy=86.22% avg_sensitivity=82.59%, avg_specificity=87.41% avg_auc=0.9265
Fold[10] Epoch: 35 [35/150 (23%)] Train loss=0.487506 Test loss=0.357508 Current lr=[0.0008883990924072372]

[0/24] Train loss=0.4539410471916199
[5/24] Train loss=0.4272955060005188
[10/24] Train loss=0.44082143902778625
[15/24] Train loss=0.4370189905166626
[20/24] Train loss=0.3778873682022095
Test set avg_accuracy=82.30% avg_sensitivity=89.17%, avg_specificity=80.07% avg_auc=0.9268
Fold[10] Epoch: 36 [36/150 (24%)] Train loss=0.458109 Test loss=0.471039 Current lr=[0.0009089842741963373]

[0/24] Train loss=0.5201002955436707
[5/24] Train loss=0.44077378511428833
[10/24] Train loss=0.4586404263973236
[15/24] Train loss=0.5114275813102722
[20/24] Train loss=0.38109368085861206
Test set avg_accuracy=87.02% avg_sensitivity=81.63%, avg_specificity=88.77% avg_auc=0.9281
Fold[10] Epoch: 37 [37/150 (25%)] Train loss=0.472675 Test loss=0.345421 Current lr=[0.0009276708508218509]

[0/24] Train loss=0.45147955417633057
[5/24] Train loss=0.41721266508102417
[10/24] Train loss=0.44406312704086304
[15/24] Train loss=0.35277432203292847
[20/24] Train loss=0.3684035837650299
Test set avg_accuracy=86.15% avg_sensitivity=84.82%, avg_specificity=86.58% avg_auc=0.9273
Fold[10] Epoch: 38 [38/150 (25%)] Train loss=0.432117 Test loss=0.389639 Current lr=[0.000944367614404117]

[0/24] Train loss=0.4002407193183899
[5/24] Train loss=0.3518696129322052
[10/24] Train loss=0.4119224548339844
[15/24] Train loss=0.35854408144950867
[20/24] Train loss=0.35963118076324463
Test set avg_accuracy=84.83% avg_sensitivity=86.09%, avg_specificity=84.42% avg_auc=0.9201
Fold[10] Epoch: 39 [39/150 (26%)] Train loss=0.408775 Test loss=0.449955 Current lr=[0.0009589930692024195]

[0/24] Train loss=0.409451961517334
[5/24] Train loss=0.42317649722099304
[10/24] Train loss=0.4517594873905182
[15/24] Train loss=0.38427138328552246
[20/24] Train loss=0.35748589038848877
Test set avg_accuracy=85.98% avg_sensitivity=82.96%, avg_specificity=86.96% avg_auc=0.9206
Fold[10] Epoch: 40 [40/150 (27%)] Train loss=0.421693 Test loss=0.400046 Current lr=[0.0009714758293900248]

[0/24] Train loss=0.4101116955280304
[5/24] Train loss=0.3721435070037842
[10/24] Train loss=0.3768899440765381
[15/24] Train loss=0.36023199558258057
[20/24] Train loss=0.3136088252067566
Test set avg_accuracy=83.28% avg_sensitivity=86.31%, avg_specificity=82.30% avg_auc=0.9200
Fold[10] Epoch: 41 [41/150 (27%)] Train loss=0.384698 Test loss=0.504549 Current lr=[0.0009817549674834328]

[0/24] Train loss=0.3886982798576355
[5/24] Train loss=0.3613087236881256
[10/24] Train loss=0.37076833844184875
[15/24] Train loss=0.39081355929374695
[20/24] Train loss=0.3545878231525421
Test set avg_accuracy=86.35% avg_sensitivity=79.94%, avg_specificity=88.44% avg_auc=0.9158
Fold[10] Epoch: 42 [42/150 (28%)] Train loss=0.392546 Test loss=0.429916 Current lr=[0.000989780311725182]

[0/24] Train loss=0.3683941960334778
[5/24] Train loss=0.3752254247665405
[10/24] Train loss=0.3767772316932678
[15/24] Train loss=0.32593318819999695
[20/24] Train loss=0.3200478255748749
Test set avg_accuracy=84.91% avg_sensitivity=82.80%, avg_specificity=85.59% avg_auc=0.9199
Fold[10] Epoch: 43 [43/150 (29%)] Train loss=0.367421 Test loss=0.438004 Current lr=[0.0009955126909687044]

[0/24] Train loss=0.33655667304992676
[5/24] Train loss=0.3591347634792328
[10/24] Train loss=0.3694336414337158
[15/24] Train loss=0.354483425617218
[20/24] Train loss=0.31949272751808167
Test set avg_accuracy=81.60% avg_sensitivity=87.85%, avg_specificity=79.57% avg_auc=0.9223
Fold[10] Epoch: 44 [44/150 (29%)] Train loss=0.360005 Test loss=0.595801 Current lr=[0.000998924125869967]

[0/24] Train loss=0.31202977895736694
[5/24] Train loss=0.35760053992271423
[10/24] Train loss=0.38736093044281006
[15/24] Train loss=0.34291937947273254
[20/24] Train loss=0.3139156401157379
Test set avg_accuracy=84.51% avg_sensitivity=84.66%, avg_specificity=84.45% avg_auc=0.9190
Fold[10] Epoch: 45 [45/150 (30%)] Train loss=0.357164 Test loss=0.499037 Current lr=[0.000999999611458977]

[0/24] Train loss=0.35205066204071045
[5/24] Train loss=0.361003577709198
[10/24] Train loss=0.366330623626709
[15/24] Train loss=0.30065327882766724
[20/24] Train loss=0.28799402713775635
Test set avg_accuracy=84.23% avg_sensitivity=85.46%, avg_specificity=83.83% avg_auc=0.9236
Fold[10] Epoch: 46 [46/150 (31%)] Train loss=0.357452 Test loss=0.496661 Current lr=[0.0009997571814855416]

[0/24] Train loss=0.36483097076416016
[5/24] Train loss=0.3437695801258087
[10/24] Train loss=0.3737381398677826
[15/24] Train loss=0.2921122610569
[20/24] Train loss=0.320823609828949
Test set avg_accuracy=86.43% avg_sensitivity=80.52%, avg_specificity=88.35% avg_auc=0.9201
Fold[10] Epoch: 47 [47/150 (31%)] Train loss=0.369164 Test loss=0.416590 Current lr=[0.0009990674029413367]

[0/24] Train loss=0.36023426055908203
[5/24] Train loss=0.33586713671684265
[10/24] Train loss=0.3472732603549957
[15/24] Train loss=0.2790062129497528
[20/24] Train loss=0.305357962846756
Test set avg_accuracy=83.63% avg_sensitivity=85.51%, avg_specificity=83.02% avg_auc=0.9202
Fold[10] Epoch: 48 [48/150 (32%)] Train loss=0.330637 Test loss=0.453542 Current lr=[0.0009979308932715778]

[0/24] Train loss=0.33416667580604553
[5/24] Train loss=0.31487199664115906
[10/24] Train loss=0.3115515410900116
[15/24] Train loss=0.28348979353904724
[20/24] Train loss=0.29956474900245667
Test set avg_accuracy=85.69% avg_sensitivity=81.05%, avg_specificity=87.20% avg_auc=0.9189
Fold[10] Epoch: 49 [49/150 (33%)] Train loss=0.324665 Test loss=0.411798 Current lr=[0.0009963486698063401]

[0/24] Train loss=0.3636346459388733
[5/24] Train loss=0.3293405771255493
[10/24] Train loss=0.33480149507522583
[15/24] Train loss=0.2826358675956726
[20/24] Train loss=0.2818552851676941
Test set avg_accuracy=85.94% avg_sensitivity=81.48%, avg_specificity=87.39% avg_auc=0.9173
Fold[10] Epoch: 50 [50/150 (33%)] Train loss=0.319355 Test loss=0.429037 Current lr=[0.0009943221488499109]

[0/24] Train loss=0.3044041693210602
[5/24] Train loss=0.25860780477523804
[10/24] Train loss=0.31870514154434204
[15/24] Train loss=0.24608266353607178
[20/24] Train loss=0.272299200296402
Test set avg_accuracy=85.38% avg_sensitivity=83.39%, avg_specificity=86.02% avg_auc=0.9168
Fold[10] Epoch: 51 [51/150 (34%)] Train loss=0.294565 Test loss=0.480821 Current lr=[0.0009918531444130035]

[0/24] Train loss=0.261898398399353
[5/24] Train loss=0.24897606670856476
[10/24] Train loss=0.2836177349090576
[15/24] Train loss=0.25154948234558105
[20/24] Train loss=0.2482546865940094
Test set avg_accuracy=81.32% avg_sensitivity=87.05%, avg_specificity=79.45% avg_auc=0.9097
Fold[10] Epoch: 52 [52/150 (35%)] Train loss=0.278466 Test loss=0.606129 Current lr=[0.0009889438665889737]

[0/24] Train loss=0.33081376552581787
[5/24] Train loss=0.2575739026069641
[10/24] Train loss=0.3331688642501831
[15/24] Train loss=0.23661163449287415
[20/24] Train loss=0.2783600687980652
Test set avg_accuracy=82.68% avg_sensitivity=87.21%, avg_specificity=81.21% avg_auc=0.9125
Fold[10] Epoch: 53 [53/150 (35%)] Train loss=0.294548 Test loss=0.559389 Current lr=[0.0009855969195754861]

[0/24] Train loss=0.3216872811317444
[5/24] Train loss=0.23979361355304718
[10/24] Train loss=0.26768895983695984
[15/24] Train loss=0.29884323477745056
[20/24] Train loss=0.2605832815170288
Test set avg_accuracy=83.66% avg_sensitivity=86.09%, avg_specificity=82.87% avg_auc=0.9159
Fold[10] Epoch: 54 [54/150 (36%)] Train loss=0.274942 Test loss=0.623089 Current lr=[0.0009818152993434051]

[0/24] Train loss=0.3059757649898529
[5/24] Train loss=0.23987415432929993
[10/24] Train loss=0.3095676004886627
[15/24] Train loss=0.2639908790588379
[20/24] Train loss=0.20682485401630402
Test set avg_accuracy=84.58% avg_sensitivity=83.28%, avg_specificity=85.01% avg_auc=0.9161
Fold[10] Epoch: 55 [55/150 (37%)] Train loss=0.268033 Test loss=0.543672 Current lr=[0.0009776023909549944]

[0/24] Train loss=0.23155856132507324
[5/24] Train loss=0.19872023165225983
[10/24] Train loss=0.2798493802547455
[15/24] Train loss=0.2176121473312378
[20/24] Train loss=0.20968113839626312
Test set avg_accuracy=87.06% avg_sensitivity=80.25%, avg_specificity=89.27% avg_auc=0.9120
Fold[10] Epoch: 56 [56/150 (37%)] Train loss=0.242801 Test loss=0.545917 Current lr=[0.0009729619655338284]

[0/24] Train loss=0.22233210504055023
[5/24] Train loss=0.20821794867515564
[10/24] Train loss=0.246977299451828
[15/24] Train loss=0.1969633549451828
[20/24] Train loss=0.17498360574245453
Test set avg_accuracy=85.68% avg_sensitivity=80.89%, avg_specificity=87.23% avg_auc=0.9175
Fold[10] Epoch: 57 [57/150 (38%)] Train loss=0.224741 Test loss=0.652278 Current lr=[0.0009678981768891258]

[0/24] Train loss=0.23973539471626282
[5/24] Train loss=0.18543066084384918
[10/24] Train loss=0.25938236713409424
[15/24] Train loss=0.1674991101026535
[20/24] Train loss=0.15815122425556183
Test set avg_accuracy=86.18% avg_sensitivity=82.91%, avg_specificity=87.25% avg_auc=0.9205
Fold[10] Epoch: 58 [58/150 (39%)] Train loss=0.208117 Test loss=0.786746 Current lr=[0.0009624155577975278]

[0/24] Train loss=0.1725345104932785
[5/24] Train loss=0.21386505663394928
[10/24] Train loss=0.18477384746074677
[15/24] Train loss=0.18505476415157318
[20/24] Train loss=0.1712007075548172
Test set avg_accuracy=83.80% avg_sensitivity=85.08%, avg_specificity=83.39% avg_auc=0.9173
Fold[10] Epoch: 59 [59/150 (39%)] Train loss=0.198231 Test loss=0.937467 Current lr=[0.0009565190159456486]

[0/24] Train loss=0.19547545909881592
[5/24] Train loss=0.1881261169910431
[10/24] Train loss=0.19753120839595795
[15/24] Train loss=0.16752846539020538
[20/24] Train loss=0.1625923216342926
Test set avg_accuracy=85.49% avg_sensitivity=86.31%, avg_specificity=85.23% avg_auc=0.9190
Fold[10] Epoch: 60 [60/150 (40%)] Train loss=0.191959 Test loss=0.995205 Current lr=[0.0009502138295370322]

[0/24] Train loss=0.22342926263809204
[5/24] Train loss=0.15569522976875305
[10/24] Train loss=0.2140994369983673
[15/24] Train loss=0.199161097407341
[20/24] Train loss=0.13376384973526
Test set avg_accuracy=85.35% avg_sensitivity=83.23%, avg_specificity=86.04% avg_auc=0.9185
Fold[10] Epoch: 61 [61/150 (41%)] Train loss=0.186088 Test loss=0.714869 Current lr=[0.0009435056425674443]

[0/24] Train loss=0.15859173238277435
[5/24] Train loss=0.13788126409053802
[10/24] Train loss=0.1639556884765625
[15/24] Train loss=0.1597120612859726
[20/24] Train loss=0.13876543939113617
Test set avg_accuracy=85.94% avg_sensitivity=84.02%, avg_specificity=86.56% avg_auc=0.9197
Fold[10] Epoch: 62 [62/150 (41%)] Train loss=0.157301 Test loss=0.853269 Current lr=[0.0009364004597727329]

[0/24] Train loss=0.1533815711736679
[5/24] Train loss=0.11646891385316849
[10/24] Train loss=0.17545892298221588
[15/24] Train loss=0.14570078253746033
[20/24] Train loss=0.15222065150737762
Test set avg_accuracy=83.74% avg_sensitivity=88.32%, avg_specificity=82.25% avg_auc=0.9214
Fold[10] Epoch: 63 [63/150 (42%)] Train loss=0.148395 Test loss=1.012063 Current lr=[0.0009289046412537752]

[0/24] Train loss=0.15413108468055725
[5/24] Train loss=0.12187515199184418
[10/24] Train loss=0.15187598764896393
[15/24] Train loss=0.140305757522583
[20/24] Train loss=0.1654617190361023
Test set avg_accuracy=85.22% avg_sensitivity=86.25%, avg_specificity=84.89% avg_auc=0.9221
Fold[10] Epoch: 64 [64/150 (43%)] Train loss=0.150548 Test loss=0.868350 Current lr=[0.0009210248967833267]

[0/24] Train loss=0.16864338517189026
[5/24] Train loss=0.12093006819486618
[10/24] Train loss=0.15016241371631622
[15/24] Train loss=0.16847223043441772
[20/24] Train loss=0.12683075666427612
Test set avg_accuracy=85.83% avg_sensitivity=85.19%, avg_specificity=86.04% avg_auc=0.9213
Fold[10] Epoch: 65 [65/150 (43%)] Train loss=0.158204 Test loss=0.901090 Current lr=[0.0009127682797998662]

[0/24] Train loss=0.15944774448871613
[5/24] Train loss=0.1400570273399353
[10/24] Train loss=0.1567825824022293
[15/24] Train loss=0.15337054431438446
[20/24] Train loss=0.10963424295186996
Test set avg_accuracy=86.18% avg_sensitivity=84.18%, avg_specificity=86.84% avg_auc=0.9209
Fold[10] Epoch: 66 [66/150 (44%)] Train loss=0.142735 Test loss=0.796539 Current lr=[0.000904142181093812]

[0/24] Train loss=0.11856305599212646
[5/24] Train loss=0.12408916652202606
[10/24] Train loss=0.1423749476671219
[15/24] Train loss=0.12845729291439056
[20/24] Train loss=0.10554184019565582
Test set avg_accuracy=87.38% avg_sensitivity=81.00%, avg_specificity=89.46% avg_auc=0.9180
Fold[10] Epoch: 67 [67/150 (45%)] Train loss=0.139669 Test loss=0.730356 Current lr=[0.0008951543221917643]

[0/24] Train loss=0.17844490706920624
[5/24] Train loss=0.11092968285083771
[10/24] Train loss=0.10790427774190903
[15/24] Train loss=0.12797893583774567
[20/24] Train loss=0.0979175716638565
Test set avg_accuracy=85.74% avg_sensitivity=81.05%, avg_specificity=87.27% avg_auc=0.9139
Fold[10] Epoch: 68 [68/150 (45%)] Train loss=0.128516 Test loss=0.893384 Current lr=[0.0008858127484446932]

[0/24] Train loss=0.10720478743314743
[5/24] Train loss=0.12025666981935501
[10/24] Train loss=0.10551165789365768
[15/24] Train loss=0.1066385805606842
[20/24] Train loss=0.1289970576763153
Test set avg_accuracy=84.35% avg_sensitivity=87.10%, avg_specificity=83.45% avg_auc=0.9181
Fold[10] Epoch: 69 [69/150 (46%)] Train loss=0.122606 Test loss=0.794577 Current lr=[0.0008761258218262597]

[0/24] Train loss=0.11796263605356216
[5/24] Train loss=0.11205456405878067
[10/24] Train loss=0.131720632314682
[15/24] Train loss=0.11344951391220093
[20/24] Train loss=0.11586175858974457
Test set avg_accuracy=85.66% avg_sensitivity=85.03%, avg_specificity=85.87% avg_auc=0.9185
Fold[10] Epoch: 70 [70/150 (47%)] Train loss=0.122986 Test loss=0.819741 Current lr=[0.0008661022134477164]

[0/24] Train loss=0.09439849108457565
[5/24] Train loss=0.10361571609973907
[10/24] Train loss=0.10401373356580734
[15/24] Train loss=0.1034652441740036
[20/24] Train loss=0.09814992547035217
Test set avg_accuracy=85.70% avg_sensitivity=84.61%, avg_specificity=86.06% avg_auc=0.9208
Fold[10] Epoch: 71 [71/150 (47%)] Train loss=0.105212 Test loss=0.868856 Current lr=[0.0008557508957960898]

[0/24] Train loss=0.08819200843572617
[5/24] Train loss=0.08233688771724701
[10/24] Train loss=0.10212880373001099
[15/24] Train loss=0.12047221511602402
[20/24] Train loss=0.080022893846035
Test set avg_accuracy=83.19% avg_sensitivity=87.42%, avg_specificity=81.82% avg_auc=0.9188
Fold[10] Epoch: 72 [72/150 (48%)] Train loss=0.098740 Test loss=1.121253 Current lr=[0.0008450811347025879]

[0/24] Train loss=0.09529203921556473
[5/24] Train loss=0.09649063646793365
[10/24] Train loss=0.11805963516235352
[15/24] Train loss=0.09243413805961609
[20/24] Train loss=0.07811152189970016
Test set avg_accuracy=85.29% avg_sensitivity=85.83%, avg_specificity=85.11% avg_auc=0.9198
Fold[10] Epoch: 73 [73/150 (49%)] Train loss=0.097915 Test loss=0.961008 Current lr=[0.000834102481048427]

[0/24] Train loss=0.0916215181350708
[5/24] Train loss=0.0880110040307045
[10/24] Train loss=0.1120699793100357
[15/24] Train loss=0.10286630690097809
[20/24] Train loss=0.08649922162294388
Test set avg_accuracy=87.03% avg_sensitivity=82.64%, avg_specificity=88.46% avg_auc=0.9189
Fold[10] Epoch: 74 [74/150 (49%)] Train loss=0.108984 Test loss=0.862750 Current lr=[0.0008228247622154996]

[0/24] Train loss=0.0743020623922348
[5/24] Train loss=0.06761085987091064
[10/24] Train loss=0.10041216015815735
[15/24] Train loss=0.09234952926635742
[20/24] Train loss=0.10741976648569107
Test set avg_accuracy=85.95% avg_sensitivity=85.72%, avg_specificity=86.02% avg_auc=0.9213
Fold[10] Epoch: 75 [75/150 (50%)] Train loss=0.097560 Test loss=0.977951 Current lr=[0.0008112580732895365]

[0/24] Train loss=0.06743083149194717
[5/24] Train loss=0.0821644589304924
[10/24] Train loss=0.08628419786691666
[15/24] Train loss=0.0815657377243042
[20/24] Train loss=0.08601067215204239
Test set avg_accuracy=85.57% avg_sensitivity=85.77%, avg_specificity=85.51% avg_auc=0.9171
Fold[10] Epoch: 76 [76/150 (51%)] Train loss=0.085433 Test loss=0.996896 Current lr=[0.0007994127680236374]

[0/24] Train loss=0.07535039633512497
[5/24] Train loss=0.06817654520273209
[10/24] Train loss=0.08893874287605286
[15/24] Train loss=0.07800658792257309
[20/24] Train loss=0.06573653221130371
Test set avg_accuracy=85.81% avg_sensitivity=84.39%, avg_specificity=86.27% avg_auc=0.9193
Fold[10] Epoch: 77 [77/150 (51%)] Train loss=0.084423 Test loss=1.045659 Current lr=[0.0007872994495702606]

[0/24] Train loss=0.08630756288766861
[5/24] Train loss=0.10670425742864609
[10/24] Train loss=0.09813657402992249
[15/24] Train loss=0.08173127472400665
[20/24] Train loss=0.09348565340042114
Test set avg_accuracy=82.99% avg_sensitivity=88.00%, avg_specificity=81.37% avg_auc=0.9190
Fold[10] Epoch: 78 [78/150 (52%)] Train loss=0.087300 Test loss=1.173563 Current lr=[0.0007749289609899649]

[0/24] Train loss=0.08981665223836899
[5/24] Train loss=0.07126984745264053
[10/24] Train loss=0.1341898888349533
[15/24] Train loss=0.08009025454521179
[20/24] Train loss=0.08143596351146698
Test set avg_accuracy=86.54% avg_sensitivity=85.88%, avg_specificity=86.75% avg_auc=0.9240
Fold[10] Epoch: 79 [79/150 (53%)] Train loss=0.089901 Test loss=0.955544 Current lr=[0.0007623123755454019]

[0/24] Train loss=0.09245694428682327
[5/24] Train loss=0.0759832113981247
[10/24] Train loss=0.08500637114048004
[15/24] Train loss=0.0764809176325798
[20/24] Train loss=0.06908287853002548
Test set avg_accuracy=83.65% avg_sensitivity=86.78%, avg_specificity=82.63% avg_auc=0.9202
Fold[10] Epoch: 80 [80/150 (53%)] Train loss=0.083738 Test loss=1.088702 Current lr=[0.0007494609867892465]

[0/24] Train loss=0.09693703055381775
[5/24] Train loss=0.06614357978105545
[10/24] Train loss=0.07609910517930984
[15/24] Train loss=0.08471257239580154
[20/24] Train loss=0.09858417510986328
Test set avg_accuracy=84.91% avg_sensitivity=85.56%, avg_specificity=84.70% avg_auc=0.9176
Fold[10] Epoch: 81 [81/150 (54%)] Train loss=0.087642 Test loss=1.143245 Current lr=[0.0007363862984549375]

[0/24] Train loss=0.07302165776491165
[5/24] Train loss=0.09521627426147461
[10/24] Train loss=0.09380213916301727
[15/24] Train loss=0.10927534103393555
[20/24] Train loss=0.09288465231657028
Test set avg_accuracy=85.74% avg_sensitivity=84.50%, avg_specificity=86.15% avg_auc=0.9208
Fold[10] Epoch: 82 [82/150 (55%)] Train loss=0.097431 Test loss=0.974457 Current lr=[0.0007231000141592781]

[0/24] Train loss=0.0630398839712143
[5/24] Train loss=0.06237015873193741
[10/24] Train loss=0.0777713730931282
[15/24] Train loss=0.07433417439460754
[20/24] Train loss=0.06561559438705444
Test set avg_accuracy=85.64% avg_sensitivity=84.71%, avg_specificity=85.94% avg_auc=0.9204
Fold[10] Epoch: 83 [83/150 (55%)] Train loss=0.077757 Test loss=0.952509 Current lr=[0.0007096140269261143]

[0/24] Train loss=0.05524763464927673
[5/24] Train loss=0.05249470844864845
[10/24] Train loss=0.06742695719003677
[15/24] Train loss=0.07202134281396866
[20/24] Train loss=0.05545061081647873
Test set avg_accuracy=85.46% avg_sensitivity=85.83%, avg_specificity=85.33% avg_auc=0.9213
Fold[10] Epoch: 84 [84/150 (56%)] Train loss=0.066038 Test loss=1.124981 Current lr=[0.0006959404085404675]

[0/24] Train loss=0.06841170787811279
[5/24] Train loss=0.05419149249792099
[10/24] Train loss=0.05078432708978653
[15/24] Train loss=0.06158549711108208
[20/24] Train loss=0.05080396309494972
Test set avg_accuracy=85.90% avg_sensitivity=84.61%, avg_specificity=86.32% avg_auc=0.9225
Fold[10] Epoch: 85 [85/150 (57%)] Train loss=0.067342 Test loss=0.911933 Current lr=[0.0006820913987426519]

[0/24] Train loss=0.0722278505563736
[5/24] Train loss=0.05274619534611702
[10/24] Train loss=0.06954057514667511
[15/24] Train loss=0.054281219840049744
[20/24] Train loss=0.06393062323331833
Test set avg_accuracy=83.98% avg_sensitivity=86.73%, avg_specificity=83.09% avg_auc=0.9197
Fold[10] Epoch: 86 [86/150 (57%)] Train loss=0.068927 Test loss=1.159723 Current lr=[0.0006680793942720491]

[0/24] Train loss=0.06106945499777794
[5/24] Train loss=0.05809837952256203
[10/24] Train loss=0.08547569066286087
[15/24] Train loss=0.0531434565782547
[20/24] Train loss=0.06231527775526047
Test set avg_accuracy=86.88% avg_sensitivity=84.02%, avg_specificity=87.80% avg_auc=0.9204
Fold[10] Epoch: 87 [87/150 (58%)] Train loss=0.070636 Test loss=1.058588 Current lr=[0.0006539169377703482]

[0/24] Train loss=0.04888438805937767
[5/24] Train loss=0.041245464235544205
[10/24] Train loss=0.0722074955701828
[15/24] Train loss=0.052515219897031784
[20/24] Train loss=0.044891685247421265
Test set avg_accuracy=86.29% avg_sensitivity=84.82%, avg_specificity=86.77% avg_auc=0.9219
Fold[10] Epoch: 88 [88/150 (59%)] Train loss=0.060901 Test loss=1.030915 Current lr=[0.0006396167065541822]

[0/24] Train loss=0.044545602053403854
[5/24] Train loss=0.055509645491838455
[10/24] Train loss=0.04902705177664757
[15/24] Train loss=0.04192955791950226
[20/24] Train loss=0.060714755207300186
Test set avg_accuracy=84.27% avg_sensitivity=86.46%, avg_specificity=83.56% avg_auc=0.9200
Fold[10] Epoch: 89 [89/150 (59%)] Train loss=0.054380 Test loss=1.169523 Current lr=[0.0006251915012672126]

[0/24] Train loss=0.06059796363115311
[5/24] Train loss=0.03751344233751297
[10/24] Train loss=0.0647306740283966
[15/24] Train loss=0.06848548352718353
[20/24] Train loss=0.053947534412145615
Test set avg_accuracy=85.18% avg_sensitivity=86.46%, avg_specificity=84.77% avg_auc=0.9200
Fold[10] Epoch: 90 [90/150 (60%)] Train loss=0.063348 Test loss=1.198975 Current lr=[0.00061065423442182]

[0/24] Train loss=0.05305127054452896
[5/24] Train loss=0.05557236820459366
[10/24] Train loss=0.06508544832468033
[15/24] Train loss=0.06007945165038109
[20/24] Train loss=0.05276081711053848
Test set avg_accuracy=85.14% avg_sensitivity=86.20%, avg_specificity=84.80% avg_auc=0.9188
Fold[10] Epoch: 91 [91/150 (61%)] Train loss=0.066486 Test loss=1.097548 Current lr=[0.0005960179188406565]

[0/24] Train loss=0.06107635051012039
[5/24] Train loss=0.04439270868897438
[10/24] Train loss=0.04826569929718971
[15/24] Train loss=0.05371953919529915
[20/24] Train loss=0.06020059809088707
Test set avg_accuracy=85.64% avg_sensitivity=85.03%, avg_specificity=85.84% avg_auc=0.9213
Fold[10] Epoch: 92 [92/150 (61%)] Train loss=0.061768 Test loss=1.140179 Current lr=[0.0005812956560084071]

[0/24] Train loss=0.049583230167627335
[5/24] Train loss=0.04045608267188072
[10/24] Train loss=0.043893616646528244
[15/24] Train loss=0.05195651203393936
[20/24] Train loss=0.050261229276657104
Test set avg_accuracy=84.91% avg_sensitivity=85.72%, avg_specificity=84.64% avg_auc=0.9235
Fold[10] Epoch: 93 [93/150 (62%)] Train loss=0.052855 Test loss=1.171844 Current lr=[0.0005665006243441873]

[0/24] Train loss=0.043965503573417664
[5/24] Train loss=0.04277176409959793
[10/24] Train loss=0.06188870221376419
[15/24] Train loss=0.05439922213554382
[20/24] Train loss=0.0475277453660965
Test set avg_accuracy=85.26% avg_sensitivity=86.15%, avg_specificity=84.97% avg_auc=0.9230
Fold[10] Epoch: 94 [94/150 (63%)] Train loss=0.057988 Test loss=1.185365 Current lr=[0.0005516460674050716]

[0/24] Train loss=0.05168900638818741
[5/24] Train loss=0.050097208470106125
[10/24] Train loss=0.06552537530660629
[15/24] Train loss=0.04877834394574165
[20/24] Train loss=0.04412524029612541
Test set avg_accuracy=86.00% avg_sensitivity=85.24%, avg_specificity=86.25% avg_auc=0.9234
Fold[10] Epoch: 95 [95/150 (63%)] Train loss=0.054776 Test loss=1.083184 Current lr=[0.0005367452820313177]

[0/24] Train loss=0.03855481743812561
[5/24] Train loss=0.037326160818338394
[10/24] Train loss=0.042457982897758484
[15/24] Train loss=0.0451626181602478
[20/24] Train loss=0.04752824455499649
Test set avg_accuracy=86.30% avg_sensitivity=84.50%, avg_specificity=86.89% avg_auc=0.9232
Fold[10] Epoch: 96 [96/150 (64%)] Train loss=0.046895 Test loss=1.191195 Current lr=[0.0005218116064438932]

[0/24] Train loss=0.030911685898900032
[5/24] Train loss=0.03366361930966377
[10/24] Train loss=0.04232187941670418
[15/24] Train loss=0.04977409914135933
[20/24] Train loss=0.034396976232528687
Test set avg_accuracy=86.65% avg_sensitivity=84.82%, avg_specificity=87.25% avg_auc=0.9241
Fold[10] Epoch: 97 [97/150 (65%)] Train loss=0.041267 Test loss=1.182395 Current lr=[0.000506858408304961]

[0/24] Train loss=0.03897520899772644
[5/24] Train loss=0.04704538360238075
[10/24] Train loss=0.04091423749923706
[15/24] Train loss=0.03213048726320267
[20/24] Train loss=0.03636806085705757
Test set avg_accuracy=85.82% avg_sensitivity=85.77%, avg_specificity=85.84% avg_auc=0.9227
Fold[10] Epoch: 98 [98/150 (65%)] Train loss=0.039780 Test loss=1.296471 Current lr=[0.0004918990727520122]

[0/24] Train loss=0.032527193427085876
[5/24] Train loss=0.0309169739484787
[10/24] Train loss=0.03696602210402489
[15/24] Train loss=0.03699932247400284
[20/24] Train loss=0.030686553567647934
Test set avg_accuracy=84.93% avg_sensitivity=86.57%, avg_specificity=84.40% avg_auc=0.9222
Fold[10] Epoch: 99 [99/150 (66%)] Train loss=0.037377 Test loss=1.550717 Current lr=[0.000476946990416354]

[0/24] Train loss=0.036977432668209076
[5/24] Train loss=0.033342793583869934
[10/24] Train loss=0.039370354264974594
[15/24] Train loss=0.044378578662872314
[20/24] Train loss=0.030037395656108856
Test set avg_accuracy=85.33% avg_sensitivity=86.20%, avg_specificity=85.04% avg_auc=0.9228
Fold[10] Epoch: 100 [100/150 (67%)] Train loss=0.038440 Test loss=1.320432 Current lr=[0.00046201554543668185]

[0/24] Train loss=0.03786018118262291
[5/24] Train loss=0.03314974904060364
[10/24] Train loss=0.03658083453774452
[15/24] Train loss=0.05571291595697403
[20/24] Train loss=0.03461911156773567
Test set avg_accuracy=85.87% avg_sensitivity=84.98%, avg_specificity=86.16% avg_auc=0.9230
Fold[10] Epoch: 101 [101/150 (67%)] Train loss=0.039757 Test loss=1.139633 Current lr=[0.00044711810347846336]

[0/24] Train loss=0.037875477224588394
[5/24] Train loss=0.040883004665374756
[10/24] Train loss=0.03575904667377472
[15/24] Train loss=0.03524899482727051
[20/24] Train loss=0.028946038335561752
Test set avg_accuracy=86.12% avg_sensitivity=84.45%, avg_specificity=86.66% avg_auc=0.9238
Fold[10] Epoch: 102 [102/150 (68%)] Train loss=0.036847 Test loss=1.334616 Current lr=[0.000432267999769856]

[0/24] Train loss=0.025964774191379547
[5/24] Train loss=0.02313176356256008
[10/24] Train loss=0.030969642102718353
[15/24] Train loss=0.04610706865787506
[20/24] Train loss=0.04895194619894028
Test set avg_accuracy=85.74% avg_sensitivity=86.04%, avg_specificity=85.65% avg_auc=0.9234
Fold[10] Epoch: 103 [103/150 (69%)] Train loss=0.034341 Test loss=1.394895 Current lr=[0.0004174785271648729]

[0/24] Train loss=0.03829581290483475
[5/24] Train loss=0.02147888019680977
[10/24] Train loss=0.03354913741350174
[15/24] Train loss=0.042720310389995575
[20/24] Train loss=0.029774075374007225
Test set avg_accuracy=86.39% avg_sensitivity=85.14%, avg_specificity=86.80% avg_auc=0.9236
Fold[10] Epoch: 104 [104/150 (69%)] Train loss=0.033735 Test loss=1.357834 Current lr=[0.00040276292424447835]

[0/24] Train loss=0.023907488211989403
[5/24] Train loss=0.022310469299554825
[10/24] Train loss=0.02831842191517353
[15/24] Train loss=0.038215044885873795
[20/24] Train loss=0.05029384419322014
Test set avg_accuracy=85.78% avg_sensitivity=85.30%, avg_specificity=85.94% avg_auc=0.9235
Fold[10] Epoch: 105 [105/150 (70%)] Train loss=0.032317 Test loss=1.376291 Current lr=[0.000388134363466264]

[0/24] Train loss=0.024498693645000458
[5/24] Train loss=0.024913422763347626
[10/24] Train loss=0.024248642846941948
[15/24] Train loss=0.0533873550593853
[20/24] Train loss=0.026131728664040565
Test set avg_accuracy=84.79% avg_sensitivity=85.51%, avg_specificity=84.56% avg_auc=0.9223
Fold[10] Epoch: 106 [106/150 (71%)] Train loss=0.030446 Test loss=1.540587 Current lr=[0.00037360593937331606]

[0/24] Train loss=0.027472877874970436
[5/24] Train loss=0.024136004969477654
[10/24] Train loss=0.027950407937169075
[15/24] Train loss=0.028528248891234398
[20/24] Train loss=0.03871921822428703
Test set avg_accuracy=85.31% avg_sensitivity=85.14%, avg_specificity=85.37% avg_auc=0.9220
Fold[10] Epoch: 107 [107/150 (71%)] Train loss=0.033255 Test loss=1.443520 Current lr=[0.00035919065687282605]

[0/24] Train loss=0.028727002441883087
[5/24] Train loss=0.02784566953778267
[10/24] Train loss=0.035498738288879395
[15/24] Train loss=0.02985520474612713
[20/24] Train loss=0.0238188486546278
Test set avg_accuracy=85.12% avg_sensitivity=85.62%, avg_specificity=84.96% avg_auc=0.9222
Fold[10] Epoch: 108 [108/150 (72%)] Train loss=0.029837 Test loss=1.639605 Current lr=[0.0003449014195949366]

[0/24] Train loss=0.02747490629553795
[5/24] Train loss=0.03461615741252899
[10/24] Train loss=0.02973329648375511
[15/24] Train loss=0.04395301640033722
[20/24] Train loss=0.026515468955039978
Test set avg_accuracy=85.13% avg_sensitivity=85.24%, avg_specificity=85.09% avg_auc=0.9209
Fold[10] Epoch: 109 [109/150 (73%)] Train loss=0.033697 Test loss=1.405781 Current lr=[0.00033075101834224526]

[0/24] Train loss=0.030675528571009636
[5/24] Train loss=0.03266352415084839
[10/24] Train loss=0.03637539595365524
[15/24] Train loss=0.03880845755338669
[20/24] Train loss=0.024545112624764442
Test set avg_accuracy=86.11% avg_sensitivity=84.50%, avg_specificity=86.63% avg_auc=0.9230
Fold[10] Epoch: 110 [110/150 (73%)] Train loss=0.034303 Test loss=1.434299 Current lr=[0.00031675211964030483]

[0/24] Train loss=0.02480136789381504
[5/24] Train loss=0.019070735201239586
[10/24] Train loss=0.022690996527671814
[15/24] Train loss=0.02892908826470375
[20/24] Train loss=0.02182980254292488
Test set avg_accuracy=86.02% avg_sensitivity=85.03%, avg_specificity=86.34% avg_auc=0.9226
Fold[10] Epoch: 111 [111/150 (74%)] Train loss=0.027901 Test loss=1.461516 Current lr=[0.00030291725439936614]

[0/24] Train loss=0.022595278918743134
[5/24] Train loss=0.015912342816591263
[10/24] Train loss=0.026436544954776764
[15/24] Train loss=0.02693370170891285
[20/24] Train loss=0.02070227637887001
Test set avg_accuracy=85.36% avg_sensitivity=85.88%, avg_specificity=85.20% avg_auc=0.9215
Fold[10] Epoch: 112 [112/150 (75%)] Train loss=0.025173 Test loss=1.617802 Current lr=[0.0002892588066975171]

[0/24] Train loss=0.01943310908973217
[5/24] Train loss=0.024790054187178612
[10/24] Train loss=0.026994552463293076
[15/24] Train loss=0.020947888493537903
[20/24] Train loss=0.02373979613184929
Test set avg_accuracy=85.36% avg_sensitivity=85.67%, avg_specificity=85.27% avg_auc=0.9210
Fold[10] Epoch: 113 [113/150 (75%)] Train loss=0.030000 Test loss=1.450868 Current lr=[0.00027578900269525507]

[0/24] Train loss=0.0294062327593565
[5/24] Train loss=0.021641679108142853
[10/24] Train loss=0.035806428641080856
[15/24] Train loss=0.0312962643802166
[20/24] Train loss=0.022713376209139824
Test set avg_accuracy=86.51% avg_sensitivity=84.71%, avg_specificity=87.09% avg_auc=0.9228
Fold[10] Epoch: 114 [114/150 (76%)] Train loss=0.031626 Test loss=1.418693 Current lr=[0.00026251989969141833]

[0/24] Train loss=0.02638143114745617
[5/24] Train loss=0.01693115383386612
[10/24] Train loss=0.040931425988674164
[15/24] Train loss=0.02628958411514759
[20/24] Train loss=0.030757591128349304
Test set avg_accuracy=85.79% avg_sensitivity=85.62%, avg_specificity=85.85% avg_auc=0.9225
Fold[10] Epoch: 115 [115/150 (77%)] Train loss=0.029434 Test loss=1.527749 Current lr=[0.0002494633753302695]

[0/24] Train loss=0.017123982310295105
[5/24] Train loss=0.016719136387109756
[10/24] Train loss=0.023797255009412766
[15/24] Train loss=0.01805376447737217
[20/24] Train loss=0.02127242088317871
Test set avg_accuracy=86.18% avg_sensitivity=84.93%, avg_specificity=86.59% avg_auc=0.9226
Fold[10] Epoch: 116 [116/150 (77%)] Train loss=0.022385 Test loss=1.614014 Current lr=[0.00023663111696939568]

[0/24] Train loss=0.015240701846778393
[5/24] Train loss=0.019603783264756203
[10/24] Train loss=0.022993886843323708
[15/24] Train loss=0.02351219952106476
[20/24] Train loss=0.01553481724113226
Test set avg_accuracy=84.90% avg_sensitivity=87.15%, avg_specificity=84.16% avg_auc=0.9217
Fold[10] Epoch: 117 [117/150 (78%)] Train loss=0.022163 Test loss=1.910304 Current lr=[0.00022403461121794154]

[0/24] Train loss=0.019521990790963173
[5/24] Train loss=0.020400548353791237
[10/24] Train loss=0.02223605290055275
[15/24] Train loss=0.023283708840608597
[20/24] Train loss=0.03346305713057518
Test set avg_accuracy=85.96% avg_sensitivity=85.72%, avg_specificity=86.04% avg_auc=0.9228
Fold[10] Epoch: 118 [118/150 (79%)] Train loss=0.025440 Test loss=1.616542 Current lr=[0.00021168513365453685]

[0/24] Train loss=0.015797553583979607
[5/24] Train loss=0.018441876396536827
[10/24] Train loss=0.045561064034700394
[15/24] Train loss=0.016476813703775406
[20/24] Train loss=0.019362669438123703
Test set avg_accuracy=85.68% avg_sensitivity=86.25%, avg_specificity=85.49% avg_auc=0.9232
Fold[10] Epoch: 119 [119/150 (79%)] Train loss=0.022327 Test loss=1.934199 Current lr=[0.00019959373873412734]

[0/24] Train loss=0.02229137346148491
[5/24] Train loss=0.021860405802726746
[10/24] Train loss=0.03139781206846237
[15/24] Train loss=0.02426961623132229
[20/24] Train loss=0.019109072163701057
Test set avg_accuracy=86.11% avg_sensitivity=84.50%, avg_specificity=86.63% avg_auc=0.9224
Fold[10] Epoch: 120 [120/150 (80%)] Train loss=0.023333 Test loss=1.756678 Current lr=[0.00018777124989274104]

[0/24] Train loss=0.01929713971912861
[5/24] Train loss=0.015890944749116898
[10/24] Train loss=0.023403646424412727
[15/24] Train loss=0.019047070294618607
[20/24] Train loss=0.01691620424389839
Test set avg_accuracy=85.03% avg_sensitivity=86.46%, avg_specificity=84.56% avg_auc=0.9215
Fold[10] Epoch: 121 [121/150 (81%)] Train loss=0.020675 Test loss=1.867007 Current lr=[0.00017622824985904581]

[0/24] Train loss=0.018151989206671715
[5/24] Train loss=0.023017840459942818
[10/24] Train loss=0.023696236312389374
[15/24] Train loss=0.03802618011832237
[20/24] Train loss=0.01605432666838169
Test set avg_accuracy=85.74% avg_sensitivity=85.24%, avg_specificity=85.90% avg_auc=0.9219
Fold[10] Epoch: 122 [122/150 (81%)] Train loss=0.024326 Test loss=1.634944 Current lr=[0.00016497507118137483]

[0/24] Train loss=0.020285164937376976
[5/24] Train loss=0.025267422199249268
[10/24] Train loss=0.02321747876703739
[15/24] Train loss=0.0154640581458807
[20/24] Train loss=0.07533244043588638
Test set avg_accuracy=84.84% avg_sensitivity=86.04%, avg_specificity=84.45% avg_auc=0.9212
Fold[10] Epoch: 123 [123/150 (82%)] Train loss=0.024103 Test loss=1.694659 Current lr=[0.00015402178697869614]

[0/24] Train loss=0.021621819585561752
[5/24] Train loss=0.01895591802895069
[10/24] Train loss=0.027222750708460808
[15/24] Train loss=0.02600785717368126
[20/24] Train loss=0.02042524144053459
Test set avg_accuracy=85.48% avg_sensitivity=85.67%, avg_specificity=85.42% avg_auc=0.9216
Fold[10] Epoch: 124 [124/150 (83%)] Train loss=0.024061 Test loss=1.605641 Current lr=[0.00014337820192380758]

[0/24] Train loss=0.023342005908489227
[5/24] Train loss=0.03188678249716759
[10/24] Train loss=0.027221597731113434
[15/24] Train loss=0.02387545071542263
[20/24] Train loss=0.0205673985183239
Test set avg_accuracy=86.35% avg_sensitivity=84.29%, avg_specificity=87.03% avg_auc=0.9221
Fold[10] Epoch: 125 [125/150 (83%)] Train loss=0.024590 Test loss=1.464652 Current lr=[0.00013305384346682566]

[0/24] Train loss=0.026774125173687935
[5/24] Train loss=0.01651473343372345
[10/24] Train loss=0.01678326167166233
[15/24] Train loss=0.028345799073576927
[20/24] Train loss=0.01861710660159588
Test set avg_accuracy=85.79% avg_sensitivity=85.40%, avg_specificity=85.92% avg_auc=0.9218
Fold[10] Epoch: 126 [126/150 (84%)] Train loss=0.022192 Test loss=1.578347 Current lr=[0.000123057953306828]

[0/24] Train loss=0.013823249377310276
[5/24] Train loss=0.01738821528851986
[10/24] Train loss=0.028287002816796303
[15/24] Train loss=0.018997566774487495
[20/24] Train loss=0.01292335893958807
Test set avg_accuracy=85.39% avg_sensitivity=86.36%, avg_specificity=85.08% avg_auc=0.9220
Fold[10] Epoch: 127 [127/150 (85%)] Train loss=0.017951 Test loss=1.694618 Current lr=[0.00011339947911928136]

[0/24] Train loss=0.016031041741371155
[5/24] Train loss=0.02195250615477562
[10/24] Train loss=0.018852809444069862
[15/24] Train loss=0.025202171877026558
[20/24] Train loss=0.019489753991365433
Test set avg_accuracy=85.82% avg_sensitivity=85.51%, avg_specificity=85.92% avg_auc=0.9224
Fold[10] Epoch: 128 [128/150 (85%)] Train loss=0.021524 Test loss=1.556550 Current lr=[0.00010408706654665958]

[0/24] Train loss=0.012049448676407337
[5/24] Train loss=0.015008422546088696
[10/24] Train loss=0.016793958842754364
[15/24] Train loss=0.04719877615571022
[20/24] Train loss=0.01659110188484192
Test set avg_accuracy=85.57% avg_sensitivity=85.62%, avg_specificity=85.56% avg_auc=0.9224
Fold[10] Epoch: 129 [129/150 (86%)] Train loss=0.018207 Test loss=1.603972 Current lr=[9.512905145942295e-05]

[0/24] Train loss=0.01733756810426712
[5/24] Train loss=0.02000262401998043
[10/24] Train loss=0.020662786439061165
[15/24] Train loss=0.018940748646855354
[20/24] Train loss=0.016357041895389557
Test set avg_accuracy=85.76% avg_sensitivity=84.77%, avg_specificity=86.08% avg_auc=0.9225
Fold[10] Epoch: 130 [130/150 (87%)] Train loss=0.019898 Test loss=1.598855 Current lr=[8.653345249428563e-05]

[0/24] Train loss=0.01628989353775978
[5/24] Train loss=0.01472803670912981
[10/24] Train loss=0.020927514880895615
[15/24] Train loss=0.018557390198111534
[20/24] Train loss=0.015673493966460228
Test set avg_accuracy=85.83% avg_sensitivity=85.51%, avg_specificity=85.94% avg_auc=0.9221
Fold[10] Epoch: 131 [131/150 (87%)] Train loss=0.018793 Test loss=1.672910 Current lr=[7.830796387644887e-05]

[0/24] Train loss=0.013798211701214314
[5/24] Train loss=0.014608968049287796
[10/24] Train loss=0.020403170958161354
[15/24] Train loss=0.018755529075860977
[20/24] Train loss=0.012353937141597271
Test set avg_accuracy=85.35% avg_sensitivity=85.77%, avg_specificity=85.21% avg_auc=0.9218
Fold[10] Epoch: 132 [132/150 (88%)] Train loss=0.015368 Test loss=1.807260 Current lr=[7.045994853222816e-05]

[0/24] Train loss=0.013324683532118797
[5/24] Train loss=0.013790024444460869
[10/24] Train loss=0.039867863059043884
[15/24] Train loss=0.019197341054677963
[20/24] Train loss=0.013320974074304104
Test set avg_accuracy=85.51% avg_sensitivity=85.72%, avg_specificity=85.44% avg_auc=0.9222
Fold[10] Epoch: 133 [133/150 (89%)] Train loss=0.020172 Test loss=1.790135 Current lr=[6.299643149823697e-05]

[0/24] Train loss=0.016577526926994324
[5/24] Train loss=0.015318676829338074
[10/24] Train loss=0.024029701948165894
[15/24] Train loss=0.0215897336602211
[20/24] Train loss=0.013551592826843262
Test set avg_accuracy=85.98% avg_sensitivity=85.51%, avg_specificity=86.13% avg_auc=0.9228
Fold[10] Epoch: 134 [134/150 (89%)] Train loss=0.019396 Test loss=1.673501 Current lr=[5.5924093633027054e-05]

[0/24] Train loss=0.010358883067965508
[5/24] Train loss=0.014578921720385551
[10/24] Train loss=0.014055595733225346
[15/24] Train loss=0.022227533161640167
[20/24] Train loss=0.02216075174510479
Test set avg_accuracy=85.96% avg_sensitivity=85.30%, avg_specificity=86.18% avg_auc=0.9229
Fold[10] Epoch: 135 [135/150 (90%)] Train loss=0.016026 Test loss=1.616275 Current lr=[4.9249265636815606e-05]

[0/24] Train loss=0.011907944455742836
[5/24] Train loss=0.013705379329621792
[10/24] Train loss=0.015936512500047684
[15/24] Train loss=0.010886896401643753
[20/24] Train loss=0.012509908527135849
Test set avg_accuracy=85.94% avg_sensitivity=85.40%, avg_specificity=86.11% avg_auc=0.9228
Fold[10] Epoch: 136 [136/150 (91%)] Train loss=0.015130 Test loss=1.708195 Current lr=[4.297792238465137e-05]

[0/24] Train loss=0.014812937006354332
[5/24] Train loss=0.019386352971196175
[10/24] Train loss=0.01674400456249714
[15/24] Train loss=0.012033521197736263
[20/24] Train loss=0.008698957040905952
Test set avg_accuracy=85.16% avg_sensitivity=86.09%, avg_specificity=84.85% avg_auc=0.9225
Fold[10] Epoch: 137 [137/150 (91%)] Train loss=0.016502 Test loss=1.919024 Current lr=[3.7115677578091596e-05]

[0/24] Train loss=0.011357760988175869
[5/24] Train loss=0.011276843957602978
[10/24] Train loss=0.02168605849146843
[15/24] Train loss=0.017133837565779686
[20/24] Train loss=0.03096397966146469
Test set avg_accuracy=84.99% avg_sensitivity=86.09%, avg_specificity=84.63% avg_auc=0.9224
Fold[10] Epoch: 138 [138/150 (92%)] Train loss=0.017441 Test loss=1.998815 Current lr=[3.1667778720179716e-05]

[0/24] Train loss=0.014783162623643875
[5/24] Train loss=0.04479410499334335
[10/24] Train loss=0.03073979914188385
[15/24] Train loss=0.01603786274790764
[20/24] Train loss=0.016987258568406105
Test set avg_accuracy=85.01% avg_sensitivity=86.09%, avg_specificity=84.66% avg_auc=0.9225
Fold[10] Epoch: 139 [139/150 (93%)] Train loss=0.018465 Test loss=1.940546 Current lr=[2.6639102418218685e-05]

[0/24] Train loss=0.015796741470694542
[5/24] Train loss=0.019383925944566727
[10/24] Train loss=0.023072944954037666
[15/24] Train loss=0.01699974574148655
[20/24] Train loss=0.01761779934167862
Test set avg_accuracy=85.53% avg_sensitivity=85.99%, avg_specificity=85.39% avg_auc=0.9225
Fold[10] Epoch: 140 [140/150 (93%)] Train loss=0.019867 Test loss=1.868750 Current lr=[2.2034150018547385e-05]

[0/24] Train loss=0.0199652798473835
[5/24] Train loss=0.01438105758279562
[10/24] Train loss=0.027673397213220596
[15/24] Train loss=0.02493259310722351
[20/24] Train loss=0.017594724893569946
Test set avg_accuracy=86.00% avg_sensitivity=85.62%, avg_specificity=86.13% avg_auc=0.9226
Fold[10] Epoch: 141 [141/150 (94%)] Train loss=0.021430 Test loss=1.760778 Current lr=[1.7857043577226207e-05]

[0/24] Train loss=0.013164559379220009
[5/24] Train loss=0.01455342210829258
[10/24] Train loss=0.023465052247047424
[15/24] Train loss=0.024486396461725235
[20/24] Train loss=0.014858613722026348
Test set avg_accuracy=86.11% avg_sensitivity=85.46%, avg_specificity=86.32% avg_auc=0.9226
Fold[10] Epoch: 142 [142/150 (95%)] Train loss=0.018219 Test loss=1.714662 Current lr=[1.4111522170237992e-05]

[0/24] Train loss=0.01393314078450203
[5/24] Train loss=0.013281471095979214
[10/24] Train loss=0.016933409497141838
[15/24] Train loss=0.01153592485934496
[20/24] Train loss=0.010410822927951813
Test set avg_accuracy=86.24% avg_sensitivity=85.35%, avg_specificity=86.53% avg_auc=0.9226
Fold[10] Epoch: 143 [143/150 (95%)] Train loss=0.014233 Test loss=1.689189 Current lr=[1.0800938546509279e-05]

[0/24] Train loss=0.010347062721848488
[5/24] Train loss=0.019725756719708443
[10/24] Train loss=0.04214700683951378
[15/24] Train loss=0.01461300253868103
[20/24] Train loss=0.010004537180066109
Test set avg_accuracy=86.12% avg_sensitivity=85.51%, avg_specificity=86.32% avg_auc=0.9227
Fold[10] Epoch: 144 [144/150 (96%)] Train loss=0.017718 Test loss=1.693221 Current lr=[7.928256126745519e-06]

[0/24] Train loss=0.025804437696933746
[5/24] Train loss=0.013912133872509003
[10/24] Train loss=0.013681533746421337
[15/24] Train loss=0.012967892922461033
[20/24] Train loss=0.01129218190908432
Test set avg_accuracy=86.03% avg_sensitivity=85.72%, avg_specificity=86.13% avg_auc=0.9226
Fold[10] Epoch: 145 [145/150 (97%)] Train loss=0.018546 Test loss=1.735428 Current lr=[5.496046350768312e-06]

[0/24] Train loss=0.012501045130193233
[5/24] Train loss=0.015999378636479378
[10/24] Train loss=0.018831586465239525
[15/24] Train loss=0.012433123774826527
[20/24] Train loss=0.00888104923069477
Test set avg_accuracy=85.92% avg_sensitivity=85.72%, avg_specificity=85.99% avg_auc=0.9226
Fold[10] Epoch: 146 [146/150 (97%)] Train loss=0.013691 Test loss=1.776065 Current lr=[3.506486375728646e-06]

[0/24] Train loss=0.014072480611503124
[5/24] Train loss=0.013499952852725983
[10/24] Train loss=0.013126078993082047
[15/24] Train loss=0.016525257378816605
[20/24] Train loss=0.009625176899135113
Test set avg_accuracy=85.76% avg_sensitivity=85.88%, avg_specificity=85.71% avg_auc=0.9226
Fold[10] Epoch: 147 [147/150 (98%)] Train loss=0.015431 Test loss=1.782243 Current lr=[1.9613571272563405e-06]

[0/24] Train loss=0.022358911111950874
[5/24] Train loss=0.008496453054249287
[10/24] Train loss=0.044437337666749954
[15/24] Train loss=0.019046369940042496
[20/24] Train loss=0.010917997919023037
Test set avg_accuracy=85.68% avg_sensitivity=85.88%, avg_specificity=85.61% avg_auc=0.9226
Fold[10] Epoch: 148 [148/150 (99%)] Train loss=0.016490 Test loss=1.818875 Current lr=[8.620417052901256e-07]

[0/24] Train loss=0.010796407237648964
[5/24] Train loss=0.013537518680095673
[10/24] Train loss=0.01118643581867218
[15/24] Train loss=0.013493399135768414
[20/24] Train loss=0.010562799870967865
Test set avg_accuracy=85.68% avg_sensitivity=86.04%, avg_specificity=85.56% avg_auc=0.9226
Fold[10] Epoch: 149 [149/150 (99%)] Train loss=0.012986 Test loss=1.819899 Current lr=[2.0952414601628282e-07]

[0/24] Train loss=0.014007305726408958
[5/24] Train loss=0.013800382614135742
[10/24] Train loss=0.01469371560961008
[15/24] Train loss=0.01043570414185524
[20/24] Train loss=0.013267735950648785
Test set avg_accuracy=85.69% avg_sensitivity=85.99%, avg_specificity=85.59% avg_auc=0.9226
Fold[10] Epoch: 150 [150/150 (100%)] Train loss=0.014516 Test loss=1.819622 Current lr=[4.388541022775342e-09]

Fold[10] Result: acc=84.54% sen=88.75%, spe=83.18%, auc=0.93!
Fold[10] Avg_overlap=0.68%(0.22677474083920937)
Final Avg Result: avg_acc=86.89%(2.368668969916064) avg_sen=88.25% (2.2768378135773486) avg_spe=86.34% (3.546699933344496) avg_auc=0.95 (0.009734088727470544) avg_overlap=0.70% (0.06729343903448362)
